<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 10:27:17 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CAMEL-12031] KafkaConsumer stops consuming messages when exception occurs during offset commit</title>
                <link>https://issues.apache.org/jira/browse/CAMEL-12031</link>
                <project id="12311211" key="CAMEL">Camel</project>
                    <description>&lt;p&gt;When processing of messages takes longer than max session timeout, the consumer thread will end after receiving the &lt;b&gt;org.apache.kafka.clients.consumer.CommitFailedException&lt;/b&gt;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
       @Override
        &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void run() {
            &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; first = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
            &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; reConnect = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;

            &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (reConnect) {

                &lt;span class=&quot;code-comment&quot;&gt;// create consumer
&lt;/span&gt;                &lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt; threadClassLoader = &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().getContextClassLoader();
                &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
                    &lt;span class=&quot;code-comment&quot;&gt;// Kafka uses reflection &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; loading authentication settings, use its classloader
&lt;/span&gt;                    &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().setContextClassLoader(org.apache.kafka.clients.consumer.KafkaConsumer.&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;getClassLoader());
                    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.consumer = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.apache.kafka.clients.consumer.KafkaConsumer(kafkaProps);
                } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
                    &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().setContextClassLoader(threadClassLoader);
                }

                &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!first) {
                    &lt;span class=&quot;code-comment&quot;&gt;// skip one poll timeout before trying again
&lt;/span&gt;                    &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; delay = endpoint.getConfiguration().getPollTimeoutMs();
                    log.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Reconnecting {} to topic {} after {} ms&quot;&lt;/span&gt;, threadId, topicName, delay);
                    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
                        &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(delay);
                    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException e) {
                        &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().interrupt();
                    }
                }

                first = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;

                &lt;span class=&quot;code-comment&quot;&gt;// doRun keeps running until we either shutdown or is told to re-connect
&lt;/span&gt;                reConnect = doRun();
            }
        }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;b&gt;doRun()&lt;/b&gt; method returns false and the loop ends. It should be possible to let the proces continue after failed offset commit.&lt;/p&gt;

&lt;p&gt;I think the catch block inside &lt;b&gt;doRun&lt;/b&gt; method should look like this:&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
           ...
            } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptException e) {
                getExceptionHandler().handleException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Interrupted &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; consuming &quot;&lt;/span&gt; + threadId + &lt;span class=&quot;code-quote&quot;&gt;&quot; from kafka topic&quot;&lt;/span&gt;, e);
                log.info(&lt;span class=&quot;code-quote&quot;&gt;&quot;Unsubscribing {} from topic {}&quot;&lt;/span&gt;, threadId, topicName);
                consumer.unsubscribe();
                &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().interrupt();
            } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (org.apache.kafka.clients.consumer.CommitFailedException e) { &lt;span class=&quot;code-comment&quot;&gt;//or even org.apache.kafka.common.KafkaException
&lt;/span&gt;                getExceptionHandler().handleException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Error consuming &quot;&lt;/span&gt; + threadId + &lt;span class=&quot;code-quote&quot;&gt;&quot; from kafka topic&quot;&lt;/span&gt;, e);
                reConnect = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
            } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Exception e) {
                getExceptionHandler().handleException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Error consuming &quot;&lt;/span&gt; + threadId + &lt;span class=&quot;code-quote&quot;&gt;&quot; from kafka topic&quot;&lt;/span&gt;, e);
            } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
                log.debug(&lt;span class=&quot;code-quote&quot;&gt;&quot;Closing {} &quot;&lt;/span&gt;, threadId);
                IOHelper.close(consumer);
            }
            ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13120571">CAMEL-12031</key>
            <summary>KafkaConsumer stops consuming messages when exception occurs during offset commit</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davsclaus">Claus Ibsen</assignee>
                                    <reporter username="rgala">Rafa&#322; Ga&#322;a</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Nov 2017 06:09:41 +0000</created>
                <updated>Tue, 5 Mar 2019 10:00:30 +0000</updated>
                            <resolved>Mon, 18 Dec 2017 14:05:49 +0000</resolved>
                                    <version>2.20.0</version>
                                    <fixVersion>2.19.5</fixVersion>
                    <fixVersion>2.20.2</fixVersion>
                    <fixVersion>2.21.0</fixVersion>
                                    <component>camel-kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16265771" author="davsclaus" created="Sat, 25 Nov 2017 17:07:14 +0000"  >&lt;p&gt;Thanks for reporting yeah we can do a re-connect if kafka throws one of its exception. You are welcome to work on a patch as github PR&lt;/p&gt;</comment>
                            <comment id="16295225" author="rgala" created="Mon, 18 Dec 2017 16:36:23 +0000"  >&lt;p&gt;You were faster than me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;I did almost the same, but was not able to create a reliable test for that so I did not issue a pull request. I tried to simulate a Kafka session timeout in the test to cause a CommitFailedException,  but could not reduce session timeout on embedded Kafka and the test had to run for at least five minutes before the timeout occured.&lt;/p&gt;
</comment>
                            <comment id="16784275" author="eugenb" created="Tue, 5 Mar 2019 10:00:30 +0000"  >&lt;p&gt;It seams I can replicate this issue with&#160;camel-kafka 3.0.0.M1 release.&lt;/p&gt;

&lt;p&gt;On some topics on&#160;kafka I get reconnect issue when either changing the offset manually (start from beginning, or when new message comes in).&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2019-03-05 10:51:36.168 INFO 5400 --- [carbpandastest]] o.a.kafka.common.utils.AppInfoParser : Kafka version : 2.0.0
2019-03-05 10:51:36.168 INFO 5400 --- [carbpandastest]] o.a.kafka.common.utils.AppInfoParser : Kafka commitId : 3402a8361b734732
2019-03-05 10:51:36.168 INFO 5400 --- [carbpandastest]] o.a.camel.component.kafka.KafkaConsumer : Reconnecting carbpandastest-&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0 to topic carbpandastest after 5000 ms
2019-03-05 10:51:41.182 INFO 5400 --- [carbpandastest]] o.a.camel.component.kafka.KafkaConsumer : Subscribing carbpandastest-&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0 to topic carbpandastest
2019-03-05 10:51:41.229 INFO 5400 --- [carbpandastest]] org.apache.kafka.clients.Metadata : Cluster ID: SV04zC4aSJuPFIuouM0CZA
2019-03-05 10:51:41.229 INFO 5400 --- [carbpandastest]] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-47, groupId=1a981fbb-60c4-41b9-9051-8696a2b84cfc] Discovered group coordinator atgrzsl2929.avl01.avlcorp.lan:9092 (id: 2147483646 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
2019-03-05 10:51:41.229 INFO 5400 --- [carbpandastest]] o.a.k.c.c.internals.ConsumerCoordinator : [Consumer clientId=consumer-47, groupId=1a981fbb-60c4-41b9-9051-8696a2b84cfc] Revoking previously assigned partitions []
2019-03-05 10:51:41.229 INFO 5400 --- [carbpandastest]] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-47, groupId=1a981fbb-60c4-41b9-9051-8696a2b84cfc] (Re-)joining group
2019-03-05 10:51:41.307 INFO 5400 --- [carbpandastest]] o.a.k.c.c.internals.AbstractCoordinator : [Consumer clientId=consumer-47, groupId=1a981fbb-60c4-41b9-9051-8696a2b84cfc] Successfully joined group with generation 93
2019-03-05 10:51:41.307 INFO 5400 --- [carbpandastest]] o.a.k.c.c.internals.ConsumerCoordinator : [Consumer clientId=consumer-47, groupId=1a981fbb-60c4-41b9-9051-8696a2b84cfc] Setting newly assigned partitions [carbpandastest-0]
2019-03-05 10:51:41.354 WARN 5400 --- [carbpandastest]] o.a.camel.component.kafka.KafkaConsumer : KafkaException consuming carbpandastest-&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0 from topic carbpandastest. Will attempt to re-connect on next run
2019-03-05 10:51:41.385 INFO 5400 --- [carbpandastest]] o.a.k.clients.consumer.ConsumerConfig : ConsumerConfig values:
auto.commit.interval.ms = 5000
auto.offset.reset = latest
bootstrap.servers = [XXXXX:9092]
check.crcs = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
client.id =
connections.max.idle.ms = 540000
&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.api.timeout.ms = 60000
enable.auto.commit = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
exclude.internal.topics = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
fetch.max.bytes = 52428800
fetch.max.wait.ms = 500
fetch.min.bytes = 1
group.id = 1a981fbb-60c4-41b9-9051-8696a2b84cfc
heartbeat.interval.ms = 3000
interceptor.classes = []
internal.leave.group.on.close = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
isolation.level = read_uncommitted
key.deserializer = &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.kafka.common.serialization.IntegerDeserializer
max.partition.fetch.bytes = 1048576
max.poll.interval.ms = 300000
max.poll.records = 500
metadata.max.age.ms = 300000
metric.reporters = []
metrics.num.samples = 2
metrics.recording.level = INFO
metrics.sample.window.ms = 30000
partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]
receive.buffer.bytes = 65536
reconnect.backoff.max.ms = 1000
reconnect.backoff.ms = 50
request.timeout.ms = 40000
retry.backoff.ms = 100
sasl.client.callback.handler.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
sasl.jaas.config = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
sasl.kerberos.kinit.cmd = /usr/bin/kinit
sasl.kerberos.min.time.before.relogin = 60000
sasl.kerberos.service.name = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
sasl.kerberos.ticket.renew.jitter = 0.05
sasl.kerberos.ticket.renew.window.factor = 0.8
sasl.login.callback.handler.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
sasl.login.class = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
sasl.login.refresh.buffer.seconds = 300
sasl.login.refresh.min.period.seconds = 60
sasl.login.refresh.window.factor = 0.8
sasl.login.refresh.window.jitter = 0.05
sasl.mechanism = GSSAPI
security.protocol = PLAINTEXT
send.buffer.bytes = 131072
session.timeout.ms = 10000
ssl.cipher.suites = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
ssl.endpoint.identification.algorithm = https
ssl.key.password = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
ssl.keymanager.algorithm = SunX509
ssl.keystore.location = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
ssl.keystore.password = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
ssl.keystore.type = JKS
ssl.protocol = TLS
ssl.provider = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
ssl.secure.random.implementation = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
ssl.trustmanager.algorithm = PKIX
ssl.truststore.location = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
ssl.truststore.password = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
ssl.truststore.type = JKS
value.deserializer = &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;io.confluent.kafka.serializers.KafkaAvroDeserializer

2019-03-05 10:51:41.385 INFO 5400 --- [carbpandastest]] i.c.k.s.KafkaAvroDeserializerConfig : KafkaAvroDeserializerConfig values:
schema.registry.url = [http:&lt;span class=&quot;code-comment&quot;&gt;//XXXX:30002]
&lt;/span&gt;basic.auth.user.info = [hidden]
auto.register.schemas = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
max.schemas.per.subject = 1000
basic.auth.credentials.source = URL
schema.registry.basic.auth.user.info = [hidden]
specific.avro.reader = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
value.subject.name.strategy = &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;io.confluent.kafka.serializers.subject.TopicNameStrategy
key.subject.name.strategy = &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;io.confluent.kafka.serializers.subject.TopicNameStrategy
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310060" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Estimated Complexity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10061"><![CDATA[Novice]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 37 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3n5o7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>