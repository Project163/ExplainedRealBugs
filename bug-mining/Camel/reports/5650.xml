<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 10:46:35 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CAMEL-14980] camel-kafka - SerializationException - consumer keeps leaving and rejoining the group</title>
                <link>https://issues.apache.org/jira/browse/CAMEL-14980</link>
                <project id="12311211" key="CAMEL">Camel</project>
                    <description>&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I found out i few days ago that if a `SerializationException` is thrown when the consumer tries to poll messages, it will keep leaving and joining the consumer-group indefinitely and without any informative log.&lt;br/&gt;
 The exception cannot either be handled by any camel exception handler.&lt;/p&gt;

&lt;p&gt;After some searching in the code i found out the culprit:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// org.apache.camel.component.kafka.KafkaConsumer (ligns 406-415):
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (KafkaException e) {
 &#160;&lt;span class=&quot;code-comment&quot;&gt;// some kind of error in kafka, it may happen during
&lt;/span&gt; &#160;&lt;span class=&quot;code-comment&quot;&gt;// unsubscribing or during normal processing
&lt;/span&gt; &#160;&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (unsubscribing){ &#160; &#160; &#160; &#160; &#160; &#160; 
    getExceptionHandler().handleException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Error unsubscribing &quot;&lt;/span&gt; + threadId + &lt;span class=&quot;code-quote&quot;&gt;&quot; from kafka topic &quot;&lt;/span&gt; + topicName, e); &#160; 
  }&lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
 &#160; &#160;LOG.debug(&lt;span class=&quot;code-quote&quot;&gt;&quot;KafkaException consuming {} from topic {} causedby {}. Will attempt to re-connect on next run&quot;&lt;/span&gt;, threadId, topicName, e.getMessage());
 &#160; &#160;reConnect = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
 &#160;}
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;`SerializationException` extends from `KafkaException`, but it is definitely not a recoverable exception.&lt;/p&gt;

&lt;p&gt;It logs with debug level, which makes it hard to track, there are SO many things logging in debug.&lt;/p&gt;

&lt;p&gt;It it cannot be handled by any camel exception handling mechanism.&lt;/p&gt;

&lt;p&gt;I think it would be better to either:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;change that catch so that it pinpoints the subclasses of `KafkaException` that are actually recoverable from rejoining (maybe `WakeupException` and a couple others)&lt;/li&gt;
	&lt;li&gt;add a `catch` block for&#160;`SerializationException` and maybe `ConfigException` and `OAuthBearerConfigException` before, with a log error andallow the user to handle those exceptions&lt;/li&gt;
	&lt;li&gt;remove that catch block entirely and let users handle any KafkaException however they see fit.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Thank you&lt;/p&gt;</description>
                <environment></environment>
        <key id="13301708">CAMEL-14980</key>
            <summary>camel-kafka - SerializationException - consumer keeps leaving and rejoining the group</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davsclaus">Claus Ibsen</assignee>
                                    <reporter username="cless91">joseph m&apos;bimbi-bene</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Apr 2020 05:23:04 +0000</created>
                <updated>Mon, 22 Mar 2021 08:39:17 +0000</updated>
                            <resolved>Mon, 22 Mar 2021 08:24:56 +0000</resolved>
                                    <version>3.2.0</version>
                                    <fixVersion>3.9.0</fixVersion>
                                    <component>camel-kafka</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="17096086" author="ramu11" created="Thu, 30 Apr 2020 03:39:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cless91&quot; class=&quot;user-hover&quot; rel=&quot;cless91&quot;&gt;cless91&lt;/a&gt; Thanks for reporting.   It would be good to have multiple catch blocks to understand better about the error. I would look into it&lt;/p&gt;</comment>
                            <comment id="17097844" author="davsclaus" created="Sat, 2 May 2020 07:07:41 +0000"  >&lt;p&gt;The serialization error is that due to a posion message in kafka, that you cannot deseerialize? And is it the key or the value? And can you maybe post the stacktrace or some more details of this exception?&lt;/p&gt;</comment>
                            <comment id="17099026" author="cless91" created="Mon, 4 May 2020 15:13:29 +0000"  >&lt;p&gt;Hi.&lt;/p&gt;

&lt;p&gt;Indeed the serialization error is due to an avro message that the consumer cannot deserialize and it is the value.&lt;/p&gt;

&lt;p&gt;Here are the logs from Camel :&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2020-05-04 16:55:18.768  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-1, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Member consumer-1-3ce58863-302b-4be3-9b86-43a963ffe327 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
2020-05-04 16:55:18.866  INFO 13972 --- [umer[cont_hist]] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [http:&lt;span class=&quot;code-comment&quot;&gt;//localhost:9092]
&lt;/span&gt;	
	[...]

2020-05-04 16:55:18.925  WARN 13972 --- [umer[cont_hist]] o.a.k.clients.consumer.ConsumerConfig    : The configuration &lt;span class=&quot;code-quote&quot;&gt;&apos;sasl.kerberos.principal.to.local.rules&apos;&lt;/span&gt; was supplied but isn&apos;t a known config.
2020-05-04 16:55:18.925  INFO 13972 --- [umer[cont_hist]] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.3.1
2020-05-04 16:55:18.925  INFO 13972 --- [umer[cont_hist]] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 18a913733fb71c01
2020-05-04 16:55:18.925  INFO 13972 --- [umer[cont_hist]] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1588604118925
2020-05-04 16:55:18.927  INFO 13972 --- [umer[cont_hist]] o.a.camel.component.kafka.KafkaConsumer  : Reconnecting cont_hist-&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0 to topic cont_hist after 5000 ms
2020-05-04 16:55:23.928  INFO 13972 --- [umer[cont_hist]] o.a.camel.component.kafka.KafkaConsumer  : Subscribing cont_hist-&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0 to topic cont_hist
2020-05-04 16:55:23.928  INFO 13972 --- [umer[cont_hist]] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Subscribed to topic(s): cont_hist
2020-05-04 16:55:23.934  INFO 13972 --- [umer[cont_hist]] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Cluster ID: RN9Osn1cTTONG3zaT0LtOg
2020-05-04 16:55:23.936  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Discovered group coordinator localhost:9092 (id: 2147483646 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
2020-05-04 16:55:23.937  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Revoking previously assigned partitions []
2020-05-04 16:55:23.937  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] (Re-)joining group
2020-05-04 16:55:23.943  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] (Re-)joining group
2020-05-04 16:55:23.949  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Successfully joined group with generation 3
2020-05-04 16:55:23.949  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Setting newly assigned partitions: cont_hist-0
2020-05-04 16:55:23.954  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Setting offset &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition cont_hist-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), epoch=0}}
2020-05-04 16:55:23.978  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-2, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Member consumer-2-54cba12d-1a38-4a5d-8b50-26f2a6b3868a sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
2020-05-04 16:55:23.998  INFO 13972 --- [umer[cont_hist]] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [http:&lt;span class=&quot;code-comment&quot;&gt;//localhost:9092]
&lt;/span&gt;	
	[...]

2020-05-04 16:55:24.014  WARN 13972 --- [umer[cont_hist]] o.a.k.clients.consumer.ConsumerConfig    : The configuration &lt;span class=&quot;code-quote&quot;&gt;&apos;sasl.kerberos.principal.to.local.rules&apos;&lt;/span&gt; was supplied but isn&apos;t a known config.
2020-05-04 16:55:24.014  INFO 13972 --- [umer[cont_hist]] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.3.1
2020-05-04 16:55:24.014  INFO 13972 --- [umer[cont_hist]] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 18a913733fb71c01
2020-05-04 16:55:24.015  INFO 13972 --- [umer[cont_hist]] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1588604124014
2020-05-04 16:55:24.015  INFO 13972 --- [umer[cont_hist]] o.a.camel.component.kafka.KafkaConsumer  : Reconnecting cont_hist-&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0 to topic cont_hist after 5000 ms
2020-05-04 16:55:29.015  INFO 13972 --- [umer[cont_hist]] o.a.camel.component.kafka.KafkaConsumer  : Subscribing cont_hist-&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0 to topic cont_hist
2020-05-04 16:55:29.016  INFO 13972 --- [umer[cont_hist]] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Subscribed to topic(s): cont_hist
2020-05-04 16:55:29.032  INFO 13972 --- [umer[cont_hist]] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Cluster ID: RN9Osn1cTTONG3zaT0LtOg
2020-05-04 16:55:29.032  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Discovered group coordinator localhost:9092 (id: 2147483646 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
2020-05-04 16:55:29.033  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Revoking previously assigned partitions []
2020-05-04 16:55:29.034  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] (Re-)joining group
2020-05-04 16:55:29.039  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] (Re-)joining group
2020-05-04 16:55:29.048  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Successfully joined group with generation 5
2020-05-04 16:55:29.048  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Setting newly assigned partitions: cont_hist-0
2020-05-04 16:55:29.050  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Setting offset &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition cont_hist-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;), epoch=0}}
2020-05-04 16:55:29.066  INFO 13972 --- [umer[cont_hist]] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-3, groupId=6dde7e33-87c6-4ea7-a173-49e903d549e6] Member consumer-3-3da59636-0a83-4abc-9293-a7e456d65574 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
2020-05-04 16:55:29.090  INFO 13972 --- [umer[cont_hist]] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;There are no stack trace, it just keep leaving and joining the group.&lt;/p&gt;

&lt;p&gt;But here is the message when i place a breakpoint in org.apache.camel.component.kafka.KafkaConsumer, lign 409, then in the debugger, evaluate `e.printStackTrace` :&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.kafka.common.errors.SerializationException: Error deserializing key/value &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition cont_hist-0 at offset 4. If needed, please seek past the record to &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt; consumption.
 Caused by: org.apache.kafka.common.errors.SerializationException: Error deserializing Avro message &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; id 2
 Caused by: org.apache.kafka.common.errors.SerializationException: Could not find &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;fr.ing.payment.cardeventnotifier.secure3d.generated.avro.PocContHist2 specified in writer&lt;span class=&quot;code-quote&quot;&gt;&apos;s schema whilst finding reader&apos;&lt;/span&gt;s schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; a SpecificRecord.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In my re-creation of the error, I deliberately changed the name of the schema avro of the producer.&lt;/p&gt;

&lt;p&gt;Another case: when i send garbage through the console-producer. Here is what i get when i evaluate `e.printStackTrace()` on the breakpoint:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.kafka.common.errors.SerializationException: Error deserializing key/value &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition cont_hist-0 at offset 5. If needed, please seek past the record to &lt;span class=&quot;code-keyword&quot;&gt;continue&lt;/span&gt; consumption.
 Caused by: org.apache.kafka.common.errors.SerializationException: Error deserializing Avro message &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; id -1
 Caused by: org.apache.kafka.common.errors.SerializationException: Unknown magic &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;!&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In any case, this error is not printed, the consumer doesn&apos;t fail, the exception cannot be handled by an exceptionHandler, and the consumer leaves and joins the group indefinitely without any informative message.&lt;/p&gt;

&lt;p&gt;Is that enough or do you need any other information ?&lt;/p&gt;

&lt;p&gt;EDIT:&lt;br/&gt;
 I added a .txt file with some logs.&lt;/p&gt;

&lt;p&gt;EDIT2:&lt;br/&gt;
 I added a executable example if necessary&lt;/p&gt;</comment>
                            <comment id="17099555" author="ramu11" created="Tue, 5 May 2020 06:10:53 +0000"  >&lt;p&gt;Thanks for the logs and example. i will look in to it&lt;/p&gt;</comment>
                            <comment id="17147518" author="ramu11" created="Mon, 29 Jun 2020 03:15:23 +0000"  >&lt;p&gt;we can get rid of these type of issues by implementing deadletterqueue for kafka .&lt;/p&gt;

&lt;p&gt;we can implement a failure-strategy  similar to kafka-connect&lt;/p&gt;

&lt;p&gt;failure-strategy  : Specify the failure strategy to apply when a message produced from a record is nacked. Values can be fail (default), ignore, or dead-letter-queue&lt;/p&gt;

&lt;p&gt;Type: string&lt;/p&gt;

&lt;p&gt;supports 3 strategies:&lt;/p&gt;

&lt;p&gt;fail - fail the application, no more records will be processed. (default) The offset of the record that has not been processed correctly is not committed.&lt;/p&gt;

&lt;p&gt;ignore - the failure is logged, but the processing continue. The offset of the record that has not been processed correctly is committed.&lt;/p&gt;

&lt;p&gt;dead-letter-queue - the offset of the record that has not been processed correctly is committed, but the record is written to a (Kafka) dead letter topic.&lt;/p&gt;

&lt;p&gt;The strategy is selected using the failure-strategy attribute.&lt;/p&gt;

&lt;p&gt;In the case of dead-letter-queue, you can configure the following attributes:&lt;/p&gt;

&lt;p&gt;dead-letter-queue.topic: the topic to use to write the records not processed correctly, default is dead-letter-topic-$channel, with $channel being the name of the channel.&lt;/p&gt;

&lt;p&gt;dead-letter-queue.key.serializer: the serializer used to write the record key on the dead letter queue. By default, it deduces the serializer from the key deserializer.&lt;/p&gt;

&lt;p&gt;dead-letter-queue.value.serializer: the serializer used to write the record value on the dead letter queue. By default, it deduces the serializer from the value deserializer.&lt;/p&gt;

&lt;p&gt;The record written on the dead letter queue contains the dead-letter-reason header with the nack reason (message from the exception passed to the nack method). It may also contain the dead-letter-cause with the message from the cause, if any.&lt;/p&gt;

&lt;p&gt;your comments welcome&lt;/p&gt;</comment>
                            <comment id="17215056" author="bedla" created="Thu, 15 Oct 2020 22:39:52 +0000"  >&lt;p&gt;I think something like failture strategy is overcomplicating things. It is IMO not needed as Camel already have similar strategies implemented as errorHandler and user can use that with `bridgeErrorHandler=true`.&lt;/p&gt;

&lt;p&gt;First step is fixing that catch block. Reconnect should be attempted only for instances of `RetriableException`. All other types of `KafkaException` should be delegated to `ExceptionHandler`. There is another user with same problem&#160;&lt;a href=&quot;https://stackoverflow.com/questions/64366380/apache-camel-kafka-bridgeerrorhandler-not-working&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://stackoverflow.com/questions/64366380/apache-camel-kafka-bridgeerrorhandler-not-working&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17215192" author="cless91" created="Fri, 16 Oct 2020 05:16:25 +0000"  >&lt;p&gt;That&apos;s also my thought, and something i put in my original post&lt;/p&gt;</comment>
                            <comment id="17244504" author="davsclaus" created="Sat, 5 Dec 2020 14:13:10 +0000"  >&lt;p&gt;There is a new camel-kafka-vertx in 3.7 that rely on vertx-kafka client which should have more roboustness out of the box&lt;/p&gt;</comment>
                            <comment id="17250009" author="maroos" created="Tue, 15 Dec 2020 23:28:33 +0000"  >&lt;p&gt;I hit a very similar problem with that `catch` block under different conditions.&lt;/p&gt;

&lt;p&gt;If I provide invalid credentials (so not a recoverable situation) then SaslAuthenticationException is thrown by &apos;consumer.poll` and hits this problematic `catch` clause. Reconnect is attempted, fails again and we get into an infinite loop situation.&lt;/p&gt;

&lt;p&gt;The big problem is that there is no way for the application to know about this problem. I&apos;d like to write a custom Spring Boot Health Indicator that would return Health.down() in such a situation, but I don&apos;t see it possible as no information about the problem bubbles outside of that infinite loop.&lt;/p&gt;

&lt;p&gt;Attempting to reconnect only for RetriableExceptions sounds reasonable, other error situations should be handed back to Camel and made visible.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17305480" author="davsclaus" created="Sat, 20 Mar 2021 15:34:08 +0000"  >&lt;p&gt;Introducing a pluggable interface so you can configure a custom behaviour.&lt;/p&gt;

&lt;p&gt;The default will retry for RetriableException and other exceptions will be delegated to ExceptionHandler.&lt;/p&gt;

&lt;p&gt;There is a PR to review&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/camel/pull/5248&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/camel/pull/5248&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17305501" author="davsclaus" created="Sat, 20 Mar 2021 16:51:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cless91&quot; class=&quot;user-hover&quot; rel=&quot;cless91&quot;&gt;cless91&lt;/a&gt; thanks for the reproducer - With the PR then the serialize exception causes Camel to not retry and you can bridge to Camel&apos;s error handler (or not). And the kafka consumer is closed and terminated. &lt;/p&gt;

&lt;p&gt;I assume that in any kind of polling exception we should make camel-kafka consumer be able to do&lt;/p&gt;

&lt;p&gt;1) retry poll again (may fail forever, eg poison message)&lt;br/&gt;
2) fail and terminate (consumer is stopped/died - not sure if this is an ideal use-case)&lt;br/&gt;
3) if bridge error handler, then let camel error handler handle it, but keep consumer up to pickup next message&lt;/p&gt;

&lt;p&gt;And for all of this you can decide what to do per exception - so let some retry, and all others do 2 or 3.&lt;/p&gt;</comment>
                            <comment id="17305722" author="davsclaus" created="Sun, 21 Mar 2021 17:07:00 +0000"  >&lt;p&gt;The PR has been updated to be more smart and offer more control for the user to decide.&lt;/p&gt;
</comment>
                            <comment id="17305990" author="cless91" created="Mon, 22 Mar 2021 08:34:54 +0000"  >&lt;p&gt;Oh, thank you for the correction.&lt;br/&gt;
 I thought about opening a PR when i first discovered it, but refrained from it, especially after someone was assigned to it.&lt;br/&gt;
I was waiting for some reply like &quot;ok your potential solutions may work, go ahead, start a PR and we will go from there&quot;, or &quot;the solution Y might work better, would you mind starting a PR with an implementation of Y ?&quot;.&lt;br/&gt;
 Next time, i will be more brave and post that PR.&lt;/p&gt;

&lt;p&gt;I was writing off Camel since, as i was working with Kafka at work pretty much all the time, but i will give it another try with 3.9.0&lt;/p&gt;</comment>
                            <comment id="17305994" author="davsclaus" created="Mon, 22 Mar 2021 08:39:17 +0000"  >&lt;p&gt;Thanks Joseph, you are surely welcome to provide feedback on Camel 3.9 onwards. We plan to do more work on camel-kafka in upcoming releases for more features and also of course bugs and more hardening.&lt;/p&gt;

&lt;p&gt;The PR also improved stopping the camel kafka consumer in a more graceful manner when it was in this &quot;error state&quot;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="13002010" name="camel-kafka-errors.txt" size="9340" author="cless91" created="Mon, 4 May 2020 15:22:40 +0000"/>
                            <attachment id="13002012" name="poc_camel_kafka.tar.gz" size="112379" author="cless91" created="Mon, 4 May 2020 16:29:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310060" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Estimated Complexity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10060"><![CDATA[Unknown]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 34 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0e6zk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>