<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 10:23:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF Jira</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[CAMEL-11215] Camel Kafka component commits offsets in case of exceptions</title>
                <link>https://issues.apache.org/jira/browse/CAMEL-11215</link>
                <project id="12311211" key="CAMEL">Camel</project>
                    <description>&lt;p&gt;My processor in the router throws an exception but the Kafka component still commits the offsets. &lt;/p&gt;

&lt;p&gt;My route: (heavily redacted and modified)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;Route&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;from( &lt;span class=&quot;code-quote&quot;&gt;&quot;kafka:&lt;span class=&quot;code-comment&quot;&gt;//blah-blah&quot;&lt;/span&gt; ).routeId(&lt;span class=&quot;code-quote&quot;&gt;&quot;MyRoute&quot;&lt;/span&gt;)
&lt;/span&gt;                .convertBodyTo( MyData.class )
                .process( &lt;span class=&quot;code-quote&quot;&gt;&quot;MyProcessor&quot;&lt;/span&gt; )
                .to( &lt;span class=&quot;code-quote&quot;&gt;&quot;DestinationProcessor&quot;&lt;/span&gt; );
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The exception I get: &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;Exception&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        at com.mycompany.MyProcessor.process(MyProcessor.java:152)
        at org.apache.camel.impl.ProcessorEndpoint.onExchange(ProcessorEndpoint.java:103)
        at org.apache.camel.impl.ProcessorEndpoint$1.process(ProcessorEndpoint.java:71)
        at org.apache.camel.util.AsyncProcessorConverterHelper$ProcessorToAsyncProcessorBridge.process(AsyncProcessorConverterHelper.java:61)
        at org.apache.camel.processor.SendProcessor.process(SendProcessor.java:145)
        at org.apache.camel.management.InstrumentationProcessor.process(InstrumentationProcessor.java:77)
        at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:542)
        at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:197)
        at org.apache.camel.processor.ChoiceProcessor.process(ChoiceProcessor.java:117)
        at org.apache.camel.management.InstrumentationProcessor.process(InstrumentationProcessor.java:77)
        at org.apache.camel.processor.RedeliveryErrorHandler.process(RedeliveryErrorHandler.java:542)
        at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:197)
        at org.apache.camel.processor.Pipeline.process(Pipeline.java:120)
        at org.apache.camel.processor.Pipeline.process(Pipeline.java:83)
        at org.apache.camel.processor.CamelInternalProcessor.process(CamelInternalProcessor.java:197)
        at org.apache.camel.processor.DelegateAsyncProcessor.process(DelegateAsyncProcessor.java:97)
        at org.apache.camel.component.kafka.KafkaConsumer$KafkaFetchRecords.run(KafkaConsumer.java:140)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.sql.SQLException: Exception occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; getting connection: oracle.ucp.UniversalConnectionPoolException: Cannot get Connection from Datasource: java.sql.SQLException: Listener refused the connection with the following error:
ORA-12514, TNS:listener does not currently know of service requested in connect descriptor
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here is the corresponding Kafka component code:(KafkaConsumer.java) -This part of the code does not seem to handle the exception. The exception handler simply eats up the exception and the fall through code happily commits the offsets. Is this a bug? or am I missing something?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;KafkaConsumer.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (isRunAllowed() &amp;amp;&amp;amp; !isStoppingOrStopped() &amp;amp;&amp;amp; !isSuspendingOrSuspended()) {
                    ConsumerRecords&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt; allRecords = consumer.poll(pollTimeoutMs);
                    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (TopicPartition partition : allRecords.partitions()) {
                        List&amp;lt;ConsumerRecord&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt;&amp;gt; partitionRecords = allRecords
                            .records(partition);
                        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (ConsumerRecord&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt; record : partitionRecords) {
                            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (LOG.isTraceEnabled()) {
                                LOG.trace(&lt;span class=&quot;code-quote&quot;&gt;&quot;partition = {}, offset = {}, key = {}, value = {}&quot;&lt;/span&gt;, record.partition(), record.offset(), record.key(), record.value());
                            }
                            Exchange exchange = endpoint.createKafkaExchange(record);
                            &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
                                processor.process(exchange);
                            } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Exception e) {
                                getExceptionHandler().handleException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Error during processing&quot;&lt;/span&gt;, exchange, e);
                            }
                        }
                        &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; autocommit is &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&lt;/span&gt;                        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (endpoint.getConfiguration().isAutoCommitEnable() != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
                            &amp;amp;&amp;amp; !endpoint.getConfiguration().isAutoCommitEnable()) {
                            &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; partitionLastoffset = partitionRecords.get(partitionRecords.size() - 1).offset();
                            consumer.commitSync(Collections.singletonMap(
                                partition, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; OffsetAndMetadata(partitionLastoffset + 1)));
                        }
                    }
                }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Any insights are appreciated.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13067537">CAMEL-11215</key>
            <summary>Camel Kafka component commits offsets in case of exceptions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davsclaus">Claus Ibsen</assignee>
                                    <reporter username="rogerhill01234">Roger</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Apr 2017 21:57:02 +0000</created>
                <updated>Thu, 25 May 2017 12:38:19 +0000</updated>
                            <resolved>Thu, 25 May 2017 12:38:19 +0000</resolved>
                                    <version>2.18.3</version>
                                    <fixVersion>2.19.1</fixVersion>
                    <fixVersion>2.20.0</fixVersion>
                                    <component>camel-kafka</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16010273" author="davsclaus" created="Mon, 15 May 2017 10:09:38 +0000"  >&lt;p&gt;We should introduce an option to break out on first exception, then users can turn this on | off.&lt;/p&gt;

&lt;p&gt;Just mind about poison message problem if the same message keeps failing, then the offset wont advance. So you need some way of dealing with that.&lt;/p&gt;</comment>
                            <comment id="16010323" author="davsclaus" created="Mon, 15 May 2017 11:02:37 +0000"  >&lt;p&gt;And btw you can use Camel&apos;s error handler to try to handle such errors with retries, then you can possible resolve intermediate errors.&lt;/p&gt;</comment>
                            <comment id="16011885" author="davsclaus" created="Tue, 16 May 2017 07:23:08 +0000"  >&lt;p&gt;I created a branch with a potential fix&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/camel/tree/CAMEL-11215&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/camel/tree/CAMEL-11215&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You are welcome to checkout and build JARs from this branch and test on your system. You need to set the option breakOnFirstError=true on your Camel kafka endpoint uris to turn this functionality on. &lt;/p&gt;</comment>
                            <comment id="16011889" author="davsclaus" created="Tue, 16 May 2017 07:25:21 +0000"  >&lt;p&gt;When an unhandled exception is thrown the consumer will now now re-connect with one poll timeout as delay in between (default 5 sec). This allows a bit of backoff between retries. Also the last good offset is synced beforehand so the consumer should start with the failed message again&lt;/p&gt;</comment>
                            <comment id="16013048" author="rogerhill01234" created="Tue, 16 May 2017 20:20:13 +0000"  >&lt;p&gt;Thanks Claus!&lt;br/&gt;
We will checkout that branch and test it.&lt;br/&gt;
When will this be available on the release? &lt;/p&gt;</comment>
                            <comment id="16021118" author="davsclaus" created="Tue, 23 May 2017 12:16:28 +0000"  >&lt;p&gt;Roger, did you get a chance to test this?&lt;/p&gt;

&lt;p&gt;It will only be in a new release if it has been tested and we get some feedback on this.&lt;/p&gt;</comment>
                            <comment id="16021167" author="rogerhill01234" created="Tue, 23 May 2017 13:07:29 +0000"  >&lt;p&gt;Claus,&lt;br/&gt;
No. We have not got a chance to test it yet. We had changed our architecture to bypass this problem. We will get to this sometime in the future. Thanks for providing the fix quickly.&lt;br/&gt;
Roger&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310060" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Estimated Complexity</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10060"><![CDATA[Unknown]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 26 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3e7pr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>