diff --git a/.travis.yml b/.travis.yml
index 2d8808493..991102ea1 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -27,11 +27,14 @@ script:
     (cd diesel_codegen && travis-cargo test)
   fi &&
   if [[ "$TRAVIS_RUST_VERSION" == nightly* ]]; then
-    (cd diesel_tests && travis-cargo test -- --no-default-features --features unstable)
+    (cd diesel_tests && travis-cargo test -- --no-default-features --features "unstable $BACKEND")
   else
-    (cd diesel_tests && travis-cargo test)
+    (cd diesel_tests && travis-cargo test -- --features $BACKEND)
   fi
 env:
+  matrix:
+    - BACKEND=sqlite
+    - BACKEND=postgres
   global:
     - DATABASE_URL=postgres://postgres@localhost/
     - TRAVIS_CARGO_NIGHTLY_FEATURE=""
diff --git a/bin/test b/bin/test
index 6e7767d6a..710b61d23 100755
--- a/bin/test
+++ b/bin/test
@@ -2,4 +2,5 @@
 (cd diesel && cargo test --features "unstable chrono") &&
   (cd diesel_cli && cargo test) &&
   (cd diesel_codegen && cargo test --no-default-features --features nightly) &&
-  (cd diesel_tests && cargo test --features unstable --no-default-features)
+  (cd diesel_tests && cargo test --features "unstable postgres" --no-default-features)
+  (cd diesel_tests && cargo test --features "unstable sqlite" --no-default-features)
diff --git a/diesel/Cargo.toml b/diesel/Cargo.toml
index 85e673c72..123465eb8 100644
--- a/diesel/Cargo.toml
+++ b/diesel/Cargo.toml
@@ -12,6 +12,7 @@ keywords = ["orm", "database", "postgres", "postgresql", "sql"]
 [dependencies]
 libc = "0.2.*"
 pq-sys = "0.2.*"
+libsqlite3-sys = "^0.4.0"
 byteorder = "0.3.*"
 quickcheck = { git = "https://github.com/BurntSushi/quickcheck.git", optional = true }
 chrono = { version = "^0.2.17", optional = true }
diff --git a/diesel/src/backend.rs b/diesel/src/backend.rs
index 00efcc2aa..ac33e7733 100644
--- a/diesel/src/backend.rs
+++ b/diesel/src/backend.rs
@@ -1,6 +1,8 @@
+use connection::sqlite::SqliteValue;
 use query_builder::QueryBuilder;
-use query_builder::pg::PgQueryBuilder;
 use query_builder::debug::DebugQueryBuilder;
+use query_builder::pg::PgQueryBuilder;
+use query_builder::sqlite::SqliteQueryBuilder;
 use types::{self, HasSqlType};
 
 pub trait Backend where
@@ -43,7 +45,7 @@ impl SupportsReturningClause for Debug {}
 
 pub struct Pg;
 
-#[derive(Debug, Clone, Copy, Default)]
+#[derive(Debug, Clone, Copy)]
 pub struct PgTypeMetadata {
     pub oid: u32,
     pub array_oid: u32,
@@ -59,3 +61,24 @@ impl TypeMetadata for Pg {
 }
 
 impl SupportsReturningClause for Pg {}
+
+pub struct Sqlite;
+
+pub enum SqliteType {
+    Binary,
+    Text,
+    Float,
+    Double,
+    SmallInt,
+    Integer,
+    Long,
+}
+
+impl Backend for Sqlite {
+    type QueryBuilder = SqliteQueryBuilder;
+    type RawValue = SqliteValue;
+}
+
+impl TypeMetadata for Sqlite {
+    type TypeMetadata = SqliteType;
+}
diff --git a/diesel/src/connection/mod.rs b/diesel/src/connection/mod.rs
index d727fe5f1..eddd7715d 100644
--- a/diesel/src/connection/mod.rs
+++ b/diesel/src/connection/mod.rs
@@ -1,8 +1,10 @@
 extern crate libc;
 
 pub mod pg;
+pub mod sqlite;
 
 pub use self::pg::PgConnection;
+pub use self::sqlite::SqliteConnection;
 
 use backend::Backend;
 use query_builder::{AsQuery, QueryFragment};
diff --git a/diesel/src/connection/sqlite/mod.rs b/diesel/src/connection/sqlite/mod.rs
new file mode 100644
index 000000000..6247cb121
--- /dev/null
+++ b/diesel/src/connection/sqlite/mod.rs
@@ -0,0 +1,140 @@
+extern crate libsqlite3_sys as ffi;
+extern crate libc;
+
+#[doc(hidden)]
+pub mod raw;
+mod stmt;
+mod statement_iterator;
+mod sqlite_value;
+
+pub use self::sqlite_value::SqliteValue;
+
+use std::cell::Cell;
+use std::ffi::CStr;
+
+use backend::Sqlite;
+use query_builder::*;
+use query_builder::sqlite::SqliteQueryBuilder;
+use query_source::*;
+use result::*;
+use result::Error::QueryBuilderError;
+use self::raw::*;
+use self::stmt::*;
+use self::statement_iterator::StatementIterator;
+use super::{SimpleConnection, Connection};
+use types::HasSqlType;
+
+pub struct SqliteConnection {
+    raw_connection: RawConnection,
+    transaction_depth: Cell<i32>,
+}
+
+impl SimpleConnection for SqliteConnection {
+    fn batch_execute(&self, query: &str) -> QueryResult<()> {
+        self.raw_connection.exec(query)
+    }
+}
+
+impl Connection for SqliteConnection {
+    type Backend = Sqlite;
+
+    fn establish(database_url: &str) -> ConnectionResult<Self> {
+        RawConnection::establish(database_url).map(|conn| {
+            SqliteConnection {
+                raw_connection: conn,
+                transaction_depth: Cell::new(0),
+            }
+        })
+    }
+
+    fn execute(&self, query: &str) -> QueryResult<usize> {
+        try!(self.batch_execute(query));
+        Ok(self.raw_connection.rows_affected_by_last_query())
+    }
+
+    fn query_all<'a, T, U: 'a>(&self, source: T) -> QueryResult<Box<Iterator<Item=U> + 'a>> where
+        T: AsQuery,
+        T::Query: QueryFragment<Self::Backend>,
+        T::SqlType: 'a,
+        Self::Backend: HasSqlType<T::SqlType>,
+        U: Queryable<T::SqlType, Self::Backend>,
+    {
+        self.prepare_query(&source.as_query()).map(|stmt| {
+            Box::new(StatementIterator::new(stmt)) as Box<Iterator<Item=U>>
+        })
+    }
+
+    fn execute_returning_count<T>(&self, source: &T) -> QueryResult<usize> where
+        T: QueryFragment<Self::Backend>,
+    {
+        let stmt = try!(self.prepare_query(source));
+        try!(stmt.run());
+        Ok(self.raw_connection.rows_affected_by_last_query())
+    }
+
+    fn silence_notices<F: FnOnce() -> T, T>(&self, f: F) -> T {
+        f()
+    }
+
+    fn begin_transaction(&self) -> QueryResult<()> {
+        let transaction_depth = self.transaction_depth.get();
+        self.change_transaction_depth(1, if transaction_depth == 0 {
+            self.execute("BEGIN")
+        } else {
+            self.execute(&format!("SAVEPOINT diesel_savepoint_{}", transaction_depth))
+        })
+    }
+
+    fn rollback_transaction(&self) -> QueryResult<()> {
+        let transaction_depth = self.transaction_depth.get();
+        self.change_transaction_depth(-1, if transaction_depth == 1 {
+            self.execute("ROLLBACK")
+        } else {
+            self.execute(&format!("ROLLBACK TO SAVEPOINT diesel_savepoint_{}",
+                                  transaction_depth - 1))
+        })
+    }
+
+    fn commit_transaction(&self) -> QueryResult<()> {
+        let transaction_depth = self.transaction_depth.get();
+        self.change_transaction_depth(-1, if transaction_depth <= 1 {
+            self.execute("COMMIT")
+        } else {
+            self.execute(&format!("RELEASE SAVEPOINT diesel_savepoint_{}",
+                                  transaction_depth - 1))
+        })
+    }
+
+    fn get_transaction_depth(&self) -> i32 {
+        self.transaction_depth.get()
+    }
+}
+
+impl SqliteConnection {
+    fn prepare_query<T: QueryFragment<Sqlite>>(&self, source: &T) -> QueryResult<Statement> {
+        let mut query_builder = SqliteQueryBuilder::new();
+        try!(source.to_sql(&mut query_builder).map_err(QueryBuilderError));
+        let mut result = try!(Statement::prepare(&self.raw_connection, &query_builder.sql));
+
+        for (tpe, value) in query_builder.bind_params.into_iter() {
+            try!(result.bind(tpe, value));
+        }
+
+        Ok(result)
+    }
+
+    fn change_transaction_depth(&self, by: i32, query: QueryResult<usize>) -> QueryResult<()> {
+        if query.is_ok() {
+            self.transaction_depth.set(self.transaction_depth.get() + by);
+        }
+        query.map(|_| ())
+    }
+}
+
+fn error_message(err_code: libc::c_int) -> &'static str {
+    unsafe {
+        let message_ptr = ffi::sqlite3_errstr(err_code);
+        let result = CStr::from_ptr(message_ptr);
+        result.to_str().unwrap()
+    }
+}
diff --git a/diesel/src/connection/sqlite/raw.rs b/diesel/src/connection/sqlite/raw.rs
new file mode 100644
index 000000000..afcb0d15c
--- /dev/null
+++ b/diesel/src/connection/sqlite/raw.rs
@@ -0,0 +1,79 @@
+extern crate libsqlite3_sys as ffi;
+extern crate libc;
+
+use std::ffi::{CString, CStr};
+use std::io::{stderr, Write};
+use std::{ptr, str};
+
+use result::*;
+use result::Error::DatabaseError;
+
+pub struct RawConnection {
+    pub internal_connection: *mut ffi::sqlite3,
+}
+
+impl RawConnection {
+    pub fn establish(database_url: &str) -> ConnectionResult<Self> {
+        let mut conn_pointer = ptr::null_mut();
+        let database_url = try!(CString::new(database_url));
+        let connection_status = unsafe {
+            ffi::sqlite3_open(database_url.as_ptr(), &mut conn_pointer)
+        };
+
+        match connection_status {
+            ffi::SQLITE_OK => Ok(RawConnection {
+                internal_connection: conn_pointer,
+            }),
+            err_code => {
+                let message = super::error_message(err_code);
+                Err(ConnectionError::BadConnection(message.into()))
+            }
+        }
+    }
+
+    pub fn exec(&self, query: &str) -> QueryResult<()> {
+        let mut err_msg = ptr::null_mut();
+        let query = try!(CString::new(query));
+        let callback_fn = None;
+        let callback_arg = ptr::null_mut();
+        unsafe {
+            ffi::sqlite3_exec(
+                self.internal_connection,
+                query.as_ptr(),
+                callback_fn,
+                callback_arg,
+                &mut err_msg,
+            );
+        }
+
+        if !err_msg.is_null() {
+            let msg = convert_to_string_and_free(err_msg);
+            Err(DatabaseError(msg))
+        } else {
+            Ok(())
+        }
+    }
+
+    pub fn rows_affected_by_last_query(&self) -> usize {
+        unsafe { ffi::sqlite3_changes(self.internal_connection) as usize }
+    }
+}
+
+impl Drop for RawConnection {
+    fn drop(&mut self) {
+        let close_result = unsafe { ffi::sqlite3_close(self.internal_connection) };
+        if close_result != ffi::SQLITE_OK {
+            let error_message = super::error_message(close_result);
+            write!(stderr(), "Error closing SQLite connection: {}", error_message).unwrap();
+        }
+    }
+}
+
+fn convert_to_string_and_free(err_msg: *const libc::c_char) -> String {
+    let msg = unsafe {
+        let bytes = CStr::from_ptr(err_msg).to_bytes();
+        str::from_utf8_unchecked(bytes).into()
+    };
+    unsafe { ffi::sqlite3_free(err_msg as *mut libc::c_void) };
+    msg
+}
diff --git a/diesel/src/connection/sqlite/sqlite_value.rs b/diesel/src/connection/sqlite/sqlite_value.rs
new file mode 100644
index 000000000..75bd6a46f
--- /dev/null
+++ b/diesel/src/connection/sqlite/sqlite_value.rs
@@ -0,0 +1,92 @@
+extern crate libsqlite3_sys as ffi;
+extern crate libc;
+
+use std::ffi::CStr;
+use std::{slice, str};
+
+use backend::Sqlite;
+use row::Row;
+
+pub struct SqliteValue {
+    inner_statement: *mut ffi::sqlite3_stmt,
+    col_index: libc::c_int,
+}
+
+pub struct SqliteRow {
+    value: SqliteValue,
+    next_col_index: libc::c_int,
+}
+
+impl SqliteValue {
+    pub fn new(inner_statement: *mut ffi::sqlite3_stmt) -> Self {
+        SqliteValue {
+            inner_statement: inner_statement,
+            col_index: 0,
+        }
+    }
+
+    pub fn read_text(&self) -> Result<&str, str::Utf8Error> {
+        unsafe {
+            let ptr = ffi::sqlite3_column_text(self.inner_statement, self.col_index);
+            CStr::from_ptr(ptr as *const libc::c_char).to_str()
+        }
+    }
+
+    pub fn read_blob(&self) -> &[u8] {
+        unsafe {
+            let ptr = ffi::sqlite3_column_blob(self.inner_statement, self.col_index);
+            let len = ffi::sqlite3_column_bytes(self.inner_statement, self.col_index);
+            slice::from_raw_parts(ptr as *const u8, len as usize)
+        }
+    }
+
+    pub fn read_integer(&self) -> i32 {
+        unsafe {
+            ffi::sqlite3_column_int(self.inner_statement, self.col_index) as i32
+        }
+    }
+
+    pub fn read_long(&self) -> i64 {
+        unsafe {
+            ffi::sqlite3_column_int64(self.inner_statement, self.col_index) as i64
+        }
+    }
+
+    pub fn read_double(&self) -> f64 {
+        unsafe {
+            ffi::sqlite3_column_double(self.inner_statement, self.col_index) as f64
+        }
+    }
+}
+
+impl SqliteRow {
+    pub fn new(inner_statement: *mut ffi::sqlite3_stmt) -> Self {
+        SqliteRow {
+            value: SqliteValue::new(inner_statement),
+            next_col_index: 0,
+        }
+    }
+}
+
+impl Row<Sqlite> for SqliteRow {
+    fn take(&mut self) -> Option<&SqliteValue> {
+        let is_null = self.next_is_null(1);
+        self.value.col_index = self.next_col_index;
+        self.next_col_index += 1;
+        if is_null {
+            None
+        } else {
+            Some(&self.value)
+        }
+    }
+
+    fn next_is_null(&self, count: usize) -> bool {
+        (0..count).all(|i| {
+            let idx = self.next_col_index + i as libc::c_int;
+            let tpe = unsafe {
+                ffi::sqlite3_column_type(self.value.inner_statement, idx)
+            };
+            tpe == ffi::SQLITE_NULL
+        })
+    }
+}
diff --git a/diesel/src/connection/sqlite/statement_iterator.rs b/diesel/src/connection/sqlite/statement_iterator.rs
new file mode 100644
index 000000000..2bf108b1d
--- /dev/null
+++ b/diesel/src/connection/sqlite/statement_iterator.rs
@@ -0,0 +1,37 @@
+use std::marker::PhantomData;
+
+use backend::Sqlite;
+use super::stmt::Statement;
+use query_source::Queryable;
+use types::{HasSqlType, FromSqlRow};
+
+pub struct StatementIterator<ST, T> {
+    stmt: Statement,
+    _marker: PhantomData<(ST, T)>,
+}
+
+impl<ST, T> StatementIterator<ST, T> {
+    pub fn new(stmt: Statement) -> Self {
+        StatementIterator {
+            stmt: stmt,
+            _marker: PhantomData,
+        }
+    }
+}
+
+impl<ST, T> Iterator for StatementIterator<ST, T> where
+    Sqlite: HasSqlType<ST>,
+    T: Queryable<ST, Sqlite>,
+{
+    type Item = T;
+
+    fn next(&mut self) -> Option<T> {
+        self.stmt.step().map(|mut row| {
+            let values = match T::Row::build_from_row(&mut row) {
+                Ok(value) => value,
+                Err(reason) => panic!("Error reading values {}", reason.description()),
+            };
+            T::build(values)
+        })
+    }
+}
diff --git a/diesel/src/connection/sqlite/stmt.rs b/diesel/src/connection/sqlite/stmt.rs
new file mode 100644
index 000000000..6e536520a
--- /dev/null
+++ b/diesel/src/connection/sqlite/stmt.rs
@@ -0,0 +1,141 @@
+extern crate libsqlite3_sys as ffi;
+extern crate libc;
+extern crate byteorder;
+
+use self::byteorder::{ReadBytesExt, BigEndian};
+use std::ffi::CString;
+use std::io::{stderr, Write};
+use std::ptr;
+
+use backend::SqliteType;
+use result::*;
+use result::Error::{DatabaseError, QueryBuilderError};
+use super::raw::RawConnection;
+use super::sqlite_value::SqliteRow;
+
+pub struct Statement {
+    inner_statement: *mut ffi::sqlite3_stmt,
+    bind_index: libc::c_int,
+}
+
+impl Statement {
+    pub fn prepare(raw_connection: &RawConnection, sql: &str) -> QueryResult<Self> {
+        let mut stmt = ptr::null_mut();
+        let mut unused_portion = ptr::null();
+        let prepare_result = unsafe {
+            ffi::sqlite3_prepare_v2(
+                raw_connection.internal_connection,
+                try!(CString::new(sql)).as_ptr(),
+                sql.len() as libc::c_int,
+                &mut stmt,
+                &mut unused_portion,
+            )
+        };
+
+        ensure_sqlite_ok(prepare_result)
+            .map(|_| Statement { inner_statement: stmt, bind_index: 0 })
+    }
+
+    pub fn run(&self) -> QueryResult<()> {
+        match unsafe { ffi::sqlite3_step(self.inner_statement) } {
+            ffi::SQLITE_DONE | ffi::SQLITE_ROW => Ok(()),
+            error => Err(DatabaseError(super::error_message(error).into()))
+        }
+    }
+
+    pub fn bind(&mut self, tpe: SqliteType, value: Option<Vec<u8>>) -> QueryResult<()> {
+        self.bind_index += 1;
+        let result = unsafe { match (tpe, value) {
+            (_, None) =>
+                ffi::sqlite3_bind_null(self.inner_statement, self.bind_index),
+            (SqliteType::Binary, Some(bytes)) =>
+                ffi::sqlite3_bind_blob(
+                    self.inner_statement,
+                    self.bind_index,
+                    bytes.as_ptr() as *const libc::c_void,
+                    bytes.len() as libc::c_int,
+                    ffi::SQLITE_TRANSIENT(),
+                ),
+            (SqliteType::Text, Some(bytes)) =>
+                ffi::sqlite3_bind_text(
+                    self.inner_statement,
+                    self.bind_index,
+                    bytes.as_ptr() as *const libc::c_char,
+                    bytes.len() as libc::c_int,
+                    ffi::SQLITE_TRANSIENT(),
+                ),
+            (SqliteType::Float, Some(bytes)) => {
+                let value = try!((&bytes[..]).read_f32::<BigEndian>()
+                    .map_err(|e| QueryBuilderError(Box::new(e))));
+                ffi::sqlite3_bind_double(
+                    self.inner_statement,
+                    self.bind_index,
+                    value as libc::c_double,
+                )
+            }
+            (SqliteType::Double, Some(bytes)) => {
+                let value = try!((&bytes[..]).read_f64::<BigEndian>()
+                    .map_err(|e| QueryBuilderError(Box::new(e))));
+                ffi::sqlite3_bind_double(
+                    self.inner_statement,
+                    self.bind_index,
+                    value as libc::c_double,
+                )
+            }
+            (SqliteType::SmallInt, Some(bytes)) => {
+                let value = try!((&bytes[..]).read_i16::<BigEndian>()
+                    .map_err(|e| QueryBuilderError(Box::new(e))));
+                ffi::sqlite3_bind_int(
+                    self.inner_statement,
+                    self.bind_index,
+                    value as libc::c_int,
+                )
+            }
+            (SqliteType::Integer, Some(bytes)) => {
+                let value = try!((&bytes[..]).read_i32::<BigEndian>()
+                    .map_err(|e| QueryBuilderError(Box::new(e))));
+                ffi::sqlite3_bind_int(
+                    self.inner_statement,
+                    self.bind_index,
+                    value as libc::c_int,
+                )
+            }
+            (SqliteType::Long, Some(bytes)) => {
+                let value = try!((&bytes[..]).read_i64::<BigEndian>()
+                    .map_err(|e| QueryBuilderError(Box::new(e))));
+                ffi::sqlite3_bind_int64(
+                    self.inner_statement,
+                    self.bind_index,
+                    value,
+                )
+            }
+        }};
+
+        ensure_sqlite_ok(result)
+    }
+
+    pub fn step(&mut self) -> Option<SqliteRow> {
+        match unsafe { ffi::sqlite3_step(self.inner_statement) } {
+            ffi::SQLITE_DONE => None,
+            ffi::SQLITE_ROW => Some(SqliteRow::new(self.inner_statement)),
+            error => panic!("{}", super::error_message(error)),
+        }
+    }
+}
+
+fn ensure_sqlite_ok(code: libc::c_int) -> QueryResult<()> {
+    if code != ffi::SQLITE_OK {
+        Err(DatabaseError(super::error_message(code).into()))
+    } else {
+        Ok(())
+    }
+}
+
+impl Drop for Statement {
+    fn drop(&mut self) {
+        let finalize_result = unsafe { ffi::sqlite3_finalize(self.inner_statement) };
+        if let Err(e) = ensure_sqlite_ok(finalize_result) {
+            write!(stderr(), "Error finalizing SQLite prepared statement: {:?}", e).unwrap();
+        }
+    }
+}
diff --git a/diesel/src/doctest_setup.rs b/diesel/src/doctest_setup.rs
index 5a836e648..3a0d9e99f 100644
--- a/diesel/src/doctest_setup.rs
+++ b/diesel/src/doctest_setup.rs
@@ -2,7 +2,6 @@ extern crate dotenv;
 
 use diesel::prelude::*;
 use diesel::backend;
-use diesel::Connection;
 use self::dotenv::dotenv;
 
 fn connection_no_data() -> diesel::connection::PgConnection {
diff --git a/diesel/src/expression/extensions/interval_dsl.rs b/diesel/src/expression/extensions/interval_dsl.rs
index 5a3333564..4595fbd3c 100644
--- a/diesel/src/expression/extensions/interval_dsl.rs
+++ b/diesel/src/expression/extensions/interval_dsl.rs
@@ -248,7 +248,7 @@ mod tests {
     use self::dotenv::dotenv;
 
     use ::{types, select};
-    use connection::{Connection, PgConnection};
+    use connection::PgConnection;
     use data_types::PgInterval;
     use expression::dsl::sql;
     use prelude::*;
diff --git a/diesel/src/lib.rs b/diesel/src/lib.rs
index 47ebf3d86..33c6aeb2b 100644
--- a/diesel/src/lib.rs
+++ b/diesel/src/lib.rs
@@ -64,6 +64,7 @@ pub mod helper_types {
 
 pub mod prelude {
     //! Re-exports important traits and types. Meant to be glob imported when using Diesel.
+    pub use connection::Connection;
     pub use expression::{Expression, SelectableExpression, BoxableExpression};
     pub use expression::expression_methods::*;
     #[doc(inline)]
@@ -73,7 +74,6 @@ pub mod prelude {
     pub use result::{QueryResult, TransactionError, TransactionResult, ConnectionError, ConnectionResult, OptionalExtension};
 }
 
-pub use connection::Connection;
 pub use prelude::*;
 #[doc(inline)]
 pub use query_builder::functions::{insert, update, delete, select};
diff --git a/diesel/src/migrations/mod.rs b/diesel/src/migrations/mod.rs
index 678ac6d99..2c150c7f7 100644
--- a/diesel/src/migrations/mod.rs
+++ b/diesel/src/migrations/mod.rs
@@ -90,11 +90,20 @@ use std::path::{PathBuf, Path};
 pub fn run_pending_migrations<Conn>(conn: &Conn) -> Result<(), RunMigrationsError> where
     Conn: Connection,
     String: FromSql<VarChar, Conn::Backend>,
+{
+    let migrations_dir = try!(find_migrations_directory());
+    run_pending_migrations_in_directory(conn, &migrations_dir)
+}
+
+#[doc(hidden)]
+pub fn run_pending_migrations_in_directory<Conn>(conn: &Conn, migrations_dir: &Path)
+    -> Result<(), RunMigrationsError> where
+        Conn: Connection,
+        String: FromSql<VarChar, Conn::Backend>,
 {
     try!(create_schema_migrations_table_if_needed(conn));
     let already_run = try!(previously_run_migration_versions(conn));
-    let migrations_dir = try!(find_migrations_directory());
-    let all_migrations = try!(migrations_in_directory(&migrations_dir));
+    let all_migrations = try!(migrations_in_directory(migrations_dir));
     let pending_migrations = all_migrations.into_iter().filter(|m| {
         !already_run.contains(m.version())
     });
@@ -147,7 +156,7 @@ pub fn create_schema_migrations_table_if_needed<Conn: Connection>(conn: &Conn) -
     conn.silence_notices(|| {
         conn.execute("CREATE TABLE IF NOT EXISTS __diesel_schema_migrations (
             version VARCHAR PRIMARY KEY NOT NULL,
-            run_on TIMESTAMP NOT NULL DEFAULT NOW()
+            run_on TIMESTAMP NOT NULL DEFAULT 'now'
         )")
     })
 }
diff --git a/diesel/src/query_builder/mod.rs b/diesel/src/query_builder/mod.rs
index 1595fce3d..0a9c97e7f 100644
--- a/diesel/src/query_builder/mod.rs
+++ b/diesel/src/query_builder/mod.rs
@@ -1,8 +1,9 @@
 //! Contains traits responsible for the actual construction of SQL statements
-#[doc(hidden)]
-pub mod pg;
 pub mod debug;
 
+#[doc(hidden)] pub mod pg;
+#[doc(hidden)] pub mod sqlite;
+
 mod delete_statement;
 #[doc(hidden)]
 pub mod functions;
diff --git a/diesel/src/query_builder/sqlite.rs b/diesel/src/query_builder/sqlite.rs
new file mode 100644
index 000000000..74f0fa261
--- /dev/null
+++ b/diesel/src/query_builder/sqlite.rs
@@ -0,0 +1,44 @@
+use backend::{Sqlite, SqliteType};
+use super::{QueryBuilder, BuildQueryResult, Context};
+use types::HasSqlType;
+
+#[doc(hidden)]
+pub struct SqliteQueryBuilder {
+    pub sql: String,
+    pub bind_params: Vec<(SqliteType, Option<Vec<u8>>)>,
+}
+
+impl SqliteQueryBuilder {
+    pub fn new() -> Self {
+        SqliteQueryBuilder {
+            sql: String::new(),
+            bind_params: Vec::new(),
+        }
+    }
+}
+
+impl QueryBuilder<Sqlite> for SqliteQueryBuilder {
+    fn push_sql(&mut self, sql: &str) {
+        self.sql.push_str(sql);
+    }
+
+    fn push_identifier(&mut self, identifier: &str) -> BuildQueryResult {
+        self.push_sql("`");
+        self.push_sql(&identifier.replace("`", "``"));
+        self.push_sql("`");
+        Ok(())
+    }
+
+    fn push_bound_value<T>(&mut self, bind: Option<Vec<u8>>) where
+        Sqlite: HasSqlType<T>,
+    {
+        self.push_sql("?");
+        self.bind_params.push((Sqlite::metadata(), bind));
+    }
+
+    fn push_context(&mut self, _context: Context) {
+    }
+
+    fn pop_context(&mut self) {
+    }
+}
diff --git a/diesel/src/result.rs b/diesel/src/result.rs
index e98a35651..48db96402 100644
--- a/diesel/src/result.rs
+++ b/diesel/src/result.rs
@@ -3,7 +3,7 @@ use std::error::Error as StdError;
 use std::fmt::{self, Display, Write};
 use std::ffi::NulError;
 
-#[derive(Debug, PartialEq)]
+#[derive(Debug)]
 /// The generic "things can fail in a myriad of ways" enum. This type is not
 /// indended to be exhaustively matched, and new variants may be added in the
 /// future without a major version bump.
@@ -11,6 +11,7 @@ pub enum Error {
     InvalidCString(NulError),
     DatabaseError(String),
     NotFound,
+    QueryBuilderError(Box<StdError>),
     #[doc(hidden)]
     __Nonexhaustive,
 }
@@ -78,6 +79,7 @@ impl Display for Error {
             &Error::InvalidCString(ref nul_err) => nul_err.fmt(f),
             &Error::DatabaseError(ref s) => write!(f, "{}", &s),
             &Error::NotFound => f.write_str("NotFound"),
+            &Error::QueryBuilderError(ref e) => e.fmt(f),
             &Error::__Nonexhaustive => unreachable!(),
         }
     }
@@ -89,6 +91,7 @@ impl StdError for Error {
             &Error::InvalidCString(ref nul_err) => nul_err.description(),
             &Error::DatabaseError(ref s) => &s,
             &Error::NotFound => "Record not found",
+            &Error::QueryBuilderError(ref e) => e.description(),
             &Error::__Nonexhaustive => unreachable!(),
         }
     }
@@ -129,3 +132,14 @@ impl<E: StdError> StdError for TransactionError<E> {
         }
     }
 }
+
+impl PartialEq for Error {
+    fn eq(&self, other: &Error) -> bool {
+        match (self, other) {
+            (&Error::InvalidCString(ref a), &Error::InvalidCString(ref b)) => a == b,
+            (&Error::DatabaseError(ref a), &Error::DatabaseError(ref b)) => a == b,
+            (&Error::NotFound, &Error::NotFound) => true,
+            _ => false,
+        }
+    }
+}
diff --git a/diesel/src/types/impls/date_and_time/chrono.rs b/diesel/src/types/impls/date_and_time/chrono.rs
index 8d3a0ead6..a9b2d6e63 100644
--- a/diesel/src/types/impls/date_and_time/chrono.rs
+++ b/diesel/src/types/impls/date_and_time/chrono.rs
@@ -108,7 +108,7 @@ mod tests {
     use self::dotenv::dotenv;
 
     use ::select;
-    use connection::{Connection, PgConnection};
+    use connection::PgConnection;
     use expression::dsl::{sql, now};
     use prelude::*;
     use types::{Date, Time, Timestamp};
diff --git a/diesel/src/types/impls/date_and_time/mod.rs b/diesel/src/types/impls/date_and_time/mod.rs
index 99db12787..dd7c9089d 100644
--- a/diesel/src/types/impls/date_and_time/mod.rs
+++ b/diesel/src/types/impls/date_and_time/mod.rs
@@ -67,12 +67,10 @@ impl PgInterval {
     }
 }
 
-primitive_impls! {
-    Date -> (PgDate, 1082, 1182),
-    Interval -> (PgInterval, 1186, 1187),
-    Time -> (PgTime, 1083, 1183),
-    Timestamp -> (PgTimestamp, 1114, 1115),
-}
+primitive_impls!(Date -> (PgDate, pg: (1082, 1182), sqlite: (Text)));
+primitive_impls!(Interval -> (PgInterval, pg: (1186, 1187)));
+primitive_impls!(Time -> (PgTime, pg: (1083, 1183), sqlite: (Text)));
+primitive_impls!(Timestamp -> (PgTimestamp, pg: (1114, 1115), sqlite: (Text)));
 
 impl ToSql<types::Timestamp, Pg> for PgTimestamp {
     fn to_sql<W: Write>(&self, out: &mut W) -> Result<IsNull, Box<Error>> {
diff --git a/diesel/src/types/impls/date_and_time/std_time.rs b/diesel/src/types/impls/date_and_time/std_time.rs
index e32fab549..a7841f773 100644
--- a/diesel/src/types/impls/date_and_time/std_time.rs
+++ b/diesel/src/types/impls/date_and_time/std_time.rs
@@ -75,7 +75,7 @@ mod tests {
     use std::time::{SystemTime, Duration, UNIX_EPOCH};
 
     use ::select;
-    use connection::{Connection, PgConnection};
+    use connection::PgConnection;
     use expression::dsl::{sql, now};
     use prelude::*;
     use types::Timestamp;
diff --git a/diesel/src/types/impls/mod.rs b/diesel/src/types/impls/mod.rs
index 45724f1e2..7a20a3efd 100644
--- a/diesel/src/types/impls/mod.rs
+++ b/diesel/src/types/impls/mod.rs
@@ -92,28 +92,35 @@ macro_rules! queryable_impls {
 }
 
 macro_rules! primitive_impls {
-    ($($Source:ident -> ($Target:ty, $oid:expr, $array_oid:expr)),+,) => {
-        $(
-            impl types::HasSqlType<types::$Source> for $crate::backend::Pg {
-                fn metadata() -> $crate::backend::PgTypeMetadata {
-                    $crate::backend::PgTypeMetadata {
-                        oid: $oid,
-                        array_oid: $array_oid,
-                    }
-                }
+    ($Source:ident -> ($Target:ty, pg: ($oid:expr, $array_oid:expr), sqlite: ($tpe:ident))) => {
+        impl types::HasSqlType<types::$Source> for $crate::backend::Sqlite {
+            fn metadata() -> $crate::backend::SqliteType {
+                $crate::backend::SqliteType::$tpe
             }
+        }
 
-            impl types::HasSqlType<types::$Source> for $crate::backend::Debug {
-                fn metadata() {
-                    ()
+        primitive_impls!($Source -> ($Target, pg: ($oid, $array_oid)));
+    };
+
+    ($Source:ident -> ($Target:ty, pg: ($oid:expr, $array_oid:expr))) => {
+        impl types::HasSqlType<types::$Source> for $crate::backend::Pg {
+            fn metadata() -> $crate::backend::PgTypeMetadata {
+                $crate::backend::PgTypeMetadata {
+                    oid: $oid,
+                    array_oid: $array_oid,
                 }
             }
+        }
 
-            impl types::NotNull for types::$Source {
-            }
-        )+
-        queryable_impls!($($Source -> $Target),+,);
-        expression_impls!($($Source -> $Target),+,);
+        impl types::HasSqlType<types::$Source> for $crate::backend::Debug {
+            fn metadata() {}
+        }
+
+        impl types::NotNull for types::$Source {
+        }
+
+        queryable_impls!($Source -> $Target,);
+        expression_impls!($Source -> $Target,);
     }
 }
 
@@ -123,4 +130,5 @@ pub mod floats;
 mod integers;
 mod option;
 mod primitives;
+mod sqlite;
 mod tuples;
diff --git a/diesel/src/types/impls/primitives.rs b/diesel/src/types/impls/primitives.rs
index 4e520b694..ccec98de2 100644
--- a/diesel/src/types/impls/primitives.rs
+++ b/diesel/src/types/impls/primitives.rs
@@ -9,24 +9,22 @@ use super::option::UnexpectedNullError;
 use types::{HasSqlType, FromSql, ToSql, IsNull, NotNull};
 use {Queryable, types};
 
-primitive_impls! {
-    Bool -> (bool, 16, 1000),
+primitive_impls!(Bool -> (bool, pg: (16, 1000), sqlite: (Integer)));
 
-    SmallInt -> (i16, 21, 1005),
-    Integer -> (i32, 23, 1007),
-    BigInt -> (i64, 20, 1016),
+primitive_impls!(SmallInt -> (i16, pg: (21, 1005), sqlite: (SmallInt)));
+primitive_impls!(Integer -> (i32, pg: (23, 1007), sqlite: (Integer)));
+primitive_impls!(BigInt -> (i64, pg: (20, 1016), sqlite: (Long)));
 
-    Oid -> (u32, 26, 1018),
+primitive_impls!(Oid -> (u32, pg: (26, 1018)));
 
-    Float -> (f32, 700, 1021),
-    Double -> (f64, 701, 1022),
-    Numeric -> (PgNumeric, 1700, 1231),
+primitive_impls!(Float -> (f32, pg: (700, 1021), sqlite: (Float)));
+primitive_impls!(Double -> (f64, pg: (701, 1022), sqlite: (Double)));
+primitive_impls!(Numeric -> (PgNumeric, pg: (1700, 1231), sqlite: (Text)));
 
-    VarChar -> (String, 1043, 1015),
-    Text -> (String, 25, 1009),
+primitive_impls!(VarChar -> (String, pg: (1043, 1015), sqlite: (Text)));
+primitive_impls!(Text -> (String, pg: (25, 1009), sqlite: (Text)));
 
-    Binary -> (Vec<u8>, 17, 1001),
-}
+primitive_impls!(Binary -> (Vec<u8>, pg: (17, 1001), sqlite: (Binary)));
 
 expression_impls! {
     VarChar -> &'a str,
diff --git a/diesel/src/types/impls/sqlite.rs b/diesel/src/types/impls/sqlite.rs
new file mode 100644
index 000000000..16df05dee
--- /dev/null
+++ b/diesel/src/types/impls/sqlite.rs
@@ -0,0 +1,56 @@
+use std::error::Error;
+
+use backend::Sqlite;
+use connection::sqlite::SqliteValue;
+use super::option::UnexpectedNullError;
+use types::{self, FromSql};
+
+impl FromSql<types::VarChar, Sqlite> for String {
+    fn from_sql(value: Option<&SqliteValue>) -> Result<Self, Box<Error>> {
+        let text = try!(not_none!(value).read_text());
+        Ok(text.into())
+    }
+}
+
+impl FromSql<types::Binary, Sqlite> for Vec<u8> {
+    fn from_sql(bytes: Option<&SqliteValue>) -> Result<Self, Box<Error>> {
+        let bytes = not_none!(bytes).read_blob();
+        Ok(bytes.into())
+    }
+}
+
+impl FromSql<types::SmallInt, Sqlite> for i16 {
+    fn from_sql(value: Option<&SqliteValue>) -> Result<Self, Box<Error>> {
+        Ok(not_none!(value).read_integer() as i16)
+    }
+}
+
+impl FromSql<types::Integer, Sqlite> for i32 {
+    fn from_sql(value: Option<&SqliteValue>) -> Result<Self, Box<Error>> {
+        Ok(not_none!(value).read_integer())
+    }
+}
+
+impl FromSql<types::Bool, Sqlite> for bool {
+    fn from_sql(value: Option<&SqliteValue>) -> Result<Self, Box<Error>> {
+        Ok(not_none!(value).read_integer() != 0)
+    }
+}
+
+impl FromSql<types::BigInt, Sqlite> for i64 {
+    fn from_sql(value: Option<&SqliteValue>) -> Result<Self, Box<Error>> {
+        Ok(not_none!(value).read_long())
+    }
+}
+
+impl FromSql<types::Float, Sqlite> for f32 {
+    fn from_sql(value: Option<&SqliteValue>) -> Result<Self, Box<Error>> {
+        Ok(not_none!(value).read_double() as f32)
+    }
+}
+
+impl FromSql<types::Double, Sqlite> for f64 {
+    fn from_sql(value: Option<&SqliteValue>) -> Result<Self, Box<Error>> {
+        Ok(not_none!(value).read_double())
+    }
+}
diff --git a/diesel/src/types/impls/tuples.rs b/diesel/src/types/impls/tuples.rs
index a2c9b7880..876e886ce 100644
--- a/diesel/src/types/impls/tuples.rs
+++ b/diesel/src/types/impls/tuples.rs
@@ -22,10 +22,9 @@ macro_rules! tuple_impls {
             impl<$($T),+, DB> HasSqlType<($($T,)+)> for DB where
                 $(DB: HasSqlType<$T>),+,
                 DB: Backend,
-                DB::TypeMetadata: Default,
             {
                 fn metadata() -> DB::TypeMetadata {
-                    Default::default()
+                    unreachable!("Tuples should never implement `ToSql` directly");
                 }
             }
 
diff --git a/diesel_tests/Cargo.toml b/diesel_tests/Cargo.toml
index e922f1cfc..0ad1b7f15 100644
--- a/diesel_tests/Cargo.toml
+++ b/diesel_tests/Cargo.toml
@@ -26,6 +26,8 @@ quickcheck = { git = "https://github.com/BurntSushi/quickcheck.git" }
 default = ["syntex", "diesel_codegen/with-syntex", "dotenv_codegen"]
 unstable = ["compiletest_rs", "diesel_codegen/nightly", "diesel/unstable",
   "quickcheck/unstable", "dotenv_macros"]
+postgres = []
+sqlite = []
 
 [[test]]
 name = "compile_tests"
diff --git a/diesel_tests/build.rs b/diesel_tests/build.rs
index f8bdcafb1..6814ca7d9 100644
--- a/diesel_tests/build.rs
+++ b/diesel_tests/build.rs
@@ -36,6 +36,7 @@ fn main() {
     let database_url = ::std::env::var("DATABASE_URL")
         .expect("DATABASE_URL must be set to run tests");
     let connection = PgConnection::establish(&database_url).unwrap();
-    migrations::run_pending_migrations(&connection).unwrap();
+    let migrations_dir = migrations::find_migrations_directory().unwrap().join("postgresql");
+    migrations::run_pending_migrations_in_directory(&connection, &migrations_dir).unwrap();
     inner::main();
 }
diff --git a/diesel_tests/tests/compile-fail/insert_statement_does_not_support_returning_methods_on_sqlite.rs b/diesel_tests/tests/compile-fail/insert_statement_does_not_support_returning_methods_on_sqlite.rs
new file mode 100644
index 000000000..aed137659
--- /dev/null
+++ b/diesel_tests/tests/compile-fail/insert_statement_does_not_support_returning_methods_on_sqlite.rs
@@ -0,0 +1,62 @@
+#[macro_use]
+extern crate diesel;
+
+use diesel::*;
+use diesel::backend::Backend;
+use diesel::connection::SqliteConnection;
+use diesel::types::{Integer, VarChar};
+
+table! {
+    users {
+        id -> Serial,
+        name -> VarChar,
+    }
+}
+
+pub struct User {
+    id: i32,
+    name: String,
+}
+
+use diesel::types::FromSqlRow;
+
+impl<DB: Backend> Queryable<(Integer, VarChar), DB> for User where
+    (i32, String): FromSqlRow<(Integer, VarChar), DB>,
+{
+    type Row = (i32, String);
+
+    fn build(row: Self::Row) -> Self {
+        User {
+            id: row.0,
+            name: row.1,
+        }
+    }
+}
+
+pub struct NewUser(String);
+
+use diesel::expression::AsExpression;
+use diesel::expression::grouped::Grouped;
+use diesel::expression::helper_types::AsExpr;
+
+impl<'a> Insertable<users::table> for &'a NewUser {
+    type Columns = users::name;
+    type Values = Grouped<AsExpr<&'a String, users::name>>;
+
+    fn columns() -> Self::Columns {
+        users::name
+    }
+
+    fn values(self) -> Self::Values {
+        Grouped(<&'a String as AsExpression<VarChar>>::as_expression(&self.0))
+    }
+}
+
+fn main() {
+    let connection = SqliteConnection::establish(":memory:").unwrap();
+
+    insert(&NewUser("Hello".into()))
+        .into(users::table)
+        .get_result::<User>(&connection);
+    //~^ ERROR: SupportsReturningClause
+}
diff --git a/diesel_tests/tests/filter.rs b/diesel_tests/tests/filter.rs
index 8a4a0af10..71036dce2 100644
--- a/diesel_tests/tests/filter.rs
+++ b/diesel_tests/tests/filter.rs
@@ -31,6 +31,47 @@ fn filter_by_string_equality() {
     assert_eq!(Err(NotFound), users.filter(name.eq("Jim")).first::<User>(&connection));
 }
 
+#[test]
+fn sqlite_empty() {
+    use diesel::connection::SqliteConnection;
+    use schema::users::dsl::*;
+
+    let connection = SqliteConnection::establish(":memory:").unwrap();
+    connection.execute("
+        CREATE TABLE users (
+          id INTEGER PRIMARY KEY AUTOINCREMENT,
+          name VARCHAR NOT NULL,
+          hair_color VARCHAR
+        )").unwrap();
+
+    assert_eq!(Vec::<User>::new(), users.load(&connection).unwrap().collect::<Vec<User>>());
+}
+
+#[test]
+fn zomg_sqlite() {
+    use diesel::connection::SqliteConnection;
+    use schema::users::dsl::*;
+
+    let connection = SqliteConnection::establish(":memory:").unwrap();
+    connection.execute("
+        CREATE TABLE users (
+          id INTEGER PRIMARY KEY AUTOINCREMENT,
+          name VARCHAR NOT NULL,
+          hair_color VARCHAR
+        )").unwrap();
+    insert(&vec![NewUser::new("Sean", None), NewUser::new("Tess", None)])
+        .into(users)
+        .execute(&connection)
+        .unwrap();
+    let data = users.load(&connection).unwrap().collect::<Vec<User>>();
+    let sean = &data[0];
+    let tess = &data[1];
+
+    assert_eq!(Ok(sean), users.filter(name.eq("Sean")).first(&connection).as_ref());
+    assert_eq!(Ok(tess), users.filter(name.eq("Tess")).first(&connection).as_ref());
+    assert_eq!(Err(NotFound), users.filter(name.eq("Jim")).first::<User>(&connection));
+}
+
 #[test]
 fn filter_by_equality_on_nullable_columns() {
     use schema::users::dsl::*;
@@ -88,6 +129,7 @@ fn filter_by_is_null_on_nullable_columns() {
 }
 
 #[test]
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 fn filter_after_joining() {
     use schema::users::name;
 
@@ -247,6 +289,7 @@ fn filter_with_or() {
 }
 
 #[test]
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 fn or_doesnt_mess_with_precidence_of_previous_statements() {
     use schema::users::dsl::*;
     use diesel::expression::AsExpression;
@@ -268,6 +311,7 @@ use diesel::types::VarChar;
 sql_function!(lower, lower_t, (x: VarChar) -> VarChar);
 
 #[test]
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 fn filter_by_boxed_predicate() {
     fn by_name(name: &str) -> Box<BoxableExpression<users::table, types::Bool, Pg, SqlType=types::Bool>> {
         Box::new(lower(users::name).eq(name.to_string()))
diff --git a/diesel_tests/tests/filter_operators.rs b/diesel_tests/tests/filter_operators.rs
index 4b4ea726a..adf3dd402 100644
--- a/diesel_tests/tests/filter_operators.rs
+++ b/diesel_tests/tests/filter_operators.rs
@@ -104,6 +104,7 @@ fn filter_by_like() {
 }
 
 #[test]
+#[cfg(feature = "postgres")]
 fn filter_by_any() {
     use schema::users::dsl::*;
     use diesel::expression::dsl::any;
@@ -131,7 +132,7 @@ impl<U> TestResultHelpers<U> for QueryResult<Box<Iterator<Item=U>>> {
     }
 }
 
-fn connection_with_3_users() -> PgConnection {
+fn connection_with_3_users() -> TestConnection {
     let connection = connection_with_sean_and_tess_in_users_table();
     connection.execute("INSERT INTO users (id, name) VALUES (3, 'Jim')").unwrap();
     connection
diff --git a/diesel_tests/tests/insert.rs b/diesel_tests/tests/insert.rs
index 91cd6ddd8..51e713209 100644
--- a/diesel_tests/tests/insert.rs
+++ b/diesel_tests/tests/insert.rs
@@ -40,6 +40,7 @@ fn insert_records_using_returning_clause() {
 }
 
 #[test]
+#[cfg(feature = "postgres")] // FIXME: This test should run on everything, the only difference is create table syntax.
 fn insert_with_defaults() {
     use schema::users::table as users;
     let connection = connection();
@@ -65,6 +66,63 @@ fn insert_with_defaults() {
 }
 
 #[test]
+#[should_panic] // FIXME: SQLite has no DEFAULT keyword. We need to work around this.
+#[cfg(feature = "sqlite")] // FIXME: This test should run on everything, the only difference is create table syntax.
+fn insert_with_defaults() {
+    use schema::users::table as users;
+    use diesel::expression::dsl::sql;
+    let connection = connection();
+    connection.execute("DROP TABLE users").unwrap();
+    connection.execute("CREATE TABLE users (
+        id INTEGER PRIMARY KEY AUTOINCREMENT,
+        name VARCHAR NOT NULL,
+        hair_color VARCHAR NOT NULL DEFAULT 'Green'
+    )").unwrap();
+
+    let new_users: &[_] = &[
+        NewUser::new("Sean", Some("Black")),
+        NewUser::new("Tess", None),
+    ];
+    insert(new_users).into(users).execute(&connection).unwrap();
+
+    let expected_users = vec![
+        User { id: 1, name: "Sean".to_string(), hair_color: Some("Black".to_string()) },
+        User { id: 2, name: "Tess".to_string(), hair_color: Some("Green".to_string()) },
+    ];
+    let actual_users: Vec<_> = users.load(&connection).unwrap().collect();
+
+    assert_eq!(expected_users, actual_users);
+}
+
+#[test]
+#[cfg(feature = "postgres")] // FIXME: This test should run on everything, the only difference is create table syntax.
+fn insert_with_defaults_not_provided() {
+    use schema::users::table as users;
+    let connection = connection();
+    connection.execute("DROP TABLE users").unwrap();
+    connection.execute("CREATE TABLE users (
+        id SERIAL PRIMARY KEY,
+        name VARCHAR NOT NULL,
+        hair_color VARCHAR NOT NULL DEFAULT 'Green'
+    )").unwrap();
+    let new_users: &[_] = &[
+        BaldUser { name: "Sean".to_string() },
+        BaldUser { name: "Tess".to_string() },
+    ];
+    insert(new_users).into(users).execute(&connection).unwrap();
+
+    let expected_users = vec![
+        User { id: 1, name: "Sean".to_string(), hair_color: Some("Green".to_string()) },
+        User { id: 2, name: "Tess".to_string(), hair_color: Some("Green".to_string()) },
+    ];
+    let actual_users: Vec<_> = users.load(&connection).unwrap().collect();
+
+    assert_eq!(expected_users, actual_users);
+}
+
+#[test]
+#[should_panic] // FIXME: SQLite has no DEFAULT keyword. We need to work around this.
+#[cfg(feature = "sqlite")] // FIXME: This test should run on everything, the only difference is create table syntax.
 fn insert_with_defaults_not_provided() {
     use schema::users::table as users;
     let connection = connection();
diff --git a/diesel_tests/tests/lib.in.rs b/diesel_tests/tests/lib.in.rs
index c46bd5d81..59da35980 100644
--- a/diesel_tests/tests/lib.in.rs
+++ b/diesel_tests/tests/lib.in.rs
@@ -1,5 +1,7 @@
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 mod annotations;
 mod deserialization;
 mod insert;
 mod schema;
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 mod update;
diff --git a/diesel_tests/tests/lib.rs b/diesel_tests/tests/lib.rs
index dc01773df..04cb95eb6 100644
--- a/diesel_tests/tests/lib.rs
+++ b/diesel_tests/tests/lib.rs
@@ -10,18 +10,23 @@ include!("lib.in.rs");
 #[cfg(not(feature = "unstable"))]
 include!(concat!(env!("OUT_DIR"), "/lib.rs"));
 
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 mod associations;
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 mod expressions;
 mod filter;
 mod filter_operators;
 mod find;
 mod internal_details;
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 mod joins;
 mod macros;
 mod order;
 mod perf_details;
 mod select;
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 mod transactions;
+#[cfg(feature = "postgres")] // FIXME: There are valuable tests for SQLite here
 mod types;
 mod types_roundtrip;
 mod debug;
diff --git a/diesel_tests/tests/macros.rs b/diesel_tests/tests/macros.rs
index 587c2ca60..46de1db56 100644
--- a/diesel_tests/tests/macros.rs
+++ b/diesel_tests/tests/macros.rs
@@ -1,3 +1,8 @@
+// FIXME: We need to support SQL functions on SQLite. The test itself will
+// probably need to change to deal with how SQLite handles functions. I do not
+// think we need to generically support creation of these functions, as it's
+// different enough in SQLite to avoid.
+#![cfg(feature = "postgres")]
 use schema::*;
 use diesel::*;
 use diesel::types::VarChar;
diff --git a/diesel_tests/tests/schema.rs b/diesel_tests/tests/schema.rs
index fcc2531b2..b6c509a3e 100644
--- a/diesel_tests/tests/schema.rs
+++ b/diesel_tests/tests/schema.rs
@@ -1,5 +1,4 @@
 use diesel::*;
-pub use diesel::connection::PgConnection;
 
 #[derive(PartialEq, Eq, Debug, Clone, Queryable)]
 #[changeset_for(users)]
@@ -108,26 +107,41 @@ pub struct NewComment<'a>(
     pub &'a str,
 );
 
-pub fn connection() -> PgConnection {
+#[cfg(feature = "postgres")]
+pub type TestConnection = ::diesel::connection::PgConnection;
+#[cfg(feature = "sqlite")]
+pub type TestConnection = ::diesel::connection::SqliteConnection;
+
+pub fn connection() -> TestConnection {
     let result = connection_without_transaction();
     result.begin_test_transaction().unwrap();
     result
 }
 
-pub fn connection_without_transaction() -> PgConnection {
+#[cfg(feature = "postgres")]
+pub fn connection_without_transaction() -> TestConnection {
     let connection_url = dotenv!("DATABASE_URL",
         "DATABASE_URL must be set in order to run tests");
-    PgConnection::establish(&connection_url).unwrap()
+    ::diesel::connection::PgConnection::establish(&connection_url).unwrap()
 }
 
-pub fn connection_with_sean_and_tess_in_users_table() -> PgConnection {
+#[cfg(feature = "sqlite")]
+pub fn connection_without_transaction() -> TestConnection {
+    let connection = ::diesel::connection::SqliteConnection::establish(":memory:").unwrap();
+    let migrations_dir = migrations::find_migrations_directory().unwrap().join("sqlite");
+    migrations::run_pending_migrations_in_directory(&connection, &migrations_dir).unwrap();
+    connection
+}
+
+
+pub fn connection_with_sean_and_tess_in_users_table() -> TestConnection {
     let connection = connection();
     connection.execute("INSERT INTO users (id, name) VALUES (1, 'Sean'), (2, 'Tess')")
         .unwrap();
     connection
 }
 
-pub fn find_user_by_name(name: &str, connection: &PgConnection) -> User {
+pub fn find_user_by_name(name: &str, connection: &TestConnection) -> User {
     users::table.filter(users::name.eq(name))
         .first(connection)
         .unwrap()
diff --git a/diesel_tests/tests/select.rs b/diesel_tests/tests/select.rs
index 023b24fa0..633cc7fbe 100644
--- a/diesel_tests/tests/select.rs
+++ b/diesel_tests/tests/select.rs
@@ -108,6 +108,7 @@ table! {
 }
 
 #[test]
+#[cfg(feature = "postgres")] // FIXME: This test should run on everything, the only difference is create table syntax.
 fn selecting_columns_and_tables_with_reserved_names() {
     use self::select::dsl::*;
 
@@ -131,6 +132,31 @@ fn selecting_columns_and_tables_with_reserved_names() {
 }
 
 #[test]
+#[cfg(feature = "sqlite")] // FIXME: This test should run on everything, the only difference is create table syntax.
+fn selecting_columns_and_tables_with_reserved_names() {
+    use self::select::dsl::*;
+
+    let connection = connection();
+    connection.execute("CREATE TABLE \"select\" (
+        id INTEGER PRIMARY KEY AUTOINCREMENT,
+        \"join\" INTEGER NOT NULL
+    )").unwrap();
+    connection.execute("INSERT INTO \"select\" (\"join\") VALUES (1), (2), (3)")
+        .unwrap();
+
+    let expected_data = vec![(1, 1), (2, 2), (3, 3)];
+    let actual_data: Vec<(i32, i32)> = select.load(&connection)
+        .unwrap().collect();
+    assert_eq!(expected_data, actual_data);
+
+    let expected_data = vec![1, 2, 3];
+    let actual_data: Vec<i32> = select.select(join).load(&connection)
+        .unwrap().collect();
+    assert_eq!(expected_data, actual_data);
+}
+
+#[test]
+#[cfg(feature = "postgres")] // FIXME: This test should run on everything, the only difference is create table syntax.
 fn selecting_columns_with_different_definition_order() {
     let connection = connection();
     connection.execute("DROP TABLE users").unwrap();
@@ -145,6 +171,22 @@ fn selecting_columns_with_different_definition_order() {
 }
 
 #[test]
+#[cfg(feature = "sqlite")] // FIXME: This test should run on everything, the only difference is create table syntax.
+fn selecting_columns_with_different_definition_order() {
+    let connection = connection();
+    connection.execute("DROP TABLE users").unwrap();
+    connection.execute("CREATE TABLE users (id INTEGER PRIMARY KEY AUTOINCREMENT, hair_color VARCHAR, name VARCHAR NOT NULL)")
+        .unwrap();
+    let expected_user = User::with_hair_color(1, "Sean", "black");
+    insert(&NewUser::new("Sean", Some("black"))).into(users::table)
+        .execute(&connection).unwrap();
+    let user_from_select = users::table.first(&connection);
+
+    assert_eq!(Ok(&expected_user), user_from_select.as_ref());
+}
+
+#[test]
+#[cfg(feature = "postgres")] // FIXME: This test is valid for SQLite, but currently relies on `= ANY` which is PG specific
 fn selection_using_subselect() {
     use schema::posts::dsl::*;
     use diesel::expression::dsl::*;
diff --git a/diesel_tests/tests/transactions.rs b/diesel_tests/tests/transactions.rs
index 69a28ba79..8440da725 100644
--- a/diesel_tests/tests/transactions.rs
+++ b/diesel_tests/tests/transactions.rs
@@ -111,15 +111,15 @@ fn test_transaction_panics_on_error() {
     });
 }
 
-fn setup_test_table(connection: &PgConnection, table_name: &str) {
+fn setup_test_table(connection: &TestConnection, table_name: &str) {
     connection.execute(&format!("CREATE TABLE {} (id SERIAL PRIMARY KEY)", table_name)).unwrap();
 }
 
-fn drop_test_table(connection: &PgConnection, table_name: &str) {
+fn drop_test_table(connection: &TestConnection, table_name: &str) {
     connection.execute(&format!("DROP TABLE {}", table_name)).unwrap();
 }
 
-fn count_test_table(connection: &PgConnection, table_name: &str) -> i64 {
+fn count_test_table(connection: &TestConnection, table_name: &str) -> i64 {
     use diesel::expression::dsl::sql;
     select(sql::<types::BigInt>(&format!("COUNT(*) FROM {}", table_name)))
         .first(connection).unwrap()
diff --git a/diesel_tests/tests/types_roundtrip.rs b/diesel_tests/tests/types_roundtrip.rs
index 2734f930f..4780aca77 100644
--- a/diesel_tests/tests/types_roundtrip.rs
+++ b/diesel_tests/tests/types_roundtrip.rs
@@ -4,20 +4,19 @@ pub use quickcheck::quickcheck;
 use self::chrono::{Duration, NaiveDate, NaiveDateTime, NaiveTime};
 use self::chrono::naive::date;
 
-pub use schema::connection;
+pub use schema::{connection, TestConnection};
 pub use diesel::*;
 pub use diesel::result::Error;
 pub use diesel::data_types::*;
 pub use diesel::types::{HasSqlType, ToSql, Nullable, Array};
 
-use diesel::backend::Pg;
 use diesel::expression::AsExpression;
 use diesel::query_builder::QueryFragment;
 
 pub fn test_type_round_trips<ST, T>(value: T) -> bool where
-    Pg: HasSqlType<ST>,
-    T: AsExpression<ST> + Queryable<ST, Pg> + PartialEq + Clone + ::std::fmt::Debug,
-    <T as AsExpression<ST>>::Expression: SelectableExpression<()> + QueryFragment<Pg>,
+    <TestConnection as Connection>::Backend: HasSqlType<ST>,
+    T: AsExpression<ST> + Queryable<ST, <TestConnection as Connection>::Backend> + PartialEq + Clone + ::std::fmt::Debug,
+    <T as AsExpression<ST>>::Expression: SelectableExpression<()> + QueryFragment<<TestConnection as Connection>::Backend>,
 {
     let connection = connection();
     let query = select(AsExpression::<ST>::as_expression(value.clone()));
@@ -56,11 +55,17 @@ macro_rules! test_round_trip {
                 test_type_round_trips::<Nullable<types::$sql_type>, _>(val)
             }
 
+            #[cfg(feature = "postgres")]
             fn vec_round_trip(val: Vec<$tpe>) -> bool {
                 let val: Vec<_> = val.into_iter().map($map_fn).collect();
                 test_type_round_trips::<Array<types::$sql_type>, _>(val)
             }
 
+            #[cfg(not(feature = "postgres"))]
+            fn vec_round_trip(_: Vec<$tpe>) -> bool {
+                true
+            }
+
             quickcheck(round_trip as fn($tpe) -> bool);
             quickcheck(option_round_trip as fn(Option<$tpe>) -> bool);
             quickcheck(vec_round_trip as fn(Vec<$tpe>) -> bool);
@@ -68,7 +73,6 @@ macro_rules! test_round_trip {
     }
 }
 
-test_round_trip!(bool_roundtrips, Bool, bool);
 test_round_trip!(i16_roundtrips, SmallInt, i16);
 test_round_trip!(i32_roundtrips, Integer, i32);
 test_round_trip!(i64_roundtrips, BigInt, i64);
@@ -77,31 +81,37 @@ test_round_trip!(f64_roundtrips, Double, f64);
 test_round_trip!(string_roundtrips, VarChar, String);
 test_round_trip!(text_roundtrips, Text, String);
 test_round_trip!(binary_roundtrips, Binary, Vec<u8>);
-test_round_trip!(date_roundtrips, Date, PgDate);
-test_round_trip!(time_roundtrips, Time, PgTime);
-test_round_trip!(timestamp_roundtrips, Timestamp, PgTimestamp);
-test_round_trip!(interval_roundtrips, Interval, PgInterval);
-test_round_trip!(numeric_roundtrips, Numeric, PgNumeric);
-test_round_trip!(naive_datetime_roundtrips, Timestamp, (i64, u32), mk_naive_datetime);
-test_round_trip!(naive_time_roundtrips, Time, (u32, u32), mk_naive_time);
-test_round_trip!(naive_date_roundtrips, Date, u32, mk_naive_date);
-
-fn mk_naive_datetime(data: (i64, u32)) -> NaiveDateTime {
+
+#[cfg(feature = "postgres")]
+mod pg_types {
+    use super::*;
+    test_round_trip!(bool_roundtrips, Bool, bool);
+    test_round_trip!(date_roundtrips, Date, PgDate);
+    test_round_trip!(time_roundtrips, Time, PgTime);
+    test_round_trip!(timestamp_roundtrips, Timestamp, PgTimestamp);
+    test_round_trip!(interval_roundtrips, Interval, PgInterval);
+    test_round_trip!(numeric_roundtrips, Numeric, PgNumeric);
+    test_round_trip!(naive_datetime_roundtrips, Timestamp, (i64, u32), mk_naive_datetime);
+    test_round_trip!(naive_time_roundtrips, Time, (u32, u32), mk_naive_time);
+    test_round_trip!(naive_date_roundtrips, Date, u32, mk_naive_date);
+}
+
+pub fn mk_naive_datetime(data: (i64, u32)) -> NaiveDateTime {
     NaiveDateTime::from_timestamp(data.0, data.1 / 1000)
 }
 
-fn mk_naive_time(data: (u32, u32)) -> NaiveTime {
+pub fn mk_naive_time(data: (u32, u32)) -> NaiveTime {
     NaiveTime::from_num_seconds_from_midnight(data.0, data.1 / 1000)
 }
 
-fn mk_naive_date(days: u32) -> NaiveDate {
+pub fn mk_naive_date(days: u32) -> NaiveDate {
     let earliest_pg_date = NaiveDate::from_ymd(-4713, 11, 24);
     let latest_chrono_date = date::MAX;
     let num_days_representable = (latest_chrono_date - earliest_pg_date).num_days();
     earliest_pg_date + Duration::days(days as i64 % num_days_representable)
 }
 
-#[cfg(feature = "unstable")]
+#[cfg(all(feature = "unstable", feature = "postgres"))]
 mod unstable_types {
     use super::*;
     use std::time::*;
diff --git a/migrations/20151219180527_create_users_and_posts_and_comments/down.sql b/migrations/postgresql/20151219180527_create_users_and_posts_and_comments/down.sql
similarity index 100%
rename from migrations/20151219180527_create_users_and_posts_and_comments/down.sql
rename to migrations/postgresql/20151219180527_create_users_and_posts_and_comments/down.sql
diff --git a/migrations/20151219180527_create_users_and_posts_and_comments/up.sql b/migrations/postgresql/20151219180527_create_users_and_posts_and_comments/up.sql
similarity index 100%
rename from migrations/20151219180527_create_users_and_posts_and_comments/up.sql
rename to migrations/postgresql/20151219180527_create_users_and_posts_and_comments/up.sql
diff --git a/migrations/20160107090901_add_tags_to_posts/down.sql b/migrations/postgresql/20160107090901_add_tags_to_posts/down.sql
similarity index 100%
rename from migrations/20160107090901_add_tags_to_posts/down.sql
rename to migrations/postgresql/20160107090901_add_tags_to_posts/down.sql
diff --git a/migrations/20160107090901_add_tags_to_posts/up.sql b/migrations/postgresql/20160107090901_add_tags_to_posts/up.sql
similarity index 100%
rename from migrations/20160107090901_add_tags_to_posts/up.sql
rename to migrations/postgresql/20160107090901_add_tags_to_posts/up.sql
diff --git a/migrations/20160116104628_create_special_posts_and_special_comments/down.sql b/migrations/postgresql/20160116104628_create_special_posts_and_special_comments/down.sql
similarity index 100%
rename from migrations/20160116104628_create_special_posts_and_special_comments/down.sql
rename to migrations/postgresql/20160116104628_create_special_posts_and_special_comments/down.sql
diff --git a/migrations/20160116104628_create_special_posts_and_special_comments/up.sql b/migrations/postgresql/20160116104628_create_special_posts_and_special_comments/up.sql
similarity index 100%
rename from migrations/20160116104628_create_special_posts_and_special_comments/up.sql
rename to migrations/postgresql/20160116104628_create_special_posts_and_special_comments/up.sql
diff --git a/migrations/sqlite/20151219180527_create_users_and_posts_and_comments/down.sql b/migrations/sqlite/20151219180527_create_users_and_posts_and_comments/down.sql
new file mode 100644
index 000000000..55e7a63b1
--- /dev/null
+++ b/migrations/sqlite/20151219180527_create_users_and_posts_and_comments/down.sql
@@ -0,0 +1,3 @@
+DROP TABLE users;
+DROP TABLE posts;
+DROP TABLE comments;
diff --git a/migrations/sqlite/20151219180527_create_users_and_posts_and_comments/up.sql b/migrations/sqlite/20151219180527_create_users_and_posts_and_comments/up.sql
new file mode 100644
index 000000000..ab300f74b
--- /dev/null
+++ b/migrations/sqlite/20151219180527_create_users_and_posts_and_comments/up.sql
@@ -0,0 +1,18 @@
+CREATE TABLE users (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  name VARCHAR NOT NULL,
+  hair_color VARCHAR
+);
+
+CREATE TABLE posts (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  user_id INTEGER NOT NULL,
+  title VARCHAR NOT NULL,
+  body TEXT
+);
+
+CREATE TABLE comments (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  post_id INTEGER NOT NULL,
+  text TEXT NOT NULL
+);
diff --git a/migrations/sqlite/20160116104628_create_special_posts_and_special_comments/down.sql b/migrations/sqlite/20160116104628_create_special_posts_and_special_comments/down.sql
new file mode 100644
index 000000000..6759f841c
--- /dev/null
+++ b/migrations/sqlite/20160116104628_create_special_posts_and_special_comments/down.sql
@@ -0,0 +1,2 @@
+DROP TABLE special_posts;
+DROP TABLE special_comments;
diff --git a/migrations/sqlite/20160116104628_create_special_posts_and_special_comments/up.sql b/migrations/sqlite/20160116104628_create_special_posts_and_special_comments/up.sql
new file mode 100644
index 000000000..9b860a13f
--- /dev/null
+++ b/migrations/sqlite/20160116104628_create_special_posts_and_special_comments/up.sql
@@ -0,0 +1,10 @@
+CREATE TABLE special_posts (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  user_id INTEGER NOT NULL,
+  title VARCHAR NOT NULL
+);
+
+CREATE TABLE special_comments (
+  id INTEGER PRIMARY KEY AUTOINCREMENT,
+  special_post_id INTEGER NOT NULL
+);
