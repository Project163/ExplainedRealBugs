diff --git a/docs/sql-migration-guide.md b/docs/sql-migration-guide.md
index 019728a45f4..c7bd0b55840 100644
--- a/docs/sql-migration-guide.md
+++ b/docs/sql-migration-guide.md
@@ -38,7 +38,6 @@ license: |
   - `spark.sql.avro.datetimeRebaseModeInWrite` instead of `spark.sql.legacy.avro.datetimeRebaseModeInWrite`
   - `spark.sql.avro.datetimeRebaseModeInRead` instead of `spark.sql.legacy.avro.datetimeRebaseModeInRead`
 - Since Spark 4.0, the default value of `spark.sql.orc.compression.codec` is changed from `snappy` to `zstd`. To restore the previous behavior, set `spark.sql.orc.compression.codec` to `snappy`.
-- Since Spark 4.0, `SELECT (*)` is equivalent to `SELECT struct(*)` instead of `SELECT *`. To restore the previous behavior, set `spark.sql.legacy.ignoreParenthesesAroundStar` to `true`.
 - Since Spark 4.0, the SQL config `spark.sql.legacy.allowZeroIndexInFormatString` is deprecated. Consider to change `strfmt` of the `format_string` function to use 1-based indexes. The first argument must be referenced by "1$", the second by "2$", etc.
 - Since Spark 4.0, JDBC read option `preferTimestampNTZ=true` will not convert Postgres TIMESTAMP WITH TIME ZONE and TIME WITH TIME ZONE data types to TimestampNTZType, which is available in Spark 3.5. 
 - Since Spark 4.0, JDBC read option `preferTimestampNTZ=true` will not convert MySQL TIMESTAMP to TimestampNTZType, which is available in Spark 3.5. MySQL DATETIME is not affected.
diff --git a/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4 b/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4
index 8ff1d3f9530..6e79d4af2f5 100644
--- a/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4
+++ b/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4
@@ -575,13 +575,8 @@ transformClause
       (RECORDREADER recordReader=stringLit)?
     ;
 
-parenthesizedStar
-    : LEFT_PAREN ASTERISK RIGHT_PAREN
-    ;
-
 selectClause
-    : SELECT (hints+=hint)* setQuantifier parenthesizedStar
-    | SELECT (hints+=hint)* setQuantifier? namedExpressionSeq
+    : SELECT (hints+=hint)* setQuantifier? namedExpressionSeq
     ;
 
 setClause
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
index 4ffff6bf765..34672485ddc 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
@@ -2595,27 +2595,13 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
     UnresolvedExtractValue(expression(ctx.value), expression(ctx.index))
   }
 
-  /**
-   * Create an expression for an expression between parentheses. This is need because the ANTLR
-   * visitor cannot automatically convert the nested context into an expression.
-   */
-  override def visitParenthesizedStar(
-     ctx: ParenthesizedStarContext): Seq[Expression] = withOrigin(ctx) {
-    Seq(UnresolvedStar(None))
- }
-
   /**
    * Create an expression for an expression between parentheses. This is need because the ANTLR
    * visitor cannot automatically convert the nested context into an expression.
    */
   override def visitParenthesizedExpression(
      ctx: ParenthesizedExpressionContext): Expression = withOrigin(ctx) {
-    val res = expression(ctx.expression())
-    res match {
-      case s: UnresolvedStar if (!conf.getConf(SQLConf.LEGACY_IGNORE_PARENTHESES_AROUND_STAR)) =>
-        CreateStruct(Seq(s))
-      case o => o
-    }
+    expression(ctx.expression)
   }
 
   /**
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
index 73cb4fba863..27fba0b19f4 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
@@ -4779,16 +4779,6 @@ object SQLConf {
     .booleanConf
     .createWithDefault(false)
 
-  val LEGACY_IGNORE_PARENTHESES_AROUND_STAR =
-    buildConf("spark.sql.legacy.ignoreParenthesesAroundStar")
-    .internal()
-    .doc("When set to true, SELECT (*) equals SELECT * FROM T instead of SELECT struct(*)." +
-      "SELECT (*) was never documented as defined behavior."
-    )
-    .version("4.0.0")
-    .booleanConf
-    .createWithDefault(false)
-
   /**
    * Holds information about keys that have been deprecated.
    *
@@ -5714,9 +5704,6 @@ class SQLConf extends Serializable with Logging with SqlApiConf {
 
   def legacyEvalCurrentTime: Boolean = getConf(SQLConf.LEGACY_EVAL_CURRENT_TIME)
 
-  def legacyIgnoreParenthesesAroundStar: Boolean =
-    getConf(SQLConf.LEGACY_IGNORE_PARENTHESES_AROUND_STAR)
-
   /** ********************** SQLConf functionality methods ************ */
 
   /** Set Spark SQL configuration properties. */
diff --git a/sql/core/src/test/resources/sql-tests/analyzer-results/selectExcept.sql.out b/sql/core/src/test/resources/sql-tests/analyzer-results/selectExcept.sql.out
index 340712399d4..24119599c53 100644
--- a/sql/core/src/test/resources/sql-tests/analyzer-results/selectExcept.sql.out
+++ b/sql/core/src/test/resources/sql-tests/analyzer-results/selectExcept.sql.out
@@ -414,7 +414,7 @@ Project [concat_ws(,, cast(c1#x as string), cast(c2#x as string), cast(c3#x as a
 -- !query
 SELECT (*) FROM v1
 -- !query analysis
-Project [named_struct(c1, c1#x, c2, c2#x, c3, c3#x, c4, c4#x, c5, c5#x) AS named_struct(c1, c1, c2, c2, c3, c3, c4, c4, c5, c5)#x]
+Project [c1#x, c2#x, c3#x, c4#x, c5#x]
 +- SubqueryAlias v1
    +- View (`v1`, [c1#x, c2#x, c3#x, c4#x, c5#x])
       +- Project [cast(c1#x as int) AS c1#x, cast(c2#x as int) AS c2#x, cast(c3#x as void) AS c3#x, cast(c4#x as int) AS c4#x, cast(c5#x as int) AS c5#x]
@@ -529,73 +529,3 @@ Project [x#x]
          +- Project [cast(c1#x as int) AS c1#x, cast(c2#x as int) AS c2#x, cast(c3#x as void) AS c3#x, cast(c4#x as int) AS c4#x, cast(c5#x as int) AS c5#x]
             +- SubqueryAlias T
                +- LocalRelation [c1#x, c2#x, c3#x, c4#x, c5#x]
-
-
--- !query
-SET spark.sql.legacy.ignoreParenthesesAroundStar = true
--- !query analysis
-SetCommand (spark.sql.legacy.ignoreParenthesesAroundStar,Some(true))
-
-
--- !query
-SELECT (*) FROM v1
--- !query analysis
-Project [c1#x, c2#x, c3#x, c4#x, c5#x]
-+- SubqueryAlias v1
-   +- View (`v1`, [c1#x, c2#x, c3#x, c4#x, c5#x])
-      +- Project [cast(c1#x as int) AS c1#x, cast(c2#x as int) AS c2#x, cast(c3#x as void) AS c3#x, cast(c4#x as int) AS c4#x, cast(c5#x as int) AS c5#x]
-         +- SubqueryAlias T
-            +- LocalRelation [c1#x, c2#x, c3#x, c4#x, c5#x]
-
-
--- !query
-SELECT DISTINCT * FROM v1
--- !query analysis
-Distinct
-+- Project [c1#x, c2#x, c3#x, c4#x, c5#x]
-   +- SubqueryAlias v1
-      +- View (`v1`, [c1#x, c2#x, c3#x, c4#x, c5#x])
-         +- Project [cast(c1#x as int) AS c1#x, cast(c2#x as int) AS c2#x, cast(c3#x as void) AS c3#x, cast(c4#x as int) AS c4#x, cast(c5#x as int) AS c5#x]
-            +- SubqueryAlias T
-               +- LocalRelation [c1#x, c2#x, c3#x, c4#x, c5#x]
-
-
--- !query
-SELECT DISTINCT(*) FROM v1
--- !query analysis
-Distinct
-+- SubqueryAlias v1
-   +- View (`v1`, [c1#x, c2#x, c3#x, c4#x, c5#x])
-      +- Project [cast(c1#x as int) AS c1#x, cast(c2#x as int) AS c2#x, cast(c3#x as void) AS c3#x, cast(c4#x as int) AS c4#x, cast(c5#x as int) AS c5#x]
-         +- SubqueryAlias T
-            +- LocalRelation [c1#x, c2#x, c3#x, c4#x, c5#x]
-
-
--- !query
-SET spark.sql.legacy.ignoreParenthesesAroundStar = false
--- !query analysis
-SetCommand (spark.sql.legacy.ignoreParenthesesAroundStar,Some(false))
-
-
--- !query
-SELECT DISTINCT(*) FROM v1
--- !query analysis
-Distinct
-+- SubqueryAlias v1
-   +- View (`v1`, [c1#x, c2#x, c3#x, c4#x, c5#x])
-      +- Project [cast(c1#x as int) AS c1#x, cast(c2#x as int) AS c2#x, cast(c3#x as void) AS c3#x, cast(c4#x as int) AS c4#x, cast(c5#x as int) AS c5#x]
-         +- SubqueryAlias T
-            +- LocalRelation [c1#x, c2#x, c3#x, c4#x, c5#x]
-
-
--- !query
-DROP VIEW v1
--- !query analysis
-DropTempViewCommand v1
-
-
--- !query
-SELECT DISTINCT(*)
--- !query analysis
-Distinct
-+- OneRowRelation
diff --git a/sql/core/src/test/resources/sql-tests/inputs/selectExcept.sql b/sql/core/src/test/resources/sql-tests/inputs/selectExcept.sql
index 96b0fcc1e6a..dcac80d5faa 100644
--- a/sql/core/src/test/resources/sql-tests/inputs/selectExcept.sql
+++ b/sql/core/src/test/resources/sql-tests/inputs/selectExcept.sql
@@ -60,7 +60,10 @@ SELECT coalesce(* EXCEPT(c1, c2)) FROM v1;
 SELECT array(*) FROM v1;
 SELECT array(v1.*) FROM v1;
 SELECT concat_ws(',', *) FROM v1;
+
+-- This is just SELECT *
 SELECT (*) FROM v1;
+
 SELECT struct(*) FROM v1;
 SELECT greatest(*) FROM v1;
 SELECT 5 IN (*) FROM v1;
@@ -73,21 +76,3 @@ SELECT 1 FROM v1 WHERE 4 IN (*);
 SELECT T.* FROM v1, LATERAL (SELECT  v1.*) AS T(c1, c2, c3, c4, c5);
 SELECT T.* FROM v1, LATERAL (SELECT  COALESCE(v1.*)) AS T(x);
 
-
--- We used to ignore () around * in the past, but now we don't
-SET spark.sql.legacy.ignoreParenthesesAroundStar = true;
-SELECT (*) FROM v1;
-
-SELECT DISTINCT * FROM v1;
-
-SELECT DISTINCT(*) FROM v1;
-
-SET spark.sql.legacy.ignoreParenthesesAroundStar = false;
-
-SELECT DISTINCT(*) FROM v1;
-
-DROP VIEW v1;
-
--- Except for DISTINCT, where we still ignore ()
-SELECT DISTINCT(*)
-
diff --git a/sql/core/src/test/resources/sql-tests/results/selectExcept.sql.out b/sql/core/src/test/resources/sql-tests/results/selectExcept.sql.out
index ecf47fdb7a2..b01d1a04e59 100644
--- a/sql/core/src/test/resources/sql-tests/results/selectExcept.sql.out
+++ b/sql/core/src/test/resources/sql-tests/results/selectExcept.sql.out
@@ -419,9 +419,9 @@ struct<concat_ws(,, c1, c2, c3, c4, c5):string>
 -- !query
 SELECT (*) FROM v1
 -- !query schema
-struct<named_struct(c1, c1, c2, c2, c3, c3, c4, c4, c5, c5):struct<c1:int,c2:int,c3:void,c4:int,c5:int>>
+struct<c1:int,c2:int,c3:void,c4:int,c5:int>
 -- !query output
-{"c1":1,"c2":2,"c3":null,"c4":4,"c5":5}
+1	2	NULL	4	5
 
 
 -- !query
@@ -494,67 +494,3 @@ SELECT T.* FROM v1, LATERAL (SELECT  COALESCE(v1.*)) AS T(x)
 struct<x:int>
 -- !query output
 1
-
-
--- !query
-SET spark.sql.legacy.ignoreParenthesesAroundStar = true
--- !query schema
-struct<key:string,value:string>
--- !query output
-spark.sql.legacy.ignoreParenthesesAroundStar	true
-
-
--- !query
-SELECT (*) FROM v1
--- !query schema
-struct<c1:int,c2:int,c3:void,c4:int,c5:int>
--- !query output
-1	2	NULL	4	5
-
-
--- !query
-SELECT DISTINCT * FROM v1
--- !query schema
-struct<c1:int,c2:int,c3:void,c4:int,c5:int>
--- !query output
-1	2	NULL	4	5
-
-
--- !query
-SELECT DISTINCT(*) FROM v1
--- !query schema
-struct<c1:int,c2:int,c3:void,c4:int,c5:int>
--- !query output
-1	2	NULL	4	5
-
-
--- !query
-SET spark.sql.legacy.ignoreParenthesesAroundStar = false
--- !query schema
-struct<key:string,value:string>
--- !query output
-spark.sql.legacy.ignoreParenthesesAroundStar	false
-
-
--- !query
-SELECT DISTINCT(*) FROM v1
--- !query schema
-struct<c1:int,c2:int,c3:void,c4:int,c5:int>
--- !query output
-1	2	NULL	4	5
-
-
--- !query
-DROP VIEW v1
--- !query schema
-struct<>
--- !query output
-
-
-
--- !query
-SELECT DISTINCT(*)
--- !query schema
-struct<>
--- !query output
-
