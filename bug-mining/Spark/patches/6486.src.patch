diff --git a/sql/core/src/main/scala/org/apache/spark/sql/execution/subquery.scala b/sql/core/src/main/scala/org/apache/spark/sql/execution/subquery.scala
index c70f17fa49b..960d47b3ac8 100644
--- a/sql/core/src/main/scala/org/apache/spark/sql/execution/subquery.scala
+++ b/sql/core/src/main/scala/org/apache/spark/sql/execution/subquery.scala
@@ -116,7 +116,7 @@ case class PlanSubqueries(sparkSession: SparkSession) extends Rule[SparkPlan] {
       case subquery: expressions.ScalarSubquery =>
         val executedPlan = new QueryExecution(sparkSession, subquery.plan).executedPlan
         ScalarSubquery(
-          SubqueryExec(s"subquery${subquery.exprId.id}", executedPlan),
+          SubqueryExec(s"scalar-subquery#${subquery.exprId.id}", executedPlan),
           subquery.exprId)
     }
   }
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/SubquerySuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/SubquerySuite.scala
index 28a99054596..fddc4f6bb35 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/SubquerySuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/SubquerySuite.scala
@@ -1371,4 +1371,16 @@ class SubquerySuite extends QueryTest with SharedSQLContext {
       }
     }
   }
+
+  test("Scalar subquery name should start with scalar-subquery#") {
+    val df = sql("SELECT a FROM l WHERE a = (SELECT max(c) FROM r WHERE c = 1)".stripMargin)
+    var subqueryExecs: ArrayBuffer[SubqueryExec] = ArrayBuffer.empty
+    df.queryExecution.executedPlan.transformAllExpressions {
+      case s @ ScalarSubquery(p: SubqueryExec, _) =>
+        subqueryExecs += p
+        s
+    }
+    assert(subqueryExecs.forall(_.name.startsWith("scalar-subquery#")),
+          "SubqueryExec name should start with scalar-subquery#")
+  }
 }
