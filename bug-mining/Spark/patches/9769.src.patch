diff --git a/connector/docker-integration-tests/src/test/scala/org/apache/spark/sql/jdbc/querytest/GeneratedSubquerySuite.scala b/connector/docker-integration-tests/src/test/scala/org/apache/spark/sql/jdbc/querytest/GeneratedSubquerySuite.scala
index 8b27e9cb0e0..015898b70b7 100644
--- a/connector/docker-integration-tests/src/test/scala/org/apache/spark/sql/jdbc/querytest/GeneratedSubquerySuite.scala
+++ b/connector/docker-integration-tests/src/test/scala/org/apache/spark/sql/jdbc/querytest/GeneratedSubquerySuite.scala
@@ -445,20 +445,5 @@ object GeneratedSubquerySuite {
   // Limit number of generated queries per test so that tests will not take too long.
   private val NUM_QUERIES_PER_TEST = 1000
 
-  // scalastyle:off line.size.limit
-  private val KNOWN_QUERIES_WITH_DIFFERENT_RESULTS = Seq(
-    // SPARK-46743
-    "SELECT outer_table.a, outer_table.b, (SELECT COUNT(null_table.a) AS aggFunctionAlias FROM null_table WHERE null_table.a = outer_table.a) AS subqueryAlias FROM outer_table ORDER BY a DESC NULLS FIRST, b DESC NULLS FIRST, subqueryAlias DESC NULLS FIRST;",
-    // SPARK-46743
-    "SELECT outer_table.a, outer_table.b, (SELECT COUNT(null_table.a) AS aggFunctionAlias FROM null_table INNER JOIN join_table ON null_table.a = join_table.a WHERE null_table.a = outer_table.a) AS subqueryAlias FROM outer_table ORDER BY a DESC NULLS FIRST, b DESC NULLS FIRST, subqueryAlias DESC NULLS FIRST;",
-    // SPARK-46743
-    "SELECT outer_table.a, outer_table.b, (SELECT COUNT(null_table.a) AS aggFunctionAlias FROM null_table LEFT OUTER JOIN join_table ON null_table.a = join_table.a WHERE null_table.a = outer_table.a) AS subqueryAlias FROM outer_table ORDER BY a DESC NULLS FIRST, b DESC NULLS FIRST, subqueryAlias DESC NULLS FIRST;",
-    // SPARK-46743
-    "SELECT outer_table.a, outer_table.b, (SELECT COUNT(null_table.a) AS aggFunctionAlias FROM null_table RIGHT OUTER JOIN join_table ON null_table.a = join_table.a WHERE null_table.a = outer_table.a) AS subqueryAlias FROM outer_table ORDER BY a DESC NULLS FIRST, b DESC NULLS FIRST, subqueryAlias DESC NULLS FIRST;",
-    // SPARK-46743
-    "SELECT outer_table.a, outer_table.b, (SELECT COUNT(innerSubqueryAlias.a) AS aggFunctionAlias FROM (SELECT null_table.a, null_table.b FROM null_table INTERSECT SELECT join_table.a, join_table.b FROM join_table) AS innerSubqueryAlias WHERE innerSubqueryAlias.a = outer_table.a) AS subqueryAlias FROM outer_table ORDER BY a DESC NULLS FIRST, b DESC NULLS FIRST, subqueryAlias DESC NULLS FIRST;",
-    // SPARK-46743
-    "SELECT outer_table.a, outer_table.b, (SELECT COUNT(innerSubqueryAlias.a) AS aggFunctionAlias FROM (SELECT null_table.a, null_table.b FROM null_table EXCEPT SELECT join_table.a, join_table.b FROM join_table) AS innerSubqueryAlias WHERE innerSubqueryAlias.a = outer_table.a) AS subqueryAlias FROM outer_table ORDER BY a DESC NULLS FIRST, b DESC NULLS FIRST, subqueryAlias DESC NULLS FIRST;"
-  )
-  // scalastyle:on line.size.limit
+  private val KNOWN_QUERIES_WITH_DIFFERENT_RESULTS = Seq()
 }
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/Optimizer.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/Optimizer.scala
index 95923a14195..647812ff80e 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/Optimizer.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/Optimizer.scala
@@ -26,6 +26,7 @@ import org.apache.spark.sql.catalyst.analysis._
 import org.apache.spark.sql.catalyst.catalog.{InMemoryCatalog, SessionCatalog}
 import org.apache.spark.sql.catalyst.expressions._
 import org.apache.spark.sql.catalyst.expressions.aggregate._
+import org.apache.spark.sql.catalyst.planning.PhysicalOperation
 import org.apache.spark.sql.catalyst.plans._
 import org.apache.spark.sql.catalyst.plans.logical._
 import org.apache.spark.sql.catalyst.rules._
@@ -332,7 +333,9 @@ abstract class Optimizer(catalogManager: CatalogManager)
       // Do not optimize DPP subquery, as it was created from optimized plan and we should not
       // optimize it again, to save optimization time and avoid breaking broadcast/subquery reuse.
       case d: DynamicPruningSubquery => d
-      case s @ ScalarSubquery(a @ Aggregate(group, _, child), _, _, _, _, mayHaveCountBug)
+      case s @ ScalarSubquery(
+        PhysicalOperation(projections, predicates, a @ Aggregate(group, _, child)),
+        _, _, _, _, mayHaveCountBug)
         if conf.getConf(SQLConf.DECORRELATE_SUBQUERY_PREVENT_CONSTANT_FOLDING_FOR_COUNT_BUG) &&
           mayHaveCountBug.nonEmpty && mayHaveCountBug.get =>
         // This is a subquery with an aggregate that may suffer from a COUNT bug.
@@ -357,19 +360,28 @@ abstract class Optimizer(catalogManager: CatalogManager)
         val needProject = projectOverAggregateChild.output.zip(optimizedInput.output).exists {
           case (oldAttr, newAttr) => oldAttr.exprId != newAttr.exprId
         }
-        if (needProject) {
+        val optimizedAgg = if (needProject) {
           val updatedProjectList = projectOverAggregateChild.output.zip(optimizedInput.output).map {
             case (oldAttr, newAttr) => Alias(newAttr, newAttr.name)(exprId = oldAttr.exprId)
           }
-          s.withNewPlan(a.withNewChildren(Seq(Project(updatedProjectList, optimizedInput))))
+          a.withNewChildren(Seq(Project(updatedProjectList, optimizedInput)))
         } else {
           // Remove the top-level project if it is trivial. We do it to minimize plan changes.
           optimizedInput match {
             case Project(projectList, input) if projectList.forall(_.isInstanceOf[Attribute]) =>
-              s.withNewPlan(a.withNewChildren(Seq(input)))
-            case _ => s.withNewPlan(a.withNewChildren(Seq(optimizedInput)))
+              a.withNewChildren(Seq(input))
+            case _ => a.withNewChildren(Seq(optimizedInput))
           }
         }
+        val newPlan = Project(projections,
+          if (predicates.nonEmpty) Filter(predicates.reduce(And), optimizedAgg) else optimizedAgg
+        )
+        val needTopLevelProject = newPlan.output.zip(optimizedAgg.output).exists {
+          case (oldAttr, newAttr) => oldAttr.exprId != newAttr.exprId
+        }
+        s.withNewPlan(
+          if (needTopLevelProject) newPlan else newPlan.child
+        )
       case s: SubqueryExpression =>
         val Subquery(newPlan, _) = Optimizer.this.execute(Subquery.fromExpression(s))
         // At this point we have an optimized subquery plan that we are going to attach
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/expressions.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/expressions.scala
index 1750a0e2757..d0ee9f2d110 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/expressions.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/expressions.scala
@@ -89,6 +89,12 @@ object ConstantFolding extends Rule[LogicalPlan] {
           e
       }
 
+    // Don't replace ScalarSubquery if its plan is an aggregate that may suffer from a COUNT bug.
+    case s @ ScalarSubquery(_, _, _, _, _, mayHaveCountBug)
+      if conf.getConf(SQLConf.DECORRELATE_SUBQUERY_PREVENT_CONSTANT_FOLDING_FOR_COUNT_BUG) &&
+        mayHaveCountBug.nonEmpty && mayHaveCountBug.get =>
+      s
+
     // Replace ScalarSubquery with null if its maxRows is 0
     case s: ScalarSubquery if s.plan.maxRows.contains(0) =>
       Literal(null, s.dataType)
diff --git a/sql/core/src/test/resources/sql-tests/analyzer-results/subquery/scalar-subquery/scalar-subquery-count-bug.sql.out b/sql/core/src/test/resources/sql-tests/analyzer-results/subquery/scalar-subquery/scalar-subquery-count-bug.sql.out
index ebe071c5261..a668e96e762 100644
--- a/sql/core/src/test/resources/sql-tests/analyzer-results/subquery/scalar-subquery/scalar-subquery-count-bug.sql.out
+++ b/sql/core/src/test/resources/sql-tests/analyzer-results/subquery/scalar-subquery/scalar-subquery-count-bug.sql.out
@@ -233,6 +233,166 @@ Project [scalar-subquery#x [a#x] AS scalarsubquery(a)#xL]
          +- LocalRelation [col1#x, col2#x]
 
 
+-- !query
+SELECT
+  (
+    SELECT
+      COUNT(null_view.a) AS result
+    FROM
+      null_view
+    INNER JOIN r
+      ON r.c = null_view.a
+      AND r.c IS NOT NULL
+    WHERE
+      null_view.a = l.a
+  )
+FROM
+  l
+-- !query analysis
+Project [scalar-subquery#x [a#x] AS scalarsubquery(a)#xL]
+:  +- Aggregate [count(a#x) AS result#xL]
+:     +- Filter (a#x = outer(a#x))
+:        +- Join Inner, ((c#x = a#x) AND isnotnull(c#x))
+:           :- SubqueryAlias null_view
+:           :  +- View (`null_view`, [a#x, b#x])
+:           :     +- Project [cast(CAST(NULL AS INT)#x as int) AS a#x, cast(CAST(NULL AS INT)#x as int) AS b#x]
+:           :        +- Project [cast(null as int) AS CAST(NULL AS INT)#x, cast(null as int) AS CAST(NULL AS INT)#x]
+:           :           +- OneRowRelation
+:           +- SubqueryAlias r
+:              +- View (`r`, [c#x, d#x])
+:                 +- Project [cast(col1#x as int) AS c#x, cast(col2#x as decimal(2,1)) AS d#x]
+:                    +- LocalRelation [col1#x, col2#x]
++- SubqueryAlias l
+   +- View (`l`, [a#x, b#x])
+      +- Project [cast(col1#x as int) AS a#x, cast(col2#x as decimal(2,1)) AS b#x]
+         +- LocalRelation [col1#x, col2#x]
+
+
+-- !query
+SELECT
+(
+  SELECT
+    COUNT(null_view.a) AS result
+  FROM
+    null_view
+  INNER JOIN r
+    ON r.c = null_view.a
+    AND r.c IS NOT NULL
+  WHERE
+    null_view.a = l.a
+  HAVING COUNT(*) > -1
+)
+FROM
+  l
+-- !query analysis
+Project [scalar-subquery#x [a#x] AS scalarsubquery(a)#xL]
+:  +- Project [result#xL]
+:     +- Filter (count(1)#xL > cast(-1 as bigint))
+:        +- Aggregate [count(a#x) AS result#xL, count(1) AS count(1)#xL]
+:           +- Filter (a#x = outer(a#x))
+:              +- Join Inner, ((c#x = a#x) AND isnotnull(c#x))
+:                 :- SubqueryAlias null_view
+:                 :  +- View (`null_view`, [a#x, b#x])
+:                 :     +- Project [cast(CAST(NULL AS INT)#x as int) AS a#x, cast(CAST(NULL AS INT)#x as int) AS b#x]
+:                 :        +- Project [cast(null as int) AS CAST(NULL AS INT)#x, cast(null as int) AS CAST(NULL AS INT)#x]
+:                 :           +- OneRowRelation
+:                 +- SubqueryAlias r
+:                    +- View (`r`, [c#x, d#x])
+:                       +- Project [cast(col1#x as int) AS c#x, cast(col2#x as decimal(2,1)) AS d#x]
+:                          +- LocalRelation [col1#x, col2#x]
++- SubqueryAlias l
+   +- View (`l`, [a#x, b#x])
+      +- Project [cast(col1#x as int) AS a#x, cast(col2#x as decimal(2,1)) AS b#x]
+         +- LocalRelation [col1#x, col2#x]
+
+
+-- !query
+SELECT
+  (
+    SELECT
+      COUNT(f.a) AS result
+    FROM
+    (
+        SELECT a, b FROM null_view
+        INTERSECT
+        SELECT c, d FROM r WHERE c IS NOT NULL
+    ) AS f
+    WHERE
+      f.a = l.a
+  )
+FROM
+  l
+-- !query analysis
+Project [scalar-subquery#x [a#x] AS scalarsubquery(a)#xL]
+:  +- Aggregate [count(a#x) AS result#xL]
+:     +- Filter (a#x = outer(a#x))
+:        +- SubqueryAlias f
+:           +- Intersect false
+:              :- Project [a#x, cast(b#x as decimal(11,1)) AS b#x]
+:              :  +- Project [a#x, b#x]
+:              :     +- SubqueryAlias null_view
+:              :        +- View (`null_view`, [a#x, b#x])
+:              :           +- Project [cast(CAST(NULL AS INT)#x as int) AS a#x, cast(CAST(NULL AS INT)#x as int) AS b#x]
+:              :              +- Project [cast(null as int) AS CAST(NULL AS INT)#x, cast(null as int) AS CAST(NULL AS INT)#x]
+:              :                 +- OneRowRelation
+:              +- Project [c#x, cast(d#x as decimal(11,1)) AS d#x]
+:                 +- Project [c#x, d#x]
+:                    +- Filter isnotnull(c#x)
+:                       +- SubqueryAlias r
+:                          +- View (`r`, [c#x, d#x])
+:                             +- Project [cast(col1#x as int) AS c#x, cast(col2#x as decimal(2,1)) AS d#x]
+:                                +- LocalRelation [col1#x, col2#x]
++- SubqueryAlias l
+   +- View (`l`, [a#x, b#x])
+      +- Project [cast(col1#x as int) AS a#x, cast(col2#x as decimal(2,1)) AS b#x]
+         +- LocalRelation [col1#x, col2#x]
+
+
+-- !query
+SELECT
+(
+  SELECT
+    COUNT(f.a) AS result
+  FROM
+  (
+      SELECT a, b FROM null_view
+      INTERSECT
+      SELECT c, d FROM r WHERE c IS NOT NULL
+  ) AS f
+  WHERE
+    f.a = l.a
+  HAVING COUNT(*) > -1
+)
+FROM
+  l
+-- !query analysis
+Project [scalar-subquery#x [a#x] AS scalarsubquery(a)#xL]
+:  +- Project [result#xL]
+:     +- Filter (count(1)#xL > cast(-1 as bigint))
+:        +- Aggregate [count(a#x) AS result#xL, count(1) AS count(1)#xL]
+:           +- Filter (a#x = outer(a#x))
+:              +- SubqueryAlias f
+:                 +- Intersect false
+:                    :- Project [a#x, cast(b#x as decimal(11,1)) AS b#x]
+:                    :  +- Project [a#x, b#x]
+:                    :     +- SubqueryAlias null_view
+:                    :        +- View (`null_view`, [a#x, b#x])
+:                    :           +- Project [cast(CAST(NULL AS INT)#x as int) AS a#x, cast(CAST(NULL AS INT)#x as int) AS b#x]
+:                    :              +- Project [cast(null as int) AS CAST(NULL AS INT)#x, cast(null as int) AS CAST(NULL AS INT)#x]
+:                    :                 +- OneRowRelation
+:                    +- Project [c#x, cast(d#x as decimal(11,1)) AS d#x]
+:                       +- Project [c#x, d#x]
+:                          +- Filter isnotnull(c#x)
+:                             +- SubqueryAlias r
+:                                +- View (`r`, [c#x, d#x])
+:                                   +- Project [cast(col1#x as int) AS c#x, cast(col2#x as decimal(2,1)) AS d#x]
+:                                      +- LocalRelation [col1#x, col2#x]
++- SubqueryAlias l
+   +- View (`l`, [a#x, b#x])
+      +- Project [cast(col1#x as int) AS a#x, cast(col2#x as decimal(2,1)) AS b#x]
+         +- LocalRelation [col1#x, col2#x]
+
+
 -- !query
 set spark.sql.optimizer.decorrelateSubqueryLegacyIncorrectCountHandling.enabled = true
 -- !query analysis
diff --git a/sql/core/src/test/resources/sql-tests/inputs/subquery/scalar-subquery/scalar-subquery-count-bug.sql b/sql/core/src/test/resources/sql-tests/inputs/subquery/scalar-subquery/scalar-subquery-count-bug.sql
index 8b37256a37a..b2e4bea480d 100644
--- a/sql/core/src/test/resources/sql-tests/inputs/subquery/scalar-subquery/scalar-subquery-count-bug.sql
+++ b/sql/core/src/test/resources/sql-tests/inputs/subquery/scalar-subquery/scalar-subquery-count-bug.sql
@@ -82,6 +82,73 @@ SELECT
 FROM
   l;
 
+-- Count bug over a subquery with an empty relation after optimization.
+SELECT
+  (
+    SELECT
+      COUNT(null_view.a) AS result
+    FROM
+      null_view
+    INNER JOIN r
+      ON r.c = null_view.a
+      AND r.c IS NOT NULL
+    WHERE
+      null_view.a = l.a
+  )
+FROM
+  l;
+
+-- Same as above but with a filter (HAVING) above the aggregate
+SELECT
+(
+  SELECT
+    COUNT(null_view.a) AS result
+  FROM
+    null_view
+  INNER JOIN r
+    ON r.c = null_view.a
+    AND r.c IS NOT NULL
+  WHERE
+    null_view.a = l.a
+  HAVING COUNT(*) > -1
+)
+FROM
+  l;
+
+-- Same as above but with intersect
+SELECT
+  (
+    SELECT
+      COUNT(f.a) AS result
+    FROM
+    (
+        SELECT a, b FROM null_view
+        INTERSECT
+        SELECT c, d FROM r WHERE c IS NOT NULL
+    ) AS f
+    WHERE
+      f.a = l.a
+  )
+FROM
+  l;
+
+SELECT
+(
+  SELECT
+    COUNT(f.a) AS result
+  FROM
+  (
+      SELECT a, b FROM null_view
+      INTERSECT
+      SELECT c, d FROM r WHERE c IS NOT NULL
+  ) AS f
+  WHERE
+    f.a = l.a
+  HAVING COUNT(*) > -1
+)
+FROM
+  l;
+
 
 set spark.sql.optimizer.decorrelateSubqueryLegacyIncorrectCountHandling.enabled = true;
 
diff --git a/sql/core/src/test/resources/sql-tests/results/subquery/scalar-subquery/scalar-subquery-count-bug.sql.out b/sql/core/src/test/resources/sql-tests/results/subquery/scalar-subquery/scalar-subquery-count-bug.sql.out
index 1f65fa84031..aa295dfaca2 100644
--- a/sql/core/src/test/resources/sql-tests/results/subquery/scalar-subquery/scalar-subquery-count-bug.sql.out
+++ b/sql/core/src/test/resources/sql-tests/results/subquery/scalar-subquery/scalar-subquery-count-bug.sql.out
@@ -205,6 +205,122 @@ struct<scalarsubquery(a):bigint>
 0
 
 
+-- !query
+SELECT
+  (
+    SELECT
+      COUNT(null_view.a) AS result
+    FROM
+      null_view
+    INNER JOIN r
+      ON r.c = null_view.a
+      AND r.c IS NOT NULL
+    WHERE
+      null_view.a = l.a
+  )
+FROM
+  l
+-- !query schema
+struct<scalarsubquery(a):bigint>
+-- !query output
+0
+0
+0
+0
+0
+0
+0
+0
+
+
+-- !query
+SELECT
+(
+  SELECT
+    COUNT(null_view.a) AS result
+  FROM
+    null_view
+  INNER JOIN r
+    ON r.c = null_view.a
+    AND r.c IS NOT NULL
+  WHERE
+    null_view.a = l.a
+  HAVING COUNT(*) > -1
+)
+FROM
+  l
+-- !query schema
+struct<scalarsubquery(a):bigint>
+-- !query output
+0
+0
+0
+0
+0
+0
+0
+0
+
+
+-- !query
+SELECT
+  (
+    SELECT
+      COUNT(f.a) AS result
+    FROM
+    (
+        SELECT a, b FROM null_view
+        INTERSECT
+        SELECT c, d FROM r WHERE c IS NOT NULL
+    ) AS f
+    WHERE
+      f.a = l.a
+  )
+FROM
+  l
+-- !query schema
+struct<scalarsubquery(a):bigint>
+-- !query output
+0
+0
+0
+0
+0
+0
+0
+0
+
+
+-- !query
+SELECT
+(
+  SELECT
+    COUNT(f.a) AS result
+  FROM
+  (
+      SELECT a, b FROM null_view
+      INTERSECT
+      SELECT c, d FROM r WHERE c IS NOT NULL
+  ) AS f
+  WHERE
+    f.a = l.a
+  HAVING COUNT(*) > -1
+)
+FROM
+  l
+-- !query schema
+struct<scalarsubquery(a):bigint>
+-- !query output
+0
+0
+0
+0
+0
+0
+0
+0
+
+
 -- !query
 set spark.sql.optimizer.decorrelateSubqueryLegacyIncorrectCountHandling.enabled = true
 -- !query schema
