diff --git a/core/src/main/resources/error/error-classes.json b/core/src/main/resources/error/error-classes.json
index f4e9a8a3df7..816df79e508 100644
--- a/core/src/main/resources/error/error-classes.json
+++ b/core/src/main/resources/error/error-classes.json
@@ -17,6 +17,12 @@
     ],
     "sqlState" : "22005"
   },
+  "CANNOT_DECODE_URL" : {
+    "message" : [
+      "Cannot decode url : <url>."
+    ],
+    "sqlState" : "42000"
+  },
   "CANNOT_INFER_DATE" : {
     "message" : [
       "Cannot infer date in schema inference when LegacyTimeParserPolicy is \"LEGACY\". Legacy Date formatter does not support strict date format matching which is required to avoid inferring timestamps and other non-date entries to date."
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/urlExpressions.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/urlExpressions.scala
index 174e60371af..de5fde27f6a 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/urlExpressions.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/urlExpressions.scala
@@ -110,7 +110,12 @@ object UrlCodec {
   }
 
   def decode(src: UTF8String, enc: UTF8String): UTF8String = {
-    UTF8String.fromString(URLDecoder.decode(src.toString, enc.toString))
+    try {
+      UTF8String.fromString(URLDecoder.decode(src.toString, enc.toString))
+    } catch {
+      case e: IllegalArgumentException =>
+        throw QueryExecutionErrors.illegalUrlError(src)
+    }
   }
 }
 
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryExecutionErrors.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryExecutionErrors.scala
index e81696621ce..d8d6139e919 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryExecutionErrors.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryExecutionErrors.scala
@@ -325,6 +325,13 @@ private[sql] object QueryExecutionErrors extends QueryErrorsBase {
       s"If necessary set ${SQLConf.ANSI_ENABLED.key} to false to bypass this error.", e)
   }
 
+  def illegalUrlError(url: UTF8String):
+  Throwable with SparkThrowable = {
+    new SparkIllegalArgumentException(errorClass = "CANNOT_DECODE_URL",
+      messageParameters = Array(url.toString)
+    )
+  }
+
   def dataTypeOperationUnsupportedError(): Throwable = {
     new UnsupportedOperationException("dataType")
   }
diff --git a/sql/core/src/test/resources/sql-tests/inputs/url-functions.sql b/sql/core/src/test/resources/sql-tests/inputs/url-functions.sql
index 9f8af7eac7e..be69e5ffb87 100644
--- a/sql/core/src/test/resources/sql-tests/inputs/url-functions.sql
+++ b/sql/core/src/test/resources/sql-tests/inputs/url-functions.sql
@@ -15,5 +15,6 @@ select url_encode(null);
 
 -- url_decode function
 select url_decode('https%3A%2F%2Fspark.apache.org');
+select url_decode('http%3A%2F%2spark.apache.org');
 select url_decode('inva lid://user:pass@host/file\\;param?query\\;p2');
 select url_decode(null);
\ No newline at end of file
diff --git a/sql/core/src/test/resources/sql-tests/results/url-functions.sql.out b/sql/core/src/test/resources/sql-tests/results/url-functions.sql.out
index fc714bfc41b..748904e9b29 100644
--- a/sql/core/src/test/resources/sql-tests/results/url-functions.sql.out
+++ b/sql/core/src/test/resources/sql-tests/results/url-functions.sql.out
@@ -95,6 +95,21 @@ struct<url_decode(https%3A%2F%2Fspark.apache.org):string>
 https://spark.apache.org
 
 
+-- !query
+select url_decode('http%3A%2F%2spark.apache.org')
+-- !query schema
+struct<>
+-- !query output
+org.apache.spark.SparkIllegalArgumentException
+{
+  "errorClass" : "CANNOT_DECODE_URL",
+  "sqlState" : "42000",
+  "messageParameters" : {
+    "url" : "http%3A%2F%2spark.apache.org"
+  }
+}
+
+
 -- !query
 select url_decode('inva lid://user:pass@host/file\\;param?query\\;p2')
 -- !query schema
