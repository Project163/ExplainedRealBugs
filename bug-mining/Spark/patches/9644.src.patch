diff --git a/python/docs/source/getting_started/install.rst b/python/docs/source/getting_started/install.rst
index 6a91a06a1c2..08b6cc813cb 100644
--- a/python/docs/source/getting_started/install.rst
+++ b/python/docs/source/getting_started/install.rst
@@ -53,6 +53,9 @@ If you want to install extra dependencies for a specific component, you can inst
     # Spark Connect
     pip install pyspark[connect]
 
+
+See :ref:`optional-dependencies` for more detail about extra dependencies.
+
 For PySpark with/without a specific Hadoop version, you can install it by using ``PYSPARK_HADOOP_VERSION`` environment variables as below:
 
 .. code-block:: bash
@@ -165,16 +168,109 @@ To install PySpark from source, refer to |building_spark|_.
 
 Dependencies
 ------------
-========================== ========================= ======================================================================================
-Package                    Supported version Note
-========================== ========================= ======================================================================================
-`py4j`                     >=0.10.9.7                Required
-`pandas`                   >=1.4.4                   Required for pandas API on Spark and Spark Connect; Optional for Spark SQL
-`pyarrow`                  >=10.0.0                  Required for pandas API on Spark and Spark Connect; Optional for Spark SQL
-`numpy`                    >=1.21                    Required for pandas API on Spark and MLLib DataFrame-based API; Optional for Spark SQL
-`grpcio`                   >=1.62.0                  Required for Spark Connect
-`grpcio-status`            >=1.62.0                  Required for Spark Connect
-`googleapis-common-protos` >=1.56.4                  Required for Spark Connect
-========================== ========================= ======================================================================================
+
+Required dependencies
+~~~~~~~~~~~~~~~~~~~~~
+
+PySpark requires the following dependencies.
+
+========================== ========================= =============================
+Package                    Supported version         Note
+========================== ========================= =============================
+`py4j`                     >=0.10.9.7                Required to interact with JVM
+========================== ========================= =============================
+
+Additional libraries that enhance functionality but are not included in the installation packages:
+
+- **memory-profiler**: Used for PySpark UDF memory profiling, ``spark.profile.show(...)`` and ``spark.sql.pyspark.udf.profiler``.
 
 Note that PySpark requires Java 17 or later with ``JAVA_HOME`` properly set and refer to |downloading|_.
+
+
+.. _optional-dependencies:
+
+Optional dependencies
+~~~~~~~~~~~~~~~~~~~~~
+
+PySpark has several optional dependencies that enhance its functionality for specific modules.
+These dependencies are only required for certain features and are not necessary for the basic functionality of PySpark.
+If these optional dependencies are not installed, PySpark will function correctly for basic operations but will raise an ``ImportError``
+when you try to use features that require these dependencies.
+
+Spark Connect
+^^^^^^^^^^^^^
+
+Installable with ``pip install "pyspark[connect]"``.
+
+========================== ================= ==========================
+Package                    Supported version Note
+========================== ================= ==========================
+`pandas`                   >=1.4.4           Required for Spark Connect
+`pyarrow`                  >=10.0.0          Required for Spark Connect
+`grpcio`                   >=1.62.0          Required for Spark Connect
+`grpcio-status`            >=1.62.0          Required for Spark Connect
+`googleapis-common-protos` >=1.56.4          Required for Spark Connect
+========================== ================= ==========================
+
+Spark SQL
+^^^^^^^^^
+
+Installable with ``pip install "pyspark[sql]"``.
+
+========= ================= ======================
+Package   Supported version Note
+========= ================= ======================
+`pandas`  >=1.4.4           Required for Spark SQL
+`pyarrow` >=10.0.0          Required for Spark SQL
+========= ================= ======================
+
+
+Pandas API on Spark
+^^^^^^^^^^^^^^^^^^^
+
+Installable with ``pip install "pyspark[pandas_on_spark]"``.
+
+========= ================= ================================
+Package   Supported version Note
+========= ================= ================================
+`pandas`  >=1.4.4           Required for Pandas API on Spark
+`pyarrow` >=10.0.0          Required for Pandas API on Spark
+========= ================= ================================
+
+Additional libraries that enhance functionality but are not included in the installation packages:
+
+- **mlflow**: Required for ``pyspark.pandas.mlflow``.
+- **plotly**: Provide plotting for visualization. It is recommended using **plotly** over **matplotlib**.
+- **matplotlib**: Provide plotting for visualization. The default is **plotly**.
+
+
+MLLib DataFrame-based API
+^^^^^^^^^^^^^^^^^^^^^^^^^
+
+Installable with ``pip install "pyspark[ml]"``.
+
+======= ================= ======================================
+Package Supported version Note
+======= ================= ======================================
+`numpy` >=1.21            Required for MLLib DataFrame-based API
+======= ================= ======================================
+
+Additional libraries that enhance functionality but are not included in the installation packages:
+
+- **scipy**: Required for SciPy integration.
+- **scikit-learn**: Required for implementing machine learning algorithms.
+- **torch**: Required for machine learning model training.
+- **torchvision**: Required for supporting image and video processing.
+- **torcheval**: Required for facilitating model evaluation metrics.
+- **deepspeed**: Required for providing high-performance model training optimizations. Installable on non-Darwin systems.
+
+MLlib
+^^^^^
+
+Installable with ``pip install "pyspark[mllib]"``.
+
+======= ================= ==================
+Package Supported version Note
+======= ================= ==================
+`numpy` >=1.21            Required for MLLib
+======= ================= ==================
