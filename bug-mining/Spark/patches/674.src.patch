diff --git a/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala b/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala
index 53df599cf81..d9eeffa8601 100644
--- a/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala
+++ b/repl/src/main/scala/org/apache/spark/repl/SparkILoop.scala
@@ -18,6 +18,7 @@ import scala.tools.nsc.interpreter._
 import scala.tools.nsc.interpreter.{ Results => IR }
 import Predef.{ println => _, _ }
 import java.io.{ BufferedReader, FileReader }
+import java.net.URI
 import java.util.concurrent.locks.ReentrantLock
 import scala.sys.process.Process
 import scala.tools.nsc.interpreter.session._
@@ -189,8 +190,16 @@ class SparkILoop(in0: Option[BufferedReader], protected val out: JPrintWriter,
     require(settings != null)
 
     if (addedClasspath != "") settings.classpath.append(addedClasspath)
+    val addedJars =
+      if (Utils.isWindows) {
+        // Strip any URI scheme prefix so we can add the correct path to the classpath
+        // e.g. file:/C:/my/path.jar -> C:/my/path.jar
+        SparkILoop.getAddedJars.map { jar => new URI(jar).getPath.stripPrefix("/") }
+      } else {
+        SparkILoop.getAddedJars
+      }
     // work around for Scala bug
-    val totalClassPath = SparkILoop.getAddedJars.foldLeft(
+    val totalClassPath = addedJars.foldLeft(
       settings.classpath.value)((l, r) => ClassPath.join(l, r))
     this.settings.classpath.value = totalClassPath
 
