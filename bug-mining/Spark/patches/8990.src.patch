diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/QueryPlanConstraints.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/QueryPlanConstraints.scala
index 6dcd9910112..022fd7fff75 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/QueryPlanConstraints.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/QueryPlanConstraints.scala
@@ -66,13 +66,15 @@ trait ConstraintHelper {
     val predicates = constraints.filterNot(_.isInstanceOf[IsNotNull])
     predicates.foreach {
       case eq @ EqualTo(l: Attribute, r: Attribute) =>
-        val candidateConstraints = predicates - eq
+        // Also remove EqualNullSafe with the same l and r to avoid Once strategy's idempotence
+        // is broken. l = r and l <=> r can infer l <=> l and r <=> r which is useless.
+        val candidateConstraints = predicates - eq - EqualNullSafe(l, r)
         inferredConstraints ++= replaceConstraints(candidateConstraints, l, r)
         inferredConstraints ++= replaceConstraints(candidateConstraints, r, l)
       case eq @ EqualTo(l @ Cast(_: Attribute, _, _, _), r: Attribute) =>
-        inferredConstraints ++= replaceConstraints(predicates - eq, r, l)
+        inferredConstraints ++= replaceConstraints(predicates - eq - EqualNullSafe(l, r), r, l)
       case eq @ EqualTo(l: Attribute, r @ Cast(_: Attribute, _, _, _)) =>
-        inferredConstraints ++= replaceConstraints(predicates - eq, l, r)
+        inferredConstraints ++= replaceConstraints(predicates - eq - EqualNullSafe(l, r), l, r)
       case _ => // No inference
     }
     inferredConstraints -- constraints
diff --git a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraintsSuite.scala b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraintsSuite.scala
index 721464cb401..d8d8a2b333b 100644
--- a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraintsSuite.scala
+++ b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/InferFiltersFromConstraintsSuite.scala
@@ -371,4 +371,32 @@ class InferFiltersFromConstraintsSuite extends PlanTest {
     val optimized = Optimize.execute(originalQuery)
     comparePlans(optimized, correctAnswer)
   }
+
+  test("SPARK-43095: Avoid Once strategy's idempotence is broken for batch: Infer Filters") {
+    val x = testRelation.as("x")
+    val y = testRelation.as("y")
+    val z = testRelation.as("z")
+
+    // Removes EqualNullSafe when constructing candidate constraints
+    comparePlans(
+      InferFiltersFromConstraints(x.select($"x.a", $"x.a".as("xa"))
+        .where($"xa" <=> $"x.a" && $"xa" === $"x.a").analyze),
+      x.select($"x.a", $"x.a".as("xa"))
+        .where($"xa".isNotNull && $"x.a".isNotNull && $"xa" <=> $"x.a" && $"xa" === $"x.a").analyze)
+
+    // Once strategy's idempotence is not broken
+    val originalQuery =
+      x.join(y, condition = Some($"x.a" === $"y.a"))
+        .select($"x.a", $"x.a".as("xa")).as("xy")
+        .join(z, condition = Some($"xy.a" === $"z.a")).analyze
+
+    val correctAnswer =
+      x.where($"a".isNotNull).join(y.where($"a".isNotNull), condition = Some($"x.a" === $"y.a"))
+        .select($"x.a", $"x.a".as("xa")).as("xy")
+        .join(z.where($"a".isNotNull), condition = Some($"xy.a" === $"z.a")).analyze
+
+    val optimizedQuery = InferFiltersFromConstraints(originalQuery)
+    comparePlans(optimizedQuery, correctAnswer)
+    comparePlans(InferFiltersFromConstraints(optimizedQuery), correctAnswer)
+  }
 }
