diff --git a/python/pyspark/sql/tests/test_dataframe.py b/python/pyspark/sql/tests/test_dataframe.py
index 2d578d74951..75a553b6283 100644
--- a/python/pyspark/sql/tests/test_dataframe.py
+++ b/python/pyspark/sql/tests/test_dataframe.py
@@ -220,6 +220,34 @@ class DataFrameTestsMixin:
         self.assertEqual(df4.columns, ["colA", "colB", "colC", "colC", "colD", "colE"])
         self.assertEqual(df4.count(), 1)
 
+    def test_drop_col_from_different_dataframe(self):
+        df1 = self.spark.range(10)
+        df2 = df1.withColumn("v0", lit(0))
+
+        # drop df2["id"] from df2
+        self.assertEqual(df2.drop(df2["id"]).columns, ["v0"])
+
+        # drop df1["id"] from df2, which is semantically equal to df2["id"]
+        # note that df1.drop(df2["id"]) works in Classic, but not in Connect
+        self.assertEqual(df2.drop(df1["id"]).columns, ["v0"])
+
+        df3 = df2.select("*", lit(1).alias("v1"))
+
+        # drop df3["id"] from df3
+        self.assertEqual(df3.drop(df3["id"]).columns, ["v0", "v1"])
+
+        # drop df2["id"] from df3, which is semantically equal to df3["id"]
+        self.assertEqual(df3.drop(df2["id"]).columns, ["v0", "v1"])
+
+        # drop df1["id"] from df3, which is semantically equal to df3["id"]
+        self.assertEqual(df3.drop(df1["id"]).columns, ["v0", "v1"])
+
+        # drop df3["v0"] from df3
+        self.assertEqual(df3.drop(df3["v0"]).columns, ["id", "v1"])
+
+        # drop df2["v0"] from df3, which is semantically equal to df3["v0"]
+        self.assertEqual(df3.drop(df2["v0"]).columns, ["id", "v1"])
+
     def test_drop_join(self):
         left_df = self.spark.createDataFrame(
             [(1, "a"), (2, "b"), (3, "c")],
diff --git a/sql/connect/client/jvm/src/test/scala/org/apache/spark/sql/connect/DataFrameSuite.scala b/sql/connect/client/jvm/src/test/scala/org/apache/spark/sql/connect/DataFrameSuite.scala
index 03793c8bbb7..890245fdd2f 100644
--- a/sql/connect/client/jvm/src/test/scala/org/apache/spark/sql/connect/DataFrameSuite.scala
+++ b/sql/connect/client/jvm/src/test/scala/org/apache/spark/sql/connect/DataFrameSuite.scala
@@ -19,7 +19,7 @@ package org.apache.spark.sql.connect
 
 import org.apache.spark.sql.AnalysisException
 import org.apache.spark.sql.connect.test.{QueryTest, RemoteSparkSession}
-import org.apache.spark.sql.functions.{concat, lit, when}
+import org.apache.spark.sql.functions.{col, concat, lit, when}
 
 class DataFrameSuite extends QueryTest with RemoteSparkSession {
 
@@ -44,6 +44,29 @@ class DataFrameSuite extends QueryTest with RemoteSparkSession {
     assert(df4.count() === 1)
   }
 
+  test("drop column from different dataframe") {
+    val sparkSession = spark
+
+    val df1 = spark.range(10)
+    val df2 = df1.select(col("id"), lit(0).as("v0"))
+
+    assert(df2.drop(df2.col("id")).columns === Array("v0"))
+    // drop df1.col("id") from df2, which is semantically equal to df2.col("id")
+    // note that df1.drop(df2.col("id")) works in Classic, but not in Connect
+    assert(df2.drop(df1.col("id")).columns === Array("v0"))
+
+    val df3 = df2.select(col("*"), lit(1).as("v1"))
+    assert(df3.drop(df3.col("id")).columns === Array("v0", "v1"))
+    // drop df2.col("id") from df3, which is semantically equal to df3.col("id")
+    assert(df3.drop(df2.col("id")).columns === Array("v0", "v1"))
+    // drop df1.col("id") from df3, which is semantically equal to df3.col("id")
+    assert(df3.drop(df1.col("id")).columns === Array("v0", "v1"))
+
+    assert(df3.drop(df3.col("v0")).columns === Array("id", "v1"))
+    // drop df2.col("v0") from df3, which is semantically equal to df3.col("v0")
+    assert(df3.drop(df2.col("v0")).columns === Array("id", "v1"))
+  }
+
   test("lazy column validation") {
     val session = spark
     import session.implicits._
