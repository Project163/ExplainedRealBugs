diff --git a/sql/api/src/main/scala/org/apache/spark/sql/types/UpCastRule.scala b/sql/api/src/main/scala/org/apache/spark/sql/types/UpCastRule.scala
index 14625596259..97a81f0fe8f 100644
--- a/sql/api/src/main/scala/org/apache/spark/sql/types/UpCastRule.scala
+++ b/sql/api/src/main/scala/org/apache/spark/sql/types/UpCastRule.scala
@@ -72,7 +72,7 @@ private[sql] object UpCastRule {
     case _ => false
   }
 
-  private def legalNumericPrecedence(from: DataType, to: DataType): Boolean = {
+  def legalNumericPrecedence(from: DataType, to: DataType): Boolean = {
     val fromPrecedence = numericPrecedence.indexOf(from)
     val toPrecedence = numericPrecedence.indexOf(to)
     fromPrecedence >= 0 && fromPrecedence < toPrecedence
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/randomExpressions.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/randomExpressions.scala
index 7148d3738f7..687dd83291b 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/randomExpressions.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/randomExpressions.scala
@@ -206,7 +206,7 @@ object Randn {
   since = "4.0.0",
   group = "math_funcs")
 case class Uniform(min: Expression, max: Expression, seedExpression: Expression, hideSeed: Boolean)
-  extends RuntimeReplaceable with TernaryLike[Expression] with RDG {
+  extends RuntimeReplaceable with TernaryLike[Expression] with RDG with ExpectsInputTypes {
   def this(min: Expression, max: Expression) =
     this(min, max, UnresolvedSeed, hideSeed = true)
   def this(min: Expression, max: Expression, seedExpression: Expression) =
@@ -216,63 +216,46 @@ case class Uniform(min: Expression, max: Expression, seedExpression: Expression,
   override val nodePatterns: Seq[TreePattern] =
     Seq(RUNTIME_REPLACEABLE, EXPRESSION_WITH_RANDOM_SEED)
 
+  override def inputTypes: Seq[AbstractDataType] = {
+    val randomSeedTypes = TypeCollection(IntegerType, LongType)
+    Seq(NumericType, NumericType, randomSeedTypes)
+  }
+
   override def dataType: DataType = {
-    val first = min.dataType
-    val second = max.dataType
     (min.dataType, max.dataType) match {
       case _ if !seedExpression.resolved || seedExpression.dataType == NullType =>
         NullType
-      case (_, NullType) | (NullType, _) => NullType
-      case (_, LongType) | (LongType, _)
-        if Seq(first, second).forall(integer) => LongType
-      case (_, IntegerType) | (IntegerType, _)
-        if Seq(first, second).forall(integer) => IntegerType
-      case (_, ShortType) | (ShortType, _)
-        if Seq(first, second).forall(integer) => ShortType
-      case (_, DoubleType) | (DoubleType, _) => DoubleType
-      case (_, FloatType) | (FloatType, _) => FloatType
+      case (left: IntegralType, right: IntegralType) =>
+        if (UpCastRule.legalNumericPrecedence(left, right)) right else left
+      case (_: NumericType, DoubleType) | (DoubleType, _: NumericType) => DoubleType
+      case (_: NumericType, FloatType) | (FloatType, _: NumericType) => FloatType
+      case (lhs: DecimalType, rhs: DecimalType) => if (lhs.isWiderThan(rhs)) lhs else rhs
+      case (_, d: DecimalType) => d
+      case (d: DecimalType, _) => d
       case _ =>
         throw SparkException.internalError(
           s"Unexpected argument data types: ${min.dataType}, ${max.dataType}")
     }
   }
 
-  private def integer(t: DataType): Boolean = t match {
-    case _: ShortType | _: IntegerType | _: LongType => true
-    case _ => false
-  }
-
   override def sql: String = {
     s"uniform(${min.sql}, ${max.sql}${if (hideSeed) "" else s", ${seedExpression.sql}"})"
   }
 
   override def checkInputDataTypes(): TypeCheckResult = {
-    var result: TypeCheckResult = TypeCheckResult.TypeCheckSuccess
+    var result: TypeCheckResult = super.checkInputDataTypes()
     def requiredType = "integer or floating-point"
-    Seq((min, "min", 0),
-      (max, "max", 1),
-      (seedExpression, "seed", 2)).foreach {
-      case (expr: Expression, name: String, index: Int) =>
-        if (result == TypeCheckResult.TypeCheckSuccess) {
-          if (!expr.foldable) {
-            result = DataTypeMismatch(
-              errorSubClass = "NON_FOLDABLE_INPUT",
-              messageParameters = Map(
-                "inputName" -> toSQLId(name),
-                "inputType" -> requiredType,
-                "inputExpr" -> toSQLExpr(expr)))
-          } else expr.dataType match {
-            case _: ShortType | _: IntegerType | _: LongType | _: FloatType | _: DoubleType |
-                 _: NullType =>
-            case _ =>
-              result = DataTypeMismatch(
-                errorSubClass = "UNEXPECTED_INPUT_TYPE",
-                messageParameters = Map(
-                  "paramIndex" -> ordinalNumber(index),
-                  "requiredType" -> requiredType,
-                  "inputSql" -> toSQLExpr(expr),
-                  "inputType" -> toSQLType(expr.dataType)))
-          }
+    Seq((min, "min"),
+      (max, "max"),
+      (seedExpression, "seed")).foreach {
+      case (expr: Expression, name: String) =>
+        if (result == TypeCheckResult.TypeCheckSuccess && !expr.foldable) {
+          result = DataTypeMismatch(
+            errorSubClass = "NON_FOLDABLE_INPUT",
+            messageParameters = Map(
+              "inputName" -> toSQLId(name),
+              "inputType" -> requiredType,
+              "inputExpr" -> toSQLExpr(expr)))
         }
     }
     result
diff --git a/sql/core/src/test/resources/sql-tests/analyzer-results/random.sql.out b/sql/core/src/test/resources/sql-tests/analyzer-results/random.sql.out
index 31919381c99..59e903b8682 100644
--- a/sql/core/src/test/resources/sql-tests/analyzer-results/random.sql.out
+++ b/sql/core/src/test/resources/sql-tests/analyzer-results/random.sql.out
@@ -119,6 +119,18 @@ SELECT uniform(0, 10L, 0) AS result
 [Analyzer test output redacted due to nondeterminism]
 
 
+-- !query
+SELECT uniform(0, cast(10 as tinyint), 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(0, cast(10 as smallint), 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
 -- !query
 SELECT uniform(0, 10S, 0) AS result
 -- !query analysis
@@ -137,6 +149,30 @@ SELECT uniform(10.0F, 20.0F, 0) AS result
 [Analyzer test output redacted due to nondeterminism]
 
 
+-- !query
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(10, 3)), 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(11, 4)), 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(10, cast(20 as decimal(10, 3)), 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(cast(10 as decimal(10, 3)), 20, 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
 -- !query
 SELECT uniform(10.0D, 20.0D, CAST(3 / 7 AS LONG)) AS result
 -- !query analysis
@@ -161,24 +197,108 @@ SELECT uniform(10, 20.0F) IS NOT NULL AS result
 [Analyzer test output redacted due to nondeterminism]
 
 
+-- !query
+SELECT uniform(-10L, 10L, 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(-20L, -10L, 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(-20L, -10L, -10) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
 -- !query
 SELECT uniform(NULL, 1, 0) AS result
 -- !query analysis
 [Analyzer test output redacted due to nondeterminism]
 
 
+-- !query
+SELECT uniform(cast(NULL AS int), 1, 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(cast(NULL AS float), 1, 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
 -- !query
 SELECT uniform(0, NULL, 0) AS result
 -- !query analysis
 [Analyzer test output redacted due to nondeterminism]
 
 
+-- !query
+SELECT uniform(0, cast(NULL AS int), 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(0, cast(NULL AS float), 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
 -- !query
 SELECT uniform(0, 1, NULL) AS result
 -- !query analysis
 [Analyzer test output redacted due to nondeterminism]
 
 
+-- !query
+SELECT uniform(NULL, NULL, 0) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(NULL, NULL, NULL) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(0, 1, cast(NULL as int)) AS result
+-- !query analysis
+[Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+SELECT uniform(0, 1, cast(NULL as float)) AS result
+-- !query analysis
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"CAST(NULL AS FLOAT)\"",
+    "inputType" : "\"FLOAT\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(0, 1, CAST(NULL AS FLOAT))\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 41,
+    "fragment" : "uniform(0, 1, cast(NULL as float))"
+  } ]
+}
+
+
 -- !query
 SELECT uniform(10, 20, col) AS result FROM VALUES (0), (1), (2) tab(col)
 -- !query analysis
@@ -271,6 +391,150 @@ org.apache.spark.sql.AnalysisException
 }
 
 
+-- !query
+SELECT uniform(10.0F, 20.0F, 0.0F) AS result
+-- !query analysis
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"0.0\"",
+    "inputType" : "\"FLOAT\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(10.0, 20.0, 0.0)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 34,
+    "fragment" : "uniform(10.0F, 20.0F, 0.0F)"
+  } ]
+}
+
+
+-- !query
+SELECT uniform(10.0F, 20.0F, 0.0D) AS result
+-- !query analysis
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"0.0\"",
+    "inputType" : "\"DOUBLE\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(10.0, 20.0, 0.0)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 34,
+    "fragment" : "uniform(10.0F, 20.0F, 0.0D)"
+  } ]
+}
+
+
+-- !query
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(10, 3)), cast(0 as decimal(10, 3)))
+-- !query analysis
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"CAST(0 AS DECIMAL(10,3))\"",
+    "inputType" : "\"DECIMAL(10,3)\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(CAST(10 AS DECIMAL(10,3)), CAST(20 AS DECIMAL(10,3)), CAST(0 AS DECIMAL(10,3)))\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 97,
+    "fragment" : "uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(10, 3)), cast(0 as decimal(10, 3)))"
+  } ]
+}
+
+
+-- !query
+SELECT uniform('abc', 10, 0) AS result
+-- !query analysis
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"abc\"",
+    "inputType" : "\"STRING\"",
+    "paramIndex" : "first",
+    "requiredType" : "\"NUMERIC\"",
+    "sqlExpr" : "\"uniform(abc, 10, 0)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 28,
+    "fragment" : "uniform('abc', 10, 0)"
+  } ]
+}
+
+
+-- !query
+SELECT uniform(0, 'def', 0) AS result
+-- !query analysis
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"def\"",
+    "inputType" : "\"STRING\"",
+    "paramIndex" : "second",
+    "requiredType" : "\"NUMERIC\"",
+    "sqlExpr" : "\"uniform(0, def, 0)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 27,
+    "fragment" : "uniform(0, 'def', 0)"
+  } ]
+}
+
+
+-- !query
+SELECT uniform(0, 10, 'ghi') AS result
+-- !query analysis
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"ghi\"",
+    "inputType" : "\"STRING\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(0, 10, ghi)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 28,
+    "fragment" : "uniform(0, 10, 'ghi')"
+  } ]
+}
+
+
 -- !query
 SELECT randstr(1, 0) AS result
 -- !query analysis
diff --git a/sql/core/src/test/resources/sql-tests/inputs/random.sql b/sql/core/src/test/resources/sql-tests/inputs/random.sql
index a71b0293295..a17571aa728 100644
--- a/sql/core/src/test/resources/sql-tests/inputs/random.sql
+++ b/sql/core/src/test/resources/sql-tests/inputs/random.sql
@@ -22,21 +22,44 @@ SELECT uniform(0, 1, 0) AS result;
 SELECT uniform(0, 10, 0) AS result;
 SELECT uniform(0L, 10L, 0) AS result;
 SELECT uniform(0, 10L, 0) AS result;
+SELECT uniform(0, cast(10 as tinyint), 0) AS result;
+SELECT uniform(0, cast(10 as smallint), 0) AS result;
 SELECT uniform(0, 10S, 0) AS result;
 SELECT uniform(10, 20, 0) AS result;
 SELECT uniform(10.0F, 20.0F, 0) AS result;
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(10, 3)), 0) AS result;
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(11, 4)), 0) AS result;
+SELECT uniform(10, cast(20 as decimal(10, 3)), 0) AS result;
+SELECT uniform(cast(10 as decimal(10, 3)), 20, 0) AS result;
 SELECT uniform(10.0D, 20.0D, CAST(3 / 7 AS LONG)) AS result;
 SELECT uniform(10, 20.0F, 0) AS result;
 SELECT uniform(10, 20, 0) AS result FROM VALUES (0), (1), (2) tab(col);
 SELECT uniform(10, 20.0F) IS NOT NULL AS result;
--- Negative test cases for the uniform random number generator.
+SELECT uniform(-10L, 10L, 0) AS result;
+SELECT uniform(-20L, -10L, 0) AS result;
+SELECT uniform(-20L, -10L, -10) AS result;
 SELECT uniform(NULL, 1, 0) AS result;
+SELECT uniform(cast(NULL AS int), 1, 0) AS result;
+SELECT uniform(cast(NULL AS float), 1, 0) AS result;
 SELECT uniform(0, NULL, 0) AS result;
+SELECT uniform(0, cast(NULL AS int), 0) AS result;
+SELECT uniform(0, cast(NULL AS float), 0) AS result;
 SELECT uniform(0, 1, NULL) AS result;
+SELECT uniform(NULL, NULL, 0) AS result;
+SELECT uniform(NULL, NULL, NULL) AS result;
+-- Negative test cases for the uniform random number generator.
+SELECT uniform(0, 1, cast(NULL as int)) AS result;
+SELECT uniform(0, 1, cast(NULL as float)) AS result;
 SELECT uniform(10, 20, col) AS result FROM VALUES (0), (1), (2) tab(col);
 SELECT uniform(col, 10, 0) AS result FROM VALUES (0), (1), (2) tab(col);
 SELECT uniform(10) AS result;
 SELECT uniform(10, 20, 30, 40) AS result;
+SELECT uniform(10.0F, 20.0F, 0.0F) AS result;
+SELECT uniform(10.0F, 20.0F, 0.0D) AS result;
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(10, 3)), cast(0 as decimal(10, 3)));
+SELECT uniform('abc', 10, 0) AS result;
+SELECT uniform(0, 'def', 0) AS result;
+SELECT uniform(0, 10, 'ghi') AS result;
 
 -- The randstr random string generation function supports generating random strings within a
 -- specified length. We use a seed of zero for these queries to keep tests deterministic.
diff --git a/sql/core/src/test/resources/sql-tests/results/random.sql.out b/sql/core/src/test/resources/sql-tests/results/random.sql.out
index 01638abdcec..eebfac5fc2b 100644
--- a/sql/core/src/test/resources/sql-tests/results/random.sql.out
+++ b/sql/core/src/test/resources/sql-tests/results/random.sql.out
@@ -147,6 +147,22 @@ struct<result:bigint>
 7
 
 
+-- !query
+SELECT uniform(0, cast(10 as tinyint), 0) AS result
+-- !query schema
+struct<result:int>
+-- !query output
+7
+
+
+-- !query
+SELECT uniform(0, cast(10 as smallint), 0) AS result
+-- !query schema
+struct<result:int>
+-- !query output
+7
+
+
 -- !query
 SELECT uniform(0, 10S, 0) AS result
 -- !query schema
@@ -171,6 +187,38 @@ struct<result:float>
 17.604954
 
 
+-- !query
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(10, 3)), 0) AS result
+-- !query schema
+struct<result:decimal(10,3)>
+-- !query output
+17.605
+
+
+-- !query
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(11, 4)), 0) AS result
+-- !query schema
+struct<result:decimal(11,4)>
+-- !query output
+17.6050
+
+
+-- !query
+SELECT uniform(10, cast(20 as decimal(10, 3)), 0) AS result
+-- !query schema
+struct<result:decimal(10,3)>
+-- !query output
+17.605
+
+
+-- !query
+SELECT uniform(cast(10 as decimal(10, 3)), 20, 0) AS result
+-- !query schema
+struct<result:decimal(10,3)>
+-- !query output
+17.605
+
+
 -- !query
 SELECT uniform(10.0D, 20.0D, CAST(3 / 7 AS LONG)) AS result
 -- !query schema
@@ -205,10 +253,50 @@ struct<result:boolean>
 true
 
 
+-- !query
+SELECT uniform(-10L, 10L, 0) AS result
+-- !query schema
+struct<result:bigint>
+-- !query output
+5
+
+
+-- !query
+SELECT uniform(-20L, -10L, 0) AS result
+-- !query schema
+struct<result:bigint>
+-- !query output
+-12
+
+
+-- !query
+SELECT uniform(-20L, -10L, -10) AS result
+-- !query schema
+struct<result:bigint>
+-- !query output
+-17
+
+
 -- !query
 SELECT uniform(NULL, 1, 0) AS result
 -- !query schema
-struct<result:void>
+struct<result:double>
+-- !query output
+NULL
+
+
+-- !query
+SELECT uniform(cast(NULL AS int), 1, 0) AS result
+-- !query schema
+struct<result:int>
+-- !query output
+NULL
+
+
+-- !query
+SELECT uniform(cast(NULL AS float), 1, 0) AS result
+-- !query schema
+struct<result:float>
 -- !query output
 NULL
 
@@ -216,7 +304,23 @@ NULL
 -- !query
 SELECT uniform(0, NULL, 0) AS result
 -- !query schema
-struct<result:void>
+struct<result:double>
+-- !query output
+NULL
+
+
+-- !query
+SELECT uniform(0, cast(NULL AS int), 0) AS result
+-- !query schema
+struct<result:int>
+-- !query output
+NULL
+
+
+-- !query
+SELECT uniform(0, cast(NULL AS float), 0) AS result
+-- !query schema
+struct<result:float>
 -- !query output
 NULL
 
@@ -224,11 +328,61 @@ NULL
 -- !query
 SELECT uniform(0, 1, NULL) AS result
 -- !query schema
-struct<result:void>
+struct<result:int>
+-- !query output
+0
+
+
+-- !query
+SELECT uniform(NULL, NULL, 0) AS result
+-- !query schema
+struct<result:double>
 -- !query output
 NULL
 
 
+-- !query
+SELECT uniform(NULL, NULL, NULL) AS result
+-- !query schema
+struct<result:double>
+-- !query output
+NULL
+
+
+-- !query
+SELECT uniform(0, 1, cast(NULL as int)) AS result
+-- !query schema
+struct<result:int>
+-- !query output
+0
+
+
+-- !query
+SELECT uniform(0, 1, cast(NULL as float)) AS result
+-- !query schema
+struct<>
+-- !query output
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"CAST(NULL AS FLOAT)\"",
+    "inputType" : "\"FLOAT\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(0, 1, CAST(NULL AS FLOAT))\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 41,
+    "fragment" : "uniform(0, 1, cast(NULL as float))"
+  } ]
+}
+
+
 -- !query
 SELECT uniform(10, 20, col) AS result FROM VALUES (0), (1), (2) tab(col)
 -- !query schema
@@ -329,6 +483,162 @@ org.apache.spark.sql.AnalysisException
 }
 
 
+-- !query
+SELECT uniform(10.0F, 20.0F, 0.0F) AS result
+-- !query schema
+struct<>
+-- !query output
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"0.0\"",
+    "inputType" : "\"FLOAT\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(10.0, 20.0, 0.0)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 34,
+    "fragment" : "uniform(10.0F, 20.0F, 0.0F)"
+  } ]
+}
+
+
+-- !query
+SELECT uniform(10.0F, 20.0F, 0.0D) AS result
+-- !query schema
+struct<>
+-- !query output
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"0.0\"",
+    "inputType" : "\"DOUBLE\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(10.0, 20.0, 0.0)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 34,
+    "fragment" : "uniform(10.0F, 20.0F, 0.0D)"
+  } ]
+}
+
+
+-- !query
+SELECT uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(10, 3)), cast(0 as decimal(10, 3)))
+-- !query schema
+struct<>
+-- !query output
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"CAST(0 AS DECIMAL(10,3))\"",
+    "inputType" : "\"DECIMAL(10,3)\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(CAST(10 AS DECIMAL(10,3)), CAST(20 AS DECIMAL(10,3)), CAST(0 AS DECIMAL(10,3)))\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 97,
+    "fragment" : "uniform(cast(10 as decimal(10, 3)), cast(20 as decimal(10, 3)), cast(0 as decimal(10, 3)))"
+  } ]
+}
+
+
+-- !query
+SELECT uniform('abc', 10, 0) AS result
+-- !query schema
+struct<>
+-- !query output
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"abc\"",
+    "inputType" : "\"STRING\"",
+    "paramIndex" : "first",
+    "requiredType" : "\"NUMERIC\"",
+    "sqlExpr" : "\"uniform(abc, 10, 0)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 28,
+    "fragment" : "uniform('abc', 10, 0)"
+  } ]
+}
+
+
+-- !query
+SELECT uniform(0, 'def', 0) AS result
+-- !query schema
+struct<>
+-- !query output
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"def\"",
+    "inputType" : "\"STRING\"",
+    "paramIndex" : "second",
+    "requiredType" : "\"NUMERIC\"",
+    "sqlExpr" : "\"uniform(0, def, 0)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 27,
+    "fragment" : "uniform(0, 'def', 0)"
+  } ]
+}
+
+
+-- !query
+SELECT uniform(0, 10, 'ghi') AS result
+-- !query schema
+struct<>
+-- !query output
+org.apache.spark.sql.catalyst.ExtendedAnalysisException
+{
+  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
+  "sqlState" : "42K09",
+  "messageParameters" : {
+    "inputSql" : "\"ghi\"",
+    "inputType" : "\"STRING\"",
+    "paramIndex" : "third",
+    "requiredType" : "(\"INT\" or \"BIGINT\")",
+    "sqlExpr" : "\"uniform(0, 10, ghi)\""
+  },
+  "queryContext" : [ {
+    "objectType" : "",
+    "objectName" : "",
+    "startIndex" : 8,
+    "stopIndex" : 28,
+    "fragment" : "uniform(0, 10, 'ghi')"
+  } ]
+}
+
+
 -- !query
 SELECT randstr(1, 0) AS result
 -- !query schema
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/DataFrameFunctionsSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/DataFrameFunctionsSuite.scala
index ce34db47c6d..018aa2159ba 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/DataFrameFunctionsSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/DataFrameFunctionsSuite.scala
@@ -517,7 +517,7 @@ class DataFrameFunctionsSuite extends QueryTest with SharedSparkSession {
         "paramIndex" -> "second",
         "inputSql" -> "\"a\"",
         "inputType" -> "\"STRING\"",
-        "requiredType" -> "integer or floating-point"),
+        "requiredType" -> "\"NUMERIC\""),
       context = ExpectedContext(
         contextType = QueryContextType.DataFrame,
         fragment = "uniform",
diff --git a/sql/hive-thriftserver/src/test/scala/org/apache/spark/sql/hive/thriftserver/ThriftServerQueryTestSuite.scala b/sql/hive-thriftserver/src/test/scala/org/apache/spark/sql/hive/thriftserver/ThriftServerQueryTestSuite.scala
index 283454ad273..bc367d0cc85 100644
--- a/sql/hive-thriftserver/src/test/scala/org/apache/spark/sql/hive/thriftserver/ThriftServerQueryTestSuite.scala
+++ b/sql/hive-thriftserver/src/test/scala/org/apache/spark/sql/hive/thriftserver/ThriftServerQueryTestSuite.scala
@@ -94,6 +94,7 @@ class ThriftServerQueryTestSuite extends SQLQueryTestSuite with SharedThriftServ
     // SPARK-28636
     "decimalArithmeticOperations.sql",
     "literals.sql",
+    "random.sql",
     "subquery/scalar-subquery/scalar-subquery-predicate.sql",
     "subquery/in-subquery/in-limit.sql",
     "subquery/in-subquery/in-group-by.sql",
