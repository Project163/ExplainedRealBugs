diff --git a/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/RocksDB.scala b/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/RocksDB.scala
index 7367ad7485b..4365d131d08 100644
--- a/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/RocksDB.scala
+++ b/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/RocksDB.scala
@@ -741,13 +741,13 @@ class RocksDB(
           changelogReader.foreach { case (recordType, key, value) =>
             recordType match {
               case RecordType.PUT_RECORD =>
-                put(key, value, includesPrefix = true)
+                put(key, value, includesPrefix = true, deriveCfName = true)
 
               case RecordType.DELETE_RECORD =>
-                remove(key, includesPrefix = true)
+                remove(key, includesPrefix = true, deriveCfName = true)
 
               case RecordType.MERGE_RECORD =>
-                merge(key, value, includesPrefix = true)
+                merge(key, value, includesPrefix = true, deriveCfName = true)
             }
           }
         } else {
@@ -876,7 +876,8 @@ class RocksDB(
       key: Array[Byte],
       value: Array[Byte],
       cfName: String = StateStore.DEFAULT_COL_FAMILY_NAME,
-      includesPrefix: Boolean = false): Unit = {
+      includesPrefix: Boolean = false,
+      deriveCfName: Boolean = false): Unit = {
     updateMemoryUsageIfNeeded()
     val keyWithPrefix = if (useColumnFamilies && !includesPrefix) {
       encodeStateRowWithPrefix(key, cfName)
@@ -884,7 +885,14 @@ class RocksDB(
       key
     }
 
-    handleMetricsUpdate(keyWithPrefix, cfName, isPutOrMerge = true)
+    val columnFamilyName = if (deriveCfName && useColumnFamilies) {
+      val (_, cfName) = decodeStateRowWithPrefix(keyWithPrefix)
+      cfName
+    } else {
+      cfName
+    }
+
+    handleMetricsUpdate(keyWithPrefix, columnFamilyName, isPutOrMerge = true)
     db.put(writeOptions, keyWithPrefix, value)
     changelogWriter.foreach(_.put(keyWithPrefix, value))
   }
@@ -904,7 +912,8 @@ class RocksDB(
       key: Array[Byte],
       value: Array[Byte],
       cfName: String = StateStore.DEFAULT_COL_FAMILY_NAME,
-      includesPrefix: Boolean = false): Unit = {
+      includesPrefix: Boolean = false,
+      deriveCfName: Boolean = false): Unit = {
     updateMemoryUsageIfNeeded()
     val keyWithPrefix = if (useColumnFamilies && !includesPrefix) {
       encodeStateRowWithPrefix(key, cfName)
@@ -912,7 +921,14 @@ class RocksDB(
       key
     }
 
-    handleMetricsUpdate(keyWithPrefix, cfName, isPutOrMerge = true)
+    val columnFamilyName = if (deriveCfName && useColumnFamilies) {
+      val (_, cfName) = decodeStateRowWithPrefix(keyWithPrefix)
+      cfName
+    } else {
+      cfName
+    }
+
+    handleMetricsUpdate(keyWithPrefix, columnFamilyName, isPutOrMerge = true)
     db.merge(writeOptions, keyWithPrefix, value)
     changelogWriter.foreach(_.merge(keyWithPrefix, value))
   }
@@ -924,7 +940,8 @@ class RocksDB(
   def remove(
       key: Array[Byte],
       cfName: String = StateStore.DEFAULT_COL_FAMILY_NAME,
-      includesPrefix: Boolean = false): Unit = {
+      includesPrefix: Boolean = false,
+      deriveCfName: Boolean = false): Unit = {
     updateMemoryUsageIfNeeded()
     val keyWithPrefix = if (useColumnFamilies && !includesPrefix) {
       encodeStateRowWithPrefix(key, cfName)
@@ -932,7 +949,14 @@ class RocksDB(
       key
     }
 
-    handleMetricsUpdate(keyWithPrefix, cfName, isPutOrMerge = false)
+    val columnFamilyName = if (deriveCfName && useColumnFamilies) {
+      val (_, cfName) = decodeStateRowWithPrefix(keyWithPrefix)
+      cfName
+    } else {
+      cfName
+    }
+
+    handleMetricsUpdate(keyWithPrefix, columnFamilyName, isPutOrMerge = false)
     db.delete(writeOptions, keyWithPrefix)
     changelogWriter.foreach(_.delete(keyWithPrefix))
   }
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingJoinSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingJoinSuite.scala
index faf0ddc9538..47f9a8f80e2 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingJoinSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamingJoinSuite.scala
@@ -48,8 +48,34 @@ trait AlsoTestWithVirtualColumnFamilyJoins extends SQLTestUtils {
   /** Tests both with and without join ops using virtual column families */
   override protected def test(testName: String, testTags: Tag*)(testBody: => Any)(
     implicit pos: Position): Unit = {
-    testWithVirtualColumnFamilyJoins(testName, testTags: _*)(testBody)
-    testWithoutVirtualColumnFamilyJoins(testName, testTags: _*)(testBody)
+    // Test with virtual column family joins with changelog checkpointing enabled and disabled
+    // Since virtual column family joins require RocksDB, we only test with RocksDB here.
+    Seq("false", "true").foreach { enabled =>
+      testWithVirtualColumnFamilyJoins(
+        testName + s" with (with changelog checkpointing = $enabled)", testTags: _*) {
+        withSQLConf(
+          "spark.sql.streaming.stateStore.rocksdb.changelogCheckpointing.enabled" -> enabled
+        ) {
+          testBody
+        }
+      }
+    }
+
+    // Test with both RocksDB and HDFS state store providers without virtual column family joins
+    val providers = Seq(
+      classOf[RocksDBStateStoreProvider].getName,
+      classOf[HDFSBackedStateStoreProvider].getName
+    )
+
+    providers.foreach { provider =>
+      testWithoutVirtualColumnFamilyJoins(testName + s" (with $provider)", testTags: _*) {
+        withSQLConf(
+          SQLConf.STATE_STORE_PROVIDER_CLASS.key -> provider
+        ) {
+          testBody
+        }
+      }
+    }
   }
 
   def testWithVirtualColumnFamilyJoins(testName: String, testTags: Tag*)(testBody: => Any): Unit = {
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithListStateSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithListStateSuite.scala
index efa95d152bb..b8932a96260 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithListStateSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithListStateSuite.scala
@@ -224,7 +224,7 @@ class ToggleSaveAndEmitProcessor
 
 @SlowSQLTest
 class TransformWithListStateSuite extends StreamTest
-  with AlsoTestWithRocksDBFeatures with AlsoTestWithEncodingTypes {
+  with AlsoTestWithRocksDBFeatures with AlsoTestWithEncodingTypes with StateStoreMetricsTest {
   import testImplicits._
 
   test("test appending null value in list state throw exception") {
@@ -362,10 +362,14 @@ class TransformWithListStateSuite extends StreamTest
         // no interaction test
         AddData(inputData, InputRow("k1", "emit", "v1")),
         CheckNewAnswer(("k1", "v1")),
+        assertNumStateRows(total = 0, updated = 0), // emit does not change state
+
         // check simple append
         AddData(inputData, InputRow("k1", "append", "v2")),
         AddData(inputData, InputRow("k1", "emitAllInState", "")),
         CheckNewAnswer(("k1", "v2")),
+        assertNumStateRows(total = 0, updated = 1), // emitAllInState clears state
+
         // multiple appends are correctly stored and emitted
         AddData(inputData, InputRow("k2", "append", "v1")),
         AddData(inputData, InputRow("k1", "append", "v4")),
@@ -373,33 +377,45 @@ class TransformWithListStateSuite extends StreamTest
         AddData(inputData, InputRow("k1", "emit", "v5")),
         AddData(inputData, InputRow("k2", "emit", "v3")),
         CheckNewAnswer(("k1", "v5"), ("k2", "v3")),
+        assertNumStateRows(total = 2, updated = 3),
+
         AddData(inputData, InputRow("k1", "emitAllInState", "")),
         AddData(inputData, InputRow("k2", "emitAllInState", "")),
         CheckNewAnswer(("k2", "v1"), ("k2", "v2"), ("k1", "v4")),
+        assertNumStateRows(total = 0, updated = 0),
+
         // check appendAll with append
         AddData(inputData, InputRow("k3", "appendAll", "v1,v2,v3")),
         AddData(inputData, InputRow("k3", "emit", "v4")),
         AddData(inputData, InputRow("k3", "append", "v5")),
         CheckNewAnswer(("k3", "v4")),
+        assertNumStateRows(total = 1, updated = 4),
+
         AddData(inputData, InputRow("k3", "emitAllInState", "")),
         CheckNewAnswer(("k3", "v1"), ("k3", "v2"), ("k3", "v3"), ("k3", "v5")),
+        assertNumStateRows(total = 0, updated = 0),
+
         // check removal cleans up all data in state
         AddData(inputData, InputRow("k4", "append", "v2")),
-        AddData(inputData, InputRow("k4", "appendList", "v3,v4")),
+        AddData(inputData, InputRow("k4", "appendAll", "v3,v4")),
         AddData(inputData, InputRow("k4", "remove", "")),
         AddData(inputData, InputRow("k4", "emitAllInState", "")),
         CheckNewAnswer(),
+        assertNumStateRows(total = 0, updated = 3), // clearing state is a single update
+
         // check put cleans up previous state and adds new state
         AddData(inputData, InputRow("k5", "appendAll", "v1,v2,v3")),
         AddData(inputData, InputRow("k5", "append", "v4")),
         AddData(inputData, InputRow("k5", "put", "v5,v6")),
         AddData(inputData, InputRow("k5", "emitAllInState", "")),
         CheckNewAnswer(("k5", "v5"), ("k5", "v6")),
+        assertNumStateRows(total = 0, updated = 2), // put resets the updated count
         Execute { q =>
           assert(q.lastProgress.stateOperators(0).customMetrics.get("numListStateVars") > 0)
           assert(q.lastProgress.stateOperators(0).numRowsUpdated === 2)
           assert(q.lastProgress.stateOperators(0).numRowsRemoved === 2)
-        }
+        },
+        StopStream
       )
     }
   }
@@ -419,9 +435,11 @@ class TransformWithListStateSuite extends StreamTest
         AddData(inputData, "k1"),
         AddData(inputData, "k2"),
         CheckNewAnswer(),
+        assertNumStateRows(total = 4, updated = 4),
         AddData(inputData, "k1"),
         AddData(inputData, "k2"),
-        CheckNewAnswer("k1", "k1", "k2", "k2")
+        CheckNewAnswer("k1", "k1", "k2", "k2"),
+        assertNumStateRows(total = 0, updated = 0)
       )
     }
   }
@@ -444,9 +462,11 @@ class TransformWithListStateSuite extends StreamTest
           // Write data with initial schema
           AddData(inputData, "item1", "item2"),
           CheckNewAnswer(("item1", 1), ("item2", 1)),
+          assertNumStateRows(total = 2, updated = 2),
           // Add more items to verify count increment
           AddData(inputData, "item1", "item3"),
           CheckNewAnswer(("item1", 2), ("item3", 1)),
+          assertNumStateRows(total = 3, updated = 2),
           StopStream
         )
 
@@ -465,6 +485,10 @@ class TransformWithListStateSuite extends StreamTest
             ("item1", "Migrated item item1 with count 1", 1),
             ("item1", "Migrated item item1 with count 2", 2),
             ("item1", "Updated item item1 with count 4", 4)),
+          // 3 listState total for keys item1, item2, item3
+          // For rows with key item1 we clear and readd 3 items (3 updates)
+          // rows with keys item2 and item3 are not migrated because they are not accessed
+          assertNumStateRows(total = 3, updated = 3),
           StopStream
         )
       }
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithListStateTTLSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithListStateTTLSuite.scala
index b6e7c659607..802535a3bb3 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithListStateTTLSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithListStateTTLSuite.scala
@@ -201,26 +201,32 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
         AddData(inputStream, "k1"),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(("k1", 1)),
+        assertNumStateRows(total = 3, updated = 3),
 
         AddData(inputStream, "k2"),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(("k2", 1)),
+        assertNumStateRows(total = 6, updated = 3),
 
         AddData(inputStream, "k1"),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(("k1", 2)),
+        assertNumStateRows(total = 7, updated = 3),
 
         AddData(inputStream, "k2"),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(("k2", 2)),
+        assertNumStateRows(total = 8, updated = 3),
 
         AddData(inputStream, "k1"),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(("k1", 3)),
+        assertNumStateRows(total = 9, updated = 3),
 
         AddData(inputStream, "k2"),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(("k2", 3)),
+        assertNumStateRows(total = 10, updated = 3)
 
         // For each unique key that occurs t times, the MultiStatefulVariableTTLProcessor maintains:
         //    - Map state: t records in the primary, and t records in the TTL index
@@ -238,7 +244,6 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
         // The number of updated rows is the total across the last time assertNumStateRows
         // was called, and we only update numRowsUpdated for primary key updates. We ran 6 batches
         // and each wrote 3 primary keys, so the total number of updated rows is 6 * 3 = 18.
-        assertNumStateRows(total = 10, updated = 18)
       )
     }
   }
@@ -267,6 +272,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
         ),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(),
+        assertNumStateRows(total = 1, updated = 3),
         // get ttl values
         AddData(inputStream, InputEvent("k1", "get_ttl_value_from_state", -1, null)),
         AdvanceManualClock(1 * 1000),
@@ -275,6 +281,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           OutputEvent("k1", 2, isTTLValue = true, 62000),
           OutputEvent("k1", 3, isTTLValue = true, 62000)
         ),
+        assertNumStateRows(total = 1, updated = 0),
         // advance clock to add elements with later TTL
         AdvanceManualClock(45 * 1000), // batch timestamp: 48000
         AddData(inputStream,
@@ -284,6 +291,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
         ),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(),
+        assertNumStateRows(total = 1, updated = 3),
         Execute { q =>
           assert(q.lastProgress.stateOperators(0).numRowsUpdated === 3)
         },
@@ -298,6 +306,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           OutputEvent("k1", 5, isTTLValue = true, 109000),
           OutputEvent("k1", 6, isTTLValue = true, 109000)
         ),
+        assertNumStateRows(total = 1, updated = 0),
         AddData(inputStream, InputEvent("k1", "get", -1, null)),
         // advance clock to expire the first three elements
         AdvanceManualClock(15 * 1000), // batch timestamp: 65000
@@ -306,6 +315,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           OutputEvent("k1", 5, isTTLValue = false, -1),
           OutputEvent("k1", 6, isTTLValue = false, -1)
         ),
+        assertNumStateRows(total = 1, updated = 0),
         Execute { q =>
           assert(q.lastProgress.stateOperators(0).numRowsRemoved === 3)
         },
@@ -317,11 +327,13 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           OutputEvent("k1", 5, isTTLValue = false, -1),
           OutputEvent("k1", 6, isTTLValue = false, -1)
         ),
+        assertNumStateRows(total = 1, updated = 0),
         AddData(inputStream, InputEvent("k1", "get_values_in_ttl_state", -1, null)),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(
           OutputEvent("k1", -1, isTTLValue = true, 109000)
-        )
+        ),
+        assertNumStateRows(total = 1, updated = 0)
       )
     }
   }
@@ -361,6 +373,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           // advance clock to trigger processing
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(),
+          assertNumStateRows(total = 1, updated = 3),
 
           // get ttl values
           AddData(inputStream, InputEvent("k1", "get_ttl_value_from_state", -1, null)),
@@ -370,6 +383,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 2, isTTLValue = true, 182000),
             OutputEvent("k1", 3, isTTLValue = true, 182000)
           ),
+          assertNumStateRows(total = 1, updated = 0),
 
           AddData(inputStream, InputEvent("k1", "get", -1, null)),
           AdvanceManualClock(1 * 1000),
@@ -378,6 +392,8 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 2, isTTLValue = false, -1),
             OutputEvent("k1", 3, isTTLValue = false, -1)
           ),
+          assertNumStateRows(total = 1, updated = 0),
+
           StopStream
         )
 
@@ -402,6 +418,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           // advance clock to trigger processing
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(),
+          assertNumStateRows(total = 1, updated = 3),
 
           // get all elements without enforcing ttl
           AddData(inputStream, InputEvent("k1", "get_without_enforcing_ttl", -1, null)),
@@ -414,6 +431,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 5, isTTLValue = false, -1),
             OutputEvent("k1", 6, isTTLValue = false, -1)
           ),
+          assertNumStateRows(total = 1, updated = 0),
 
           AddData(inputStream, InputEvent("k1", "get_ttl_value_from_state", -1, null)),
           AdvanceManualClock(1 * 1000),
@@ -425,6 +443,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 5, isTTLValue = true, 20000),
             OutputEvent("k1", 6, isTTLValue = true, 20000)
           ),
+          assertNumStateRows(total = 1, updated = 0),
           StopStream
         )
 
@@ -439,6 +458,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           // advance clock to trigger processing
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(),
+          assertNumStateRows(total = 1, updated = 3),
 
           // advance clock to expire the middle three elements
           AddData(inputStream, InputEvent("k1", "get_values_in_ttl_state", -1, null)),
@@ -446,6 +466,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           CheckNewAnswer(
             OutputEvent("k1", -1, isTTLValue = true, 20000)
           ),
+          assertNumStateRows(total = 1, updated = 0),
 
           // progress batch timestamp from 9000 to 54000, expiring the middle
           // three elements.
@@ -461,6 +482,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 8, isTTLValue = false, -1),
             OutputEvent("k1", 9, isTTLValue = false, -1)
           ),
+          assertNumStateRows(total = 1, updated = 0),
 
           AddData(inputStream, InputEvent("k1", "get_without_enforcing_ttl", -1, null)),
           AdvanceManualClock(1 * 1000),
@@ -472,6 +494,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 8, isTTLValue = false, -1),
             OutputEvent("k1", 9, isTTLValue = false, -1)
           ),
+          assertNumStateRows(total = 1, updated = 0),
 
           AddData(inputStream, InputEvent("k1", "get_values_in_ttl_state", -1, null)),
           AdvanceManualClock(1 * 1000),
@@ -516,14 +539,17 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           AddData(inputStream, InputEvent("k1", "append", 1)),
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(),
+          assertNumStateRows(total = 1, updated = 1),
 
           AddData(inputStream, InputEvent("k1", "append", 2)),
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(),
+          assertNumStateRows(total = 1, updated = 1),
 
           AddData(inputStream, InputEvent("k1", "append", 3)),
           AdvanceManualClock(1 * 1000), // Time is 3000
           CheckNewAnswer(),
+          assertNumStateRows(total = 1, updated = 1),
 
           // Add a separate key; this should not be affected by k1 expiring.
           // It will have an expiration of 64000.
@@ -537,12 +563,14 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 2, isTTLValue = true, 62000),
             OutputEvent("k1", 3, isTTLValue = true, 63000)
           ),
+          assertNumStateRows(total = 2, updated = 1),
 
           AddData(inputStream, InputEvent("k1", "get_values_in_min_state", -1, null)),
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer( // Time is 5000 for this micro-batch
             OutputEvent("k1", -1, isTTLValue = true, 61000)
           ),
+          assertNumStateRows(total = 2, updated = 0),
 
           // The k1 records expire at 63000, and the current time is 5000. So, we advance the
           // clock by 63 - 5 = 58 seconds to expire those.
@@ -554,7 +582,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           //
           // It's important to check with assertNumStateRows, since the InputEvents
           // only return values for the current grouping key, not the entirety of RocksDB.
-          assertNumStateRows(total = 1, updated = 4),
+          assertNumStateRows(total = 1, updated = 0),
 
           // The k1 calls should both return no values. However, the k2 calls should return
           // one record each. We put these into one AddData call since we want them all to
@@ -619,6 +647,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           // advance clock to trigger processing
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(),
+          assertNumStateRows(total = 1, updated = 3),
 
           // get ttl values
           AddData(inputStream,
@@ -635,6 +664,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             // From the get_values_in_min_state call
             OutputEvent("k1", -1, isTTLValue = true, 121000)
           ),
+          assertNumStateRows(total = 1, updated = 0),
 
           AddData(inputStream, InputEvent("k1", "get", -1, null)),
           AdvanceManualClock(1 * 1000),
@@ -643,6 +673,8 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 2, isTTLValue = false, -1),
             OutputEvent("k1", 3, isTTLValue = false, -1)
           ),
+          assertNumStateRows(total = 1, updated = 0),
+
           StopStream
         )
 
@@ -658,6 +690,7 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
           // advance clock to trigger processing
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(),
+          assertNumStateRows(total = 1, updated = 3),
 
           // get ttl values
           AddData(inputStream, InputEvent("k1", "get_ttl_value_from_state", -1, null)),
@@ -670,12 +703,15 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 5, isTTLValue = true, 65000),
             OutputEvent("k1", 6, isTTLValue = true, 65000)
           ),
+          assertNumStateRows(total = 1, updated = 0),
+
           AddData(inputStream, InputEvent("k1", "get_values_in_ttl_state", -1, null)),
           AdvanceManualClock(1 * 1000),
-
           CheckNewAnswer(
             OutputEvent("k1", -1, isTTLValue = true, 65000)
           ),
+          assertNumStateRows(total = 1, updated = 0),
+
           // expire end values, batch timestamp from 7000 to 67000
           AdvanceManualClock(60 * 1000),
           AddData(inputStream, InputEvent("k1", "get", -1, null)),
@@ -685,6 +721,8 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 2, isTTLValue = false, -1),
             OutputEvent("k1", 3, isTTLValue = false, -1)
           ),
+          assertNumStateRows(total = 1, updated = 0),
+
           AddData(inputStream, InputEvent("k1", "get_without_enforcing_ttl", -1, null)),
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(
@@ -692,14 +730,61 @@ class TransformWithListStateTTLSuite extends TransformWithStateTTLTest
             OutputEvent("k1", 2, isTTLValue = false, -1),
             OutputEvent("k1", 3, isTTLValue = false, -1)
           ),
+          assertNumStateRows(total = 1, updated = 0),
+
           AddData(inputStream, InputEvent("k1", "get_values_in_ttl_state", -1, null)),
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(
             OutputEvent("k1", -1, isTTLValue = true, 121000)
           ),
+          assertNumStateRows(total = 1, updated = 0),
+
           StopStream
         )
       }
     }
   }
+
+  test("SPARK-53069: stopping and restarting the query maintains correct state total rows") {
+    withSQLConf(SQLConf.STATE_STORE_PROVIDER_CLASS.key ->
+      classOf[RocksDBStateStoreProvider].getName,
+      SQLConf.SHUFFLE_PARTITIONS.key -> "1") {
+      val ttlConfig = TTLConfig(ttlDuration = Duration.ofMinutes(10))
+      val inputStream = MemoryStream[String]
+      val result = inputStream.toDS()
+        .groupByKey(x => x)
+        .transformWithState(
+          new MultiStatefulVariableTTLProcessor(ttlConfig),
+          TimeMode.ProcessingTime(),
+          OutputMode.Append())
+      val clock = new StreamManualClock
+
+      testStream(result)(
+        StartStream(Trigger.ProcessingTime("1 second"), triggerClock = clock),
+
+        AddData(inputStream, "k1"),
+        AdvanceManualClock(1 * 1000),
+        CheckNewAnswer(("k1", 1)),
+        assertNumStateRows(total = 3, updated = 3),
+
+        StopStream,
+        StartStream(Trigger.ProcessingTime("1 second"), triggerClock = clock),
+
+        AddData(inputStream, "k1"),
+        AdvanceManualClock(1 * 1000),
+        CheckNewAnswer(("k1", 2)),
+        assertNumStateRows(total = 4, updated = 3),
+
+        StopStream,
+        StartStream(Trigger.ProcessingTime("1 second"), triggerClock = clock),
+
+        AddData(inputStream, "k1"),
+        AdvanceManualClock(1 * 1000),
+        CheckNewAnswer(("k1", 3)),
+        assertNumStateRows(total = 5, updated = 3),
+
+        StopStream
+      )
+    }
+  }
 }
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithMapStateSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithMapStateSuite.scala
index 62effb8d7d1..70ab969975d 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithMapStateSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithMapStateSuite.scala
@@ -142,7 +142,8 @@ class EvolvedMapStateProcessor extends StatefulProcessor[String, String, (String
 @SlowSQLTest
 class TransformWithMapStateSuite extends StreamTest
   with AlsoTestWithEncodingTypes
-  with AlsoTestWithRocksDBFeatures {
+  with AlsoTestWithRocksDBFeatures
+  with StateStoreMetricsTest {
   import testImplicits._
 
   private def testMapStateWithNullUserKey(inputMapRow: InputMapRow): Unit = {
@@ -184,7 +185,8 @@ class TransformWithMapStateSuite extends StreamTest
 
       testStream(result, OutputMode.Update())(
         AddData(inputData, InputMapRow("k1", "getValue", ("v1", ""))),
-        CheckAnswer(("k1", "v1", null))
+        CheckAnswer(("k1", "v1", null)),
+        assertNumStateRows(total = 0, updated = 0)
       )
     }
   }
@@ -234,6 +236,7 @@ class TransformWithMapStateSuite extends StreamTest
         AddData(inputData, InputMapRow("k1", "exists", ("", ""))),
         AddData(inputData, InputMapRow("k2", "exists", ("", ""))),
         CheckNewAnswer(("k1", "exists", "true"), ("k2", "exists", "false")),
+        assertNumStateRows(total = 1, updated = 1),
 
         // Test get and put with composite key
         AddData(inputData, InputMapRow("k1", "updateValue", ("v2", "5"))),
@@ -245,32 +248,42 @@ class TransformWithMapStateSuite extends StreamTest
         // Different grouping key, same user key
         AddData(inputData, InputMapRow("k1", "getValue", ("v2", ""))),
         CheckNewAnswer(("k1", "v2", "5")),
+        assertNumStateRows(total = 4, updated = 4), // new state store row for each (k, v) pair
+
         // Same grouping key, same user key, update value should reflect
         AddData(inputData, InputMapRow("k2", "getValue", ("v2", ""))),
         CheckNewAnswer(("k2", "v2", "12")),
+        assertNumStateRows(total = 4, updated = 0),
 
         // Test get full map for a given grouping key - prefixScan
         AddData(inputData, InputMapRow("k2", "iterator", ("", ""))),
         CheckNewAnswer(("k2", "v2", "12"), ("k2", "v4", "1")),
+        assertNumStateRows(total = 4, updated = 0),
 
         AddData(inputData, InputMapRow("k2", "keys", ("", ""))),
         CheckNewAnswer(("k2", "v2", ""), ("k2", "v4", "")),
+        assertNumStateRows(total = 4, updated = 0),
 
         AddData(inputData, InputMapRow("k2", "values", ("", ""))),
         CheckNewAnswer(("k2", "", "12"), ("k2", "", "1")),
+        assertNumStateRows(total = 4, updated = 0),
 
         // Test remove functionalities
         AddData(inputData, InputMapRow("k1", "removeKey", ("v2", ""))),
         AddData(inputData, InputMapRow("k1", "containsKey", ("v2", ""))),
         CheckNewAnswer(("k1", "v2", "false")),
+        assertNumStateRows(total = 3, updated = 0), // remove does not count as update
 
         AddData(inputData, InputMapRow("k2", "clear", ("", ""))),
         AddData(inputData, InputMapRow("k2", "iterator", ("", ""))),
         CheckNewAnswer(),
+        assertNumStateRows(total = 1, updated = 0),
+
         AddData(inputData, InputMapRow("k2", "exists", ("", ""))),
         AddData(inputData, InputMapRow("k1", "clear", ("", ""))),
         AddData(inputData, InputMapRow("k3", "updateValue", ("v7", "11"))),
         CheckNewAnswer(("k2", "exists", "false")),
+        assertNumStateRows(total = 1, updated = 1),
         Execute { q =>
           assert(q.lastProgress.stateOperators(0).customMetrics.get("numMapStateVars") > 0)
           assert(q.lastProgress.stateOperators(0).numRowsUpdated === 1)
@@ -311,8 +324,10 @@ class TransformWithMapStateSuite extends StreamTest
           StartStream(checkpointLocation = dir.getCanonicalPath),
           AddData(inputData, "a", "b"),
           CheckNewAnswer(("a", "a", 1), ("b", "b", 1)),
+          assertNumStateRows(total = 2, updated = 2),
           AddData(inputData, "a"),
           CheckNewAnswer(("a", "a", 2)),
+          assertNumStateRows(total = 2, updated = 1),
           StopStream
         )
 
@@ -327,9 +342,11 @@ class TransformWithMapStateSuite extends StreamTest
           StartStream(checkpointLocation = dir.getCanonicalPath),
           AddData(inputData, "c"),
           CheckNewAnswer(("c", "c", 1)),
+          assertNumStateRows(total = 3, updated = 1),
           // Verify we can still read old state format
           AddData(inputData, "a"),
           CheckNewAnswer(("a", "a", 3)), // Count should continue from previous state
+          assertNumStateRows(total = 3, updated = 1),
           StopStream
         )
       }
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithMapStateTTLSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithMapStateTTLSuite.scala
index ef2e4f5a919..a94deaf23b2 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithMapStateTTLSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithMapStateTTLSuite.scala
@@ -205,12 +205,18 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
         AddData(inputStream, MapInputEvent("k1", "key1", "put", 1)),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(),
+        assertNumStateRows(total = 1, updated = 1),
+
         AddData(inputStream, MapInputEvent("k1", "key1", "get", -1)),
         AdvanceManualClock(30 * 1000),
         CheckNewAnswer(MapOutputEvent("k1", "key1", 1, isTTLValue = false, -1)),
+        assertNumStateRows(total = 1, updated = 0),
+
         AddData(inputStream, MapInputEvent("k1", "key2", "put", 2)),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(),
+        assertNumStateRows(total = 2, updated = 1),
+
         Execute { q =>
           assert(q.lastProgress.stateOperators(0).numRowsUpdated === 1)
         },
@@ -219,6 +225,7 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
         // advance clock to expire first key
         AdvanceManualClock(30 * 1000),
         CheckNewAnswer(MapOutputEvent("k1", "key2", 2, isTTLValue = false, -1)),
+        assertNumStateRows(total = 1, updated = 0),
         Execute { q =>
           assert(q.lastProgress.stateOperators(0).numRowsRemoved === 1)
         },
@@ -250,6 +257,8 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
         ),
         AdvanceManualClock(1 * 1000), // batch timestamp: 1000
         CheckNewAnswer(),
+        assertNumStateRows(total = 2, updated = 2),
+
         AddData(inputStream,
           MapInputEvent("k1", "key1", "get", -1),
           MapInputEvent("k1", "key2", "get", -1)
@@ -259,6 +268,8 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
           MapOutputEvent("k1", "key1", 1, isTTLValue = false, -1),
           MapOutputEvent("k1", "key2", 2, isTTLValue = false, -1)
         ),
+        assertNumStateRows(total = 2, updated = 0),
+
         // get values from ttl state
         AddData(inputStream,
           MapInputEvent("k1", "", "get_values_in_ttl_state", -1)
@@ -268,6 +279,8 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
           MapOutputEvent("k1", "key1", -1, isTTLValue = true, 61000),
           MapOutputEvent("k1", "key2", -1, isTTLValue = true, 61000)
         ),
+        assertNumStateRows(total = 2, updated = 0),
+
         // advance clock to expire first two values
         AdvanceManualClock(30 * 1000), // batch timestamp: 62000
         AddData(inputStream,
@@ -282,6 +295,8 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
           MapOutputEvent("k1", "key4", 4, isTTLValue = false, -1),
           MapOutputEvent("k1", "key5", 5, isTTLValue = false, -1)
         ),
+        assertNumStateRows(total = 3, updated = 3),
+
         AddData(inputStream,
           MapInputEvent("k1", "", "get_values_in_ttl_state", -1)
         ),
@@ -291,6 +306,8 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
           MapOutputEvent("k1", "key4", -1, isTTLValue = true, 123000),
           MapOutputEvent("k1", "key5", -1, isTTLValue = true, 123000)
         ),
+        assertNumStateRows(total = 3, updated = 0),
+
         // get all values without enforcing ttl
         AddData(inputStream,
           MapInputEvent("k1", "key1", "get_without_enforcing_ttl", -1),
@@ -305,6 +322,8 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
           MapOutputEvent("k1", "key4", 4, isTTLValue = false, -1),
           MapOutputEvent("k1", "key5", 5, isTTLValue = false, -1)
         ),
+        assertNumStateRows(total = 3, updated = 0),
+
         // check that updating a key updates its TTL
         AddData(inputStream, MapInputEvent("k1", "key3", "put", 3)),
         AdvanceManualClock(1 * 1000),
@@ -315,11 +334,15 @@ class TransformWithMapStateTTLSuite extends TransformWithStateTTLTest {
           MapOutputEvent("k1", "key4", -1, isTTLValue = true, 123000),
           MapOutputEvent("k1", "key5", -1, isTTLValue = true, 123000)
         ),
+        assertNumStateRows(total = 3, updated = 1),
+
         AddData(inputStream, MapInputEvent("k1", "key3", "get_ttl_value_from_state", -1)),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(
           MapOutputEvent("k1", "key3", 3, isTTLValue = true, 126000)
         ),
+        assertNumStateRows(total = 3, updated = 0),
+
         StopStream
       )
     }
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithStateTTLTest.scala b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithStateTTLTest.scala
index 18e1626b3cd..a499ca3f25b 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithStateTTLTest.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithStateTTLTest.scala
@@ -42,7 +42,8 @@ case class OutputEvent(
  */
 abstract class TransformWithStateTTLTest
   extends StreamTest with AlsoTestWithEncodingTypes
-  with AlsoTestWithRocksDBFeatures {
+  with AlsoTestWithRocksDBFeatures
+  with StateStoreMetricsTest {
   import testImplicits._
 
   def getProcessor(ttlConfig: TTLConfig): StatefulProcessor[String, InputEvent, OutputEvent]
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithValueStateTTLSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithValueStateTTLSuite.scala
index 3070de83b67..b01cb67a6b7 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithValueStateTTLSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/streaming/TransformWithValueStateTTLSuite.scala
@@ -220,6 +220,8 @@ class TransformWithValueStateTTLSuite extends TransformWithStateTTLTest {
         // advance clock to trigger processing
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(),
+        assertNumStateRows(total = 2, updated = 2),
+
         // get both state values, and make sure we get unexpired value
         AddData(inputStream, InputEvent(ttlKey, "get", -1)),
         AddData(inputStream, InputEvent(noTtlKey, "get", -1)),
@@ -228,15 +230,21 @@ class TransformWithValueStateTTLSuite extends TransformWithStateTTLTest {
           OutputEvent(ttlKey, 1, isTTLValue = false, -1),
           OutputEvent(noTtlKey, 2, isTTLValue = false, -1)
         ),
+        assertNumStateRows(total = 2, updated = 0),
+
         // ensure ttl values were added correctly, and noTtlKey has no ttl values
         AddData(inputStream, InputEvent(ttlKey, "get_ttl_value_from_state", -1)),
         AddData(inputStream, InputEvent(noTtlKey, "get_ttl_value_from_state", -1)),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(OutputEvent(ttlKey, 1, isTTLValue = true, 61000)),
+        assertNumStateRows(total = 2, updated = 0),
+
         AddData(inputStream, InputEvent(ttlKey, "get_values_in_ttl_state", -1)),
         AddData(inputStream, InputEvent(noTtlKey, "get_values_in_ttl_state", -1)),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(OutputEvent(ttlKey, -1, isTTLValue = true, 61000)),
+        assertNumStateRows(total = 2, updated = 0),
+
         // advance clock after expiry
         AdvanceManualClock(60 * 1000),
         AddData(inputStream, InputEvent(ttlKey, "get", -1)),
@@ -245,19 +253,27 @@ class TransformWithValueStateTTLSuite extends TransformWithStateTTLTest {
         AdvanceManualClock(1 * 1000),
         // validate ttlKey is expired, bot noTtlKey is still present
         CheckNewAnswer(OutputEvent(noTtlKey, 2, isTTLValue = false, -1)),
+        assertNumStateRows(total = 1, updated = 0),
+
         // validate ttl value is removed in the value state column family
         AddData(inputStream, InputEvent(ttlKey, "get_ttl_value_from_state", -1)),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(),
+        assertNumStateRows(total = 1, updated = 0),
+
         AddData(inputStream, InputEvent(ttlKey, "put", 3)),
         AdvanceManualClock(1 * 1000),
         CheckNewAnswer(),
+        assertNumStateRows(total = 2, updated = 1),
+
         Execute { q =>
           assert(q.lastProgress.stateOperators(0).numRowsUpdated === 1)
         },
         AddData(inputStream, InputEvent(noTtlKey, "get", -1)),
         AdvanceManualClock(60 * 1000),
         CheckNewAnswer(OutputEvent(noTtlKey, 2, isTTLValue = false, -1)),
+        assertNumStateRows(total = 1, updated = 0),
+
         Execute { q =>
           assert(q.lastProgress.stateOperators(0).numRowsRemoved === 1)
         }
@@ -471,6 +487,7 @@ class TransformWithValueStateTTLSuite extends TransformWithStateTTLTest {
           AddData(inputStream, InputEvent(noTtlKey, "put", 2)),
           AdvanceManualClock(1 * 1000),
           CheckNewAnswer(),
+          assertNumStateRows(total = 2, updated = 2),
           Execute { q =>
             val schemaFilePath = fm.list(stateSchemaPath).toSeq.head.getPath
             val providerId = StateStoreProviderId(
