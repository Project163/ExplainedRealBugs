diff --git a/sql/connect/client/jvm/src/test/scala/org/apache/spark/sql/DataFrameTableValuedFunctionsSuite.scala b/sql/connect/client/jvm/src/test/scala/org/apache/spark/sql/DataFrameTableValuedFunctionsSuite.scala
index d11f276e8ed..e619279940d 100644
--- a/sql/connect/client/jvm/src/test/scala/org/apache/spark/sql/DataFrameTableValuedFunctionsSuite.scala
+++ b/sql/connect/client/jvm/src/test/scala/org/apache/spark/sql/DataFrameTableValuedFunctionsSuite.scala
@@ -523,4 +523,22 @@ class DataFrameTableValuedFunctionsSuite extends QueryTest with RemoteSparkSessi
         sql("SELECT t1.id, t.* FROM variant_table AS t1, LATERAL variant_explode_outer(v) AS t"))
     }
   }
+
+  test("explode with udf") {
+    Seq("NO_CODEGEN", "CODEGEN_ONLY").foreach { codegenMode =>
+      withSQLConf("spark.sql.codegen.factoryMode" -> codegenMode) {
+        sql(
+          """create or replace temporary function spark_func (params array<struct<x int, y int>>)
+            | returns STRUCT<a: int, b: int> LANGUAGE SQL
+            | return (select ns from (
+            | SELECT try_divide(SUM(item.x * item.y), SUM(item.x * item.x)) AS beta1,
+            | NAMED_STRUCT('a', beta1,'b', beta1) ns
+            | FROM (SELECT params) LATERAL VIEW EXPLODE(params) AS item LIMIT 1));""".stripMargin)
+        val expected = Seq(Row(Row(1, 1)))
+        val actual =
+          sql("""select spark_func(collect_list(NAMED_STRUCT('x', 1, 'y', 1))) as result;""")
+        checkAnswer(actual, expected)
+      }
+    }
+  }
 }
diff --git a/sql/core/src/main/scala/org/apache/spark/sql/execution/GenerateExec.scala b/sql/core/src/main/scala/org/apache/spark/sql/execution/GenerateExec.scala
index d6a46d47c10..b5a9d38042d 100644
--- a/sql/core/src/main/scala/org/apache/spark/sql/execution/GenerateExec.scala
+++ b/sql/core/src/main/scala/org/apache/spark/sql/execution/GenerateExec.scala
@@ -86,12 +86,16 @@ case class GenerateExec(
       val generatorNullRow = new GenericInternalRow(generator.elementSchema.length)
       val rows = if (requiredChildOutput.nonEmpty) {
 
-        val pruneChildForResult: InternalRow => InternalRow =
-          if (child.outputSet == AttributeSet(requiredChildOutput)) {
+        val pruneChildForResult: InternalRow => InternalRow = {
+          // The declared output of this operator is `requiredChildOutput ++ generatorOutput`.
+          // If `child.output` is different from `requiredChildOutput`, we must do an projection
+          // to adjust the child output and make sure the final result matches the declared output.
+          if (child.output == requiredChildOutput) {
             identity
           } else {
             UnsafeProjection.create(requiredChildOutput, child.output)
           }
+        }
 
         val joinedRow = new JoinedRow
         iter.flatMap { row =>
@@ -142,10 +146,8 @@ case class GenerateExec(
   override def needCopyResult: Boolean = true
 
   override def doConsume(ctx: CodegenContext, input: Seq[ExprCode], row: ExprCode): String = {
-    val requiredAttrSet = AttributeSet(requiredChildOutput)
-    val requiredInput = child.output.zip(input).filter {
-      case (attr, _) => requiredAttrSet.contains(attr)
-    }.map(_._2)
+    val attrToInputCode = AttributeMap(child.output.zip(input))
+    val requiredInput = requiredChildOutput.map(attrToInputCode)
     boundGenerator match {
       case e: CollectionGenerator => codeGenCollection(ctx, e, requiredInput)
       case g => codeGenIterableOnce(ctx, g, requiredInput)
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/DataFrameTableValuedFunctionsSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/DataFrameTableValuedFunctionsSuite.scala
index 637e0cf964f..ad7c297c6f9 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/DataFrameTableValuedFunctionsSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/DataFrameTableValuedFunctionsSuite.scala
@@ -18,6 +18,7 @@
 package org.apache.spark.sql
 
 import org.apache.spark.sql.functions._
+import org.apache.spark.sql.internal.SQLConf
 import org.apache.spark.sql.test.SharedSparkSession
 
 class DataFrameTableValuedFunctionsSuite extends QueryTest with SharedSparkSession {
@@ -526,4 +527,21 @@ class DataFrameTableValuedFunctionsSuite extends QueryTest with SharedSparkSessi
       )
     }
   }
+
+  test("explode with udf") {
+    Seq("NO_CODEGEN", "CODEGEN_ONLY").foreach { codegenMode =>
+      withSQLConf(SQLConf.CODEGEN_FACTORY_MODE.key -> codegenMode)  {
+        sql("""create or replace temporary function spark_func (params array<struct<x int, y int>>)
+            | returns STRUCT<a: int, b: int> LANGUAGE SQL
+            | return (select ns from (
+            | SELECT try_divide(SUM(item.x * item.y), SUM(item.x * item.x)) AS beta1,
+            | NAMED_STRUCT('a', beta1,'b', beta1) ns
+            | FROM (SELECT params) LATERAL VIEW EXPLODE(params) AS item LIMIT 1));""".stripMargin)
+        val expected = Seq(Row(Row(1, 1)))
+        val actual =
+          sql("""select spark_func(collect_list(NAMED_STRUCT('x', 1, 'y', 1))) as result;""")
+        checkAnswer(actual, expected)
+      }
+    }
+  }
 }
