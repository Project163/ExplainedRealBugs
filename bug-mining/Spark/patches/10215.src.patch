diff --git a/python/pyspark/sql/conversion.py b/python/pyspark/sql/conversion.py
index 349d9aacd07..20e27c5c044 100644
--- a/python/pyspark/sql/conversion.py
+++ b/python/pyspark/sql/conversion.py
@@ -348,26 +348,29 @@ class LocalDataToArrowConversion:
 
         rows = [to_row(item) for item in data]
 
-        column_convs = [
-            LocalDataToArrowConversion._create_converter(field.dataType, field.nullable)
-            for field in schema.fields
-        ]
-
-        pylist = [[conv(row[i]) for row in rows] for i, conv in enumerate(column_convs)]
-
-        pa_schema = to_arrow_schema(
-            StructType(
-                [
-                    StructField(
-                        field.name, _deduplicate_field_names(field.dataType), field.nullable
-                    )
-                    for field in schema.fields
-                ]
-            ),
-            prefers_large_types=use_large_var_types,
-        )
+        if len_column_names > 0:
+            column_convs = [
+                LocalDataToArrowConversion._create_converter(field.dataType, field.nullable)
+                for field in schema.fields
+            ]
+
+            pylist = [[conv(row[i]) for row in rows] for i, conv in enumerate(column_convs)]
 
-        return pa.Table.from_arrays(pylist, schema=pa_schema)
+            pa_schema = to_arrow_schema(
+                StructType(
+                    [
+                        StructField(
+                            field.name, _deduplicate_field_names(field.dataType), field.nullable
+                        )
+                        for field in schema.fields
+                    ]
+                ),
+                prefers_large_types=use_large_var_types,
+            )
+
+            return pa.Table.from_arrays(pylist, schema=pa_schema)
+        else:
+            return pa.table({"_": [None] * len(rows)}).drop("_")
 
 
 class ArrowTableToRowsConversion:
diff --git a/python/pyspark/sql/tests/test_creation.py b/python/pyspark/sql/tests/test_creation.py
index 0045deb7638..8936e275449 100644
--- a/python/pyspark/sql/tests/test_creation.py
+++ b/python/pyspark/sql/tests/test_creation.py
@@ -35,6 +35,7 @@ from pyspark.errors import (
     PySparkTypeError,
     PySparkValueError,
 )
+from pyspark.testing import assertDataFrameEqual
 from pyspark.testing.sqlutils import (
     ReusedSQLTestCase,
     have_pandas,
@@ -228,6 +229,13 @@ class DataFrameCreationTestsMixin:
                 [Row(str_col="second", dict_col={"first": 0.7, "second": 0.3}, test=0.3)],
             )
 
+    def test_empty_schema(self):
+        schema = StructType()
+        for data in [[], [Row()]]:
+            with self.subTest(data=data):
+                sdf = self.spark.createDataFrame(data, schema)
+                assertDataFrameEqual(sdf, data)
+
 
 class DataFrameCreationTests(
     DataFrameCreationTestsMixin,
