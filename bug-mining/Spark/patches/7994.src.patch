diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAggregates.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAggregates.scala
index a2f23acea92..bf17791fdd0 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAggregates.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAggregates.scala
@@ -53,7 +53,7 @@ object RemoveRedundantAggregates extends Rule[LogicalPlan] with AliasHelper {
     val upperHasNoDuplicateSensitiveAgg = upper
       .aggregateExpressions
       .forall(expr => expr.find {
-        case ae: AggregateExpression => !EliminateDistinct.isDuplicateAgnostic(ae.aggregateFunction)
+        case ae: AggregateExpression => isDuplicateSensitive(ae)
         case e => AggregateExpression.isAggregate(e)
       }.isEmpty)
 
@@ -67,4 +67,8 @@ object RemoveRedundantAggregates extends Rule[LogicalPlan] with AliasHelper {
 
     upperHasNoDuplicateSensitiveAgg && upperRefsOnlyDeterministicNonAgg
   }
+
+  private def isDuplicateSensitive(ae: AggregateExpression): Boolean = {
+    !ae.isDistinct && !EliminateDistinct.isDuplicateAgnostic(ae.aggregateFunction)
+  }
 }
diff --git a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAggregatesSuite.scala b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAggregatesSuite.scala
index 7ca7c45aeab..d11ff16229b 100644
--- a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAggregatesSuite.scala
+++ b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/RemoveRedundantAggregatesSuite.scala
@@ -143,11 +143,11 @@ class RemoveRedundantAggregatesSuite extends PlanTest {
     val relation = LocalRelation('a.int, 'b.int)
     val query = relation
       .groupBy('a, 'b)('a, 'b)
-      // The max does not change if there are duplicate values
-      .groupBy('a)('a, max('b))
+      // The max and countDistinct does not change if there are duplicate values
+      .groupBy('a)('a, max('b), countDistinct('b))
       .analyze
     val expected = relation
-      .groupBy('a)('a, max('b))
+      .groupBy('a)('a, max('b), countDistinct('b))
       .analyze
     val optimized = Optimize.execute(query)
     comparePlans(optimized, expected)
