diff --git a/python/pyspark/sql/connect/plan.py b/python/pyspark/sql/connect/plan.py
index ebfe23d16d1..7a93580aa11 100644
--- a/python/pyspark/sql/connect/plan.py
+++ b/python/pyspark/sql/connect/plan.py
@@ -1182,7 +1182,7 @@ class SQL(LogicalPlan):
             elif not isinstance(args, List):
                 raise PySparkTypeError(
                     error_class="INVALID_TYPE",
-                    message_parameters={"arg_name": "args", "arg_type": str(type(args))},
+                    message_parameters={"arg_name": "args", "arg_type": type(args).__name__},
                 )
 
         self._query = query
diff --git a/python/pyspark/sql/session.py b/python/pyspark/sql/session.py
index 53c97b8d43f..f12a5365d86 100644
--- a/python/pyspark/sql/session.py
+++ b/python/pyspark/sql/session.py
@@ -1687,7 +1687,7 @@ class SparkSession(SparkConversionMixin):
             else:
                 raise PySparkTypeError(
                     error_class="INVALID_TYPE",
-                    message_parameters={"arg_name": "args", "arg_type": str(type(args))},
+                    message_parameters={"arg_name": "args", "arg_type": type(args).__name__},
                 )
             return DataFrame(self._jsparkSession.sql(sqlQuery, litArgs), self)
         finally:
diff --git a/python/pyspark/sql/tests/connect/test_connect_basic.py b/python/pyspark/sql/tests/connect/test_connect_basic.py
index 8aef2d8a852..cb7e286c537 100755
--- a/python/pyspark/sql/tests/connect/test_connect_basic.py
+++ b/python/pyspark/sql/tests/connect/test_connect_basic.py
@@ -1409,7 +1409,7 @@ class SparkConnectBasicTests(SparkConnectSQLTestCase):
             self.check_error(
                 exception=pe.exception,
                 error_class="INVALID_TYPE",
-                message_parameters={"arg_name": "args", "arg_type": "<class 'set'>"},
+                message_parameters={"arg_name": "args", "arg_type": "set"},
             )
 
     def test_head(self):
