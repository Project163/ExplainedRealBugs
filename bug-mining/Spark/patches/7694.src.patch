diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/CharVarcharUtils.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/CharVarcharUtils.scala
index 5fc070a1210..1480c88a9ae 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/CharVarcharUtils.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/CharVarcharUtils.scala
@@ -160,9 +160,10 @@ object CharVarcharUtils extends Logging {
   }
 
   private def paddingWithLengthCheck(expr: Expression, dt: DataType): Expression = dt match {
-    case CharType(length) => StringRPad(stringLengthCheck(expr, dt), Literal(length))
+    case CharType(length) =>
+      StringRPad(stringLengthCheck(expr, dt, needTrim = false), Literal(length))
 
-    case VarcharType(_) => stringLengthCheck(expr, dt)
+    case VarcharType(_) => stringLengthCheck(expr, dt, needTrim = false)
 
     case StructType(fields) =>
       val struct = CreateNamedStruct(fields.zipWithIndex.flatMap { case (f, i) =>
@@ -199,7 +200,7 @@ object CharVarcharUtils extends Logging {
    */
   def stringLengthCheck(expr: Expression, targetAttr: Attribute): Expression = {
     getRawType(targetAttr.metadata).map { rawType =>
-      stringLengthCheck(expr, rawType)
+      stringLengthCheck(expr, rawType, needTrim = true)
     }.getOrElse(expr)
   }
 
@@ -208,53 +209,60 @@ object CharVarcharUtils extends Logging {
     RaiseError(Literal(errMsg, StringType), StringType)
   }
 
-  private def stringLengthCheck(expr: Expression, dt: DataType): Expression = dt match {
-    case CharType(length) =>
-      val trimmed = StringTrimRight(expr)
-      // Trailing spaces do not count in the length check. We don't need to retain the trailing
-      // spaces, as we will pad char type columns/fields at read time.
-      If(
-        GreaterThan(Length(trimmed), Literal(length)),
-        raiseError("char", length),
-        trimmed)
-
-    case VarcharType(length) =>
-      val trimmed = StringTrimRight(expr)
-      // Trailing spaces do not count in the length check. We need to retain the trailing spaces
-      // (truncate to length N), as there is no read-time padding for varchar type.
-      // TODO: create a special TrimRight function that can trim to a certain length.
-      If(
-        LessThanOrEqual(Length(expr), Literal(length)),
-        expr,
+  private def stringLengthCheck(expr: Expression, dt: DataType, needTrim: Boolean): Expression = {
+    dt match {
+      case CharType(length) =>
+        val trimmed = if (needTrim) StringTrimRight(expr) else expr
+        // Trailing spaces do not count in the length check. We don't need to retain the trailing
+        // spaces, as we will pad char type columns/fields at read time.
         If(
           GreaterThan(Length(trimmed), Literal(length)),
-          raiseError("varchar", length),
-          StringRPad(trimmed, Literal(length))))
+          raiseError("char", length),
+          trimmed)
+
+      case VarcharType(length) =>
+        if (needTrim) {
+          val trimmed = StringTrimRight(expr)
+          // Trailing spaces do not count in the length check. We need to retain the trailing spaces
+          // (truncate to length N), as there is no read-time padding for varchar type.
+          // TODO: create a special TrimRight function that can trim to a certain length.
+          If(
+            LessThanOrEqual(Length(expr), Literal(length)),
+            expr,
+            If(
+              GreaterThan(Length(trimmed), Literal(length)),
+              raiseError("varchar", length),
+              StringRPad(trimmed, Literal(length))))
+        } else {
+          If(GreaterThan(Length(expr), Literal(length)), raiseError("varchar", length), expr)
+        }
 
-    case StructType(fields) =>
-      val struct = CreateNamedStruct(fields.zipWithIndex.flatMap { case (f, i) =>
-        Seq(Literal(f.name), stringLengthCheck(GetStructField(expr, i, Some(f.name)), f.dataType))
-      })
-      if (expr.nullable) {
-        If(IsNull(expr), Literal(null, struct.dataType), struct)
-      } else {
-        struct
-      }
+      case StructType(fields) =>
+        val struct = CreateNamedStruct(fields.zipWithIndex.flatMap { case (f, i) =>
+          Seq(Literal(f.name),
+            stringLengthCheck(GetStructField(expr, i, Some(f.name)), f.dataType, needTrim))
+        })
+        if (expr.nullable) {
+          If(IsNull(expr), Literal(null, struct.dataType), struct)
+        } else {
+          struct
+        }
 
-    case ArrayType(et, containsNull) => stringLengthCheckInArray(expr, et, containsNull)
+      case ArrayType(et, containsNull) => stringLengthCheckInArray(expr, et, containsNull, needTrim)
 
-    case MapType(kt, vt, valueContainsNull) =>
-      val newKeys = stringLengthCheckInArray(MapKeys(expr), kt, containsNull = false)
-      val newValues = stringLengthCheckInArray(MapValues(expr), vt, valueContainsNull)
-      MapFromArrays(newKeys, newValues)
+      case MapType(kt, vt, valueContainsNull) =>
+        val newKeys = stringLengthCheckInArray(MapKeys(expr), kt, containsNull = false, needTrim)
+        val newValues = stringLengthCheckInArray(MapValues(expr), vt, valueContainsNull, needTrim)
+        MapFromArrays(newKeys, newValues)
 
-    case _ => expr
+      case _ => expr
+    }
   }
 
   private def stringLengthCheckInArray(
-      arr: Expression, et: DataType, containsNull: Boolean): Expression = {
+      arr: Expression, et: DataType, containsNull: Boolean, needTrim: Boolean): Expression = {
     val param = NamedLambdaVariable("x", replaceCharVarcharWithString(et), containsNull)
-    val func = LambdaFunction(stringLengthCheck(param, et), Seq(param))
+    val func = LambdaFunction(stringLengthCheck(param, et, needTrim), Seq(param))
     ArrayTransform(arr, func)
   }
 
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/CharVarcharTestSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/CharVarcharTestSuite.scala
index fbf3f2ab0fa..048d5a7b4e6 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/CharVarcharTestSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/CharVarcharTestSuite.scala
@@ -472,6 +472,22 @@ trait CharVarcharTestSuite extends QueryTest with SQLTestUtils {
         Row(1))
     }
   }
+
+  test("SPARK-34114: varchar type will strip tailing spaces to certain length at write time") {
+    withTable("t") {
+      sql(s"CREATE TABLE t(v VARCHAR(3)) USING $format")
+      sql("INSERT INTO t VALUES ('c      ')")
+      checkAnswer(spark.table("t"), Row("c  "))
+    }
+  }
+
+  test("SPARK-34114: varchar type will remain the value length with spaces at read time") {
+    withTable("t") {
+      sql(s"CREATE TABLE t(v VARCHAR(3)) USING $format")
+      sql("INSERT INTO t VALUES ('c ')")
+      checkAnswer(spark.table("t"), Row("c "))
+    }
+  }
 }
 
 // Some basic char/varchar tests which doesn't rely on table implementation.
@@ -666,6 +682,19 @@ class FileSourceCharVarcharTestSuite extends CharVarcharTestSuite with SharedSpa
       assert(rest.contains("CHAR(5)"))
     }
   }
+
+  test("SPARK-34114: should not trim right for read-side length check and char padding") {
+    Seq("char", "varchar").foreach { typ =>
+      withTempPath { dir =>
+        withTable("t") {
+          sql("SELECT '12  ' as col").write.format(format).save(dir.toString)
+          sql(s"CREATE TABLE t (col $typ(2)) using $format LOCATION '$dir'")
+          val e = intercept[SparkException] { sql("select * from t").collect() }
+          assert(e.getCause.getMessage.contains(s"Exceeds $typ type length limitation: 2"))
+        }
+      }
+    }
+  }
 }
 
 class DSV2CharVarcharTestSuite extends CharVarcharTestSuite
