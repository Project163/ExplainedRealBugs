diff --git a/connector/connect/client/jvm/src/test/scala/org/apache/spark/sql/UserDefinedFunctionE2ETestSuite.scala b/connector/connect/client/jvm/src/test/scala/org/apache/spark/sql/UserDefinedFunctionE2ETestSuite.scala
index b5bbee67803..ca1bcf3fe67 100644
--- a/connector/connect/client/jvm/src/test/scala/org/apache/spark/sql/UserDefinedFunctionE2ETestSuite.scala
+++ b/connector/connect/client/jvm/src/test/scala/org/apache/spark/sql/UserDefinedFunctionE2ETestSuite.scala
@@ -198,18 +198,30 @@ class UserDefinedFunctionE2ETestSuite extends RemoteSparkSession {
     assert(sum.get() == 0) // The value is not 45
   }
 
-  test("Dataset reduce") {
+  test("Dataset reduce without null partition inputs") {
     val session: SparkSession = spark
     import session.implicits._
-    assert(spark.range(10).map(_ + 1).reduce(_ + _) == 55)
+    assert(spark.range(0, 10, 1, 5).map(_ + 1).reduce(_ + _) == 55)
   }
 
-  test("Dataset reduce - java") {
+  test("Dataset reduce with null partition inputs") {
+    val session: SparkSession = spark
+    import session.implicits._
+    assert(spark.range(0, 10, 1, 16).map(_ + 1).reduce(_ + _) == 55)
+  }
+
+  test("Dataset reduce with null partition inputs - java to scala long type") {
+    val session: SparkSession = spark
+    import session.implicits._
+    assert(spark.range(0, 5, 1, 10).as[Long].reduce(_ + _) == 10)
+  }
+
+  test("Dataset reduce with null partition inputs - java") {
     val session: SparkSession = spark
     import session.implicits._
     assert(
       spark
-        .range(10)
+        .range(0, 10, 1, 16)
         .map(_ + 1)
         .reduce(new ReduceFunction[Long] {
           override def call(v1: Long, v2: Long): Long = v1 + v2
diff --git a/sql/core/src/main/scala/org/apache/spark/sql/expressions/ReduceAggregator.scala b/sql/core/src/main/scala/org/apache/spark/sql/expressions/ReduceAggregator.scala
index 41306cd0a99..e897fdfe008 100644
--- a/sql/core/src/main/scala/org/apache/spark/sql/expressions/ReduceAggregator.scala
+++ b/sql/core/src/main/scala/org/apache/spark/sql/expressions/ReduceAggregator.scala
@@ -32,7 +32,18 @@ private[sql] class ReduceAggregator[T: Encoder](func: (T, T) => T)
 
   @transient private val encoder = implicitly[Encoder[T]]
 
-  override def zero: (Boolean, T) = (false, null.asInstanceOf[T])
+  private val _zero = encoder.clsTag.runtimeClass match {
+    case java.lang.Boolean.TYPE => false
+    case java.lang.Byte.TYPE => 0.toByte
+    case java.lang.Short.TYPE => 0.toShort
+    case java.lang.Integer.TYPE => 0
+    case java.lang.Long.TYPE => 0L
+    case java.lang.Float.TYPE => 0f
+    case java.lang.Double.TYPE => 0d
+    case _ => null
+  }
+
+  override def zero: (Boolean, T) = (false, _zero.asInstanceOf[T])
 
   override def bufferEncoder: Encoder[(Boolean, T)] =
     ExpressionEncoder.tuple(
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/expressions/ReduceAggregatorSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/expressions/ReduceAggregatorSuite.scala
index f65dcdf119c..c1071373287 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/expressions/ReduceAggregatorSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/expressions/ReduceAggregatorSuite.scala
@@ -24,10 +24,16 @@ import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder
 class ReduceAggregatorSuite extends SparkFunSuite {
 
   test("zero value") {
-    val encoder: ExpressionEncoder[Int] = ExpressionEncoder()
     val func = (v1: Int, v2: Int) => v1 + v2
     val aggregator: ReduceAggregator[Int] = new ReduceAggregator(func)(Encoders.scalaInt)
-    assert(aggregator.zero == (false, null).asInstanceOf[(Boolean, Int)])
+    assert(aggregator.zero == (false, 0))
+  }
+
+  test("zero value boxed null") {
+    val func = (v1: java.lang.Integer, v2: java.lang.Integer) =>
+      (v1 + v2).asInstanceOf[java.lang.Integer]
+    val aggregator: ReduceAggregator[java.lang.Integer] = new ReduceAggregator(func)(Encoders.INT)
+    assert(aggregator.zero == (false, null).asInstanceOf[(Boolean, java.lang.Integer)])
   }
 
   test("reduce, merge and finish") {
