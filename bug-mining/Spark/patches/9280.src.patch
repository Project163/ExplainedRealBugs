diff --git a/sql/api/src/main/scala/org/apache/spark/sql/catalyst/JavaTypeInference.scala b/sql/api/src/main/scala/org/apache/spark/sql/catalyst/JavaTypeInference.scala
index 3d536b735db..191ccc52544 100644
--- a/sql/api/src/main/scala/org/apache/spark/sql/catalyst/JavaTypeInference.scala
+++ b/sql/api/src/main/scala/org/apache/spark/sql/catalyst/JavaTypeInference.scala
@@ -130,10 +130,13 @@ object JavaTypeInference {
       // TODO: we should only collect properties that have getter and setter. However, some tests
       //   pass in scala case class as java bean class which doesn't have getter and setter.
       val properties = getJavaBeanReadableProperties(c)
+      // add type variables from inheritance hierarchy of the class
+      val classTV = JavaTypeUtils.getTypeArguments(c, classOf[Object]).asScala.toMap ++
+        typeVariables
       // Note that the fields are ordered by name.
       val fields = properties.map { property =>
         val readMethod = property.getReadMethod
-        val encoder = encoderFor(readMethod.getGenericReturnType, seenTypeSet + c, typeVariables)
+        val encoder = encoderFor(readMethod.getGenericReturnType, seenTypeSet + c, classTV)
         // The existence of `javax.annotation.Nonnull`, means this field is not nullable.
         val hasNonNull = readMethod.isAnnotationPresent(classOf[Nonnull])
         EncoderField(
diff --git a/sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/JavaBeanWithGenerics.java b/sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/JavaTypeInferenceBeans.java
similarity index 54%
rename from sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/JavaBeanWithGenerics.java
rename to sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/JavaTypeInferenceBeans.java
index b84a3122cf8..cc3540717ee 100644
--- a/sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/JavaBeanWithGenerics.java
+++ b/sql/catalyst/src/test/java/org/apache/spark/sql/catalyst/JavaTypeInferenceBeans.java
@@ -17,25 +17,66 @@
 
 package org.apache.spark.sql.catalyst;
 
-class JavaBeanWithGenerics<T,A> {
+public class JavaTypeInferenceBeans {
+
+  static class JavaBeanWithGenericsA<T> {
+    public T getPropertyA() {
+      return null;
+    }
+
+    public void setPropertyA(T a) {
+
+    }
+  }
+
+  static class JavaBeanWithGenericsAB<T> extends JavaBeanWithGenericsA<String> {
+    public T getPropertyB() {
+      return null;
+    }
+
+    public void setPropertyB(T a) {
+
+    }
+  }
+
+  static class JavaBeanWithGenericsABC<T> extends JavaBeanWithGenericsAB<Long> {
+    public T getPropertyC() {
+      return null;
+    }
+
+    public void setPropertyC(T a) {
+
+    }
+  }
+
+  static class JavaBeanWithGenerics<T, A> {
     private A attribute;
 
     private T value;
 
     public A getAttribute() {
-        return attribute;
+      return attribute;
     }
 
     public void setAttribute(A attribute) {
-        this.attribute = attribute;
+      this.attribute = attribute;
     }
 
     public T getValue() {
-        return value;
+      return value;
     }
 
     public void setValue(T value) {
-        this.value = value;
+      this.value = value;
     }
+  }
+
+  static class JavaBeanWithGenericBase extends JavaBeanWithGenerics<String, String> {
+
+  }
+
+  static class JavaBeanWithGenericHierarchy extends JavaBeanWithGenericsABC<Integer> {
+
+  }
 }
 
diff --git a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/JavaTypeInferenceSuite.scala b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/JavaTypeInferenceSuite.scala
index 64399976097..f7c1043d1cb 100644
--- a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/JavaTypeInferenceSuite.scala
+++ b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/JavaTypeInferenceSuite.scala
@@ -24,6 +24,7 @@ import scala.beans.{BeanProperty, BooleanBeanProperty}
 import scala.reflect.{classTag, ClassTag}
 
 import org.apache.spark.SparkFunSuite
+import org.apache.spark.sql.catalyst.JavaTypeInferenceBeans.{JavaBeanWithGenericBase, JavaBeanWithGenericHierarchy, JavaBeanWithGenericsABC}
 import org.apache.spark.sql.catalyst.encoders.{AgnosticEncoder, UDTCaseClass, UDTForCaseClass}
 import org.apache.spark.sql.catalyst.encoders.AgnosticEncoders._
 import org.apache.spark.sql.types.{DecimalType, MapType, Metadata, StringType, StructField, StructType}
@@ -66,7 +67,8 @@ class LeafBean {
   @BeanProperty var period: java.time.Period = _
   @BeanProperty var enum: java.time.Month = _
   @BeanProperty val readOnlyString = "read-only"
-  @BeanProperty var genericNestedBean: JavaBeanWithGenerics[String, String] = _
+  @BeanProperty var genericNestedBean: JavaBeanWithGenericBase = _
+  @BeanProperty var genericNestedBean2: JavaBeanWithGenericsABC[Integer] = _
 
   var nonNullString: String = "value"
   @javax.annotation.Nonnull
@@ -186,8 +188,18 @@ class JavaTypeInferenceSuite extends SparkFunSuite {
       encoderField("duration", DayTimeIntervalEncoder),
       encoderField("enum", JavaEnumEncoder(classTag[java.time.Month])),
       encoderField("genericNestedBean", JavaBeanEncoder(
-        ClassTag(classOf[JavaBeanWithGenerics[String, String]]),
-        Seq(encoderField("attribute", StringEncoder), encoderField("value", StringEncoder)))),
+        ClassTag(classOf[JavaBeanWithGenericBase]),
+        Seq(
+          encoderField("attribute", StringEncoder),
+          encoderField("value", StringEncoder)
+        ))),
+      encoderField("genericNestedBean2", JavaBeanEncoder(
+        ClassTag(classOf[JavaBeanWithGenericsABC[Integer]]),
+        Seq(
+          encoderField("propertyA", StringEncoder),
+          encoderField("propertyB", BoxedLongEncoder),
+          encoderField("propertyC", BoxedIntEncoder)
+        ))),
       encoderField("instant", STRICT_INSTANT_ENCODER),
       encoderField("localDate", STRICT_LOCAL_DATE_ENCODER),
       encoderField("localDateTime", LocalDateTimeEncoder),
@@ -224,4 +236,27 @@ class JavaTypeInferenceSuite extends SparkFunSuite {
     ))
     assert(encoder === expected)
   }
+
+  test("SPARK-44910: resolve bean with generic base class") {
+    val encoder =
+      JavaTypeInference.encoderFor(classOf[JavaBeanWithGenericBase])
+    val expected =
+      JavaBeanEncoder(ClassTag(classOf[JavaBeanWithGenericBase]), Seq(
+        encoderField("attribute", StringEncoder),
+        encoderField("value", StringEncoder)
+      ))
+    assert(encoder === expected)
+  }
+
+  test("SPARK-44910: resolve bean with hierarchy of generic classes") {
+    val encoder =
+      JavaTypeInference.encoderFor(classOf[JavaBeanWithGenericHierarchy])
+    val expected =
+      JavaBeanEncoder(ClassTag(classOf[JavaBeanWithGenericHierarchy]), Seq(
+        encoderField("propertyA", StringEncoder),
+        encoderField("propertyB", BoxedLongEncoder),
+        encoderField("propertyC", BoxedIntEncoder)
+      ))
+    assert(encoder === expected)
+  }
 }
