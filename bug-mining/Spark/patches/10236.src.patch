diff --git a/python/pyspark/pandas/series.py b/python/pyspark/pandas/series.py
index d55de6e1182..c5670d36c0f 100644
--- a/python/pyspark/pandas/series.py
+++ b/python/pyspark/pandas/series.py
@@ -369,6 +369,10 @@ class Series(Frame, IndexOpsMixin, Generic[T]):
     pandas-on-Spark Series that corresponds to pandas Series logically. This holds Spark Column
     internally.
 
+    .. versionchanged:: 4.1.0
+        Support construction from a pandas-on-Spark Series input, which can be used with
+        additional parameters index, dtype, and name for overriding the original value.
+
     :ivar _internal: an internal immutable Frame to manage metadata.
     :type _internal: InternalFrame
     :ivar _psdf: Parent's pandas-on-Spark DataFrame
@@ -376,9 +380,10 @@ class Series(Frame, IndexOpsMixin, Generic[T]):
 
     Parameters
     ----------
-    data : array-like, dict, or scalar value, pandas Series
+    data : array-like, dict, or scalar value, pandas Series, pandas-on-Spark Series
         Contains data stored in Series
-        Note that if `data` is a pandas Series, other arguments should not be used.
+        Note that if `data` is a Series, index, dtype, or name can also be
+        specified to override the original value.
     index : array-like or Index (1d)
         Values must be hashable and have the same length as `data`.
         Non-unique index values are allowed. Will default to
@@ -387,6 +392,8 @@ class Series(Frame, IndexOpsMixin, Generic[T]):
         dict.
     dtype : numpy.dtype or None
         If None, dtype will be inferred
+    name : str, default None
+        The name to give to the Series.
     copy : boolean, default False
         Copy input data
     """
@@ -406,6 +413,24 @@ class Series(Frame, IndexOpsMixin, Generic[T]):
 
             self._anchor = data
             self._col_label = index
+
+        elif isinstance(data, Series):
+            assert not copy
+            assert not fastpath
+
+            if name:
+                data = data.rename(name)
+
+            if index:
+                data = data.reindex(index)
+
+            if dtype:
+                data = data.astype(dtype)
+
+            anchor = DataFrame(data)
+            self._anchor = anchor
+            self._col_label = anchor._internal.column_labels[0]
+            object.__setattr__(anchor, "_psseries", {self._column_label: self})
         else:
             if isinstance(data, pd.Series):
                 assert index is None
diff --git a/python/pyspark/pandas/tests/series/test_series.py b/python/pyspark/pandas/tests/series/test_series.py
index 7409bcc26c2..ffb8f33e6e4 100644
--- a/python/pyspark/pandas/tests/series/test_series.py
+++ b/python/pyspark/pandas/tests/series/test_series.py
@@ -103,6 +103,29 @@ class SeriesTestsMixin:
 
         self.assertTrue(pser_a.empty)
 
+    def test_series_from_series(self):
+        psser = ps.Series([1, 2, 3, 4, 5, 6, 7], name="x")
+
+        psser_from_psser = ps.Series(psser)
+        self.assert_eq(psser_from_psser, psser)
+
+        psser = ps.Series([1, 2, 3])
+
+        # Specify new index
+        psser_from_psser = ps.Series(psser, index=[1])
+        self.assert_eq(psser_from_psser, ps.Series([2], index=[1]))
+
+        psser_from_psser = ps.Series(psser, index=[1, 2])
+        self.assert_eq(psser_from_psser, ps.Series([2, 3], index=[1, 2]))
+
+        # Specify new out-of-order index
+        psser_from_psser = ps.Series(psser, index=[1, 2, 0])
+        self.assert_eq(psser_from_psser, ps.Series([2, 3, 1], index=[1, 2, 0]))
+
+        # Specify new dtype and name
+        psser_from_psser = ps.Series(psser, name="y", dtype=float)
+        self.assert_eq(psser_from_psser, ps.Series([1, 2, 3], name="y", dtype=float))
+
     def test_all_null_series(self):
         pser_a = pd.Series([None, None, None], dtype="float64")
         pser_b = pd.Series([None, None, None], dtype="str")
