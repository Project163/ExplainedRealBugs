diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala
index 580e2b318c7..5e356fba96a 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala
@@ -1227,8 +1227,8 @@ class Analyzer(override val catalogManager: CatalogManager) extends RuleExecutor
           // We put the synchronously resolved relation into the [[AnalyzerBridgeState]] for
           // it to be later reused by the single-pass [[Resolver]] to avoid resolving the relation
           // metadata twice.
-          AnalysisContext.get.getSinglePassResolverBridgeState.map { bridgeState =>
-            bridgeState.relationsWithResolvedMetadata.put(unresolvedRelation, relation)
+          AnalysisContext.get.getSinglePassResolverBridgeState.foreach { bridgeState =>
+            bridgeState.addUnresolvedRelation(unresolvedRelation, relation)
           }
           relation
         }
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/AnalyzerBridgeState.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/AnalyzerBridgeState.scala
index e28b0417832..a3fd6cf1cc8 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/AnalyzerBridgeState.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/AnalyzerBridgeState.scala
@@ -19,7 +19,7 @@ package org.apache.spark.sql.catalyst.analysis.resolver
 
 import java.util.HashMap
 
-import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation
+import org.apache.spark.sql.catalyst.analysis.{AnalysisContext, UnresolvedRelation}
 import org.apache.spark.sql.catalyst.catalog.UnresolvedCatalogRelation
 import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan
 
@@ -28,7 +28,7 @@ import org.apache.spark.sql.catalyst.plans.logical.LogicalPlan
  * [[Resolver]]. It is used  in dual-run mode (when
  * [[ANALYZER_SINGLE_PASS_RESOLVER_RELATION_BRIDGING_ENABLED]] is true).
  *
- * @param relationsWithResolvedMetadata A map from [[UnresolvedRelation]] to the relations with
+ * @param relationsWithResolvedMetadata A map from [[BridgedRelationId]] to the relations with
  *   resolved metadata. It allows us to reuse the relation metadata and avoid duplicate
  *   catalog/table lookups.
  * @param catalogRelationsWithResolvedMetadata A map from [[UnresolvedCatalogRelation]] to the
@@ -40,9 +40,16 @@ case class AnalyzerBridgeState(
       new AnalyzerBridgeState.RelationsWithResolvedMetadata,
     catalogRelationsWithResolvedMetadata: AnalyzerBridgeState.CatalogRelationsWithResolvedMetadata =
       new AnalyzerBridgeState.CatalogRelationsWithResolvedMetadata
-)
+) {
+  def addUnresolvedRelation(unresolvedRelation: UnresolvedRelation, relation: LogicalPlan): Unit = {
+    relationsWithResolvedMetadata.put(
+        BridgedRelationId(unresolvedRelation, AnalysisContext.get.catalogAndNamespace),
+        relation
+      )
+  }
+}
 
 object AnalyzerBridgeState {
-  type RelationsWithResolvedMetadata = HashMap[UnresolvedRelation, LogicalPlan]
+  type RelationsWithResolvedMetadata = HashMap[BridgedRelationId, LogicalPlan]
   type CatalogRelationsWithResolvedMetadata = HashMap[UnresolvedCatalogRelation, LogicalPlan]
 }
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/BridgedRelationId.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/BridgedRelationId.scala
new file mode 100644
index 00000000000..02c42853fd4
--- /dev/null
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/BridgedRelationId.scala
@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.spark.sql.catalyst.analysis.resolver
+
+import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation
+
+/**
+ * The [[BridgedRelationId]] is a unique identifier for an unresolved relation in the whole logical
+ * plan including all the nested views. It is used to lookup relations with resolved metadata which
+ * were processed by the fixed-point when running two Analyzers in dual-run mode. Storing
+ * [[catalogAndNamespace]] is required to differentiate tables/views created in different catalogs
+ * as their [[UnresolvedRelation]]s could have same structure.
+ */
+case class BridgedRelationId(
+    unresolvedRelation: UnresolvedRelation,
+    catalogAndNamespace: Seq[String]
+)
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/BridgedRelationMetadataProvider.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/BridgedRelationMetadataProvider.scala
index f01b9adf2a9..db75a3909c4 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/BridgedRelationMetadataProvider.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/BridgedRelationMetadataProvider.scala
@@ -32,15 +32,17 @@ import org.apache.spark.sql.connector.catalog.CatalogManager
 class BridgedRelationMetadataProvider(
     override val catalogManager: CatalogManager,
     override val relationResolution: RelationResolution,
-    analyzerBridgeState: AnalyzerBridgeState
+    analyzerBridgeState: AnalyzerBridgeState,
+    viewResolver: ViewResolver
 ) extends RelationMetadataProvider {
   override val relationsWithResolvedMetadata = new RelationsWithResolvedMetadata
-  updateRelationsWithResolvedMetadata()
 
   /**
    * We update relations on each [[resolve]] call, because relation IDs might have changed.
    * This can happen for the nested views, since catalog name may differ, and expanded table name
-   * will differ for the same [[UnresolvedRelation]].
+   * will differ for the same [[UnresolvedRelation]]. In order to overcome this issue, we use
+   * [[viewResolver]]'s context to peek into the most recent context and to only resolve the
+   * relations which were created under this same context.
    *
    * See [[ViewResolver.resolve]] for more info on how SQL configs are propagated to nested views).
    */
@@ -50,11 +52,14 @@ class BridgedRelationMetadataProvider(
 
   private def updateRelationsWithResolvedMetadata(): Unit = {
     analyzerBridgeState.relationsWithResolvedMetadata.forEach(
-      (unresolvedRelation, relationWithResolvedMetadata) => {
-        relationsWithResolvedMetadata.put(
-          relationIdFromUnresolvedRelation(unresolvedRelation),
-          tryConvertUnresolvedCatalogRelation(relationWithResolvedMetadata)
-        )
+      (bridgeRelationId, relationWithResolvedMetadata) => {
+        if (viewResolver.getCatalogAndNamespace.getOrElse(Seq.empty)
+          == bridgeRelationId.catalogAndNamespace) {
+          relationsWithResolvedMetadata.put(
+            relationIdFromUnresolvedRelation(bridgeRelationId.unresolvedRelation),
+            tryConvertUnresolvedCatalogRelation(relationWithResolvedMetadata)
+          )
+        }
       }
     )
   }
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/Resolver.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/Resolver.scala
index 3103e64885f..44a0ad52be9 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/Resolver.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/Resolver.scala
@@ -120,7 +120,10 @@ class Resolver(
    * This method is a top-level analysis entry point:
    * 1. Substitute IDENTIFIERs and CTEs in the `unresolvedPlan` using
    *    [[IdentifierAndCteSubstitutor]];
-   * 2. Resolve the metadata for the plan using [[MetadataResolver]];
+   * 2. Resolve the metadata for the plan using [[MetadataResolver]]. When
+   *    [[ANALYZER_SINGLE_PASS_RESOLVER_RELATION_BRIDGING_ENABLED]] is enabled, we need to
+   *    re-instantiate the [[RelationMetadataProvider]] as [[View]] resolution context might have
+   *    changed in the meantime;
    * 3. Resolve the plan using [[resolve]].
    *
    * This method is called for the top-level query and each unresolved [[View]].
@@ -139,7 +142,8 @@ class Resolver(
         new BridgedRelationMetadataProvider(
           catalogManager,
           relationResolution,
-          analyzerBridgeState
+          analyzerBridgeState,
+          viewResolver
         )
       case None =>
         relationMetadataProvider
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/ViewResolver.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/ViewResolver.scala
index ea89db614ad..f96ce534556 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/ViewResolver.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/resolver/ViewResolver.scala
@@ -35,6 +35,13 @@ class ViewResolver(resolver: Resolver, catalogManager: CatalogManager)
   private val sourceUnresolvedRelationStack = new ArrayDeque[UnresolvedRelation]
   private val viewResolutionContextStack = new ArrayDeque[ViewResolutionContext]
 
+  def getCatalogAndNamespace: Option[Seq[String]] =
+    if (viewResolutionContextStack.isEmpty) {
+      None
+    } else {
+      viewResolutionContextStack.peek().catalogAndNamespace
+    }
+
   /**
    * This method preserves the resolved [[UnresolvedRelation]] for the further view resolution
    * process.
@@ -108,7 +115,8 @@ class ViewResolver(resolver: Resolver, catalogManager: CatalogManager)
       }
 
       val viewResolutionContext = prevContext.copy(
-        nestedViewDepth = prevContext.nestedViewDepth + 1
+        nestedViewDepth = prevContext.nestedViewDepth + 1,
+        catalogAndNamespace = Some(unresolvedView.desc.viewCatalogAndNamespace)
       )
       viewResolutionContext.validate(unresolvedView)
 
@@ -136,8 +144,12 @@ class ViewResolver(resolver: Resolver, catalogManager: CatalogManager)
  * @param nestedViewDepth Current nested view depth. Cannot exceed the `maxNestedViewDepth`.
  * @param maxNestedViewDepth Maximum allowed nested view depth. Configured in the upper context
  *   based on [[SQLConf.MAX_NESTED_VIEW_DEPTH]].
+ * @param catalogAndNamespace Catalog and camespace under which the [[View]] was created.
  */
-case class ViewResolutionContext(nestedViewDepth: Int, maxNestedViewDepth: Int) {
+case class ViewResolutionContext(
+    nestedViewDepth: Int,
+    maxNestedViewDepth: Int,
+    catalogAndNamespace: Option[Seq[String]] = None) {
   def validate(unresolvedView: View): Unit = {
     if (nestedViewDepth > maxNestedViewDepth) {
       throw QueryCompilationErrors.viewDepthExceedsMaxResolutionDepthError(
diff --git a/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/rules.scala b/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/rules.scala
index 6420d3ab374..4e38e9acb55 100644
--- a/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/rules.scala
+++ b/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/rules.scala
@@ -81,8 +81,8 @@ class ResolveSQLOnFile(sparkSession: SparkSession) extends Rule[LogicalPlan] {
           // We put the resolved relation into the [[AnalyzerBridgeState]] for
           // it to be later reused by the single-pass [[Resolver]] to avoid resolving the
           // relation metadata twice.
-          AnalysisContext.get.getSinglePassResolverBridgeState.map { bridgeState =>
-            bridgeState.relationsWithResolvedMetadata.put(unresolvedRelation, resolvedRelation)
+          AnalysisContext.get.getSinglePassResolverBridgeState.foreach { bridgeState =>
+            bridgeState.addUnresolvedRelation(unresolvedRelation, resolvedRelation)
           }
         case _ =>
       })
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/analysis/resolver/MetadataResolverSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/analysis/resolver/MetadataResolverSuite.scala
index 385f9bd7130..b85e6913bd3 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/analysis/resolver/MetadataResolverSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/analysis/resolver/MetadataResolverSuite.scala
@@ -24,10 +24,12 @@ import org.apache.spark.sql.catalyst.{AliasIdentifier, TableIdentifier}
 import org.apache.spark.sql.catalyst.analysis.UnresolvedRelation
 import org.apache.spark.sql.catalyst.analysis.resolver.{
   AnalyzerBridgeState,
+  BridgedRelationId,
   BridgedRelationMetadataProvider,
   MetadataResolver,
   RelationId,
-  Resolver
+  Resolver,
+  ViewResolver
 }
 import org.apache.spark.sql.catalyst.catalog.UnresolvedCatalogRelation
 import org.apache.spark.sql.catalyst.expressions.{Expression, PlanExpression}
@@ -173,7 +175,7 @@ class MetadataResolverSuite extends QueryTest with SharedSparkSession with SQLTe
 
       val analyzerBridgeState = new AnalyzerBridgeState
       analyzerBridgeState.relationsWithResolvedMetadata.put(
-        UnresolvedRelation(Seq("src")),
+        BridgedRelationId(UnresolvedRelation(Seq("src")), Seq.empty),
         createUnresolvedCatalogRelation("src")
       )
 
@@ -239,22 +241,24 @@ class MetadataResolverSuite extends QueryTest with SharedSparkSession with SQLTe
       analyzerBridgeState: Option[AnalyzerBridgeState]): Unit = {
     val unresolvedPlan = spark.sql(sqlText).queryExecution.logical
 
+    val resolver = new Resolver(spark.sessionState.catalogManager)
+
     val metadataResolver = analyzerBridgeState match {
       case Some(analyzerBridgeState) =>
         new BridgedRelationMetadataProvider(
           spark.sessionState.catalogManager,
           Resolver.createRelationResolution(spark.sessionState.catalogManager),
-          analyzerBridgeState
+          analyzerBridgeState,
+          new ViewResolver(resolver = resolver, catalogManager = spark.sessionState.catalogManager)
         )
       case None =>
-        val metadataResolver = new MetadataResolver(
+        new MetadataResolver(
           spark.sessionState.catalogManager,
           Resolver.createRelationResolution(spark.sessionState.catalogManager),
           Seq(new FileResolver(spark))
         )
-        metadataResolver.resolve(unresolvedPlan)
-        metadataResolver
     }
+    metadataResolver.resolve(unresolvedPlan)
 
     val actualTableData = new mutable.HashMap[RelationId, TestTableData]
 
