diff --git a/common/utils/src/main/resources/error/error-conditions.json b/common/utils/src/main/resources/error/error-conditions.json
index fac75797cb1..0a6a2fbed9b 100644
--- a/common/utils/src/main/resources/error/error-conditions.json
+++ b/common/utils/src/main/resources/error/error-conditions.json
@@ -3798,6 +3798,21 @@
     ],
     "sqlState" : "22003"
   },
+  "SYNTAX_DISCONTINUED" : {
+    "message" : [
+      "Support of the clause or keyword: <clause> has been discontinued in this context."
+    ],
+    "subClass" : {
+      "BANG_EQUALS_NOT" : {
+        "message" : [
+          "The '!' keyword is only supported as an alias for the prefix operator 'NOT'.",
+          "Use the 'NOT' keyword instead for infix clauses such as `NOT LIKE`, `NOT IN`, `NOT BETWEEN`, etc.",
+          "To re-enable the '!' keyword, set \"spark.sql.legacy.bangEqualsNot\" to \"true\"."
+        ]
+      }
+    },
+    "sqlState" : "42601"
+  },
   "TABLE_OR_VIEW_ALREADY_EXISTS" : {
     "message" : [
       "Cannot create table or view <relationName> because it already exists.",
diff --git a/docs/sql-error-conditions-syntax-discontinued-error-class.md b/docs/sql-error-conditions-syntax-discontinued-error-class.md
new file mode 100644
index 00000000000..966e1100436
--- /dev/null
+++ b/docs/sql-error-conditions-syntax-discontinued-error-class.md
@@ -0,0 +1,39 @@
+---
+layout: global
+title: SYNTAX_DISCONTINUED error class
+displayTitle: SYNTAX_DISCONTINUED error class
+license: |
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+---
+
+<!--
+  DO NOT EDIT THIS FILE.
+  It was generated automatically by `org.apache.spark.SparkThrowableSuite`.
+-->
+
+[SQLSTATE: 42601](sql-error-conditions-sqlstates.html#class-42-syntax-error-or-access-rule-violation)
+
+Support of the clause or keyword: `<clause>` has been discontinued in this context.
+
+This error class has the following derived error classes:
+
+## BANG_EQUALS_NOT
+
+The '!' keyword is supported as a prefix operator in a logical operation only.
+Use the 'NOT' keyword instead for clauses such as `NOT LIKE`, `NOT IN`, `NOT BETWEEN`, etc.
+To re-enable the '!' keyword, set "spark.sql.legacy.bangEqualsNot" to "true".
+
+
diff --git a/docs/sql-migration-guide.md b/docs/sql-migration-guide.md
index 6331498ff4c..9b189eee6ad 100644
--- a/docs/sql-migration-guide.md
+++ b/docs/sql-migration-guide.md
@@ -49,6 +49,7 @@ license: |
 - Since Spark 4.0, Oracle JDBC datasource will write TimestampType as TIMESTAMP WITH LOCAL TIME ZONE, while in Spark 3.5 and previous, write as TIMESTAMP. To restore the previous behavior, set `spark.sql.legacy.oracle.timestampMapping.enabled` to `true`.
 - Since Spark 4.0, The default value for `spark.sql.legacy.ctePrecedencePolicy` has been changed from `EXCEPTION` to `CORRECTED`. Instead of raising an error, inner CTE definitions take precedence over outer definitions.
 - Since Spark 4.0, The default value for `spark.sql.legacy.timeParserPolicy` has been changed from `EXCEPTION` to `CORRECTED`. Instead of raising an `INCONSISTENT_BEHAVIOR_CROSS_VERSION` error, `CANNOT_PARSE_TIMESTAMP` will be raised if ANSI mode is enable. `NULL` will be returned if ANSI mode is disabled. See [Datetime Patterns for Formatting and Parsing](sql-ref-datetime-pattern.html).
+- Since Spark 4.0, A bug falsely allowing `!` instead of `NOT` when `!` is not a prefix operator has been fixed. Clauses such as `expr ! IN (...)`, `expr ! BETWEEN ...`, or `col ! NULL` now raise syntax errors. To restore the previous behavior, set `spark.sql.legacy.bangEqualsNot` to `true`. 
 
 ## Upgrading from Spark SQL 3.5.1 to 3.5.2
 
diff --git a/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4 b/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4
index 60b67b08021..71bd75f934c 100644
--- a/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4
+++ b/sql/api/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBaseParser.g4
@@ -77,7 +77,7 @@ statement
     | USE identifierReference                                          #use
     | USE namespace identifierReference                                #useNamespace
     | SET CATALOG (errorCapturingIdentifier | stringLit)                  #setCatalog
-    | CREATE namespace (IF NOT EXISTS)? identifierReference
+    | CREATE namespace (IF errorCapturingNot EXISTS)? identifierReference
         (commentSpec |
          locationSpec |
          (WITH (DBPROPERTIES | PROPERTIES) propertyList))*             #createNamespace
@@ -92,7 +92,7 @@ statement
     | createTableHeader (LEFT_PAREN createOrReplaceTableColTypeList RIGHT_PAREN)? tableProvider?
         createTableClauses
         (AS? query)?                                                   #createTable
-    | CREATE TABLE (IF NOT EXISTS)? target=tableIdentifier
+    | CREATE TABLE (IF errorCapturingNot EXISTS)? target=tableIdentifier
         LIKE source=tableIdentifier
         (tableProvider |
         rowFormat |
@@ -141,7 +141,7 @@ statement
         SET SERDE stringLit (WITH SERDEPROPERTIES propertyList)?       #setTableSerDe
     | ALTER TABLE identifierReference (partitionSpec)?
         SET SERDEPROPERTIES propertyList                               #setTableSerDe
-    | ALTER (TABLE | VIEW) identifierReference ADD (IF NOT EXISTS)?
+    | ALTER (TABLE | VIEW) identifierReference ADD (IF errorCapturingNot EXISTS)?
         partitionSpecLocation+                                         #addTablePartition
     | ALTER TABLE identifierReference
         from=partitionSpec RENAME TO to=partitionSpec                  #renameTablePartition
@@ -153,7 +153,7 @@ statement
     | DROP TABLE (IF EXISTS)? identifierReference PURGE?               #dropTable
     | DROP VIEW (IF EXISTS)? identifierReference                       #dropView
     | CREATE (OR REPLACE)? (GLOBAL? TEMPORARY)?
-        VIEW (IF NOT EXISTS)? identifierReference
+        VIEW (IF errorCapturingNot EXISTS)? identifierReference
         identifierCommentList?
         (commentSpec |
          (PARTITIONED ON identifierList) |
@@ -163,7 +163,7 @@ statement
         tableIdentifier (LEFT_PAREN colTypeList RIGHT_PAREN)? tableProvider
         (OPTIONS propertyList)?                                        #createTempViewUsing
     | ALTER VIEW identifierReference AS? query                         #alterViewQuery
-    | CREATE (OR REPLACE)? TEMPORARY? FUNCTION (IF NOT EXISTS)?
+    | CREATE (OR REPLACE)? TEMPORARY? FUNCTION (IF errorCapturingNot EXISTS)?
         identifierReference AS className=stringLit
         (USING resource (COMMA resource)*)?                            #createFunction
     | DROP TEMPORARY? FUNCTION (IF EXISTS)? identifierReference        #dropFunction
@@ -224,7 +224,7 @@ statement
     | SET .*?                                                          #setConfiguration
     | RESET configKey                                                  #resetQuotedConfiguration
     | RESET .*?                                                        #resetConfiguration
-    | CREATE INDEX (IF NOT EXISTS)? identifier ON TABLE?
+    | CREATE INDEX (IF errorCapturingNot EXISTS)? identifier ON TABLE?
         identifierReference (USING indexType=identifier)?
         LEFT_PAREN columns=multipartIdentifierPropertyList RIGHT_PAREN
         (OPTIONS options=propertyList)?                                #createIndex
@@ -315,7 +315,7 @@ unsupportedHiveNativeCommands
     ;
 
 createTableHeader
-    : CREATE TEMPORARY? EXTERNAL? TABLE (IF NOT EXISTS)? identifierReference
+    : CREATE TEMPORARY? EXTERNAL? TABLE (IF errorCapturingNot EXISTS)? identifierReference
     ;
 
 replaceTableHeader
@@ -351,8 +351,8 @@ query
     ;
 
 insertInto
-    : INSERT OVERWRITE TABLE? identifierReference (partitionSpec (IF NOT EXISTS)?)?  ((BY NAME) | identifierList)? #insertOverwriteTable
-    | INSERT INTO TABLE? identifierReference partitionSpec? (IF NOT EXISTS)? ((BY NAME) | identifierList)?   #insertIntoTable
+    : INSERT OVERWRITE TABLE? identifierReference (partitionSpec (IF errorCapturingNot EXISTS)?)?  ((BY NAME) | identifierList)? #insertOverwriteTable
+    | INSERT INTO TABLE? identifierReference partitionSpec? (IF errorCapturingNot EXISTS)? ((BY NAME) | identifierList)?   #insertIntoTable
     | INSERT INTO TABLE? identifierReference REPLACE whereClause                                             #insertIntoReplaceWhere
     | INSERT OVERWRITE LOCAL? DIRECTORY path=stringLit rowFormat? createFileFormat?                     #insertOverwriteHiveDir
     | INSERT OVERWRITE LOCAL? DIRECTORY (path=stringLit)? tableProvider (OPTIONS options=propertyList)? #insertOverwriteDir
@@ -588,11 +588,11 @@ matchedClause
     : WHEN MATCHED (AND matchedCond=booleanExpression)? THEN matchedAction
     ;
 notMatchedClause
-    : WHEN NOT MATCHED (BY TARGET)? (AND notMatchedCond=booleanExpression)? THEN notMatchedAction
+    : WHEN errorCapturingNot MATCHED (BY TARGET)? (AND notMatchedCond=booleanExpression)? THEN notMatchedAction
     ;
 
 notMatchedBySourceClause
-    : WHEN NOT MATCHED BY SOURCE (AND notMatchedBySourceCond=booleanExpression)? THEN notMatchedBySourceAction
+    : WHEN errorCapturingNot MATCHED BY SOURCE (AND notMatchedBySourceCond=booleanExpression)? THEN notMatchedBySourceAction
     ;
 
 matchedAction
@@ -956,15 +956,20 @@ booleanExpression
     ;
 
 predicate
-    : NOT? kind=BETWEEN lower=valueExpression AND upper=valueExpression
-    | NOT? kind=IN LEFT_PAREN expression (COMMA expression)* RIGHT_PAREN
-    | NOT? kind=IN LEFT_PAREN query RIGHT_PAREN
-    | NOT? kind=RLIKE pattern=valueExpression
-    | NOT? kind=(LIKE | ILIKE) quantifier=(ANY | SOME | ALL) (LEFT_PAREN RIGHT_PAREN | LEFT_PAREN expression (COMMA expression)* RIGHT_PAREN)
-    | NOT? kind=(LIKE | ILIKE) pattern=valueExpression (ESCAPE escapeChar=stringLit)?
-    | IS NOT? kind=NULL
-    | IS NOT? kind=(TRUE | FALSE | UNKNOWN)
-    | IS NOT? kind=DISTINCT FROM right=valueExpression
+    : errorCapturingNot? kind=BETWEEN lower=valueExpression AND upper=valueExpression
+    | errorCapturingNot? kind=IN LEFT_PAREN expression (COMMA expression)* RIGHT_PAREN
+    | errorCapturingNot? kind=IN LEFT_PAREN query RIGHT_PAREN
+    | errorCapturingNot? kind=RLIKE pattern=valueExpression
+    | errorCapturingNot? kind=(LIKE | ILIKE) quantifier=(ANY | SOME | ALL) (LEFT_PAREN RIGHT_PAREN | LEFT_PAREN expression (COMMA expression)* RIGHT_PAREN)
+    | errorCapturingNot? kind=(LIKE | ILIKE) pattern=valueExpression (ESCAPE escapeChar=stringLit)?
+    | IS errorCapturingNot? kind=NULL
+    | IS errorCapturingNot? kind=(TRUE | FALSE | UNKNOWN)
+    | IS errorCapturingNot? kind=DISTINCT FROM right=valueExpression
+    ;
+
+errorCapturingNot
+    : NOT
+    | BANG
     ;
 
 valueExpression
@@ -1143,7 +1148,7 @@ qualifiedColTypeWithPosition
     ;
 
 colDefinitionDescriptorWithPosition
-    : NOT NULL
+    : errorCapturingNot NULL
     | defaultExpression
     | commentSpec
     | colPosition
@@ -1162,7 +1167,7 @@ colTypeList
     ;
 
 colType
-    : colName=errorCapturingIdentifier dataType (NOT NULL)? commentSpec?
+    : colName=errorCapturingIdentifier dataType (errorCapturingNot NULL)? commentSpec?
     ;
 
 createOrReplaceTableColTypeList
@@ -1174,7 +1179,7 @@ createOrReplaceTableColType
     ;
 
 colDefinitionOption
-    : NOT NULL
+    : errorCapturingNot NULL
     | defaultExpression
     | generationExpression
     | commentSpec
@@ -1189,7 +1194,7 @@ complexColTypeList
     ;
 
 complexColType
-    : errorCapturingIdentifier COLON? dataType (NOT NULL)? commentSpec?
+    : errorCapturingIdentifier COLON? dataType (errorCapturingNot NULL)? commentSpec?
     ;
 
 whenClause
@@ -1296,7 +1301,7 @@ alterColumnAction
     : TYPE dataType
     | commentSpec
     | colPosition
-    | setOrDrop=(SET | DROP) NOT NULL
+    | setOrDrop=(SET | DROP) errorCapturingNot NULL
     | SET defaultExpression
     | dropDefault=DROP DEFAULT
     ;
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
index 69220613a89..28327c9dd3b 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/parser/AstBuilder.scala
@@ -50,7 +50,9 @@ import org.apache.spark.sql.connector.catalog.{CatalogV2Util, SupportsNamespaces
 import org.apache.spark.sql.connector.catalog.TableChange.ColumnPosition
 import org.apache.spark.sql.connector.expressions.{ApplyTransform, BucketTransform, DaysTransform, Expression => V2Expression, FieldReference, HoursTransform, IdentityTransform, LiteralValue, MonthsTransform, Transform, YearsTransform}
 import org.apache.spark.sql.errors.{QueryCompilationErrors, QueryParsingErrors}
+import org.apache.spark.sql.errors.DataTypeErrors.toSQLStmt
 import org.apache.spark.sql.internal.SQLConf
+import org.apache.spark.sql.internal.SQLConf.LEGACY_BANG_EQUALS_NOT
 import org.apache.spark.sql.types._
 import org.apache.spark.unsafe.types.{CalendarInterval, UTF8String}
 import org.apache.spark.util.ArrayImplicits._
@@ -365,6 +367,8 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
     val cols = Option(ctx.identifierList()).map(visitIdentifierList).getOrElse(Nil)
     val partitionKeys = Option(ctx.partitionSpec).map(visitPartitionSpec).getOrElse(Map.empty)
 
+    blockBang(ctx.errorCapturingNot())
+
     if (ctx.EXISTS != null) {
       invalidStatement("INSERT INTO ... IF NOT EXISTS", ctx)
     }
@@ -381,6 +385,8 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
     val cols = Option(ctx.identifierList()).map(visitIdentifierList).getOrElse(Nil)
     val partitionKeys = Option(ctx.partitionSpec).map(visitPartitionSpec).getOrElse(Map.empty)
 
+    blockBang(ctx.errorCapturingNot())
+
     val dynamicPartitionKeys: Map[String, Option[String]] = partitionKeys.filter(_._2.isEmpty)
     if (ctx.EXISTS != null && dynamicPartitionKeys.nonEmpty) {
       operationNotAllowed("IF NOT EXISTS with dynamic partitions: " +
@@ -1866,6 +1872,25 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
       exceptCols.toSeq)
   }
 
+  /**
+   * Check for the inappropriate usage of the '!' token.
+   * '!' used to be a synonym for 'NOT' in the lexer, but that was too general.
+   * '!' should only be a synonym for 'NOT' when used as a prefix in a logical operation.
+   * We do that now explicitly.
+   */
+  def blockBang(ctx: ErrorCapturingNotContext): ErrorCapturingNotContext = {
+    val tolerateBang = conf.getConf(LEGACY_BANG_EQUALS_NOT)
+    if (ctx != null && ctx.BANG() != null && !tolerateBang) {
+      withOrigin(ctx) {
+        throw new ParseException(
+          errorClass = "SYNTAX_DISCONTINUED.BANG_EQUALS_NOT",
+          messageParameters = Map("clause" -> toSQLStmt("!")),
+          ctx)
+      }
+    }
+    ctx
+  }
+
   /**
    * Create an aliased expression if an alias is specified. Both single and multi-aliases are
    * supported.
@@ -2005,9 +2030,12 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
    */
   private def withPredicate(e: Expression, ctx: PredicateContext): Expression = withOrigin(ctx) {
     // Invert a predicate if it has a valid NOT clause.
-    def invertIfNotDefined(e: Expression): Expression = ctx.NOT match {
-      case null => e
-      case not => Not(e)
+    def invertIfNotDefined(e: Expression): Expression = {
+      val withNot = blockBang(ctx.errorCapturingNot)
+      withNot match {
+        case null => e
+        case _ => Not(e)
+      }
     }
 
     def getValueExpressions(e: Expression): Seq[Expression] = e match {
@@ -2029,6 +2057,8 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
       case _ => new Like(expr, pattern)
     }
 
+    val withNot = blockBang(ctx.errorCapturingNot)
+
     // Create the predicate.
     ctx.kind.getType match {
       case SqlBaseParser.BETWEEN =>
@@ -2048,7 +2078,7 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
               // So we use LikeAny or NotLikeAny instead.
               val patterns = expressions.map(_.eval(EmptyRow).asInstanceOf[UTF8String])
               val (expr, pat) = lowerLikeArgsIfNeeded(e, patterns)
-              ctx.NOT match {
+              withNot match {
                 case null => LikeAny(expr, pat)
                 case _ => NotLikeAny(expr, pat)
               }
@@ -2064,7 +2094,7 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
               // So we use LikeAll or NotLikeAll instead.
               val patterns = expressions.map(_.eval(EmptyRow).asInstanceOf[UTF8String])
               val (expr, pat) = lowerLikeArgsIfNeeded(e, patterns)
-              ctx.NOT match {
+              withNot match {
                 case null => LikeAll(expr, pat)
                 case _ => NotLikeAll(expr, pat)
               }
@@ -2088,23 +2118,23 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
         }
       case SqlBaseParser.RLIKE =>
         invertIfNotDefined(RLike(e, expression(ctx.pattern)))
-      case SqlBaseParser.NULL if ctx.NOT != null =>
+      case SqlBaseParser.NULL if withNot != null =>
         IsNotNull(e)
       case SqlBaseParser.NULL =>
         IsNull(e)
-      case SqlBaseParser.TRUE => ctx.NOT match {
+      case SqlBaseParser.TRUE => withNot match {
         case null => EqualNullSafe(e, Literal(true))
         case _ => Not(EqualNullSafe(e, Literal(true)))
       }
-      case SqlBaseParser.FALSE => ctx.NOT match {
+      case SqlBaseParser.FALSE => withNot match {
         case null => EqualNullSafe(e, Literal(false))
         case _ => Not(EqualNullSafe(e, Literal(false)))
       }
-      case SqlBaseParser.UNKNOWN => ctx.NOT match {
+      case SqlBaseParser.UNKNOWN => withNot match {
         case null => IsUnknown(e)
         case _ => IsNotUnknown(e)
       }
-      case SqlBaseParser.DISTINCT if ctx.NOT != null =>
+      case SqlBaseParser.DISTINCT if withNot != null =>
         EqualNullSafe(e, expression(ctx.right))
       case SqlBaseParser.DISTINCT =>
         Not(EqualNullSafe(e, expression(ctx.right)))
@@ -3173,6 +3203,7 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
     var commentSpec: Option[CommentSpecContext] = None
     ctx.colDefinitionOption().asScala.foreach { option =>
       if (option.NULL != null) {
+        blockBang(option.errorCapturingNot)
         if (!nullable) {
           throw QueryParsingErrors.duplicateTableColumnDescriptor(
             option, name, "NOT NULL")
@@ -3426,6 +3457,7 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
    */
   override def visitCreateTableHeader(
       ctx: CreateTableHeaderContext): TableHeader = withOrigin(ctx) {
+    blockBang(ctx.errorCapturingNot)
     val temporary = ctx.TEMPORARY != null
     val ifNotExists = ctx.EXISTS != null
     if (temporary && ifNotExists) {
@@ -3602,6 +3634,8 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
       properties += PROP_LOCATION -> _
     }
 
+    blockBang(ctx.errorCapturingNot)
+
     CreateNamespace(
       withIdentClause(ctx.identifierReference, UnresolvedNamespace(_)),
       ctx.EXISTS != null,
@@ -4209,7 +4243,10 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
     var colPosition: Option[ColPositionContext] = None
     val columnName = name.last
     ctx.colDefinitionDescriptorWithPosition.asScala.foreach { option =>
+      blockBang(option.errorCapturingNot)
+
       if (option.NULL != null) {
+        blockBang(option.errorCapturingNot)
         if (!nullable) {
           throw QueryParsingErrors.duplicateTableColumnDescriptor(
             option, columnName, "NOT NULL", isCreate = false)
@@ -4413,6 +4450,8 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
         }
         var commentSpec: Option[CommentSpecContext] = None
         colType.colDefinitionDescriptorWithPosition.asScala.foreach { opt =>
+          blockBang(opt.errorCapturingNot)
+
           if (opt.NULL != null) {
             throw QueryParsingErrors.operationInHiveStyleCommandUnsupportedError(
               "NOT NULL", "REPLACE COLUMNS", ctx)
@@ -4864,6 +4903,7 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
       val location = Option(splCtx.locationSpec).map(visitLocationSpec)
       UnresolvedPartitionSpec(spec, location)
     }
+    blockBang(ctx.errorCapturingNot)
     AddPartitions(
       createUnresolvedTable(
         ctx.identifierReference,
@@ -5108,6 +5148,8 @@ class AstBuilder extends DataTypeAstBuilder with SQLConfHelper with Logging {
       .map(x => (Option(x.options).map(visitPropertyKeyValues).getOrElse(Map.empty))).toSeq
     val options = Option(ctx.options).map(visitPropertyKeyValues).getOrElse(Map.empty)
 
+    blockBang(ctx.errorCapturingNot)
+
     CreateIndex(
       createUnresolvedTable(ctx.identifierReference, "CREATE INDEX"),
       indexName,
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
index 1c7ae3d0bfa..428ad052eba 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala
@@ -4821,6 +4821,16 @@ object SQLConf {
     .booleanConf
     .createWithDefault(false)
 
+  val LEGACY_BANG_EQUALS_NOT = buildConf("spark.sql.legacy.bangEqualsNot")
+    .internal()
+    .doc("When set to true, '!' is a lexical equivalent for 'NOT'. That is '!' can be used " +
+      "outside of the documented prefix usage in a logical expression." +
+      "Examples are: `expr ! IN (1, 2)` and `expr ! BETWEEN 1 AND 2`, but also `IF ! EXISTS`."
+    )
+    .version("4.0.0")
+    .booleanConf
+    .createWithDefault(false)
+
   /**
    * Holds information about keys that have been deprecated.
    *
diff --git a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/parser/ErrorParserSuite.scala b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/parser/ErrorParserSuite.scala
index 6fb37ae33fa..0130ae72a03 100644
--- a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/parser/ErrorParserSuite.scala
+++ b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/parser/ErrorParserSuite.scala
@@ -323,4 +323,37 @@ class ErrorParserSuite extends AnalysisTest {
       parameters = Map("type" -> "\"CHARACTER\""),
       context = ExpectedContext(fragment = "Character", start = 19, stop = 27))
   }
+
+  test("'!' where only NOT should be allowed") {
+    checkError(
+      exception = parseException("SELECT 1 ! IN (2)"),
+      errorClass = "SYNTAX_DISCONTINUED.BANG_EQUALS_NOT",
+      parameters = Map("clause" -> "!"),
+      context = ExpectedContext(fragment = "!", start = 9, stop = 9))
+    checkError(
+      exception = parseException("SELECT 'a' ! LIKE 'b'"),
+      errorClass = "SYNTAX_DISCONTINUED.BANG_EQUALS_NOT",
+      parameters = Map("clause" -> "!"),
+      context = ExpectedContext(fragment = "!", start = 11, stop = 11))
+    checkError(
+      exception = parseException("SELECT 1 ! BETWEEN 1 AND 2"),
+      errorClass = "SYNTAX_DISCONTINUED.BANG_EQUALS_NOT",
+      parameters = Map("clause" -> "!"),
+      context = ExpectedContext(fragment = "!", start = 9, stop = 9))
+    checkError(
+      exception = parseException("SELECT 1 IS ! NULL"),
+      errorClass = "SYNTAX_DISCONTINUED.BANG_EQUALS_NOT",
+      parameters = Map("clause" -> "!"),
+      context = ExpectedContext(fragment = "!", start = 12, stop = 12))
+    checkError(
+      exception = parseException("CREATE TABLE IF ! EXISTS t(c1 INT)"),
+      errorClass = "SYNTAX_DISCONTINUED.BANG_EQUALS_NOT",
+      parameters = Map("clause" -> "!"),
+      context = ExpectedContext(fragment = "!", start = 16, stop = 16))
+    checkError(
+      exception = parseException("CREATE TABLE t(c1 INT ! NULL)"),
+      errorClass = "SYNTAX_DISCONTINUED.BANG_EQUALS_NOT",
+      parameters = Map("clause" -> "!"),
+      context = ExpectedContext(fragment = "!", start = 22, stop = 22))
+  }
 }
diff --git a/sql/core/src/test/resources/sql-tests/analyzer-results/predicate-functions.sql.out b/sql/core/src/test/resources/sql-tests/analyzer-results/predicate-functions.sql.out
index 772e643027b..7e720995c44 100644
--- a/sql/core/src/test/resources/sql-tests/analyzer-results/predicate-functions.sql.out
+++ b/sql/core/src/test/resources/sql-tests/analyzer-results/predicate-functions.sql.out
@@ -1,4 +1,151 @@
 -- Automatically generated by SQLQueryTestSuite
+-- !query
+select not true
+-- !query analysis
+Project [NOT true AS (NOT true)#x]
++- OneRowRelation
+
+
+-- !query
+select ! true
+-- !query analysis
+Project [NOT true AS (NOT true)#x]
++- OneRowRelation
+
+
+-- !query
+select not null::boolean
+-- !query analysis
+Project [NOT cast(null as boolean) AS (NOT CAST(NULL AS BOOLEAN))#x]
++- OneRowRelation
+
+
+-- !query
+select true and true
+-- !query analysis
+Project [(true AND true) AS (true AND true)#x]
++- OneRowRelation
+
+
+-- !query
+select true and false
+-- !query analysis
+Project [(true AND false) AS (true AND false)#x]
++- OneRowRelation
+
+
+-- !query
+select false and true
+-- !query analysis
+Project [(false AND true) AS (false AND true)#x]
++- OneRowRelation
+
+
+-- !query
+select false and false
+-- !query analysis
+Project [(false AND false) AS (false AND false)#x]
++- OneRowRelation
+
+
+-- !query
+select true and null::boolean
+-- !query analysis
+Project [(true AND cast(null as boolean)) AS (true AND CAST(NULL AS BOOLEAN))#x]
++- OneRowRelation
+
+
+-- !query
+select false and null::boolean
+-- !query analysis
+Project [(false AND cast(null as boolean)) AS (false AND CAST(NULL AS BOOLEAN))#x]
++- OneRowRelation
+
+
+-- !query
+select null::boolean and true
+-- !query analysis
+Project [(cast(null as boolean) AND true) AS (CAST(NULL AS BOOLEAN) AND true)#x]
++- OneRowRelation
+
+
+-- !query
+select null::boolean and false
+-- !query analysis
+Project [(cast(null as boolean) AND false) AS (CAST(NULL AS BOOLEAN) AND false)#x]
++- OneRowRelation
+
+
+-- !query
+select null::boolean and null::boolean
+-- !query analysis
+Project [(cast(null as boolean) AND cast(null as boolean)) AS (CAST(NULL AS BOOLEAN) AND CAST(NULL AS BOOLEAN))#x]
++- OneRowRelation
+
+
+-- !query
+select true or true
+-- !query analysis
+Project [(true OR true) AS (true OR true)#x]
++- OneRowRelation
+
+
+-- !query
+select true or false
+-- !query analysis
+Project [(true OR false) AS (true OR false)#x]
++- OneRowRelation
+
+
+-- !query
+select false or true
+-- !query analysis
+Project [(false OR true) AS (false OR true)#x]
++- OneRowRelation
+
+
+-- !query
+select false or false
+-- !query analysis
+Project [(false OR false) AS (false OR false)#x]
++- OneRowRelation
+
+
+-- !query
+select true or null::boolean
+-- !query analysis
+Project [(true OR cast(null as boolean)) AS (true OR CAST(NULL AS BOOLEAN))#x]
++- OneRowRelation
+
+
+-- !query
+select false or null::boolean
+-- !query analysis
+Project [(false OR cast(null as boolean)) AS (false OR CAST(NULL AS BOOLEAN))#x]
++- OneRowRelation
+
+
+-- !query
+select null::boolean or true
+-- !query analysis
+Project [(cast(null as boolean) OR true) AS (CAST(NULL AS BOOLEAN) OR true)#x]
++- OneRowRelation
+
+
+-- !query
+select null::boolean or false
+-- !query analysis
+Project [(cast(null as boolean) OR false) AS (CAST(NULL AS BOOLEAN) OR false)#x]
++- OneRowRelation
+
+
+-- !query
+select null::boolean or null::boolean
+-- !query analysis
+Project [(cast(null as boolean) OR cast(null as boolean)) AS (CAST(NULL AS BOOLEAN) OR CAST(NULL AS BOOLEAN))#x]
++- OneRowRelation
+
+
 -- !query
 select 1 = 1
 -- !query analysis
@@ -450,3 +597,50 @@ Project [NOT between(to_timestamp(2022-12-26 00:00:01, None, TimestampType, Some
 select rand(123) not between 0.1 AND 0.2
 -- !query analysis
 [Analyzer test output redacted due to nondeterminism]
+
+
+-- !query
+set spark.sql.legacy.bangEqualsNot=true
+-- !query analysis
+SetCommand (spark.sql.legacy.bangEqualsNot,Some(true))
+
+
+-- !query
+select 1 ! between 0 and 2
+-- !query analysis
+Project [NOT between(1, 0, 2) AS (NOT between(1, 0, 2))#x]
++- OneRowRelation
+
+
+-- !query
+select 1 ! in (3, 4)
+-- !query analysis
+Project [NOT 1 IN (3,4) AS (NOT (1 IN (3, 4)))#x]
++- OneRowRelation
+
+
+-- !query
+select 'hello' ! like 'world'
+-- !query analysis
+Project [NOT hello LIKE world AS (NOT hello LIKE world)#x]
++- OneRowRelation
+
+
+-- !query
+select 1 is ! null
+-- !query analysis
+Project [isnotnull(1) AS (1 IS NOT NULL)#x]
++- OneRowRelation
+
+
+-- !query
+select false is ! true
+-- !query analysis
+Project [NOT (false <=> true) AS (NOT (false <=> true))#x]
++- OneRowRelation
+
+
+-- !query
+set spark.sql.legacy.bangEqualsNot=false
+-- !query analysis
+SetCommand (spark.sql.legacy.bangEqualsNot,Some(false))
diff --git a/sql/core/src/test/resources/sql-tests/inputs/predicate-functions.sql b/sql/core/src/test/resources/sql-tests/inputs/predicate-functions.sql
index 6f64b0da650..195db17a3a1 100644
--- a/sql/core/src/test/resources/sql-tests/inputs/predicate-functions.sql
+++ b/sql/core/src/test/resources/sql-tests/inputs/predicate-functions.sql
@@ -1,3 +1,30 @@
+-- NOT
+select not true;
+select ! true;
+select not null::boolean;
+
+-- AND
+select true and true;
+select true and false;
+select false and true;
+select false and false;
+select true and null::boolean;
+select false and null::boolean;
+select null::boolean and true;
+select null::boolean and false;
+select null::boolean and null::boolean;
+
+-- OR
+select true or true;
+select true or false;
+select false or true;
+select false or false;
+select true or null::boolean;
+select false or null::boolean;
+select null::boolean or true;
+select null::boolean or false;
+select null::boolean or null::boolean;
+
 -- EqualTo
 select 1 = 1;
 select 1 = '1';
@@ -82,3 +109,12 @@ select 2.0 not between '1.0' and '3.0';
 select 'b' not between 'a' and 'c';
 select to_timestamp('2022-12-26 00:00:01') not between to_date('2022-03-01') and to_date('2022-12-31');
 select rand(123) not between 0.1 AND 0.2;
+
+-- Sanity test for legacy flag equating ! with NOT
+set spark.sql.legacy.bangEqualsNot=true;
+select 1 ! between 0 and 2;
+select 1 ! in (3, 4);
+select 'hello' ! like 'world';
+select 1 is ! null;
+select false is ! true;
+set spark.sql.legacy.bangEqualsNot=false;
diff --git a/sql/core/src/test/resources/sql-tests/results/predicate-functions.sql.out b/sql/core/src/test/resources/sql-tests/results/predicate-functions.sql.out
index 71c342054ae..5b97f2a27b8 100644
--- a/sql/core/src/test/resources/sql-tests/results/predicate-functions.sql.out
+++ b/sql/core/src/test/resources/sql-tests/results/predicate-functions.sql.out
@@ -1,4 +1,172 @@
 -- Automatically generated by SQLQueryTestSuite
+-- !query
+select not true
+-- !query schema
+struct<(NOT true):boolean>
+-- !query output
+false
+
+
+-- !query
+select ! true
+-- !query schema
+struct<(NOT true):boolean>
+-- !query output
+false
+
+
+-- !query
+select not null::boolean
+-- !query schema
+struct<(NOT CAST(NULL AS BOOLEAN)):boolean>
+-- !query output
+NULL
+
+
+-- !query
+select true and true
+-- !query schema
+struct<(true AND true):boolean>
+-- !query output
+true
+
+
+-- !query
+select true and false
+-- !query schema
+struct<(true AND false):boolean>
+-- !query output
+false
+
+
+-- !query
+select false and true
+-- !query schema
+struct<(false AND true):boolean>
+-- !query output
+false
+
+
+-- !query
+select false and false
+-- !query schema
+struct<(false AND false):boolean>
+-- !query output
+false
+
+
+-- !query
+select true and null::boolean
+-- !query schema
+struct<(true AND CAST(NULL AS BOOLEAN)):boolean>
+-- !query output
+NULL
+
+
+-- !query
+select false and null::boolean
+-- !query schema
+struct<(false AND CAST(NULL AS BOOLEAN)):boolean>
+-- !query output
+false
+
+
+-- !query
+select null::boolean and true
+-- !query schema
+struct<(CAST(NULL AS BOOLEAN) AND true):boolean>
+-- !query output
+NULL
+
+
+-- !query
+select null::boolean and false
+-- !query schema
+struct<(CAST(NULL AS BOOLEAN) AND false):boolean>
+-- !query output
+false
+
+
+-- !query
+select null::boolean and null::boolean
+-- !query schema
+struct<(CAST(NULL AS BOOLEAN) AND CAST(NULL AS BOOLEAN)):boolean>
+-- !query output
+NULL
+
+
+-- !query
+select true or true
+-- !query schema
+struct<(true OR true):boolean>
+-- !query output
+true
+
+
+-- !query
+select true or false
+-- !query schema
+struct<(true OR false):boolean>
+-- !query output
+true
+
+
+-- !query
+select false or true
+-- !query schema
+struct<(false OR true):boolean>
+-- !query output
+true
+
+
+-- !query
+select false or false
+-- !query schema
+struct<(false OR false):boolean>
+-- !query output
+false
+
+
+-- !query
+select true or null::boolean
+-- !query schema
+struct<(true OR CAST(NULL AS BOOLEAN)):boolean>
+-- !query output
+true
+
+
+-- !query
+select false or null::boolean
+-- !query schema
+struct<(false OR CAST(NULL AS BOOLEAN)):boolean>
+-- !query output
+NULL
+
+
+-- !query
+select null::boolean or true
+-- !query schema
+struct<(CAST(NULL AS BOOLEAN) OR true):boolean>
+-- !query output
+true
+
+
+-- !query
+select null::boolean or false
+-- !query schema
+struct<(CAST(NULL AS BOOLEAN) OR false):boolean>
+-- !query output
+NULL
+
+
+-- !query
+select null::boolean or null::boolean
+-- !query schema
+struct<(CAST(NULL AS BOOLEAN) OR CAST(NULL AS BOOLEAN)):boolean>
+-- !query output
+NULL
+
+
 -- !query
 select 1 = 1
 -- !query schema
@@ -517,3 +685,59 @@ select rand(123) not between 0.1 AND 0.2
 struct<(NOT between(rand(123), 0.1, 0.2)):boolean>
 -- !query output
 false
+
+
+-- !query
+set spark.sql.legacy.bangEqualsNot=true
+-- !query schema
+struct<key:string,value:string>
+-- !query output
+spark.sql.legacy.bangEqualsNot	true
+
+
+-- !query
+select 1 ! between 0 and 2
+-- !query schema
+struct<(NOT between(1, 0, 2)):boolean>
+-- !query output
+false
+
+
+-- !query
+select 1 ! in (3, 4)
+-- !query schema
+struct<(NOT (1 IN (3, 4))):boolean>
+-- !query output
+true
+
+
+-- !query
+select 'hello' ! like 'world'
+-- !query schema
+struct<(NOT hello LIKE world):boolean>
+-- !query output
+true
+
+
+-- !query
+select 1 is ! null
+-- !query schema
+struct<(1 IS NOT NULL):boolean>
+-- !query output
+true
+
+
+-- !query
+select false is ! true
+-- !query schema
+struct<(NOT (false <=> true)):boolean>
+-- !query output
+true
+
+
+-- !query
+set spark.sql.legacy.bangEqualsNot=false
+-- !query schema
+struct<key:string,value:string>
+-- !query output
+spark.sql.legacy.bangEqualsNot	false
