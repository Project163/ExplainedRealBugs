diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/v2AlterTableCommands.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/v2AlterTableCommands.scala
index c0a5f0dabc0..a0def801ee6 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/v2AlterTableCommands.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/v2AlterTableCommands.scala
@@ -210,7 +210,7 @@ case class AlterColumnSpec(
     newPosition: Option[FieldPosition],
     newDefaultExpression: Option[String]) extends Expression with Unevaluable {
 
-  override def children: Seq[Expression] = Seq(column)
+  override def children: Seq[Expression] = Seq(column) ++ newPosition.toSeq
   override def nullable: Boolean = false
   override def dataType: DataType = throw new UnresolvedException("dataType")
   override protected def withNewChildrenInternal(newChildren: IndexedSeq[Expression]): Expression =
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/execution/command/PlanResolutionSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/execution/command/PlanResolutionSuite.scala
index c221cc9104b..eef1f55b6a1 100644
--- a/sql/core/src/test/scala/org/apache/spark/sql/execution/command/PlanResolutionSuite.scala
+++ b/sql/core/src/test/scala/org/apache/spark/sql/execution/command/PlanResolutionSuite.scala
@@ -27,7 +27,7 @@ import org.mockito.invocation.InvocationOnMock
 import org.apache.spark.SparkUnsupportedOperationException
 import org.apache.spark.sql.{AnalysisException, SaveMode}
 import org.apache.spark.sql.catalyst.{AliasIdentifier, TableIdentifier}
-import org.apache.spark.sql.catalyst.analysis.{AnalysisContext, AnalysisTest, Analyzer, EmptyFunctionRegistry, NoSuchTableException, ResolvedFieldName, ResolvedIdentifier, ResolvedTable, ResolveSessionCatalog, UnresolvedAttribute, UnresolvedInlineTable, UnresolvedRelation, UnresolvedSubqueryColumnAliases, UnresolvedTable}
+import org.apache.spark.sql.catalyst.analysis.{AnalysisContext, AnalysisTest, Analyzer, EmptyFunctionRegistry, NoSuchTableException, ResolvedFieldName, ResolvedFieldPosition, ResolvedIdentifier, ResolvedTable, ResolveSessionCatalog, UnresolvedAttribute, UnresolvedFieldPosition, UnresolvedInlineTable, UnresolvedRelation, UnresolvedSubqueryColumnAliases, UnresolvedTable}
 import org.apache.spark.sql.catalyst.catalog.{BucketSpec, CatalogStorageFormat, CatalogTable, CatalogTableType, InMemoryCatalog, SessionCatalog, TempVariableManager}
 import org.apache.spark.sql.catalyst.expressions.{AttributeReference, Cast, EqualTo, Expression, InSubquery, IntegerLiteral, ListQuery, Literal, StringLiteral}
 import org.apache.spark.sql.catalyst.expressions.objects.StaticInvoke
@@ -36,7 +36,7 @@ import org.apache.spark.sql.catalyst.plans.logical.{AlterColumns, AlterColumnSpe
 import org.apache.spark.sql.catalyst.rules.Rule
 import org.apache.spark.sql.catalyst.util.TypeUtils.toSQLId
 import org.apache.spark.sql.connector.FakeV2Provider
-import org.apache.spark.sql.connector.catalog.{CatalogManager, Column, ColumnDefaultValue, Identifier, SupportsDelete, Table, TableCapability, TableCatalog, TableWritePrivilege, V1Table}
+import org.apache.spark.sql.connector.catalog.{CatalogManager, Column, ColumnDefaultValue, Identifier, SupportsDelete, Table, TableCapability, TableCatalog, TableChange, TableWritePrivilege, V1Table}
 import org.apache.spark.sql.connector.catalog.CatalogManager.SESSION_CATALOG_NAME
 import org.apache.spark.sql.connector.expressions.{LiteralValue, Transform}
 import org.apache.spark.sql.errors.QueryExecutionErrors
@@ -1389,7 +1389,7 @@ class PlanResolutionSuite extends SharedSparkSession with AnalysisTest {
                   None,
                   None))) =>
               assert(column.name == Seq("i"))
-            case _ => fail("expect AlterTableAlterColumn")
+            case _ => fail("expect AlterColumns")
           }
 
           parsed2 match {
@@ -1403,7 +1403,7 @@ class PlanResolutionSuite extends SharedSparkSession with AnalysisTest {
                   None,
                   None))) =>
               assert(column.name == Seq("i"))
-            case _ => fail("expect AlterTableAlterColumn")
+            case _ => fail("expect AlterColumns")
           }
 
           val parsed3 = parseAndResolve(sql3)
@@ -1427,7 +1427,7 @@ class PlanResolutionSuite extends SharedSparkSession with AnalysisTest {
                     Some("'value'")))) =>
               assert(column1.name == Seq("i"))
               assert(column2.name == Seq("s"))
-            case _ => fail("expect AlterTableAlterColumn")
+            case _ => fail("expect AlterColumns")
           }
         }
     }
@@ -1441,6 +1441,25 @@ class PlanResolutionSuite extends SharedSparkSession with AnalysisTest {
     comparePlans(parsed, expected)
   }
 
+  test("SPARK-51010: AlterColumnSpec should correctly report resolved status") {
+    val unresolvedSpec = AlterColumnSpec(
+      ResolvedFieldName(Seq("test"), StructField("i", IntegerType)),
+      newDataType = None,
+      newNullability = None,
+      newComment = None,
+      newPosition = Some(UnresolvedFieldPosition(TableChange.ColumnPosition.first)),
+      newDefaultExpression = None)
+    assert(!unresolvedSpec.resolved)
+
+    val partiallyResolvedSpec = unresolvedSpec.copy(
+      column = ResolvedFieldName(Seq("test"), StructField("i", IntegerType)))
+    assert(!partiallyResolvedSpec.resolved)
+
+    val resolvedSpec = partiallyResolvedSpec.copy(
+      newPosition = Some(ResolvedFieldPosition(TableChange.ColumnPosition.first)))
+    assert(resolvedSpec.resolved)
+  }
+
   test("alter table: alter column action is not specified") {
     val sql = "ALTER TABLE v1Table ALTER COLUMN i"
     checkError(
