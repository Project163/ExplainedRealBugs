diff --git a/python/pyspark/sql/connect/client/core.py b/python/pyspark/sql/connect/client/core.py
index e36b7d74a78..0b502494f78 100644
--- a/python/pyspark/sql/connect/client/core.py
+++ b/python/pyspark/sql/connect/client/core.py
@@ -1520,20 +1520,6 @@ class SparkConnectClient(object):
         except grpc.RpcError:
             return None
 
-    def _display_server_stack_trace(self) -> bool:
-        from pyspark.sql.connect.conf import RuntimeConf
-
-        conf = RuntimeConf(self)
-        try:
-            if conf.get("spark.sql.connect.serverStacktrace.enabled") == "true":
-                return True
-            return conf.get("spark.sql.pyspark.jvmStacktrace.enabled") == "true"
-        except Exception as e:  # noqa: F841
-            # Falls back to true if an exception occurs during reading the config.
-            # Otherwise, it will recursively try to get the conf when it consistently
-            # fails, ending up with `RecursionError`.
-            return True
-
     def _handle_rpc_error(self, rpc_error: grpc.RpcError) -> NoReturn:
         """
         Error handling helper for dealing with GRPC Errors. On the server side, certain
@@ -1567,7 +1553,7 @@ class SparkConnectClient(object):
                         info,
                         status.message,
                         self._fetch_enriched_error(info),
-                        self._display_server_stack_trace(),
+                        True,
                     ) from None
 
             raise SparkConnectGrpcException(status.message) from None
