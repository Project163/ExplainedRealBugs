diff --git a/python/pyspark/sql/connect/column.py b/python/pyspark/sql/connect/column.py
index 19ec93151f0..a6d9ca8a2ff 100644
--- a/python/pyspark/sql/connect/column.py
+++ b/python/pyspark/sql/connect/column.py
@@ -461,6 +461,8 @@ class Column:
                     message_parameters={},
                 )
             return self.substr(k.start, k.stop)
+        elif isinstance(k, Column):
+            return Column(UnresolvedExtractValue(self._expr, k._expr))
         else:
             return Column(UnresolvedExtractValue(self._expr, LiteralExpression._from_value(k)))
 
diff --git a/python/pyspark/sql/tests/test_column.py b/python/pyspark/sql/tests/test_column.py
index db6cd321cf2..622c1f7b210 100644
--- a/python/pyspark/sql/tests/test_column.py
+++ b/python/pyspark/sql/tests/test_column.py
@@ -16,7 +16,9 @@
 # limitations under the License.
 #
 
+from itertools import chain
 from pyspark.sql import Column, Row
+from pyspark.sql import functions as sf
 from pyspark.sql.types import StructType, StructField, LongType
 from pyspark.errors import AnalysisException, PySparkTypeError
 from pyspark.testing.sqlutils import ReusedSQLTestCase
@@ -207,6 +209,15 @@ class ColumnTestsMixin:
 
         self.assertTrue("e" not in result["a2"]["d"] and "f" in result["a2"]["d"])
 
+    def test_getitem_column(self):
+        mapping = {"A": "20", "B": "28", "C": "34"}
+        mapping_expr = sf.create_map([sf.lit(x) for x in chain(*mapping.items())])
+        df = self.spark.createDataFrame(
+            data=[["A", "10"], ["B", "14"], ["C", "17"]],
+            schema=["key", "value"],
+        ).withColumn("square_value", mapping_expr[sf.col("key")])
+        self.assertEqual(df.count(), 3)
+
 
 class ColumnTests(ColumnTestsMixin, ReusedSQLTestCase):
     pass
