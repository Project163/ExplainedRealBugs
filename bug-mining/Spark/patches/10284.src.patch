diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ordering.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ordering.scala
index 37a3b3a34e4..c735f5b334b 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ordering.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ordering.scala
@@ -38,6 +38,8 @@ class BaseOrdering extends Ordering[InternalRow] {
  * An interpreted row ordering comparator.
  */
 class InterpretedOrdering(ordering: Seq[SortOrder]) extends BaseOrdering {
+  private val leftEvaluators = ordering.map(_.child)
+  private val rightEvaluators = leftEvaluators.map(_.freshCopyIfContainsStatefulExpression())
   private lazy val physicalDataTypes = ordering.map { order =>
     val dt = order.dataType match {
       case udt: UserDefinedType[_] => udt.sqlType
@@ -54,8 +56,8 @@ class InterpretedOrdering(ordering: Seq[SortOrder]) extends BaseOrdering {
     val size = ordering.size
     while (i < size) {
       val order = ordering(i)
-      val left = order.child.eval(a)
-      val right = order.child.eval(b)
+      val left = leftEvaluators(i).eval(a)
+      val right = rightEvaluators(i).eval(b)
 
       if (left == null && right == null) {
         // Both null, continue looking.
diff --git a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/OrderingSuite.scala b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/OrderingSuite.scala
index 52ab9ed46c6..06c8b5ccef6 100644
--- a/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/OrderingSuite.scala
+++ b/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/OrderingSuite.scala
@@ -24,7 +24,9 @@ import org.apache.spark.serializer.KryoSerializer
 import org.apache.spark.sql.{RandomDataGenerator, Row}
 import org.apache.spark.sql.catalyst.{CatalystTypeConverters, InternalRow}
 import org.apache.spark.sql.catalyst.dsl.expressions._
+import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder
 import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, GenerateOrdering, LazilyGeneratedOrdering}
+import org.apache.spark.sql.internal.SQLConf
 import org.apache.spark.sql.types._
 import org.apache.spark.util.ArrayImplicits._
 
@@ -166,4 +168,24 @@ class OrderingSuite extends SparkFunSuite with ExpressionEvalHelper {
     GenerateOrdering.genComparisons(ctx, schema)
     assert(ctx.INPUT_ROW == null)
   }
+
+  test("SPARK-53275: ordering by stateful expressions in interpreted mode") {
+    // even though we explicitly create an InterpretedOrdering below, we still need
+    // to set CODEGEN_FACTORY_MODE to NO_CODEGEN because the ScalaUDF expression will
+    // indirectly create an UnsafeProjection, and we want that UnsafeProjection to be
+    // an InterpretedUnsafeProjection
+    withSQLConf(SQLConf.CODEGEN_FACTORY_MODE.key -> CodegenObjectFactoryMode.NO_CODEGEN.toString) {
+      val udfFunc = (s: String) => s
+      val stringUdf = ScalaUDF(udfFunc, StringType, BoundReference(0, StringType, true) :: Nil,
+        Option(ExpressionEncoder[String]().resolveAndBind()) :: Nil,
+        Some(ExpressionEncoder[String]().resolveAndBind()))
+      val sortOrder = Seq(SortOrder(stringUdf, Ascending))
+      val rowOrdering = new InterpretedOrdering(sortOrder)
+      val rowType = StructType(StructField("col1", StringType, nullable = true) :: Nil)
+      val toCatalyst = CatalystTypeConverters.createToCatalystConverter(rowType)
+      val rowB1 = toCatalyst(Row("B")).asInstanceOf[InternalRow]
+      val rowB2 = toCatalyst(Row("A")).asInstanceOf[InternalRow]
+      assert(rowOrdering.compare(rowB1, rowB2) > 0)
+    }
+  }
 }
