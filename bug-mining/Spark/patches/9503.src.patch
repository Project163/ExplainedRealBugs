diff --git a/python/docs/source/migration_guide/pyspark_upgrade.rst b/python/docs/source/migration_guide/pyspark_upgrade.rst
index 49872fb197a..9ef04814ef8 100644
--- a/python/docs/source/migration_guide/pyspark_upgrade.rst
+++ b/python/docs/source/migration_guide/pyspark_upgrade.rst
@@ -68,6 +68,7 @@ Upgrading from PySpark 3.5 to 4.0
 * In Spark 4.0, ``DatatimeIndex.week`` and ``DatatimeIndex.weekofyear`` have been removed from Pandas API on Spark, use ``DatetimeIndex.isocalendar().week`` instead.
 * In Spark 4.0, ``Series.dt.week`` and ``Series.dt.weekofyear`` have been removed from Pandas API on Spark, use ``Series.dt.isocalendar().week`` instead.
 * In Spark 4.0, when applying ``astype`` to a decimal type object, the existing missing value is changed to ``True`` instead of ``False`` from Pandas API on Spark.
+* In Spark 4.0, ``pyspark.testing.assertPandasOnSparkEqual`` has been removed from Pandas API on Spark, use ``pyspark.pandas.testing.assert_frame_equal`` instead.
 
 
 
diff --git a/python/docs/source/reference/pyspark.testing.rst b/python/docs/source/reference/pyspark.testing.rst
index 96b0c72a7bb..7a6b6cc0d70 100644
--- a/python/docs/source/reference/pyspark.testing.rst
+++ b/python/docs/source/reference/pyspark.testing.rst
@@ -26,5 +26,4 @@ Testing
     :toctree: api/
 
     assertDataFrameEqual
-    assertPandasOnSparkEqual
     assertSchemaEqual
diff --git a/python/pyspark/pandas/tests/test_utils.py b/python/pyspark/pandas/tests/test_utils.py
index 37fba9a9c67..c763d7401b3 100644
--- a/python/pyspark/pandas/tests/test_utils.py
+++ b/python/pyspark/pandas/tests/test_utils.py
@@ -27,7 +27,6 @@ from pyspark.pandas.utils import (
 )
 from pyspark.testing.pandasutils import (
     PandasOnSparkTestCase,
-    assertPandasOnSparkEqual,
     _assert_pandas_equal,
     _assert_pandas_almost_equal,
 )
@@ -110,74 +109,6 @@ class UtilsTestsMixin:
         with self.assertRaisesRegex(IndexError, err_msg):
             validate_index_loc(psidx, -4)
 
-    def test_assert_df_assert_pandas_on_spark_equal(self):
-        import pyspark.pandas as ps
-
-        psdf1 = ps.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})
-        psdf2 = ps.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})
-
-        assertPandasOnSparkEqual(psdf1, psdf2, checkRowOrder=False)
-        assertPandasOnSparkEqual(psdf1, psdf2, checkRowOrder=True)
-
-    def test_assert_pandas_on_spark_equal_ignore_order(self):
-        import pyspark.pandas as ps
-
-        psdf1 = ps.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})
-        psdf2 = ps.DataFrame({"a": [2, 1, 3], "b": [5, 4, 6], "c": [8, 7, 9]})
-
-        assertPandasOnSparkEqual(psdf1, psdf2, checkRowOrder=False)
-
-    def test_assert_series_assert_pandas_on_spark_equal(self):
-        import pyspark.pandas as ps
-
-        s1 = ps.Series([212.32, 100.0001])
-        s2 = ps.Series([212.32, 100.0001])
-
-        assertPandasOnSparkEqual(s1, s2, checkExact=False)
-
-    def test_assert_index_assert_pandas_on_spark_equal(self):
-        import pyspark.pandas as ps
-
-        s1 = ps.Index([212.300001, 100.000])
-        s2 = ps.Index([212.3, 100.0001])
-
-        assertPandasOnSparkEqual(s1, s2, almost=True)
-
-    def test_assert_error_assert_pandas_on_spark_equal(self):
-        import pyspark.pandas as ps
-
-        list1 = [10, 20, 30]
-        list2 = [10, 20, 30]
-
-        with self.assertRaises(PySparkAssertionError) as pe:
-            assertPandasOnSparkEqual(list1, list2)
-
-        self.check_error(
-            exception=pe.exception,
-            error_class="INVALID_TYPE_DF_EQUALITY_ARG",
-            message_parameters={
-                "expected_type": f"{ps.DataFrame.__name__}, "
-                f"{ps.Series.__name__}, "
-                f"{ps.Index.__name__}",
-                "arg_name": "actual",
-                "actual_type": type(list1),
-            },
-        )
-
-    def test_assert_None_assert_pandas_on_spark_equal(self):
-        psdf1 = None
-        psdf2 = None
-
-        assertPandasOnSparkEqual(psdf1, psdf2)
-
-    def test_assert_empty_assert_pandas_on_spark_equal(self):
-        import pyspark.pandas as ps
-
-        psdf1 = ps.DataFrame()
-        psdf2 = ps.DataFrame()
-
-        assertPandasOnSparkEqual(psdf1, psdf2)
-
     def test_dataframe_error_assert_pandas_equal(self):
         pdf1 = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]}, index=[0, 1, 3])
         pdf2 = pd.DataFrame({"a": [1, 3, 3], "b": [4, 5, 6]}, index=[0, 1, 3])
@@ -252,26 +183,6 @@ class UtilsTestsMixin:
             },
         )
 
-    def test_dataframe_error_assert_pandas_on_spark_almost_equal(self):
-        import pyspark.pandas as ps
-
-        psdf1 = ps.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]})
-        psdf2 = ps.DataFrame({"a": [1, 2], "b": [4, 5], "c": [7, 8]})
-
-        with self.assertRaises(PySparkAssertionError) as pe:
-            assertPandasOnSparkEqual(psdf1, psdf2, almost=True)
-
-        self.check_error(
-            exception=pe.exception,
-            error_class="DIFFERENT_PANDAS_DATAFRAME",
-            message_parameters={
-                "left": psdf1.to_string(),
-                "left_dtype": str(psdf1.dtypes),
-                "right": psdf2.to_string(),
-                "right_dtype": str(psdf2.dtypes),
-            },
-        )
-
 
 class TestClassForLazyProp:
     def __init__(self):
diff --git a/python/pyspark/testing/__init__.py b/python/pyspark/testing/__init__.py
index 57c206629a8..88853e925f8 100644
--- a/python/pyspark/testing/__init__.py
+++ b/python/pyspark/testing/__init__.py
@@ -16,6 +16,4 @@
 #
 from pyspark.testing.utils import assertDataFrameEqual, assertSchemaEqual
 
-from pyspark.testing.pandasutils import assertPandasOnSparkEqual
-
-__all__ = ["assertDataFrameEqual", "assertSchemaEqual", "assertPandasOnSparkEqual"]
+__all__ = ["assertDataFrameEqual", "assertSchemaEqual"]
diff --git a/python/pyspark/testing/pandasutils.py b/python/pyspark/testing/pandasutils.py
index 6c6d10a04db..1d2dc35280e 100644
--- a/python/pyspark/testing/pandasutils.py
+++ b/python/pyspark/testing/pandasutils.py
@@ -64,9 +64,6 @@ from pyspark.testing.sqlutils import ReusedSQLTestCase
 from pyspark.errors import PySparkAssertionError
 
 
-__all__ = ["assertPandasOnSparkEqual"]
-
-
 def _assert_pandas_equal(
     left: Union[pd.DataFrame, pd.Series, pd.Index],
     right: Union[pd.DataFrame, pd.Series, pd.Index],
@@ -326,130 +323,6 @@ def _assert_pandas_almost_equal(
             )
 
 
-def assertPandasOnSparkEqual(
-    actual: Union[DataFrame, Series, Index],
-    expected: Union[DataFrame, pd.DataFrame, Series, pd.Series, Index, pd.Index],
-    checkExact: bool = True,
-    almost: bool = False,
-    rtol: float = 1e-5,
-    atol: float = 1e-8,
-    checkRowOrder: bool = True,
-):
-    r"""
-    A util function to assert equality between actual (pandas-on-Spark object) and expected
-    (pandas-on-Spark or pandas object).
-
-    .. versionadded:: 3.5.0
-
-    .. deprecated:: 3.5.1
-        `assertPandasOnSparkEqual` will be removed in Spark 4.0.0.
-        Use `ps.testing.assert_frame_equal`, `ps.testing.assert_series_equal`
-        and `ps.testing.assert_index_equal` instead.
-
-    Parameters
-    ----------
-    actual: pandas-on-Spark DataFrame, Series, or Index
-        The object that is being compared or tested.
-    expected: pandas-on-Spark or pandas DataFrame, Series, or Index
-        The expected object, for comparison with the actual result.
-    checkExact: bool, optional
-        A flag indicating whether to compare exact equality.
-        If set to 'True' (default), the data is compared exactly.
-        If set to 'False', the data is compared less precisely, following pandas assert_frame_equal
-        approximate comparison (see documentation for more details).
-    almost: bool, optional
-        A flag indicating whether to use unittest `assertAlmostEqual` or `assertEqual`.
-        If set to 'True', the comparison is delegated to `unittest`'s `assertAlmostEqual`
-        (see documentation for more details).
-        If set to 'False' (default), the data is compared exactly with `unittest`'s
-        `assertEqual`.
-    rtol : float, optional
-        The relative tolerance, used in asserting almost equality for float values in actual
-        and expected. Set to 1e-5 by default. (See Notes)
-    atol : float, optional
-        The absolute tolerance, used in asserting almost equality for float values in actual
-        and expected. Set to 1e-8 by default. (See Notes)
-    checkRowOrder : bool, optional
-        A flag indicating whether the order of rows should be considered in the comparison.
-        If set to `False`, the row order is not taken into account.
-        If set to `True` (default), the order of rows will be checked during comparison.
-        (See Notes)
-
-    Notes
-    -----
-    For `checkRowOrder`, note that pandas-on-Spark DataFrame ordering is non-deterministic, unless
-    explicitly sorted.
-
-    When `almost` is set to True, approximate equality will be asserted, where two values
-    a and b are approximately equal if they satisfy the following formula:
-
-    ``absolute(a - b) <= (atol + rtol * absolute(b))``.
-
-    Examples
-    --------
-    >>> import pyspark.pandas as ps
-    >>> psdf1 = ps.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})
-    >>> psdf2 = ps.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})
-    >>> assertPandasOnSparkEqual(psdf1, psdf2)  # pass, ps.DataFrames are equal
-    >>> s1 = ps.Series([212.32, 100.0001])
-    >>> s2 = ps.Series([212.32, 100.0])
-    >>> assertPandasOnSparkEqual(s1, s2, checkExact=False)  # pass, ps.Series are approx equal
-    >>> s1 = ps.Index([212.300001, 100.000])
-    >>> s2 = ps.Index([212.3, 100.0001])
-    >>> assertPandasOnSparkEqual(s1, s2, almost=True)  # pass, ps.Index obj are almost equal
-    """
-    warnings.warn(
-        "`assertPandasOnSparkEqual` will be removed in Spark 4.0.0. "
-        "Use `ps.testing.assert_frame_equal`, `ps.testing.assert_series_equal` "
-        "and `ps.testing.assert_index_equal` instead.",
-        FutureWarning,
-    )
-    if actual is None and expected is None:
-        return True
-    elif actual is None or expected is None:
-        return False
-
-    if not isinstance(actual, (DataFrame, Series, Index)):
-        raise PySparkAssertionError(
-            error_class="INVALID_TYPE_DF_EQUALITY_ARG",
-            message_parameters={
-                "expected_type": f"{DataFrame.__name__}, {Series.__name__}, {Index.__name__}",
-                "arg_name": "actual",
-                "actual_type": type(actual),
-            },
-        )
-    elif not isinstance(expected, (DataFrame, pd.DataFrame, Series, pd.Series, Index, pd.Index)):
-        raise PySparkAssertionError(
-            error_class="INVALID_TYPE_DF_EQUALITY_ARG",
-            message_parameters={
-                "expected_type": f"{DataFrame.__name__}, "
-                f"{pd.DataFrame.__name__}, "
-                f"{Series.__name__}, "
-                f"{pd.Series.__name__}, "
-                f"{Index.__name__}"
-                f"{pd.Index.__name__}, ",
-                "arg_name": "expected",
-                "actual_type": type(expected),
-            },
-        )
-    else:
-        if not isinstance(actual, (pd.DataFrame, pd.Index, pd.Series)):
-            actual = actual.to_pandas()
-        if not isinstance(expected, (pd.DataFrame, pd.Index, pd.Series)):
-            expected = expected.to_pandas()
-
-        if not checkRowOrder:
-            if isinstance(actual, pd.DataFrame) and len(actual.columns) > 0:
-                actual = actual.sort_values(by=actual.columns[0], ignore_index=True)
-            if isinstance(expected, pd.DataFrame) and len(expected.columns) > 0:
-                expected = expected.sort_values(by=expected.columns[0], ignore_index=True)
-
-        if almost:
-            _assert_pandas_almost_equal(actual, expected, rtol=rtol, atol=atol)
-        else:
-            _assert_pandas_equal(actual, expected, checkExact=checkExact)
-
-
 class PandasOnSparkTestUtils:
     def convert_str_to_lambda(self, func: str):
         """
@@ -502,15 +375,53 @@ class PandasOnSparkTestUtils:
 
         # for pandas-on-Spark DataFrames, allow choice to ignore row order
         if isinstance(left, (ps.DataFrame, ps.Series, ps.Index)):
-            return assertPandasOnSparkEqual(
-                left,
-                right,
-                checkExact=check_exact,
-                almost=almost,
-                rtol=rtol,
-                atol=atol,
-                checkRowOrder=check_row_order,
-            )
+            if left is None and right is None:
+                return True
+            elif left is None or right is None:
+                return False
+
+            if not isinstance(left, (DataFrame, Series, Index)):
+                raise PySparkAssertionError(
+                    error_class="INVALID_TYPE_DF_EQUALITY_ARG",
+                    message_parameters={
+                        "expected_type": f"{DataFrame.__name__}, {Series.__name__}, "
+                        f"{Index.__name__}",
+                        "arg_name": "actual",
+                        "actual_type": type(left),
+                    },
+                )
+            elif not isinstance(
+                right, (DataFrame, pd.DataFrame, Series, pd.Series, Index, pd.Index)
+            ):
+                raise PySparkAssertionError(
+                    error_class="INVALID_TYPE_DF_EQUALITY_ARG",
+                    message_parameters={
+                        "expected_type": f"{DataFrame.__name__}, "
+                        f"{pd.DataFrame.__name__}, "
+                        f"{Series.__name__}, "
+                        f"{pd.Series.__name__}, "
+                        f"{Index.__name__}"
+                        f"{pd.Index.__name__}, ",
+                        "arg_name": "expected",
+                        "actual_type": type(right),
+                    },
+                )
+            else:
+                if not isinstance(left, (pd.DataFrame, pd.Index, pd.Series)):
+                    left = left.to_pandas()
+                if not isinstance(right, (pd.DataFrame, pd.Index, pd.Series)):
+                    right = right.to_pandas()
+
+                if not check_row_order:
+                    if isinstance(left, pd.DataFrame) and len(left.columns) > 0:
+                        left = left.sort_values(by=left.columns[0], ignore_index=True)
+                    if isinstance(right, pd.DataFrame) and len(right.columns) > 0:
+                        right = right.sort_values(by=right.columns[0], ignore_index=True)
+
+                if almost:
+                    _assert_pandas_almost_equal(left, right, rtol=rtol, atol=atol)
+                else:
+                    _assert_pandas_equal(left, right, checkExact=check_exact)
 
         lobj = self._to_pandas(left)
         robj = self._to_pandas(right)
