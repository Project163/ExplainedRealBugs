diff --git a/docs/running-on-yarn.md b/docs/running-on-yarn.md
index 0968fc5ad63..b6701b64c29 100644
--- a/docs/running-on-yarn.md
+++ b/docs/running-on-yarn.md
@@ -189,6 +189,13 @@ Most of the configs are the same for Spark on YARN as for other deployment modes
   In cluster mode, use spark.driver.extraJavaOptions instead.
   </td>
 </tr>
+<tr>
+  <td><code>spark.yarn.am.extraLibraryPath</code></td>
+  <td>(none)</td>
+  <td>
+    Set a special library path to use when launching the application master in client mode.
+  </td>
+</tr>
 <tr>
   <td><code>spark.yarn.maxAppAttempts</code></td>
   <td>yarn.resourcemanager.am.max-attempts in YARN</td>
diff --git a/yarn/src/main/scala/org/apache/spark/deploy/yarn/Client.scala b/yarn/src/main/scala/org/apache/spark/deploy/yarn/Client.scala
index b945395f24e..31ab6b491ec 100644
--- a/yarn/src/main/scala/org/apache/spark/deploy/yarn/Client.scala
+++ b/yarn/src/main/scala/org/apache/spark/deploy/yarn/Client.scala
@@ -544,6 +544,10 @@ private[spark] class Client(
         }
         javaOpts ++= Utils.splitCommandString(opts).map(YarnSparkHadoopUtil.escapeForShell)
       }
+
+      sparkConf.getOption("spark.yarn.am.extraLibraryPath").foreach { paths =>
+        prefixEnv = Some(Utils.libraryPathEnvPrefix(Seq(paths)))
+      }
     }
 
     // For log4j configuration to reference
