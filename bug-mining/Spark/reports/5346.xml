<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:57:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-22516] CSV Read breaks: When &quot;multiLine&quot; = &quot;true&quot;, if &quot;comment&quot; option is set as last line&apos;s first character</title>
                <link>https://issues.apache.org/jira/browse/SPARK-22516</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Try to read attached CSV file with following parse properties,&lt;/p&gt;

&lt;p&gt;scala&amp;gt; *val csvFile = spark.read.option(&quot;header&quot;,&quot;true&quot;).option(&quot;inferSchema&quot;, &quot;true&quot;).option(&quot;parserLib&quot;, &quot;univocity&quot;).option(&quot;comment&quot;, &quot;c&quot;).csv(&quot;hdfs://localhost:8020/test&lt;br/&gt;
CommentChar.csv&quot;);   *                                                                                                                                                        &lt;br/&gt;
csvFile: org.apache.spark.sql.DataFrame = &lt;span class=&quot;error&quot;&gt;&amp;#91;a: string, b: string&amp;#93;&lt;/span&gt;                                                                                                             &lt;/p&gt;

&lt;p&gt;scala&amp;gt; csvFile.show                                                                                                                                                          &lt;br/&gt;
&lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+                                                                                                                                                                    &lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  a&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  b&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+                                                                                                                                                                    &lt;br/&gt;
&lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+   &lt;/p&gt;

&lt;p&gt;&lt;font color=&quot;#8eb021&quot;&gt;&lt;b&gt;Noticed that it works fine.&lt;/b&gt;&lt;/font&gt;&lt;/p&gt;

&lt;p&gt;If we add an option &quot;multiLine&quot; = &quot;true&quot;, it fails with below exception. This happens only if we pass &quot;comment&quot; == input dataset&apos;s last line&apos;s first character&lt;/p&gt;

&lt;p&gt;scala&amp;gt; val csvFile = &lt;b&gt;spark.read.option(&quot;header&quot;,&quot;true&quot;).&lt;font color=&quot;red&quot;&gt;&lt;font color=&quot;#d04437&quot;&gt;&lt;/font&gt;option(&quot;multiLine&quot;,&quot;true&quot;)&lt;/font&gt;&lt;font color=&quot;&quot;&gt;&lt;/font&gt;.option(&quot;inferSchema&quot;, &quot;true&quot;).option(&quot;parserLib&quot;, &quot;univocity&quot;).option(&quot;comment&quot;, &quot;c&quot;).csv(&quot;hdfs://localhost:8020/testCommentChar.csv&quot;);&lt;/b&gt;&lt;br/&gt;
17/11/14 14:26:17 ERROR Executor: Exception in task 0.0 in stage 8.0 (TID 8)&lt;br/&gt;
com.univocity.parsers.common.TextParsingException: java.lang.IllegalArgumentException - Unable to skip 1 lines from line 2. End of input reached&lt;br/&gt;
Parser Configuration: CsvParserSettings:&lt;br/&gt;
        Auto configuration enabled=true&lt;br/&gt;
        Autodetect column delimiter=false&lt;br/&gt;
        Autodetect quotes=false&lt;br/&gt;
        Column reordering enabled=true&lt;br/&gt;
        Empty value=null&lt;br/&gt;
        Escape unquoted values=false&lt;br/&gt;
        Header extraction enabled=null&lt;br/&gt;
        Headers=null&lt;br/&gt;
        Ignore leading whitespaces=false&lt;br/&gt;
        Ignore trailing whitespaces=false&lt;br/&gt;
        Input buffer size=128&lt;br/&gt;
        Input reading on separate thread=false&lt;br/&gt;
        Keep escape sequences=false&lt;br/&gt;
        Keep quotes=false&lt;br/&gt;
        Length of content displayed on error=-1&lt;br/&gt;
        Line separator detection enabled=false&lt;br/&gt;
        Maximum number of characters per column=-1&lt;br/&gt;
        Maximum number of columns=20480&lt;br/&gt;
        Normalize escaped line separators=true&lt;br/&gt;
        Null value=&lt;br/&gt;
        Number of records to read=all&lt;br/&gt;
        Processor=none&lt;br/&gt;
        Restricting data in exceptions=false&lt;br/&gt;
        RowProcessor error handler=null&lt;br/&gt;
        Selected fields=none&lt;br/&gt;
        Skip empty lines=true&lt;br/&gt;
        Unescaped quote handling=STOP_AT_DELIMITERFormat configuration:&lt;br/&gt;
        CsvFormat:&lt;br/&gt;
                Comment character=c&lt;br/&gt;
                Field delimiter=,&lt;br/&gt;
                Line separator (normalized)=\n&lt;br/&gt;
                Line separator sequence=\r\n&lt;br/&gt;
                Quote character=&quot;&lt;br/&gt;
                Quote escape character=\&lt;br/&gt;
                Quote escape escape character=null&lt;br/&gt;
Internal state when error was thrown: line=3, column=0, record=1, charIndex=19&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:339)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:475)&lt;br/&gt;
        at org.apache.spark.sql.execution.datasources.csv.UnivocityParser$$anon$1.next(UnivocityParser.scala:281)&lt;br/&gt;
        at scala.collection.Iterator$$anon$12.next(Iterator.scala:444)&lt;br/&gt;
        at scala.collection.Iterator$$anon$10.next(Iterator.scala:393)&lt;br/&gt;
        at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)&lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)&lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)&lt;br/&gt;
        at scala.collection.AbstractIterator.to(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)&lt;br/&gt;
        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)&lt;br/&gt;
        at scala.collection.AbstractIterator.toArray(Iterator.scala:1336)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354)&lt;br/&gt;
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062)&lt;br/&gt;
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062)&lt;br/&gt;
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)&lt;br/&gt;
        at org.apache.spark.scheduler.Task.run(Task.scala:108)&lt;br/&gt;
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
Caused by: java.lang.IllegalArgumentException: Unable to skip 1 lines from line 2. End of input reached&lt;br/&gt;
        at com.univocity.parsers.common.input.AbstractCharInputReader.skipLines(AbstractCharInputReader.java:262)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.processComment(AbstractParser.java:96)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:440)&lt;br/&gt;
        ... 24 more&lt;br/&gt;
17/11/14 14:26:17 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 8, localhost, executor driver): com.univocity.parsers.common.TextParsingException: java.lang.IllegalArgumentException - Unable to skip 1 lines from line 2. End of input reached&lt;br/&gt;
Parser Configuration: CsvParserSettings:&lt;br/&gt;
        Auto configuration enabled=true&lt;br/&gt;
        Autodetect column delimiter=false&lt;br/&gt;
        Autodetect quotes=false&lt;br/&gt;
        Column reordering enabled=true&lt;br/&gt;
        Empty value=null&lt;br/&gt;
        Escape unquoted values=false&lt;br/&gt;
        Header extraction enabled=null&lt;br/&gt;
        Headers=null&lt;br/&gt;
        Ignore leading whitespaces=false&lt;br/&gt;
        Ignore trailing whitespaces=false&lt;br/&gt;
        Input buffer size=128&lt;br/&gt;
        Input reading on separate thread=false&lt;br/&gt;
        Keep escape sequences=false&lt;br/&gt;
        Keep quotes=false&lt;br/&gt;
        Length of content displayed on error=-1&lt;br/&gt;
        Line separator detection enabled=false&lt;br/&gt;
        Maximum number of characters per column=-1&lt;br/&gt;
        Maximum number of columns=20480&lt;br/&gt;
        Normalize escaped line separators=true&lt;br/&gt;
        Null value=&lt;br/&gt;
        Number of records to read=all&lt;br/&gt;
        Processor=none&lt;br/&gt;
        Restricting data in exceptions=false&lt;br/&gt;
        RowProcessor error handler=null&lt;br/&gt;
        Selected fields=none&lt;br/&gt;
        Skip empty lines=true&lt;br/&gt;
        Unescaped quote handling=STOP_AT_DELIMITERFormat configuration:&lt;br/&gt;
        CsvFormat:&lt;br/&gt;
                Comment character=c&lt;br/&gt;
                Field delimiter=,&lt;br/&gt;
                Line separator (normalized)=\n&lt;br/&gt;
                Line separator sequence=\r\n&lt;br/&gt;
                Quote character=&quot;&lt;br/&gt;
                Quote escape character=\&lt;br/&gt;
                Quote escape escape character=null&lt;br/&gt;
Internal state when error was thrown: line=3, column=0, record=1, charIndex=19&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:339)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:475)&lt;br/&gt;
        at org.apache.spark.sql.execution.datasources.csv.UnivocityParser$$anon$1.next(UnivocityParser.scala:281)&lt;br/&gt;
        at scala.collection.Iterator$$anon$12.next(Iterator.scala:444)&lt;br/&gt;
        at scala.collection.Iterator$$anon$10.next(Iterator.scala:393)&lt;br/&gt;
        at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)&lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)&lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)&lt;br/&gt;
        at scala.collection.AbstractIterator.to(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)&lt;br/&gt;
        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)&lt;br/&gt;
        at scala.collection.AbstractIterator.toArray(Iterator.scala:1336)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354)&lt;br/&gt;
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062)&lt;br/&gt;
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062)&lt;br/&gt;
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)&lt;br/&gt;
        at org.apache.spark.scheduler.Task.run(Task.scala:108)&lt;br/&gt;
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
Caused by: java.lang.IllegalArgumentException: Unable to skip 1 lines from line 2. End of input reached&lt;br/&gt;
        at com.univocity.parsers.common.input.AbstractCharInputReader.skipLines(AbstractCharInputReader.java:262)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.processComment(AbstractParser.java:96)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:440)&lt;br/&gt;
        ... 24 more&lt;/p&gt;

&lt;p&gt;17/11/14 14:26:17 ERROR TaskSetManager: Task 0 in stage 8.0 failed 1 times; aborting job&lt;br/&gt;
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 1 times, most recent failure: Lost task 0.0 in stage 8.0 (TID 8, localhost, executor driver): com.univocity.parsers.common.TextParsingException: java.lang.IllegalArgumentException - Unable to skip 1 lines from line 2. End of input reached&lt;br/&gt;
Parser Configuration: CsvParserSettings:&lt;br/&gt;
        Auto configuration enabled=true&lt;br/&gt;
        Autodetect column delimiter=false&lt;br/&gt;
        Autodetect quotes=false&lt;br/&gt;
        Column reordering enabled=true&lt;br/&gt;
        Empty value=null&lt;br/&gt;
        Escape unquoted values=false&lt;br/&gt;
        Header extraction enabled=null&lt;br/&gt;
        Headers=null&lt;br/&gt;
        Ignore leading whitespaces=false&lt;br/&gt;
        Ignore trailing whitespaces=false&lt;br/&gt;
        Input buffer size=128&lt;br/&gt;
        Input reading on separate thread=false&lt;br/&gt;
        Keep escape sequences=false&lt;br/&gt;
        Keep quotes=false&lt;br/&gt;
        Length of content displayed on error=-1&lt;br/&gt;
        Line separator detection enabled=false&lt;br/&gt;
        Maximum number of characters per column=-1&lt;br/&gt;
        Maximum number of columns=20480&lt;br/&gt;
        Normalize escaped line separators=true&lt;br/&gt;
        Null value=&lt;br/&gt;
        Number of records to read=all&lt;br/&gt;
        Processor=none&lt;br/&gt;
        Restricting data in exceptions=false&lt;br/&gt;
        RowProcessor error handler=null&lt;br/&gt;
        Selected fields=none&lt;br/&gt;
        Skip empty lines=true&lt;br/&gt;
        Unescaped quote handling=STOP_AT_DELIMITERFormat configuration:&lt;br/&gt;
        CsvFormat:&lt;br/&gt;
                Comment character=c&lt;br/&gt;
                Field delimiter=,&lt;br/&gt;
                Line separator (normalized)=\n&lt;br/&gt;
                Line separator sequence=\r\n&lt;br/&gt;
                Quote character=&quot;&lt;br/&gt;
                Quote escape character=\&lt;br/&gt;
                Quote escape escape character=null&lt;br/&gt;
Internal state when error was thrown: line=3, column=0, record=1, charIndex=19&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:339)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:475)&lt;br/&gt;
        at org.apache.spark.sql.execution.datasources.csv.UnivocityParser$$anon$1.next(UnivocityParser.scala:281)&lt;br/&gt;
        at scala.collection.Iterator$$anon$12.next(Iterator.scala:444)&lt;br/&gt;
        at scala.collection.Iterator$$anon$10.next(Iterator.scala:393)&lt;br/&gt;
        at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)&lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)&lt;br/&gt;
        at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)&lt;br/&gt;
        at scala.collection.AbstractIterator.to(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)&lt;br/&gt;
        at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336)&lt;br/&gt;
        at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)&lt;br/&gt;
        at scala.collection.AbstractIterator.toArray(Iterator.scala:1336)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354)&lt;br/&gt;
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062)&lt;br/&gt;
        at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062)&lt;br/&gt;
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)&lt;br/&gt;
        at org.apache.spark.scheduler.Task.run(Task.scala:108)&lt;br/&gt;
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
        at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
Caused by: java.lang.IllegalArgumentException: Unable to skip 1 lines from line 2. End of input reached&lt;br/&gt;
        at com.univocity.parsers.common.input.AbstractCharInputReader.skipLines(AbstractCharInputReader.java:262)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.processComment(AbstractParser.java:96)&lt;br/&gt;
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:440)&lt;br/&gt;
        ... 24 more&lt;/p&gt;

&lt;p&gt;Driver stacktrace:&lt;br/&gt;
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)&lt;br/&gt;
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)&lt;br/&gt;
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)&lt;br/&gt;
  at scala.Option.foreach(Option.scala:257)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)&lt;br/&gt;
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)&lt;br/&gt;
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)&lt;br/&gt;
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)&lt;br/&gt;
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)&lt;br/&gt;
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)&lt;br/&gt;
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1354)&lt;br/&gt;
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)&lt;br/&gt;
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)&lt;br/&gt;
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)&lt;br/&gt;
  at org.apache.spark.rdd.RDD.take(RDD.scala:1327)&lt;br/&gt;
  at org.apache.spark.sql.execution.datasources.csv.MultiLineCSVDataSource$.infer(CSVDataSource.scala:224)&lt;br/&gt;
  at org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:62)&lt;br/&gt;
  at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:57)&lt;br/&gt;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$7.apply(DataSource.scala:177)&lt;br/&gt;
  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$7.apply(DataSource.scala:177)&lt;br/&gt;
  at scala.Option.orElse(Option.scala:289)&lt;br/&gt;
  at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:176)&lt;br/&gt;
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:533)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:412)&lt;br/&gt;
  ... 48 elided&lt;br/&gt;
Caused by: com.univocity.parsers.common.TextParsingException: java.lang.IllegalArgumentException - Unable to skip 1 lines from line 2. End of input reached&lt;br/&gt;
Parser Configuration: CsvParserSettings:&lt;br/&gt;
        Auto configuration enabled=true&lt;br/&gt;
        Autodetect column delimiter=false&lt;br/&gt;
        Autodetect quotes=false&lt;br/&gt;
        Column reordering enabled=true&lt;br/&gt;
        Empty value=null&lt;br/&gt;
        Escape unquoted values=false&lt;br/&gt;
        Header extraction enabled=null&lt;br/&gt;
        Headers=null&lt;br/&gt;
        Ignore leading whitespaces=false&lt;br/&gt;
        Ignore trailing whitespaces=false&lt;br/&gt;
        Input buffer size=128&lt;br/&gt;
        Input reading on separate thread=false&lt;br/&gt;
        Keep escape sequences=false&lt;br/&gt;
        Keep quotes=false&lt;br/&gt;
        Length of content displayed on error=-1&lt;br/&gt;
        Line separator detection enabled=false&lt;br/&gt;
        Maximum number of characters per column=-1&lt;br/&gt;
        Maximum number of columns=20480&lt;br/&gt;
        Normalize escaped line separators=true&lt;br/&gt;
        Null value=&lt;br/&gt;
        Number of records to read=all&lt;br/&gt;
        Processor=none&lt;br/&gt;
        Restricting data in exceptions=false&lt;br/&gt;
        RowProcessor error handler=null&lt;br/&gt;
        Selected fields=none&lt;br/&gt;
        Skip empty lines=true&lt;br/&gt;
        Unescaped quote handling=STOP_AT_DELIMITERFormat configuration:&lt;br/&gt;
        CsvFormat:&lt;br/&gt;
                Comment character=c&lt;br/&gt;
                Field delimiter=,&lt;br/&gt;
                Line separator (normalized)=\n&lt;br/&gt;
                Line separator sequence=\r\n&lt;br/&gt;
                Quote character=&quot;&lt;br/&gt;
                Quote escape character=\&lt;br/&gt;
                Quote escape escape character=null&lt;br/&gt;
Internal state when error was thrown: line=3, column=0, record=1, charIndex=19&lt;br/&gt;
  at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:339)&lt;br/&gt;
  at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:475)&lt;br/&gt;
  at org.apache.spark.sql.execution.datasources.csv.UnivocityParser$$anon$1.next(UnivocityParser.scala:281)&lt;br/&gt;
  at scala.collection.Iterator$$anon$12.next(Iterator.scala:444)&lt;br/&gt;
  at scala.collection.Iterator$$anon$10.next(Iterator.scala:393)&lt;br/&gt;
  at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
  at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
  at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)&lt;br/&gt;
  at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)&lt;br/&gt;
  at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)&lt;br/&gt;
  at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)&lt;br/&gt;
  at scala.collection.AbstractIterator.to(Iterator.scala:1336)&lt;br/&gt;
  at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)&lt;br/&gt;
  at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336)&lt;br/&gt;
  at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)&lt;br/&gt;
  at scala.collection.AbstractIterator.toArray(Iterator.scala:1336)&lt;br/&gt;
  at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354)&lt;br/&gt;
  at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354)&lt;br/&gt;
  at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062)&lt;br/&gt;
  at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062)&lt;br/&gt;
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)&lt;br/&gt;
  at org.apache.spark.scheduler.Task.run(Task.scala:108)&lt;br/&gt;
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)&lt;br/&gt;
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
  at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
Caused by: java.lang.IllegalArgumentException: Unable to skip 1 lines from line 2. End of input reached&lt;br/&gt;
  at com.univocity.parsers.common.input.AbstractCharInputReader.skipLines(AbstractCharInputReader.java:262)&lt;br/&gt;
  at com.univocity.parsers.common.AbstractParser.processComment(AbstractParser.java:96)&lt;br/&gt;
  at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:440)&lt;br/&gt;
  ... 24 more&lt;/p&gt;

&lt;p&gt;scala&amp;gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13118180">SPARK-22516</key>
            <summary>CSV Read breaks: When &quot;multiLine&quot; = &quot;true&quot;, if &quot;comment&quot; option is set as last line&apos;s first character</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="smurakozi">Sandor Murakozi</assignee>
                                    <reporter username="crkumaresh24">Kumaresh C R</reporter>
                        <labels>
                            <label>csvparser</label>
                    </labels>
                <created>Tue, 14 Nov 2017 08:57:57 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:55 +0000</updated>
                            <resolved>Wed, 6 Dec 2017 21:22:31 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16251110" author="crkumaresh24" created="Tue, 14 Nov 2017 09:04:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt;: Need your help here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16257088" author="mgaido" created="Fri, 17 Nov 2017 15:01:14 +0000"  >&lt;p&gt;not sure why but this is caused by the fact that your file contains &quot;CR LF&quot; as line separator instead of only LF&lt;/p&gt;</comment>
                            <comment id="16259157" author="crkumaresh24" created="Mon, 20 Nov 2017 12:00:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mgaido&quot; class=&quot;user-hover&quot; rel=&quot;mgaido&quot;&gt;mgaido&lt;/a&gt;: Even after I replaced all &apos;CR LF&apos; to &apos;LF&apos;, still in the below case, the error is thrown.&lt;/p&gt;

&lt;p&gt; -&amp;gt; When the file doesn&apos;t have &apos;LF&apos; as the last character in its last line  i.e. EOF&lt;br/&gt;
 (Note: All other lines in the file ends with LF) character&lt;/p&gt;

&lt;p&gt;Attached the failing file &apos;test_file_without_eof_char.csv&apos; for your reference.&lt;/p&gt;

&lt;p&gt;Is it something the problem with the parser or the input data (which doesn&apos;t have any line ending as its last character) ?&lt;/p&gt;</comment>
                            <comment id="16260904" author="mgaido" created="Tue, 21 Nov 2017 15:29:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=crkumaresh24&quot; class=&quot;user-hover&quot; rel=&quot;crkumaresh24&quot;&gt;crkumaresh24&lt;/a&gt; I can&apos;t reproduce the issue with the new file you have uploaded. I am running on a OSX, maybe it depends on the OS:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; val a = spark.read.option(&lt;span class=&quot;code-quote&quot;&gt;&quot;header&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;inferSchema&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;multiLine&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;comment&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;c&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;parserLib&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;univocity&quot;&lt;/span&gt;).csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/mgaido/Downloads/test_file_without_eof_char.csv&quot;&lt;/span&gt;)
a: org.apache.spark.sql.DataFrame = [abc: string, def: string]

scala&amp;gt; a.show
+---+---+
|abc|def|
+---+---+
|ghi|jkl|
+---+---+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16262189" author="gurwls223" created="Wed, 22 Nov 2017 09:10:26 +0000"  >&lt;p&gt;This can be reproduced by:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
spark.read.option(&lt;span class=&quot;code-quote&quot;&gt;&quot;header&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;inferSchema&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;multiLine&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;comment&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;g&quot;&lt;/span&gt;).csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;test_file_without_eof_char.csv&quot;&lt;/span&gt;).show()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The root cause seems from Univocity parser. I filed an issue there - &lt;a href=&quot;https://github.com/uniVocity/univocity-parsers/issues/213&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/uniVocity/univocity-parsers/issues/213&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;BTW, let&apos;s keep the description and reproducer clean as possible as we can. I was actually about to say the same things above ^ but realised it&apos;s a separate issue after multiple close looks. &lt;/p&gt;</comment>
                            <comment id="16262334" author="gurwls223" created="Wed, 22 Nov 2017 11:24:10 +0000"  >&lt;p&gt;Seems fixed in 2.5.9. We could probably bump up Univocity library.&lt;/p&gt;</comment>
                            <comment id="16262516" author="smurakozi" created="Wed, 22 Nov 2017 13:34:28 +0000"  >&lt;p&gt;I&apos;m a newbie, I would be happy to happy to work on it. Would it be ok for you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="16262738" author="gurwls223" created="Wed, 22 Nov 2017 14:53:59 +0000"  >&lt;p&gt;Sure. Please go ahead. Probably, you could refer the changes here - &lt;a href=&quot;https://github.com/apache/spark/pull/19113/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19113/files&lt;/a&gt;. I opened a PR bumping the version of Univocity library before in order to to resolve an issue fixed in higher version of it. We probably also need a test case too likewise.&lt;/p&gt;</comment>
                            <comment id="16279818" author="apachespark" created="Wed, 6 Dec 2017 08:18:04 +0000"  >&lt;p&gt;User &apos;smurakozi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19906&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19906&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16280949" author="vanzin" created="Wed, 6 Dec 2017 21:22:31 +0000"  >&lt;p&gt;Issue resolved by pull request 19906&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19906&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19906&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12897519" name="testCommentChar.csv" size="19" author="crkumaresh24" created="Tue, 14 Nov 2017 09:00:54 +0000"/>
                            <attachment id="12898472" name="test_file_without_eof_char.csv" size="31" author="crkumaresh24" created="Mon, 20 Nov 2017 12:01:28 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 49 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3mqyf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>