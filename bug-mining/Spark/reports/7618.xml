<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:20:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-33071] Join with ambiguous column succeeding but giving wrong output</title>
                <link>https://issues.apache.org/jira/browse/SPARK-33071</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When joining two datasets where one column in each dataset is sourced from the same input dataset, the join successfully runs, but does not select the correct columns, leading to incorrect output.&lt;/p&gt;

&lt;p&gt;Repro using pyspark:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
sc.version
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pyspark.sql.functions as F
d = [{&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 1, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 2}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 2, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 4}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;b&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 5, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 10}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;c&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 1, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 2}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 3, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 6}]
input_df = spark.createDataFrame(d)
df1 = input_df.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;).agg(F.sum(&lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;))
df2 = input_df.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;).agg(F.sum(&lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt;))
df1 = df1.filter(F.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;) != F.lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;c&quot;&lt;/span&gt;))
df2 = df2.filter(F.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;) != F.lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;d&quot;&lt;/span&gt;))
ret = df1.join(df2, df1.key == df2.key, &lt;span class=&quot;code-quote&quot;&gt;&quot;full&quot;&lt;/span&gt;).select(
df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;].alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df1_key&quot;&lt;/span&gt;),
df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;].alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df2_key&quot;&lt;/span&gt;),
df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;sales&quot;&lt;/span&gt;],
df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;units&quot;&lt;/span&gt;],
F.coalesce(df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;], df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;]).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;))
ret.show()
ret.explain()&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output for 2.4.4:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; sc.version
u&lt;span class=&quot;code-quote&quot;&gt;&apos;2.4.4&apos;&lt;/span&gt;
&amp;gt;&amp;gt;&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pyspark.sql.functions as F
&amp;gt;&amp;gt;&amp;gt; d = [{&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 1, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 2}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 2, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 4}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;b&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 5, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 10}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;c&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 1, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 2}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 3, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 6}]
&amp;gt;&amp;gt;&amp;gt; input_df = spark.createDataFrame(d)
&amp;gt;&amp;gt;&amp;gt; df1 = input_df.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;).agg(F.sum(&lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; df2 = input_df.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;).agg(F.sum(&lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; df1 = df1.filter(F.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;) != F.lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;c&quot;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; df2 = df2.filter(F.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;) != F.lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;d&quot;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; ret = df1.join(df2, df1.key == df2.key, &lt;span class=&quot;code-quote&quot;&gt;&quot;full&quot;&lt;/span&gt;).select(
... df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;].alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df1_key&quot;&lt;/span&gt;),
... df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;].alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df2_key&quot;&lt;/span&gt;),
... df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;sales&quot;&lt;/span&gt;],
... df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;units&quot;&lt;/span&gt;],
... F.coalesce(df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;], df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;]).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;))
20/10/05 15:46:14 WARN Column: Constructing trivially &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; equals predicate, &lt;span class=&quot;code-quote&quot;&gt;&apos;key#213 = key#213&apos;&lt;/span&gt;. Perhaps you need to use aliases.
&amp;gt;&amp;gt;&amp;gt; ret.show()
+-------+-------+-----+-----+----+
|df1_key|df2_key|sales|units| key|
+-------+-------+-----+-----+----+
|      d|      d|    3| &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|   d|
|   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;| &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|    2|&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|
|      b|      b|    5|   10|   b|
|      a|      a|    3|    6|   a|
+-------+-------+-----+-----+----+&amp;gt;&amp;gt;&amp;gt; ret.explain()
== Physical Plan ==
*(5) Project [key#213 AS df1_key#258, key#213 AS df2_key#259, sales#223L, units#230L, coalesce(key#213, key#213) AS key#260]
+- SortMergeJoin [key#213], [key#237], FullOuter
   :- *(2) Sort [key#213 ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
   :  +- *(2) HashAggregate(keys=[key#213], functions=[sum(sales#214L)])
   :     +- Exchange hashpartitioning(key#213, 200)
   :        +- *(1) HashAggregate(keys=[key#213], functions=[partial_sum(sales#214L)])
   :           +- *(1) Project [key#213, sales#214L]
   :              +- *(1) Filter (isnotnull(key#213) &amp;amp;&amp;amp; NOT (key#213 = c))
   :                 +- Scan ExistingRDD[key#213,sales#214L,units#215L]
   +- *(4) Sort [key#237 ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
      +- *(4) HashAggregate(keys=[key#237], functions=[sum(units#239L)])
         +- Exchange hashpartitioning(key#237, 200)
            +- *(3) HashAggregate(keys=[key#237], functions=[partial_sum(units#239L)])
               +- *(3) Project [key#237, units#239L]
                  +- *(3) Filter (isnotnull(key#237) &amp;amp;&amp;amp; NOT (key#237 = d))
                     +- Scan ExistingRDD[key#237,sales#238L,units#239L]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;output for 3.0.1:&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// code placeholder
&lt;/span&gt;&amp;gt;&amp;gt;&amp;gt; sc.version
u&lt;span class=&quot;code-quote&quot;&gt;&apos;3.0.1&apos;&lt;/span&gt;
&amp;gt;&amp;gt;&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pyspark.sql.functions as F
&amp;gt;&amp;gt;&amp;gt; d = [{&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 1, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 2}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 2, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 4}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;b&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 5, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 10}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;c&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 1, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 2}, {&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;: 3, &lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt; : 6}]
&amp;gt;&amp;gt;&amp;gt; input_df = spark.createDataFrame(d)
/usr/local/lib/python2.7/site-packages/pyspark/sql/session.py:381: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead
  warnings.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;inferring schema from dict is deprecated,&quot;&lt;/span&gt;
&amp;gt;&amp;gt;&amp;gt; df1 = input_df.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;).agg(F.sum(&lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&apos;sales&apos;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; df2 = input_df.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;).agg(F.sum(&lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&apos;units&apos;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; df1 = df1.filter(F.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;) != F.lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;c&quot;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; df2 = df2.filter(F.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;) != F.lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;d&quot;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; ret = df1.join(df2, df1.key == df2.key, &lt;span class=&quot;code-quote&quot;&gt;&quot;full&quot;&lt;/span&gt;).select(
... df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;].alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df1_key&quot;&lt;/span&gt;),
... df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;].alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df2_key&quot;&lt;/span&gt;),
... df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;sales&quot;&lt;/span&gt;],
... df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;units&quot;&lt;/span&gt;],
... F.coalesce(df1[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;], df2[&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;]).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;key&quot;&lt;/span&gt;))
&amp;gt;&amp;gt;&amp;gt; ret.show()
+-------+-------+-----+-----+----+
|df1_key|df2_key|sales|units| key|
+-------+-------+-----+-----+----+
|      d|      d|    3| &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|   d|
|   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;| &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|    2|&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|
|      b|      b|    5|   10|   b|
|      a|      a|    3|    6|   a|
+-------+-------+-----+-----+----+&amp;gt;&amp;gt;&amp;gt; ret.explain()
== Physical Plan ==
*(5) Project [key#0 AS df1_key#45, key#0 AS df2_key#46, sales#10L, units#17L, coalesce(key#0, key#0) AS key#47]
+- SortMergeJoin [key#0], [key#24], FullOuter
   :- *(2) Sort [key#0 ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
   :  +- *(2) HashAggregate(keys=[key#0], functions=[sum(sales#1L)])
   :     +- Exchange hashpartitioning(key#0, 200), &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, [id=#152]
   :        +- *(1) HashAggregate(keys=[key#0], functions=[partial_sum(sales#1L)])
   :           +- *(1) Project [key#0, sales#1L]
   :              +- *(1) Filter (isnotnull(key#0) AND NOT (key#0 = c))
   :                 +- *(1) Scan ExistingRDD[key#0,sales#1L,units#2L]
   +- *(4) Sort [key#24 ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
      +- *(4) HashAggregate(keys=[key#24], functions=[sum(units#26L)])
         +- Exchange hashpartitioning(key#24, 200), &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, [id=#158]
            +- *(3) HashAggregate(keys=[key#24], functions=[partial_sum(units#26L)])
               +- *(3) Project [key#24, units#26L]
                  +- *(3) Filter (isnotnull(key#24) AND NOT (key#24 = d))
                     +- *(3) Scan ExistingRDD[key#24,sales#25L,units#26L]&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;key#0 is the reference used for both alias operations and both sides of the coalesce, despite the query plan projecting key#24 for the right side of the join.&lt;br/&gt;
Concretely, I believe the output of the join should be this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
+-------+-------+-----+-----+----+
|df1_key|df2_key|sales|units| key|
+-------+-------+-----+-----+----+
|      d|   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|    3| &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|   d|
|   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|      c| &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|    2|   c|
|      b|      b|    5|   10|   b|
|      a|      a|    3|    6|   a|
+-------+-------+-----+-----+----+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13333791">SPARK-33071</key>
            <summary>Join with ambiguous column succeeding but giving wrong output</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Ngone51">wuyi</assignee>
                                    <reporter username="gcooper120">George</reporter>
                        <labels>
                            <label>correctness</label>
                    </labels>
                <created>Mon, 5 Oct 2020 20:10:02 +0000</created>
                <updated>Wed, 9 Dec 2020 08:32:24 +0000</updated>
                            <resolved>Wed, 2 Dec 2020 17:51:46 +0000</resolved>
                                    <version>2.4.4</version>
                    <version>3.0.1</version>
                    <version>3.1.0</version>
                                    <fixVersion>3.1.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="17209026" author="eveliao" created="Tue, 6 Oct 2020 18:36:52 +0000"  >&lt;p&gt;Need to talk with experienced contributors to see if it is a bug. The issue here is that there will be duplicate columns after join. So df1&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;quot;key&amp;quot;&amp;#93;&lt;/span&gt; and df2&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;quot;key&amp;quot;&amp;#93;&lt;/span&gt; in select statement actually refer to the same column: key from df1. A workaround should be:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; df1=df1.alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df1&quot;&lt;/span&gt;)
&amp;gt;&amp;gt;&amp;gt; df2=df2.alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df2&quot;&lt;/span&gt;)
&amp;gt;&amp;gt;&amp;gt; df1.join(df2, df1.key == df2.key, &lt;span class=&quot;code-quote&quot;&gt;&quot;full&quot;&lt;/span&gt;).select(F.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;df1.key&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df1_key&quot;&lt;/span&gt;),F.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;df2.key&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;df2_key&quot;&lt;/span&gt;),&lt;span class=&quot;code-quote&quot;&gt;&quot;sales&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;units&quot;&lt;/span&gt;).show()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17209050" author="gcooper120" created="Tue, 6 Oct 2020 19:08:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=EveLiao&quot; class=&quot;user-hover&quot; rel=&quot;EveLiao&quot;&gt;EveLiao&lt;/a&gt;&#160;Yeah that sounds correct, another workaround I found was something like&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
df1_cols = list(map(lambda x: x + &lt;span class=&quot;code-quote&quot;&gt;&quot;_1&quot;&lt;/span&gt;, df1.columns))
df1 = toDF(df1_cols)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;In my mind the reason why I view this as a bug is that it takes a fairly deep understanding of how spark handles columns, copying and references to expect this behavior. For many developers, this just wouldn&apos;t be the behavior they expect to see.&lt;/p&gt;</comment>
                            <comment id="17209064" author="eveliao" created="Tue, 6 Oct 2020 19:18:45 +0000"  >&lt;p&gt;Yeah, I agree with you. IMHO, would prefer a error message pops up when&#160;select( df1&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;quot;key&amp;quot;&amp;#93;&lt;/span&gt;) after join, like &quot; Reference &apos;key&apos; is ambiguous&quot; when using reference as &quot;key&quot;. Right now, the mistake is actually made out of sight, which is not ideal.&lt;/p&gt;</comment>
                            <comment id="17212862" author="angerszhuuu" created="Tue, 13 Oct 2020 06:25:23 +0000"  >&lt;p&gt;it is wrong, I am working on this&#160;&lt;/p&gt;</comment>
                            <comment id="17212895" author="angerszhuuu" created="Tue, 13 Oct 2020 07:40:11 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maropu&quot; class=&quot;user-hover&quot; rel=&quot;maropu&quot;&gt;maropu&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;&#160; This error cause by ResolveReference `dedupRight` generate new LogicalPlan with&#160; new ExprId, but `df2&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;#39;key&amp;#39;&amp;#93;&lt;/span&gt;` resolved as origin right side ExprId, then two `key` all resolved to `df1.key`.&#160;I believe this is not the only case.&#160; Seems a serious data issue. Any suggestion?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17213205" author="cloud_fan" created="Tue, 13 Oct 2020 16:25:41 +0000"  >&lt;p&gt;To confirm: is this a long-standing bug that 2.4, 3.0, and the master branch all give wrong (but same) result?&lt;/p&gt;</comment>
                            <comment id="17213312" author="eveliao" created="Tue, 13 Oct 2020 18:55:50 +0000"  >&lt;p&gt;The master branch has the same bug.&lt;/p&gt;</comment>
                            <comment id="17238481" author="apachespark" created="Wed, 25 Nov 2020 03:26:43 +0000"  >&lt;p&gt;User &apos;Ngone51&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/30488&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/30488&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17242572" author="cloud_fan" created="Wed, 2 Dec 2020 17:51:46 +0000"  >&lt;p&gt;Issue resolved by pull request 30488&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/30488&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/30488&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17246357" author="apachespark" created="Wed, 9 Dec 2020 08:32:24 +0000"  >&lt;p&gt;User &apos;HyukjinKwon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/30682&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/30682&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 48 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0jfl4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>