<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:24:08 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-34193] Potential race condition during decommissioning with TorrentBroadcast</title>
                <link>https://issues.apache.org/jira/browse/SPARK-34193</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I found this while back porting so the line numbers should be ignored, but the core of the issue is that we shouldn&apos;t be failing the job on this (I don&apos;t think). We could fix this by allowing broadcast blocks to be put or having the torrent broadcast ignore this exception.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3.0 failed 4 times, most recent failure: Lost task 1.3 in stage 3.0 (TID 8, 192.168.1.57, executor 1): java.io.IOException: org.apache.spark.storage.BlockSavedOnDecommissionedBlockManagerException: Block broadcast_2_piece0 cannot be saved on decommissioned executor&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3.0 failed 4 times, most recent failure: Lost task 1.3 in stage 3.0 (TID 8, 192.168.1.57, executor 1): java.io.IOException: org.apache.spark.storage.BlockSavedOnDecommissionedBlockManagerException: Block broadcast_2_piece0 cannot be saved on decommissioned executor&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1333)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:215)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:84)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.scheduler.Task.run(Task.scala:123)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.executor.Executor$TaskRunner$$anonfun$12.apply(Executor.scala:448)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:454)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at java.lang.Thread.run(Thread.java:748)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; Caused by: org.apache.spark.storage.BlockSavedOnDecommissionedBlockManagerException: Block broadcast_2_piece0 cannot be saved on decommissioned executor&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1105)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.storage.BlockManager.doPutBytes(BlockManager.scala:1010)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.storage.BlockManager.putBytes(BlockManager.scala:986)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:181)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:159)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:159)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at scala.collection.immutable.List.foreach(List.scala:392)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:159)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1$$anonfun$apply$2.apply(TorrentBroadcast.scala:239)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at scala.Option.getOrElse(Option.scala:121)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:219)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1326)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; ... 13 more&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; Driver stacktrace:&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1928)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1916)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1915)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1915)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:951)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:951)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at scala.Option.foreach(Option.scala:257)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:951)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2149)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2098)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2087)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:762)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2089)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2110)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2129)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkContext.runJob(SparkContext.scala:2154)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.rdd.RDD.count(RDD.scala:1213)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.storage.BlockManagerDecommissionIntegrationSuite.org$apache$spark$storage$BlockManagerDecommissionIntegrationSuite$$runDecomTest(BlockManagerDecommissionIntegrationSuite.scala:276)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.storage.BlockManagerDecommissionIntegrationSuite$$anonfun$1.apply$mcV$sp(BlockManagerDecommissionIntegrationSuite.scala:61)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.storage.BlockManagerDecommissionIntegrationSuite$$anonfun$1.apply(BlockManagerDecommissionIntegrationSuite.scala:61)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.storage.BlockManagerDecommissionIntegrationSuite$$anonfun$1.apply(BlockManagerDecommissionIntegrationSuite.scala:61)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.Transformer.apply(Transformer.scala:22)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.Transformer.apply(Transformer.scala:20)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:147)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterEach$$super$runTest(SparkFunSuite.scala:54)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.BeforeAndAfterEach$class.runTest(BeforeAndAfterEach.scala:221)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkFunSuite.runTest(SparkFunSuite.scala:54)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at scala.collection.immutable.List.foreach(List.scala:392)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.Suite$class.run(Suite.scala:1147)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.SuperEngine.runImpl(Engine.scala:521)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:54)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:213)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:210)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:54)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:314)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:480)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at sbt.ForkMain$Run$2.call(ForkMain.java:296)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at sbt.ForkMain$Run$2.call(ForkMain.java:286)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.lang.Thread.run(Thread.java:748)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; Cause: java.io.IOException: org.apache.spark.storage.BlockSavedOnDecommissionedBlockManagerException: Block broadcast_2_piece0 cannot be saved on decommissioned executor&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1333)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:215)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:84)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.Task.run(Task.scala:123)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.executor.Executor$TaskRunner$$anonfun$12.apply(Executor.scala:448)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:454)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.lang.Thread.run(Thread.java:748)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; Cause: org.apache.spark.storage.BlockSavedOnDecommissionedBlockManagerException: Block broadcast_2_piece0 cannot be saved on decommissioned executor&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1105)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.storage.BlockManager.doPutBytes(BlockManager.scala:1010)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.storage.BlockManager.putBytes(BlockManager.scala:986)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:181)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:159)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:159)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at scala.collection.immutable.List.foreach(List.scala:392)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:159)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1$$anonfun$apply$2.apply(TorrentBroadcast.scala:239)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at scala.Option.getOrElse(Option.scala:121)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:219)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1326)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:215)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:84)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.scheduler.Task.run(Task.scala:123)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.executor.Executor$TaskRunner$$anonfun$12.apply(Executor.scala:448)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:454)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; &#160; at java.util.concurrent.ThreadPoolExecutor$W&lt;/p&gt;</description>
                <environment></environment>
        <key id="13353828">SPARK-34193</key>
            <summary>Potential race condition during decommissioning with TorrentBroadcast</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="holden">Holden Karau</assignee>
                                    <reporter username="holden">Holden Karau</reporter>
                        <labels>
                    </labels>
                <created>Thu, 21 Jan 2021 19:28:32 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:40 +0000</updated>
                            <resolved>Wed, 27 Jan 2021 21:17:32 +0000</resolved>
                                    <version>3.1.0</version>
                    <version>3.1.1</version>
                    <version>3.1.2</version>
                    <version>3.2.0</version>
                                    <fixVersion>3.1.1</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17269565" author="holdenk" created="Thu, 21 Jan 2021 19:29:08 +0000"  >&lt;p&gt;Note, so far I&apos;ve only triggered this once and in the back porting, the &quot;Affects Version&quot; is currently a guess.&lt;/p&gt;</comment>
                            <comment id="17270408" author="apachespark" created="Fri, 22 Jan 2021 20:34:09 +0000"  >&lt;p&gt;User &apos;holdenk&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/31298&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/31298&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17273146" author="gurwls223" created="Wed, 27 Jan 2021 21:17:32 +0000"  >&lt;p&gt;Issue resolved by pull request 31298&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/31298&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/31298&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 41 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0muug:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>