<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:32:19 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-42346] distinct(count colname) with UNION ALL causes query analyzer bug</title>
                <link>https://issues.apache.org/jira/browse/SPARK-42346</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;If you combine a UNION ALL with a count(distinct colname) you get a query analyzer bug.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;This behaviour is introduced in 3.3.0.&#160; The bug was not present in 3.2.1.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Here is a reprex in PySpark:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;df_pd = pd.DataFrame([&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160; &#160; {&apos;surname&apos;: &apos;a&apos;, &apos;first_name&apos;: &apos;b&apos;&lt;/tt&gt;}&lt;br/&gt;
&lt;tt&gt;])&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;df_spark = spark.createDataFrame(df_pd)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;df_spark.createOrReplaceTempView(&quot;input_table&quot;)&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;sql = &quot;&quot;&quot;&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;SELECT&#160;&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160; &#160; (SELECT Count(DISTINCT first_name) FROM &#160; input_table)&#160;&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160; &#160; &#160; &#160; AS distinct_value_count&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;FROM &#160; input_table&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;UNION ALL&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;SELECT&#160;&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160; &#160; (SELECT Count(DISTINCT surname) FROM &#160; input_table)&#160;&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160; &#160; &#160; &#160; AS distinct_value_count&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;FROM &#160; input_table &quot;&quot;&quot;&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;spark.sql(sql).toPandas()&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13523064">SPARK-42346</key>
            <summary>distinct(count colname) with UNION ALL causes query analyzer bug</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="petertoth">Peter Toth</assignee>
                                    <reporter username="RobinLinacre">Robin</reporter>
                        <labels>
                    </labels>
                <created>Sat, 4 Feb 2023 08:52:04 +0000</created>
                <updated>Wed, 8 Feb 2023 19:40:59 +0000</updated>
                            <resolved>Mon, 6 Feb 2023 13:29:37 +0000</resolved>
                                    <version>3.3.0</version>
                    <version>3.4.0</version>
                    <version>3.5.0</version>
                                    <fixVersion>3.3.2</fixVersion>
                    <fixVersion>3.4.0</fixVersion>
                    <fixVersion>3.5.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="17684177" author="q79969786" created="Sat, 4 Feb 2023 15:03:35 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petertoth&quot; class=&quot;user-hover&quot; rel=&quot;petertoth&quot;&gt;petertoth&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17684184" author="petertoth" created="Sat, 4 Feb 2023 15:58:55 +0000"  >&lt;p&gt;Thanks for pinging me &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt;, this might be subquery merge related. I will look into it.&lt;/p&gt;</comment>
                            <comment id="17684271" author="apachespark" created="Sun, 5 Feb 2023 10:19:59 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39887&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39887&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17684272" author="petertoth" created="Sun, 5 Feb 2023 10:23:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=RobinLinacre&quot; class=&quot;user-hover&quot; rel=&quot;RobinLinacre&quot;&gt;RobinLinacre&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/spark/pull/39887&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39887&lt;/a&gt;&#160;will fix the issue.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=viirya&quot; class=&quot;user-hover&quot; rel=&quot;viirya&quot;&gt;viirya&lt;/a&gt;, as this is a regression from 3.2 to 3.3, if possible please include this in 3.3.2.&lt;/p&gt;</comment>
                            <comment id="17684332" author="viirya" created="Sun, 5 Feb 2023 17:58:43 +0000"  >&lt;p&gt;I will wait for this patch before cutting RC1.&lt;/p&gt;</comment>
                            <comment id="17684679" author="q79969786" created="Mon, 6 Feb 2023 13:29:37 +0000"  >&lt;p&gt;Issue resolved by pull request 39887&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39887&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39887&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17684992" author="ritikam" created="Tue, 7 Feb 2023 01:35:27 +0000"  >&lt;p&gt;I have Spark 3.3.0 and I do not have 39887 fix . I am not able to reproduce this issue. Am I missing something?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; val df = Seq((&quot;a&quot;,&quot;b&quot;)).toDF(&quot;surname&quot;,&quot;first_name&quot;)&lt;/p&gt;

&lt;p&gt;&lt;b&gt;df&lt;/b&gt;: &lt;b&gt;org.apache.spark.sql.DataFrame&lt;/b&gt; = &lt;span class=&quot;error&quot;&gt;&amp;#91;surname: string, first_name: string&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; df.createOrReplaceTempView(&quot;input_table&quot;)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; spark.sql(&quot;select(Select Count(Distinct first_name) from input_table) As distinct_value_count from input_table Union all select (select count(Distinct surname) from input_table) as distinct_value_count from input_table&quot;).show()&lt;/p&gt;

&lt;p&gt;&lt;ins&gt;--------------------&lt;/ins&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;distinct_value_count&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;--------------------&lt;/ins&gt;&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;--------------------&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;= Physical Plan ==&lt;br/&gt;
AdaptiveSparkPlan isFinalPlan=false&lt;br/&gt;
+- Union&lt;br/&gt;
&#160; &#160;:- Project &lt;a href=&quot;#46, [id=#114] as string) AS distinct_value_count#62&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cast(Subquery subquery#46, [id=#114] as string) AS distinct_value_count#62&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;: &#160;+- Subquery subquery#46, &lt;a href=&quot;#114&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#114&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; +- AdaptiveSparkPlan isFinalPlan=false&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160;+- HashAggregate(keys=[], functions=&lt;a href=&quot;#12)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count(first_name#12)&lt;/a&gt;, output=&lt;a href=&quot;#53L&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count(DISTINCT first_name)#53L&lt;/a&gt;)&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; +- Exchange SinglePartition, ENSURE_REQUIREMENTS, &lt;a href=&quot;#112&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#112&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; &#160; &#160;+- HashAggregate(keys=[], functions=&lt;a href=&quot;#12)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;partial_count(first_name#12)&lt;/a&gt;, output=&lt;a href=&quot;#67L&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count#67L&lt;/a&gt;)&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; +- LocalTableScan &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;first_name#12&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;+- LocalTableScan &lt;a href=&quot;#6, _2#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;_1#6, _2#7&lt;/a&gt;&lt;br/&gt;
&#160; &#160;+- Project &lt;a href=&quot;#48, [id=#125] as string) AS distinct_value_count#64&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cast(Subquery subquery#48, [id=#125] as string) AS distinct_value_count#64&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; : &#160;+- Subquery subquery#48, &lt;a href=&quot;#125&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#125&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; +- AdaptiveSparkPlan isFinalPlan=false&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160;+- HashAggregate(keys=[], functions=&lt;a href=&quot;#11)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count(surname#11)&lt;/a&gt;, output=&lt;a href=&quot;#55L&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count(DISTINCT surname)#55L&lt;/a&gt;)&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; +- Exchange SinglePartition, ENSURE_REQUIREMENTS, &lt;a href=&quot;#123&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#123&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; &#160; &#160;+- HashAggregate(keys=[], functions=&lt;a href=&quot;#11)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;partial_count(surname#11)&lt;/a&gt;, output=&lt;a href=&quot;#68L&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count#68L&lt;/a&gt;)&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; +- LocalTableScan &lt;a href=&quot;#11&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;surname#11&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; +- LocalTableScan &lt;a href=&quot;#50, _2#51&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;_1#50, _2#51&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;This is what I have in my SparkOptimizer.scala&lt;/p&gt;


&lt;p&gt;override def defaultBatches: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Batch&amp;#93;&lt;/span&gt; = (preOptimizationBatches ++ super.defaultBatches :+&lt;br/&gt;
Batch(&quot;Optimize Metadata Only Query&quot;, Once, OptimizeMetadataOnlyQuery(catalog)) :+&lt;br/&gt;
Batch(&quot;PartitionPruning&quot;, Once,&lt;br/&gt;
PartitionPruning) :+&lt;br/&gt;
Batch(&quot;InjectRuntimeFilter&quot;, FixedPoint(1),&lt;br/&gt;
InjectRuntimeFilter,&lt;br/&gt;
RewritePredicateSubquery) :+&lt;br/&gt;
Batch(&quot;MergeScalarSubqueries&quot;, Once,&lt;br/&gt;
MergeScalarSubqueries) :+&lt;br/&gt;
Batch(&quot;Pushdown Filters from PartitionPruning&quot;, fixedPoint,&lt;br/&gt;
PushDownPredicates) :+&lt;br/&gt;
Batch&lt;/p&gt;</comment>
                            <comment id="17685124" author="petertoth" created="Tue, 7 Feb 2023 07:56:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ritikam&quot; class=&quot;user-hover&quot; rel=&quot;ritikam&quot;&gt;ritikam&lt;/a&gt;, please use the Pyspark repro in description or add a 2nd row to your input_table if you use Scala. That&apos;s because Spark can optimize out count distinct from one row local relations.&lt;/p&gt;</comment>
                            <comment id="17685466" author="ritikam" created="Tue, 7 Feb 2023 20:58:08 +0000"  >&lt;p&gt;Hello added three rows to input_table. Still no error. I do have DPP enabled.&lt;/p&gt;

&lt;p&gt;*********************************************************************&lt;/p&gt;

&lt;p&gt;Using Scala version 2.12.15 (Java HotSpot(TM) 64-Bit Server VM, Java 12.0.2)&lt;/p&gt;

&lt;p&gt;Type in expressions to have them evaluated.&lt;/p&gt;

&lt;p&gt;Type :help for more information.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; val df = Seq((&quot;a&quot;,&quot;b&quot;),(&quot;c&quot;,&quot;d&quot;),(&quot;e&quot;,&quot;f&quot;)).toDF(&quot;surname&quot;,&quot;first_name&quot;)&lt;/p&gt;

&lt;p&gt;&lt;b&gt;df&lt;/b&gt;: &lt;b&gt;org.apache.spark.sql.DataFrame&lt;/b&gt; = &lt;span class=&quot;error&quot;&gt;&amp;#91;surname: string, first_name: string&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; df.createOrReplaceTempView(&quot;input_table&quot;)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; spark.sql(&quot;select(Select Count(Distinct first_name) from input_table) As distinct_value_count from input_table Union all select (select count(Distinct surname) from input_table) as distinct_value_count from input_table&quot;).show()&lt;/p&gt;

&lt;p&gt;&lt;ins&gt;--------------------&lt;/ins&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;distinct_value_count&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;--------------------&lt;/ins&gt;&lt;/p&gt;

&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 3&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;--------------------&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;**************************************************************&lt;/p&gt;

&lt;p&gt;AdaptiveSparkPlan isFinalPlan=false&lt;br/&gt;
+- Union&lt;br/&gt;
&#160; &#160;:- Project &lt;a href=&quot;#145, [id=#571] as string) AS distinct_value_count#161&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cast(Subquery subquery#145, [id=#571] as string) AS distinct_value_count#161&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;: &#160;+- Subquery subquery#145, &lt;a href=&quot;#571&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#571&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; +- AdaptiveSparkPlan isFinalPlan=false&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160;+- HashAggregate(keys=[], functions=&lt;a href=&quot;#8)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count(distinct first_name#8)&lt;/a&gt;, output=&lt;a href=&quot;#152L&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count(DISTINCT first_name)#152L&lt;/a&gt;)&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; +- Exchange SinglePartition, ENSURE_REQUIREMENTS, &lt;a href=&quot;#569&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#569&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; &#160; &#160;+- HashAggregate(keys=[], functions=&lt;a href=&quot;#8)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;partial_count(distinct first_name#8)&lt;/a&gt;, output=&lt;a href=&quot;#167L&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count#167L&lt;/a&gt;)&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; +- HashAggregate(keys=&lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;first_name#8&lt;/a&gt;, functions=[], output=&lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;first_name#8&lt;/a&gt;)&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;+- Exchange hashpartitioning(first_name#8, 200), ENSURE_REQUIREMENTS, &lt;a href=&quot;#565&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#565&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; +- HashAggregate(keys=&lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;first_name#8&lt;/a&gt;, functions=[], output=&lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;first_name#8&lt;/a&gt;)&lt;br/&gt;
&#160; &#160;: &#160;: &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;+- LocalTableScan &lt;a href=&quot;#8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;first_name#8&lt;/a&gt;&lt;br/&gt;
&#160; &#160;: &#160;+- LocalTableScan &lt;a href=&quot;#2, _2#3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;_1#2, _2#3&lt;/a&gt;&lt;br/&gt;
&#160; &#160;+- Project &lt;a href=&quot;#147, [id=#590] as string) AS distinct_value_count#163&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;cast(Subquery subquery#147, [id=#590] as string) AS distinct_value_count#163&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; : &#160;+- Subquery subquery#147, &lt;a href=&quot;#590&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#590&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; +- AdaptiveSparkPlan isFinalPlan=false&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160;+- HashAggregate(keys=[], functions=&lt;a href=&quot;#7)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count(distinct surname#7)&lt;/a&gt;, output=&lt;a href=&quot;#154L&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count(DISTINCT surname)#154L&lt;/a&gt;)&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; +- Exchange SinglePartition, ENSURE_REQUIREMENTS, &lt;a href=&quot;#588&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#588&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; &#160; &#160;+- HashAggregate(keys=[], functions=&lt;a href=&quot;#7)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;partial_count(distinct surname#7)&lt;/a&gt;, output=&lt;a href=&quot;#170L&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;count#170L&lt;/a&gt;)&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; +- HashAggregate(keys=&lt;a href=&quot;#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;surname#7&lt;/a&gt;, functions=[], output=&lt;a href=&quot;#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;surname#7&lt;/a&gt;)&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;+- Exchange hashpartitioning(surname#7, 200), ENSURE_REQUIREMENTS, &lt;a href=&quot;#584&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;id=#584&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; +- HashAggregate(keys=&lt;a href=&quot;#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;surname#7&lt;/a&gt;, functions=[], output=&lt;a href=&quot;#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;surname#7&lt;/a&gt;)&lt;br/&gt;
&#160; &#160; &#160; : &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;+- LocalTableScan &lt;a href=&quot;#7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;surname#7&lt;/a&gt;&lt;br/&gt;
&#160; &#160; &#160; +- LocalTableScan &lt;a href=&quot;#149, _2#150&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;_1#149, _2#150&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17685858" author="petertoth" created="Wed, 8 Feb 2023 11:16:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ritikam&quot; class=&quot;user-hover&quot; rel=&quot;ritikam&quot;&gt;ritikam&lt;/a&gt;, you also need to disable the &quot;ConvertToLocalRelation&quot; rule optimization `--conf &quot;spark.sql.optimizer.excludedRules=org.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation&quot;` to get the error from spark-shell.&lt;/p&gt;</comment>
                            <comment id="17686081" author="ritikam" created="Wed, 8 Feb 2023 19:40:59 +0000"  >&lt;p&gt;Yes that caused the error to appear. Thanks&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 39 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1fnfk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>