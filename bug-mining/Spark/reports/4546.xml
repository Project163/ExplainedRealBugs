<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:51:12 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17714] ClassCircularityError is thrown when using org.apache.spark.util.Utils.classForName&#160;</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17714</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;This jira is a follow up to &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-15857&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;SPARK-15857&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;Task invokes CallerContext. SetCurrentContext() to set its callerContext to HDFS. In SetCurrentContext(), it tries looking for class &lt;tt&gt;org.apache.hadoop.ipc.CallerContext&lt;/tt&gt; by using &lt;tt&gt;org.apache.spark.util.Utils.classForName&lt;/tt&gt;. This causes ClassCircularityError to be thrown when running ReplSuite in master Maven builds (The same tests pass in the SBT build). A hotfix &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-17710&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;SPARK-17710&lt;/a&gt; has been made by using Class.forName instead, but it needs further investigation.&lt;/p&gt;

&lt;p&gt;Error:&lt;br/&gt;
&lt;a href=&quot;https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Test%20(Dashboard)/job/spark-master-test-maven-hadoop-2.3/2000/testReport/junit/org.apache.spark.repl/ReplSuite/simple_foreach_with_accumulator/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Test%20(Dashboard)/job/spark-master-test-maven-hadoop-2.3/2000/testReport/junit/org.apache.spark.repl/ReplSuite/simple_foreach_with_accumulator/&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; accum: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 0, name: None, value: 0)
scala&amp;gt; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.ClassCircularityError: io/netty/util/internal/_matchers_/org/apache/spark/network/protocol/MessageMatcher
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:348)
at io.netty.util.internal.JavassistTypeParameterMatcherGenerator.generate(JavassistTypeParameterMatcherGenerator.java:62)
at io.netty.util.internal.JavassistTypeParameterMatcherGenerator.generate(JavassistTypeParameterMatcherGenerator.java:54)
at io.netty.util.internal.TypeParameterMatcher.get(TypeParameterMatcher.java:42)
at io.netty.util.internal.TypeParameterMatcher.find(TypeParameterMatcher.java:78)
at io.netty.handler.codec.MessageToMessageEncoder.&amp;lt;init&amp;gt;(MessageToMessageEncoder.java:59)
at org.apache.spark.network.protocol.MessageEncoder.&amp;lt;init&amp;gt;(MessageEncoder.java:34)
at org.apache.spark.network.TransportContext.&amp;lt;init&amp;gt;(TransportContext.java:78)
at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:354)
at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:324)
at org.apache.spark.repl.ExecutorClassLoader.org$apache$spark$repl$ExecutorClassLoader$$getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:90)
at org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:57)
at org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:57)
at org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:162)
at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:80)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:424)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:357)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:348)
at io.netty.util.internal.JavassistTypeParameterMatcherGenerator.generate(JavassistTypeParameterMatcherGenerator.java:62)
at io.netty.util.internal.JavassistTypeParameterMatcherGenerator.generate(JavassistTypeParameterMatcherGenerator.java:54)
at io.netty.util.internal.TypeParameterMatcher.get(TypeParameterMatcher.java:42)
at io.netty.util.internal.TypeParameterMatcher.find(TypeParameterMatcher.java:78)
at io.netty.handler.codec.MessageToMessageEncoder.&amp;lt;init&amp;gt;(MessageToMessageEncoder.java:59)
at org.apache.spark.network.protocol.MessageEncoder.&amp;lt;init&amp;gt;(MessageEncoder.java:34)
at org.apache.spark.network.TransportContext.&amp;lt;init&amp;gt;(TransportContext.java:78)
at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:354)
at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:324)
at org.apache.spark.repl.ExecutorClassLoader.org$apache$spark$repl$ExecutorClassLoader$$getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:90)
at org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:57)
at org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:57)
at org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:162)
at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:80)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:424)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:357)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:348)
at org.apache.spark.util.Utils$.classForName(Utils.scala:225)
at org.apache.spark.util.CallerContext.setCurrentContext(Utils.scala:2492)
at org.apache.spark.scheduler.Task.run(Task.scala:96)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Driver stacktrace:
at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1433)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1421)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1420)
at scala.collection.mutable.ResizableArray$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(ResizableArray.scala:59)
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1420)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
at scala.Option.foreach(Option.scala:257)
at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1648)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1603)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1592)
at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:1901)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:1914)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:1927)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:1941)
at org.apache.spark.rdd.RDD$$anonfun$foreach$1.apply(RDD.scala:894)
at org.apache.spark.rdd.RDD$$anonfun$foreach$1.apply(RDD.scala:892)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
at org.apache.spark.rdd.RDD.foreach(RDD.scala:892)
... 94 elided
Caused by: java.lang.ClassCircularityError: io/netty/util/internal/_matchers_/org/apache/spark/network/protocol/MessageMatcher
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:348)
at io.netty.util.internal.JavassistTypeParameterMatcherGenerator.generate(JavassistTypeParameterMatcherGenerator.java:62)
at io.netty.util.internal.JavassistTypeParameterMatcherGenerator.generate(JavassistTypeParameterMatcherGenerator.java:54)
at io.netty.util.internal.TypeParameterMatcher.get(TypeParameterMatcher.java:42)
at io.netty.util.internal.TypeParameterMatcher.find(TypeParameterMatcher.java:78)
at io.netty.handler.codec.MessageToMessageEncoder.&amp;lt;init&amp;gt;(MessageToMessageEncoder.java:59)
at org.apache.spark.network.protocol.MessageEncoder.&amp;lt;init&amp;gt;(MessageEncoder.java:34)
at org.apache.spark.network.TransportContext.&amp;lt;init&amp;gt;(TransportContext.java:78)
at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:354)
at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:324)
at org.apache.spark.repl.ExecutorClassLoader.org$apache$spark$repl$ExecutorClassLoader$$getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:90)
at org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:57)
at org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:57)
at org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:162)
at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:80)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:424)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:357)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:348)
at io.netty.util.internal.JavassistTypeParameterMatcherGenerator.generate(JavassistTypeParameterMatcherGenerator.java:62)
at io.netty.util.internal.JavassistTypeParameterMatcherGenerator.generate(JavassistTypeParameterMatcherGenerator.java:54)
at io.netty.util.internal.TypeParameterMatcher.get(TypeParameterMatcher.java:42)
at io.netty.util.internal.TypeParameterMatcher.find(TypeParameterMatcher.java:78)
at io.netty.handler.codec.MessageToMessageEncoder.&amp;lt;init&amp;gt;(MessageToMessageEncoder.java:59)
at org.apache.spark.network.protocol.MessageEncoder.&amp;lt;init&amp;gt;(MessageEncoder.java:34)
at org.apache.spark.network.TransportContext.&amp;lt;init&amp;gt;(TransportContext.java:78)
at org.apache.spark.rpc.netty.NettyRpcEnv.downloadClient(NettyRpcEnv.scala:354)
at org.apache.spark.rpc.netty.NettyRpcEnv.openChannel(NettyRpcEnv.scala:324)
at org.apache.spark.repl.ExecutorClassLoader.org$apache$spark$repl$ExecutorClassLoader$$getClassFileInputStreamFromSparkRPC(ExecutorClassLoader.scala:90)
at org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:57)
at org.apache.spark.repl.ExecutorClassLoader$$anonfun$1.apply(ExecutorClassLoader.scala:57)
at org.apache.spark.repl.ExecutorClassLoader.findClassLocally(ExecutorClassLoader.scala:162)
at org.apache.spark.repl.ExecutorClassLoader.findClass(ExecutorClassLoader.scala:80)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:424)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:357)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:348)
at org.apache.spark.util.Utils$.classForName(Utils.scala:225)
at org.apache.spark.util.CallerContext.setCurrentContext(Utils.scala:2492)
at org.apache.spark.scheduler.Task.run(Task.scala:96)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
scala&amp;gt; res1: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = 0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13008388">SPARK-17714</key>
            <summary>ClassCircularityError is thrown when using org.apache.spark.util.Utils.classForName&#160;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zsxwing">Shixiong Zhu</assignee>
                                    <reporter username="WeiqingYang">Weiqing Yang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 28 Sep 2016 23:26:28 +0000</created>
                <updated>Mon, 13 Feb 2017 20:04:44 +0000</updated>
                            <resolved>Mon, 13 Feb 2017 20:04:36 +0000</resolved>
                                                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15572435" author="srowen" created="Thu, 13 Oct 2016 16:34:44 +0000"  >&lt;p&gt;This is resolved now, right?&lt;/p&gt;</comment>
                            <comment id="15572580" author="weiqingyang" created="Thu, 13 Oct 2016 17:17:57 +0000"  >&lt;p&gt;Not yet, need to investigate more. Could we pull in people more familiar with the Repl classloader stuff? Thanks.&lt;/p&gt;</comment>
                            <comment id="15856638" author="lian cheng" created="Tue, 7 Feb 2017 19:38:18 +0000"  >&lt;p&gt;Although I&apos;ve no idea why this error occurs, it seems that setting system property &lt;tt&gt;io.netty.noJavassist&lt;/tt&gt; to &lt;tt&gt;true&lt;/tt&gt; can workaround this issue by disabling Javassist usage in Netty.&lt;/p&gt;</comment>
                            <comment id="15858482" author="apachespark" created="Wed, 8 Feb 2017 20:13:04 +0000"  >&lt;p&gt;User &apos;zsxwing&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16859&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16859&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13008360">SPARK-17710</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12977449">SPARK-15857</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 40 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i347vr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>