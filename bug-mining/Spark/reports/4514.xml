<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:50:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-10063] Remove DirectParquetOutputCommitter</title>
                <link>https://issues.apache.org/jira/browse/SPARK-10063</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When we use DirectParquetOutputCommitter on S3 and speculation is enabled, there is a chance that we can loss data. &lt;/p&gt;

&lt;p&gt;Here is the code to reproduce the problem.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.functions._
val failSpeculativeTask = sqlContext.udf.register(&lt;span class=&quot;code-quote&quot;&gt;&quot;failSpeculativeTask&quot;&lt;/span&gt;, (i: Int, partitionId: Int, attemptNumber: Int) =&amp;gt; {
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (partitionId == 0 &amp;amp;&amp;amp; i == 5) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (attemptNumber &amp;gt; 0) {
      &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(15000)
      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Exception(&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; exception&quot;&lt;/span&gt;)
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(10000)
    }
  }
  
  i
})

val df = sc.parallelize((1 to 100), 20).mapPartitions { iter =&amp;gt;
  val context = org.apache.spark.TaskContext.get()
  val partitionId = context.partitionId
  val attemptNumber = context.attemptNumber
  iter.map(i =&amp;gt; (i, partitionId, attemptNumber))
}.toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;i&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;partitionId&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;attemptNumber&quot;&lt;/span&gt;)

df
  .select(failSpeculativeTask($&lt;span class=&quot;code-quote&quot;&gt;&quot;i&quot;&lt;/span&gt;, $&lt;span class=&quot;code-quote&quot;&gt;&quot;partitionId&quot;&lt;/span&gt;, $&lt;span class=&quot;code-quote&quot;&gt;&quot;attemptNumber&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;i&quot;&lt;/span&gt;), $&lt;span class=&quot;code-quote&quot;&gt;&quot;partitionId&quot;&lt;/span&gt;, $&lt;span class=&quot;code-quote&quot;&gt;&quot;attemptNumber&quot;&lt;/span&gt;)
  .write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).format(&lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;).save(&lt;span class=&quot;code-quote&quot;&gt;&quot;/home/yin/outputCommitter&quot;&lt;/span&gt;)

sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;/home/yin/outputCommitter&quot;&lt;/span&gt;).count
&lt;span class=&quot;code-comment&quot;&gt;// The result is 99 and 5 is missing from the output.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What happened is that the original task finishes first and uploads its output file to S3, then the speculative task somehow fails. Because we have to call output stream&apos;s close method, which uploads data to S3, we actually uploads the partial result generated by the failed speculative task to S3 and this file overwrites the correct file generated by the original task.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12856694">SPARK-10063</key>
            <summary>Remove DirectParquetOutputCommitter</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rxin">Reynold Xin</assignee>
                                    <reporter username="yhuai">Yin Huai</reporter>
                        <labels>
                    </labels>
                <created>Mon, 17 Aug 2015 18:38:05 +0000</created>
                <updated>Tue, 6 Feb 2018 12:25:49 +0000</updated>
                            <resolved>Thu, 7 Apr 2016 07:51:49 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>20</watches>
                                                                                                                <comments>
                            <comment id="14700347" author="rxin" created="Mon, 17 Aug 2015 22:31:56 +0000"  >&lt;p&gt;Let&apos;s not remove it for now until we have a better alternative.&lt;/p&gt;</comment>
                            <comment id="15171744" author="stevel@apache.org" created="Mon, 29 Feb 2016 11:05:46 +0000"  >&lt;p&gt;The fault is having speculation turned on, rather than the committer itself. Best to add a way for the system to detect that the output is going to an object store with potential consistency issues, and reject.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9545&quot; title=&quot;Improve logging in ActiveStandbyElector&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9545&quot;&gt;&lt;del&gt;HADOOP-9545&lt;/del&gt;&lt;/a&gt; we&apos;ve been considering an explicit object store API, one which uses PUT to write stuff, rather than pretend that the output stream is writing stuff and that &lt;tt&gt;close()&lt;/tt&gt; is a low-cost, minimal side-effect operation.&lt;/p&gt;</comment>
                            <comment id="15172277" author="yhuai" created="Mon, 29 Feb 2016 18:13:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steve_l&quot; class=&quot;user-hover&quot; rel=&quot;steve_l&quot;&gt;steve_l&lt;/a&gt; Seems &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9545&quot; title=&quot;Improve logging in ActiveStandbyElector&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9545&quot;&gt;&lt;del&gt;HADOOP-9545&lt;/del&gt;&lt;/a&gt; is not the right jira?&lt;/p&gt;</comment>
                            <comment id="15172654" author="stevel@apache.org" created="Mon, 29 Feb 2016 21:37:04 +0000"  >&lt;p&gt;sorry! &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9565&quot; title=&quot;Add a Blobstore interface to add to blobstore FileSystems&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9565&quot;&gt;HADOOP-9565&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15221551" author="stevel@apache.org" created="Fri, 1 Apr 2016 11:06:05 +0000"  >&lt;p&gt;I should add that as the default committer is using rename(), on some object stores (s3n, swift), that&apos;s a client-side copy may be taking place. On s3a a server-side copy happens. After all of these, a recursive delete kicks in. So the FileOutputCommitter is equally prone to race conditions, and uses significantly more IO; rename() is likely to take time O(data) rather than O(1). I&apos;d go for direct, if you are planning to use s3 as the direct output of an operation. For speculation, better to write to HDFS and then copy after&lt;/p&gt;</comment>
                            <comment id="15229675" author="rxin" created="Thu, 7 Apr 2016 04:34:30 +0000"  >&lt;p&gt;Note that since this is a problem when there are multiple attempts of the same task due to failures, even when speculation is off. Let&apos;s remove it in Spark 2.0 so users don&apos;t run into corrupted outputs.&lt;/p&gt;</comment>
                            <comment id="15229679" author="apachespark" created="Thu, 7 Apr 2016 04:38:03 +0000"  >&lt;p&gt;User &apos;rxin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12229&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12229&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15229880" author="stevel@apache.org" created="Thu, 7 Apr 2016 08:16:13 +0000"  >&lt;p&gt;The problem with returning to the classic committer is that it assumes that rename is O(1) &amp;amp; atomic, neither condition holding against s3 or swift. It can fail too, except the failure window is smaller (the O(output-size) rename phase) rather than the whole app.&lt;/p&gt;

&lt;p&gt;Someone (and I suspect it will be me, unless there are other volunteers) will have to do something that works better. Ideally something like direct output with a commit protocol that either works well on an object store with create consistency (as all S3 installations now do), or at least can outsource the consistency requirements to something else (as s3mper does).&lt;/p&gt;

&lt;p&gt;At the very least, it can do recovery of previous failures on startup through some cleanup mechanism.&lt;/p&gt;</comment>
                            <comment id="15229953" author="mkim" created="Thu, 7 Apr 2016 09:05:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt;, can you clarify why this is a problem even when speculation is off? I&apos;ve been using direct output committers without any problem with speculation off. DataFrame knew how to clean up left-over files from failed tasks as long as the two task runs don&apos;t overlap. (i.e. retry starts after the former try finishes)&lt;/p&gt;</comment>
                            <comment id="15231465" author="rxin" created="Fri, 8 Apr 2016 01:18:35 +0000"  >&lt;p&gt;I think Josh et al already replied &amp;#8211; but to close the loop, the direct committer is not safe when there is a network partition, e.g. Spark driver might not be aware of a task that&apos;s running on the executor.&lt;/p&gt;</comment>
                            <comment id="15377301" author="matt.martin" created="Thu, 14 Jul 2016 17:16:07 +0000"  >&lt;p&gt;For what it&apos;s worth, I gather that the Netflix folks have their own S3-specific solution (based purely on the couple minutes they spend talking about in this Hadoop Summit talk: &lt;a href=&quot;https://youtu.be/85sew9OFaYc?t=8m39s&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://youtu.be/85sew9OFaYc?t=8m39s&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="15405663" author="andyd88" created="Wed, 3 Aug 2016 10:09:24 +0000"  >&lt;p&gt;What&apos;s the alternative for this? Because we rely on this for publishing our parquet files to S3 and without this the normal output committer takes forever to rename the files in S3.&lt;/p&gt;</comment>
                            <comment id="15410870" author="stevel@apache.org" created="Sun, 7 Aug 2016 08:54:20 +0000"  >&lt;p&gt;The solution for this is going to be s3guard, &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13345&quot; title=&quot;S3Guard: Improved Consistency for S3A&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13345&quot;&gt;&lt;del&gt;HADOOP-13345&lt;/del&gt;&lt;/a&gt;, which adds the dynamo-metadata storing for atomic/consistent operations, plus, as an added bonus, the ability to skip s3 HTTP calls in getFileStatus(). That&apos;ll be the foundation for an output committer to handle speculative commits and bypass the rename.&lt;/p&gt;

&lt;p&gt;That work is just starting up &#8212;I would strongly encourage you to get involved, making sure your needs are represented, and helping test it.&lt;/p&gt;

&lt;p&gt;Until then: &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;switch your code to using s3a and Hadoop 2.7.2+ ; it&apos;s better all round, gets better in Hadoop 2.8, and is the basis for s3guard.&lt;/li&gt;
	&lt;li&gt;use the Hadoop &lt;tt&gt;FileOutputCommitter&lt;/tt&gt; and set &lt;tt&gt;mapreduce.fileoutputcommitter.algorithm.version&lt;/tt&gt; to 2.&lt;/li&gt;
&lt;/ol&gt;

</comment>
                            <comment id="15486990" author="mayank-shete" created="Tue, 13 Sep 2016 11:38:58 +0000"  >&lt;p&gt;How can you achieve this in AWS EMR 5.0 while using Spark 2.0 ?&lt;/p&gt;</comment>
                            <comment id="15490023" author="stevel@apache.org" created="Wed, 14 Sep 2016 10:05:00 +0000"  >&lt;p&gt;Amazon EMR&apos;s s3 is its own codebase; afraid you&apos;ll have to talk to the EMR team there&lt;/p&gt;</comment>
                            <comment id="15543412" author="aid129" created="Mon, 3 Oct 2016 21:01:04 +0000"  >&lt;p&gt;You can add this line for your SparkContext, and this change the EMR&apos;s hadoop config&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sparkContext.hadoopConfiguration.set(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapreduce.fileoutputcommitter.algorithm.version&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;2&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15547216" author="yhuai" created="Wed, 5 Oct 2016 00:43:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt; I took a quick look at hadoop 1 (&lt;a href=&quot;https://github.com/apache/hadoop/blob/release-1.2.1/src/mapred/org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter.java#L111&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/release-1.2.1/src/mapred/org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter.java#L111&lt;/a&gt;) and hadoop 2 (&lt;a href=&quot;https://github.com/apache/hadoop/blob/branch-2.7.3/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter.java#L326&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/branch-2.7.3/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter.java#L326&lt;/a&gt;). Seems Hadoop 1 actually uses algorithm 2. Is my understanding correct?&lt;/p&gt;</comment>
                            <comment id="15548557" author="stevel@apache.org" created="Wed, 5 Oct 2016 12:24:35 +0000"  >&lt;p&gt;Looking at the git logs to see which code changed, &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-4815&quot; title=&quot;Speed up FileOutputCommitter#commitJob for many output files&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-4815&quot;&gt;&lt;del&gt;MAPREDUCE-4815&lt;/del&gt;&lt;/a&gt;(&lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-4815&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/MAPREDUCE-4815&lt;/a&gt;) implies that you are correct &#8212;but that at some point in Hadoop 0.23 (the one between 1.x and 2.x), the commit algorithm changed and slowed down&lt;/p&gt;</comment>
                            <comment id="15549570" author="yhuai" created="Wed, 5 Oct 2016 18:24:03 +0000"  >&lt;p&gt;Thanks! Seems &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-2702&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/MAPREDUCE-2702&lt;/a&gt; introduced the change (&lt;a href=&quot;https://github.com/apache/hadoop/commit/ea8f6cf534c158894e53159d11fab3509d1dd5eb#diff-57c61145d037a5af6b2db37812d9bab3L73&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;diff&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="15574339" author="chiragvaya" created="Fri, 14 Oct 2016 05:55:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mkim&quot; class=&quot;user-hover&quot; rel=&quot;mkim&quot;&gt;mkim&lt;/a&gt; Can you please tell us in what environment(Standalone Spark on single node or multiple nodes or AWS EMR) were you using direct output committer ? According to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt;, any environment that has network partition (e.g. AWS EMR) would lead to inconsistencies. Please correct me if i am wrong on this.&lt;/p&gt;</comment>
                            <comment id="15644092" author="stevel@apache.org" created="Mon, 7 Nov 2016 12:49:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13786&quot; title=&quot;Add S3A committers for zero-rename commits to S3 endpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13786&quot;&gt;&lt;del&gt;HADOOP-13786&lt;/del&gt;&lt;/a&gt; covers adding a committer for direct output to S3, provided S3 adds the ability to fail any PUT which would ovewrite and existing blob, that is: with an atomic PUT-without-overwrite. Dynamo can add this for AWS S3; other implementations of the API may be able to provide something similar&lt;/p&gt;</comment>
                            <comment id="15852170" author="apachespark" created="Fri, 3 Feb 2017 21:47:03 +0000"  >&lt;p&gt;User &apos;rxin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16796&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16796&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16094610" author="apachespark" created="Thu, 20 Jul 2017 12:30:03 +0000"  >&lt;p&gt;User &apos;cloud-fan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18689&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18689&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16097479" author="apachespark" created="Sun, 23 Jul 2017 02:00:03 +0000"  >&lt;p&gt;User &apos;cloud-fan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18716&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18716&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12838551">SPARK-8413</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13017346">HADOOP-13786</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12782149">SPARK-6352</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12839975">SPARK-8578</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 17 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2j0on:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>