<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:35:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-11633] HiveContext throws TreeNode Exception : Failed to Copy Node</title>
                <link>https://issues.apache.org/jira/browse/SPARK-11633</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;h2&gt;&lt;a name=&quot;HiveContext%23sqlisthrowingthefollowingexceptioninaspecificscenario%3A&quot;&gt;&lt;/a&gt;HiveContext#sql is throwing the following exception in a specific scenario :&lt;/h2&gt;

&lt;h2&gt;&lt;a name=&quot;Exception%3A&quot;&gt;&lt;/a&gt;Exception :&lt;/h2&gt;

&lt;p&gt;Caused by: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: &lt;br/&gt;
Failed to copy node.&lt;br/&gt;
Is otherCopyArgs specified correctly for LogicalRDD.&lt;br/&gt;
Exception message: wrong number of arguments&lt;br/&gt;
ctor: public org.apache.spark.sql.execution.LogicalRDD&lt;br/&gt;
(scala.collection.Seq,org.apache.spark.rdd.RDD,org.apache.spark.sql.SQLContext)?&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;Code%3A&quot;&gt;&lt;/a&gt;Code :&lt;/h2&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;SparkClient.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;StructField[] fields = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructField[2];
fields[0] = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;F1&quot;&lt;/span&gt;, DataTypes.StringType, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, Metadata.empty());
fields[1] = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;F2&quot;&lt;/span&gt;, DataTypes.StringType, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, Metadata.empty());
    
JavaRDD&amp;lt;Row&amp;gt; rdd = javaSparkContext.parallelize(Arrays.asList(RowFactory.create(&lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;, &quot;&lt;/span&gt;&quot;)));

DataFrame df = sparkHiveContext.createDataFrame(rdd, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructType(fields));
sparkHiveContext.registerDataFrameAsTable(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;t1&quot;&lt;/span&gt;);

DataFrame aliasedDf = sparkHiveContext.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select f1, F2 as F2 from t1&quot;&lt;/span&gt;);

sparkHiveContext.registerDataFrameAsTable(aliasedDf, &lt;span class=&quot;code-quote&quot;&gt;&quot;t2&quot;&lt;/span&gt;);
sparkHiveContext.registerDataFrameAsTable(aliasedDf, &lt;span class=&quot;code-quote&quot;&gt;&quot;t3&quot;&lt;/span&gt;);

sparkHiveContext.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select a.F1 from t2 a &lt;span class=&quot;code-keyword&quot;&gt;inner&lt;/span&gt; join t3 b on a.F2=b.F2&quot;&lt;/span&gt;);

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;h2&gt;&lt;a name=&quot;Observations%3A&quot;&gt;&lt;/a&gt;Observations :&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;if F1(exact name of field) is used instead of f1, the code works correctly.&lt;/li&gt;
	&lt;li&gt;If alias is not used for F2, then also code works irrespective of case of F1.&lt;/li&gt;
	&lt;li&gt;if Field F2 is not used in the final query also the code works correctly.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="12911918">SPARK-11633</key>
            <summary>HiveContext throws TreeNode Exception : Failed to Copy Node</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="smilegator">Xiao Li</assignee>
                                    <reporter username="Saurabh Santhosh">Saurabh Santhosh</reporter>
                        <labels>
                    </labels>
                <created>Tue, 10 Nov 2015 17:55:01 +0000</created>
                <updated>Fri, 20 Nov 2015 12:20:56 +0000</updated>
                            <resolved>Thu, 19 Nov 2015 20:45:49 +0000</resolved>
                                    <version>1.4.1</version>
                    <version>1.5.0</version>
                    <version>1.5.1</version>
                                    <fixVersion>1.6.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="15000042" author="smilegator" created="Wed, 11 Nov 2015 07:12:49 +0000"  >&lt;p&gt;I am interested in this issue. Can you post your exception? &lt;/p&gt;</comment>
                            <comment id="15000328" author="saurabh santhosh" created="Wed, 11 Nov 2015 12:59:07 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;Stacktrace&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: makeCopy, tree:
LogicalRDD [F1#2,F2#3], MapPartitionsRDD[2] at createDataFrame at SparkClientTest.java:79

	at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:49)
	at org.apache.spark.sql.catalyst.trees.TreeNode.makeCopy(TreeNode.scala:346)
	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsDown(QueryPlan.scala:96)
	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressions(QueryPlan.scala:64)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$8$$anonfun$3.applyOrElse(Analyzer.scala:333)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$8$$anonfun$3.applyOrElse(Analyzer.scala:332)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:286)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:286)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:285)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:299)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenUp(TreeNode.scala:329)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:283)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:299)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenUp(TreeNode.scala:329)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:283)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:299)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenUp(TreeNode.scala:329)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:283)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:299)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenUp(TreeNode.scala:329)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:283)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$8.applyOrElse(Analyzer.scala:332)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$8.applyOrElse(Analyzer.scala:243)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:286)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:286)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:285)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:299)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenUp(TreeNode.scala:329)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:283)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.apply(Analyzer.scala:243)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.apply(Analyzer.scala:242)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:61)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:59)
	at scala.collection.LinearSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(LinearSeqOptimized.scala:111)
	at scala.collection.immutable.List.foldLeft(List.scala:84)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:59)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:51)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:51)
	at org.apache.spark.sql.SQLContext$QueryExecution.analyzed$lzycompute(SQLContext.scala:933)
	at org.apache.spark.sql.SQLContext$QueryExecution.analyzed(SQLContext.scala:933)
	at org.apache.spark.sql.SQLContext$QueryExecution.assertAnalyzed(SQLContext.scala:931)
	at org.apache.spark.sql.DataFrame.&amp;lt;init&amp;gt;(DataFrame.scala:131)
	at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:755)
Caused by: org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: 
Failed to copy node.
Is otherCopyArgs specified correctly &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; LogicalRDD.
Exception message: wrong number of arguments
ctor: &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; org.apache.spark.sql.execution.LogicalRDD(scala.collection.Seq,org.apache.spark.rdd.RDD,org.apache.spark.sql.SQLContext)?
args: List(f1#2, F2#3), MapPartitionsRDD[2] at createDataFrame at SparkClientTest.java:79
           , tree:
LogicalRDD [F1#2,F2#3], MapPartitionsRDD[2] at createDataFrame at SparkClientTest.java:79

	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$makeCopy$1.apply(TreeNode.scala:364)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$makeCopy$1.apply(TreeNode.scala:346)
	at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:48)
	... 135 more

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15006493" author="saurabh santhosh" created="Mon, 16 Nov 2015 10:43:08 +0000"  >&lt;p&gt;I Tried using version 1.4.1 as well as 1.5.1.&lt;br/&gt;
In Both cases, i got the same error.&lt;/p&gt;

&lt;p&gt;Following are the dependencies used (used version 1.4.1, 1.5.1):&lt;/p&gt;

&lt;p&gt;compile (&apos;org.apache.spark:spark-core_2.10:1.5.1&apos;) &lt;/p&gt;
{ exclude group: &quot;org.jboss.netty&quot; }
&lt;p&gt;compile (&apos;org.apache.spark:spark-sql_2.10:1.5.1&apos;) &lt;/p&gt;
{ exclude group: &quot;org.jboss.netty&quot; }
&lt;p&gt;compile (&apos;org.apache.spark:spark-hive_2.10:1.5.1&apos;) &lt;/p&gt;
{
    exclude group: &quot;org.jboss.netty&quot;
    exclude group: &quot;org.mortbay.jetty&quot;
  }

&lt;p&gt;Do you want me to share anything else?&lt;/p&gt;</comment>
                            <comment id="15007086" author="smilegator" created="Mon, 16 Nov 2015 18:39:19 +0000"  >&lt;p&gt;Yeah. I can reproduce it. Will try to find the root cause ASAP. &lt;/p&gt;</comment>
                            <comment id="15007668" author="smilegator" created="Tue, 17 Nov 2015 00:03:13 +0000"  >&lt;p&gt;The fix is ready. Will deliver it soon. &lt;/p&gt;</comment>
                            <comment id="15008235" author="apachespark" created="Tue, 17 Nov 2015 08:07:06 +0000"  >&lt;p&gt;User &apos;gatorsmile&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/9762&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/9762&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15010228" author="saurabh santhosh" created="Wed, 18 Nov 2015 04:53:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; Tried with your change. Works fine. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/biggrin.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15012561" author="smilegator" created="Thu, 19 Nov 2015 01:38:14 +0000"  >&lt;p&gt;Great!&lt;/p&gt;</comment>
                            <comment id="15014312" author="marmbrus" created="Thu, 19 Nov 2015 20:45:49 +0000"  >&lt;p&gt;Issue resolved by pull request 9762&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/9762&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/9762&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15015070" author="smilegator" created="Fri, 20 Nov 2015 02:38:53 +0000"  >&lt;p&gt;Thank you! &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt; This is another resolved JIRA, can you please also set me as the &apos;assigned&apos; user?&lt;/p&gt;
</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2o7dz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311620" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Shepherd</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>pwendell</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>