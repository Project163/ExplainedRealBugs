<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:36:56 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-12654] sc.wholeTextFiles with spark.hadoop.cloneConf=true fails on secure Hadoop</title>
                <link>https://issues.apache.org/jira/browse/SPARK-12654</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;On a secure hadoop cluster using pyspark or spark-shell in yarn client mode with spark.hadoop.cloneConf=true, start it up and wait for over 1 minute.  Then try to use:&lt;br/&gt;
val files =  sc.wholeTextFiles(&quot;dir&quot;) &lt;br/&gt;
files.collect()&lt;br/&gt;
and it fails with:&lt;/p&gt;

&lt;p&gt;py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.&lt;br/&gt;
: org.apache.hadoop.ipc.RemoteException(java.io.IOException): Delegation Token can be issued only with kerberos or web authentication&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:7365)&lt;br/&gt;
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:528)&lt;br/&gt;
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:963)&lt;br/&gt;
        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)&lt;br/&gt;
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)&lt;br/&gt;
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2096)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2092)&lt;br/&gt;
        at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
        at javax.security.auth.Subject.doAs(Subject.java:422)&lt;br/&gt;
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1694)&lt;br/&gt;
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2090)&lt;/p&gt;

&lt;p&gt;        at org.apache.hadoop.ipc.Client.call(Client.java:1451)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client.call(Client.java:1382)&lt;br/&gt;
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)&lt;br/&gt;
        at com.sun.proxy.$Proxy12.getDelegationToken(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getDelegationToken(ClientNamenodeProtocolTranslatorPB.java:909)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:483)&lt;br/&gt;
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)&lt;br/&gt;
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)&lt;br/&gt;
        at com.sun.proxy.$Proxy13.getDelegationToken(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient.getDelegationToken(DFSClient.java:1029)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken(DistributedFileSystem.java:1434)&lt;br/&gt;
        at org.apache.hadoop.fs.FileSystem.collectDelegationTokens(FileSystem.java:529)&lt;br/&gt;
        at org.apache.hadoop.fs.FileSystem.addDelegationTokens(FileSystem.java:507)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DistributedFileSystem.addDelegationTokens(DistributedFileSystem.java:2120)&lt;br/&gt;
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:121)&lt;br/&gt;
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:100)&lt;br/&gt;
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:80)&lt;br/&gt;
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:242)&lt;br/&gt;
        at org.apache.spark.input.WholeTextFileInputFormat.setMinPartitions(WholeTextFileInputFormat.scala:55)&lt;br/&gt;
        at org.apache.spark.rdd.WholeTextFileRDD.getPartitions(NewHadoopRDD.scala:304)&lt;br/&gt;
        at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)&lt;/p&gt;</description>
                <environment></environment>
        <key id="12927343">SPARK-12654</key>
            <summary>sc.wholeTextFiles with spark.hadoop.cloneConf=true fails on secure Hadoop</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tgraves">Thomas Graves</assignee>
                                    <reporter username="tgraves">Thomas Graves</reporter>
                        <labels>
                    </labels>
                <created>Tue, 5 Jan 2016 19:38:59 +0000</created>
                <updated>Fri, 8 Jan 2016 20:40:07 +0000</updated>
                            <resolved>Fri, 8 Jan 2016 20:40:07 +0000</resolved>
                                    <version>1.5.0</version>
                                    <fixVersion>1.6.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="15083643" author="tgraves" created="Tue, 5 Jan 2016 19:40:53 +0000"  >&lt;p&gt;So the bug here is that WholeTextFileRDD.getPartitions has:&lt;br/&gt;
val conf = getConf&lt;br/&gt;
in getConf if the cloneConf=true it creates a new Hadoop Configuration. Then it uses that to create a new newJobContext.&lt;/p&gt;

&lt;p&gt;The newJobContext will copy credentials around, but credentials are only present in a JobConf not in a Hadoop Configuration. So basically when it is cloning the hadoop configuration its changing it from a JobConf to Configuration and dropping the credentials that were there. NewHadoopRDD just uses the conf passed in for the getPartitions (not getConf) which is why it works.  &lt;/p&gt;

&lt;p&gt;Need to investigate to see if wholeTextfiles should be using conf or if getConf needs to change.&lt;/p&gt;</comment>
                            <comment id="15083663" author="tgraves" created="Tue, 5 Jan 2016 19:52:38 +0000"  >&lt;p&gt;It looks like the version of getConf in HadoopRDD already creates it as a JobConf versus a hadoop Configuration.  Not sure why NewHadoopRDD didn&apos;t do the same.  &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt;  Do you know the history on that?&lt;/p&gt;</comment>
                            <comment id="15088290" author="apachespark" created="Thu, 7 Jan 2016 22:37:04 +0000"  >&lt;p&gt;User &apos;tgravescs&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10651&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10651&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 45 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2qtfj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>