<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:59:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21033] fix the potential OOM in UnsafeExternalSorter</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21033</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;In `UnsafeInMemorySorter`, one record may take 32 bytes: 1 `long` for pointer, 1 `long` for key-prefix, and another 2 `long`s as the temporary buffer for radix sort.&lt;/p&gt;

&lt;p&gt;In `UnsafeExternalSorter`, we set the `DEFAULT_NUM_ELEMENTS_FOR_SPILL_THRESHOLD` to be `1024 * 1024 * 1024 / 2`, and hoping the max size of point array to be 8 GB. However this is wrong, `1024 * 1024 * 1024 / 2 * 32` is actually 16 GB, and if we grow the point array before reach this limitation, we may hit the max-page-size error.&lt;/p&gt;

&lt;p&gt;Users may see exception like this on large dataset:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.lang.IllegalArgumentException: Cannot allocate a page with more than 17179869176 bytes
at org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:241)
at org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:121)
at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:374)
at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:396)
at org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:94)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13078540">SPARK-21033</key>
            <summary>fix the potential OOM in UnsafeExternalSorter</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cloud_fan">Wenchen Fan</assignee>
                                    <reporter username="cloud_fan">Wenchen Fan</reporter>
                        <labels>
                    </labels>
                <created>Fri, 9 Jun 2017 08:40:04 +0000</created>
                <updated>Thu, 14 May 2020 01:38:46 +0000</updated>
                            <resolved>Mon, 30 Oct 2017 17:07:52 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="16044162" author="apachespark" created="Fri, 9 Jun 2017 08:49:02 +0000"  >&lt;p&gt;User &apos;cloud-fan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18251&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18251&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16211526" author="clehene" created="Thu, 19 Oct 2017 18:41:34 +0000"  >&lt;p&gt;I think this may be responsible for other problems, such as not being able to allocate memory while running in a container as well as getting killed from exceeding max memory.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;17/10/19 18:15:39 INFO memory.TaskMemoryManager: Memory used in task 6317340
17/10/19 18:15:39 INFO memory.TaskMemoryManager: Acquired by org.apache.spark.shuffle.sort.ShuffleExternalSorter@2c98b15b: 32.0 KB
17/10/19 18:15:39 INFO memory.TaskMemoryManager: Acquired by org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@566144b7: 64.0 KB
17/10/19 18:15:39 INFO memory.TaskMemoryManager: Acquired by org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@ea479ad: 13.3 GB
17/10/19 18:15:39 INFO memory.TaskMemoryManager: 0 bytes of memory were used by task 6317340 but are not associated with specific consumers
17/10/19 18:15:39 INFO memory.TaskMemoryManager: 14496792576 bytes of memory are used for execution and 198127044 bytes of memory are used for storage
17/10/19 18:15:39 ERROR executor.Executor: Exception in task 6.0 in stage 320.2 (TID 6317340)
java.lang.OutOfMemoryError: Unable to acquire 65536 bytes of memory, got 0
	at org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:98)
	at org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter.&amp;lt;init&amp;gt;(UnsafeInMemorySorter.java:126)
	at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.&amp;lt;init&amp;gt;(UnsafeExternalSorter.java:153)
	at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.create(UnsafeExternalSorter.java:120)
	at org.apache.spark.sql.execution.UnsafeExternalRowSorter.&amp;lt;init&amp;gt;(UnsafeExternalRowSorter.java:82)
	at org.apache.spark.sql.execution.SortExec.createSorter(SortExec.scala:87)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.init(Unknown Source)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(WholeStageCodegenExec.scala:392)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8.apply(WholeStageCodegenExec.scala:389)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16211562" author="srowen" created="Thu, 19 Oct 2017 19:10:03 +0000"  >&lt;p&gt;I&apos;m seeing that same problem consistently in a deployment &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=clehene&quot; class=&quot;user-hover&quot; rel=&quot;clehene&quot;&gt;clehene&lt;/a&gt;, though I also don&apos;t know whether it&apos;s resolved by the change above.&lt;/p&gt;</comment>
                            <comment id="16211574" author="clehene" created="Thu, 19 Oct 2017 19:17:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt; Can you update the title and description? It helps, when finding the issue through Google, to get an accurate description within JIRA &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;n UnsafeInMemorySorter, one record may take 32 bytes: 1 long for pointer, 1 long for key-prefix, and another 2 longs as the temporary buffer for radix sort.&lt;/p&gt;

&lt;p&gt;In UnsafeExternalSorter, we set the DEFAULT_NUM_ELEMENTS_FOR_SPILL_THRESHOLD to be 1024 * 1024 * 1024 / 2, and hoping the max size of point array to be 8 GB. However this is wrong, 1024 * 1024 * 1024 / 2 * 32 is actually 16 GB, and if we grow the point array before reach this limitation, we may hit the max-page-size error.&lt;/p&gt;

&lt;p&gt;This PR fixes this by making DEFAULT_NUM_ELEMENTS_FOR_SPILL_THRESHOLD 2 times smaller, and adding a safe check in UnsafeExternalSorter.growPointerArrayIfNecessary to avoid allocating a page larger than max page size.&lt;/p&gt;
&lt;/blockquote&gt;</comment>
                            <comment id="16211576" author="clehene" created="Thu, 19 Oct 2017 19:18:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; I&apos;m hitting this while running some large jobs. I&apos;m planning on patching and giving this a run today.&lt;/p&gt;</comment>
                            <comment id="16225328" author="cloud_fan" created="Mon, 30 Oct 2017 17:07:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=clehene&quot; class=&quot;user-hover&quot; rel=&quot;clehene&quot;&gt;clehene&lt;/a&gt; I think you hit a different issue. By looking at the stacktrace, seems your task failed because of running out of memory. There can be 2 possible reasons: 1) you have too many tasks running in one executor and the executor doesn&apos;t have enough memory. 2) a memory leak bug in Spark. Feel free to create a new ticket for it.&lt;/p&gt;</comment>
                            <comment id="16439118" author="apachespark" created="Mon, 16 Apr 2018 08:28:05 +0000"  >&lt;p&gt;User &apos;wangyum&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21077&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21077&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16467803" author="tgraves" created="Tue, 8 May 2018 18:33:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;&#160;the followup PR&#160;&lt;a href=&quot;https://github.com/apache/spark/pull/21077&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21077&lt;/a&gt;&#160;didn&apos;t go into spark 2.3.0, this should have had its own Jira and we need to udpate the fix version.&#160; Can you please fix so we properly track what version this is in.&#160; Also does this need to be backported to 2.3.1?&lt;/p&gt;</comment>
                            <comment id="16468231" author="cloud_fan" created="Wed, 9 May 2018 02:23:25 +0000"  >&lt;p&gt;The followup is just a code cleanup, I think we should not backport.&lt;/p&gt;

&lt;p&gt;I agree that it should have its own JIRA, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuming&quot; class=&quot;user-hover&quot; rel=&quot;yuming&quot;&gt;yuming&lt;/a&gt; can you create a new JIRA for that PR? thanks!&lt;/p&gt;</comment>
                            <comment id="17106774" author="fanyunbojerry" created="Thu, 14 May 2020 01:38:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=clehene&quot; class=&quot;user-hover&quot; rel=&quot;clehene&quot;&gt;clehene&lt;/a&gt;&#160;Since it&apos;s 2020, have you solved the problem?&lt;/p&gt;

&lt;p&gt;I&#8216;m seeing the same one.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13115895">SPARK-22438</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 26 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3g2rr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>