<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:05:41 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-27018] Checkpointed RDD deleted prematurely when using GBTClassifier</title>
                <link>https://issues.apache.org/jira/browse/SPARK-27018</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Steps to reproduce:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.ml.classification.GBTClassifier

case class Row(features: org.apache.spark.ml.linalg.Vector, label: Int)

sc.setCheckpointDir(&quot;/checkpoints&quot;)
val trainingData = sc.parallelize(1 to 2426874, 256).map(x =&amp;gt; Row(Vectors.dense(x, x + 1, x * 2 % 10), if (x % 5 == 0) 1 else 0)).toDF
val classifier = new GBTClassifier()
  .setLabelCol(&quot;label&quot;)
  .setFeaturesCol(&quot;features&quot;)
  .setProbabilityCol(&quot;probability&quot;)
  .setMaxIter(100)
  .setMaxDepth(10)
  .setCheckpointInterval(2)

classifier.fit(trainingData)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The last line fails with:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 56.0 failed 10 times, most recent failure: Lost task 0.9 in stage 56.0 (TID 12058, 127.0.0.1, executor 0): java.io.FileNotFoundException: /checkpoints/191c9209-0955-440f-8c11-f042bdf7f804/rdd-51
at com.datastax.bdp.fs.hadoop.DseFileSystem$$anonfun$1.applyOrElse(DseFileSystem.scala:63)
at com.datastax.bdp.fs.hadoop.DseFileSystem$$anonfun$1.applyOrElse(DseFileSystem.scala:61)
at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
at com.datastax.bdp.fs.hadoop.DseFileSystem.com$datastax$bdp$fs$hadoop$DseFileSystem$$translateToHadoopExceptions(DseFileSystem.scala:70)
at com.datastax.bdp.fs.hadoop.DseFileSystem$$anonfun$6.apply(DseFileSystem.scala:264)
at com.datastax.bdp.fs.hadoop.DseFileSystem$$anonfun$6.apply(DseFileSystem.scala:264)
at com.datastax.bdp.fs.hadoop.DseFsInputStream.input(DseFsInputStream.scala:31)
at com.datastax.bdp.fs.hadoop.DseFsInputStream.openUnderlyingDataSource(DseFsInputStream.scala:39)
at com.datastax.bdp.fs.hadoop.DseFileSystem.open(DseFileSystem.scala:269)
at org.apache.spark.rdd.ReliableCheckpointRDD$.readCheckpointFile(ReliableCheckpointRDD.scala:292)
at org.apache.spark.rdd.ReliableCheckpointRDD.compute(ReliableCheckpointRDD.scala:100)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:322)
at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)
at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)
at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:337)
at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:335)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
at org.apache.spark.scheduler.Task.run(Task.scala:121)
at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The problem happens as well when checkpointing directory is placed on the local file system, on a single-node setup.&#160;&lt;/p&gt;

&lt;p&gt;Debugging at the FS level showed that the driver requests to recursively delete the checkpointed rdd-51 soon before the exception gets thrown by the task.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment>&lt;p&gt;OS: Ubuntu Linux 18.10&lt;/p&gt;

&lt;p&gt;Java:&#160;java version &quot;1.8.0_201&quot;&lt;br/&gt;
Java(TM) SE Runtime Environment (build 1.8.0_201-b09)&lt;br/&gt;
Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)&lt;/p&gt;

&lt;p&gt;Reproducible with a single-node Spark in standalone mode.&lt;/p&gt;

&lt;p&gt;Reproducible with Zepellin or Spark shell.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</environment>
        <key id="13218837">SPARK-27018</key>
            <summary>Checkpointed RDD deleted prematurely when using GBTClassifier</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="podongfeng">Ruifeng Zheng</assignee>
                                    <reporter username="pkolaczk">Piotr Kolaczkowski</reporter>
                        <labels>
                    </labels>
                <created>Fri, 1 Mar 2019 08:24:52 +0000</created>
                <updated>Mon, 24 Jun 2019 14:38:29 +0000</updated>
                            <resolved>Mon, 24 Jun 2019 14:35:48 +0000</resolved>
                                    <version>2.2.2</version>
                    <version>2.2.3</version>
                    <version>2.3.3</version>
                    <version>2.4.0</version>
                                    <fixVersion>2.3.4</fixVersion>
                    <fixVersion>2.4.4</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>ML</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16781481" author="pkolaczk" created="Fri, 1 Mar 2019 09:04:37 +0000"  >&lt;p&gt;The checkpoint is deleted here (stacktrace for Spark 2.4.0):&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;removeCheckpointFile:186, PeriodicCheckpointer$ (org.apache.spark.util)
apply:175, PeriodicCheckpointer$$anonfun$removeCheckpointFile$1 (org.apache.spark.util)
apply:175, PeriodicCheckpointer$$anonfun$removeCheckpointFile$1 (org.apache.spark.util)
foreach:392, List (scala.collection.immutable)
removeCheckpointFile:174, PeriodicCheckpointer (org.apache.spark.util)
update:104, PeriodicCheckpointer (org.apache.spark.util)
boost:341, GradientBoostedTrees$ (org.apache.spark.ml.tree.impl)
run:55, GradientBoostedTrees$ (org.apache.spark.ml.tree.impl)
apply:206, GBTClassifier$$anonfun$train$1 (org.apache.spark.ml.classification)
apply:156, GBTClassifier$$anonfun$train$1 (org.apache.spark.ml.classification)
apply:183, Instrumentation$$anonfun$11 (org.apache.spark.ml.util)
apply:192, Try$ (scala.util)
instrumented:183, Instrumentation$ (org.apache.spark.ml.util)
train:156, GBTClassifier (org.apache.spark.ml.classification)
train:58, GBTClassifier (org.apache.spark.ml.classification)
fit:118, Predictor (org.apache.spark.ml)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16781492" author="pkolaczk" created="Fri, 1 Mar 2019 09:16:02 +0000"  >&lt;p&gt;PeriodicCheckpointer:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;// Remove checkpoints before the latest one.
var canDelete = true
while (checkpointQueue.size &amp;gt; 1 &amp;amp;&amp;amp; canDelete) {
  // Delete the oldest checkpoint only if the next checkpoint exists.
  if (isCheckpointed(checkpointQueue.head)) {   
    removeCheckpointFile()
  } else {
    canDelete = false
  }
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;PeriodicCheckpointer: 103:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;if (isCheckpointed(checkpointQueue.head))&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This line doesn&apos;t do what the comment says it should do; it checks the CURRENT checkpoint to remove, not the NEXT checkpoint! And the debugger tells me the next checkpoint hasn&apos;t been materialized yet.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Patch coming.&lt;/p&gt;</comment>
                            <comment id="16781501" author="pkolaczk" created="Fri, 1 Mar 2019 09:32:38 +0000"  >&lt;p&gt;Attached a patch for Spark 2.2.2. Should be compatible with all later versions.&lt;/p&gt;</comment>
                            <comment id="16781558" author="mgaido" created="Fri, 1 Mar 2019 10:43:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pkolaczk&quot; class=&quot;user-hover&quot; rel=&quot;pkolaczk&quot;&gt;pkolaczk&lt;/a&gt; thanks for reporting the issue. Spark works with PRs, not patches. Can you please submit a PR for master branch? Thanks.&lt;/p&gt;</comment>
                            <comment id="16781640" author="pkolaczk" created="Fri, 1 Mar 2019 12:57:05 +0000"  >&lt;p&gt;For master only? Why not for 2.2, 2.3, master?&lt;/p&gt;</comment>
                            <comment id="16781657" author="mgaido" created="Fri, 1 Mar 2019 13:11:44 +0000"  >&lt;p&gt;First the issue is fixed on master and then it is backported to the other branches (if there are no conflicts, the committer will do it while merging to master). Anyway, 2.2 is EOL, so it will be eventually backported to 2.3/2.4.&lt;/p&gt;</comment>
                            <comment id="16786619" author="pkolaczk" created="Thu, 7 Mar 2019 10:51:21 +0000"  >&lt;p&gt;The file does not exist on master branch. Where has that code been moved?&lt;/p&gt;</comment>
                            <comment id="16786984" author="mgaido" created="Thu, 7 Mar 2019 17:02:27 +0000"  >&lt;p&gt;The PeriodicCheckpointer is still there in master, you can check it on github: &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/util/PeriodicCheckpointer.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/util/PeriodicCheckpointer.scala&lt;/a&gt;. You can just check file histories in git in order to know what and how was changed. I&apos;d recommend you, anyway, to test whether current master is still affected by this issue as it may have been fixed since 2.2.&lt;/p&gt;</comment>
                            <comment id="16859889" author="podongfeng" created="Mon, 10 Jun 2019 10:11:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pkolaczk&quot; class=&quot;user-hover&quot; rel=&quot;pkolaczk&quot;&gt;pkolaczk&lt;/a&gt;&#160; With the codes you provided, I reproduced this failure. &lt;/p&gt;

&lt;p&gt;moreover, I doubt that this bug may also affect the computation on distributed env.&lt;/p&gt;

&lt;p&gt;I also encountered a similar case on a cluster, I will look into this.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.io.FileNotFoundException: File does not exist: /tmp/sparkGBM/application_1551338088092_2518369/checkpoints/edbd13db-b61f-445a-8703-691acd595d62/rdd-46484/_partitioner
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:71)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:61)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1929)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1900)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1803)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:604)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:388)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:624)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2094)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2090)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.base/java.security.AccessController.doPrivileged(Native Method)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1803)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2090)

&#160;&#160;&#160;&#160;&#160;&#160;&#160; at sun.reflect.GeneratedConstructorAccessor79.newInstance(Unknown Source)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1268)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1253)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1241)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:303)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:269)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DFSInputStream.&amp;lt;init&amp;gt;(DFSInputStream.java:261)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1566)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:303)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:299)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:299)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.ReliableCheckpointRDD$.org$apache$spark$rdd$ReliableCheckpointRDD$$readCheckpointedPartitionerFile(ReliableCheckpointRDD.scala:255)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$3.apply(ReliableCheckpointRDD.scala:59)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.ReliableCheckpointRDD$$anonfun$3.apply(ReliableCheckpointRDD.scala:59)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at scala.Option.orElse(Option.scala:289)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.ReliableCheckpointRDD.&amp;lt;init&amp;gt;(ReliableCheckpointRDD.scala:58)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.ReliableCheckpointRDD$.writeRDDToCheckpointDirectory(ReliableCheckpointRDD.scala:151)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.ReliableRDDCheckpointData.doCheckpoint(ReliableRDDCheckpointData.scala:58)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.RDDCheckpointData.checkpoint(RDDCheckpointData.scala:75)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.RDD$$anonfun$doCheckpoint$1.apply$mcV$sp(RDD.scala:1734)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.RDD$$anonfun$doCheckpoint$1.apply(RDD.scala:1724)
&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.rdd.RDD$$anonfun$doCheckpoint$1.apply(RDD.scala:1724)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16860579" author="podongfeng" created="Tue, 11 Jun 2019 05:49:21 +0000"  >&lt;p&gt;I test on both local env and a cluster env, and your patch works fine.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pkolaczk&quot; class=&quot;user-hover&quot; rel=&quot;pkolaczk&quot;&gt;pkolaczk&lt;/a&gt;&#160; Could you plz create a PR to master branch? I think commiters can help backporting it to older versions.&lt;/p&gt;</comment>
                            <comment id="16871240" author="srowen" created="Mon, 24 Jun 2019 14:35:48 +0000"  >&lt;p&gt;Issue resolved by pull request 24870&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24870&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24870&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12960748" name="Fix_check_if_the_next_checkpoint_exists_before_deleting_the_old_one.patch" size="793" author="pkolaczk" created="Fri, 1 Mar 2019 09:31:42 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 21 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0081c:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>