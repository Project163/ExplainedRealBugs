<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:25:01 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3266] JavaDoubleRDD doesn&apos;t contain max()</title>
                <link>https://issues.apache.org/jira/browse/SPARK-3266</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;While I can compile my code, I see:&lt;/p&gt;

&lt;p&gt;Caused by: java.lang.NoSuchMethodError: org.apache.spark.api.java.JavaDoubleRDD.max(Ljava/util/Comparator;)Ljava/lang/Double;&lt;/p&gt;

&lt;p&gt;When I try to execute my Spark code. Stepping into the JavaDoubleRDD class, I don&apos;t notice max()&lt;br/&gt;
although it is clearly listed in the documentation.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12737240">SPARK-3266</key>
            <summary>JavaDoubleRDD doesn&apos;t contain max()</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="ameyc">Amey Chaugule</reporter>
                        <labels>
                    </labels>
                <created>Wed, 27 Aug 2014 22:13:34 +0000</created>
                <updated>Sun, 7 Jun 2015 22:27:56 +0000</updated>
                            <resolved>Tue, 17 Mar 2015 16:23:57 +0000</resolved>
                                    <version>1.0.1</version>
                    <version>1.0.2</version>
                    <version>1.1.0</version>
                    <version>1.2.0</version>
                                    <fixVersion>1.2.2</fixVersion>
                    <fixVersion>1.3.1</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>Java API</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="14113710" author="srowen" created="Thu, 28 Aug 2014 12:34:34 +0000"  >&lt;p&gt;The method is declared in the superclass, JavaRDDLike: &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/api/java/JavaRDDLike.scala#L538&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/api/java/JavaRDDLike.scala#L538&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You are running a different version of Spark than you are compiling with, and the runtime version is perhaps too old to contain this method. This is not a Spark issue.&lt;/p&gt;</comment>
                            <comment id="14114328" author="lanzaa" created="Thu, 28 Aug 2014 20:50:50 +0000"  >&lt;p&gt;I have attached a simple java project which reproduces the issue. &lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12665070/12665070_spark-repro-3266.tar.gz&quot; title=&quot;spark-repro-3266.tar.gz attached to SPARK-3266&quot;&gt;spark-repro-3266.tar.gz&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&amp;gt; tar xvzf spark-repro-3266.tar.gz
...
&amp;gt; cd spark-repro-3266
&amp;gt; mvn clean &lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;
&amp;gt; /path/to/spark-1.0.2-bin-hadoop2/bin/spark-submit --&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;SimpleApp target/testcase-4-1.0.jar
...
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.NoSuchMethodError: org.apache.spark.api.java.JavaDoubleRDD.max(Ljava/util/Comparator;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;;
        at SimpleApp.main(SimpleApp.java:17)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:303)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:55)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14114362" author="joshrosen" created="Thu, 28 Aug 2014 21:18:29 +0000"  >&lt;p&gt;Thanks for the reproduction!  I tried it myself and see the same issue.&lt;/p&gt;

&lt;p&gt;If I replace &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        JavaDoubleRDD javaDoubleRDD = sc.parallelizeDoubles(numbers);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;with &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        JavaRDDLike&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;, ?&amp;gt; javaDoubleRDD = sc.parallelizeDoubles(numbers);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;then it seems to work.  I&apos;ll take a closer look using &lt;tt&gt;javap&lt;/tt&gt; to see if I can figure out why this is happening.&lt;/p&gt;</comment>
                            <comment id="14114387" author="lanzaa" created="Thu, 28 Aug 2014 21:34:03 +0000"  >&lt;p&gt;So there is no method:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.api.java.JavaDoubleRDD.max(Ljava/util/Comparator;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but there is a method:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.api.java.JavaDoubleRDD.max(Ljava/util/Comparator;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ve heard that the return type is part of the type signature in java bytecode, so the two are different. (one returns a Double, the other an Object)&lt;/p&gt;

&lt;p&gt;This looks a bit like a scala type erasure related issue. The spark/scala code generated for JavaRDDLike includes a max method that returns an object. In JavaDoubleRDD the type is bounded to Double, so java code which calls max on JavaDoubleRDD expects a method returning Double. Since the code for max is implemented in the JavaRDDLike trait, the java code doesn&apos;t seem to inherit it correctly when types are involved.&lt;/p&gt;

&lt;p&gt;I tested making JavaRDDLike an abstract class instead of a trait. It was able to compile and run correctly. However it is not compatible with 1.0.2.&lt;/p&gt;</comment>
                            <comment id="14114391" author="srowen" created="Thu, 28 Aug 2014 21:36:35 +0000"  >&lt;p&gt;(Mea culpa! The example shows this is a legitimate question. I&apos;ll be quiet now.)&lt;/p&gt;</comment>
                            <comment id="14114413" author="ameyc" created="Thu, 28 Aug 2014 21:46:40 +0000"  >&lt;p&gt;No worries, I initially assumed my runtime env was old too until i rechecked.&lt;/p&gt;</comment>
                            <comment id="14114414" author="joshrosen" created="Thu, 28 Aug 2014 21:46:45 +0000"  >&lt;p&gt;JavaRDDLike probably should be an abstract class.  I think the current trait implementation was a holdover from an earlier prototype that attempted to achieve higher code reuse for operations like map() and filter().&lt;/p&gt;

&lt;p&gt;I added a test case to JavaAPISuite that reproduces this issue on master, too.&lt;/p&gt;

&lt;p&gt;The simplest solution is probably to make JavaRDDLike into a trait.  I think we can do this while maintaining source compatibility.  A less invasive but messier solution would be to just copy the implementation of max() and min() into each Java*RDD class and remove it from the trait.  &lt;/p&gt;</comment>
                            <comment id="14114453" author="apachespark" created="Thu, 28 Aug 2014 22:05:45 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2186&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2186&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14114680" author="pwendell" created="Fri, 29 Aug 2014 00:50:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt; is there a solution here that preserves binary compatibility? That&apos;s been our goal at this point and we&apos;ve maintained it by and large except for a few very minor mandatory Scala 2.11 upgrades.&lt;/p&gt;</comment>
                            <comment id="14114870" author="joshrosen" created="Fri, 29 Aug 2014 05:07:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pwendell&quot; class=&quot;user-hover&quot; rel=&quot;pwendell&quot;&gt;pwendell&lt;/a&gt; I think the JavaRDDLike trait compiles down to a Java interface (named JavaRDDLike) and an abstract class named JavaRDDLike$class that contains the implementations of the trait&apos;s members.  After this change, I think JavaRDDLike would compile into a Java abstract base class with the same name and we wouldn&apos;t have a separate interface.&lt;/p&gt;

&lt;p&gt;My concern here is that it&apos;s going to be a &lt;em&gt;huge&lt;/em&gt; pain to find and fix all of the possible issues that could be caused by this being a trait instead of an abstract base class.  Having it be a trait was a mistake that we should have caught and fixed earlier.&lt;/p&gt;</comment>
                            <comment id="14114881" author="lanzaa" created="Fri, 29 Aug 2014 05:37:23 +0000"  >&lt;p&gt;Broken for JavaDoubleRDD: fold, reduce, min, max&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.lang.NoSuchMethodError: org.apache.spark.api.java.JavaDoubleRDD.fold(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;;Lorg/apache/spark/api/java/function/Function2;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;;
java.lang.NoSuchMethodError: org.apache.spark.api.java.JavaDoubleRDD.reduce(Lorg/apache/spark/api/java/function/Function2;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;;
java.lang.NoSuchMethodError: org.apache.spark.api.java.JavaDoubleRDD.min(Ljava/util/Comparator;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;;
java.lang.NoSuchMethodError: org.apache.spark.api.java.JavaDoubleRDD.max(Ljava/util/Comparator;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &quot;first&quot; method would also be affected, but it seems that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt; fixed that when he first implemented JavaDoubleRDD.&lt;/p&gt;

&lt;p&gt;Also, I would bet JavaPairRDD and JavaSchemaRDD have similar issues.&lt;/p&gt;</comment>
                            <comment id="14169873" author="joshrosen" created="Mon, 13 Oct 2014 20:09:41 +0000"  >&lt;p&gt;I believe the erasure to &lt;tt&gt;Object&lt;/tt&gt; is due to a Scala compiler bug; I&apos;ve opened &lt;a href=&quot;https://issues.scala-lang.org/browse/SI-8905&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues.scala-lang.org/browse/SI-8905&lt;/a&gt; to let the Scala team know about this.  In the meantime, though, it seems that moving the implementation of these methods into the JavaRDD classes should fix things.  I&apos;ll work on putting together a patch based on that workaround.&lt;/p&gt;</comment>
                            <comment id="14184688" author="apachespark" created="Sun, 26 Oct 2014 22:52:33 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2951&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2951&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14184696" author="joshrosen" created="Sun, 26 Oct 2014 23:12:08 +0000"  >&lt;p&gt;I&apos;ve opened a new pull request which tries to work around the Scala issue by moving the implementations of these methods from the Java*Like traits into abstract base classes that inherit from those traits (essentially making the traits act as interfaces).  This breaks binary compatibility from Scala&apos;s point of view, since the fact that a trait contains a default implementation of a method is part of its API contract (it affects implementors of that trait).  I don&apos;t think there&apos;s any legitimate reason for someone to have extended JavaRDDLike from their own code, so we shouldn&apos;t have to worry about this.&lt;/p&gt;

&lt;p&gt;From a simplicity perspective, I prefer the approach from my first PR of simply converting JavaRDDLike into an abstract class.  This would cause problems for Java API users who were invoking methods through the interface, though.  I can&apos;t imagine that most users would have done this, but maybe it&apos;s important to not break compatibility.  On the other hand, the current API is functionally broken as long as it&apos;s throwing NoSuchMethodErrors.&lt;/p&gt;

&lt;p&gt;The one approach that doesn&apos;t break &lt;em&gt;any&lt;/em&gt; binary compatibility would be to just keep the default implementations of methods in JavaRDDLike then copy-paste the ones affected by the bugs into the individual JavaRDD classes.  This is a mess, but I can do it if necessary.&lt;/p&gt;</comment>
                            <comment id="14184704" author="pwendell" created="Sun, 26 Oct 2014 23:33:43 +0000"  >&lt;p&gt;I think it sort of depends how many people use JavaRDDLike and how they use it. In my mind it wasn&apos;t intended to be used by user applications, but probably some do because there isn&apos;t really a way to write functions that pass RDD&apos;s around and deal with both Pair RDD&apos;s and normal ones in Java. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=matei&quot; class=&quot;user-hover&quot; rel=&quot;matei&quot;&gt;matei&lt;/a&gt;, what do you think of this vis-a-vis compatibility?&lt;/p&gt;</comment>
                            <comment id="14219076" author="joshrosen" created="Thu, 20 Nov 2014 07:09:41 +0000"  >&lt;p&gt;I&apos;m unassigning myself from this since I&apos;m no longer actively working on it (although I really want to fix this as soon as I have time).&lt;/p&gt;

&lt;p&gt;Copying a &lt;a href=&quot;https://github.com/apache/spark/pull/2951#issuecomment-63769092&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;comment from one of my pull requests&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;@viper-kun No, I&apos;m not actively working on this. A pull request here would be very welcome, since this is an annoying bug. If you&apos;re planning to work on this, make sure to include the extra test cases that I added to JavaAPISuite; these tests should be useful regardless of what approach you taking to fixing these bugs.&lt;/p&gt;

&lt;p&gt;From a binary compatibility standpoint, it&apos;s important to keep the Java*Like interfaces since there&apos;s some code in the wild that uses these interfaces to abstract over the different implementations. Removing default implementations from traits technically breaks compatibility for anyone who might have extended those traits, but I don&apos;t think that should be a huge concern / likely problem.&lt;/p&gt;

&lt;p&gt;If you want to avoid copying / moving everything around, then I think it would be sufficient to just identify the methods that are affected by this compiler bug and copy only those methods to each subclass. We could maintain 100% binary compatibility with this approach, even for the obscure case where someone extended a trait, and it might make it easier to backport the fix to maintenance branches, but it also seems sort of risk-prone because someone might add new default implementations in the trait.&lt;/p&gt;

&lt;p&gt;For the sake of keeping the discussion in one place, let&apos;s chat about alternative designs on the JIRA ticket. I&apos;ll unassign myself from it and copy this comment over there.&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="14362052" author="srowen" created="Sat, 14 Mar 2015 21:46:42 +0000"  >&lt;p&gt;Related note to self for the future: the histogram() function here returns Pair, which is an alias for Tuple2, but one that&apos;s deprecated in Scala 2.11. This shouldn&apos;t be Pair and maybe shouldn&apos;t even be Tuple2 in the Java API.&lt;/p&gt;</comment>
                            <comment id="14363607" author="apachespark" created="Mon, 16 Mar 2015 17:59:22 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5050&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5050&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14365429" author="joshrosen" created="Tue, 17 Mar 2015 16:23:57 +0000"  >&lt;p&gt;Issue resolved by pull request 5050&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5050&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5050&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14365434" author="joshrosen" created="Tue, 17 Mar 2015 16:26:14 +0000"  >&lt;p&gt;After many months, I&apos;ve finally fixed this issue thanks to a good workaround suggested by Jason Zaugg: &lt;a href=&quot;https://issues.scala-lang.org/browse/SI-8905?focusedCommentId=72096&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-72096&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues.scala-lang.org/browse/SI-8905?focusedCommentId=72096&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-72096&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&apos;ve merged this fix into 1.4.0 and 1.3.1.  If there&apos;s any demand to backport this to other maintenance branches, please let me know, but I suspect that merging into the next release should be sufficient for most users (users running legacy versions of Spark probably have their own workarounds in place already).&lt;/p&gt;</comment>
                            <comment id="14374859" author="jlewandowski" created="Sun, 22 Mar 2015 10:04:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt; it would be awesome to include this fix into 1.2.x. We&apos;ve recently added cross compilation for Scala 2.10 and Scala 2.11 of our Spark Cassandra Connector. It turned out that we were unable to subclass &lt;tt&gt;JavaPairRDD&lt;/tt&gt; in Java when Scala 2.11 compiler was used. The compilation error said:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[error] /Users/jlewandowski/Projects/OpenSource/spark-cassandra-connector/spark-cassandra-connector-java/src/main/java/com/datastax/spark/connector/japi/rdd/CassandraJavaPairRDD.java:32: error: min(Comparator) in JavaPairRDD cannot implement min(Comparator&amp;lt;T&amp;gt;) in JavaRDDLike
[error] public class CassandraJavaPairRDD&amp;lt;K, V&amp;gt; extends JavaPairRDD&amp;lt;K, V&amp;gt; {
[error]        ^
[error]   return type Object is not compatible with Tuple2&amp;lt;K,V&amp;gt;
[error]   where T,K,V are type-variables:
[error]     T extends Object declared in interface JavaRDDLike
[error]     K extends Object declared in class CassandraJavaPairRDD
[error]     V extends Object declared in class CassandraJavaPairRDD
[error] 1 error
[error] (spark-cassandra-connector-java/compile:compile) javac returned nonzero exit code
[error] Total time: 3 s, completed Mar 22, 2015 8:46:28 AM
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which seems to be tightly related to this issue.&lt;/p&gt;</comment>
                            <comment id="14378583" author="joshrosen" created="Tue, 24 Mar 2015 20:57:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jlewandowski&quot; class=&quot;user-hover&quot; rel=&quot;jlewandowski&quot;&gt;jlewandowski&lt;/a&gt; I have now merged this into `branch-1.2` (1.2.2) as well.&lt;/p&gt;</comment>
                            <comment id="14380915" author="jlewandowski" created="Wed, 25 Mar 2015 22:29:04 +0000"  >&lt;p&gt;Thanks a lot &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt;, really appreciate that &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12714257">SPARK-1834</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12665070" name="spark-repro-3266.tar.gz" size="1026" author="lanzaa" created="Thu, 28 Aug 2014 20:50:50 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 34 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1zezb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>