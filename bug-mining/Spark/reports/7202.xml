<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:16:33 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-31399] Closure cleaner broken in Scala 2.12</title>
                <link>https://issues.apache.org/jira/browse/SPARK-31399</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The `ClosureCleaner` only support Scala functions and it uses the following check to catch closures&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-comment&quot;&gt;// Check whether a &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;represents a Scala closure
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def isClosure(cls: &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;[_]): &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = {
    cls.getName.contains(&lt;span class=&quot;code-quote&quot;&gt;&quot;$anonfun$&quot;&lt;/span&gt;)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This doesn&apos;t work in 3.0 any more as we upgrade to Scala 2.12 and most Scala functions become Java lambdas.&lt;/p&gt;

&lt;p&gt;As an example, the following code works well in Spark 2.4 Spark Shell:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; :pa
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.functions.lit

&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Foo(id: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;)
val col = lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;123&quot;&lt;/span&gt;)
val df = sc.range(0,10,1,1).map { _ =&amp;gt; Foo(&quot;&quot;) }

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.functions.lit
defined &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Foo
col: org.apache.spark.sql.Column = 123
df: org.apache.spark.rdd.RDD[Foo] = MapPartitionsRDD[5] at map at &amp;lt;pastie&amp;gt;:20
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But fails in 3.0&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; :pa
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.functions.lit

&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Foo(id: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;)
val col = lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;123&quot;&lt;/span&gt;)
val df = sc.range(0,10,1,1).map { _ =&amp;gt; Foo(&quot;&quot;) }

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
org.apache.spark.SparkException: Task not serializable
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:396)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:386)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:159)
  at org.apache.spark.SparkContext.clean(SparkContext.scala:2371)
  at org.apache.spark.rdd.RDD.$anonfun$map$1(RDD.scala:422)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
  at org.apache.spark.rdd.RDD.map(RDD.scala:421)
  ... 39 elided
Caused by: java.io.NotSerializableException: org.apache.spark.sql.Column
Serialization stack:
	- object not serializable (class: org.apache.spark.sql.Column, value: 123)
	- field (class: $iw, name: col, type: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.sql.Column)
	- object (class $iw, $iw@2d87ac2b)
	- element of array (index: 0)
	- array (class [Ljava.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;, size 1)
	- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)
	- object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class $iw, functionalInterfaceMethod=scala/Function1.apply:(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;, implementation=invokeStatic $anonfun$df$1$adapted:(L$iw;Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)LFoo;, instantiatedMethodType=(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)LFoo;, numCaptured=1])
	- writeReplace data (class: java.lang.invoke.SerializedLambda)
	- object (class $Lambda$2438/170049100, $Lambda$2438/170049100@d6b8c43)
  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)
  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47)
  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:393)
  ... 47 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;*&lt;b&gt;Apache Spark 2.4.5 with Scala 2.12&lt;/b&gt;*&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.5
      /_/

Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 1.8.0_242)
Type in expressions to have them evaluated.
Type :help &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.

scala&amp;gt; :pa
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.functions.lit

&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Foo(id: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;)
val col = lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;123&quot;&lt;/span&gt;)
val df = sc.range(0,10,1,1).map { _ =&amp;gt; Foo(&quot;&quot;) }

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
org.apache.spark.SparkException: Task not serializable
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:403)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:393)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)
  at org.apache.spark.SparkContext.clean(SparkContext.scala:2326)
  at org.apache.spark.rdd.RDD.$anonfun$map$1(RDD.scala:393)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
  at org.apache.spark.rdd.RDD.map(RDD.scala:392)
  ... 45 elided
Caused by: java.io.NotSerializableException: org.apache.spark.sql.Column
Serialization stack:
	- object not serializable (class: org.apache.spark.sql.Column, value: 123)
	- field (class: $iw, name: col, type: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.sql.Column)
	- object (class $iw, $iw@73534675)
	- element of array (index: 0)
	- array (class [Ljava.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;, size 1)
	- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)
	- object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class $iw, functionalInterfaceMethod=scala/Function1.apply:(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;, implementation=invokeStatic $anonfun$df$1$adapted:(L$iw;Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)LFoo;, instantiatedMethodType=(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)LFoo;, numCaptured=1])
	- writeReplace data (class: java.lang.invoke.SerializedLambda)
	- object (class $Lambda$1952/356563238, $Lambda$1952/356563238@6ca95b1e)
  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)
  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)
  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:400)
  ... 53 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13297412">SPARK-31399</key>
            <summary>Closure cleaner broken in Scala 2.12</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rednaxelafx">Kris Mok</assignee>
                                    <reporter username="cloud_fan">Wenchen Fan</reporter>
                        <labels>
                    </labels>
                <created>Thu, 9 Apr 2020 15:01:22 +0000</created>
                <updated>Tue, 19 May 2020 19:30:53 +0000</updated>
                            <resolved>Mon, 18 May 2020 05:33:24 +0000</resolved>
                                    <version>2.4.5</version>
                    <version>3.0.0</version>
                                    <fixVersion>2.4.6</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>18</watches>
                                                                                                                <comments>
                            <comment id="17079454" author="cloud_fan" created="Thu, 9 Apr 2020 15:05:51 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sowen&quot; class=&quot;user-hover&quot; rel=&quot;sowen&quot;&gt;sowen&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tgraves&quot; class=&quot;user-hover&quot; rel=&quot;tgraves&quot;&gt;tgraves&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17079514" author="smilegator" created="Thu, 9 Apr 2020 16:02:01 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zsxwing&quot; class=&quot;user-hover&quot; rel=&quot;zsxwing&quot;&gt;zsxwing&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17079992" author="dongjoon" created="Thu, 9 Apr 2020 20:42:28 +0000"  >&lt;p&gt;Thank you for pinging me, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;.&lt;br/&gt;
cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dbtsai&quot; class=&quot;user-hover&quot; rel=&quot;dbtsai&quot;&gt;dbtsai&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=holden&quot; class=&quot;user-hover&quot; rel=&quot;holden&quot;&gt;holden&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17080265" author="rxin" created="Fri, 10 Apr 2020 05:56:49 +0000"  >&lt;p&gt;This is bad... &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sowen&quot; class=&quot;user-hover&quot; rel=&quot;sowen&quot;&gt;sowen&lt;/a&gt;&#160;and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt;&#160; did you look into this in the past?&lt;/p&gt;</comment>
                            <comment id="17080359" author="joshrosen" created="Fri, 10 Apr 2020 08:43:43 +0000"  >&lt;h3&gt;&lt;a name=&quot;Myroughfirstimpression&quot;&gt;&lt;/a&gt;My rough first impression&lt;/h3&gt;

&lt;p&gt;I think the problem is that Spark 3.x isn&apos;t performing full cleaning of lambdas: the old cleaning logic (which clones closures and nulls out unreferenced fields) only seems to run for non-lambdas (&lt;a href=&quot;https://github.com/apache/spark/blob/e42a3945acd614a26c7941a9eed161b500fb4520/core/src/main/scala/org/apache/spark/util/ClosureCleaner.scala#L259-L260&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;source&lt;/a&gt;); the lambda cleaner runs a &lt;a href=&quot;https://github.com/apache/spark/blame/e42a3945acd614a26c7941a9eed161b500fb4520/core/src/main/scala/org/apache/spark/util/ClosureCleaner.scala#L374-L382&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;subset&lt;/a&gt; of the old cleaning logic to check for&#160;&lt;tt&gt;return&lt;/tt&gt; statements, skipping the rest of the cleaning steps.&lt;/p&gt;
&lt;h3&gt;&lt;a name=&quot;Differentcasestoconsider%C2%A0&quot;&gt;&lt;/a&gt;Different cases to consider&#160;&lt;/h3&gt;

&lt;p&gt;Some closures might contain&#160;&lt;em&gt;entirely&lt;/em&gt;&#160;spurious&#160;&lt;tt&gt;$outer&lt;/tt&gt;&#160;references, where in theory we could just omit the entire &lt;tt&gt;$outer&lt;/tt&gt; object (as opposed to cloning it and nulling a subset of its fields). These situations can happen because the Scala compiler&apos;s (escape?) analysis isn&apos;t perfect.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;In 2.11 these will closures will be serializable because the ClosureCleaner can null the &lt;tt&gt;$outer&lt;/tt&gt;&#160;reference.&lt;/li&gt;
	&lt;li&gt;In 2.12 these will fail to serialize because we can&apos;t perform that type of cleaning.&lt;/li&gt;
	&lt;li&gt;In the past we discovered some cases where Scala 2.12 would generate &lt;em&gt;more&lt;/em&gt; unnecessary &lt;tt&gt;$outer&lt;/tt&gt; references than 2.11, so a closure which could have been serialized&#160;&lt;em&gt;even without&#160;any cleaning&lt;/em&gt; on 2.11 would require cleaning to serialize on 2.12.&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-14540&quot; title=&quot;Support Scala 2.12 closures and Java 8 lambdas in ClosureCleaner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-14540&quot;&gt;&lt;del&gt;SPARK-14540&lt;/del&gt;&lt;/a&gt; describes a few examples of this: I think the known cases have been fixed in newer 2.12 versions.&lt;/li&gt;
	&lt;li&gt;In other cases, however, &lt;em&gt;both&lt;/em&gt; 2.11 and 2.12 generate entirely spurious references. These aren&apos;t behavior regressions w.r.t capture (both versions capture the same things), but such cases will be broken on 2.12 unless we add full cleaning support for lambdas (or modify improve Scala 2.12&apos;s analysis beyond 2.11&apos;s so the compiler never generate the unnecessary reference in the first place).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In other cases, however, we can&apos;t&#160;entirely null out all captured references because we need to transitively access some fields or methods in those references. Even if the compiler analysis was perfect, I think these cases will still require cleaning to be serializable.&lt;/p&gt;
&lt;h3&gt;&lt;a name=&quot;Exampleofunnecessary%24outercaptureinboth2.11and2.12&quot;&gt;&lt;/a&gt;Example of unnecessary $outer capture in both 2.11 and 2.12&lt;/h3&gt;

&lt;p&gt;Here&apos;s an example of a closure which over-captures in both 2.11 and 2.12. Here I&apos;m deliberately using &lt;tt&gt;sc.emptyRDD&lt;/tt&gt; instead of &lt;tt&gt;spark.range&lt;/tt&gt; because &lt;tt&gt;range&lt;/tt&gt; makes it own closure cleaner calls and that clutters up the logs:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.4-SNAPSHOT
      /_/

Using Scala version 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_191)
Type in expressions to have them evaluated.
Type :help &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.

scala&amp;gt; :paste
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
sc.setLogLevel(&lt;span class=&quot;code-quote&quot;&gt;&quot;DEBUG&quot;&lt;/span&gt;)
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Foo(id: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;)
val nonSerializableObj = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;
val df = sc.emptyRDD[Int].map { _ =&amp;gt; Foo(&quot;&quot;) }

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
20/04/10 00:56:24 DEBUG ClosureCleaner: +++ Cleaning closure &amp;lt;function1&amp;gt; ($line14.$read$$iw$$iw$$anonfun$1) +++
20/04/10 00:56:24 DEBUG ClosureCleaner:  + declared fields: 2
20/04/10 00:56:24 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; $line14.$read$$iw$$iw$$anonfun$1.serialVersionUID
20/04/10 00:56:24 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; $line14.$read$$iw$$iw $line14.$read$$iw$$iw$$anonfun$1.$&lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt;
20/04/10 00:56:24 DEBUG ClosureCleaner:  + declared methods: 2
20/04/10 00:56:24 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; $line14.$read$$iw$$iw$$anonfun$1.apply(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;)
20/04/10 00:56:24 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; $line14.$read$$iw$$iw$Foo $line14.$read$$iw$$iw$$anonfun$1.apply(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)
20/04/10 00:56:24 DEBUG ClosureCleaner:  + &lt;span class=&quot;code-keyword&quot;&gt;inner&lt;/span&gt; classes: 0
20/04/10 00:56:24 DEBUG ClosureCleaner:  + &lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt; classes: 1
20/04/10 00:56:24 DEBUG ClosureCleaner:      $line14.$read$$iw$$iw
20/04/10 00:56:24 DEBUG ClosureCleaner:  + &lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt; objects: 1
20/04/10 00:56:24 DEBUG ClosureCleaner:      $line14.$read$$iw$$iw@163cd4a6
20/04/10 00:56:24 DEBUG ClosureCleaner:  + populating accessed fields because &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is the starting closure
20/04/10 00:56:24 DEBUG ClosureCleaner:  + fields accessed by starting closure: 2
20/04/10 00:56:24 DEBUG ClosureCleaner:      (class $line14.$read$$iw$$iw,Set())
20/04/10 00:56:24 DEBUG ClosureCleaner:      (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;,Set())
20/04/10 00:56:24 DEBUG ClosureCleaner:  + outermost object is a REPL line object, so we clone it: (class $line14.$read$$iw$$iw,$line14.$read$$iw$$iw@163cd4a6)
20/04/10 00:56:24 DEBUG ClosureCleaner:  + cloning the object $line14.$read$$iw$$iw@163cd4a6 of class $line14.$read$$iw$$iw
20/04/10 00:56:24 DEBUG ClosureCleaner:  +++ closure &amp;lt;function1&amp;gt; ($line14.$read$$iw$$iw$$anonfun$1) is now cleaned +++
defined &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Foo
nonSerializableObj: &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; = java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;@f1d5f3
df: org.apache.spark.rdd.RDD[Foo] = MapPartitionsRDD[1] at map at &amp;lt;console&amp;gt;:16
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here we have an outer object of type &lt;tt&gt;$line14.$read$$iw$$iw&lt;/tt&gt;&#160;but the &quot;&lt;tt&gt;fields accessed by starting closure:&quot;&lt;/tt&gt; log output shows that the closure doesn&apos;t actually reference any of the outer object&apos;s fields.&lt;/p&gt;

&lt;p&gt;In 3.0 this fails because the closure cleaning doesn&apos;t omit the outer object reference:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.0.0-SNAPSHOT
      /_/

Using Scala version 2.12.10 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_191)
Type in expressions to have them evaluated.
Type :help &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.

scala&amp;gt; :paste
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
sc.setLogLevel(&lt;span class=&quot;code-quote&quot;&gt;&quot;DEBUG&quot;&lt;/span&gt;)
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Foo(id: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;)
val nonSerializableObj = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;
val df = sc.emptyRDD[Int].map { _ =&amp;gt; Foo(&quot;&quot;) }

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
20/04/10 01:00:34 DEBUG ClosureCleaner: Cleaning lambda: $anonfun$df$1$adapted
20/04/10 01:00:34 DEBUG ClosureCleaner:  +++ Lambda closure ($anonfun$df$1$adapted) is now cleaned +++
org.apache.spark.SparkException: Task not serializable
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:396)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:386)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:159)
  at org.apache.spark.SparkContext.clean(SparkContext.scala:2379)
  at org.apache.spark.rdd.RDD.$anonfun$map$1(RDD.scala:396)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
  at org.apache.spark.rdd.RDD.map(RDD.scala:395)
  ... 41 elided
Caused by: java.io.NotSerializableException: java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;
Serialization stack:
	- object not serializable (class: java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, value: java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;@76c1ede3)
	- field (class: $iw, name: nonSerializableObj, type: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;)
	- object (class $iw, $iw@463a0302)
	- element of array (index: 0)
	- array (class [Ljava.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;, size 1)
	- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)
	- object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class $iw, functionalInterfaceMethod=scala/Function1.apply:(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;, implementation=invokeStatic $anonfun$df$1$adapted:(L$iw;Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)LFoo;, instantiatedMethodType=(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)LFoo;, numCaptured=1])
	- writeReplace data (class: java.lang.invoke.SerializedLambda)
	- object (class $Lambda$2029/1917668362, $Lambda$2029/1917668362@60af08b2)
  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)
  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47)
  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:393)
  ... 49 more
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a name=&quot;Exampleofnecessaryreferencetocleanable%24outerobject&quot;&gt;&lt;/a&gt;Example of necessary reference to cleanable $outer object&lt;/h3&gt;

&lt;p&gt;Here&apos;s a similar example, except this time the closure needs to reference a subset of the outer object&apos;s fields:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.4-SNAPSHOT
      /_/

Using Scala version 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_191)
Type in expressions to have them evaluated.
Type :help &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.

scala&amp;gt; :paste
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
sc.setLogLevel(&lt;span class=&quot;code-quote&quot;&gt;&quot;DEBUG&quot;&lt;/span&gt;)
val constant = 1
val nonSerializableObj = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;
val df = sc.emptyRDD[Int].map { _ =&amp;gt; constant }

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
20/04/10 01:06:30 DEBUG ClosureCleaner: +++ Cleaning closure &amp;lt;function1&amp;gt; ($line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1) +++
20/04/10 01:06:30 DEBUG ClosureCleaner:  + declared fields: 2
20/04/10 01:06:30 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1.serialVersionUID
20/04/10 01:06:30 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1.$&lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt;
20/04/10 01:06:30 DEBUG ClosureCleaner:  + declared methods: 3
20/04/10 01:06:30 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1.apply(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)
20/04/10 01:06:30 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1.apply(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;)
20/04/10 01:06:30 DEBUG ClosureCleaner:      &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1.apply$mcII$sp(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)
20/04/10 01:06:30 DEBUG ClosureCleaner:  + &lt;span class=&quot;code-keyword&quot;&gt;inner&lt;/span&gt; classes: 0
20/04/10 01:06:30 DEBUG ClosureCleaner:  + &lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt; classes: 1
20/04/10 01:06:30 DEBUG ClosureCleaner:      $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw
20/04/10 01:06:30 DEBUG ClosureCleaner:  + &lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt; objects: 1
20/04/10 01:06:30 DEBUG ClosureCleaner:      $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw@7bc239db
20/04/10 01:06:30 DEBUG ClosureCleaner:  + populating accessed fields because &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is the starting closure
20/04/10 01:06:30 DEBUG ClosureCleaner:  + fields accessed by starting closure: 2
20/04/10 01:06:30 DEBUG ClosureCleaner:      (class $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw,Set(constant))
20/04/10 01:06:30 DEBUG ClosureCleaner:      (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;,Set())
20/04/10 01:06:30 DEBUG ClosureCleaner:  + outermost object is a REPL line object, so we clone it: (class $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw,$line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw@7bc239db)
20/04/10 01:06:30 DEBUG ClosureCleaner:  + cloning the object $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw@7bc239db of class $line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw
20/04/10 01:06:30 DEBUG ClosureCleaner:  +++ closure &amp;lt;function1&amp;gt; ($line14.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$1) is now cleaned +++
constant: Int = 1
nonSerializableObj: &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; = java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;@5dd5422f
df: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[1] at map at &amp;lt;console&amp;gt;:27
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here Spark has cloned both the closure&#160;&lt;em&gt;and&lt;/em&gt; the outer object, nulling the cloned outer object&apos;s unaccessed fields.&lt;/p&gt;

&lt;p&gt;As expected, this fails in 2.12:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.0.0-SNAPSHOT
      /_/

Using Scala version 2.12.10 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_191)
Type in expressions to have them evaluated.
Type :help &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.

scala&amp;gt; :paste
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
sc.setLogLevel(&lt;span class=&quot;code-quote&quot;&gt;&quot;DEBUG&quot;&lt;/span&gt;)
val constant = 1
val nonSerializableObj = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;
val df = sc.emptyRDD[Int].map { _ =&amp;gt; constant }

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
20/04/10 01:07:49 DEBUG ClosureCleaner: Cleaning lambda: $anonfun$df$1
20/04/10 01:07:49 DEBUG ClosureCleaner:  +++ Lambda closure ($anonfun$df$1) is now cleaned +++
org.apache.spark.SparkException: Task not serializable
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:396)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:386)
  at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:159)
  at org.apache.spark.SparkContext.clean(SparkContext.scala:2379)
  at org.apache.spark.rdd.RDD.$anonfun$map$1(RDD.scala:396)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
  at org.apache.spark.rdd.RDD.map(RDD.scala:395)
  ... 47 elided
Caused by: java.io.NotSerializableException: java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;
Serialization stack:
	- object not serializable (class: java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, value: java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;@291fbdc9)
	- field (class: $iw, name: nonSerializableObj, type: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;)
	- object (class $iw, $iw@6f3b4c9a)
	- element of array (index: 0)
	- array (class [Ljava.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;, size 1)
	- field (class: java.lang.invoke.SerializedLambda, name: capturedArgs, type: class [Ljava.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)
	- object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.invoke.SerializedLambda, SerializedLambda[capturingClass=class $iw, functionalInterfaceMethod=scala/runtime/java8/JFunction1$mcII$sp.apply$mcII$sp:(I)I, implementation=invokeStatic $anonfun$df$1:(L$iw;I)I, instantiatedMethodType=(I)I, numCaptured=1])
	- writeReplace data (class: java.lang.invoke.SerializedLambda)
	- object (class $Lambda$1853/1591026569, $Lambda$1853/1591026569@1cf38112)
  at org.apache.spark.serializer.SerializationDebugger$.improveException(SerializationDebugger.scala:41)
  at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:47)
  at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)
  at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:393)
  ... 55 more
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;h3&gt;&lt;a name=&quot;Brainstormingonpossiblefixesandworkarounds&quot;&gt;&lt;/a&gt;Brainstorming on possible fixes and workarounds&lt;/h3&gt;

&lt;p&gt;Some rough ideas on how Spark / Scala could fix this (not all of them good, but listed for completeness / brainstorming):&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;If the Scala compiler didn&apos;t over-capture then more closures would be serializable without any cleaning. However:
	&lt;ul&gt;
		&lt;li&gt;It requires a new Scala release and requires users to upgrade to it.&lt;/li&gt;
		&lt;li&gt;It&apos;s probably pretty hard to do, especially without impacting compile performance.&lt;/li&gt;
		&lt;li&gt;It isn&apos;t a complete fix because it only addresses the &quot;completely spurious capture&quot; case, not the &quot;capture but only need a subset of things along the reference chains&quot; cases.&lt;/li&gt;
		&lt;li&gt;Even if a closure is serializable without cleaning, unreferenced outer object fields might add a lot of bloat to the closure which slows down deserialization (which is performed on a per-task basis).&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;If Spark implemented &quot;full&quot; closure cleaning for lambdas then we might be able to achieve near-complete parity.
	&lt;ul&gt;
		&lt;li&gt;I&apos;m unsure of technical feasibility, but this is definitely worth investigating further: this seems like the most user-friendly fix.&lt;/li&gt;
		&lt;li&gt;If we do this, we should re-introduce some of the ClosureCleaner suite tests which were removed in&#160;&lt;a href=&quot;https://github.com/apache/spark/commit/8bc304f97ee693b57f33fa6708eb63e2d641c609&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/8bc304f97ee693b57f33fa6708eb63e2d641c609&lt;/a&gt;&#160;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Some workarounds which require users to change their code:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Users could mark unserializable / unused closure fields as &lt;tt&gt;@transient&lt;/tt&gt;:
	&lt;ul&gt;
		&lt;li&gt;In my examples above, marking the &lt;tt&gt;nonSerializableObj&lt;/tt&gt; field as &lt;tt&gt;@transient&lt;/tt&gt; would allow the closure to be serialized without cleaning (and avoids size bloat).&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Moving the failures to compile-time:
	&lt;ul&gt;
		&lt;li&gt;This &quot;non-serializable closure&quot; issue is especially painful because it shows up at compile-time, not runtime: if users&apos; code doesn&apos;t have full unit / integration test coverage then finding these issues can be an unpleasant game of wack-a-mole of tracking down broken jobs (hopefully in a test / staging environment and not production).&lt;/li&gt;
		&lt;li&gt;If we could somehow move these failures to compile time (whether through macros or a compiler plugin) then users would have a much more reasonable porting devloop since we&apos;d be moving further in the direction of &quot;if the code compiles then it&apos;ll probably run successfully&quot;. It looks like Spores can do this:&#160;&lt;a href=&quot;https://scalacenter.github.io/spores/java-serialization.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://scalacenter.github.io/spores/java-serialization.html&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;In notebooks and REPLs the compile-time and run-time phases are interleaved, so these approaches wouldn&apos;t be of as much help there.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17080627" author="dongjoon" created="Fri, 10 Apr 2020 16:48:39 +0000"  >&lt;p&gt;According to the above information,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;I added the failure result in Apache Spark 2.4.5 with Scala 2.12 additionally into the JIRA description.&lt;/li&gt;
	&lt;li&gt;Update the title from `in Spark 3.0` to `in Scala 2.12`.&lt;/li&gt;
	&lt;li&gt;Add `2.4.5` as `Affected Version` (but not a target version)&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17084356" author="smilegator" created="Wed, 15 Apr 2020 20:15:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rednaxelafx&quot; class=&quot;user-hover&quot; rel=&quot;rednaxelafx&quot;&gt;rednaxelafx&lt;/a&gt;&#160;will help this ticket and do more investigation.&#160;&lt;/p&gt;</comment>
                            <comment id="17092836" author="dongjoon" created="Sun, 26 Apr 2020 19:29:57 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rednaxelafx&quot; class=&quot;user-hover&quot; rel=&quot;rednaxelafx&quot;&gt;rednaxelafx&lt;/a&gt;. Is there any update for this Blocker issue? Thank you for any update in advance!&lt;/p&gt;</comment>
                            <comment id="17096191" author="rednaxelafx" created="Thu, 30 Apr 2020 06:29:57 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;, I&apos;ve been working on a fix of this issue and will send out a WIP PR as soon as possible. I&apos;ve pretty much done an analysis of the situation in parallel to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt;&apos;s analysis above and have arrived at very similar conclusions.&lt;/p&gt;

&lt;p&gt;The fact is, Scala 2.12+&apos;s indylambda (aka LMF-based closures) does still have an equivalent of an &lt;tt&gt;&quot;$outer&quot;&lt;/tt&gt;, just under a different name. Thus the logic inside the &lt;tt&gt;ClosureCleaner&lt;/tt&gt; for Scala 2.11 support has to be ported basically verbatim to Scala 2.12+/indylambda. That&apos;s exactly what I&apos;m working on right now, and it&apos;s the main contents of the WIP PR.&lt;/p&gt;

&lt;p&gt;A separate issue is that the test coverage of &lt;tt&gt;ClosureCleaner&lt;/tt&gt; in the Spark repo is very insufficient. Neither &lt;tt&gt;ClosureCleanerSuite&lt;/tt&gt; nor &lt;tt&gt;ClosureCleanerSuite2&lt;/tt&gt; cover anything related to the Scala REPL. There needs to be a separate suite, similar to &lt;tt&gt;ReplSuite&lt;/tt&gt;, that fires up an actual Scala REPL and trigger ClosureCleaner in it to bridge the gap in test coverage. I will do that as a second step of the PR, and once the new test suite is in, the PR can be considered complete and ready for final review.&lt;/p&gt;</comment>
                            <comment id="17096629" author="dongjoon" created="Thu, 30 Apr 2020 15:08:06 +0000"  >&lt;p&gt;Thank you so much, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rednaxelafx&quot; class=&quot;user-hover&quot; rel=&quot;rednaxelafx&quot;&gt;rednaxelafx&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17100721" author="apachespark" created="Wed, 6 May 2020 11:51:45 +0000"  >&lt;p&gt;User &apos;rednaxelafx&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28463&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28463&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17109895" author="cloud_fan" created="Mon, 18 May 2020 05:33:24 +0000"  >&lt;p&gt;Issue resolved by pull request 28463&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28463&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28463&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17110888" author="apachespark" created="Tue, 19 May 2020 06:21:33 +0000"  >&lt;p&gt;User &apos;rednaxelafx&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28577&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28577&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17110889" author="apachespark" created="Tue, 19 May 2020 06:21:41 +0000"  >&lt;p&gt;User &apos;rednaxelafx&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28577&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28577&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 26 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0dgtk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12339177">3.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>