<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:59:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-22371] dag-scheduler-event-loop thread stopped with error  Attempted to access garbage collected accumulator 5605982</title>
                <link>https://issues.apache.org/jira/browse/SPARK-22371</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Our Spark Jobs are getting stuck on DagScheduler.runJob as dagscheduler thread is stopped because of &lt;b&gt;Attempted to access garbage collected accumulator 5605982&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;from our investigation it look like accumulator is cleaned by GC first and same accumulator is used for merging the results from executor on task completion event.&lt;/p&gt;


&lt;p&gt;As the error java.lang.IllegalAccessError is LinkageError which is treated as FatalError so dag-scheduler loop is finished with below exception.&lt;/p&gt;

&lt;p&gt;---ERROR stack trace &amp;#8211;&lt;br/&gt;
Exception in thread &quot;dag-scheduler-event-loop&quot; java.lang.IllegalAccessError: Attempted to access garbage collected accumulator 5605982&lt;br/&gt;
	at org.apache.spark.util.AccumulatorContext$$anonfun$get$1.apply(AccumulatorV2.scala:253)&lt;br/&gt;
	at org.apache.spark.util.AccumulatorContext$$anonfun$get$1.apply(AccumulatorV2.scala:249)&lt;br/&gt;
	at scala.Option.map(Option.scala:146)&lt;br/&gt;
	at org.apache.spark.util.AccumulatorContext$.get(AccumulatorV2.scala:249)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1083)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1080)&lt;br/&gt;
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)&lt;br/&gt;
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.updateAccumulators(DAGScheduler.scala:1080)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1183)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1647)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)&lt;br/&gt;
at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)&lt;/p&gt;

&lt;p&gt;I am attaching the thread dump of driver as well &lt;/p&gt;</description>
                <environment></environment>
        <key id="13112560">SPARK-22371</key>
            <summary>dag-scheduler-event-loop thread stopped with error  Attempted to access garbage collected accumulator 5605982</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Rudoy">Artem Rudoy</assignee>
                                    <reporter username="mayank.agarwal2305">Mayank Agarwal</reporter>
                        <labels>
                    </labels>
                <created>Fri, 27 Oct 2017 10:35:42 +0000</created>
                <updated>Thu, 4 Oct 2018 12:00:16 +0000</updated>
                            <resolved>Thu, 17 May 2018 10:50:35 +0000</resolved>
                                    <version>2.1.0</version>
                                    <fixVersion>2.3.1</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>7</votes>
                                    <watches>16</watches>
                                                                                                                <comments>
                            <comment id="16234112" author="mgaido" created="Wed, 1 Nov 2017 14:13:56 +0000"  >&lt;p&gt;Could you please provide an easy way to reproduce the issue?&lt;/p&gt;</comment>
                            <comment id="16292134" author="mayank.agarwal2305" created="Fri, 15 Dec 2017 07:13:16 +0000"  >&lt;p&gt;Hi, Sorry for late reply.&lt;/p&gt;

&lt;p&gt;From our analysis this error seems to come when there are jobs running parallel on datasets and union of all those datasets and Full GC triggered at same time which clears the accumulate of children dataset of union.&lt;/p&gt;

&lt;p&gt;I am attaching a small program from which this error comes frequently.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12902246/12902246_ShuffleIssue.java&quot; title=&quot;ShuffleIssue.java attached to SPARK-22371&quot;&gt;ShuffleIssue.java&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12902231/12902231_Helper.scala&quot; title=&quot;Helper.scala attached to SPARK-22371&quot;&gt;Helper.scala&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12902247/12902247_sampledata&quot; title=&quot;sampledata attached to SPARK-22371&quot;&gt;sampledata&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Steps for generating sample data&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;UNIX COMMAND&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;((i=1472428800;i&amp;lt;=1472947200;i=i+86400));&lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; mkdir -p output/testdata/eventtime=$i;cp sampledata output/testdata/eventtime=$i/000001_0;cp sampledata output/testdata/eventtime=$i/000001_1;cp sampledata output/testdata/eventtime=$i/000001_2;cp sampledata output/testdata/eventtime=$i/000001_3;done
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16396640" author="mayank.agarwal2305" created="Tue, 13 Mar 2018 07:25:58 +0000"  >&lt;p&gt;Hi, Any update on the above issue&#160;&lt;/p&gt;</comment>
                            <comment id="16402271" author="craftsman" created="Fri, 16 Mar 2018 18:01:25 +0000"  >&lt;p&gt;We&apos;ve seen this for the first time on 2.3.0.&#160;&lt;/p&gt;

&lt;p&gt;The scenario that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mayank.agarwal2305&quot; class=&quot;user-hover&quot; rel=&quot;mayank.agarwal2305&quot;&gt;mayank.agarwal2305&lt;/a&gt; described of jobs running in parallel on datasets and union of all datasets and full gc triggered&quot; sounds exactly like our scenario. We&apos;ve been unable to upgrade because of this issue.&lt;/p&gt;</comment>
                            <comment id="16420397" author="bysza" created="Fri, 30 Mar 2018 11:18:17 +0000"  >&lt;p&gt;We were hit by this issue on 2.3.0 too while running just &quot;show tables&quot;.&lt;/p&gt;

&lt;p&gt;Stack trace:&lt;/p&gt;

&lt;p&gt;java.lang.IllegalStateException: Attempted to access garbage collected accumulator 793&lt;br/&gt;
at org.apache.spark.util.AccumulatorContext$$anonfun$get$1.apply(AccumulatorV2.scala:265)&lt;br/&gt;
at org.apache.spark.util.AccumulatorContext$$anonfun$get$1.apply(AccumulatorV2.scala:261)&lt;br/&gt;
at scala.Option.map(Option.scala:146)&lt;br/&gt;
at org.apache.spark.util.AccumulatorContext$.get(AccumulatorV2.scala:261)&lt;br/&gt;
at org.apache.spark.util.AccumulatorV2$$anonfun$name$1.apply(AccumulatorV2.scala:87)&lt;br/&gt;
at org.apache.spark.util.AccumulatorV2$$anonfun$name$1.apply(AccumulatorV2.scala:87)&lt;br/&gt;
at scala.Option.orElse(Option.scala:289)&lt;br/&gt;
at org.apache.spark.util.AccumulatorV2.name(AccumulatorV2.scala:87)&lt;br/&gt;
at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(TaskResultGetter.scala:103)&lt;br/&gt;
at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(TaskResultGetter.scala:102)&lt;br/&gt;
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&lt;br/&gt;
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&lt;br/&gt;
at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)&lt;br/&gt;
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)&lt;br/&gt;
at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)&lt;br/&gt;
at scala.collection.AbstractTraversable.map(Traversable.scala:104)&lt;br/&gt;
at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply$mcV$sp(TaskResultGetter.scala:102)&lt;br/&gt;
at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63)&lt;br/&gt;
at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$1.apply(TaskResultGetter.scala:63)&lt;br/&gt;
at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1988)&lt;br/&gt;
at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:62)&lt;br/&gt;
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;br/&gt;
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;br/&gt;
at java.lang.Thread.run(Thread.java:748)&lt;/p&gt;</comment>
                            <comment id="16440683" author="aclegg" created="Tue, 17 Apr 2018 09:53:10 +0000"  >&lt;p&gt;Another data point &amp;#8211; I&apos;ve seen this happen (in 2.3.0) during cleanup after a&#160;task&#160;failure:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt;
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Exception while getting task result: java.lang.IllegalStateException: Attempted to access garbage collected accumulator 365
        at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
        at scala.Option.foreach(Option.scala:257)
        at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)
        at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
        at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)
        at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:194)
        ... 31 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16445999" author="rudoy" created="Fri, 20 Apr 2018 16:36:07 +0000"  >&lt;p&gt;Do we really need to throw an exception from AccumulatorContext.get() when an accumulator is garbage collected? There&apos;s a period of time when an accumulator has been garbage collected, but hasn&apos;t been removed from AccumulatorContext.originals by ContextCleaner. When an update is received for such accumulator it will throw an exception and kill the whole job. This can happen when a stage completed, but there&apos;re still running tasks from other attempts, speculation etc. Since AccumulatorContext.get() returns an Option we could just return None in such case. Before &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-20940&quot; title=&quot;AccumulatorV2 should not throw IllegalAccessError&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-20940&quot;&gt;&lt;del&gt;SPARK-20940&lt;/del&gt;&lt;/a&gt; this method threw IllegalAccessError which is not a NonFatal, was caught at a lower level and didn&apos;t cause job failure.&lt;/p&gt;</comment>
                            <comment id="16446084" author="apachespark" created="Fri, 20 Apr 2018 17:46:05 +0000"  >&lt;p&gt;User &apos;artemrd&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21114&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21114&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16466099" author="zwu.net@gmail.com" created="Mon, 7 May 2018 16:24:40 +0000"  >&lt;p&gt;Got the same problem with 2.3 and also the program stalled:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;&#160;Uncaught exception in thread heartbeat-receiver-event-loop-thread&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;java.lang.IllegalStateException: Attempted to access garbage collected accumulator 8825&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.util.AccumulatorContext$$anonfun$get$1.apply(AccumulatorV2.scala:265)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.util.AccumulatorContext$$anonfun$get$1.apply(AccumulatorV2.scala:261)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at scala.Option.map(Option.scala:146)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.util.AccumulatorContext$.get(AccumulatorV2.scala:261)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.util.AccumulatorV2$$anonfun$name$1.apply(AccumulatorV2.scala:87)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.util.AccumulatorV2$$anonfun$name$1.apply(AccumulatorV2.scala:87)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at scala.Option.orElse(Option.scala:289)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.util.AccumulatorV2.name(AccumulatorV2.scala:87)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160; at org.apache.spark.util.AccumulatorV2.toInfo(AccumulatorV2.scala:108)&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="16478885" author="cloud_fan" created="Thu, 17 May 2018 10:50:35 +0000"  >&lt;p&gt;Issue resolved by pull request 21114&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21114&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21114&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16638105" author="davide.mandrini" created="Thu, 4 Oct 2018 11:46:01 +0000"  >&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;is this fix included in version 2.3.2?&lt;/p&gt;

&lt;p&gt;From here, I would say yes: &lt;a href=&quot;https://github.com/apache/spark/blob/v2.3.2/core/src/main/scala/org/apache/spark/util/AccumulatorV2.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v2.3.2/core/src/main/scala/org/apache/spark/util/AccumulatorV2.scala&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In case it is, can you&#160;add 2.3.2 in the &quot;Fix version&quot; field of this Jira ticket?&lt;/p&gt;</comment>
                            <comment id="16638119" author="cloud_fan" created="Thu, 4 Oct 2018 12:00:16 +0000"  >&lt;p&gt;if it&apos;s fixed in 2.3.1, it goes without saying that it&apos;s fixed in 2.3.2 as well.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12902231" name="Helper.scala" size="829" author="mayank.agarwal2305" created="Fri, 15 Dec 2017 07:40:33 +0000"/>
                            <attachment id="12902246" name="ShuffleIssue.java" size="5569" author="mayank.agarwal2305" created="Fri, 15 Dec 2017 08:49:33 +0000"/>
                            <attachment id="12894331" name="driver-thread-dump-spark2.1.txt" size="316276" author="mayank.agarwal2305" created="Fri, 27 Oct 2017 10:37:48 +0000"/>
                            <attachment id="12902247" name="sampledata" size="11619979" author="mayank.agarwal2305" created="Fri, 15 Dec 2017 08:54:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 6 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3lscv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>