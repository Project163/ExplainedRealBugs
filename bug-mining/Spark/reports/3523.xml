<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:43:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-14261] Memory leak in Spark Thrift Server</title>
                <link>https://issues.apache.org/jira/browse/SPARK-14261</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I am running Spark Thrift server on Windows Server 2012. The Spark Thrift server is launched as Yarn client mode. Its memory usage is increased gradually with the queries in.  I am wondering there is memory leak in Spark Thrift server.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12954504">SPARK-14261</key>
            <summary>Memory leak in Spark Thrift Server</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="olegd">Oleg Danilov</assignee>
                                    <reporter username="xiaochun">Xiaochun Liang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 30 Mar 2016 02:27:18 +0000</created>
                <updated>Mon, 18 Jul 2022 03:03:40 +0000</updated>
                            <resolved>Fri, 20 May 2016 05:25:55 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>1.6.2</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15217273" author="xiaochun" created="Wed, 30 Mar 2016 02:30:40 +0000"  >&lt;p&gt;This is the memory snapshot with query runs over 11 hours&lt;/p&gt;</comment>
                            <comment id="15217824" author="srowen" created="Wed, 30 Mar 2016 11:39:07 +0000"  >&lt;p&gt;I don&apos;t think this argues that there&apos;s a memory leak. You should do a heap dump to see what the allocated memory consists of. It could be a build-up of cached objects, for example, which aren&apos;t cleared unless memory is actually low.&lt;/p&gt;</comment>
                            <comment id="15219294" author="xiaochun" created="Thu, 31 Mar 2016 04:05:07 +0000"  >&lt;p&gt;Screenshots of heap dumps of Spark Thrift server under 6.4g and 8.0g memory situation respectively.&lt;/p&gt;</comment>
                            <comment id="15219304" author="xiaochun" created="Thu, 31 Mar 2016 04:21:07 +0000"  >&lt;p&gt;I did take heap dump when the serer is running. Unfortunately the heap dump file is too big to be uploaded, I just uploaded the screenshots of the heap dump. &lt;/p&gt;

&lt;p&gt;Some explanations on the screenshots of  heap dump:&lt;br/&gt;
1. The heap dump file was analyzed by MemoryAnalyzer,&lt;br/&gt;
2. 16716 is the process id,&lt;br/&gt;
3. 64g means the dump file was generated when the java process reaches 6.4g, while 80g means the dump file was generated when the java process reaches 8.0g&lt;/p&gt;

&lt;p&gt;I looked through the memory under two cases and had following findings:&lt;br/&gt;
1. java.io.DeleteOnExitHook took more memories in both cases,&lt;br/&gt;
2. The memory of org.apache.hadoop.hive.ql.processors.CommandProcessorFactory increases a lot when memory reaches 8g,&lt;br/&gt;
3. The memory of org.apache.hadoop.conf.Configuration increases a lot when memory reaches 8g.&lt;/p&gt;</comment>
                            <comment id="15270290" author="olegd" created="Wed, 4 May 2016 08:06:39 +0000"  >&lt;p&gt;I&apos;ve reproduced this issue as following:&lt;/p&gt;

&lt;p&gt;test.sql&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;add jar nexr-hive-udf-0.2-SNAPSHOT.jar;
CREATE TEMPORARY FUNCTION decoder AS &lt;span class=&quot;code-quote&quot;&gt;&apos;com.nexr.platform.hive.udf.GenericUDFDecode&apos;&lt;/span&gt; ;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;test.sh&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in {1..600}; &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; beeline -u jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//u1:10000 -f test.sql; done&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After that I found that the following HashMap in the CommandProcessorFactory contains 600 HiveConf instances preventing them from gc:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; Map&amp;lt;HiveConf, Driver&amp;gt; mapDrivers = Collections.synchronizedMap(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashMap&amp;lt;HiveConf, Driver&amp;gt;());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Seems like ClientWrapper should remove these instances. Something like:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;          &lt;span class=&quot;code-comment&quot;&gt;// Throw an exception &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there is an error in query processing.
&lt;/span&gt;          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (response.getResponseCode != 0) {
+            CommandProcessorFactory.clean(conf)
            driver.close()
            &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; QueryExecutionException(response.getErrorMessage)
          }
          driver.setMaxRows(maxRows)

          val results = shim.getDriverResults(driver)
+          CommandProcessorFactory.clean(conf)
          driver.close()
          results
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15272324" author="apachespark" created="Thu, 5 May 2016 13:25:04 +0000"  >&lt;p&gt;User &apos;dosoft&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12932&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12932&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15275238" author="sephiroth-lin" created="Sat, 7 May 2016 13:32:23 +0000"  >&lt;p&gt;I also face this issue.&lt;br/&gt;
I found each session will add one HiveConf on sun.misc.Launcher$AppClassLoader and one on org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1. All these HiveConf can&apos;t be released until OOM.&lt;br/&gt;
From the OOM dump(Use Eclipse Memory Analyzer to analyze), all these HiveConf have ref, it&apos;s GC root like below:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.hadoop.hive.conf.HiveConf
  conf org.apache.hadoop.hive.ql.session.SessionState$SessionStates
    value java.lang.ThreadLocal$ThreadLocalMap$Entry
      [19]  java.lang.ThreadLocal$ThreadLocalMap$Entry[32]
        table java.lang.ThreadLocal$ThreadLocalMap
          threadLocals java.lang.Thread
  referent java.util.WeakHashMap$Entry
  conf org.apache.hadoop.hive.ql.session.SessionState
    state org.apache.spark.sql.hive.client.ClientWrapper
      metaHive, metadataHive, metaHive org.apache.spark.sql.hive.client.HiveContext
        $outer org.apache.spark.sql.SQLContext$$anon$4
        [265] java.lang.Object[267]
          array java.util.concurrent.CopyWriteArrayList
            listeners org.apache.spark.scheduler.LiveListenerBus
              $outer org.apache.spark.util.AsynchronousListenerBus$$anon$1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15275514" author="xiaochun" created="Sun, 8 May 2016 08:19:23 +0000"  >&lt;p&gt;Thanks for taking care of the issue. I will apply the patch and verify the changes.&lt;/p&gt;</comment>
                            <comment id="15277789" author="xiaochun" created="Tue, 10 May 2016 08:20:49 +0000"  >&lt;p&gt;I tried the fix on Spark-1.6.1, apply the fix in ClientWrapper.scala(sql\hive\src\main\scala\org\apache\spark\sql\hive\client\ClientWrapper.scala), the test result is promising. The memory snapshot attached (8892_MemorySnapshot.PNG) shows the memory snapshot of spark thrift server after 21-hour long run. We can see memory used is dropped after query stopped. Also the memory snapshots with 4g, 5g, 6g, and 6g_stop_longrunquery, CommandProcessorFactory does not take memory any more. The spark thrift server runs well with the fix.&lt;/p&gt;


</comment>
                            <comment id="15277790" author="xiaochun" created="Tue, 10 May 2016 08:22:41 +0000"  >&lt;p&gt;Memory snapshots with the PR: 12932. &lt;a href=&quot;https://github.com/apache/spark/pull/12932&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12932&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17567787" author="tianshuang" created="Mon, 18 Jul 2022 03:03:40 +0000"  >&lt;p&gt;The memory usage problem of java.io.DeleteOnExitHook still exists. There seems to be no good fix. After ThriftServer runs for several months, java.io.DeleteOnExitHook#files will occupy a lot of memory.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12796228" name="16716_heapdump_64g.PNG" size="176356" author="xiaochun" created="Thu, 31 Mar 2016 04:05:07 +0000"/>
                            <attachment id="12796229" name="16716_heapdump_80g.PNG" size="180343" author="xiaochun" created="Thu, 31 Mar 2016 04:05:07 +0000"/>
                            <attachment id="12803184" name="8892_4g_objects.PNG" size="144654" author="xiaochun" created="Tue, 10 May 2016 08:22:41 +0000"/>
                            <attachment id="12803185" name="8892_5g_objects.PNG" size="145120" author="xiaochun" created="Tue, 10 May 2016 08:22:41 +0000"/>
                            <attachment id="12803186" name="8892_6g_objects.PNG" size="149024" author="xiaochun" created="Tue, 10 May 2016 08:22:41 +0000"/>
                            <attachment id="12803187" name="8892_6g_stop_longrunquery_objects.PNG" size="147769" author="xiaochun" created="Tue, 10 May 2016 08:22:41 +0000"/>
                            <attachment id="12803188" name="8892_MemorySnapshot.PNG" size="256148" author="xiaochun" created="Tue, 10 May 2016 08:22:41 +0000"/>
                            <attachment id="12796002" name="MemorySnapshot.PNG" size="219458" author="xiaochun" created="Wed, 30 Mar 2016 02:30:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 17 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2vdon:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12334910">1.6.2</customfieldvalue>
    <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>