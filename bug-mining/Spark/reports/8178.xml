<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:27:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-36803] ClassCastException: optional int32 col-0 is not a group when reading legacy Parquet files </title>
                <link>https://issues.apache.org/jira/browse/SPARK-36803</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When reading Parquet files that have been written in legacy mode and schema evolution, we observed that 2-level LIST annotated types are traversed incorrectly.&#160;&lt;/p&gt;

&lt;p&gt;The root cause is the imprecise check on the underlying element type for Array types (and potentially Map types but I have not checked those yet) that happens here: &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/parquet/ParquetRowConverter.scala#L606&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/parquet/ParquetRowConverter.scala#L606&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The issue is only reproducible with schema evolution with parquet-mr reader and when there are two schemas like this:&lt;/p&gt;

&lt;p&gt;File 1:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
root
 |-- col-0: array (nullable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
 |    |-- element: struct (containsNull = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)
 |    |    |-- col-0: integer (nullable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;File 2:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
root
 |-- col-0: array (nullable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
 |    |-- element: struct (containsNull = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)
 |    |    |-- col-0: integer (nullable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
 |    |    |-- col-1: integer (nullable = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;When ParquetRowConverter tries to unwrap ArrayType, it checks if the underlying types between Parquet and Spark match. However, in the case above since the actual schema would include both fields, resulting in mismatch and failure to read File 1:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 11.0 failed 1 times, most recent failure: Lost task 1.0 in stage 11.0 (TID 18) (ip-1-2-3-4.us-west-2.compute.internal executor driver): java.lang.ClassCastException: optional int32 col-0 is not a group
at org.apache.parquet.schema.Type.asGroupType(Type.java:248)
at org.apache.spark.sql.execution.datasources.parquet.ParquetRowConverter.org$apache$spark$sql$execution$datasources$parquet$ParquetRowConverter$$newConverter(ParquetRowConverter.scala:424)
at org.apache.spark.sql.execution.datasources.parquet.ParquetRowConverter$ParquetArrayConverter$ElementConverter.&amp;lt;init&amp;gt;(ParquetRowConverter.scala:633)
at org.apache.spark.sql.execution.datasources.parquet.ParquetRowConverter$ParquetArrayConverter.&amp;lt;init&amp;gt;(ParquetRowConverter.scala:616)
at org.apache.spark.sql.execution.datasources.parquet.ParquetRowConverter.org$apache$spark$sql$execution$datasources$parquet$ParquetRowConverter$$newConverter(ParquetRowConverter.scala:390)
at org.apache.spark.sql.execution.datasources.parquet.ParquetRowConverter.$anonfun$fieldConverters$1(ParquetRowConverter.scala:214)
at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
at scala.collection.TraversableLike.map(TraversableLike.scala:286)
at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
at scala.collection.AbstractTraversable.map(Traversable.scala:108)
at org.apache.spark.sql.execution.datasources.parquet.ParquetRowConverter.&amp;lt;init&amp;gt;(ParquetRowConverter.scala:210)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This happens due to L606 in ParquetRowConverter:&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
DataType.equalsIgnoreCompatibleNullability(guessedElementType, elementType)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The code assumes that we are working with 3 level lists and would incorrectly remove the &#8220;dummy&#8221; level from the Parquet schema.&lt;/p&gt;

&lt;p&gt;The actual error varies depending on column names - in this case struct type name matches primitive type name so we end up with &quot;optional int32 col-0 is not a group&quot;. In other case, it could fail with IndexOutOfBoundException or NoSuchElementException when the column name is not found in the struct.&lt;/p&gt;

&lt;p&gt;The reason it works with 3-level list, that DataType.equalsIgnoreCompatibleNullability(guessedElementType, elementType) always evaluates to false, we remove the &#8220;dummy&#8221; level and perform struct match which takes into account schema evolution. &#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Repro:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.types._

val schema1 = StructType(
  StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;col-0&quot;&lt;/span&gt;, ArrayType(
    StructType(
      StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;col-0&quot;&lt;/span&gt;, IntegerType, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) :: Nil
    ), 
    containsNull = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
  )) :: Nil
)
val rdd1 = sc.parallelize(Row(Array(Row(1))) :: Nil, 1)
val df1 = spark.createDataFrame(rdd1, schema1)

df1.write.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/legacy-parquet&quot;&lt;/span&gt;)

val schema2 = StructType(
  StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;col-0&quot;&lt;/span&gt;, ArrayType(
    StructType(
      StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;col-0&quot;&lt;/span&gt;, IntegerType, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) :: StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;col-1&quot;&lt;/span&gt;, IntegerType, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) :: Nil
    ), 
    containsNull = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
  )) :: Nil
)
val rdd2 = sc.parallelize(Row(Array(Row(1, 2))) :: Nil, 1)
val df2 = spark.createDataFrame(rdd2, schema2)

df2.write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;append&quot;&lt;/span&gt;).parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/legacy-parquet&quot;&lt;/span&gt;)

&lt;span class=&quot;code-comment&quot;&gt;// Fails with: Caused by: ClassCastException: optional int32 col-0 is not a group
&lt;/span&gt;display(spark.read.schema(schema2).parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/legacy-parquet&quot;&lt;/span&gt;))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13402082">SPARK-36803</key>
            <summary>ClassCastException: optional int32 col-0 is not a group when reading legacy Parquet files </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ivan.sadikov">Ivan Sadikov</assignee>
                                    <reporter username="ivan.sadikov">Ivan Sadikov</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Sep 2021 00:20:50 +0000</created>
                <updated>Wed, 22 Sep 2021 09:43:45 +0000</updated>
                            <resolved>Wed, 22 Sep 2021 09:42:36 +0000</resolved>
                                    <version>3.1.2</version>
                                    <fixVersion>3.2.0</fixVersion>
                    <fixVersion>3.1.3</fixVersion>
                    <fixVersion>3.0.4</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17417425" author="apachespark" created="Mon, 20 Sep 2021 00:55:16 +0000"  >&lt;p&gt;User &apos;sadikovi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34044&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34044&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17417426" author="apachespark" created="Mon, 20 Sep 2021 00:55:51 +0000"  >&lt;p&gt;User &apos;sadikovi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34044&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34044&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17418498" author="cloud_fan" created="Wed, 22 Sep 2021 09:42:36 +0000"  >&lt;p&gt;Issue resolved by pull request 34044&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34044&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34044&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0v2u8:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>