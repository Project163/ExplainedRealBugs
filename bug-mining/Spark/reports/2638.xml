<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:34:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-10986] ClassNotFoundException when running on Client mode, with a Mesos master.</title>
                <link>https://issues.apache.org/jira/browse/SPARK-10986</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When running an example task on a Mesos cluster (local master, local agent), any Spark tasks will stall with the following error (in the executor&apos;s stderr):&lt;/p&gt;

&lt;p&gt;Works fine in coarse-grained mode, only fails in &lt;b&gt;fine-grained mode&lt;/b&gt;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/10/07 15:21:14 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;sparkExecutor&apos;&lt;/span&gt; on port 53689.
15/10/07 15:21:14 WARN TransportChannelHandler: Exception in connection from /10.0.79.8:53673
java.lang.ClassNotFoundException: org/apache/spark/rpc/netty/AskResponse
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:348)
	at org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:68)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1613)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1518)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1774)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:109)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$deserialize$1.apply(NettyRpcEnv.scala:227)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:265)
	at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$3$$anon$4.onSuccess(NettyRpcEnv.scala:196)
	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:152)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
15/10/07 15:21:14 ERROR NettyRpcHandler: org/apache/spark/rpc/netty/AskResponse
java.lang.ClassNotFoundException: org/apache/spark/rpc/netty/AskResponse
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:348)
	at org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:68)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1613)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1518)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1774)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:109)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anonfun$deserialize$1.apply(NettyRpcEnv.scala:227)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
	at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:265)
	at org.apache.spark.rpc.netty.NettyRpcEnv.deserialize(NettyRpcEnv.scala:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv$$anon$3$$anon$4.onSuccess(NettyRpcEnv.scala:196)
	at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:152)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:103)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:244)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The commands to setup the environment and submit a job:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;cd &amp;lt;mesos-binaries&amp;gt;
mesos-master.sh --ip=127.0.0.1 --work_dir=&amp;lt;temp&amp;gt;
mesos-slave.sh --master=127.0.0.1:5050

cd &amp;lt;spark-home&amp;gt;
bin/spark-submit --master mesos:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:5050 examples/src/main/python/pi.py 10&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On v1.4.1 and v1.5.1, the Spark job finished with no problems.&lt;/p&gt;

&lt;p&gt;Possibly introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-6028&quot; title=&quot;Provide an alternative RPC implementation based on the network transport module&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-6028&quot;&gt;&lt;del&gt;SPARK-6028&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</description>
                <environment>&lt;p&gt;OSX, Java 8, Mesos 0.25.0&lt;/p&gt;

&lt;p&gt;HEAD of Spark (`f5d154bc731aedfc2eecdb4ed6af8cac820511c9`)&lt;br/&gt;
Built from source:&lt;br/&gt;
build/mvn -Pyarn -Phadoop-2.4 -Dhadoop.version=2.4.0 -DskipTests clean package&lt;/p&gt;</environment>
        <key id="12903155">SPARK-10986</key>
            <summary>ClassNotFoundException when running on Client mode, with a Mesos master.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dragos">Dragos Dascalita Haut</assignee>
                                    <reporter username="kaysoky">Joseph Wu</reporter>
                        <labels>
                            <label>mesos</label>
                            <label>spark</label>
                    </labels>
                <created>Wed, 7 Oct 2015 22:21:49 +0000</created>
                <updated>Fri, 30 Oct 2015 16:52:17 +0000</updated>
                            <resolved>Fri, 30 Oct 2015 16:51:58 +0000</resolved>
                                    <version>1.5.2</version>
                                    <fixVersion>1.6.0</fixVersion>
                                    <component>Mesos</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14950507" author="dragos" created="Fri, 9 Oct 2015 14:48:44 +0000"  >&lt;p&gt;I can confirm this issue. It only happens in &lt;b&gt;fine-grained mode&lt;/b&gt;. &lt;/p&gt;

&lt;p&gt;It&apos;s weird, because I downloaded the Spark assembly jar from the slave where it failed (it fails on all slaves), and the class &lt;b&gt;is&lt;/b&gt; there:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ javap -classpath ~/Downloads/spark-assembly-1.6.0-SNAPSHOT-hadoop2.6.0.jar org.apache.spark.rpc.netty.AskResponse
Compiled from &lt;span class=&quot;code-quote&quot;&gt;&quot;NettyRpcEnv.scala&quot;&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.rpc.netty.AskResponse &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; org.apache.spark.rpc.netty.ResponseMessage,scala.Product,scala.Serializable {
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; scala.Option&amp;lt;scala.Tuple2&amp;lt;org.apache.spark.rpc.netty.NettyRpcEndpointRef, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt;&amp;gt; unapply(org.apache.spark.rpc.netty.AskResponse);
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; org.apache.spark.rpc.netty.AskResponse apply(org.apache.spark.rpc.netty.NettyRpcEndpointRef, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;);
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; scala.Function1&amp;lt;scala.Tuple2&amp;lt;org.apache.spark.rpc.netty.NettyRpcEndpointRef, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt;, org.apache.spark.rpc.netty.AskResponse&amp;gt; tupled();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; scala.Function1&amp;lt;org.apache.spark.rpc.netty.NettyRpcEndpointRef, scala.Function1&amp;lt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;, org.apache.spark.rpc.netty.AskResponse&amp;gt;&amp;gt; curried();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; org.apache.spark.rpc.netty.NettyRpcEndpointRef sender();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; reply();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; org.apache.spark.rpc.netty.AskResponse copy(org.apache.spark.rpc.netty.NettyRpcEndpointRef, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;);
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; org.apache.spark.rpc.netty.NettyRpcEndpointRef copy$&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;$1();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; copy$&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;$2();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; productPrefix();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; productArity();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; productElement(&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;);
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; scala.collection.Iterator&amp;lt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt; productIterator();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; canEqual(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;);
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; hashCode();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; toString();
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; equals(java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;);
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; org.apache.spark.rpc.netty.AskResponse(org.apache.spark.rpc.netty.NettyRpcEndpointRef, java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;);
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14974480" author="dragos" created="Mon, 26 Oct 2015 16:16:55 +0000"  >&lt;p&gt;Digging a bit deeper. The problem is that the context class loader is not set when running in fine-grained mode. When the Java serializer is created, it uses a &lt;tt&gt;null&lt;/tt&gt; classloader, leading to &lt;tt&gt;ClassNotFoundException&lt;/tt&gt; (&lt;tt&gt;Class.forName&lt;/tt&gt; with a null classloader uses the primordial class loader, meaning only the JDK is in there).&lt;/p&gt;

&lt;p&gt;In coarse-grained, the context class loader is set by some hadoop classes dealing with &lt;tt&gt;UserGroupInformation&lt;/tt&gt;, via &lt;tt&gt;runAsSparkUser&lt;/tt&gt;. It&apos;s probably totally accidental that it works.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure where is the right place to set the context class loader, and who else relies on it. This part is totally undocumented.&lt;/p&gt;</comment>
                            <comment id="14974488" author="kaysoky" created="Mon, 26 Oct 2015 16:21:09 +0000"  >&lt;p&gt;Definitely accidental.  I&apos;ve tried running in course-grained mode, and it has the same error for me.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gabriel.hartmann%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;gabriel.hartmann@gmail.com&quot;&gt;gabriel.hartmann@gmail.com&lt;/a&gt; also tried.&lt;/p&gt;</comment>
                            <comment id="14974548" author="apachespark" created="Mon, 26 Oct 2015 17:03:03 +0000"  >&lt;p&gt;User &apos;dragos&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/9282&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/9282&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14974673" author="dragos" created="Mon, 26 Oct 2015 17:58:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kaysoky&quot; class=&quot;user-hover&quot; rel=&quot;kaysoky&quot;&gt;kaysoky&lt;/a&gt; can you try my PR and see if it solves it for you?&lt;/p&gt;</comment>
                            <comment id="14974763" author="kaysoky" created="Mon, 26 Oct 2015 18:23:09 +0000"  >&lt;p&gt;It works!  I&apos;ll also notify Gabriel to try his more complex/interesting test case.  (He&apos;s currently OOO until next week.)&lt;/p&gt;</comment>
                            <comment id="14974777" author="dragos" created="Mon, 26 Oct 2015 18:28:43 +0000"  >&lt;p&gt;Great! Please leave a note on the PR as well.. It&apos;s been particularly difficult to get attention from committers lately.&lt;/p&gt;</comment>
                            <comment id="14982861" author="srowen" created="Fri, 30 Oct 2015 16:51:58 +0000"  >&lt;p&gt;Issue resolved by pull request 9282&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/9282&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/9282&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 3 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2mptr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12333083">1.6.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>