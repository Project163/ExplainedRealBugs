<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:00:06 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-24373] &quot;df.cache() df.count()&quot; no longer eagerly caches data when the analyzed plans are different after re-analyzing the plans</title>
                <link>https://issues.apache.org/jira/browse/SPARK-24373</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Here is the code to reproduce in local mode&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; val df = sc.range(1, 2).toDF
df: org.apache.spark.sql.DataFrame = [value: bigint]

scala&amp;gt; val myudf = udf({x: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; =&amp;gt; println(&lt;span class=&quot;code-quote&quot;&gt;&quot;xxxx&quot;&lt;/span&gt;); x + 1})
myudf: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&amp;lt;function1&amp;gt;,LongType,Some(List(LongType)))

scala&amp;gt; val df1 = df.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;value1&quot;&lt;/span&gt;, myudf(col(&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;)))
df1: org.apache.spark.sql.DataFrame = [value: bigint, value1: bigint]

scala&amp;gt; df1.cache
res0: df1.type = [value: bigint, value1: bigint]

scala&amp;gt; df1.count
res1: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = 1 

scala&amp;gt; df1.count
res2: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = 1

scala&amp;gt; df1.count
res3: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;in Spark 2.2, you could see it prints &quot;xxxx&quot;.&#160;&lt;/p&gt;

&lt;p&gt;In the above example, when you do explain. You could see&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; df1.explain(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
== Parsed Logical Plan ==
&lt;span class=&quot;code-quote&quot;&gt;&apos;Project [value#2L, UDF(&apos;&lt;/span&gt;value) AS value1#5]
+- AnalysisBarrier
+- SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- ExternalRDD [obj#1L]

== Analyzed Logical Plan ==
value: bigint, value1: bigint
Project [value#2L, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; UDF(value#2L) AS value1#5L]
+- SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- ExternalRDD [obj#1L]

== Optimized Logical Plan ==
InMemoryRelation [value#2L, value1#5L], &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)
+- *(1) Project [value#2L, UDF(value#2L) AS value1#5L]
+- *(1) SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- Scan ExternalRDDScan[obj#1L]

== Physical Plan ==
*(1) InMemoryTableScan [value#2L, value1#5L]
+- InMemoryRelation [value#2L, value1#5L], &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)
+- *(1) Project [value#2L, UDF(value#2L) AS value1#5L]
+- *(1) SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- Scan ExternalRDDScan[obj#1L]

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but the ImMemoryTableScan is mising in the following explain()&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; df1.groupBy().count().explain(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
== Parsed Logical Plan ==
Aggregate [count(1) AS count#170L]
+- Project [value#2L, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; UDF(value#2L) AS value1#5L]
+- SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- ExternalRDD [obj#1L]

== Analyzed Logical Plan ==
count: bigint
Aggregate [count(1) AS count#170L]
+- Project [value#2L, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; UDF(value#2L) AS value1#5L]
+- SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- ExternalRDD [obj#1L]

== Optimized Logical Plan ==
Aggregate [count(1) AS count#170L]
+- Project
+- SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- ExternalRDD [obj#1L]

== Physical Plan ==
*(2) HashAggregate(keys=[], functions=[count(1)], output=[count#170L])
+- Exchange SinglePartition
+- *(1) HashAggregate(keys=[], functions=[partial_count(1)], output=[count#175L])
+- *(1) Project
+- *(1) SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- Scan ExternalRDDScan[obj#1L]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13161595">SPARK-24373</key>
            <summary>&quot;df.cache() df.count()&quot; no longer eagerly caches data when the analyzed plans are different after re-analyzing the plans</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mgaido">Marco Gaido</assignee>
                                    <reporter username="wbzhao">Wenbo Zhao</reporter>
                        <labels>
                    </labels>
                <created>Wed, 23 May 2018 21:44:46 +0000</created>
                <updated>Wed, 30 May 2018 21:19:08 +0000</updated>
                            <resolved>Mon, 28 May 2018 05:57:49 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.1</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="16488109" author="icexelloss" created="Wed, 23 May 2018 22:13:18 +0000"  >&lt;p&gt;We found after upgrading to Spark 2.3, many of our production systems runs slower. This is founded to be caused by &quot;df.cache(); df.count()&quot; no longer eagerly cache df correctly.&#160;I think this&#160;might be a regression from 2.2.&#160;&lt;/p&gt;

&lt;p&gt;I think any one uses&#160;&#160;&quot;df.cache() df.count()&quot; to cache data eagerly will be affected.&lt;/p&gt;</comment>
                            <comment id="16489060" author="icexelloss" created="Thu, 24 May 2018 14:05:00 +0000"  >&lt;p&gt;This is a reproduce:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val myUDF = udf((x: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;) =&amp;gt; { println(&lt;span class=&quot;code-quote&quot;&gt;&quot;xxxx&quot;&lt;/span&gt;); x + 1 })

val df1 = spark.range(0, 1).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;s&quot;&lt;/span&gt;).select(myUDF($&lt;span class=&quot;code-quote&quot;&gt;&quot;s&quot;&lt;/span&gt;))
df1.cache()
df1.count()
&lt;span class=&quot;code-comment&quot;&gt;// No xxxx printed&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;It appears the issue is related to UDF:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val df1 = spark.range(0, 1).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;s&quot;&lt;/span&gt;).select(myUDF($&lt;span class=&quot;code-quote&quot;&gt;&quot;s&quot;&lt;/span&gt;))
df1.cache()
df1.groupBy().count().explain()

== Physical Plan ==
*(2) HashAggregate(keys=[], functions=[count(1)])
+- Exchange SinglePartition
  +- *(1) HashAggregate(keys=[], functions=[partial_count(1)])
    +- *(1) Project
      +- *(1) Range (0, 1, step=1, splits=2)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Without UDF it uses &quot;count&quot; materialize cache:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val df1 = spark.range(0, 1).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;s&quot;&lt;/span&gt;).select($&lt;span class=&quot;code-quote&quot;&gt;&quot;s&quot;&lt;/span&gt; + 1)
df1.cache()
df1.groupBy().count().explain()

== Physical Plan ==
*(2) HashAggregate(keys=[], functions=[count(1)])
  +- Exchange SinglePartition
    +- *(1) HashAggregate(keys=[], functions=[partial_count(1)])
      +- *(1) InMemoryTableScan
        +- InMemoryRelation [(s + 1)#179L], CachedRDDBuilder(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,10000,StorageLevel(disk, memory, deserialized, 1 replicas),*(1) Project [(id#175L + 1) AS (s + 1)#179L]
          +- *(1) Range (0, 1, step=1, splits=2) ,None)
            +- *(1) Project [(id#175L + 1) AS (s + 1)#179L]
               +- *(1) Range (0, 1, step=1, splits=2)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16489129" author="aweise" created="Thu, 24 May 2018 14:46:09 +0000"  >&lt;p&gt;We are also facing increased runtime duration for our SQL jobs (after upgrading from 2.2.1 to 2.3.0), but didn&apos;t trace it down to the root cause. This issue sounds reasonable to me, as we are also using cache() + count() quite often.&lt;/p&gt;</comment>
                            <comment id="16489233" author="wbzhao" created="Thu, 24 May 2018 15:37:26 +0000"  >&lt;p&gt;I turned on the log trace of RuleExecutor and found that in my example of df1.count() after cache.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; df1.groupBy().count().explain(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)

=== Applying Rule org.apache.spark.sql.catalyst.analysis.Analyzer$HandleNullInputsForUDF ===
Aggregate [count(1) AS count#40L] Aggregate [count(1) AS count#40L]
!+- Project [value#2L, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; UDF(value#2L) AS value1#5L] +- Project [value#2L, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; UDF(value#2L) AS value1#5L]
+- SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L] +- SerializeFromObject [input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] AS value#2L]
+- ExternalRDD [obj#1L] +- ExternalRDD [obj#1L]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;that is node&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Project [value#2L, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; UDF(value#2L) AS value1#5L]&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;becomes&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Project [value#2L, &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isnull(value#2L)) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; UDF(value#2L) AS value1#5L]&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;This will cause a miss in the CacheManager?&lt;/p&gt;

&lt;p&gt;which could be confirmed by later&#160;applying&#160;ColumnPrunning rule&apos;s log trace.&#160;&#160;&lt;/p&gt;

&lt;p&gt;May question is: is that supposed protected by AnalysisBarrier ?&lt;/p&gt;</comment>
                            <comment id="16489389" author="vanzin" created="Thu, 24 May 2018 16:57:16 +0000"  >&lt;p&gt;This  could be the same as &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-23309&quot; title=&quot;Spark 2.3 cached query performance 20-30% worse then spark 2.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-23309&quot;&gt;&lt;del&gt;SPARK-23309&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16489534" author="wbzhao" created="Thu, 24 May 2018 18:23:30 +0000"  >&lt;p&gt;It is not apparently to me that they are the same issue though&lt;/p&gt;</comment>
                            <comment id="16489820" author="wbzhao" created="Thu, 24 May 2018 21:17:11 +0000"  >&lt;p&gt;I guess we should use `planWithBarrier` in the &apos;RelationalGroupedDataset&apos;&#160;or other similar places. Any suggestion?&lt;/p&gt;</comment>
                            <comment id="16490551" author="mgaido" created="Fri, 25 May 2018 10:51:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wbzhao&quot; class=&quot;user-hover&quot; rel=&quot;wbzhao&quot;&gt;wbzhao&lt;/a&gt; yes, I do agree with you. That is the problem.&lt;/p&gt;</comment>
                            <comment id="16490772" author="apachespark" created="Fri, 25 May 2018 14:12:07 +0000"  >&lt;p&gt;User &apos;mgaido91&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21432&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21432&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16491081" author="smilegator" created="Fri, 25 May 2018 17:54:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=icexelloss&quot; class=&quot;user-hover&quot; rel=&quot;icexelloss&quot;&gt;icexelloss&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aweise&quot; class=&quot;user-hover&quot; rel=&quot;aweise&quot;&gt;aweise&lt;/a&gt; Are you also using the Dataset APIs groupBy(), rollup(), cube(), rollup, pivot() and groupByKey()?&lt;/p&gt;</comment>
                            <comment id="16491086" author="icexelloss" created="Fri, 25 May 2018 17:56:08 +0000"  >&lt;p&gt;We use groupby() and pivot()&lt;/p&gt;</comment>
                            <comment id="16491088" author="smilegator" created="Fri, 25 May 2018 17:59:36 +0000"  >&lt;p&gt;BTW, I plan to continue my work of &lt;a href=&quot;https://github.com/apache/spark/pull/18717&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18717&lt;/a&gt;, which will add an eager persist/cache API. &lt;/p&gt;</comment>
                            <comment id="16491124" author="mgaido" created="Fri, 25 May 2018 18:24:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; I think an eager API is not related to the problem experienced here, though.&lt;/p&gt;</comment>
                            <comment id="16491153" author="tomaszgaweda" created="Fri, 25 May 2018 18:52:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=LI%2CXiao&quot; class=&quot;user-hover&quot; rel=&quot;LI,Xiao&quot;&gt;LI,Xiao&lt;/a&gt;  That is a good idea &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Eager caching is useful, many times I see additional count just to cache eagerly&lt;/p&gt;</comment>
                            <comment id="16491224" author="smilegator" created="Fri, 25 May 2018 20:18:51 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  def count(): &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = withAction(&lt;span class=&quot;code-quote&quot;&gt;&quot;count&quot;&lt;/span&gt;, groupBy().count().queryExecution) { plan =&amp;gt;
    plan.executeCollect().head.getLong(0)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Many Spark users are using df.count() after df.cache() for achieving eager caching.  Since our count() API is using `groupBy()`, the impact becomes much bigger. The count() API will not trigger the data materialization when the plans are different after multiple rounds of plan analysis. &lt;/p&gt;</comment>
                            <comment id="16491271" author="mgaido" created="Fri, 25 May 2018 21:09:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; yes, you&apos;re right, the impact would be definitely lower.&lt;/p&gt;</comment>
                            <comment id="16491304" author="smilegator" created="Fri, 25 May 2018 21:50:15 +0000"  >&lt;p&gt;In the above example, each time when we re-analyze the plan that is recreated through the Dataset APIs count(), groupBy(), rollup(), cube(), rollup, pivot() and groupByKey(), the Analyzer rule HandleNullInputsForUDF will add the extra IF expression above the UDF in the previously resolved sub-plan. Note, this is not the only rule that could change the analyzed plans if we re-run the analyzer.&lt;/p&gt;

&lt;p&gt;This is a regression introduced by &lt;a href=&quot;https://github.com/apache/spark/pull/17770&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17770&lt;/a&gt;. We replaced the original solution (based on the analyzed flag) by the AnalysisBarrier. However, we did not add the AnalysisBarrier on the APIs of RelationalGroupedDataset and KeyValueGroupedDataset.&lt;/p&gt;

&lt;p&gt;To fix it, we will changes the plan again. We might face some unknown issues. How about adding a temporary flag in Spark 2.3.1? If anything unexpected happens, our users still can change it back to the Spark 2.3.0 behavior?&lt;/p&gt;</comment>
                            <comment id="16491309" author="icexelloss" created="Fri, 25 May 2018 21:54:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; do you mean that add AnalysisBarrier to&#160;RelationalGroupedDataset and&#160;KeyValueGroupedDataset could lead to new bugs?&lt;/p&gt;</comment>
                            <comment id="16493548" author="mgaido" created="Tue, 29 May 2018 13:53:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wbzhao&quot; class=&quot;user-hover&quot; rel=&quot;wbzhao&quot;&gt;wbzhao&lt;/a&gt; as I answered on the PR, the fix is complete and includes also &lt;tt&gt;flatMapGroupsInPandas&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="16493569" author="wbzhao" created="Tue, 29 May 2018 14:18:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mgaido&quot; class=&quot;user-hover&quot; rel=&quot;mgaido&quot;&gt;mgaido&lt;/a&gt; Thanks. I didn&apos;t look the comment carefully.&#160;&lt;/p&gt;</comment>
                            <comment id="16495691" author="smilegator" created="Wed, 30 May 2018 21:15:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=icexelloss&quot; class=&quot;user-hover&quot; rel=&quot;icexelloss&quot;&gt;icexelloss&lt;/a&gt; This is still possible since the query plans are changed. I am also fine to do it without a flag. If you apply the fix to your internal fork, I would suggest to add a flag. At least, you can turn it off when anything unexpected happens. &lt;/p&gt;</comment>
                            <comment id="16495695" author="icexelloss" created="Wed, 30 May 2018 21:19:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; Thank you for the suggestion.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 24 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3u3a7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12342432">2.3.1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>