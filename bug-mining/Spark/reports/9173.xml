<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:34:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-29497] Cannot assign instance of java.lang.invoke.SerializedLambda to field</title>
                <link>https://issues.apache.org/jira/browse/SPARK-29497</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Note this is for scala 2.12:&lt;/p&gt;

&lt;p&gt;There seems to be an issue in spark with serializing a udf that is created from a function assigned to a class member that references another function assigned to a class member. This is similar to&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-25047&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-25047&lt;/a&gt;&#160;but it looks like the resolution has an issue with this case. After trimming it down to the base issue I came up with the following to reproduce:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
object TestLambdaShell &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Serializable {
  val hello: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; =&amp;gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = s =&amp;gt; s&lt;span class=&quot;code-quote&quot;&gt;&quot;hello $s!&quot;&lt;/span&gt;  
  val lambdaTest: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; =&amp;gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = hello( _ )  
  def functionTest: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; =&amp;gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = hello( _ )
}

val hello = udf( TestLambdaShell.hello )
val functionTest = udf( TestLambdaShell.functionTest )
val lambdaTest = udf( TestLambdaShell.lambdaTest )

sc.parallelize(Seq(&lt;span class=&quot;code-quote&quot;&gt;&quot;world&quot;&lt;/span&gt;),1).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;).select(hello($&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;)).show(1)
sc.parallelize(Seq(&lt;span class=&quot;code-quote&quot;&gt;&quot;world&quot;&lt;/span&gt;),1).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;).select(functionTest($&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;)).show(1)
sc.parallelize(Seq(&lt;span class=&quot;code-quote&quot;&gt;&quot;world&quot;&lt;/span&gt;),1).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;).select(lambdaTest($&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;)).show(1)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;All of which works except the last line which results in an exception on the executors:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field $$$82b5b23cea489b2712a1db46c77e458$$$$w$TestLambdaShell$.lambdaTest of type scala.Function1 in instance of $$$82b5b23cea489b2712a1db46c77e458$$$$w$TestLambdaShell$
  at java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2133)
  at java.io.ObjectStreamClass.setObjFieldValues(ObjectStreamClass.java:1305)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2251)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1933)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1529)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1933)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1529)
  at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1933)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1529)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1933)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1529)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
  at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
  at java.lang.reflect.Method.invoke(Method.java:498)
  at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
  at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
  at java.lang.reflect.Method.invoke(Method.java:498)
  at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2136)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
  at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
  at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
  at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
  at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
  at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
  at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:114)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;In spark 2.2.x I used a class that had something like this that worked fine, now that we&apos;ve upgraded to 2.12 we ran into a few serialization issues in places, most of which were solved by extending serializable but this case was not fixed by that.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Also this happens regardless of whether it&apos;s done in the shell or in a jar.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;So after much more debugging, this turns out to be some weird mix of scala 2.12.0 and scala 2.12.8. Spark is compiled on 2.12.8 and so is our own code but I noticed that the maven compiled class did not match the compiled class using 2.12.8 scalac directly. After a lot of digging we realized that scala-compiler actually indirectly depends on scala library 2.12.0 and only when the spark dependency is added does it start using it for some reason. Without the spark dependency and just direct scala 2.12.8 dependencies, the code builds fine and compiles correctly as 2.12.8.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;We were able to fix this using:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;lt;failOnMultipleScalaVersions&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&amp;lt;/failOnMultipleScalaVersions&amp;gt;
&amp;lt;scalaCompatVersion&amp;gt;2.12&amp;lt;/scalaCompatVersion&amp;gt;
&amp;lt;scalaVersion&amp;gt;2.12.8&amp;lt;/scalaVersion&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;And this resolves our issue for our own jars that we create and link to spark. However, my original test case still seems to reproduce in the spark shell and for us also in apache zeppelin so it seems almost like somehow they are also compiling it on 2.12.0 but I&apos;m not quite sure how. In the spark pom.xml it seems to have the fail on multiple versions and compiles fine so I&apos;m not quite sure how this is happening but at least its more isolated now. I&apos;m also wondering if anything else could be affected by this.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Spark 2.4.3 Scala 2.12&lt;br/&gt;
Spark 3.2.0 Scala 2.13.5 (Java 11.0.12)&lt;/p&gt;</environment>
        <key id="13262803">SPARK-29497</key>
            <summary>Cannot assign instance of java.lang.invoke.SerializedLambda to field</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="rrusso2007">Rob Russo</reporter>
                        <labels>
                    </labels>
                <created>Thu, 17 Oct 2019 09:08:20 +0000</created>
                <updated>Tue, 1 Aug 2023 18:55:18 +0000</updated>
                                            <version>2.4.3</version>
                    <version>3.0.1</version>
                    <version>3.2.0</version>
                                                    <component>Spark Core</component>
                        <due></due>
                            <votes>6</votes>
                                    <watches>15</watches>
                                                                                                                <comments>
                            <comment id="17247482" author="nkronenfeld" created="Thu, 10 Dec 2020 20:09:09 +0000"  >&lt;p&gt;This is happening to us too.&#160; We haven&apos;t figured out how to get around it in our own code, other than passing raw functions around.&lt;/p&gt;

&lt;p&gt;We&apos;re using Gradle instead of Maven, so I&apos;m not sure if those variables even exist for us.&lt;/p&gt;</comment>
                            <comment id="17396760" author="victor3y" created="Tue, 10 Aug 2021 16:09:19 +0000"  >&lt;p&gt;I&apos;ve also been able to reproduce this on Spark 3.1.1 using Scala 2.12.10 on the vanilla Spark-Shell&lt;/p&gt;

&lt;p&gt;Seems like a persistent issue&lt;/p&gt;</comment>
                            <comment id="17498239" author="jaysen" created="Fri, 25 Feb 2022 17:59:36 +0000"  >&lt;p&gt;some more verifying and additional info.&lt;br/&gt;
i was able to reproduce this on both spark-3.2.1 (scala 2.12) and spark-3.2.1 (scala 2.13)) - hadoop3.2 on shell as well as via java code.&lt;/p&gt;

&lt;p&gt;local scala and java version:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&#10095; scala -version
Scala code runner version 2.12.14 -- Copyright 2002-2021, LAMP/EPFL and Lightbend, Inc.
&#10095; java --version
openjdk 11.0.12 2021-07-20&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In my case, I am using map ( same with mapParttion also)&lt;/p&gt;

&lt;p&gt;Example:&#160; simple Function with dummy reducer:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
JavaRDD&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt; rdd =
data.toJavaRDD().map(
&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Function&amp;lt;Row, &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;&amp;gt;() {
@Override
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; call(Row v1) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception
{ &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; v1 !=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; }
}
);
&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; result = rdd.reduce(LocalClass::reduceDummy);
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; reduceDummy(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; a, &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; b)
{ &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;; }
&#160;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Error:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.rdd.MapPartitionsRDD.f of type scala.Function3 in instance of org.apache.spark.rdd.MapPartitionsRDD
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Stacktrace:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.rdd.MapPartitionsRDD.f of type scala.Function3 in instance of org.apache.spark.rdd.MapPartitionsRDD
at java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2205)
at java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2168)
at java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1422)
Caused by: java.lang.ClassCastException: cannot assign instance of java.lang.invoke.SerializedLambda to field org.apache.spark.rdd.MapPartitionsRDD.f of type scala.Function3 in instance of org.apache.spark.rdd.MapPartitionsRDD
at java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2480)
at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2387)
at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:115)
at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:83)
at org.apache.spark.scheduler.Task.run(Task.scala:131)
at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
at java.base/java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:829)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;It works fine via spark test framework, but not with spark standalone:&lt;/b&gt; com.holdenkarau:spark-testing-base_2.12&lt;/p&gt;</comment>
                            <comment id="17748961" author="hvanhovell" created="Sun, 30 Jul 2023 19:06:58 +0000"  >&lt;p&gt;We have seen the same problem with Spark Connect. As far as I can tell this is either a Scala or Java bug. As soon as you invoke a lambda from a lambda this will fail. A simple non-spark reproduction:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-scala&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Command1() &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Serializable {
  &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; direct: Int =&amp;gt; Int = (i: Int) =&amp;gt; i + 1
}

&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Command2(prev: Command1) &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Serializable {
  &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; indirect: Int =&amp;gt; Int = (i: Int) =&amp;gt; prev.direct(i)
}

...
&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; command2 = Command2(Command1())
SparkSerDeUtils.deserialize[Int =&amp;gt; Int](SparkSerDeUtils.serialize(command2.indirect))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I am trying to find out if this is a Scala or a Java bug. If you decode this using &lt;a href=&quot;https://github.com/NickstaDB/SerializationDumper&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/NickstaDB/SerializationDumper&lt;/a&gt; the dump looks reasonable.&lt;/p&gt;</comment>
                            <comment id="17748963" author="jaysen" created="Sun, 30 Jul 2023 19:17:35 +0000"  >&lt;p&gt;In Java, This looks like by design.&lt;/p&gt;

&lt;p&gt;I was able to make it serializable and resolve the problem.&lt;/p&gt;

&lt;p&gt;For ex: If you are using `UnaryOperator` you can tell to be serializable via following syntax.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
UnaryOperator&amp;lt;Row&amp;gt; rowTransform = (UnaryOperator&amp;lt;Row&amp;gt; &amp;amp; Serializable) row -&amp;gt; { 
    ....
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I found this at: &lt;a href=&quot;https://stackoverflow.com/questions/22807912/how-to-serialize-a-lambda&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://stackoverflow.com/questions/22807912/how-to-serialize-a-lambda&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There is also good explanation on serialization logic here: &lt;a href=&quot;https://stackoverflow.com/questions/28186607/java-lang-classcastexception-using-lambda-expressions-in-spark-job-on-remote-ser&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://stackoverflow.com/questions/28186607/java-lang-classcastexception-using-lambda-expressions-in-spark-job-on-remote-ser&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hope this helps.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17748964" author="hvanhovell" created="Sun, 30 Jul 2023 19:21:22 +0000"  >&lt;p&gt;I have also tried the following code (inspired by the what was reported in this ticket), and that failed in a similar fashion:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;MultipleLambdas() &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Serializable {
  val direct: Int =&amp;gt; Int = (i: Int) =&amp;gt; i + 1
  val indirect: Int =&amp;gt; Int = (i: Int) =&amp;gt; direct(i)
}
...
val ml = MultipleLambdas()
SparkSerDeUtils.deserialize[Int =&amp;gt; Int](SparkSerDeUtils.serialize(ml.indirect))

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17748966" author="hvanhovell" created="Sun, 30 Jul 2023 19:35:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jaysen&quot; class=&quot;user-hover&quot; rel=&quot;jaysen&quot;&gt;jaysen&lt;/a&gt; Thanks for the reaction.&lt;/p&gt;

&lt;p&gt;The scala functions &lt;b&gt;are&lt;/b&gt; serializable, otherwise UDFs in general wouldn&apos;t work. The second SO article you linked definitely helped me to understand why we got weird exceptions when we were deserializing UDFs without having all the required CP entries. I ran a debugger on the serverside, and this does not seem to be the case here (you should have CNFE exceptions in the HandleTable), the &apos;indirect&apos; lambda does not seem to be properly initialized. It is probably an ordering issue.&lt;/p&gt;</comment>
                            <comment id="17749003" author="hvanhovell" created="Mon, 31 Jul 2023 02:31:55 +0000"  >&lt;p&gt;This all seems to boil down to the fact that you cannot deserialize an object graph if this contains a self reference and that self-reference is a proxy. In this case readResolve is never called (because its inputs are not fully deserialized), and you get a ClassCastException because you are trying to assign a proxy to the real object. In this particular case SerializedLambda is a serialization proxy. See &lt;a href=&quot;https://docs.oracle.com/en/java/javase/17/docs/specs/serialization/input.html#the-readresolve-method&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;this&lt;/a&gt; for more information.&lt;/p&gt;

&lt;p&gt;All of the examples mentioned here contain such a self reference, in the form of lamdba -&amp;gt; parent -&amp;gt; lambda. An even simpler example would be the following:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-scala&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;SelfRef(start: Int) &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Serializable {
  &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; method: Int =&amp;gt; Int = (i: Int) =&amp;gt; i + start
}
...
SparkSerDeUtils.deserialize[Int =&amp;gt; Int](SparkSerDeUtils.serialize(SelfRef(43).method)) &lt;span class=&quot;code-comment&quot;&gt;// KABOOM&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As far as mitigations go there is not much we can do besides improving error handling (hard because the observed exception also masks dependency problems), and writing down which patterns to avoid.&lt;/p&gt;</comment>
                            <comment id="17749991" author="hvanhovell" created="Tue, 1 Aug 2023 18:55:18 +0000"  >&lt;p&gt;I have added a check for this to Spark Connect. If someone is brave enough they can do the same thing for other UDFs.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 15 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z07oio:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>