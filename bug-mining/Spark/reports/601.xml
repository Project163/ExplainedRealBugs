<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:16:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-1065] PySpark runs out of memory with large broadcast variables</title>
                <link>https://issues.apache.org/jira/browse/SPARK-1065</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;PySpark&apos;s driver components may run out of memory when broadcasting large variables (say 1 gigabyte).&lt;/p&gt;

&lt;p&gt;Because PySpark&apos;s broadcast is implemented on top of Java Spark&apos;s broadcast by broadcasting a pickled Python as a byte array, we may be retaining multiple copies of the large object: a pickled copy in the JVM and a deserialized copy in the Python driver.&lt;/p&gt;

&lt;p&gt;The problem could also be due to memory requirements during pickling.&lt;/p&gt;

&lt;p&gt;PySpark is also affected by broadcast variables not being garbage collected.  Adding an unpersist() method to broadcast variables may fix this: &lt;a href=&quot;https://github.com/apache/incubator-spark/pull/543&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/incubator-spark/pull/543&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a first step to fixing this, we should write a failing test to reproduce the error.&lt;/p&gt;

&lt;p&gt;This was discovered by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sandy&quot; class=&quot;user-hover&quot; rel=&quot;sandy&quot;&gt;sandy&lt;/a&gt;: &lt;a href=&quot;http://apache-spark-user-list.1001560.n3.nabble.com/trouble-with-broadcast-variables-on-pyspark-tp1301.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&quot;trouble with broadcast variables on pyspark&quot;&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12704673">SPARK-1065</key>
            <summary>PySpark runs out of memory with large broadcast variables</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="joshrosen">Josh Rosen</reporter>
                        <labels>
                    </labels>
                <created>Fri, 7 Feb 2014 11:41:54 +0000</created>
                <updated>Sun, 17 Aug 2014 00:00:30 +0000</updated>
                            <resolved>Sun, 17 Aug 2014 00:00:30 +0000</resolved>
                                    <version>0.7.3</version>
                    <version>0.8.1</version>
                    <version>0.9.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="13953640" author="sandy" created="Fri, 7 Feb 2014 18:01:27 +0000"  >&lt;p&gt;Here&apos;s some code that reproduces it.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;theconf = SparkConf().set(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.executor.memory&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;5g&quot;&lt;/span&gt;).setAppName(&lt;span class=&quot;code-quote&quot;&gt;&quot;broadcastfail&quot;&lt;/span&gt;).setMaster(cluster_url)
sc = SparkContext(conf=theconf)

broadcast_vals = []
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(5):
  datas = [[&lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;(i) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(200)] &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(100000)]
  val = sc.broadcast(datas).value
  broadcast_vals.append(val)

sc.parallelize([i &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(80)]).map(lambda x: sum([len(val) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; val in broadcast_vals])).collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It generates a few arrays of floats, each of which should take about 160 MB.  The executors never end up using much memory, but the driver uses an enormous amount.  Both the python and java processes ramp up to multiple GB until I start seeing a bunch of &quot;OutOfMemoryError: java heap space&quot;.&lt;/p&gt;

&lt;p&gt;With a single 160MB array, the job completes fine, but the driver still uses about 9 GB.&lt;/p&gt;</comment>
                            <comment id="14093413" author="frol" created="Mon, 11 Aug 2014 22:06:09 +0000"  >&lt;p&gt;I am facing the same issue in my project, where I use PySpark. As a proof of that the big objects I have could easily fit into nodes&apos; memory, I am going to use dummy solution of saving my big objects into HDFS and load them on Python nodes.&lt;/p&gt;

&lt;p&gt;Does anybody have an idea how to fix the issue in a better way? I don&apos;t have enough either Scala nor Java knowledge to fix this in Spark core. However, I feel like broadcast variables could be reimplemented on Python side though it seems a bit dangerous idea because we don&apos;t want to have separate implementations of one thing in both languages. That will also save memory, because while we use broadcasts through Scala we have 1 copy in JVM, 1 pickled copy in Python and 1 constructed object copy in Python.&lt;/p&gt;</comment>
                            <comment id="14094333" author="frol" created="Tue, 12 Aug 2014 17:18:09 +0000"  >&lt;p&gt;I have finished my experiment of using HDFS as a temp storage for my big objects. It showed that my mappers do not leak memory and work pretty stable. However, it takes long time to load these objects on each node.&lt;/p&gt;

&lt;p&gt;Is there straightforward way to detect memory leaks in Spark and PySpark?&lt;/p&gt;</comment>
                            <comment id="14094947" author="davies" created="Wed, 13 Aug 2014 00:30:24 +0000"  >&lt;p&gt;The broadcast was not used correctly in the above code, it should be used like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;broadcast_vals = []
&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(5):
  datas = [[&lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;(i) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(200)] &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(100000)]
  val = sc.broadcast(datas)
  broadcast_vals.append(val)

sc.parallelize([i &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(80)]).map(lambda x: sum([len(val.value) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; val in broadcast_vals])).collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The reference of object in Python driver in not necessary in most cases, we will make it optional (no reference by default), then it can reduce the memory used in Python driver.&lt;/p&gt;</comment>
                            <comment id="14094952" author="apachespark" created="Wed, 13 Aug 2014 00:33:10 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/1912&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/1912&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14094965" author="frol" created="Wed, 13 Aug 2014 00:45:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt; Will your PR take into account this fix: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2521&quot; title=&quot;Broadcast RDD object once per TaskSet (instead of sending it for every task)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2521&quot;&gt;&lt;del&gt;SPARK-2521&lt;/del&gt;&lt;/a&gt; Broadcast RDD object (instead of sending it along with every task) &lt;a href=&quot;https://github.com/apache/spark/commit/7b8cd175254d42c8e82f0aa8eb4b7f3508d8fde2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/7b8cd175254d42c8e82f0aa8eb4b7f3508d8fde2&lt;/a&gt; ?&lt;br/&gt;
&quot;The patch uses broadcast to send RDD objects and the closures to executors&quot;&lt;/p&gt;</comment>
                            <comment id="14094976" author="frol" created="Wed, 13 Aug 2014 00:54:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt; I have not noticed that there was that mistake in the example, but I have not used that code. I run into the issue in my own code, where I use broadcasts correctly.&lt;/p&gt;

&lt;p&gt;I&apos;m building your branch now and will try it right away. Thank you for your fix!&lt;/p&gt;</comment>
                            <comment id="14094981" author="davies" created="Wed, 13 Aug 2014 00:57:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=frol&quot; class=&quot;user-hover&quot; rel=&quot;frol&quot;&gt;frol&lt;/a&gt;, I think broadcast the RDD object is already done by that PR.&lt;/p&gt;

&lt;p&gt;But the serialized closure will still be sent to JVM by py4j. After using broadcast for large datasets, the serialized closure should not be too huge, so I guess it will not be a big issue.&lt;/p&gt;</comment>
                            <comment id="14094986" author="davies" created="Wed, 13 Aug 2014 01:02:25 +0000"  >&lt;p&gt;After this patch, the above test can run successfully with about 700M memory in Python driver, 5xxMB memory in JVM driver, and 3G memory in python worker.&lt;/p&gt;

&lt;p&gt;It may triggle another problem when run it with Mesos or YARN, because Spark does not reserve memory for Python worker, this may be fixed in 1.2 release.&lt;/p&gt;</comment>
                            <comment id="14094987" author="frol" created="Wed, 13 Aug 2014 01:04:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt; I understand that if you use broadcast explicitly the closure won&apos;t be huge, but the point of that PR was also &quot;1. Users won&apos;t need to decide what to broadcast anymore, unless they would want to use a large object multiple times in different operations&quot;.&lt;/p&gt;</comment>
                            <comment id="14094989" author="frol" created="Wed, 13 Aug 2014 01:05:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt; I use YARN setup so I will see how it goes.&lt;/p&gt;</comment>
                            <comment id="14095021" author="frol" created="Wed, 13 Aug 2014 01:43:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt; I have compiled and run your broadcast branch against my cluster on YARN. It does not leak memory any more! And it is at least 25% faster than my dummy implementation on top of HDFS. Implementation with broadcasts takes 4.5 minutes to finish a task, where my implementation took 6 minutes. More heavy tests are still working.&lt;/p&gt;</comment>
                            <comment id="14095063" author="frol" created="Wed, 13 Aug 2014 02:37:13 +0000"  >&lt;p&gt;Heavy tasks completed in 18 minutes each instead of 22 minutes, which is 20% speed up. That is nice!&lt;br/&gt;
I don&apos;t see any problems on my YARN cluster. Java nodes eat up to 1.5GB RAM (which is my JVM limit) each and Python daemons eat around 650MB each. Though those numbers are still a bit weird, it is obvious to me that workers don&apos;t leak now.&lt;/p&gt;

&lt;p&gt;Thank you a lot!&lt;/p&gt;</comment>
                            <comment id="14095150" author="davies" created="Wed, 13 Aug 2014 04:57:18 +0000"  >&lt;p&gt;Cool, thanks for the tests. If we can compress the data, it will be faster. I will do it in another separate PR.&lt;/p&gt;

&lt;p&gt;The closure is serialized by cloudpickle, so it will be much slower if you do not use broadcast explicitly. We can show an warning if the serialized closure is too big.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>383168</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1u0gv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>383436</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>