<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:25:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-5821] JSONRelation and ParquetRelation2 should check if delete is successful for the overwrite operation.</title>
                <link>https://issues.apache.org/jira/browse/SPARK-5821</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When you run CTAS command such as&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;TEMPORARY&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;TABLE&lt;/span&gt; jsonTable
&lt;span class=&quot;code-keyword&quot;&gt;USING&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.json.DefaultSource
&lt;span class=&quot;code-keyword&quot;&gt;OPTIONS&lt;/span&gt; (
&lt;span class=&quot;code-keyword&quot;&gt;path&lt;/span&gt; /&lt;span class=&quot;code-keyword&quot;&gt;a&lt;/span&gt;/b/&lt;span class=&quot;code-keyword&quot;&gt;c&lt;/span&gt;/d
) &lt;span class=&quot;code-keyword&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;a&lt;/span&gt;, b &lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt; jt
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;you will run into failure if you don&apos;t have write permission for directory /a/b/c whether d is a directory or file.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;main&quot; org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/a/b/c/d already exists
        at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:132)
        at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1053)
        at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:954)
        at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:863)
        at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1284)
        at org.apache.spark.sql.json.DefaultSource.createRelation(JSONRelation.scala:81)
        at org.apache.spark.sql.sources.ResolvedDataSource$.apply(ddl.scala:300)
        at org.apache.spark.sql.sources.CreateTempTableUsingAsSelect.run(ddl.scala:388)
        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:55)
        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:55)
        at org.apache.spark.sql.execution.ExecutedCommand.execute(commands.scala:65)
        at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:927)
        at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:927)
        at org.apache.spark.sql.DataFrameImpl.&amp;lt;init&amp;gt;(DataFrameImpl.scala:71)
        at org.apache.spark.sql.DataFrameImpl.&amp;lt;init&amp;gt;(DataFrameImpl.scala:58)
        at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:35)
        at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:778)
        at org.apache.spark.sql.Test$.main(Test.scala:149)
        at org.apache.spark.sql.Test.main(Test.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:483)
        at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12775152">SPARK-5821</key>
            <summary>JSONRelation and ParquetRelation2 should check if delete is successful for the overwrite operation.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yanboliang">Yanbo Liang</assignee>
                                    <reporter username="yanboliang">Yanbo Liang</reporter>
                        <labels>
                    </labels>
                <created>Sat, 14 Feb 2015 17:29:43 +0000</created>
                <updated>Sat, 21 Mar 2015 03:22:03 +0000</updated>
                            <resolved>Sat, 21 Mar 2015 03:17:09 +0000</resolved>
                                    <version>1.3.0</version>
                                    <fixVersion>1.3.1</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14321578" author="yanboliang" created="Sat, 14 Feb 2015 17:31:46 +0000"  >&lt;p&gt;The following is one kind of exception log:&lt;br/&gt;
Exception in thread &quot;main&quot; org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory &lt;a href=&quot;file:/a/b/c/d&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/a/b/c/d&lt;/a&gt; already exists&lt;br/&gt;
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:132)&lt;br/&gt;
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1053)&lt;br/&gt;
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:954)&lt;br/&gt;
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:863)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1284)&lt;br/&gt;
	at org.apache.spark.sql.json.DefaultSource.createRelation(JSONRelation.scala:81)&lt;br/&gt;
	at org.apache.spark.sql.sources.ResolvedDataSource$.apply(ddl.scala:300)&lt;br/&gt;
	at org.apache.spark.sql.sources.CreateTempTableUsingAsSelect.run(ddl.scala:388)&lt;br/&gt;
	at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:55)&lt;br/&gt;
	at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:55)&lt;br/&gt;
	at org.apache.spark.sql.execution.ExecutedCommand.execute(commands.scala:65)&lt;br/&gt;
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:927)&lt;br/&gt;
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:927)&lt;br/&gt;
	at org.apache.spark.sql.DataFrameImpl.&amp;lt;init&amp;gt;(DataFrameImpl.scala:71)&lt;br/&gt;
	at org.apache.spark.sql.DataFrameImpl.&amp;lt;init&amp;gt;(DataFrameImpl.scala:58)&lt;br/&gt;
	at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:35)&lt;br/&gt;
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:778)&lt;br/&gt;
	at org.apache.spark.sql.Test$.main(Test.scala:149)&lt;br/&gt;
	at org.apache.spark.sql.Test.main(Test.scala)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:483)&lt;br/&gt;
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)&lt;/p&gt;</comment>
                            <comment id="14321584" author="yanboliang" created="Sat, 14 Feb 2015 17:35:37 +0000"  >&lt;p&gt;This is because that INSERT OVERWRITE in external data sources will first delete the file /a/b/c/d and then save the generated RDD to /a/b/c/d/. However if we don&apos;t have write permission for directory /a/b/c, the delete will failure and /a/b/c/d still exists. After that, when call RDD.saveAsTextFile will throw exception.&lt;/p&gt;</comment>
                            <comment id="14321603" author="apachespark" created="Sat, 14 Feb 2015 18:02:23 +0000"  >&lt;p&gt;User &apos;yanbohappy&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4607&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4607&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14321824" author="apachespark" created="Sun, 15 Feb 2015 05:57:53 +0000"  >&lt;p&gt;User &apos;yanbohappy&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4610&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4610&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14321828" author="yhuai" created="Sun, 15 Feb 2015 06:12:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lian+cheng&quot; class=&quot;user-hover&quot; rel=&quot;lian cheng&quot;&gt;lian cheng&lt;/a&gt; Can you check if we need to address the same issue in parquet relation?&lt;/p&gt;</comment>
                            <comment id="14369305" author="lian cheng" created="Thu, 19 Mar 2015 13:21:26 +0000"  >&lt;p&gt;Left comments on GitHub.&lt;/p&gt;</comment>
                            <comment id="14371445" author="apachespark" created="Fri, 20 Mar 2015 15:18:57 +0000"  >&lt;p&gt;User &apos;yanboliang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5107&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5107&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14372476" author="lian cheng" created="Sat, 21 Mar 2015 03:17:09 +0000"  >&lt;p&gt;Issue resolved by pull request 5107&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5107&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5107&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12774324">SPARK-5746</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 35 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i25n67:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329486">1.3.1</customfieldvalue>
    <customfieldvalue id="12329359">1.4.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>