<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:32:47 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-42851] EquivalentExpressions methods need to be consistently guarded by supportedExpression</title>
                <link>https://issues.apache.org/jira/browse/SPARK-42851</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-41468&quot; title=&quot;Fix PlanExpression handling in EquivalentExpressions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-41468&quot;&gt;&lt;del&gt;SPARK-41468&lt;/del&gt;&lt;/a&gt; tried to fix a bug but introduced a new regression. Its change to &lt;tt&gt;EquivalentExpressions&lt;/tt&gt; added a &lt;tt&gt;supportedExpression()&lt;/tt&gt; guard to the &lt;tt&gt;addExprTree()&lt;/tt&gt; and &lt;tt&gt;getExprState()&lt;/tt&gt; methods, but didn&apos;t add the same guard to the other &quot;add&quot; entry point &amp;#8211; &lt;tt&gt;addExpr()&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;As such, uses that add single expressions to CSE via &lt;tt&gt;addExpr()&lt;/tt&gt; may succeed, but upon retrieval via &lt;tt&gt;getExprState()&lt;/tt&gt; it&apos;d inconsistently get a &lt;tt&gt;None&lt;/tt&gt; due to failing the guard.&lt;/p&gt;

&lt;p&gt;We need to make sure the &quot;add&quot; and &quot;get&quot; methods are consistent. It could be done by one of:&lt;br/&gt;
1. Adding the same &lt;tt&gt;supportedExpression()&lt;/tt&gt; guard to &lt;tt&gt;addExpr()&lt;/tt&gt;, or&lt;br/&gt;
2. Removing the guard from &lt;tt&gt;getExprState()&lt;/tt&gt;, relying solely on the guard on the &quot;add&quot; path to make sure only intended state is added.&lt;br/&gt;
(or other alternative refactorings to fuse the guard into various methods to make it more efficient)&lt;/p&gt;

&lt;p&gt;There are pros and cons to the two directions above, because &lt;tt&gt;addExpr()&lt;/tt&gt; used to allow (potentially incorrect) more expressions to get CSE&apos;d, making it more restrictive may cause performance regressions (for the cases that happened to work).&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;max&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;transform&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;array&lt;/span&gt;(id), x -&amp;gt; x)), &lt;span class=&quot;code-keyword&quot;&gt;max&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;transform&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;array&lt;/span&gt;(id), x -&amp;gt; x)) &lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;range&lt;/span&gt;(2)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Running this query on Spark 3.2 branch returns the correct value:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; spark.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select max(transform(array(id), x -&amp;gt; x)), max(transform(array(id), x -&amp;gt; x)) from range(2)&quot;&lt;/span&gt;).collect
res0: Array[org.apache.spark.sql.Row] = Array([WrappedArray(1),WrappedArray(1)])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here, &lt;tt&gt;transform(array(id), x -&amp;gt; x)&lt;/tt&gt; is an &lt;tt&gt;AggregateExpression&lt;/tt&gt; that was (potentially unsafely) recognized by &lt;tt&gt;addExpr()&lt;/tt&gt; as a common subexpression, and &lt;tt&gt;getExprState()&lt;/tt&gt; doesn&apos;t do extra guarding, so during physical planning, in &lt;tt&gt;PhysicalAggregation&lt;/tt&gt; this expression gets CSE&apos;d in both the aggregation expression list and the result expressions list.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
AdaptiveSparkPlan isFinalPlan=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
+- SortAggregate(key=[], functions=[max(transform(array(id#0L), lambdafunction(lambda x#1L, lambda x#1L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)))])
   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=11]
      +- SortAggregate(key=[], functions=[partial_max(transform(array(id#0L), lambdafunction(lambda x#1L, lambda x#1L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)))])
         +- Range (0, 2, step=1, splits=16)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Running the same query on current master triggers an error when binding the result expression to the aggregate expression in the Aggregate operators (for a WSCG-enabled operator like &lt;tt&gt;HashAggregateExec&lt;/tt&gt;, the same error would show up during codegen):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 16) (ip-10-110-16-93.us-west-2.compute.internal executor driver): java.lang.IllegalStateException: Couldn&apos;t find max(transform(array(id#0L), lambdafunction(lambda x#2L, lambda x#2L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)))#4 in [max(transform(array(id#0L), lambdafunction(lambda x#1L, lambda x#1L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)))#3]
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:80)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:73)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:517)
	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1249)
	at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1248)
	at org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:532)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:517)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:456)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:73)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$.$anonfun$bindReferences$1(BoundAttribute.scala:94)
	at scala.collection.immutable.List.map(List.scala:297)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReferences(BoundAttribute.scala:94)
	at org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:161)
	at org.apache.spark.sql.execution.aggregate.AggregationIterator.generateResultProjection(AggregationIterator.scala:246)
	at org.apache.spark.sql.execution.aggregate.AggregationIterator.&amp;lt;init&amp;gt;(AggregationIterator.scala:296)
	at org.apache.spark.sql.execution.aggregate.SortBasedAggregationIterator.&amp;lt;init&amp;gt;(SortBasedAggregationIterator.scala:49)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1(SortAggregateExec.scala:79)
	at org.apache.spark.sql.execution.aggregate.SortAggregateExec.$anonfun$doExecute$1$adapted(SortAggregateExec.scala:59)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Note that the aggregate expressions are deduplicated in &lt;tt&gt;PhysicalAggregation&lt;/tt&gt;, but the result expressions were unable to deduplicate consistently due to the bug mentioned in this ticket.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
AdaptiveSparkPlan isFinalPlan=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
+- SortAggregate(key=[], functions=[max(transform(array(id#15L), lambdafunction(lambda x#16L, lambda x#16L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)))])
   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=38]
      +- SortAggregate(key=[], functions=[partial_max(transform(array(id#15L), lambdafunction(lambda x#16L, lambda x#16L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)))])
         +- Range (0, 2, step=1, splits=16)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Fixing it via method 1 is more correct than method 2 in terms of avoiding incorrect CSE:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unable to find source-code formatter for language: diff.&lt;/span&gt; Available languages are: actionscript, ada, applescript, bash, c, c#, c++, cpp, css, erlang, go, groovy, haskell, html, java, javascript, js, json, lua, none, nyan, objc, perl, php, python, r, rainbow, ruby, scala, sh, sql, swift, visualbasic, xml, yaml&lt;/div&gt;&lt;pre&gt;
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/EquivalentExpressions.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/EquivalentExpressions.scala
index 330d66a21b..12def60042 100644
--- a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/EquivalentExpressions.scala
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/EquivalentExpressions.scala
@@ -40,7 +40,11 @@ &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;EquivalentExpressions {
    * Returns &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there was already a matching expression.
    */
   def addExpr(expr: Expression): &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = {
-    updateExprInMap(expr, equivalenceMap)
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (supportedExpression(expr)) {
+      updateExprInMap(expr, equivalenceMap)
+    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
+      &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
+    }
   }
 
   /**
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;the query runs correctly again, but this time the aggregate expression is NOT CSE&apos;d anymore, done consistently for both aggregate expressions and result expressions:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
AdaptiveSparkPlan isFinalPlan=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
+- SortAggregate(key=[], functions=[max(transform(array(id#0L), lambdafunction(lambda x#1L, lambda x#1L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;))), max(transform(array(id#0L), lambdafunction(lambda x#2L, lambda x#2L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)))])
   +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=11]
      +- SortAggregate(key=[], functions=[partial_max(transform(array(id#0L), lambdafunction(lambda x#1L, lambda x#1L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;))), partial_max(transform(array(id#0L), lambdafunction(lambda x#2L, lambda x#2L, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)))])
         +- Range (0, 2, step=1, splits=16)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and for this particular case, the CSE that used to take place was actually okay, so losing CSE here means performance regression.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13529035">SPARK-42851</key>
            <summary>EquivalentExpressions methods need to be consistently guarded by supportedExpression</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rednaxelafx">Kris Mok</assignee>
                                    <reporter username="rednaxelafx">Kris Mok</reporter>
                        <labels>
                    </labels>
                <created>Sat, 18 Mar 2023 01:04:12 +0000</created>
                <updated>Tue, 21 Mar 2023 13:28:44 +0000</updated>
                            <resolved>Tue, 21 Mar 2023 13:28:44 +0000</resolved>
                                    <version>3.3.2</version>
                    <version>3.4.0</version>
                                    <fixVersion>3.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17702033" author="apachespark" created="Sat, 18 Mar 2023 01:25:17 +0000"  >&lt;p&gt;User &apos;rednaxelafx&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/40473&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/40473&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17702657" author="apachespark" created="Mon, 20 Mar 2023 12:34:17 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/40488&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/40488&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17702658" author="apachespark" created="Mon, 20 Mar 2023 12:35:01 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/40488&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/40488&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17703202" author="cloud_fan" created="Tue, 21 Mar 2023 13:28:44 +0000"  >&lt;p&gt;Issue resolved by pull request 40473&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/40473&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/40473&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 34 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1go8o:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>