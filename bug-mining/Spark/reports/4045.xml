<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:47:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17100] pyspark filter on a udf column after join gives java.lang.UnsupportedOperationException</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17100</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;In pyspark, when filtering on a udf derived column after some join types,&lt;br/&gt;
the optimized logical plan results is a java.lang.UnsupportedOperationException.&lt;/p&gt;

&lt;p&gt;I could not replicate this in scala code from the shell, just python. It is a pyspark regression from spark 1.6.2.&lt;/p&gt;

&lt;p&gt;This can be replicated with: bin/spark-submit bug.py&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pyspark.sql.functions as F
from pyspark.sql &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; Row, SparkSession

&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; __name__ == &lt;span class=&quot;code-quote&quot;&gt;&apos;__main__&apos;&lt;/span&gt;:
    spark = SparkSession.builder.appName(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;).getOrCreate()
    left = spark.createDataFrame([Row(a=1)])
    right = spark.createDataFrame([Row(a=1)])
    df = left.join(right, on=&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;, how=&lt;span class=&quot;code-quote&quot;&gt;&apos;left_outer&apos;&lt;/span&gt;)
    df = df.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&apos;b&apos;&lt;/span&gt;, F.udf(lambda x: &lt;span class=&quot;code-quote&quot;&gt;&apos;x&apos;&lt;/span&gt;)(df.a))
    df = df.filter(&lt;span class=&quot;code-quote&quot;&gt;&apos;b = &lt;span class=&quot;code-quote&quot;&gt;&quot;x&quot;&lt;/span&gt;&apos;&lt;/span&gt;)
    df.explain(extended=True)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The output is:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;== Parsed Logical Plan ==
&lt;span class=&quot;code-quote&quot;&gt;&apos;Filter (&apos;&lt;/span&gt;b = x)
+- Project [a#0L, &amp;lt;lambda&amp;gt;(a#0L) AS b#8]
   +- Project [a#0L]
      +- Join LeftOuter, (a#0L = a#3L)
         :- LogicalRDD [a#0L]
         +- LogicalRDD [a#3L]

== Analyzed Logical Plan ==
a: bigint, b: string
Filter (b#8 = x)
+- Project [a#0L, &amp;lt;lambda&amp;gt;(a#0L) AS b#8]
   +- Project [a#0L]
      +- Join LeftOuter, (a#0L = a#3L)
         :- LogicalRDD [a#0L]
         +- LogicalRDD [a#3L]

== Optimized Logical Plan ==
java.lang.UnsupportedOperationException: Cannot evaluate expression: &amp;lt;lambda&amp;gt;(input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;])
== Physical Plan ==
java.lang.UnsupportedOperationException: Cannot evaluate expression: &amp;lt;lambda&amp;gt;(input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;It fails when the join is:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;how=&apos;outer&apos;, on=column expression&lt;/li&gt;
	&lt;li&gt;how=&apos;left_outer&apos;, on=string or column expression&lt;/li&gt;
	&lt;li&gt;how=&apos;right_outer&apos;, on=string or column expression&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It passes when the join is:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;how=&apos;inner&apos;, on=string or column expression&lt;/li&gt;
	&lt;li&gt;how=&apos;outer&apos;, on=string&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I made some tests to demonstrate each of these.&lt;/p&gt;

&lt;p&gt;Run with bin/spark-submit test_bug.py&lt;/p&gt;</description>
                <environment>&lt;p&gt;spark-2.0.0-bin-hadoop2.7. Python2 and Python3.&lt;/p&gt;</environment>
        <key id="12997803">SPARK-17100</key>
            <summary>pyspark filter on a udf column after join gives java.lang.UnsupportedOperationException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="tim_s">Tim Sell</reporter>
                        <labels>
                    </labels>
                <created>Wed, 17 Aug 2016 03:51:41 +0000</created>
                <updated>Fri, 25 Nov 2016 21:27:55 +0000</updated>
                            <resolved>Mon, 19 Sep 2016 20:24:08 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15423917" author="tim_s" created="Wed, 17 Aug 2016 05:28:38 +0000"  >&lt;p&gt;I don&apos;t know why, but using `dataframe.cache()` before the filter is a workaround. &lt;/p&gt;</comment>
                            <comment id="15491518" author="apachespark" created="Wed, 14 Sep 2016 21:39:07 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15103&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15103&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15504588" author="davies" created="Mon, 19 Sep 2016 20:24:09 +0000"  >&lt;p&gt;Issue resolved by pull request 15103&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15103&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15103&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13023447">SPARK-18589</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12824066" name="bug.py" size="426" author="tim_s" created="Wed, 17 Aug 2016 03:52:30 +0000"/>
                            <attachment id="12824067" name="test_bug.py" size="3390" author="tim_s" created="Wed, 17 Aug 2016 03:52:45 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 9 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32en3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>