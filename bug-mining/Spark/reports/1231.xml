<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:22:02 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4943] Parsing error for query with table name having dot</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4943</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When integrating Spark 1.2.0 with Cassandra SQL, the following query is broken. It was working for Spark 1.1.0 version. Basically we use the table name having dot to include database name &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[info]   java.lang.RuntimeException: [1.29] failure: ``UNION&lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; expected but `.&apos;&lt;/span&gt; found
[info] 

[info] SELECT test1.a FROM sql_test.test1 AS test1 UNION DISTINCT SELECT test2.a FROM sql_test.test2 AS test2
[info]                             ^
[info]   at scala.sys.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.error(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:27)
[info]   at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.apply(SparkSQLParser.scala:33)
[info]   at org.apache.spark.sql.SQLContext$$anonfun$1.apply(SQLContext.scala:79)
[info]   at org.apache.spark.sql.SQLContext$$anonfun$1.apply(SQLContext.scala:79)
[info]   at org.apache.spark.sql.catalyst.SparkSQLParser$$anonfun$org$apache$spark$sql$catalyst$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:174)
[info]   at org.apache.spark.sql.catalyst.SparkSQLParser$$anonfun$org$apache$spark$sql$catalyst$SparkSQLParser$$others$1.apply(SparkSQLParser.scala:173)
[info]   at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136)
[info]   at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:135)
[info]   at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
[info]   at scala.util.parsing.combinator.Parsers$Parser$$anonfun$map$1.apply(Parsers.scala:242)
[info]   at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
[info]   at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
[info]   at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1$$anonfun$apply$2.apply(Parsers.scala:254)
[info]   at scala.util.parsing.combinator.Parsers$Failure.append(Parsers.scala:202)
[info]   at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
[info]   at scala.util.parsing.combinator.Parsers$Parser$$anonfun$append$1.apply(Parsers.scala:254)
[info]   at scala.util.parsing.combinator.Parsers$$anon$3.apply(Parsers.scala:222)
[info]   at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
[info]   at scala.util.parsing.combinator.Parsers$$anon$2$$anonfun$apply$14.apply(Parsers.scala:891)
[info]   at scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)
[info]   at scala.util.parsing.combinator.Parsers$$anon$2.apply(Parsers.scala:890)
[info]   at scala.util.parsing.combinator.PackratParsers$$anon$1.apply(PackratParsers.scala:110)
[info]   at org.apache.spark.sql.catalyst.AbstractSparkSQLParser.apply(SparkSQLParser.scala:31)
[info]   at org.apache.spark.sql.SQLContext$$anonfun$parseSql$1.apply(SQLContext.scala:83)
[info]   at org.apache.spark.sql.SQLContext$$anonfun$parseSql$1.apply(SQLContext.scala:83)
[info]   at scala.Option.getOrElse(Option.scala:120)
[info]   at org.apache.spark.sql.SQLContext.parseSql(SQLContext.scala:83)
[info]   at org.apache.spark.sql.cassandra.CassandraSQLContext.cassandraSql(CassandraSQLContext.scala:53)
[info]   at org.apache.spark.sql.cassandra.CassandraSQLContext.sql(CassandraSQLContext.scala:56)
[info]   at com.datastax.spark.connector.sql.CassandraSQLSpec$$anonfun$20.apply$mcV$sp(CassandraSQLSpec.scala:169)
[info]   at com.datastax.spark.connector.sql.CassandraSQLSpec$$anonfun$20.apply(CassandraSQLSpec.scala:168)
[info]   at com.datastax.spark.connector.sql.CassandraSQLSpec$$anonfun$20.apply(CassandraSQLSpec.scala:168)
[info]   at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
[info]   at org.scalatest.OutcomeOf$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;outcomeOf(OutcomeOf.scala:85)
[info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
[info]   at org.scalatest.Transformer.apply(Transformer.scala:22)
[info]   at org.scalatest.Transformer.apply(Transformer.scala:20)
[info]   at org.scalatest.FlatSpecLike$$anon$1.apply(FlatSpecLike.scala:1647)
[info]   at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;withFixture(Suite.scala:1122)
[info]   at org.scalatest.FlatSpec.withFixture(FlatSpec.scala:1683)
[info]   at org.scalatest.FlatSpecLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;invokeWithFixture$1(FlatSpecLike.scala:1644)
[info]   at org.scalatest.FlatSpecLike$$anonfun$runTest$1.apply(FlatSpecLike.scala:1656)
[info]   at org.scalatest.FlatSpecLike$$anonfun$runTest$1.apply(FlatSpecLike.scala:1656)
[info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
[info]   at org.scalatest.FlatSpecLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runTest(FlatSpecLike.scala:1656)
[info]   at org.scalatest.FlatSpec.runTest(FlatSpec.scala:1683)
[info]   at org.scalatest.FlatSpecLike$$anonfun$runTests$1.apply(FlatSpecLike.scala:1714)
[info]   at org.scalatest.FlatSpecLike$$anonfun$runTests$1.apply(FlatSpecLike.scala:1714)
[info]   at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
[info]   at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
[info]   at scala.collection.immutable.List.foreach(List.scala:318)
[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
[info]   at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
[info]   at org.scalatest.FlatSpecLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runTests(FlatSpecLike.scala:1714)
[info]   at org.scalatest.FlatSpec.runTests(FlatSpec.scala:1683)
[info]   at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(Suite.scala:1424)
[info]   at org.scalatest.FlatSpec.org$scalatest$FlatSpecLike$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(FlatSpec.scala:1683)
[info]   at org.scalatest.FlatSpecLike$$anonfun$run$1.apply(FlatSpecLike.scala:1760)
[info]   at org.scalatest.FlatSpecLike$$anonfun$run$1.apply(FlatSpecLike.scala:1760)
[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
[info]   at org.scalatest.FlatSpecLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(FlatSpecLike.scala:1760)
[info]   at org.scalatest.FlatSpec.run(FlatSpec.scala:1683)
[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:466)
[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:677)
[info]   at sbt.ForkMain$Run$2.call(ForkMain.java:294)
[info]   at sbt.ForkMain$Run$2.call(ForkMain.java:284)
[info]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)
[info]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
[info]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
[info]   at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
[info] - should allow to select rows with union distinct clause *** FAILED *** (46 milliseconds)
[info]   java.lang.RuntimeException: [1.29] failure: ``UNION&lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; expected but `.&apos;&lt;/span&gt; found
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12763602">SPARK-4943</key>
            <summary>Parsing error for query with table name having dot</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="alexliu68">Alex Liu</reporter>
                        <labels>
                    </labels>
                <created>Wed, 24 Dec 2014 01:19:51 +0000</created>
                <updated>Thu, 15 Jan 2015 14:17:46 +0000</updated>
                            <resolved>Sat, 10 Jan 2015 21:42:56 +0000</resolved>
                                    <version>1.2.0</version>
                                    <fixVersion>1.2.1</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>8</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14261396" author="apachespark" created="Tue, 30 Dec 2014 19:38:45 +0000"  >&lt;p&gt;User &apos;alexliu68&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3848&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3848&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14262412" author="marmbrus" created="Wed, 31 Dec 2014 20:25:36 +0000"  >&lt;p&gt;One possible approach here is to change the signature of UnresolvedRelation as follows:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;UnresolvedRelation(tableIdentifier: Seq[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], alias: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This way we can leave parsing and handling of backticks up to the parser and let the catalogs interpret the identifiers in a system dependent way.&lt;/p&gt;</comment>
                            <comment id="14262442" author="alexliu68" created="Wed, 31 Dec 2014 21:26:54 +0000"  >&lt;p&gt;The seq can be like &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;tableName, databaseName, clusterName, catalog
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;First element is tableName, the next one is databaseName, then clusterName and catalog(option).&lt;/p&gt;


&lt;p&gt;SQL query looks like&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SELECT test_table.column1 FROM catalog.cluster.database.table AS test_table 
SELECT test_table.column1 FROM cluster.database.table AS test_table 
SELECT test_table.column1 FROM database.table AS test_table 
SELECT table.column1 FROM table
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Potentially we should not use AS clause here.&lt;/p&gt;

&lt;p&gt;Parser only allow maximum four levels in full table name. &lt;span class=&quot;error&quot;&gt;&amp;#91;catalog&amp;#93;&lt;/span&gt;.&lt;span class=&quot;error&quot;&gt;&amp;#91;cluster&amp;#93;&lt;/span&gt;.&lt;span class=&quot;error&quot;&gt;&amp;#91;database&amp;#93;&lt;/span&gt;.&lt;span class=&quot;error&quot;&gt;&amp;#91;table&amp;#93;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="14263230" author="alexliu68" created="Fri, 2 Jan 2015 20:55:07 +0000"  >&lt;p&gt;Should we also change the signatures of Catalog methods to use &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;tableIdentifier: Seq[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;] &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; instead of &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;db: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], tableName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  def tableExists(db: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], tableName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;

  def lookupRelation(
    databaseName: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;],
    tableName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;,
    alias: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;] = None): LogicalPlan

  def registerTable(databaseName: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], tableName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, plan: LogicalPlan): Unit

  def unregisterTable(databaseName: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], tableName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): Unit

  def unregisterAllTables(): Unit

  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; def processDatabaseAndTableName(
      databaseName: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;],
      tableName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): (Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14265089" author="alexliu68" created="Mon, 5 Jan 2015 20:59:09 +0000"  >&lt;p&gt;The approach of &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;UnresolvedRelation(tableIdentifier: Seq[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], alias: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; is a little unclear about what&apos;s stored in tableIdentifier by simply reading the code.&lt;/p&gt;

&lt;p&gt;Another approach is storing  catalog.cluster.database in databaseName and tableName in tableName and keep case class no change&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;UnresolvedRelation(databaseName: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], tableName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, alias: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;so no API changes.&lt;/p&gt;

&lt;p&gt;If we keep clusterName as a separate parameter, then API changes to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;UnresolvedRelation(clusterName: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], databaseName: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], tableName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, alias: Option[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Catalog API  needs change accordingly&lt;/p&gt;
</comment>
                            <comment id="14265157" author="marmbrus" created="Mon, 5 Jan 2015 21:44:35 +0000"  >&lt;p&gt;I wouldn&apos;t say that the notion of &lt;tt&gt;tableIdentifier: Seq[String]&lt;/tt&gt; is unclear.  Instead I would say that it is deliberately unspecified in order to be flexible.  Some systems have &lt;tt&gt;clusters&lt;/tt&gt;, some systems have &lt;tt&gt;databases&lt;/tt&gt;, some systems have &lt;tt&gt;schema&lt;/tt&gt;, some have &lt;tt&gt;tables&lt;/tt&gt;.  Thus, this API gives us one interface for communicating between the parser and the underlying datastore that makes no assumption about how that datastore is laid out.&lt;/p&gt;

&lt;p&gt;If we do make this change then yes, I agree that we should also make it in the catalog as well.  In general our handling of this has always been a little clunky since there is a whole bunch of code that just ignores the database field.&lt;/p&gt;

&lt;p&gt;One question is: what parts of the table identifier Spark SQL handles and what parts we pass on to the datasource?  A goal here should be to be able to connect to and join data from multiple sources.  Here is what I would propose as an addition to the current API, which only lets you register individual tables.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Users can register external catalogs which are responsible for producing {{BaseRelation}}s.&lt;/li&gt;
	&lt;li&gt;Each external catalog has a user specified name that is given when registering.&lt;/li&gt;
	&lt;li&gt;There is a notion of the current catalog, which can be changed with &lt;tt&gt;USE&lt;/tt&gt;.  By default, we pass the all the &lt;tt&gt;tableIdentifiers&lt;/tt&gt; to this default catalog and its up to it to determine what each part means.&lt;/li&gt;
	&lt;li&gt;Users can also specify fully qualified tables when joining multiple data sources.  We detect this case when the first &lt;tt&gt;tableIdentifier&lt;/tt&gt; matches one of the registered catalogs.  In this case we strip of the catalog name and pass the remaining &lt;tt&gt;tableIdentifiers&lt;/tt&gt; to the specified catalog.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What do you think?&lt;/p&gt;</comment>
                            <comment id="14265212" author="alexliu68" created="Mon, 5 Jan 2015 22:13:47 +0000"  >&lt;p&gt;Catalog part of table identifier should be handled by Spark SQL which calls the registered catalog Context to connect to the underline datasources. cluster/database/scheme/table should be handled by datasource(Cassandra Spark SQL integration can handle cluster, database and table level join).&lt;/p&gt;

&lt;p&gt;e.g.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SELECT test1.a, test1.b, test2.c FROM cassandra.cluster.database.table1 AS test1
    LEFT OUTER JOIN mySql.cluster.database.table2 AS test2 ON test1.a = test2.a
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so cluster.database.table1 is passed to cassandra catalog datasource, cassandra is handled by Spark SQL to call cassandraContext which then call the underline datasource.&lt;/p&gt;

&lt;p&gt;cluster.database.table2 is passed to mySql catalog datasource, mySql is handled by Spark SQL to call the mySqlContext which then call the underline datasource.&lt;/p&gt;


&lt;p&gt;If USE command is used, then all tableIdentifiers are passed to datasource.  e.g.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;USE cassandra
SELECT test1.a, test1.b, test2.c FROM cluster1.database.table AS test1
    LEFT OUTER JOIN cluster2.database.table AS test2 ON test1.a = test2.a
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;cluster1.database.table1 and cluster2.database.table are passed to cassandra datasource&lt;/p&gt;
</comment>
                            <comment id="14265224" author="alexliu68" created="Mon, 5 Jan 2015 22:19:29 +0000"  >&lt;p&gt;For each catalog, the configuration settings should start with catalog name. e.g.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;set cassandra.cluster.database.table.ttl = 1000
set cassandra.database.table.ttl =1000 (default cluster)
set mysql.cluster.database.table.xxx = 200
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If there&apos;s no catalog in the setting string, use the default catalog.&lt;/p&gt;</comment>
                            <comment id="14265335" author="marmbrus" created="Mon, 5 Jan 2015 23:30:27 +0000"  >&lt;p&gt;Thanks for your comments Alex.  Are you proposing any changes to what I said?&lt;/p&gt;

&lt;p&gt;Another thing I&apos;m confused about is your comment regarding joins.  As of now there is no public API for passing that kind of information down into a datasource.&lt;/p&gt;

&lt;p&gt;Regarding the configuration.  We will pass the datasource a SQLContext and you can do &lt;tt&gt;.getConf&lt;/tt&gt; using whatever arbitrary string you want.  I don&apos;t think Spark SQL needs to have any control here.&lt;/p&gt;</comment>
                            <comment id="14265351" author="alexliu68" created="Mon, 5 Jan 2015 23:42:39 +0000"  >&lt;p&gt;No changes to your approach. &lt;/p&gt;

&lt;p&gt;Regarding cluster1.database.table1 and cluster2.database.table passing to datasources. they are set as tableIdentifier and tableIdentifier is passed to catalog.lookupRelation method where datasource can use it.&lt;/p&gt;</comment>
                            <comment id="14268830" author="apachespark" created="Thu, 8 Jan 2015 05:13:55 +0000"  >&lt;p&gt;User &apos;alexliu68&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3941&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3941&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14272703" author="marmbrus" created="Sat, 10 Jan 2015 21:42:56 +0000"  >&lt;p&gt;Issue resolved by pull request 3941&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3941&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3941&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14278710" author="apachespark" created="Thu, 15 Jan 2015 14:17:46 +0000"  >&lt;p&gt;User &apos;scwf&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4062&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4062&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 44 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i23qyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>