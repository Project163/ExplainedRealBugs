<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:19:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-31448] Difference in Storage Levels used in cache() and persist() for pyspark dataframes</title>
                <link>https://issues.apache.org/jira/browse/SPARK-31448</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;There is a difference in default storage level &lt;b&gt;MEMORY_AND_DISK&lt;/b&gt; in pyspark and scala.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Scala&lt;/b&gt;: StorageLevel(true, true, false, true)&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Pyspark:&lt;/b&gt;&#160;StorageLevel(True, True, False, False)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Problem Description:&lt;/b&gt;&#160;&lt;/p&gt;

&lt;p&gt;Calling &lt;b&gt;df.cache()&lt;/b&gt;&#160; for pyspark dataframe directly invokes Scala method cache() and Storage Level used is StorageLevel(true, true, false, true).&lt;/p&gt;

&lt;p&gt;But calling &lt;b&gt;df.persist()&lt;/b&gt; for pyspark dataframe sets the newStorageLevel=StorageLevel(true, true, false, false) inside pyspark and then invokes Scala function persist(newStorageLevel).&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Possible Fix:&lt;/b&gt;&lt;br/&gt;
Invoke pyspark function persist inside pyspark function cache instead of calling the scala function directly.&lt;/p&gt;

&lt;p&gt;I can raise a PR for this fix if someone can confirm that this is a bug and the possible fix is the correct approach.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13298468">SPARK-31448</key>
            <summary>Difference in Storage Levels used in cache() and persist() for pyspark dataframes</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="abhishekd0907">Abhishek Dixit</assignee>
                                    <reporter username="abhishekd0907">Abhishek Dixit</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Apr 2020 06:25:15 +0000</created>
                <updated>Mon, 12 Dec 2022 18:11:01 +0000</updated>
                            <resolved>Tue, 15 Sep 2020 13:43:59 +0000</resolved>
                                    <version>2.4.3</version>
                                    <fixVersion>3.1.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17093079" author="abhishekd0907" created="Mon, 27 Apr 2020 07:10:47 +0000"  >&lt;p&gt;Any update on this?&lt;/p&gt;</comment>
                            <comment id="17100374" author="tianshi" created="Wed, 6 May 2020 01:35:48 +0000"  >&lt;p&gt;I found the following comment in StorageLevel.py in Spark 2.4.3:&#160;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&quot;.. note:: The following four storage level constants are deprecated in 2.0, since the records&lt;/em&gt;&lt;br/&gt;
 &lt;em&gt;will always be serialized in Python.&quot;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/v2.4.3/python/pyspark/storagelevel.py#L61&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v2.4.3/python/pyspark/storagelevel.py#L61&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So I would assume the counterpart in Scala is&#160;&lt;/p&gt;

&lt;p&gt;val MEMORY_AND_DISK_SER = new StorageLevel(true, true, false, false)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/storage/StorageLevel.scala#L162&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/storage/StorageLevel.scala#L162&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;val MEMORY_AND_DISK = new StorageLevel(true, true, false, true) means the data is deserialized. Does that help?&lt;/p&gt;</comment>
                            <comment id="17100445" author="gurwls223" created="Wed, 6 May 2020 04:12:07 +0000"  >&lt;p&gt;The diff is intentional. See also &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2014&quot; title=&quot;Make PySpark store RDDs in MEMORY_ONLY_SER with compression by default&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2014&quot;&gt;&lt;del&gt;SPARK-2014&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17101626" author="abhishekd0907" created="Thu, 7 May 2020 12:31:13 +0000"  >&lt;p&gt;Let me try to explain the problem more.&#160;&lt;/p&gt;

&lt;p&gt;Please look at this code in pyspark/dataframe.py:&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    @since(1.3)
    def cache(self):
        &quot;&quot;&quot;Persists the :class:`DataFrame` with the &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; storage level (C{MEMORY_AND_DISK}).
        .. note:: The &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; storage level has changed to C{MEMORY_AND_DISK} to match Scala in 2.0.
        &quot;&quot;&quot;
        self.is_cached = True
        self._jdf.cache()
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Cache method in pyspark data frame directly calls scala&apos;s cache method. Hence Storage level used is based on Scala defaults i.e. StorageLevel(true, true, false, true)&#160; with deserialized equal to true. But since, data from python is already serialized by the Pickle library, we should be using storage level with deserialized = false for pyspark dataframes.&lt;/p&gt;

&lt;p&gt;But if you look at cache method in pyspark/rdd.py, it sets the storage level in pyspark only and then calls the scala method with parameter. Hence correct storage level is used in this case with deserialzied = false.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def cache(self):
        &quot;&quot;&quot;
        Persist &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; RDD with the &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; storage level (C{MEMORY_ONLY}).
        &quot;&quot;&quot;
        self.is_cached = True
        self.persist(StorageLevel.MEMORY_ONLY)
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;We need to implement a similar way in cache method in dataframe.py to avoid using the scala defaults of deserialized = true&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17113035" author="abhishekd0907" created="Thu, 21 May 2020 10:09:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tianshi&quot; class=&quot;user-hover&quot; rel=&quot;tianshi&quot;&gt;tianshi&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Any update on this?&lt;/p&gt;</comment>
                            <comment id="17165164" author="apachespark" created="Sun, 26 Jul 2020 05:55:53 +0000"  >&lt;p&gt;User &apos;abhishekd0907&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/29242&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/29242&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17196159" author="srowen" created="Tue, 15 Sep 2020 13:43:59 +0000"  >&lt;p&gt;Issue resolved by pull request 29242&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/29242&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/29242&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 9 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0dncw:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>