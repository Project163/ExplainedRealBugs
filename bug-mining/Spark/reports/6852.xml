<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:08:05 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-30162] Add PushedFilters to metadata in Parquet DSv2 implementation</title>
                <link>https://issues.apache.org/jira/browse/SPARK-30162</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Filters are not pushed down in Spark 3.0 preview. Also the output of &quot;explain&quot; method is different. It is hard to debug in 3.0 whether filters were pushed down or not. Below code could reproduce the bug:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// code placeholder
&lt;/span&gt;df = spark.createDataFrame([(&lt;span class=&quot;code-quote&quot;&gt;&quot;usr1&quot;&lt;/span&gt;,17.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-10T15:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr1&quot;&lt;/span&gt;,13.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-11T12:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr1&quot;&lt;/span&gt;,25.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-12T11:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr1&quot;&lt;/span&gt;,20.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-13T15:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr1&quot;&lt;/span&gt;,17.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-14T12:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr2&quot;&lt;/span&gt;,99.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-15T11:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr2&quot;&lt;/span&gt;,156.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-22T11:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr2&quot;&lt;/span&gt;,17.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-31T11:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr2&quot;&lt;/span&gt;,25.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-15T11:27:18+00:00&quot;&lt;/span&gt;),
                            (&lt;span class=&quot;code-quote&quot;&gt;&quot;usr2&quot;&lt;/span&gt;,25.00, &lt;span class=&quot;code-quote&quot;&gt;&quot;2018-03-16T11:27:18+00:00&quot;&lt;/span&gt;)
                            ],
                           [&lt;span class=&quot;code-quote&quot;&gt;&quot;user&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;ts&quot;&lt;/span&gt;])
df = df.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&apos;ts&apos;&lt;/span&gt;, df.ts.&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&apos;timestamp&apos;&lt;/span&gt;))
df.write.partitionBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;user&quot;&lt;/span&gt;).parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/home/cnali/data/&quot;&lt;/span&gt;)df2 = spark.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;/home/cnali/data/&quot;&lt;/span&gt;)df2.filter(&lt;span class=&quot;code-quote&quot;&gt;&quot;user==&lt;span class=&quot;code-quote&quot;&gt;&apos;usr2&apos;&lt;/span&gt;&quot;&lt;/span&gt;).explain(True)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// Spark 2.4 output
&lt;/span&gt;== Parsed Logical Plan ==
&lt;span class=&quot;code-quote&quot;&gt;&apos;Filter (&apos;&lt;/span&gt;user = usr2)
+- Relation[id#38,ts#39,user#40] parquet== Analyzed Logical Plan ==
id: &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;, ts: timestamp, user: string
Filter (user#40 = usr2)
+- Relation[id#38,ts#39,user#40] parquet== Optimized Logical Plan ==
Filter (isnotnull(user#40) &amp;amp;&amp;amp; (user#40 = usr2))
+- Relation[id#38,ts#39,user#40] parquet== Physical Plan ==
*(1) FileScan parquet [id#38,ts#39,user#40] Batched: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, Format: Parquet, Location: InMemoryFileIndex[file:/home/cnali/data], PartitionCount: 1, PartitionFilters: [isnotnull(user#40), (user#40 = usr2)], PushedFilters: [], ReadSchema: struct&amp;lt;id:&lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;,ts:timestamp&amp;gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// Spark 3.0.0-preview output
&lt;/span&gt;== Parsed Logical Plan ==
&lt;span class=&quot;code-quote&quot;&gt;&apos;Filter (&apos;&lt;/span&gt;user = usr2)
+- RelationV2[id#0, ts#1, user#2] parquet file:/home/cnali/data== Analyzed Logical Plan ==
id: &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;, ts: timestamp, user: string
Filter (user#2 = usr2)
+- RelationV2[id#0, ts#1, user#2] parquet file:/home/cnali/data== Optimized Logical Plan ==
Filter (isnotnull(user#2) AND (user#2 = usr2))
+- RelationV2[id#0, ts#1, user#2] parquet file:/home/cnali/data== Physical Plan ==
*(1) Project [id#0, ts#1, user#2]
+- *(1) Filter (isnotnull(user#2) AND (user#2 = usr2))
   +- *(1) ColumnarToRow
      +- BatchScan[id#0, ts#1, user#2] ParquetScan Location: InMemoryFileIndex[file:/home/cnali/data], ReadSchema: struct&amp;lt;id:&lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;,ts:timestamp&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I have tested it on much larger dataset. Spark 3.0 tries to load whole data and then apply filter. Whereas Spark 2.4 push down the filter. Above output shows that Spark 2.4 applied partition filter but not the Spark 3.0 preview.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Minor: in Spark 3.0 &quot;explain()&quot; output is truncated (maybe fixed length?) and it&apos;s hard to debug.&#160; spark.sql.orc.cache.stripe.details.size=10000 doesn&apos;t work.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// pyspark 3 shell output
&lt;/span&gt;$ pyspark
Python 3.6.8 (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, Aug  7 2019, 17:28:10) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux
Type &lt;span class=&quot;code-quote&quot;&gt;&quot;help&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;copyright&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;credits&quot;&lt;/span&gt; or &lt;span class=&quot;code-quote&quot;&gt;&quot;license&quot;&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.
Warning: Ignoring non-spark config property: java.io.dir=/md2k/data1,/md2k/data2,/md2k/data3,/md2k/data4,/md2k/data5,/md2k/data6,/md2k/data7,/md2k/data8
19/12/09 07:05:36 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
Using Spark&apos;s &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; log4j profile: org/apache/spark/log4j-defaults.properties
Setting &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; log level to &lt;span class=&quot;code-quote&quot;&gt;&quot;WARN&quot;&lt;/span&gt;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
19/12/09 07:05:36 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.0.0-preview
      /_/Using Python version 3.6.8 (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, Aug  7 2019 17:28:10)
SparkSession available as &lt;span class=&quot;code-quote&quot;&gt;&apos;spark&apos;&lt;/span&gt;.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// pyspark 2.4.4 shell output
&lt;/span&gt;pyspark
Python 3.6.8 (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, Aug  7 2019, 17:28:10) 
[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux
Type &lt;span class=&quot;code-quote&quot;&gt;&quot;help&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;copyright&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;credits&quot;&lt;/span&gt; or &lt;span class=&quot;code-quote&quot;&gt;&quot;license&quot;&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.
2019-12-09 07:09:07 WARN  NativeCodeLoader:62 - Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
Setting &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; log level to &lt;span class=&quot;code-quote&quot;&gt;&quot;WARN&quot;&lt;/span&gt;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.4.0
      /_/Using Python version 3.6.8 (&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, Aug  7 2019 17:28:10)
SparkSession available as &lt;span class=&quot;code-quote&quot;&gt;&apos;spark&apos;&lt;/span&gt;.

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment>&lt;p&gt;pyspark 3.0 preview&lt;/p&gt;

&lt;p&gt;Ubuntu/Centos&lt;/p&gt;

&lt;p&gt;pyarrow 0.14.1&#160;&lt;/p&gt;</environment>
        <key id="13272899">SPARK-30162</key>
            <summary>Add PushedFilters to metadata in Parquet DSv2 implementation</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gurwls223">Hyukjin Kwon</assignee>
                                    <reporter username="nasirali">Nasir Ali</reporter>
                        <labels>
                    </labels>
                <created>Sat, 7 Dec 2019 07:30:35 +0000</created>
                <updated>Mon, 12 Dec 2022 17:35:04 +0000</updated>
                            <resolved>Tue, 21 Apr 2020 20:31:38 +0000</resolved>
                                    <version>3.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="16990725" author="toopt4" created="Sun, 8 Dec 2019 05:10:24 +0000"  >&lt;p&gt;did u try on scala sparkshell?&lt;/p&gt;</comment>
                            <comment id="16990741" author="nasirali" created="Sun, 8 Dec 2019 05:58:23 +0000"  >&lt;p&gt;No, I only use pyspark shell.&lt;/p&gt;</comment>
                            <comment id="16991137" author="aman_omer" created="Mon, 9 Dec 2019 04:58:54 +0000"  >&lt;p&gt;Kindly share the results of spark-shell.&lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="16991573" author="nasirali" created="Mon, 9 Dec 2019 13:10:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aman_omer&quot; class=&quot;user-hover&quot; rel=&quot;aman_omer&quot;&gt;aman_omer&lt;/a&gt;&#160;added in my question&lt;/p&gt;</comment>
                            <comment id="16994852" author="dongjoon" created="Thu, 12 Dec 2019 16:34:38 +0000"  >&lt;p&gt;Issue resolved by pull request 26857&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/26857&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/26857&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17006548" author="nasirali" created="Thu, 2 Jan 2020 03:02:15 +0000"  >&lt;p&gt;This issue has not been fixed. It shows pushed filters but it does not actually push filters. For example, look at 2.4.* output; there it clearly shows &apos;user&apos; as partition filter but not in 3.* version.&#160; Have a look at spark ui sql graph.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;On a bigger dataset, spark 2.4.* takes less than a second to show one row. Whereas, spark 3.* takes way too long to produce the same result. Code is exactly same (load parquet, filter based on partition key user)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17089031" author="dongjoon" created="Tue, 21 Apr 2020 20:09:04 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sowen&quot; class=&quot;user-hover&quot; rel=&quot;sowen&quot;&gt;sowen&lt;/a&gt;.&lt;br/&gt;
Is there a reason for you to remove the fixed version? It&apos;s fixed since `3.0.0-preview2`, isn&apos;t it?&lt;/p&gt;

&lt;p&gt;*&lt;b&gt;Apache Spark 3.0.0-preview2&lt;/b&gt;*&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; spark.range(10).write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/foo&quot;&lt;/span&gt;)
&amp;gt;&amp;gt;&amp;gt; spark.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/foo&quot;&lt;/span&gt;).filter(&lt;span class=&quot;code-quote&quot;&gt;&quot;5 &amp;gt; id&quot;&lt;/span&gt;).explain()
== Physical Plan ==
*(1) Project [id#3L]
+- *(1) Filter (isnotnull(id#3L) AND (5 &amp;gt; id#3L))
   +- *(1) ColumnarToRow
      +- BatchScan[id#3L] ParquetScan Location: InMemoryFileIndex[file:/tmp/foo], ReadSchema: struct&amp;lt;id:bigint&amp;gt;, PushedFilters: [IsNotNull(id), LessThan(id,5)]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;*&lt;b&gt;Apache Spark 3.0.0-RC1&lt;/b&gt;*&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;set spark.sql.sources.useV1SourceList=&apos;&apos;&quot;&lt;/span&gt;)
DataFrame[key: string, value: string]
&amp;gt;&amp;gt;&amp;gt; spark.range(10).write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/foo&quot;&lt;/span&gt;)
&amp;gt;&amp;gt;&amp;gt; spark.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/foo&quot;&lt;/span&gt;).filter(&lt;span class=&quot;code-quote&quot;&gt;&quot;5 &amp;gt; id&quot;&lt;/span&gt;).explain()
== Physical Plan ==
*(1) Project [id#53L]
+- *(1) Filter (isnotnull(id#53L) AND (5 &amp;gt; id#53L))
   +- *(1) ColumnarToRow
      +- BatchScan[id#53L] ParquetScan DataFilters: [isnotnull(id#53L), (5 &amp;gt; id#53L)], Location: InMemoryFileIndex[file:/tmp/foo], PartitionFilters: [], ReadSchema: struct&amp;lt;id:bigint&amp;gt;, PushedFilters: [IsNotNull(id), LessThan(id,5)]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17089034" author="nasirali" created="Tue, 21 Apr 2020 20:14:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;&#160;This bug has not been fixed. Please have a look at my previous comment and uploaded screenshots. Yes you added logs to debug but it doesn&apos;t perform filtering on partition key yet.&lt;/p&gt;</comment>
                            <comment id="17089037" author="dongjoon" created="Tue, 21 Apr 2020 20:17:48 +0000"  >&lt;p&gt;Could you try 3.0.0-RC1, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=nasirali&quot; class=&quot;user-hover&quot; rel=&quot;nasirali&quot;&gt;nasirali&lt;/a&gt;?&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;a href=&quot;https://dist.apache.org/repos/dist/dev/spark/v3.0.0-rc1-bin/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://dist.apache.org/repos/dist/dev/spark/v3.0.0-rc1-bin/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17089041" author="dongjoon" created="Tue, 21 Apr 2020 20:29:49 +0000"  >&lt;p&gt;In 3.0.0-RC1, I can see `number of partitions read: 1`.&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13000743/13000743_partition_pruning.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="17089044" author="dongjoon" created="Tue, 21 Apr 2020 20:31:38 +0000"  >&lt;p&gt;Please feel free to reopen this if you are facing a bug with 3.0.0-RC1. For me, it looks correctly.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12989784" name="Screenshot from 2020-01-01 21-01-18.png" size="134909" author="nasirali" created="Thu, 2 Jan 2020 03:03:12 +0000"/>
                            <attachment id="12989785" name="Screenshot from 2020-01-01 21-01-32.png" size="104890" author="nasirali" created="Thu, 2 Jan 2020 03:03:12 +0000"/>
                            <attachment id="13000743" name="partition_pruning.png" size="52704" author="dongjoon" created="Tue, 21 Apr 2020 20:28:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 29 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z09ec8:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>