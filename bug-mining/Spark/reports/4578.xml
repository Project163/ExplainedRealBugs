<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:51:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-19038] Can&apos;t find keytab file when using Hive catalog</title>
                <link>https://issues.apache.org/jira/browse/SPARK-19038</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;h2&gt;&lt;a name=&quot;StackTrace&quot;&gt;&lt;/a&gt;Stack Trace&lt;/h2&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Py4JJavaErrorTraceback (most recent call last)
&amp;lt;ipython-input-13-c35b9cad36ad&amp;gt; in &amp;lt;module&amp;gt;()
----&amp;gt; 1 sdf = sql.createDataFrame(df)

/opt/spark2/python/pyspark/sql/context.py in createDataFrame(self, data, schema, samplingRatio, verifySchema)
    307         Py4JJavaError: ...
    308         &quot;&quot;&quot;
--&amp;gt; 309         return self.sparkSession.createDataFrame(data, schema, samplingRatio, verifySchema)
    310 
    311     @since(1.3)

/opt/spark2/python/pyspark/sql/session.py in createDataFrame(self, data, schema, samplingRatio, verifySchema)
    524             rdd, schema = self._createFromLocal(map(prepare, data), schema)
    525         jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
--&amp;gt; 526         jdf = self._jsparkSession.applySchemaToPythonRDD(jrdd.rdd(), schema.json())
    527         df = DataFrame(jdf, self._wrapped)
    528         df._schema = schema

/opt/spark2/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py in __call__(self, *args)
   1131         answer = self.gateway_client.send_command(command)
   1132         return_value = get_return_value(
-&amp;gt; 1133             answer, self.gateway_client, self.target_id, self.name)
   1134 
   1135         for temp_arg in temp_args:

/opt/spark2/python/pyspark/sql/utils.py in deco(*a, **kw)
     61     def deco(*a, **kw):
     62         try:
---&amp;gt; 63             return f(*a, **kw)
     64         except py4j.protocol.Py4JJavaError as e:
     65             s = e.java_exception.toString()

/opt/spark2/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
    317                 raise Py4JJavaError(
    318                     &quot;An error occurred while calling {0}{1}{2}.\n&quot;.
--&amp;gt; 319                     format(target_id, &quot;.&quot;, name), value)
    320             else:
    321                 raise Py4JError(

Py4JJavaError: An error occurred while calling o47.applySchemaToPythonRDD.
: org.apache.spark.SparkException: Keytab file: .keytab-f0b9b814-460e-4fa8-8e7d-029186b696c4 specified in spark.yarn.keytab does not exist
	at org.apache.spark.sql.hive.client.HiveClientImpl.&amp;lt;init&amp;gt;(HiveClientImpl.scala:113)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:258)
	at org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:359)
	at org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:263)
	at org.apache.spark.sql.hive.HiveSharedState.metadataHive$lzycompute(HiveSharedState.scala:39)
	at org.apache.spark.sql.hive.HiveSharedState.metadataHive(HiveSharedState.scala:38)
	at org.apache.spark.sql.hive.HiveSharedState.externalCatalog$lzycompute(HiveSharedState.scala:46)
	at org.apache.spark.sql.hive.HiveSharedState.externalCatalog(HiveSharedState.scala:45)
	at org.apache.spark.sql.hive.HiveSessionState.catalog$lzycompute(HiveSessionState.scala:50)
	at org.apache.spark.sql.hive.HiveSessionState.catalog(HiveSessionState.scala:48)
	at org.apache.spark.sql.hive.HiveSessionState$$anon$1.&amp;lt;init&amp;gt;(HiveSessionState.scala:63)
	at org.apache.spark.sql.hive.HiveSessionState.analyzer$lzycompute(HiveSessionState.scala:63)
	at org.apache.spark.sql.hive.HiveSessionState.analyzer(HiveSessionState.scala:62)
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:49)
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)
	at org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:666)
	at org.apache.spark.sql.SparkSession.applySchemaToPythonRDD(SparkSession.scala:656)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;h2&gt;&lt;a name=&quot;Stepstoreproduce&quot;&gt;&lt;/a&gt;Steps to reproduce&lt;/h2&gt;

&lt;p&gt;1. Pass valid --principal=user@REALM and --keytab=/home/user/.keytab to spark-submit&lt;br/&gt;
2. Set spark.sql.catalogImplementation = &apos;hive&apos;&lt;br/&gt;
3. Set deploy mode to yarn-client&lt;br/&gt;
4. Create a SparkSession and try to use session.createDataFrame()&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;Observations&quot;&gt;&lt;/a&gt;Observations&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;The &lt;tt&gt;setupCredentials&lt;/tt&gt; function in Client.scala sets &lt;tt&gt;spark.yarn.keytab&lt;/tt&gt; to a UUID suffixed version of the base keytab filename without any path. For example, &lt;tt&gt;sparkContext.getConf().getAll()&lt;/tt&gt; shows &lt;tt&gt;spark.yarn.keytab&lt;/tt&gt; as having value &lt;tt&gt;.keytab-f0b9b814-460e-4fa8-8e7d-029186b696c4&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;When listing the contents of the application staging directory on HDFS, no suffixed file exists. Rather, the keytab file appears in the listing with its original name. For instance, &lt;tt&gt;hdfs dfs -ls hdfs://home/user/.sparkStaging/appication_big_uuid/&lt;/tt&gt; shows an entry &lt;tt&gt;hdfs://home/user/.sparkStaging/appication_big_uuid/.keytab&lt;/tt&gt;, but not &lt;tt&gt;hdfs://home/user/.sparkStaging/appication_big_uuid/.keytab-big-uuid&lt;/tt&gt;.&lt;/li&gt;
	&lt;li&gt;The same exception noted above occurs even after I manually put a copy of the keytab with a filename matching the new value of &lt;tt&gt;spark.yarn.keytab&lt;/tt&gt; onto HDFS in the staging directory.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;&lt;a name=&quot;ExpectedBehavior&quot;&gt;&lt;/a&gt;Expected Behavior&lt;/h2&gt;

&lt;p&gt;HiveClientImpl should be able to read &lt;tt&gt;spark.yarn.keytab&lt;/tt&gt; to find the keytab file and initialize itself properly.&lt;/p&gt;

&lt;h2&gt;&lt;a name=&quot;References&quot;&gt;&lt;/a&gt;References&lt;/h2&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-8619&quot; title=&quot;Can&amp;#39;t find the keytab file when recovering the streaming application.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-8619&quot;&gt;&lt;del&gt;SPARK-8619&lt;/del&gt;&lt;/a&gt; also noted trouble with the keytab property getting changed  after app startup.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment>&lt;p&gt;Hadoop / YARN 2.6, pyspark, yarn-client mode&lt;/p&gt;</environment>
        <key id="13031350">SPARK-19038</key>
            <summary>Can&apos;t find keytab file when using Hive catalog</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jerryshao">Saisai Shao</assignee>
                                    <reporter username="parente">Peter Parente</reporter>
                        <labels>
                            <label>hive</label>
                            <label>kerberos</label>
                            <label>pyspark</label>
                    </labels>
                <created>Fri, 30 Dec 2016 23:22:02 +0000</created>
                <updated>Sun, 17 May 2020 18:14:35 +0000</updated>
                            <resolved>Fri, 24 Feb 2017 17:33:30 +0000</resolved>
                                    <version>2.0.2</version>
                                    <fixVersion>2.0.3</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>Spark Core</component>
                    <component>YARN</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15791995" author="parente" created="Mon, 2 Jan 2017 01:52:03 +0000"  >&lt;p&gt;Also, since the keytab file name in the staging directory does not match the new Spark config setting, the Kerberos ticket is not properly renewed before expiration.&lt;/p&gt;</comment>
                            <comment id="15803617" author="apachespark" created="Fri, 6 Jan 2017 05:28:04 +0000"  >&lt;p&gt;User &apos;parente&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16482&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16482&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15803722" author="jerryshao" created="Fri, 6 Jan 2017 06:25:59 +0000"  >&lt;p&gt;Please see the comment I made in Github(&lt;a href=&quot;https://github.com/apache/spark/pull/16482&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16482&lt;/a&gt;), from my understanding the behavior is expected.&lt;/p&gt;</comment>
                            <comment id="15864968" author="tagar" created="Tue, 14 Feb 2017 03:34:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt; PR 16482 is for a different issue &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-19105&quot; title=&quot;yarn/Client.scala copyToRemote does not include keytab destination name&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-19105&quot;&gt;&lt;del&gt;SPARK-19105&lt;/del&gt;&lt;/a&gt;? &lt;/p&gt;

&lt;p&gt;I still see this issue after Spark 2.0 upgrade. &lt;br/&gt;
See details in &lt;a href=&quot;https://github.com/apache/spark/pull/16482#issuecomment-279563855&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16482#issuecomment-279563855&lt;/a&gt;&lt;br/&gt;
We didn&apos;t have this problem in Spark 1.5 nor 1.6.&lt;/p&gt;

&lt;p&gt;Tried to workaround by putting keytab in user&apos;s home directory in HDFS but this fails with (expected?)&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;main&quot; org.apache.spark.SparkException: Keytab file: hdfs:///user/svc_odiprd/.kt does not exist
        at org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:555)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:158)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;created &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-19588&quot; title=&quot;Allow putting keytab file to HDFS location specified in spark.yarn.keytab&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-19588&quot;&gt;&lt;del&gt;SPARK-19588&lt;/del&gt;&lt;/a&gt; to create this separate issue for the workaround.&lt;/p&gt;</comment>
                            <comment id="15864983" author="jerryshao" created="Tue, 14 Feb 2017 03:44:10 +0000"  >&lt;p&gt;I think the issue you met is the same as this JIRA mentioned, but PR 16482 tries to use a different way to solve this problem, which is not correct for current Spark on YARN. Let me figure out a decent solution to fix this.&lt;/p&gt;</comment>
                            <comment id="15864995" author="tagar" created="Tue, 14 Feb 2017 03:54:34 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15865013" author="tagar" created="Tue, 14 Feb 2017 04:06:16 +0000"  >&lt;p&gt;Another possible workaround is to pass principal and keytab to spark-submit through SPARK_SUBMIT_OPTIONS environment variable&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;environ[&lt;span class=&quot;code-quote&quot;&gt;&quot;SPARK_SUBMIT_OPTIONS&quot;&lt;/span&gt;] = &lt;span class=&quot;code-quote&quot;&gt;&quot;--principal %s --keytab %s&quot;&lt;/span&gt; % (kt_principal, kt_location)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;instead of setting in &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SparkConf().set(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.yarn.keytab&quot;&lt;/span&gt;, kt_location).set(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.yarn.principal&quot;&lt;/span&gt;, kt_principal)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but again this is a breaking change / bug in Spark 2.&lt;/p&gt;</comment>
                            <comment id="15865415" author="apachespark" created="Tue, 14 Feb 2017 09:13:03 +0000"  >&lt;p&gt;User &apos;jerryshao&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16923&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16923&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13042791">SPARK-19588</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 40 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i385ef:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>