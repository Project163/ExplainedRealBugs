<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:21:12 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3926] result of JavaRDD collectAsMap() is not serializable</title>
                <link>https://issues.apache.org/jira/browse/SPARK-3926</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Using the Java API, I want to collect the result of a RDD&amp;lt;String, String&amp;gt; as a HashMap using collectAsMap function:&lt;br/&gt;
Map&amp;lt;String, String&amp;gt; map = myJavaRDD.collectAsMap();&lt;br/&gt;
This works fine, but when passing this map to another function, such as...&lt;br/&gt;
myOtherJavaRDD.mapToPair(new CustomFunction(map))&lt;br/&gt;
...this leads to the following error:&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;main&quot; org.apache.spark.SparkException: Task not serializable&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.SparkContext.clean(SparkContext.scala:1242)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.rdd.RDD.map(RDD.scala:270)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.api.java.JavaRDDLike$class.mapToPair(JavaRDDLike.scala:99)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.api.java.JavaPairRDD.mapToPair(JavaPairRDD.scala:44)&lt;/p&gt;

&lt;p&gt;	../.. MY CLASS ../..&lt;/p&gt;

&lt;p&gt;	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;/p&gt;

&lt;p&gt;	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;/p&gt;

&lt;p&gt;	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;/p&gt;

&lt;p&gt;	at java.lang.reflect.Method.invoke(Method.java:606)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:328)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)&lt;/p&gt;

&lt;p&gt;Caused by: java.io.NotSerializableException: scala.collection.convert.Wrappers$MapWrapper&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1183)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)&lt;/p&gt;

&lt;p&gt;	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:42)&lt;/p&gt;

&lt;p&gt;	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:73)&lt;/p&gt;

&lt;p&gt;at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:164)&lt;/p&gt;

&lt;p&gt;This seems to be due to WrapAsJava.scala being non serializable&lt;br/&gt;
../..&lt;br/&gt;
  implicit def mapAsJavaMap&lt;span class=&quot;error&quot;&gt;&amp;#91;A, B&amp;#93;&lt;/span&gt;(m: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;A, B&amp;#93;&lt;/span&gt;): ju.Map&lt;span class=&quot;error&quot;&gt;&amp;#91;A, B&amp;#93;&lt;/span&gt; = m match &lt;/p&gt;
{
    //case JConcurrentMapWrapper(wrapped) =&amp;gt; wrapped
    case JMapWrapper(wrapped) =&amp;gt; wrapped.asInstanceOf[ju.Map[A, B]]
    case _ =&amp;gt; new MapWrapper(m)
  }
&lt;p&gt;../..&lt;/p&gt;

&lt;p&gt;The workaround is to manually wrapper this map into another one (serialized)&lt;br/&gt;
Map&amp;lt;String, String&amp;gt; map = myJavaRDD.collectAsMap();&lt;br/&gt;
Map&amp;lt;String, String&amp;gt; tmp = new HashMap&amp;lt;String, String&amp;gt;(map);&lt;br/&gt;
myOtherJavaRDD.mapToPair(new CustomFunction(tmp))&lt;/p&gt;</description>
                <environment>&lt;p&gt;CentOS / Spark 1.1 / Hadoop Hortonworks 2.4.0.2.1.2.0-402&lt;/p&gt;</environment>
        <key id="12747731">SPARK-3926</key>
            <summary>result of JavaRDD collectAsMap() is not serializable</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="aamend">Antoine Amend</reporter>
                        <labels>
                    </labels>
                <created>Mon, 13 Oct 2014 14:44:05 +0000</created>
                <updated>Wed, 17 Dec 2014 20:14:46 +0000</updated>
                            <resolved>Wed, 17 Dec 2014 20:14:24 +0000</resolved>
                                    <version>1.0.2</version>
                    <version>1.1.0</version>
                    <version>1.1.1</version>
                    <version>1.2.0</version>
                                    <fixVersion>1.2.1</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>Java API</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14169383" author="srowen" created="Mon, 13 Oct 2014 15:16:13 +0000"  >&lt;p&gt;Yeah, seems fine to just let &lt;tt&gt;MapWrapper&lt;/tt&gt; implement &lt;tt&gt;Serializable&lt;/tt&gt;, because standard Java &lt;tt&gt;Map&lt;/tt&gt; implementations are as well. It&apos;s backwards-compatible so seems like an easy PR to submit if you like.&lt;/p&gt;</comment>
                            <comment id="14171418" author="srowen" created="Tue, 14 Oct 2014 19:52:09 +0000"  >&lt;p&gt;Oops, embarrassed to say I didn&apos;t realize &lt;tt&gt;WrapAsJava.scala&lt;/tt&gt; is a Scala class. Can&apos;t change that.&lt;br/&gt;
This requires subclassing &lt;tt&gt;MapWrapper&lt;/tt&gt; to add &lt;tt&gt;java.io.Serializable&lt;/tt&gt;. It still basically seems worthwhile to support this use case, so I&apos;ll propose it as a PR.&lt;/p&gt;</comment>
                            <comment id="14171421" author="apachespark" created="Tue, 14 Oct 2014 19:55:14 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2805&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2805&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14171817" author="joshrosen" created="Wed, 15 Oct 2014 01:05:37 +0000"  >&lt;p&gt;I opened a Scala JIRA to try to fix this: &lt;a href=&quot;https://issues.scala-lang.org/browse/SI-8911&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues.scala-lang.org/browse/SI-8911&lt;/a&gt;.  In the meantime, I suppose that our own wrapper subclass works, although I wonder whether it&apos;s potentially serializing the wrapper&apos;s parent object or other undesirable things.&lt;/p&gt;</comment>
                            <comment id="14172098" author="srowen" created="Wed, 15 Oct 2014 07:29:49 +0000"  >&lt;p&gt;Nice one, yes it should probably be changed upstream. &lt;tt&gt;MapWrapper&lt;/tt&gt; extends &lt;tt&gt;java.util.AbstractMap&lt;/tt&gt; and does not add fields, and this Spark wrapper is just another subclass that implements &lt;tt&gt;java.io.Serializable&lt;/tt&gt; without adding anything else. It looks safe to serialize.&lt;/p&gt;</comment>
                            <comment id="14176093" author="joshrosen" created="Sat, 18 Oct 2014 19:43:08 +0000"  >&lt;p&gt;This has been fixed by Sean&apos;s patch in 1.1.1 and 1.2.0.&lt;/p&gt;</comment>
                            <comment id="14229318" author="joshrosen" created="Mon, 1 Dec 2014 01:25:43 +0000"  >&lt;p&gt;Just saw a bug report on the mailing list that looks possily related to this: &lt;a href=&quot;http://apache-spark-user-list.1001560.n3.nabble.com/java-io-InvalidClassException-org-apache-spark-api-java-JavaUtils-SerializableMapWrapper-no-valid-cor-td20034.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://apache-spark-user-list.1001560.n3.nabble.com/java-io-InvalidClassException-org-apache-spark-api-java-JavaUtils-SerializableMapWrapper-no-valid-cor-td20034.html&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in
stage 815081.0 failed 4 times, most recent failure: Lost task 0.3 in stage
815081.0 (TID 4751, ns2.xxxxx.net): java.io.InvalidClassException:
org.apache.spark.api.java.JavaUtils$SerializableMapWrapper; no valid
constructor
        at
java.io.ObjectStreamClass$ExceptionInfo.newInvalidClassException(ObjectStreamClass.java:150)
        at
java.io.ObjectStreamClass.checkDeserialize(ObjectStreamClass.java:768)
        at
java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1775)
        at
java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
        at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
        at
org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        at
org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:216)
        at
org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:177)
        at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1000)
        at
org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:164)
        at
org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
        at
org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
        at
org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:87)
        at
com.xxxxxxx.common.chores.kafka.kafkaListenerChore$4$1.call(kafkaListenerChore.java:418)
        at
com.xxxxxxx.common.chores.kafka.kafkaListenerChore$4$1.call(kafkaListenerChore.java:406)
        at
org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)
        at
org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)
        at
org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:775)
        at
org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:775)
        at
org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1314)
        at
org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1314)
        at
org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
        at org.apache.spark.scheduler.Task.run(Task.scala:56)
        at
org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
        at
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Any idea what&apos;s going on here?&lt;/p&gt;</comment>
                            <comment id="14229599" author="zsxwing" created="Mon, 1 Dec 2014 09:44:03 +0000"  >&lt;blockquote&gt;
&lt;p&gt;To allow subtypes of non-serializable classes to be serialized, the subtype may assume responsibility for saving and restoring the state of the supertype&apos;s public, protected, and (if accessible) package fields. The subtype may assume this responsibility only if the class it extends has an accessible no-arg constructor to initialize the class&apos;s state. It is an error to declare a class Serializable if this is not the case. The error will be detected at runtime.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;From &lt;a href=&quot;https://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So it requires that `MapWrapper` must be serializable or has an accessible no-arg constructor.&lt;/p&gt;</comment>
                            <comment id="14229628" author="srowen" created="Mon, 1 Dec 2014 10:10:59 +0000"  >&lt;p&gt;I see, there may be even two issues here &amp;#8211; constructor, and embedded field reference. Let me write a unit test to exercise this and see if this is something that can be amended to work or whether some other approach is needed.&lt;/p&gt;</comment>
                            <comment id="14230042" author="srowen" created="Mon, 1 Dec 2014 17:02:57 +0000"  >&lt;p&gt;Yep, you&apos;re right, it&apos;s the constructor. I think there are two fixes:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Copy the return value to a &lt;tt&gt;HashMap&lt;/tt&gt; and return that. This requires a copy (of references only, note), so introduces some overhead, but is simple and works&lt;/li&gt;
	&lt;li&gt;Copy the &lt;tt&gt;MapWrapper&lt;/tt&gt; source and make it &lt;tt&gt;Serializable&lt;/tt&gt; with a no-arg constructor.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I have the latter working but both are simple. Any preference?&lt;/p&gt;</comment>
                            <comment id="14231098" author="zsxwing" created="Tue, 2 Dec 2014 07:15:52 +0000"  >&lt;p&gt;I checked the usage of `mapAsSerializableJavaMap` and found it&apos;s used in org.apache.spark.sql.api.java.Row: &lt;a href=&quot;https://github.com/apache/spark/blob/23f966f47523f85ba440b4080eee665271f53b5e/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala#L122&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/23f966f47523f85ba440b4080eee665271f53b5e/sql/core/src/main/scala/org/apache/spark/sql/api/java/Row.scala#L122&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It&apos;s called from `Row.get(i: Int)` -&amp;gt; `Row.toJavaValue`. Since `Row.get` may be used in some iteration and called frequently, the overhead of copying may be a lot. I suggest option 2): Copy the MapWrapper source and make it Serializable with a no-arg constructor. &lt;/p&gt;</comment>
                            <comment id="14233446" author="srowen" created="Wed, 3 Dec 2014 19:59:43 +0000"  >&lt;p&gt;I am reopening as it is not actually serializable without a no-arg constructor. PR coming shortly, that copies the implementation from Scala&apos;s Wrappers.MapWrapper.&lt;/p&gt;</comment>
                            <comment id="14233453" author="apachespark" created="Wed, 3 Dec 2014 20:03:40 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3587&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3587&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14238728" author="joshrosen" created="Tue, 9 Dec 2014 00:16:00 +0000"  >&lt;p&gt;I&apos;ve merged &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt;&apos;s patch into &lt;tt&gt;master&lt;/tt&gt; and &lt;tt&gt;branch-1.1&lt;/tt&gt; and have tagged this for a &lt;tt&gt;branch-1.2&lt;/tt&gt; backport.  Thanks!&lt;/p&gt;</comment>
                            <comment id="14250454" author="joshrosen" created="Wed, 17 Dec 2014 20:14:24 +0000"  >&lt;p&gt;I&apos;ve merged this into &lt;tt&gt;branch-1.2&lt;/tt&gt; for inclusion in 1.2.1, so I&apos;m marking this as Fixed.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 48 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i213t3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329029">1.2.1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>