<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:45:24 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16182] Utils.scala -- terminateProcess() should call Process.destroyForcibly() if and only if Process.destroy() fails</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16182</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Spark streaming documentation recommends application developers create static connection pools. To clean up this pool, we add a shutdown hook.&lt;/p&gt;

&lt;p&gt;The problem is that in spark 1.6.1, the shutdown hook for an executor will be called only for the first submitted job.  (on the second and subsequent job submissions, the shutdown hook for the executor will NOT be invoked)&lt;/p&gt;

&lt;p&gt;problem not seen when using java 1.7&lt;br/&gt;
problem not seen when using spark 1.6.0&lt;/p&gt;

&lt;p&gt;looks like this bug is caused by this modification from 1.6.0 to 1.6.1:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-12486&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-12486&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;steps to reproduce the problem :&lt;/p&gt;

&lt;p&gt;1.) install spark 1.6.1&lt;br/&gt;
2.) submit this basic spark application&lt;/p&gt;

&lt;p&gt;import org.apache.spark.&lt;/p&gt;
{ SparkContext, SparkConf }
&lt;p&gt;object MyPool {&lt;br/&gt;
    def printToFile( f : java.io.File )( op : java.io.PrintWriter =&amp;gt; Unit ) {&lt;br/&gt;
        val p = new java.io.PrintWriter(f)&lt;br/&gt;
        try &lt;/p&gt;
{
            op(p)
        }
&lt;p&gt;        finally &lt;/p&gt;
{
            p.close()
        }
&lt;p&gt;    }&lt;br/&gt;
    def myfunc( ) = &lt;/p&gt;
{
        &quot;a&quot;
    }
&lt;p&gt;    def createEvidence( ) = {&lt;br/&gt;
        printToFile(new java.io.File(&quot;/var/tmp/evidence.txt&quot;)) &lt;/p&gt;
{ p =&amp;gt;
            p.println(&quot;the evidence&quot;)
        }
&lt;p&gt;    }&lt;br/&gt;
    sys.addShutdownHook &lt;/p&gt;
{
        createEvidence()
    }
&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;object BasicSpark {&lt;br/&gt;
    def main( args : Array&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt; ) = {&lt;br/&gt;
        val sparkConf = new SparkConf().setAppName(&quot;BasicPi&quot;)&lt;br/&gt;
        val sc = new SparkContext(sparkConf)&lt;br/&gt;
        sc.parallelize(1 to 2).foreach &lt;/p&gt;
{ i =&amp;gt; println(&quot;f : &quot; + MyPool.myfunc())
        }
&lt;p&gt;        sc.stop()&lt;br/&gt;
    }&lt;br/&gt;
}&lt;/p&gt;


&lt;p&gt;3.) you will see that /var/tmp/evidence.txt is created&lt;br/&gt;
4.) now delete this file &lt;br/&gt;
5.) submit a second job&lt;br/&gt;
6.) you will see that /var/tmp/evidence.txt is no longer created on the second submission&lt;/p&gt;

&lt;p&gt;7.) if you use java 7 or spark 1.6.0, the evidence file will be created on the second and subsequent submits&lt;/p&gt;</description>
                <environment>&lt;p&gt;OSX El Capitan (java &quot;1.8.0_65&quot;), Oracle Linux 6 (java 1.8.0_92-b14)&lt;/p&gt;</environment>
        <key id="12982534">SPARK-16182</key>
            <summary>Utils.scala -- terminateProcess() should call Process.destroyForcibly() if and only if Process.destroy() fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="christianchua">Christian Chua</reporter>
                        <labels>
                    </labels>
                <created>Fri, 24 Jun 2016 01:07:00 +0000</created>
                <updated>Wed, 6 Jul 2016 01:41:38 +0000</updated>
                            <resolved>Fri, 1 Jul 2016 08:22:53 +0000</resolved>
                                    <version>1.6.1</version>
                                    <fixVersion>1.6.3</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15347760" author="srowen" created="Fri, 24 Jun 2016 06:00:37 +0000"  >&lt;p&gt;This isn&apos;t a Spark issue though right? Whatever is going on concerns the JVM&apos;s shutdown hook or a process not dying.&lt;/p&gt;</comment>
                            <comment id="15347856" author="christianchua" created="Fri, 24 Jun 2016 06:43:17 +0000"  >&lt;p&gt;The 1.6.1 code uses Process.destroyForcibly when available :&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/v1.6.1/core/src/main/scala/org/apache/spark/util/Utils.scala#L1702&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v1.6.1/core/src/main/scala/org/apache/spark/util/Utils.scala#L1702&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;what I believe should happen is that terminateProcess should call Process.destroy first, then after some timeout check for whether the process is still alive or not.  If still alive, then use destroy forcibly.  It appears that destroy forcibly is calling &quot;kill -9&quot; and so the shutdown hook getting called is not guaranteed.&lt;/p&gt;

&lt;p&gt;But to answer your question, I believe this is a spark issue &amp;#8211; spark should properly manage the jvm&apos;s it spawns.&lt;/p&gt;</comment>
                            <comment id="15347869" author="srowen" created="Fri, 24 Jun 2016 06:57:55 +0000"  >&lt;p&gt;OK that sounds more reasonable, go ahead.&lt;/p&gt;</comment>
                            <comment id="15355100" author="apachespark" created="Wed, 29 Jun 2016 12:01:06 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/13973&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/13973&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15358643" author="srowen" created="Fri, 1 Jul 2016 08:22:53 +0000"  >&lt;p&gt;Issue resolved by pull request 13973&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/13973&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/13973&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 20 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i300an:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>