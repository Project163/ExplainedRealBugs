<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:29:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-38652] uploadFileUri should preserve file scheme</title>
                <link>https://issues.apache.org/jira/browse/SPARK-38652</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;DepsTestsSuite in k8s IT test is blocked with PathIOException in hadoop-aws-3.3.2. Exception Message is as follow&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; org.apache.spark.SparkException: Uploading file /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar failed...        
at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadFileUri(KubernetesUtils.scala:332)        
at org.apache.spark.deploy.k8s.KubernetesUtils$.$anonfun$uploadAndTransformFileUris$1(KubernetesUtils.scala:277)        
at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)        
at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)        
at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)        
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)        
at scala.collection.TraversableLike.map(TraversableLike.scala:286)        
at scala.collection.TraversableLike.map$(TraversableLike.scala:279)        
at scala.collection.AbstractTraversable.map(Traversable.scala:108)        
at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadAndTransformFileUris(KubernetesUtils.scala:275)        
at org.apache.spark.deploy.k8s.features.BasicDriverFeatureStep.$anonfun$getAdditionalPodSystemProperties$1(BasicDriverFeatureStep.scala:187)       
at scala.collection.immutable.List.foreach(List.scala:431)        
at org.apache.spark.deploy.k8s.features.BasicDriverFeatureStep.getAdditionalPodSystemProperties(BasicDriverFeatureStep.scala:178)        
at org.apache.spark.deploy.k8s.submit.KubernetesDriverBuilder.$anonfun$buildFromFeatures$5(KubernetesDriverBuilder.scala:86)        at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)        
at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)        
at scala.collection.immutable.List.foldLeft(List.scala:91)        
at org.apache.spark.deploy.k8s.submit.KubernetesDriverBuilder.buildFromFeatures(KubernetesDriverBuilder.scala:84)        
at org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:104)        
at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$5(KubernetesClientApplication.scala:248)        
at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$5$adapted(KubernetesClientApplication.scala:242)
at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2738)        
at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:242)        
at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:214)        
at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958)        
at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)        
at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)        
at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)        
at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046)        
at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055)        
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)Caused by: org.apache.spark.SparkException: Error uploading file spark-examples_2.12-3.4.0-SNAPSHOT.jar        
at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadFileToHadoopCompatibleFS(KubernetesUtils.scala:355)        
at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadFileUri(KubernetesUtils.scala:328)        
... 30 more
Caused by: org.apache.hadoop.fs.PathIOException: `Cannot get relative path &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; URI:file:&lt;span class=&quot;code-comment&quot;&gt;///Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar&apos;: Input/output error
&lt;/span&gt;at org.apache.hadoop.fs.s3a.impl.CopyFromLocalOperation.getFinalPath(CopyFromLocalOperation.java:365)        
at org.apache.hadoop.fs.s3a.impl.CopyFromLocalOperation.uploadSourceFromFS(CopyFromLocalOperation.java:226)        
at org.apache.hadoop.fs.s3a.impl.CopyFromLocalOperation.execute(CopyFromLocalOperation.java:170)        
at org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$copyFromLocalFile$25(S3AFileSystem.java:3920)        
at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)        at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)        
at org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)        
at org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)        
at org.apache.hadoop.fs.s3a.S3AFileSystem.copyFromLocalFile(S3AFileSystem.java:3913)        
at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadFileToHadoopCompatibleFS(KubernetesUtils.scala:352)        
... 31 more  &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For more information please refer to &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-18173&quot; title=&quot;S3a copyFromLocalOperation doesn&amp;#39;t support single file&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-18173&quot;&gt;HADOOP-18173&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;But, DepsTestsSuite with hadoop-aws-3.3.1 works normally.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;hengzhen.sq@b-q922md6r-0237 ~/Desktop$ /Users/hengzhen.sq/IdeaProjects/spark/bin/spark-submit --deploy-mode cluster --class org.apache.spark.examples.SparkRemoteFileTest --master k8s://https://192.168.64.86:8443/ --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.testing=false&#160; --conf spark.hadoop.fs.s3a.access.key=minio --conf spark.kubernetes.driver.label.spark-app-locator=a8937b5fdf6a444a806ee1c3ecac37fc --conf spark.kubernetes.file.upload.path=s3a://spark --conf spark.authenticate=true --conf spark.executor.instances=1 --conf spark.kubernetes.submission.waitAppCompletion=false --conf spark.kubernetes.executor.label.spark-app-locator=a8937b5fdf6a444a806ee1c3ecac37fc --conf spark.kubernetes.namespace=spark-job --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.hadoop.fs.s3a.secret.key=miniostorage --conf spark.executor.extraJavaOptions=-Dlog4j2.debug --conf spark.hadoop.fs.s3a.endpoint=192.168.64.86:32681 --conf spark.app.name=spark-test-app --conf spark.files=/tmp/tmp7013228683780235449.txt --conf spark.ui.enabled=true --conf spark.driver.extraJavaOptions=-Dlog4j2.debug --conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/smart-spark/spark:test --conf spark.executor.cores=1 --conf spark.jars.packages=org.apache.hadoop:hadoop-aws:3.3.1 --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar tmp7013228683780235449.txt
22/03/25 10:24:10 WARN Utils: Your hostname, B-Q922MD6R-0237.local resolves to a loopback address: 127.0.0.1; using 30.25.86.17 instead (on interface en0)
22/03/25 10:24:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
:: loading settings :: url = jar:file:/Users/hengzhen.sq/IdeaProjects/spark/assembly/target/scala-2.12/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /Users/hengzhen.sq/.ivy2/cache
The jars for the packages stored in: /Users/hengzhen.sq/.ivy2/jars
org.apache.hadoop#hadoop-aws added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-8220baa6-0490-4484-9779-945d4cf69df4;1.0
	confs: [default]
	found org.apache.hadoop#hadoop-aws;3.3.1 in central
	found com.amazonaws#aws-java-sdk-bundle;1.11.901 in central
	found org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central
:: resolution report :: resolve 224ms :: artifacts dl 6ms
	:: modules in use:
	com.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]
	org.apache.hadoop#hadoop-aws;3.3.1 from central in [default]
	org.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]
	---------------------------------------------------------------------
	|&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; |&#160; &#160; &#160; &#160; &#160; &#160; modules&#160; &#160; &#160; &#160; &#160; &#160; || &#160; artifacts &#160; |
	| &#160; &#160; &#160; conf &#160; &#160; &#160; | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|&#160; &#160; &#160; default &#160; &#160; | &#160; 3 &#160; | &#160; 0 &#160; | &#160; 0 &#160; | &#160; 0 &#160; || &#160; 3 &#160; | &#160; 0 &#160; |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-8220baa6-0490-4484-9779-945d4cf69df4
	confs: [default]
	0 artifacts copied, 3 already retrieved (0kB/6ms)
22/03/25 10:24:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/03/25 10:24:11 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
22/03/25 10:24:12 INFO KerberosConfDriverFeatureStep: You have not specified a krb5.conf file locally or via a ConfigMap. Make sure that you have the krb5.conf locally on the driver image.
22/03/25 10:24:12 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
22/03/25 10:24:12 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
22/03/25 10:24:12 INFO MetricsSystemImpl: s3a-file-system metrics system started
22/03/25 10:24:13 INFO KubernetesUtils: Uploading file: /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar to dest: s3a://spark/spark-upload-f49ee7fc-182d-499a-b073-40b298c55e8b/spark-examples_2.12-3.4.0-SNAPSHOT.jar...
22/03/25 10:24:13 INFO KubernetesUtils: Uploading file: /private/tmp/tmp7013228683780235449.txt to dest: s3a://spark/spark-upload-906c6d35-6aa7-4ee8-8c37-434f547c6087/tmp7013228683780235449.txt...
22/03/25 10:24:14 INFO ShutdownHookManager: Shutdown hook called
22/03/25 10:24:14 INFO ShutdownHookManager: Deleting directory /private/var/folders/3t/v_td68551s78mq4c1cpk86gc0000gn/T/spark-e89a395e-c3b4-4619-8c9b-e60310af6503
22/03/25 10:24:14 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
22/03/25 10:24:14 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
22/03/25 10:24:14 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;CopyFromLocalFile action in hadoop-aws is different between 3.3.1 and 3.3.2, because 3.3.2 introuduces CopyFromLocalFileOperation.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13435698">SPARK-38652</key>
            <summary>uploadFileUri should preserve file scheme</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dongjoon">Dongjoon Hyun</assignee>
                                    <reporter username="dcoliversun">Qian Sun</reporter>
                        <labels>
                    </labels>
                <created>Fri, 25 Mar 2022 02:28:09 +0000</created>
                <updated>Wed, 30 Mar 2022 15:28:38 +0000</updated>
                            <resolved>Wed, 30 Mar 2022 15:28:25 +0000</resolved>
                                    <version>3.3.0</version>
                                    <fixVersion>3.1.3</fixVersion>
                    <fixVersion>3.0.4</fixVersion>
                    <fixVersion>3.3.0</fixVersion>
                    <fixVersion>3.2.2</fixVersion>
                                    <component>Kubernetes</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17512163" author="dcoliversun" created="Fri, 25 Mar 2022 02:31:24 +0000"  >&lt;p&gt;I am working on it.&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chaosun&quot; class=&quot;user-hover&quot; rel=&quot;chaosun&quot;&gt;chaosun&lt;/a&gt;&#160; &amp;amp; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17512458" author="stevel@apache.org" created="Fri, 25 Mar 2022 16:03:01 +0000"  >&lt;p&gt;have you tried running the same suite against an aws s3 endpoint?&lt;/p&gt;</comment>
                            <comment id="17512657" author="dcoliversun" created="Sat, 26 Mar 2022 01:51:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt; No. I can do it, which help us to confirm whether the cause of the problem is minio or hadoop-aws-3.3.2. And, I share result about test here.&lt;/p&gt;</comment>
                            <comment id="17512846" author="dcoliversun" created="Sun, 27 Mar 2022 07:21:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt; Hi, I run the same suite against an real aws s3 endpoint, and have same exception. I think we could exclude reason about minio deployment.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ bin/spark-submit --deploy-mode cluster --class org.apache.spark.examples.SparkRemoteFileTest --master k8s://https://192.168.64.87:8443/ --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem --conf spark.testing=false &#160;--conf spark.hadoop.fs.s3a.access.key=XXXXXXX --conf spark.kubernetes.driver.label.spark-app-locator=a8937b5fdf6a444a806ee1c3ecac37fc --conf spark.kubernetes.file.upload.path=s3a://dcoliversun --conf spark.authenticate=true --conf spark.executor.instances=1 --conf spark.kubernetes.submission.waitAppCompletion=false --conf spark.kubernetes.executor.label.spark-app-locator=a8937b5fdf6a444a806ee1c3ecac37fc --conf spark.kubernetes.namespace=spark-job --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark --conf spark.hadoop.fs.s3a.secret.key=XXXXXXX --conf spark.executor.extraJavaOptions=-Dlog4j2.debug --conf spark.hadoop.fs.s3a.endpoint=https://s3.ap-southeast-1.amazonaws.com --conf spark.app.name=spark-test-app --conf spark.files=/tmp/tmp7013228683780235449.txt --conf spark.ui.enabled=true --conf spark.driver.extraJavaOptions=-Dlog4j2.debug --conf spark.kubernetes.container.image=registry.cn-hangzhou.aliyuncs.com/smart-spark/spark:test --conf spark.executor.cores=1 --conf spark.hadoop.fs.s3a.connection.ssl.enabled=false /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar tmp7013228683780235449.txt


22/03/27 15:16:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/03/27 15:16:28 INFO SparkKubernetesClientFactory: Auto-configuring K8S client using current context from users K8S config file
22/03/27 15:16:28 INFO KerberosConfDriverFeatureStep: You have not specified a krb5.conf file locally or via a ConfigMap. Make sure that you have the krb5.conf locally on the driver image.
22/03/27 15:16:29 INFO KubernetesUtils: sq-isLocalAndResolvable =&amp;gt; resource is file:/Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar
22/03/27 15:16:29 INFO KubernetesUtils: sq =&amp;gt; uri is file:/Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar, uri scheme is file
22/03/27 15:16:29 INFO KubernetesUtils: sq-uploadAndTransformFileUris, uri is file:/Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar
22/03/27 15:16:29 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
22/03/27 15:16:29 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
22/03/27 15:16:29 INFO MetricsSystemImpl: s3a-file-system metrics system started
22/03/27 15:16:31 INFO KubernetesUtils: Uploading file: /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar to dest: s3a://dcoliversun/spark-upload-eb20e2da-17b6-4dcd-b4f1-8e47bc80c1e9/spark-examples_2.12-3.4.0-SNAPSHOT.jar...
22/03/27 15:16:31 INFO S3AFileSystem: Copying local file from /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar to s3a://dcoliversun/spark-upload-eb20e2da-17b6-4dcd-b4f1-8e47bc80c1e9/spark-examples_2.12-3.4.0-SNAPSHOT.jar
22/03/27 15:16:31 INFO CopyFromLocalOperation: Copying local file from /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar to s3a://dcoliversun/spark-upload-eb20e2da-17b6-4dcd-b4f1-8e47bc80c1e9/spark-examples_2.12-3.4.0-SNAPSHOT.jar
22/03/27 15:16:31 INFO CopyFromLocalOperation: execute#CopyFromLocalOperation, sourceFile is /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar
22/03/27 15:16:31 INFO CopyFromLocalOperation: uploadSourceFromFS#CopyFromLocalOperation, localFile 1: path is LocatedFileStatus{path=file:/Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar; isDirectory=false; length=1567474; replication=1; blocksize=33554432; modification_time=1647874074000; access_time=1647874074000; owner=hengzhen.sq; group=staff; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}
22/03/27 15:16:31 INFO CopyFromLocalOperation: getFinalPath#CopyFromLocalOperation, src is file:/Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar, source is /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar
Exception in thread &quot;main&quot; org.apache.spark.SparkException: Uploading file /Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar failed...
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadFileUri(KubernetesUtils.scala:332)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.KubernetesUtils$.$anonfun$uploadAndTransformFileUris$1(KubernetesUtils.scala:277)
&#160; &#160; &#160; &#160; at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)
&#160; &#160; &#160; &#160; at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
&#160; &#160; &#160; &#160; at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
&#160; &#160; &#160; &#160; at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
&#160; &#160; &#160; &#160; at scala.collection.TraversableLike.map(TraversableLike.scala:286)
&#160; &#160; &#160; &#160; at scala.collection.TraversableLike.map$(TraversableLike.scala:279)
&#160; &#160; &#160; &#160; at scala.collection.AbstractTraversable.map(Traversable.scala:108)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadAndTransformFileUris(KubernetesUtils.scala:275)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.features.BasicDriverFeatureStep.$anonfun$getAdditionalPodSystemProperties$1(BasicDriverFeatureStep.scala:187)
&#160; &#160; &#160; &#160; at scala.collection.immutable.List.foreach(List.scala:431)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.features.BasicDriverFeatureStep.getAdditionalPodSystemProperties(BasicDriverFeatureStep.scala:178)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.submit.KubernetesDriverBuilder.$anonfun$buildFromFeatures$5(KubernetesDriverBuilder.scala:86)
&#160; &#160; &#160; &#160; at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
&#160; &#160; &#160; &#160; at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
&#160; &#160; &#160; &#160; at scala.collection.immutable.List.foldLeft(List.scala:91)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.submit.KubernetesDriverBuilder.buildFromFeatures(KubernetesDriverBuilder.scala:84)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.submit.Client.run(KubernetesClientApplication.scala:104)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$5(KubernetesClientApplication.scala:248)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.$anonfun$run$5$adapted(KubernetesClientApplication.scala:242)
&#160; &#160; &#160; &#160; at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:2738)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.run(KubernetesClientApplication.scala:242)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.submit.KubernetesClientApplication.start(KubernetesClientApplication.scala:214)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.SparkException: Error uploading file spark-examples_2.12-3.4.0-SNAPSHOT.jar
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadFileToHadoopCompatibleFS(KubernetesUtils.scala:355)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadFileUri(KubernetesUtils.scala:328)
&#160; &#160; &#160; &#160; ... 30 more
Caused by: org.apache.hadoop.fs.PathIOException: `Cannot get relative path for URI:file:///Users/hengzhen.sq/IdeaProjects/spark/dist/examples/jars/spark-examples_2.12-3.4.0-SNAPSHOT.jar&apos;: Input/output error
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.s3a.impl.CopyFromLocalOperation.getFinalPath(CopyFromLocalOperation.java:365)
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.s3a.impl.CopyFromLocalOperation.uploadSourceFromFS(CopyFromLocalOperation.java:226)
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.s3a.impl.CopyFromLocalOperation.execute(CopyFromLocalOperation.java:170)
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.s3a.S3AFileSystem.lambda$copyFromLocalFile$25(S3AFileSystem.java:3920)
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:499)
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:444)
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2337)
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.s3a.S3AFileSystem.trackDurationAndSpan(S3AFileSystem.java:2356)
&#160; &#160; &#160; &#160; at org.apache.hadoop.fs.s3a.S3AFileSystem.copyFromLocalFile(S3AFileSystem.java:3913)
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.k8s.KubernetesUtils$.uploadFileToHadoopCompatibleFS(KubernetesUtils.scala:352)
&#160; &#160; &#160; &#160; ... 31 more
22/03/27 15:16:31 INFO ShutdownHookManager: Shutdown hook called
22/03/27 15:16:31 INFO ShutdownHookManager: Deleting directory /private/var/folders/3t/v_td68551s78mq4c1cpk86gc0000gn/T/spark-c7717437-e729-47d8-aa13-4bdd716beb1d
22/03/27 15:16:32 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
22/03/27 15:16:32 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
22/03/27 15:16:32 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17514343" author="dongjoon" created="Tue, 29 Mar 2022 22:16:31 +0000"  >&lt;p&gt;Any update, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dcoliversun&quot; class=&quot;user-hover&quot; rel=&quot;dcoliversun&quot;&gt;dcoliversun&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="17514379" author="dongjoon" created="Wed, 30 Mar 2022 00:37:21 +0000"  >&lt;p&gt;BTW, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dcoliversun&quot; class=&quot;user-hover&quot; rel=&quot;dcoliversun&quot;&gt;dcoliversun&lt;/a&gt;. K8s IT itself doesn&apos;t fail in both Apache Spark `master` branch and `branch-3.3` in my environment. Do you mean the test case fails when you do `spark-submit`?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ build/sbt -Psparkr -Pkubernetes -Pvolcano -Pkubernetes-integration-tests -Dtest.exclude.tags=minikube -Dspark.kubernetes.test.deployMode=docker-&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt;-desktop &lt;span class=&quot;code-quote&quot;&gt;&quot;kubernetes-integration-tests/test&quot;&lt;/span&gt;
...
[info] KubernetesSuite:
[info] - Run SparkPi with no resources (8 seconds, 527 milliseconds)
[info] - Run SparkPi with no resources &amp;amp; statefulset allocation (8 seconds, 323 milliseconds)
[info] - Run SparkPi with a very &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt; application name. (8 seconds, 386 milliseconds)
[info] - Use SparkLauncher.NO_RESOURCE (8 seconds, 425 milliseconds)
[info] - Run SparkPi with a master URL without a scheme. (8 seconds, 385 milliseconds)
[info] - Run SparkPi with an argument. (8 seconds, 328 milliseconds)
[info] - Run SparkPi with custom labels, annotations, and environment variables. (8 seconds, 384 milliseconds)
[info] - All pods have the same service account by &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; (8 seconds, 342 milliseconds)
[info] - Run extraJVMOptions check on driver (4 seconds, 327 milliseconds)
[info] - Run SparkRemoteFileTest using a remote data file (8 seconds, 429 milliseconds)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17514390" author="dcoliversun" created="Wed, 30 Mar 2022 01:26:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; Hi. DepsTestsSuite has tests as follow&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Launcher client dependencies&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-33615&quot; title=&quot;Make spark.archives working in Kubernates&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-33615&quot;&gt;&lt;del&gt;SPARK-33615&lt;/del&gt;&lt;/a&gt;: Launcher client archives&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-33748&quot; title=&quot;Support PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON environment variables&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-33748&quot;&gt;&lt;del&gt;SPARK-33748&lt;/del&gt;&lt;/a&gt;: Launcher python client respecting PYSPARK_PYTHON&lt;/li&gt;
	&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;spark-submit command is used by these tests. So, I think DepsTestsSuite blocks.&lt;/p&gt;

&lt;p&gt;Could you please check these tests run? Maybe `-Dtest.exclude.tags` option doesn&apos;t need `minikube` value.&lt;/p&gt;</comment>
                            <comment id="17514398" author="dongjoon" created="Wed, 30 Mar 2022 02:09:52 +0000"  >&lt;p&gt;Got it, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dcoliversun&quot; class=&quot;user-hover&quot; rel=&quot;dcoliversun&quot;&gt;dcoliversun&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17514431" author="dongjoon" created="Wed, 30 Mar 2022 04:23:34 +0000"  >&lt;p&gt;I also confirmed this regression and raise this issue as a blocker. Thank you, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dcoliversun&quot; class=&quot;user-hover&quot; rel=&quot;dcoliversun&quot;&gt;dcoliversun&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17514566" author="dongjoon" created="Wed, 30 Mar 2022 09:41:59 +0000"  >&lt;p&gt;I&apos;m going to make a PR for this.&lt;/p&gt;</comment>
                            <comment id="17514569" author="apachespark" created="Wed, 30 Mar 2022 09:47:32 +0000"  >&lt;p&gt;User &apos;dongjoon-hyun&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/36010&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/36010&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17514774" author="dongjoon" created="Wed, 30 Mar 2022 15:28:25 +0000"  >&lt;p&gt;Issue resolved by pull request 36010&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/36010&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/36010&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13317485">HADOOP-17139</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13435694">HADOOP-18173</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 32 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z10t3k:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>