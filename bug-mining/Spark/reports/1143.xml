<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:21:20 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4826] Possible flaky tests in WriteAheadLogBackedBlockRDDSuite: &quot;java.lang.IllegalStateException: File exists and there is no append support!&quot;</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4826</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I saw a recent master Maven build failure in WriteHeadLogBackedBlockRDDSuite where four tests failed with the same exception.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-pre-YARN/1156/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Link to test result (this will eventually break)&lt;/a&gt;.  In case that link breaks:&lt;/p&gt;

&lt;p&gt;The failed tests:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite.Read data available only in block manager, not in write ahead log
org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite.Read data available only in write ahead log, not in block manager
org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite.Read data available only in write ahead log, and test storing in block manager
org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite.Read data with partially available in block manager, and &lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt; in write ahead log
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The error messages are all (essentially) the same:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;     java.lang.IllegalStateException: File exists and there is no append support!
      at org.apache.spark.streaming.util.HdfsUtils$.getOutputStream(HdfsUtils.scala:33)
      at org.apache.spark.streaming.util.WriteAheadLogWriter.org$apache$spark$streaming$util$WriteAheadLogWriter$$stream$lzycompute(WriteAheadLogWriter.scala:34)
      at org.apache.spark.streaming.util.WriteAheadLogWriter.org$apache$spark$streaming$util$WriteAheadLogWriter$$stream(WriteAheadLogWriter.scala:34)
      at org.apache.spark.streaming.util.WriteAheadLogWriter.&amp;lt;init&amp;gt;(WriteAheadLogWriter.scala:42)
      at org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite.writeLogSegments(WriteAheadLogBackedBlockRDDSuite.scala:140)
      at org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite.org$apache$spark$streaming$rdd$WriteAheadLogBackedBlockRDDSuite$$testRDD(WriteAheadLogBackedBlockRDDSuite.scala:95)
      at org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite$$anonfun$4.apply$mcV$sp(WriteAheadLogBackedBlockRDDSuite.scala:67)
      at org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite$$anonfun$4.apply(WriteAheadLogBackedBlockRDDSuite.scala:67)
      at org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite$$anonfun$4.apply(WriteAheadLogBackedBlockRDDSuite.scala:67)
      at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
      at org.scalatest.OutcomeOf$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;outcomeOf(OutcomeOf.scala:85)
      at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
      at org.scalatest.Transformer.apply(Transformer.scala:22)
      at org.scalatest.Transformer.apply(Transformer.scala:20)
      at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
      at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;withFixture(Suite.scala:1122)
      at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
      at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;invokeWithFixture$1(FunSuiteLike.scala:163)
      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
      at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
      at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
      at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runTest(FunSuiteLike.scala:175)
      at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
      at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
      at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
      at scala.collection.immutable.List.foreach(List.scala:318)
      at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
      at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
      at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
      at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runTests(FunSuiteLike.scala:208)
      at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
      at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(Suite.scala:1424)
      at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(FunSuite.scala:1555)
      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
      at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
      at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
      at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(FunSuiteLike.scala:212)
      at org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite.org$scalatest$BeforeAndAfterAll$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(WriteAheadLogBackedBlockRDDSuite.scala:31)
      at org.scalatest.BeforeAndAfterAll$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;liftedTree1$1(BeforeAndAfterAll.scala:257)
      at org.scalatest.BeforeAndAfterAll$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(BeforeAndAfterAll.scala:256)
      at org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite.run(WriteAheadLogBackedBlockRDDSuite.scala:31)
      at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;callExecuteOnSuite$1(Suite.scala:1492)
      at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
      at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
      at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IndexedSeqOptimized.scala:33)
      at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
      at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runNestedSuites(Suite.scala:1526)
      at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
      at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(Suite.scala:1421)
      at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
      at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
      at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
      at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
      at scala.collection.immutable.List.foreach(List.scala:318)
      at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
      at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
      at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
      at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
      at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
      at org.scalatest.tools.Runner$.main(Runner.scala:860)
      at org.scalatest.tools.Runner.main(Runner.scala)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12760954">SPARK-4826</key>
            <summary>Possible flaky tests in WriteAheadLogBackedBlockRDDSuite: &quot;java.lang.IllegalStateException: File exists and there is no append support!&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="joshrosen">Josh Rosen</assignee>
                                    <reporter username="joshrosen">Josh Rosen</reporter>
                        <labels>
                            <label>flaky-test</label>
                    </labels>
                <created>Thu, 11 Dec 2014 07:08:41 +0000</created>
                <updated>Mon, 15 Dec 2014 22:34:31 +0000</updated>
                            <resolved>Mon, 15 Dec 2014 22:34:22 +0000</resolved>
                                    <version>1.2.0</version>
                    <version>1.3.0</version>
                                    <fixVersion>1.2.1</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>DStreams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14242248" author="joshrosen" created="Thu, 11 Dec 2014 07:09:31 +0000"  >&lt;p&gt;Actually, it turns out that this has happened twice.  Here&apos;s a link to another occurrence of the same failure pattern: &lt;a href=&quot;https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-pre-YARN/1147/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://amplab.cs.berkeley.edu/jenkins/job/Spark-Master-Maven-pre-YARN/1147/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14245978" author="joshrosen" created="Sun, 14 Dec 2014 16:40:31 +0000"  >&lt;p&gt;I committed a documentation typo fix to &lt;tt&gt;master&lt;/tt&gt; and &lt;tt&gt;branch-1.2&lt;/tt&gt; at the same time, which caused a huge number of Maven builds to kick off simultaneously in Jenkins (since it was otherwise idle), and alll of these builds failed due to tests in WriteAheadLogBackedBlockRDDSuite; ; it also broke the master SBT build.&lt;/p&gt;

&lt;p&gt;I wonder if there&apos;s some kind of sharing / contention where multiple copies of the test are attempting to write to the same directory.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hshreedharan&quot; class=&quot;user-hover&quot; rel=&quot;hshreedharan&quot;&gt;hshreedharan&lt;/a&gt;, it would be great to get your help with this to see if you can spot any potential problems in that test suite.&lt;/p&gt;</comment>
                            <comment id="14246041" author="hshreedharan" created="Sun, 14 Dec 2014 18:32:47 +0000"  >&lt;p&gt;It looks like there is some issue with the directories/files existing (though we use random names for files/dirs). I will see try to get something ready later today&lt;/p&gt;</comment>
                            <comment id="14246091" author="nchammas" created="Sun, 14 Dec 2014 20:21:10 +0000"  >&lt;p&gt;This raises an interesting test infrastructure question: Do we have a way of invoking multiple copies of the same test (on the same or across multiple JVMs) to check a test&apos;s level of isolation? If not, that might be a good thing to look into.&lt;/p&gt;</comment>
                            <comment id="14246122" author="nchammas" created="Sun, 14 Dec 2014 20:57:55 +0000"  >&lt;p&gt;I just cooked up a quick way of invoking this test multiple times in parallel using &lt;a href=&quot;http://www.gnu.org/software/parallel/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;GNU parallel&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;parallel &lt;span class=&quot;code-quote&quot;&gt;&apos;sbt/sbt -Pyarn -Phadoop-2.3 -Dhadoop.version=2.3.0 -Pkinesis-asl -Phive -Phive-thriftserver &lt;span class=&quot;code-quote&quot;&gt;&quot;testOnly org.apache.spark.streaming.rdd.WriteAheadLogBackedBlockRDDSuite&quot;&lt;/span&gt;&apos;&lt;/span&gt; ::: &lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; &apos;&lt;/span&gt;&lt;span class=&quot;code-quote&quot;&gt;&apos; &apos;&lt;/span&gt;&lt;span class=&quot;code-quote&quot;&gt;&apos; &apos;&lt;/span&gt;&apos;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This will fire up 4 copies of that one test in parallel. I ran it a couple of times on my laptop without issue, but appears to be due to some sbt locking that prevents the tests from actually running in parallel.&lt;/p&gt;

&lt;p&gt;I&apos;ve &lt;a href=&quot;http://stackoverflow.com/questions/27474000/how-can-i-run-multiple-copies-of-the-same-test-in-parallel&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;posted a question on Stack Overflow&lt;/a&gt; about this.&lt;/p&gt;</comment>
                            <comment id="14246270" author="hshreedharan" created="Mon, 15 Dec 2014 03:10:54 +0000"  >&lt;p&gt;I suspect that the nextString is conflicting and producing strings that are likely conflicting (since createTempDir is atomic). Using monotonically increasing names for the file counter will likely fix the issue.&lt;/p&gt;</comment>
                            <comment id="14246289" author="apachespark" created="Mon, 15 Dec 2014 03:37:38 +0000"  >&lt;p&gt;User &apos;harishreedharan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3695&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3695&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14247043" author="pwendell" created="Mon, 15 Dec 2014 19:00:31 +0000"  >&lt;p&gt;I pushed a hotfix disabling these tests, but let&apos;s re-enable them once things are working.&lt;/p&gt;</comment>
                            <comment id="14247082" author="apachespark" created="Mon, 15 Dec 2014 19:26:01 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3704&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14247360" author="joshrosen" created="Mon, 15 Dec 2014 22:34:22 +0000"  >&lt;p&gt;Issue resolved by pull request 3704&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3704&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 49 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i23b1j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329029">1.2.1</customfieldvalue>
    <customfieldvalue id="12327642">1.3.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>