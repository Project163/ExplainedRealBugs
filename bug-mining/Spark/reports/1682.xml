<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:26:01 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-5068] When the path not found in the hdfs,we can&apos;t get the result</title>
                <link>https://issues.apache.org/jira/browse/SPARK-5068</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;when the partion path was found in the metastore but not found in the hdfs,it will casue some problems as follow:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;hive&amp;gt; show partitions partition_test;
OK
dt=1
dt=2
dt=3
dt=4
Time taken: 0.168 seconds, Fetched: 4 row(s)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;hive&amp;gt; dfs -ls /user/jeanlyn/warehouse/partition_test;
Found 3 items
drwxr-xr-x   - jeanlyn supergroup          0 2014-12-02 16:29 /user/jeanlyn/warehouse/partition_test/dt=1
drwxr-xr-x   - jeanlyn supergroup          0 2014-12-02 16:29 /user/jeanlyn/warehouse/partition_test/dt=3
drwxr-xr-x   - jeanlyn supergroup          0 2014-12-02 17:42 /user/jeanlyn/warehouse/partition_test/dt=4
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;when i run the sql &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;select * from partition_test limit 10
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; in  &lt;b&gt;hive&lt;/b&gt;,i got no problem,but when i run in &lt;b&gt;spark-sql&lt;/b&gt; i get the error as follow:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;main&quot; org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://jeanlyn:9000/user/jeanlyn/warehouse/partition_test/dt=2
    at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:251)
    at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:270)
    at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:201)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:203)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.rdd.RDD.partitions(RDD.scala:203)
    at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:203)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.rdd.RDD.partitions(RDD.scala:203)
    at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:32)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:203)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.rdd.RDD.partitions(RDD.scala:203)
    at org.apache.spark.rdd.UnionRDD$$anonfun$1.apply(UnionRDD.scala:66)
    at org.apache.spark.rdd.UnionRDD$$anonfun$1.apply(UnionRDD.scala:66)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.immutable.List.foreach(List.scala:318)
    at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
    at scala.collection.AbstractTraversable.map(Traversable.scala:105)
    at org.apache.spark.rdd.UnionRDD.getPartitions(UnionRDD.scala:66)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:203)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.rdd.RDD.partitions(RDD.scala:203)
    at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)
    at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:203)
    at scala.Option.getOrElse(Option.scala:120)
    at org.apache.spark.rdd.RDD.partitions(RDD.scala:203)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1328)
    at org.apache.spark.rdd.RDD.collect(RDD.scala:780)
    at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:84)
    at org.apache.spark.sql.SchemaRDD.collect(SchemaRDD.scala:444)
    at org.apache.spark.sql.hive.testpartition$.main(test.scala:23)
    at org.apache.spark.sql.hive.testpartition.main(test.scala)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12764750">SPARK-5068</key>
            <summary>When the path not found in the hdfs,we can&apos;t get the result</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dongxu">Dongxu</assignee>
                                    <reporter username="jeanlyn">jeanlyn</reporter>
                        <labels>
                    </labels>
                <created>Sun, 4 Jan 2015 06:05:53 +0000</created>
                <updated>Wed, 4 Nov 2015 20:34:26 +0000</updated>
                            <resolved>Sun, 12 Apr 2015 01:33:43 +0000</resolved>
                                    <version>1.2.0</version>
                                    <fixVersion>1.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14263902" author="apachespark" created="Sun, 4 Jan 2015 16:49:47 +0000"  >&lt;p&gt;User &apos;jeanlyn&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3891&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3891&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14267483" author="apachespark" created="Wed, 7 Jan 2015 10:16:55 +0000"  >&lt;p&gt;User &apos;jeanlyn&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3907&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3907&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14304710" author="apachespark" created="Wed, 4 Feb 2015 06:44:12 +0000"  >&lt;p&gt;User &apos;chenghao-intel&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4356&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4356&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14364490" author="apachespark" created="Tue, 17 Mar 2015 03:28:47 +0000"  >&lt;p&gt;User &apos;lazyman500&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5059&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5059&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14990025" author="njonkers" created="Wed, 4 Nov 2015 17:49:53 +0000"  >&lt;p&gt;We stil see this issue on Spark 1.5:&lt;br/&gt;
hive can handle the missing partition but not spark-sql:&lt;/p&gt;

&lt;p&gt;HDFS:&lt;/p&gt;

&lt;p&gt;$ hdfs dfs -lsr /data&lt;br/&gt;
lsr: DEPRECATED: Please use &apos;ls -R&apos; instead.&lt;br/&gt;
drwxr-xr-x   - hadoop hadoop          0 2015-11-04 17:40 /data/year=2015&lt;br/&gt;
drwxr-xr-x   - hadoop hadoop          0 2015-11-04 17:35 /data/year=2015/month=10&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;-   1 hadoop hadoop         20 2015-11-04 17:35 /data/year=2015/month=10/names&lt;/p&gt;

&lt;p&gt;Spark:&lt;/p&gt;

&lt;p&gt;15/11/04 17:47:46 INFO ParseDriver: Parsing command: select * from th&lt;br/&gt;
15/11/04 17:47:46 INFO ParseDriver: Parse Completed&lt;br/&gt;
15/11/04 17:47:46 INFO MemoryStore: ensureFreeSpace(481656) called with curMem=9466, maxMem=560993402&lt;br/&gt;
15/11/04 17:47:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 470.4 KB, free 534.5 MB)&lt;br/&gt;
15/11/04 17:47:46 INFO MemoryStore: ensureFreeSpace(45219) called with curMem=491122, maxMem=560993402&lt;br/&gt;
15/11/04 17:47:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 44.2 KB, free 534.5 MB)&lt;br/&gt;
15/11/04 17:47:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.43.193.77:57944 (size: 44.2 KB, free: 535.0 MB)&lt;br/&gt;
15/11/04 17:47:46 INFO SparkContext: Created broadcast 3 from processCmd at CliDriver.java:376&lt;br/&gt;
15/11/04 17:47:46 INFO FileInputFormat: Total input paths to process : 1&lt;br/&gt;
15/11/04 17:47:46 ERROR SparkSQLDriver: Failed in &lt;span class=&quot;error&quot;&gt;&amp;#91;select * from th&amp;#93;&lt;/span&gt;&lt;br/&gt;
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://ip-10-43-193-77.ec2.internal:8020/data/year=2015/month=11&lt;br/&gt;
	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:251)&lt;br/&gt;
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:200)&lt;br/&gt;
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:279)&lt;br/&gt;
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:207)&lt;/p&gt;</comment>
                            <comment id="14990352" author="smilegator" created="Wed, 4 Nov 2015 20:33:38 +0000"  >&lt;p&gt;Now, the default value of this feature is off. spark.sql.hive.verifyPartitionPath &lt;/p&gt;

&lt;p&gt;You can turn it on and do a retry. &lt;/p&gt;

&lt;p&gt;For more details, you can read the following JIRA:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-10198&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-10198&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 2 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i23xf3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>