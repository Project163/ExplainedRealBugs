<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:40:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-14252] Executors do not try to download remote cached blocks</title>
                <link>https://issues.apache.org/jira/browse/SPARK-14252</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I noticed this when taking a look at the root cause of &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-14209&quot; title=&quot;Application failure during preemption.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-14209&quot;&gt;&lt;del&gt;SPARK-14209&lt;/del&gt;&lt;/a&gt;. 2.0.0 includes &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-12817&quot; title=&quot;Remove CacheManager and replace it with new BlockManager.getOrElseUpdate method&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-12817&quot;&gt;&lt;del&gt;SPARK-12817&lt;/del&gt;&lt;/a&gt;, which changed the caching code a bit to remove duplication. But it seems to have removed the part where executors check whether other executors contain the needed cached block.&lt;/p&gt;

&lt;p&gt;In 1.6, that was done by the call to &lt;tt&gt;BlockManager.get&lt;/tt&gt; in &lt;tt&gt;CacheManager.getOrCompute&lt;/tt&gt;. But in the new version, &lt;tt&gt;RDD.iterator&lt;/tt&gt; calls &lt;tt&gt;BlockManager.getOrElseUpdate&lt;/tt&gt;, which never calls &lt;tt&gt;BlockManager.get&lt;/tt&gt;, and thus the executor never gets block that are cached by other executors, causing the blocks to be instead recomputed locally.&lt;/p&gt;

&lt;p&gt;I wrote a small program that shows this. In 1.6, running with &lt;tt&gt;--num-executors 2&lt;/tt&gt;, I get 5 blocks cached on each executor, and messages like these in the logs:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;16/03/29 13:18:01 DEBUG spark.CacheManager: Looking for partition rdd_0_7
16/03/29 13:18:01 DEBUG storage.BlockManager: Getting local block rdd_0_7
16/03/29 13:18:01 DEBUG storage.BlockManager: Block rdd_0_7 not registered locally
16/03/29 13:18:01 DEBUG storage.BlockManager: Getting remote block rdd_0_7
16/03/29 13:18:01 DEBUG storage.BlockManager: Getting remote block rdd_0_7 from BlockManagerId(1, blah, 58831)
1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On 2.0, I get (almost) all the 10 partitions cached on &lt;b&gt;both&lt;/b&gt; executors, because once the second one fails to find a block locally it just recomputes it and caches it. It never tries to download the block from the other executor.  The log messages above, which still exist in the code, don&apos;t show up anywhere.&lt;/p&gt;


&lt;p&gt;Here&apos;s the code I used for the above (trimmed of some other stuff from my little test harness, so might not compile as is):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    val sc = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkContext(conf)
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      val rdd = sc.parallelize(1 to 10000000, 10)
      rdd.cache()
      rdd.count()

      &lt;span class=&quot;code-comment&quot;&gt;// Create a single task that will sleep and block, so that a particular executor is busy.
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// This should force &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; tasks to download cached data from that executor.
&lt;/span&gt;      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Running sleep job..&quot;&lt;/span&gt;)
      val thread =  &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Runnable&lt;/span&gt;() {
        override def run(): Unit = {
          rdd.mapPartitionsWithIndex { (i, iter) =&amp;gt;
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (i == 0) {
              &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(TimeUnit.MINUTES.toMillis(10))
            }
            iter
          }.count()
        }
      })
      thread.setDaemon(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
      thread.start()

      &lt;span class=&quot;code-comment&quot;&gt;// Wait a few seconds to make sure the task is running (too lazy &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; listeners)
&lt;/span&gt;      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; tasks to start...&quot;&lt;/span&gt;)
      TimeUnit.SECONDS.sleep(10)

      &lt;span class=&quot;code-comment&quot;&gt;// Now run a job that will touch everything and should use the cached data.
&lt;/span&gt;      val cnt = rdd.map(_*2).count()
      println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Counted $cnt elements.&quot;&lt;/span&gt;)

      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Killing sleep job.&quot;&lt;/span&gt;)
      thread.interrupt()
      thread.join()
    } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
      sc.stop()
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12954427">SPARK-14252</key>
            <summary>Executors do not try to download remote cached blocks</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ekhliang">Eric Liang</assignee>
                                    <reporter username="vanzin">Marcelo Masiero Vanzin</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Mar 2016 21:14:23 +0000</created>
                <updated>Wed, 6 Apr 2016 05:37:40 +0000</updated>
                            <resolved>Wed, 6 Apr 2016 05:37:40 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15216886" author="vanzin" created="Tue, 29 Mar 2016 21:33:16 +0000"  >&lt;p&gt;Here&apos;s a slightly updated piece of code where it&apos;s easier to show the problem:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    val sc = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkContext(conf)
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      val mapCount = sc.accumulator(0L)

      val rdd = sc.parallelize(1 to 10000000, 10).map { i =&amp;gt;
        mapCount += 1
        i
      }.cache()
      rdd.count()

      println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Map count after first count: $mapCount&quot;&lt;/span&gt;)

      &lt;span class=&quot;code-comment&quot;&gt;// Create a single task that will sleep and block, so that a particular executor is busy.
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// This should force &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; tasks to download cached data from that executor.
&lt;/span&gt;      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Running sleep job..&quot;&lt;/span&gt;)
      val thread =  &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Runnable&lt;/span&gt;() {
        override def run(): Unit = {
          rdd.mapPartitionsWithIndex { (i, iter) =&amp;gt;
            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (i == 0) {
              &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(TimeUnit.MINUTES.toMillis(10))
            }
            iter
          }.count()
        }
      })
      thread.setDaemon(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
      thread.start()

      &lt;span class=&quot;code-comment&quot;&gt;// Wait a few seconds to make sure the task is running (too lazy &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; listeners)
&lt;/span&gt;      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; tasks to start...&quot;&lt;/span&gt;)
      TimeUnit.SECONDS.sleep(10)

      &lt;span class=&quot;code-comment&quot;&gt;// Now run a job that will touch everything and should use the cached data.
&lt;/span&gt;      val cnt = rdd.map(_*2).count()
      println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Counted $cnt elements.&quot;&lt;/span&gt;)

      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Killing sleep job.&quot;&lt;/span&gt;)
      thread.interrupt()
      thread.join()

      println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Map count after all tasks finished: $mapCount&quot;&lt;/span&gt;)
    } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
      sc.stop()
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On 1.6. I get:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Map count after first count: 10000000
Map count after all tasks finished: 10000000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On 2.0 I get:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Map count after first count: 10000000
Map count after all tasks finished: 15000000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15227493" author="ekhliang" created="Wed, 6 Apr 2016 01:09:50 +0000"  >&lt;p&gt;I&apos;m going to take a look at fixing this&lt;/p&gt;</comment>
                            <comment id="15227562" author="apachespark" created="Wed, 6 Apr 2016 02:04:03 +0000"  >&lt;p&gt;User &apos;ericl&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12193&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12193&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 32 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2vd7r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>