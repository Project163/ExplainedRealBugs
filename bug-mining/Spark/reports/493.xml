<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:15:35 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-791] [pyspark] operator.getattr not serialized</title>
                <link>https://issues.apache.org/jira/browse/SPARK-791</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Using operator.itemgetter as a function in map seems to confuse the serialization process in pyspark.  I&apos;m using itemgetter to return tuples, which fails with a TypeError (details below).  Using an equivalent lambda function returns the correct result.&lt;/p&gt;

&lt;p&gt;Use a test file:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sh&quot;&gt;echo 1,1 &amp;gt; test.txt
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then try mapping it to a tuple:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-python&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; csv
sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.txt&quot;&lt;/span&gt;).mapPartitions(csv.reader).&lt;span class=&quot;code-object&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;lambda&lt;/span&gt; l: (l[0],l[1])).first()
Out[7]: (&lt;span class=&quot;code-quote&quot;&gt;&apos;1&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;1&apos;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But this does not work when using operator.itemgetter:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-python&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; operator
sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.txt&quot;&lt;/span&gt;).mapPartitions(csv.reader).&lt;span class=&quot;code-object&quot;&gt;map&lt;/span&gt;(operator.itemgetter(0,1)).first()
&lt;span class=&quot;code-comment&quot;&gt;# &lt;span class=&quot;code-object&quot;&gt;TypeError&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;list&lt;/span&gt; indices must be integers, &lt;span class=&quot;code-keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;tuple&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is running with git master, commit 6d60fe571a405eb9306a2be1817901316a46f892&lt;br/&gt;
IPython 0.13.2 &lt;br/&gt;
java version &quot;1.7.0_25&quot;&lt;br/&gt;
Scala code runner version 2.9.1 &lt;br/&gt;
Ubuntu 12.04&lt;/p&gt;

&lt;p&gt;Full debug output:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-python&quot;&gt;In [9]: sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.txt&quot;&lt;/span&gt;).mapPartitions(csv.reader).&lt;span class=&quot;code-object&quot;&gt;map&lt;/span&gt;(operator.itemgetter(0,1)).first()
13/07/04 16:19:49 INFO storage.MemoryStore: ensureFreeSpace(33632) called &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; curMem=201792, maxMem=339585269
13/07/04 16:19:49 INFO storage.MemoryStore: Block broadcast_6 stored &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; values to memory (estimated size 32.8 KB, free 323.6 MB)
13/07/04 16:19:49 INFO mapred.FileInputFormat: Total &lt;span class=&quot;code-object&quot;&gt;input&lt;/span&gt; paths to process : 1
13/07/04 16:19:49 INFO spark.SparkContext: Starting job: takePartition at NativeMethodAccessorImpl.java:-2
13/07/04 16:19:49 INFO scheduler.DAGScheduler: Got job 4 (takePartition at NativeMethodAccessorImpl.java:-2) &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; 1 output partitions (allowLocal=true)
13/07/04 16:19:49 INFO scheduler.DAGScheduler: Final stage: Stage 4 (PythonRDD at NativeConstructorAccessorImpl.java:-2)
13/07/04 16:19:49 INFO scheduler.DAGScheduler: Parents of final stage: List()
13/07/04 16:19:49 INFO scheduler.DAGScheduler: Missing parents: List()
13/07/04 16:19:49 INFO scheduler.DAGScheduler: Computing the requested partition locally
13/07/04 16:19:49 INFO scheduler.DAGScheduler: Failed to run takePartition at NativeMethodAccessorImpl.java:-2
---------------------------------------------------------------------------
Py4JJavaError                             Traceback (most recent call last)
&amp;lt;ipython-&lt;span class=&quot;code-object&quot;&gt;input&lt;/span&gt;-9-1fdb3e7a8ac7&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; &amp;lt;module&amp;gt;()
----&amp;gt; 1 sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.txt&quot;&lt;/span&gt;).mapPartitions(csv.reader).&lt;span class=&quot;code-object&quot;&gt;map&lt;/span&gt;(operator.itemgetter(0,1)).first()

/home/jim/src/spark/python/pyspark/rdd.pyc &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; first(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;)
    389         2
    390         &quot;&quot;&quot;
--&amp;gt; 391         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;.take(1)[0]
    392 
    393     &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; saveAsTextFile(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;, path):

/home/jim/src/spark/python/pyspark/rdd.pyc &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; take(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;, num)
    372         items = []
    373         &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partition &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;._jrdd.splits().size()):
--&amp;gt; 374             iterator = &lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;.ctx._takePartition(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;._jrdd.rdd(), partition)
    375             &lt;span class=&quot;code-comment&quot;&gt;# Each item &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; the iterator &lt;span class=&quot;code-keyword&quot;&gt;is&lt;/span&gt; a string, Python &lt;span class=&quot;code-object&quot;&gt;object&lt;/span&gt;, batch of
&lt;/span&gt;    376             &lt;span class=&quot;code-comment&quot;&gt;# Python objects.  Regardless, it &lt;span class=&quot;code-keyword&quot;&gt;is&lt;/span&gt; sufficient to take `num`
&lt;/span&gt;
/home/jim/src/spark/python/lib/py4j0.7.egg/py4j/java_gateway.pyc &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; __call__(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;, *args)
    498         answer = &lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;.gateway_client.send_command(command)
    499         return_value = get_return_value(answer, &lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;.gateway_client,
--&amp;gt; 500                 &lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;.target_id, &lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;.name)
    501 
    502         &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; temp_arg &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; temp_args:

/home/jim/src/spark/python/lib/py4j0.7.egg/py4j/protocol.pyc &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; get_return_value(answer, gateway_client, target_id, name)
    298                 &lt;span class=&quot;code-keyword&quot;&gt;raise&lt;/span&gt; Py4JJavaError(
    299                     &lt;span class=&quot;code-quote&quot;&gt;&apos;An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling {0}{1}{2}.\n&apos;&lt;/span&gt;.
--&amp;gt; 300                     &lt;span class=&quot;code-object&quot;&gt;format&lt;/span&gt;(target_id, &lt;span class=&quot;code-quote&quot;&gt;&apos;.&apos;&lt;/span&gt;, name), value)
    301             &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
    302                 &lt;span class=&quot;code-keyword&quot;&gt;raise&lt;/span&gt; Py4JError(

Py4JJavaError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling z:spark.api.python.PythonRDD.takePartition.
: spark.api.python.PythonException: Traceback (most recent call last):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/jim/src/spark/python/pyspark/worker.py&quot;&lt;/span&gt;, line 53, &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; main
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; obj &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; func(split_index, iterator):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/jim/src/spark/python/pyspark/serializers.py&quot;&lt;/span&gt;, line 24, &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; batched
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; item &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; iterator:
&lt;span class=&quot;code-object&quot;&gt;TypeError&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;list&lt;/span&gt; indices must be integers, &lt;span class=&quot;code-keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;tuple&lt;/span&gt;

	at spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:117)
	at spark.api.python.PythonRDD$$anon$1.&amp;lt;init&amp;gt;(PythonRDD.scala:139)
	at spark.api.python.PythonRDD.compute(PythonRDD.scala:82)
	at spark.RDD.computeOrReadCheckpoint(RDD.scala:232)
	at spark.RDD.iterator(RDD.scala:221)
	at spark.scheduler.DAGScheduler.runLocallyWithinThread(DAGScheduler.scala:423)
	at spark.scheduler.DAGScheduler$$anon$2.run(DAGScheduler.scala:410)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12704789">SPARK-791</key>
            <summary>[pyspark] operator.getattr not serialized</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="jblomo">Jim Blomo</reporter>
                        <labels>
                    </labels>
                <created>Thu, 4 Jul 2013 16:27:33 +0000</created>
                <updated>Tue, 29 Jul 2014 08:18:47 +0000</updated>
                            <resolved>Tue, 29 Jul 2014 08:18:33 +0000</resolved>
                                    <version>0.7.2</version>
                    <version>0.9.0</version>
                    <version>1.0.0</version>
                                    <fixVersion>0.9.3</fixVersion>
                    <fixVersion>1.0.3</fixVersion>
                    <fixVersion>1.1.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="13953127" author="joshrosen" created="Sun, 28 Jul 2013 21:00:45 +0000"  >&lt;p&gt;I think this is a problem with how operator.itemgetter is serialized, because&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.txt&quot;&lt;/span&gt;).mapPartitions(csv.reader).map(lambda x: &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;.itemgetter(0, 1)(x)).first()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;works for me, while&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.txt&quot;&lt;/span&gt;).mapPartitions(csv.reader).map(&lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;.itemgetter(0, 1)).first()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;gives the error that you saw.  Interestingly, the example works fine if I only specify a single index, e.g. operator.itemgetter(0).&lt;/p&gt;

&lt;p&gt;To get a bit more insight into what&apos;s going on, I used pickletools.dis to log the pickled functions (specifically, I used pickletools.dis(pickletools.optimize(cloudpickle.dumps(func))) with the extra optimization added to remove unnecessary PUTs in order to make the output easier to read).  For &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.txt&quot;&lt;/span&gt;).mapPartitions(csv.reader).cache().map(&lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;.itemgetter(0, 1)).first()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;the second map function&apos;s pickled form disassembles into&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;     0: \x80 PROTO      2
    2: (    MARK
    3: c        GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;pyspark.cloudpickle _modules_to_main&apos;&lt;/span&gt;
   41: q        BINPUT     0
   43: ]        EMPTY_LIST
   44: U        SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;pyspark.rdd&apos;&lt;/span&gt;
   57: q        BINPUT     2
   59: a        APPEND
   60: \x85     TUPLE1
   61: R        REDUCE
   62: 1        POP_MARK   (MARK at 2)
   63: c    GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;pyspark.cloudpickle _fill_function&apos;&lt;/span&gt;
   99: q    BINPUT     4
  101: (    MARK
  102: c        GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;pyspark.cloudpickle _make_skel_func&apos;&lt;/span&gt;
  139: q        BINPUT     5
  141: c        GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; code&apos;&lt;/span&gt;
  151: q        BINPUT     6
  153: (        MARK
  154: K            BININT1    2
  156: K            BININT1    2
  158: K            BININT1    4
  160: K            BININT1    19
  162: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;t\x00\x00\x88\x00\x00|\x00\x00|\x01\x00\x83\x02\x00\x88\x01\x00\x83\x02\x00S&apos;&lt;/span&gt;
  186: N            NONE
  187: \x85         TUPLE1
  188: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;batched&apos;&lt;/span&gt;
  197: q            BINPUT     9
  199: \x85         TUPLE1
  200: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;split&apos;&lt;/span&gt;
  207: q            BINPUT     11
  209: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;iterator&apos;&lt;/span&gt;
  219: q            BINPUT     12
  221: \x86         TUPLE2
  222: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;/Users/joshrosen/Documents/spark/spark/python/pyspark/rdd.py&apos;&lt;/span&gt;
  284: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;batched_func&apos;&lt;/span&gt;
  298: M            BININT2    725
  301: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;\x00\x01&apos;&lt;/span&gt;
  305: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;oldfunc&apos;&lt;/span&gt;
  314: U            SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;batchSize&apos;&lt;/span&gt;
  325: \x86         TUPLE2
  326: )            EMPTY_TUPLE
  327: t            TUPLE      (MARK at 153)
  328: R        REDUCE
  329: K        BININT1    2
  331: }        EMPTY_DICT
  332: q        BINPUT     22
  334: \x87     TUPLE3
  335: R        REDUCE
  336: }        EMPTY_DICT
  337: h        BINGET     9
  339: c        GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;pyspark.serializers batched&apos;&lt;/span&gt;
  368: s        SETITEM
  369: N        NONE
  370: ]        EMPTY_LIST
  371: (        MARK
  372: (            MARK
  373: h                BINGET     0
  375: ]                EMPTY_LIST
  376: h                BINGET     2
  378: a                APPEND
  379: \x85             TUPLE1
  380: R                REDUCE
  381: 1                POP_MARK   (MARK at 372)
  382: h            BINGET     4
  384: (            MARK
  385: h                BINGET     5
  387: h                BINGET     6
  389: (                MARK
  390: K                    BININT1    2
  392: K                    BININT1    2
  394: K                    BININT1    3
  396: K                    BININT1    19
  398: U                    SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;t\x00\x00\x88\x00\x00|\x01\x00\x83\x02\x00S&apos;&lt;/span&gt;
  413: N                    NONE
  414: \x85                 TUPLE1
  415: U                    SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;imap&apos;&lt;/span&gt;
  421: q                    BINPUT     32
  423: \x85                 TUPLE1
  424: h                    BINGET     11
  426: h                    BINGET     12
  428: \x86                 TUPLE2
  429: U                    SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;/Users/joshrosen/Documents/spark/spark/python/pyspark/rdd.py&apos;&lt;/span&gt;
  491: U                    SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;func&apos;&lt;/span&gt;
  497: K                    BININT1    87
  499: U                    SHORT_BINSTRING &apos;&apos;
  501: U                    SHORT_BINSTRING &lt;span class=&quot;code-quote&quot;&gt;&apos;f&apos;&lt;/span&gt;
  504: \x85                 TUPLE1
  505: )                    EMPTY_TUPLE
  506: t                    TUPLE      (MARK at 389)
  507: R                REDUCE
  508: K                BININT1    1
  510: h                BINGET     22
  512: \x87             TUPLE3
  513: R                REDUCE
  514: }                EMPTY_DICT
  515: h                BINGET     32
  517: c                GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;itertools imap&apos;&lt;/span&gt;
  533: s                SETITEM
  534: N                NONE
  535: ]                EMPTY_LIST
  536: c                GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; itemgetter&apos;&lt;/span&gt;
  557: K                BININT1    0
  559: K                BININT1    1
  561: \x86             TUPLE2
  562: \x85             TUPLE1
  563: R                REDUCE
  564: a                APPEND
  565: }                EMPTY_DICT
  566: t                TUPLE      (MARK at 384)
  567: R            REDUCE
  568: M            BININT2    1024
  571: e            APPENDS    (MARK at 371)
  572: }        EMPTY_DICT
  573: t        TUPLE      (MARK at 101)
  574: R    REDUCE
  575: .    STOP
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It looks like something strange is happening to operator.itemgetter:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  536: c                GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; itemgetter&apos;&lt;/span&gt;
  557: K                BININT1    0
  559: K                BININT1    1
  561: \x86             TUPLE2
  562: \x85             TUPLE1
  563: R                REDUCE
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It&apos;s supposed to be constructed using two arguments, 0 and 1, but instead it looks like it&apos;s being constructed with (0, 1).  To verify this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pickle
s = &lt;span class=&quot;code-quote&quot;&gt;&quot;coperator\nitemgetter\nK\x00K\x01\x86\x85R.&quot;&lt;/span&gt;
op = pickle.loads(s)
t = [1, 2, 2, 3]
print op(t)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;gives &quot;TypeError: list indices must be integers, not tuple&quot;.&lt;/p&gt;

&lt;p&gt;If I leave off the extra TUPLE1 opcode, then this works as expected:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pickle
s = &lt;span class=&quot;code-quote&quot;&gt;&quot;coperator\nitemgetter\nK\x00K\x01\x86R.&quot;&lt;/span&gt;
op = pickle.loads(s)
t = [1, 2, 2, 3]
print op(t)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;gives (1, 2).&lt;/p&gt;

&lt;p&gt;I&apos;m guessing this is a problem in the CloudPickle library, but it might take me a while to find and fix it.&lt;/p&gt;</comment>
                            <comment id="13953237" author="schumach" created="Tue, 27 Aug 2013 14:31:34 +0000"  >&lt;p&gt;Just an observation: the same error occurs with the cloudpickler from cloud-2.8.5 from 2013-08-21. If it&apos;s a problem with the library, maybe one should file a bug report there?&lt;/p&gt;</comment>
                            <comment id="13953574" author="joshrosen" created="Thu, 23 Jan 2014 16:56:12 +0000"  >&lt;p&gt;Quick update: It looks like the Dill serialization library handles this case properly, but there are a couple of issues to work out before we can consider switching to it: &lt;a href=&quot;https://mail-archives.apache.org/mod_mbox/spark-dev/201312.mbox/%3CCAOEPXP5hu-dhGnjQq=RYdT35G-eeEYPVopgqQdf2NFxRB7vA_g@mail.gmail.com%3E&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://mail-archives.apache.org/mod_mbox/spark-dev/201312.mbox/%3CCAOEPXP5hu-dhGnjQq=RYdT35G-eeEYPVopgqQdf2NFxRB7vA_g@mail.gmail.com%3E&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13988698" author="airhorns" created="Sat, 3 May 2014 14:20:52 +0000"  >&lt;p&gt;Hey Josh, looks like that issue mentioned in that thread has been fixed in Dill: &lt;a href=&quot;https://github.com/uqfoundation/dill/issues/18&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/uqfoundation/dill/issues/18&lt;/a&gt;. Anecdotally playing around with Dill I&apos;ve found it a bit more friendly than Cloudpickle and as you mentioned the actively-maintained status of it is really encouraging. Would you mind if I tried to rebase your port to Dill on top of current master and opened a PR?&lt;/p&gt;</comment>
                            <comment id="14034779" author="distobj" created="Wed, 18 Jun 2014 03:52:58 +0000"  >&lt;p&gt;I began porting Pyspark to Python 3, but with my modest Python-fu, hit a wall at cloudpickle. Dill supports Python 3, so seems like a big win in that direction too.&lt;/p&gt;</comment>
                            <comment id="14077239" author="davies" created="Tue, 29 Jul 2014 01:10:37 +0000"  >&lt;p&gt;This will be fixed by PR-1627&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://github.com/apache/spark/pull/1627&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/1627&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12704537">SPARK-1091</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>383151</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 17 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1u0d3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>383419</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12327168">1.0.2</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>