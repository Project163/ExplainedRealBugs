<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:43:38 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-48965] toJSON produces wrong values if DecimalType information is lost in as[Product]</title>
                <link>https://issues.apache.org/jira/browse/SPARK-48965</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Consider this example:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-scala&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt; com.jetbrains.jetstat.etl

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.SparkSession
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.types.DecimalType

&lt;span class=&quot;code-keyword&quot;&gt;object&lt;/span&gt; A {
  &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Example(x: BigDecimal)

  &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; main(args: Array[String]): Unit = {
    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; spark = SparkSession.builder()
      .master(&lt;span class=&quot;code-quote&quot;&gt;&quot;local[1]&quot;&lt;/span&gt;)
      .getOrCreate()

    &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; spark.implicits._

    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; originalRaw = BigDecimal(&lt;span class=&quot;code-quote&quot;&gt;&quot;123.456&quot;&lt;/span&gt;)
    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; original = Example(originalRaw)

    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; ds1 = spark.createDataset(Seq(original))
    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; ds2 = ds1
      .withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x&quot;&lt;/span&gt;, $&lt;span class=&quot;code-quote&quot;&gt;&quot;x&quot;&lt;/span&gt; cast DecimalType(12, 6))

    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; ds3 = ds2
      .as[Example]

    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;DS1: schema=${ds1.schema}, encoder.schema=${ds1.encoder.schema}&quot;&lt;/span&gt;)
    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;DS2: schema=${ds1.schema}, encoder.schema=${ds2.encoder.schema}&quot;&lt;/span&gt;)
    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;DS3: schema=${ds1.schema}, encoder.schema=${ds3.encoder.schema}&quot;&lt;/span&gt;)

    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; json1 = ds1.toJSON.collect().head
    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; json2 = ds2.toJSON.collect().head
    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; json3 = ds3.toJSON.collect().head

    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; collect1 = ds1.collect().head
    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; collect2_ = ds2.collect().head
    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; collect2 = collect2_.getDecimal(collect2_.fieldIndex(&lt;span class=&quot;code-quote&quot;&gt;&quot;x&quot;&lt;/span&gt;))
    &lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; collect3 = ds3.collect().head

    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Original: $original (scale = ${original.x.scale}, precision = ${original.x.precision})&quot;&lt;/span&gt;)
    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Collect1: $collect1 (scale = ${collect1.x.scale}, precision = ${collect1.x.precision})&quot;&lt;/span&gt;)
    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Collect2: $collect2 (scale = ${collect2.scale}, precision = ${collect2.precision})&quot;&lt;/span&gt;)
    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Collect3: $collect3 (scale = ${collect3.x.scale}, precision = ${collect3.x.precision})&quot;&lt;/span&gt;)
    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;json1: $json1&quot;&lt;/span&gt;)
    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;json2: $json2&quot;&lt;/span&gt;)
    println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;json3: $json3&quot;&lt;/span&gt;)
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Running it you&apos;d see that json3 contains very much wrong data. After a bit of debugging, and sorry since I&apos;m bad with Spark internals, I&apos;ve found that:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;In-memory representation of the data in this example used &lt;tt&gt;UnsafeRow&lt;/tt&gt;, whose &lt;tt&gt;.getDecimal&lt;/tt&gt; uses compression to store small Decimal values as longs, but doesn&apos;t remember decimal sizing parameters,&lt;/li&gt;
	&lt;li&gt;However, there are at least two sources for precision &amp;amp; scale to pass to that method: &lt;tt&gt;Dataset.schema&lt;/tt&gt; (which is based on query execution, always contains 38,18 for me) and &lt;tt&gt;Dataset.encoder.schema&lt;/tt&gt; (that gets updated in `ds2` to 12,6 but then is reset in `ds3`). Also, there is a &lt;tt&gt;Dataset.deserializer&lt;/tt&gt; that seems to be combining those two non-trivially.&lt;/li&gt;
	&lt;li&gt;This doesn&apos;t seem to affect &lt;tt&gt;Dataset.collect()&lt;/tt&gt; methods since they use &lt;tt&gt;deserializer&lt;/tt&gt;, but &lt;tt&gt;Dataset.toJSON&lt;/tt&gt; only uses the first schema.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Seems to me that either &lt;tt&gt;.toJSON&lt;/tt&gt; should be more aware of what&apos;s going on or &lt;tt&gt;.as[]&lt;/tt&gt; should be doing something else.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13586566">SPARK-48965</key>
            <summary>toJSON produces wrong values if DecimalType information is lost in as[Product]</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bersprockets">Bruce Robbins</assignee>
                                    <reporter username="LDVSoft">Dmitry Lapshin</reporter>
                        <labels>
                            <label>correctness</label>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 22 Jul 2024 18:39:39 +0000</created>
                <updated>Tue, 10 Sep 2024 20:20:51 +0000</updated>
                            <resolved>Thu, 5 Sep 2024 04:59:52 +0000</resolved>
                                    <version>3.1.1</version>
                    <version>3.5.1</version>
                                    <fixVersion>3.4.4</fixVersion>
                    <fixVersion>3.5.3</fixVersion>
                    <fixVersion>4.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17867857" author="JIRAUSER284238" created="Mon, 22 Jul 2024 19:34:22 +0000"  >&lt;p&gt;I might&apos;ve overlooked some internals, but it&apos;s definitely a conflict between &lt;tt&gt;encoder&lt;/tt&gt;/&lt;tt&gt;exprEnc&lt;/tt&gt;/&lt;tt&gt;resolvedEnc&lt;/tt&gt; schema and &lt;tt&gt;queryExecution&lt;/tt&gt; schema.&lt;/p&gt;</comment>
                            <comment id="17874352" author="bersprockets" created="Fri, 16 Aug 2024 18:20:15 +0000"  >&lt;p&gt;It&apos;s not just decimals. &lt;tt&gt;toJSON&lt;/tt&gt; is simply using the wrong schema. For example:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; case class Data(x: Int, y: String)
class Data

scala&amp;gt; sql(&quot;select &apos;Hey there&apos; as y, 22 as x&quot;).as[Data].collect
warning: 1 deprecation (since 2.13.3); for details, enable `:setting -deprecation` or `:replay -deprecation`
val res0: Array[Data] = Array(Data(22,Hey there))

scala&amp;gt; sql(&quot;select &apos;Hey there&apos; as y, 22 as x&quot;).as[Data].toJSON.collect
warning: 1 deprecation (since 2.13.3); for details, enable `:setting -deprecation` or `:replay -deprecation`
val res1: Array[String] = Array({&quot;y&quot;:&quot;\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000\u0000\u0000\u0000\u0000\u0000\u0000\t\u0000\u0000\u0000\u0018\u0000&quot;,&quot;x&quot;:9})
scala&amp;gt; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Edit: Even more interesting, you can crash the JVM:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; case class Data(x: Array[Int], y: String)
class Data

scala&amp;gt; sql(&quot;select repeat(&apos;Hey there&apos;, 17) as y, array_repeat(22, 17) as x&quot;).as[Data].collect
warning: 1 deprecation (since 2.13.3); for details, enable `:setting -deprecation` or `:replay -deprecation`
val res0: Array[Data] = Array(Data([I@3ca370ae,Hey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey thereHey there))

scala&amp;gt; sql(&quot;select repeat(&apos;Hey there&apos;, 17) as y, array_repeat(22, 17) as x&quot;).as[Data].toJSON.collect
warning: 1 deprecation (since 2.13.3); for details, enable `:setting -deprecation` or `:replay -deprecation`
Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.InternalError: a fault occurred in a recent unsafe memory access operation in compiled Java code
	at org.apache.spark.sql.catalyst.json.JacksonGenerator.$anonfun$makeWriter$5(JacksonGenerator.scala:129) ~[spark-catalyst_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
	at org.apache.spark.sql.catalyst.json.JacksonGenerator.$anonfun$makeWriter$5$adapted(JacksonGenerator.scala:128) ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17878658" author="bersprockets" created="Mon, 2 Sep 2024 21:26:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=LDVSoft&quot; class=&quot;user-hover&quot; rel=&quot;LDVSoft&quot;&gt;LDVSoft&lt;/a&gt; are you looking to fix this? If not, I could submit a fix.&lt;/p&gt;</comment>
                            <comment id="17879178" author="JIRAUSER284238" created="Wed, 4 Sep 2024 10:41:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bersprockets&quot; class=&quot;user-hover&quot; rel=&quot;bersprockets&quot;&gt;bersprockets&lt;/a&gt; Sorry, I don&apos;t have that good of a grasp on Spark internals to do so atm. I see you&apos;ve submitted a PR, thanks for that!&lt;/p&gt;

&lt;p&gt;I see that your change is basically a one-liner, and that makes sense to me but it also raises a question for me if I as external user should trust Dataset.schema, if expressionEncoder uses a different one.&lt;/p&gt;</comment>
                            <comment id="17879263" author="bersprockets" created="Wed, 4 Sep 2024 15:18:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=LDVSoft&quot; class=&quot;user-hover&quot; rel=&quot;LDVSoft&quot;&gt;LDVSoft&lt;/a&gt; &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;it also raises a question for me if I as external user should trust Dataset.schema&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Good question. Certainly, this is an oddity:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; case class Data(a: BigDecimal)
class Data

scala&amp;gt; val ds = sql(&quot;select 123.456bd as a&quot;).as[Data]
val ds: org.apache.spark.sql.Dataset[Data] = [a: decimal(6,3)]

scala&amp;gt; ds.printSchema
warning: 1 deprecation (since 2.13.3); for details, enable `:setting -deprecation` or `:replay -deprecation`
root
 |-- a: decimal(6,3) (nullable = false)


scala&amp;gt; ds.map(identity).printSchema
warning: 1 deprecation (since 2.13.3); for details, enable `:setting -deprecation` or `:replay -deprecation`
root
 |-- a: decimal(38,18) (nullable = true)


scala&amp;gt; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;tt&gt;map(identity)&lt;/tt&gt; performs no transformations, yet the precision changes in the schema. Not sure if this is intentional, or an oversight. Needs some research.&lt;/p&gt;</comment>
                            <comment id="17879308" author="JIRAUSER284238" created="Wed, 4 Sep 2024 17:18:38 +0000"  >&lt;p&gt;In my experience `.as[]` is more of type punning operation (it will check that all columns are present, but it won&apos;t, for example, remove extra columns, also different versions of Spark handle nullability here differently), and also encoders created from BigDecimal fields don&apos;t carry any precision information, since there is no source. The only way to protect those fields is not to write operations that actually operate on deserialised rows, and that kinda sends you to DataFrame-only world.&lt;/p&gt;

&lt;p&gt;So in our code we usually have wrappers around read/write operation that do more thorough schema validation (including differences between file/table formats), including special side channel information on what expected width/precision is for decimals.&lt;/p&gt;</comment>
                            <comment id="17879422" author="dongjoon" created="Thu, 5 Sep 2024 04:59:52 +0000"  >&lt;p&gt;Issue resolved by pull request 47982&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/47982&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/47982&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 9 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1qgy0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>