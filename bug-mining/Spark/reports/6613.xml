<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:06:20 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21067] Thrift Server - CTAS fail with Unable to move source</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21067</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;After upgrading our Thrift cluster to 2.1.1, we ran into an issue where CTAS would fail, sometimes...&lt;/p&gt;

&lt;p&gt;Most of the time, the CTAS would work only once, after starting the thrift server. After that, dropping the table and re-issuing the same CTAS would fail with the following message (Sometime, it fails right away, sometime it work for a long period of time):&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Error: org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://nameservice1//tmp/hive-staging/thrift_hive_2017-06-12_16-56-18_464_7598877199323198104-31/-ext-10000/part-00000 to destination hdfs://nameservice1/user/hive/warehouse/dricard.db/test/part-00000; (state=,code=0)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We have already found the following Jira (&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-11021&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-11021&lt;/a&gt;) which state that the &lt;tt&gt;hive.exec.stagingdir&lt;/tt&gt; had to be added in order for Spark to be able to handle CREATE TABLE properly as of 2.0. As you can see in the error, we have ours set to &quot;/tmp/hive-staging/{user.name}&quot;&lt;/p&gt;

&lt;p&gt;Same issue with INSERT statements:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;CREATE TABLE IF NOT EXISTS dricard.test (col1 int); INSERT INTO TABLE dricard.test SELECT 1;
Error: org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://nameservice1/tmp/hive-staging/thrift_hive_2017-06-12_20-41-12_964_3086448130033637241-16/-ext-10000/part-00000 to destination hdfs://nameservice1/user/hive/warehouse/dricard.db/test/part-00000; (state=,code=0)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This worked fine in 1.6.2, which we currently run in our Production Environment but since 2.0+, we haven&apos;t been able to CREATE TABLE consistently on the cluster.&lt;/p&gt;

&lt;p&gt;SQL to reproduce issue:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;DROP SCHEMA IF EXISTS dricard CASCADE; 
CREATE SCHEMA dricard; 
CREATE TABLE dricard.test (col1 int); 
INSERT INTO TABLE dricard.test SELECT 1; 
SELECT * from dricard.test; 
DROP TABLE dricard.test; 
CREATE TABLE dricard.test AS select 1 as `col1`;
SELECT * from dricard.test
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thrift server usually fails at INSERT...&lt;/p&gt;

&lt;p&gt;Tried the same procedure in a spark context using spark.sql() and didn&apos;t encounter the same issue.&lt;/p&gt;

&lt;p&gt;Full stack Trace:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;17/06/14 14:52:18 ERROR thriftserver.SparkExecuteStatementOperation: Error executing query, currentState RUNNING,
org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://nameservice1/tmp/hive-staging/thrift_hive_2017-06-14_14-52-18_521_5906917519254880890-5/-ext-10000/part-00000 to desti
nation hdfs://nameservice1/user/hive/warehouse/dricard.db/test/part-00000;
        at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:106)
        at org.apache.spark.sql.hive.HiveExternalCatalog.loadTable(HiveExternalCatalog.scala:766)
        at org.apache.spark.sql.hive.execution.InsertIntoHiveTable.sideEffectResult$lzycompute(InsertIntoHiveTable.scala:374)
        at org.apache.spark.sql.hive.execution.InsertIntoHiveTable.sideEffectResult(InsertIntoHiveTable.scala:221)
        at org.apache.spark.sql.hive.execution.InsertIntoHiveTable.doExecute(InsertIntoHiveTable.scala:407)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)
        at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)
        at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)
        at org.apache.spark.sql.Dataset.&amp;lt;init&amp;gt;(Dataset.scala:185)
        at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:64)
        at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:592)
        at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:699)
        at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:231)
        at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1$$anon$2.run(SparkExecuteStatementOperation.scala:174)
        at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1$$anon$2.run(SparkExecuteStatementOperation.scala:171)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
        at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$1.run(SparkExecuteStatementOperation.scala:184)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://nameservice1/tmp/hive-staging/thrift_hive_2017-06-14_14-52-18_521_5906917519254880890-5/-ext-10000/part-00000 to destination hdfs://nameservice1/user/hive/warehouse/dricard.db/test/part-00000
        at org.apache.hadoop.hive.ql.metadata.Hive.moveFile(Hive.java:2644)
        at org.apache.hadoop.hive.ql.metadata.Hive.copyFiles(Hive.java:2711)
        at org.apache.hadoop.hive.ql.metadata.Hive.loadTable(Hive.java:1645)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.spark.sql.hive.client.Shim_v0_14.loadTable(HiveShim.scala:728)
        at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$loadTable$1.apply$mcV$sp(HiveClientImpl.scala:676)
        at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$loadTable$1.apply(HiveClientImpl.scala:676)
        at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$loadTable$1.apply(HiveClientImpl.scala:676)
        at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$withHiveState$1.apply(HiveClientImpl.scala:279)
        at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:226)
        at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:225)
        at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:268)
        at org.apache.spark.sql.hive.client.HiveClientImpl.loadTable(HiveClientImpl.scala:675)
        at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$loadTable$1.apply$mcV$sp(HiveExternalCatalog.scala:768)
        at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$loadTable$1.apply(HiveExternalCatalog.scala:766)
        at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$loadTable$1.apply(HiveExternalCatalog.scala:766)
        at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)
        ... 28 more
Caused by: java.io.IOException: Filesystem closed
        at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
        at org.apache.hadoop.hdfs.DFSClient.getEZForPath(DFSClient.java:3288)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getEZForPath(DistributedFileSystem.java:2093)
        at org.apache.hadoop.hdfs.client.HdfsAdmin.getEncryptionZoneForPath(HdfsAdmin.java:289)
        at org.apache.hadoop.hive.shims.Hadoop23Shims$HdfsEncryptionShim.isPathEncrypted(Hadoop23Shims.java:1221)
        at org.apache.hadoop.hive.ql.metadata.Hive.moveFile(Hive.java:2607)
        ... 47 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;Yarn&lt;br/&gt;
Hive MetaStore&lt;br/&gt;
HDFS (HA)&lt;/p&gt;</environment>
        <key id="13079307">SPARK-21067</key>
            <summary>Thrift Server - CTAS fail with Unable to move source</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="4">Incomplete</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="dricard">Dominic Ricard</reporter>
                        <labels>
                            <label>bulk-closed</label>
                    </labels>
                <created>Mon, 12 Jun 2017 20:49:00 +0000</created>
                <updated>Tue, 25 May 2021 01:52:34 +0000</updated>
                            <resolved>Tue, 25 May 2021 01:38:02 +0000</resolved>
                                    <version>2.1.1</version>
                    <version>2.2.0</version>
                    <version>2.4.0</version>
                    <version>2.4.3</version>
                                                    <component>SQL</component>
                        <due></due>
                            <votes>6</votes>
                                    <watches>15</watches>
                                                                                                                <comments>
                            <comment id="16062368" author="q79969786" created="Sun, 25 Jun 2017 16:04:44 +0000"  >&lt;p&gt;Are you enable &lt;a href=&quot;http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/Federation.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;HDFS Federation&lt;/a&gt;? Try to add this configure to &lt;tt&gt;hive-site.xml&lt;/tt&gt;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hive.exec.stagingdir&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;code-tag&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/user/hive/warehouse/staging/.hive-staging&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;code-tag&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16064833" author="dricard" created="Tue, 27 Jun 2017 13:31:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=q79969786&quot; class=&quot;user-hover&quot; rel=&quot;q79969786&quot;&gt;q79969786&lt;/a&gt;, yes. As stated in the description, ours is set to &quot;/tmp/hive-staging/{user.name}&quot;&lt;/p&gt;</comment>
                            <comment id="16080399" author="dricard" created="Mon, 10 Jul 2017 14:25:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=q79969786&quot; class=&quot;user-hover&quot; rel=&quot;q79969786&quot;&gt;q79969786&lt;/a&gt; Using the setting proposed, I get the same error on my 2nd session of Beeline:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Error: org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs://nameservice1/user/hive/warehouse/staging/.hive-staging_hive_2017-07-10_14-17-43_389_2840765500912655498-3/-ext-10000/part-00000 to destination hdfs://nameservice1/user/hive/warehouse/dricard.db/test/part-00000; (state=,code=0)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This is what makes this very frustrating. The 1st session seems to work without issues. After closing and restarting Beeline, the same queries gives out the error...&lt;/p&gt;</comment>
                            <comment id="16080503" author="dricard" created="Mon, 10 Jul 2017 15:28:38 +0000"  >&lt;p&gt;Interesting findings today.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Open &lt;b&gt;&lt;font color=&quot;#59afe1&quot;&gt;Beeline Session 1&lt;/font&gt;&lt;/b&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;Create Table 1 (Success)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Open &lt;b&gt;&lt;font color=&quot;#14892c&quot;&gt;Beeline Session 2&lt;/font&gt;&lt;/b&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;Create Table 2 (Success)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Close &lt;b&gt;&lt;font color=&quot;#59afe1&quot;&gt;Beeline Session 1&lt;/font&gt;&lt;/b&gt;&lt;/li&gt;
	&lt;li&gt;Create Table 3 in &lt;b&gt;&lt;font color=&quot;#14892c&quot;&gt;Beeline Session 2&lt;/font&gt;&lt;/b&gt; (&lt;font color=&quot;#d04437&quot;&gt;FAIL&lt;/font&gt;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So, it seems like the problem occurs after the 1st session is closed. What does the Thrift server do when a session is closed that could cause this issue?&lt;/p&gt;

&lt;p&gt;Looking at the Hive Metastore logs, I notice that the same SQL query (CREATE TABLE ...) translate to different actions between the 1st and later sessions:&lt;/p&gt;

&lt;p&gt;Session 1:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;...
PERFLOG method=create_table_with_environment_context from=org.apache.hadoop.hive.metastore.RetryingHMSHandler
...
PERFLOG method=alter_table_with_cascade from=org.apache.hadoop.hive.metastore.RetryingHMSHandler
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Session 2:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;...
PERFLOG method=create_table_with_environment_context from=org.apache.hadoop.hive.metastore.RetryingHMSHandler&amp;gt;
...
PERFLOG method=drop_table_with_environment_context from=org.apache.hadoop.hive.metastore.RetryingHMSHandler
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16082441" author="dricard" created="Tue, 11 Jul 2017 16:09:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; Hey Xiao, I see that you have made many contribution around CREATE TABLE issues. Could you shed some light on this issue? We are either looking for a fix or for a property to set hive.default.fileformat in Spark 2 to have it use parquet instead of textfile, since the issue is not present when the fileformat is set to &quot;parquet&quot;. &lt;/p&gt;

&lt;p&gt;Looks like your Pull Request to add spark.sql.default.fileformat (&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16825&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-16825&lt;/a&gt;) did not go in and that would have solve the issue with default store / fileformat...&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;

&lt;p&gt;FWD: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;, you might also know how this can be resolved...&lt;/p&gt;</comment>
                            <comment id="16103202" author="zhangxin0112zx" created="Thu, 27 Jul 2017 13:27:16 +0000"  >&lt;p&gt;same here.&lt;br/&gt;
problem  reappeared in Spark 2.1.0 thriftserver :&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
Open Beeline Session 1&lt;br/&gt;
Create Table 1 (Success)&lt;br/&gt;
Open Beeline Session 2&lt;br/&gt;
Create Table 2 (Success)&lt;br/&gt;
Close Beeline Session 1&lt;br/&gt;
Create Table 3 in Beeline Session 2 (FAIL)&lt;br/&gt;
&amp;lt;&amp;lt;&amp;lt;&amp;lt;&lt;br/&gt;
use parquet,  the issue is not present .&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16104918" author="cloud_fan" created="Fri, 28 Jul 2017 13:06:31 +0000"  >&lt;p&gt;We have many tests for CREATE TABLE inside Spark SQL, so I think this issue is thrift-server specific.&lt;/p&gt;

&lt;p&gt;However I&apos;m not familiar with the thrift-server code, cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt; do you know who is the maintainer?&lt;/p&gt;</comment>
                            <comment id="16108303" author="zhangxin0112zx" created="Tue, 1 Aug 2017 02:41:24 +0000"  >&lt;p&gt;hi .&lt;br/&gt;
 I use the parquet to avoid the issuse about create table as.&lt;br/&gt;
It appear in insert overwrite table (partition). I could not find any ways to avoid this issuse ?Any suggests will be great helpful.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-21725&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-21725&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16119310" author="zhangxin0112zx" created="Wed, 9 Aug 2017 02:03:23 +0000"  >&lt;p&gt;hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt;&lt;br/&gt;
Can you push this BUG repair? &lt;br/&gt;
In my consideration, this is a very big obstacle for us when we go to popularization and use SparkSQL(thriftserver).&lt;/p&gt;</comment>
                            <comment id="16158192" author="zhangxin0112zx" created="Fri, 8 Sep 2017 06:36:52 +0000"  >&lt;p&gt;hi  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dricard&quot; class=&quot;user-hover&quot; rel=&quot;dricard&quot;&gt;dricard&lt;/a&gt;&lt;br/&gt;
do u have any solutions now? &lt;br/&gt;
any suggests will helpful.&lt;/p&gt;</comment>
                            <comment id="16158802" author="dricard" created="Fri, 8 Sep 2017 15:39:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhangxin0112zx&quot; class=&quot;user-hover&quot; rel=&quot;zhangxin0112zx&quot;&gt;zhangxin0112zx&lt;/a&gt; Our solution was to migrate the CTAS code to use Parquet... CTAS for Hive Tables is Broken when using the Thrift server.&lt;/p&gt;

&lt;p&gt;Still looking forward for a fix to this issue...&lt;/p&gt;</comment>
                            <comment id="16160550" author="zhangxin0112zx" created="Mon, 11 Sep 2017 02:00:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dricard&quot; class=&quot;user-hover&quot; rel=&quot;dricard&quot;&gt;dricard&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks for your reply.&lt;br/&gt;
So do we . Use the parquet . But another pro is when u use sql like &quot;insert overwrite table a partition(pt=&apos;2&apos;) select....&quot; . &lt;br/&gt;
It will also cause the thriftserver fail . Do you happen to have the same problem?&lt;br/&gt;
Only happend with the table which use partitions . this all right when use parquet without partition. &quot;insert overwrite table a  select....&quot;&lt;/p&gt;</comment>
                            <comment id="16235127" author="zhangxin0112zx" created="Thu, 2 Nov 2017 03:36:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dricard&quot; class=&quot;user-hover&quot; rel=&quot;dricard&quot;&gt;dricard&lt;/a&gt;&lt;br/&gt;
Please check issue here link and try .&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-21725&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-21725&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16774675" author="xinxianyin" created="Fri, 22 Feb 2019 01:54:30 +0000"  >&lt;p&gt;Upload a patch which is based on 2.3.2.&lt;/p&gt;</comment>
                            <comment id="16789589" author="moriarty279" created="Mon, 11 Mar 2019 13:54:05 +0000"  >&lt;p&gt;Spark 2.4.0 still has the same problem. And I want to&#160;elaborate a bit more about how this bug happens.&lt;br/&gt;
 &#160;&lt;br/&gt;
 To reproduce this bug, we have to set hive.server2.enable.doAs to true in hive-site.xml. It causes SparkThriftServer to execute&#160;&lt;/p&gt;

&lt;p&gt;SparkExecuteStatementOperation&#160;with&#160;org.apache.hive.service.cli.session.HiveSessionImplwithUGI#sessionUgi.&lt;/p&gt;

&lt;p&gt;When the first time a&#160;CTAS statement is executed, HiveClientImpl#state#hdfsEncryptionShim#hdfsAdmin#dfs is initialized&#160;using ugi&#160;from&#160;HiveSessionImplwithUGI#sessionUgi. HiveClientImpl#state#hdfsEncryptionShim#hdfsAdmin#dfs&#160;will be closed when session closes.&lt;/p&gt;

&lt;p&gt;Since&#160;HiveClientImpl is shared among&#160;SparkThriftServer and&#160;HiveClientImpl#state#hdfsEncryptionShim won&apos;t be initialized again, subsequent&#160; usage of&#160;HiveClientImpl#state#hdfsEncryptionShim will throw &quot;java.io.IOException: Filesystem closed&quot;.&lt;/p&gt;

&lt;p&gt;Here is a simpler&#160;way&#160;to reproduce:&lt;/p&gt;

&lt;p&gt;1. Open&#160;Session1 with beeline and execute SQL:&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
CREATE TABLE tbl (i &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;);
INSERT INTO tbl SELECT 1;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;2. Close Session1&lt;/p&gt;

&lt;p&gt;3. Open&#160;Session2 with beeline and execute SQL:&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
INSERT INTO tbl SELECT 1;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;4. Get exception in Session2:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Error: org.apache.spark.sql.AnalysisException: org.apache.hadoop.hive.ql.metadata.HiveException: Unable to move source hdfs:&lt;span class=&quot;code-comment&quot;&gt;//xxx/user/hive/warehouse/tbl/.hive-staging_hive_2019-03-11_20-22-53_627_4903214085803350096-2/-ext-10000/part-00000-b6277b02-c70f-4784-bc99-1201ac6e6364-c000 to destination hdfs://xxx/user/hive/warehouse/tbl/part-00000-b6277b02-c70f-4784-bc99-1201ac6e6364-c000; (state=,code=0)&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;By the way, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xinxianyin&quot; class=&quot;user-hover&quot; rel=&quot;xinxianyin&quot;&gt;xinxianyin&lt;/a&gt;&apos;s patch works for me and I think it is the simplest to solve this issue.&lt;/p&gt;</comment>
                            <comment id="16790119" author="xinxianyin" created="Tue, 12 Mar 2019 01:37:42 +0000"  >&lt;p&gt;Yep,&#160;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Moriarty279&quot; class=&quot;user-hover&quot; rel=&quot;Moriarty279&quot;&gt;Moriarty279&lt;/a&gt; , nice analysis.&lt;/p&gt;</comment>
                            <comment id="16863796" author="pin_zhang" created="Fri, 14 Jun 2019 07:49:36 +0000"  >&lt;p&gt;We also encounter this issue, any plan to fix this bug?&lt;/p&gt;</comment>
                            <comment id="16865592" author="dricard" created="Mon, 17 Jun 2019 13:25:37 +0000"  >&lt;p&gt;In 2.4, the problem also affect Parquet tables creation... So we had to move all our CTAS to a different process which does not use the thrift server...&lt;/p&gt;</comment>
                            <comment id="16885019" author="xinxianyin" created="Mon, 15 Jul 2019 09:52:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dricard&quot; class=&quot;user-hover&quot; rel=&quot;dricard&quot;&gt;dricard&lt;/a&gt;&#65292;does the attached patch work in your case?&lt;/p&gt;</comment>
                            <comment id="16915225" author="angerszhuuu" created="Sun, 25 Aug 2019 11:58:20 +0000"  >&lt;p&gt;the root cause is in Spark we use just one SessionState. In hiveserver2, each session have it&apos;s own SessionState&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12993824">SPARK-16825</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12959695" name="SPARK-21067.patch" size="1161" author="xinxianyin" created="Fri, 22 Feb 2019 01:53:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 12 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3g6nb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>