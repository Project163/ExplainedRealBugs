<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:46:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-11227] Spark1.5+ HDFS HA mode throw java.net.UnknownHostException: nameservice1</title>
                <link>https://issues.apache.org/jira/browse/SPARK-11227</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When running jar including Spark Job at HDFS HA Cluster, Mesos and Spark1.5.1, the job throw Exception as &quot;java.net.UnknownHostException: nameservice1&quot; and fail.&lt;/p&gt;

&lt;p&gt;I do below in Terminal.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;/opt/spark/bin/spark-submit \
  --&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;com.example.Job /jobs/job-assembly-1.0.0.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So, job throw below message.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/10/21 15:22:12 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, spark003.example.com): java.lang.IllegalArgumentException: java.net.UnknownHostException: nameservice1
        at org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:374)
        at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:312)
        at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:178)
        at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:665)
        at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:601)
        at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:148)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2596)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)
        at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2630)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2612)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:169)
        at org.apache.hadoop.mapred.JobConf.getWorkingDirectory(JobConf.java:656)
        at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:436)
        at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:409)
        at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32.apply(SparkContext.scala:1016)
        at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32.apply(SparkContext.scala:1016)
        at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
        at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
        at scala.Option.map(Option.scala:145)
        at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
        at org.apache.spark.rdd.HadoopRDD$$anon$1.&amp;lt;init&amp;gt;(HadoopRDD.scala:220)
        at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:216)
        at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
        at org.apache.spark.scheduler.Task.run(Task.scala:88)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.net.UnknownHostException: nameservice1
        ... 41 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But, I changed from Spark Cluster 1.5.1 to Spark Cluster 1.4.0, then run the job, job complete with Success.&lt;br/&gt;
In Addition, I disable High Availability on HDFS, then run the job, job complete with Success.&lt;/p&gt;

&lt;p&gt;So, I think Spark1.5 and higher have bug as the point.&lt;/p&gt;

&lt;p&gt;note: I try these packages in my Cluster, But both of these fail.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;spark-1.5.1-bin-hadoop2.6.tgz&lt;/li&gt;
	&lt;li&gt;spark-1.5.1-bin-without-hadoop.tgz&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Only &lt;b&gt;spark-1.4.0-bin-hadoop2.6.tgz&lt;/b&gt; success.&lt;/p&gt;</description>
                <environment>&lt;p&gt;OS: CentOS 6.6&lt;br/&gt;
Memory: 28G&lt;br/&gt;
CPU: 8&lt;br/&gt;
Mesos: 0.22.0&lt;br/&gt;
HDFS: Hadoop 2.6.0-CDH5.4.0 (build by Cloudera Manager)&lt;/p&gt;</environment>
        <key id="12906449">SPARK-11227</key>
            <summary>Spark1.5+ HDFS HA mode throw java.net.UnknownHostException: nameservice1</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sarutak">Kousuke Saruta</assignee>
                                    <reporter username="x1">Yuri Saito</reporter>
                        <labels>
                    </labels>
                <created>Wed, 21 Oct 2015 07:56:52 +0000</created>
                <updated>Fri, 19 Aug 2016 15:12:09 +0000</updated>
                            <resolved>Fri, 19 Aug 2016 15:12:09 +0000</resolved>
                                    <version>1.5.0</version>
                    <version>1.5.1</version>
                    <version>1.6.1</version>
                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="14966601" author="stevel@apache.org" created="Wed, 21 Oct 2015 10:28:57 +0000"  >&lt;p&gt;sounds like an HA config problem: HDFS is picking up &quot;nameservice1&quot; as a hostname, not as a reference for an HA setup, then failing as the hostname won&apos;t resolve&lt;/p&gt;

&lt;p&gt;Look at &lt;a href=&quot;https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#Configuration_details&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html#Configuration_details&lt;/a&gt; to see that your config is right.&lt;/p&gt;</comment>
                            <comment id="14969002" author="x1" created="Thu, 22 Oct 2015 11:51:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt;&lt;br/&gt;
But, same environments, spark1.4.0 run with successfully.&lt;/p&gt;</comment>
                            <comment id="14973943" author="x1" created="Mon, 26 Oct 2015 09:43:40 +0000"  >&lt;p&gt;Resolved myself.&lt;br/&gt;
I change from SQLContext to HiveContext.&lt;br/&gt;
So, it work well.&lt;/p&gt;</comment>
                            <comment id="15083258" author="ansonism" created="Tue, 5 Jan 2016 15:48:29 +0000"  >&lt;p&gt;I am having this issue as well, in my environment.  But i&apos;m not running mesos or yarn.  it only occurs w/ spark-submit.  It works with spark 1.4.x, but 1.5.x &amp;gt; i get the same error, when my cluster is in HA mode (but non-yarn or mesos).  I double checked configs and it is correct. Any help would be appreciated here. &lt;/p&gt;</comment>
                            <comment id="15084457" author="x1" created="Wed, 6 Jan 2016 00:49:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ansonism&quot; class=&quot;user-hover&quot; rel=&quot;ansonism&quot;&gt;ansonism&lt;/a&gt; Even if you use HiveContext, it dosen&apos;t work with spark 1.5.x?&lt;/p&gt;</comment>
                            <comment id="15253250" author="valgrind_girl" created="Fri, 22 Apr 2016 03:07:53 +0000"  >&lt;p&gt;we run into the same problem at spark 1.6.1&#65288;we are using sparkContext.textfile&#65289;&#12290;and it only occurs at spark-submit&#65292;while the same codes work fine at spark-shell&#12290;&lt;/p&gt;</comment>
                            <comment id="15253760" author="x1" created="Fri, 22 Apr 2016 11:15:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=valgrind_girl&quot; class=&quot;user-hover&quot; rel=&quot;valgrind_girl&quot;&gt;valgrind_girl&lt;/a&gt;: Have you run spark-submit and your jar with hive-site.xml?&lt;/p&gt;

&lt;p&gt;ex )&lt;br/&gt;
spark-submit \&lt;br/&gt;
  --files &quot;conf/hive-site.xml,conf/core-site.xml,conf/hdfs-site.xml&quot; \&lt;br/&gt;
  --class MAIN_CLASS \&lt;br/&gt;
  JAR_PATH&lt;/p&gt;</comment>
                            <comment id="15266237" author="meethumathew" created="Mon, 2 May 2016 08:51:12 +0000"  >&lt;p&gt;I am also facing the same issue when HA is setup in cloudera HDFS . I am using spark 1.6.1 and using ipython notebook. When HA is disabled, everything is fine.&lt;/p&gt;</comment>
                            <comment id="15336348" author="apachespark" created="Fri, 17 Jun 2016 15:57:05 +0000"  >&lt;p&gt;User &apos;sarutak&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/13738&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/13738&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15338916" author="sarutak" created="Mon, 20 Jun 2016 02:44:54 +0000"  >&lt;p&gt;I would like to reopen this ticket because I noticed there is a case when UnknownHostException is thrown even if NNHA is configured correctly.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 22 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2n9u7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>