<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:30:42 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-39833] Filtered parquet data frame count() and show() produce inconsistent results when spark.sql.parquet.filterPushdown is true</title>
                <link>https://issues.apache.org/jira/browse/SPARK-39833</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;One of our data scientists discovered a problem wherein a data frame `.show()` call printed non-empty results, but `.count()` printed 0. I&apos;ve narrowed the issue to a small, reproducible test case which exhibits this aberrant behavior. In pyspark, run the following code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-python&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; pyspark.sql.types &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; *
parquet_pushdown_bug_df = spark.createDataFrame([{&lt;span class=&quot;code-quote&quot;&gt;&quot;COL0&quot;&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;(0)}], schema=StructType(fields=[StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;COL0&quot;&lt;/span&gt;,IntegerType(),&lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;True&lt;/span&gt;&lt;/span&gt;)]))
parquet_pushdown_bug_df.repartition(1).write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;parquet_pushdown_bug/col0=0/parquet_pushdown_bug.parquet&quot;&lt;/span&gt;)
reread_parquet_pushdown_bug_df = spark.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;parquet_pushdown_bug&quot;&lt;/span&gt;)
reread_parquet_pushdown_bug_df.&lt;span class=&quot;code-object&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;col0 = 0&quot;&lt;/span&gt;).show()
&lt;span class=&quot;code-object&quot;&gt;print&lt;/span&gt;(reread_parquet_pushdown_bug_df.&lt;span class=&quot;code-object&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;col0 = 0&quot;&lt;/span&gt;).count())
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In my usage, this prints a data frame with 1 row and a count of 0. However, disabling `spark.sql.parquet.filterPushdown` produces consistent results:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-python&quot;&gt;
spark.conf.&lt;span class=&quot;code-object&quot;&gt;set&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.sql.parquet.filterPushdown&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;False&lt;/span&gt;&lt;/span&gt;)
reread_parquet_pushdown_bug_df.&lt;span class=&quot;code-object&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;col0 = 0&quot;&lt;/span&gt;).show()
reread_parquet_pushdown_bug_df.&lt;span class=&quot;code-object&quot;&gt;filter&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;col0 = 0&quot;&lt;/span&gt;).count()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This will print the same data frame, however it will print a count of 1. The key to triggering this bug is not just enabling `spark.sql.parquet.filterPushdown` (which is enabled by default). The case of the column in the data frame (before writing) must differ from the case of the partition column in the file path, i.e. COL0 versus col0 or col0 versus COL0.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13472785">SPARK-39833</key>
            <summary>Filtered parquet data frame count() and show() produce inconsistent results when spark.sql.parquet.filterPushdown is true</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ivan.sadikov">Ivan Sadikov</assignee>
                                    <reporter username="msa">Michael Allman</reporter>
                        <labels>
                            <label>correctness</label>
                    </labels>
                <created>Thu, 21 Jul 2022 22:05:26 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:50 +0000</updated>
                            <resolved>Sun, 21 Aug 2022 10:07:43 +0000</resolved>
                                    <version>3.2.1</version>
                    <version>3.3.0</version>
                                    <fixVersion>3.3.1</fixVersion>
                    <fixVersion>3.2.3</fixVersion>
                    <fixVersion>3.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17571763" author="gurwls223" created="Wed, 27 Jul 2022 06:45:08 +0000"  >&lt;p&gt;Seems like a bug from Parquet side in rowgroup filtering.&lt;/p&gt;</comment>
                            <comment id="17571768" author="ivan.sadikov" created="Wed, 27 Jul 2022 07:12:47 +0000"  >&lt;p&gt;Interesting, I will take a look.&lt;/p&gt;</comment>
                            <comment id="17575032" author="ivan.sadikov" created="Thu, 4 Aug 2022 05:47:02 +0000"  >&lt;p&gt;Your example should work with&#160;&lt;/p&gt;

&lt;p&gt;spark.conf.set(&quot;spark.sql.caseSensitive&quot;, &quot;true&quot;)&lt;/p&gt;

&lt;p&gt;Or when disabling column index.&lt;/p&gt;

&lt;p&gt;spark.conf.set(&quot;parquet.filter.columnindex.enabled&quot;, &quot;false&quot;)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;In fact, you should be getting a log4j warning for duplicate columns:&lt;/p&gt;

&lt;p&gt;05:44:55.016 WARN org.apache.spark.sql.execution.datasources.DataSource: Found duplicate column(s) in the data schema and the partition schema: `col`&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;That said, it is still a bug to return a different row count due to case-insensitive analysis in Spark and a bug in filtering in Parquet-Mr. I will open a PR to fix it.&lt;/p&gt;</comment>
                            <comment id="17575510" author="ivan.sadikov" created="Fri, 5 Aug 2022 01:47:42 +0000"  >&lt;p&gt;It appears to be a bug in Parquet-Mr.&#160;&lt;/p&gt;

&lt;p&gt;There is a condition in ParquetFileReader that determines the total number of records that we expect when doing predicate pushdown. Depending on whether or not column index feature is enabled, we would either return all filtered rows from a row group or row ranges. The bug is checking column paths against an empty set which is created when the projection is empty. In this case, we should return all row group rows instead of failing the condition and returning 0 records.&lt;/p&gt;</comment>
                            <comment id="17575570" author="ivan.sadikov" created="Fri, 5 Aug 2022 05:06:58 +0000"  >&lt;p&gt;I opened a PR to quickly fix it: &lt;a href=&quot;https://github.com/apache/spark/pull/37419&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/37419&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here is the ticket to address the issue in Parquet-Mr: &lt;a href=&quot;https://issues.apache.org/jira/browse/PARQUET-2170&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/PARQUET-2170&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17575571" author="apachespark" created="Fri, 5 Aug 2022 05:07:50 +0000"  >&lt;p&gt;User &apos;sadikovi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/37419&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/37419&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17575573" author="apachespark" created="Fri, 5 Aug 2022 05:08:41 +0000"  >&lt;p&gt;User &apos;sadikovi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/37419&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/37419&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17582520" author="gurwls223" created="Sun, 21 Aug 2022 10:07:43 +0000"  >&lt;p&gt;Issue resolved by pull request 37419&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/37419&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/37419&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13475278">PARQUET-2170</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13477866">SPARK-40169</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 12 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z172hk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>