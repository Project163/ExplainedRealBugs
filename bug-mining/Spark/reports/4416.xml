<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:50:19 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18877] Unable to read given csv data. Excepion: java.lang.IllegalArgumentException: requirement failed: Decimal precision 28 exceeds max precision 20</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18877</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When reading below mentioned csv data, even though the maximum decimal precision is 38, following exception is thrown java.lang.IllegalArgumentException: requirement failed: Decimal precision 28 exceeds max precision 20&lt;/p&gt;


&lt;p&gt;Decimal&lt;br/&gt;
2323366225312000000000000000&lt;br/&gt;
24335739714000000&lt;br/&gt;
23233662253000&lt;br/&gt;
232336622530000&lt;/p&gt;
</description>
                <environment></environment>
        <key id="13028314">SPARK-18877</key>
            <summary>Unable to read given csv data. Excepion: java.lang.IllegalArgumentException: requirement failed: Decimal precision 28 exceeds max precision 20</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dongjoon">Dongjoon Hyun</assignee>
                                    <reporter username="Navya Krishnappa">Navya Krishnappa</reporter>
                        <labels>
                    </labels>
                <created>Thu, 15 Dec 2016 07:38:15 +0000</created>
                <updated>Fri, 26 Jan 2018 10:40:53 +0000</updated>
                            <resolved>Tue, 3 Jan 2017 15:07:47 +0000</resolved>
                                    <version>2.0.2</version>
                                    <fixVersion>2.0.3</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15750878" author="srowen" created="Thu, 15 Dec 2016 09:20:51 +0000"  >&lt;p&gt;You should include the stack trace whenever you report an exception.&lt;br/&gt;
How are you reading, where do you set max precision, etc? &lt;br/&gt;
This could use a lot more detail.&lt;/p&gt;</comment>
                            <comment id="15753716" author="navya krishnappa" created="Fri, 16 Dec 2016 07:35:52 +0000"  >&lt;p&gt;I&apos;m reading through csvReader (.csv(sourceFile)) and i&apos;m not setting any precision and scale, Spark is automatically detecting the precision and scale for the values in the source file. And precision and scale vary depending on the decimal values in the column. &lt;/p&gt;

&lt;p&gt;Stack trace:&lt;/p&gt;

&lt;p&gt;Caused by: java.lang.IllegalArgumentException: requirement failed: Decimal precision 28 exceeds max precision 20&lt;br/&gt;
	at scala.Predef$.require(Predef.scala:224)&lt;br/&gt;
	at org.apache.spark.sql.types.Decimal.set(Decimal.scala:112)&lt;br/&gt;
	at org.apache.spark.sql.types.Decimal$.apply(Decimal.scala:425)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$.castTo(CSVInferSchema.scala:264)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:116)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:85)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:128)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:127)&lt;br/&gt;
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)&lt;br/&gt;
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)&lt;br/&gt;
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:91)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:128)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:91)&lt;br/&gt;
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)&lt;br/&gt;
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)&lt;br/&gt;
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)&lt;br/&gt;
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)&lt;br/&gt;
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)&lt;br/&gt;
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)&lt;br/&gt;
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)&lt;br/&gt;
	at org.apache.spark.scheduler.Task.run(Task.scala:86)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	... 1 common frames omitted&lt;/p&gt;</comment>
                            <comment id="15753728" author="navya krishnappa" created="Fri, 16 Dec 2016 07:40:10 +0000"  >&lt;p&gt;Precision and scale vary depending on the decimal values in the column. Suppose if source file contains &lt;/p&gt;

&lt;p&gt;Amount(column name)&lt;br/&gt;
9.03E+12&lt;br/&gt;
1.19E+11&lt;br/&gt;
24335739714&lt;br/&gt;
1.71E+11&lt;/p&gt;

&lt;p&gt;then spark consider Amount column as decimal(3,-9). and throws an below mentioned exception&lt;/p&gt;

&lt;p&gt;Caused by: java.lang.IllegalArgumentException: requirement failed: Decimal precision 4 exceeds max precision 3&lt;br/&gt;
	at scala.Predef$.require(Predef.scala:224)&lt;br/&gt;
	at org.apache.spark.sql.types.Decimal.set(Decimal.scala:112)&lt;br/&gt;
	at org.apache.spark.sql.types.Decimal$.apply(Decimal.scala:425)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$.castTo(CSVInferSchema.scala:264)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:116)&lt;/p&gt;
</comment>
                            <comment id="15754094" author="dongjoon" created="Fri, 16 Dec 2016 10:50:15 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Navya+Krishnappa&quot; class=&quot;user-hover&quot; rel=&quot;Navya Krishnappa&quot;&gt;Navya Krishnappa&lt;/a&gt;.&lt;br/&gt;
Could you give us more details? What kind of case class did you use?&lt;br/&gt;
If you use simply `spark.read.format(&quot;csv&quot;).load(~~)` on those files, it returns `string`, doesn&apos;t it?&lt;/p&gt;</comment>
                            <comment id="15754865" author="navya krishnappa" created="Fri, 16 Dec 2016 16:27:07 +0000"  >&lt;p&gt;I&apos;m using SparkContext.read() to read the content. Refer the given code using to read the csv file.&lt;/p&gt;

&lt;p&gt;Dataset dataset = getSqlContext().read()&lt;br/&gt;
                .option(HEADER, &quot;true&quot;)&lt;br/&gt;
                .option(PARSER_LIB, &quot;commons&quot;)&lt;br/&gt;
                .option(INFER_SCHEMA, &quot;true&quot;)&lt;br/&gt;
                .option(DELIMITER, &quot;,&quot;)&lt;br/&gt;
                .option(QUOTE, &quot;\&quot;&quot;)&lt;br/&gt;
                .option(ESCAPE, &quot;&lt;br class=&quot;atl-forced-newline&quot; /&gt;&quot;)&lt;br/&gt;
                .option(MODE, Mode.PERMISSIVE)&lt;br/&gt;
                .csv(sourceFile);&lt;/p&gt;

&lt;p&gt;if we collect the dataset (dataset.collect()). i will get java.lang.IllegalArgumentException: requirement failed: Decimal precision 28 exceeds max precision 20 exception.&lt;/p&gt;</comment>
                            <comment id="15754973" author="dongjoon" created="Fri, 16 Dec 2016 17:08:36 +0000"  >&lt;p&gt;Thank you for the details.&lt;/p&gt;</comment>
                            <comment id="15755579" author="dongjoon" created="Fri, 16 Dec 2016 21:39:44 +0000"  >&lt;p&gt;Yes. I reproduced the bug and found the root cause on schema inferencing.&lt;br/&gt;
I&apos;ll make a PR for this.&lt;/p&gt;</comment>
                            <comment id="15755691" author="apachespark" created="Fri, 16 Dec 2016 22:35:05 +0000"  >&lt;p&gt;User &apos;dongjoon-hyun&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16320&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16320&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15756554" author="navya krishnappa" created="Sat, 17 Dec 2016 07:28:10 +0000"  >&lt;p&gt;Thank you for replying &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;. Can you help me in understanding whether the above mentioned PR will resolve the below mentioned issue.&lt;/p&gt;

&lt;p&gt;I have another issue with respect to the decimal scale. When i&apos;m trying to read the below mentioned csv source file and creating an parquet file from that throws an java.lang.IllegalArgumentException: Invalid DECIMAL scale: -9 exception.&lt;/p&gt;


&lt;p&gt;The source file content is &lt;br/&gt;
Row(column name)&lt;br/&gt;
9.03E+12&lt;br/&gt;
1.19E+11&lt;/p&gt;

&lt;p&gt; Refer the given code used read the csv file and creating an parquet file:&lt;/p&gt;

&lt;p&gt;//Read the csv file&lt;br/&gt;
Dataset dataset = getSqlContext().read()&lt;br/&gt;
.option(HEADER, &quot;true&quot;)&lt;br/&gt;
.option(PARSER_LIB, &quot;commons&quot;)&lt;br/&gt;
.option(INFER_SCHEMA, &quot;true&quot;)&lt;br/&gt;
.option(DELIMITER, &quot;,&quot;)&lt;br/&gt;
.option(QUOTE, &quot;\&quot;&quot;)&lt;br/&gt;
.option(ESCAPE, &quot;&lt;br/&gt;
&quot;)&lt;br/&gt;
.option(MODE, Mode.PERMISSIVE)&lt;br/&gt;
.csv(sourceFile)&lt;/p&gt;

&lt;p&gt;// create an parquet file&lt;br/&gt;
dataset.write().parquet(&quot;//path.parquet&quot;)&lt;/p&gt;


&lt;p&gt;Stack trace:&lt;/p&gt;

&lt;p&gt;Caused by: java.lang.IllegalArgumentException: Invalid DECIMAL scale: -9&lt;br/&gt;
	at org.apache.parquet.Preconditions.checkArgument(Preconditions.java:55)&lt;br/&gt;
	at org.apache.parquet.schema.Types$PrimitiveBuilder.decimalMetadata(Types.java:410)&lt;br/&gt;
	at org.apache.parquet.schema.Types$PrimitiveBuilder.build(Types.java:324)&lt;br/&gt;
	at org.apache.parquet.schema.Types$PrimitiveBuilder.build(Types.java:250)&lt;br/&gt;
	at org.apache.parquet.schema.Types$Builder.named(Types.java:228)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.parquet.ParquetSchemaConverter.convertField(ParquetSchemaConverter.scala:412)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.parquet.ParquetSchemaConverter.convertField(ParquetSchemaConverter.scala:321)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.parquet.ParquetSchemaConverter$$anonfun$convert$1.apply(ParquetSchemaConverter.scala:313)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.parquet.ParquetSchemaConverter$$anonfun$convert$1.apply(ParquetSchemaConverter.scala:313)&lt;/p&gt;
</comment>
                            <comment id="15757924" author="dongjoon" created="Sun, 18 Dec 2016 01:04:22 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Navya+Krishnappa&quot; class=&quot;user-hover&quot; rel=&quot;Navya Krishnappa&quot;&gt;Navya Krishnappa&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As you see in the stack trace, that is a different exception from Apache Parquet code.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: java.lang.IllegalArgumentException: Invalid DECIMAL scale: -9
	at org.apache.parquet.Preconditions.checkArgument(Preconditions.java:55)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And, this is the Parquet code &lt;a href=&quot;https://github.com/Parquet/parquet-mr/blob/master/parquet-column/src/main/java/parquet/schema/Types.java#L405-L417&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It apparently does not fully support BigDecimal.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; DecimalMetadata decimalMetadata() {
      DecimalMetadata meta = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (OriginalType.DECIMAL == originalType) {
        Preconditions.checkArgument(precision &amp;gt; 0,
            &lt;span class=&quot;code-quote&quot;&gt;&quot;Invalid DECIMAL precision: &quot;&lt;/span&gt; + precision);
        Preconditions.checkArgument(scale &amp;gt;= 0,
            &lt;span class=&quot;code-quote&quot;&gt;&quot;Invalid DECIMAL scale: &quot;&lt;/span&gt; + scale);
        Preconditions.checkArgument(scale &amp;lt;= precision,
            &lt;span class=&quot;code-quote&quot;&gt;&quot;Invalid DECIMAL scale: cannot be greater than precision&quot;&lt;/span&gt;);
        meta = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DecimalMetadata(precision, scale);
      }
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; meta;
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I cannot make a PR for Parquet.&lt;br/&gt;
I hope you register another issue for that in Apache Parquet JIRA.&lt;/p&gt;</comment>
                            <comment id="15757940" author="dongjoon" created="Sun, 18 Dec 2016 01:06:55 +0000"  >&lt;p&gt;For a Spark usage workaround, I think you can change the schema into a Parquet-acceptable one manually.&lt;/p&gt;</comment>
                            <comment id="15760487" author="navya krishnappa" created="Mon, 19 Dec 2016 07:50:14 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; and i will create an issue in  Apache Parquet JIRA.&lt;/p&gt;</comment>
                            <comment id="15762186" author="dongjoon" created="Mon, 19 Dec 2016 20:17:31 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="15796183" author="apachespark" created="Tue, 3 Jan 2017 21:09:07 +0000"  >&lt;p&gt;User &apos;dongjoon-hyun&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16463&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16463&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15798945" author="apachespark" created="Wed, 4 Jan 2017 18:19:04 +0000"  >&lt;p&gt;User &apos;dongjoon-hyun&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16472&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16472&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16072240" author="navya krishnappa" created="Mon, 3 Jul 2017 10:33:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; I have created parquet bug for the invalid scale issue in Decimal data type. But Parquet team is telling its Spark issue. Please refer &lt;a href=&quot;https://issues.apache.org/jira/browse/PARQUET-815&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/PARQUET-815&lt;/a&gt; and add your comments.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13133945">SPARK-23225</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 20 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i37mo7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>