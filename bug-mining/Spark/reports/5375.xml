<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:57:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21652] Optimizer cannot reach a fixed point on certain queries</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21652</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The optimizer cannot reach a fixed point on the following query:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Seq((1, 2)).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;col2&quot;&lt;/span&gt;).write.saveAsTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;t1&quot;&lt;/span&gt;)
Seq(1, 2).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;col&quot;&lt;/span&gt;).write.saveAsTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;t2&quot;&lt;/span&gt;)
spark.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM t1, t2 WHERE t1.col1 = 1 AND 1 = t1.col2 AND t1.col1 = t2.col AND t1.col2 = t2.col&quot;&lt;/span&gt;).explain(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At some point during the optimization, InferFiltersFromConstraints infers a new constraint &apos;(col2#33 = col1#32)&apos; that is appended to the join condition, then PushPredicateThroughJoin pushes it down, ConstantPropagation replaces &apos;(col2#33 = col1#32)&apos; with &apos;1 = 1&apos; based on other propagated constraints, ConstantFolding replaces &apos;1 = 1&apos; with &apos;true and BooleanSimplification finally removes this predicate. However, InferFiltersFromConstraints will again infer &apos;(col2#33 = col1#32)&apos; on the next iteration and the process will continue until the limit of iterations is reached. &lt;/p&gt;

&lt;p&gt;See below for more details&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;=== Applying Rule org.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints ===
!Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))                                       Join Inner, ((col2#33 = col1#32) &amp;amp;&amp;amp; ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34)))
 :- Filter ((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33)))   :- Filter ((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33)))
 :  +- Relation[col1#32,col2#33] parquet                                                      :  +- Relation[col1#32,col2#33] parquet
 +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))                                                +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))
    +- Relation[col#34] parquet                                                                  +- Relation[col#34] parquet
                

=== Applying Rule org.apache.spark.sql.catalyst.optimizer.PushPredicateThroughJoin ===
!Join Inner, ((col2#33 = col1#32) &amp;amp;&amp;amp; ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34)))              Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))
!:- Filter ((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33)))   :- Filter (col2#33 = col1#32)
!:  +- Relation[col1#32,col2#33] parquet                                                      :  +- Filter ((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33)))
!+- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))                                                :     +- Relation[col1#32,col2#33] parquet
!   +- Relation[col#34] parquet                                                               +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))
!                                                                                                +- Relation[col#34] parquet
                

=== Applying Rule org.apache.spark.sql.catalyst.optimizer.CombineFilters ===
 Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))                                          Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))
!:- Filter (col2#33 = col1#32)                                                                   :- Filter (((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33))) &amp;amp;&amp;amp; (col2#33 = col1#32))
!:  +- Filter ((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33)))   :  +- Relation[col1#32,col2#33] parquet
!:     +- Relation[col1#32,col2#33] parquet                                                      +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))
!+- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))                                                      +- Relation[col#34] parquet
!   +- Relation[col#34] parquet                                                                  
                

=== Applying Rule org.apache.spark.sql.catalyst.optimizer.ConstantPropagation ===
 Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))                                                                Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))
!:- Filter (((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33))) &amp;amp;&amp;amp; (col2#33 = col1#32))   :- Filter (((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33))) &amp;amp;&amp;amp; (1 = 1))
 :  +- Relation[col1#32,col2#33] parquet                                                                               :  +- Relation[col1#32,col2#33] parquet
 +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))                                                                         +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))
    +- Relation[col#34] parquet                                                                                           +- Relation[col#34] parquet
                

=== Applying Rule org.apache.spark.sql.catalyst.optimizer.ConstantFolding ===
 Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))                                                    Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))
!:- Filter (((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33))) &amp;amp;&amp;amp; (1 = 1))   :- Filter (((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33))) &amp;amp;&amp;amp; true)
 :  +- Relation[col1#32,col2#33] parquet                                                                   :  +- Relation[col1#32,col2#33] parquet
 +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))                                                             +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))
    +- Relation[col#34] parquet                                                                               +- Relation[col#34] parquet
                

=== Applying Rule org.apache.spark.sql.catalyst.optimizer.BooleanSimplification ===
 Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))                                                 Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))
!:- Filter (((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33))) &amp;amp;&amp;amp; true)   :- Filter ((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33)))
 :  +- Relation[col1#32,col2#33] parquet                                                                :  +- Relation[col1#32,col2#33] parquet
 +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))                                                          +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))
    +- Relation[col#34] parquet                                                                            +- Relation[col#34] parquet
                

=== Applying Rule org.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints ===
!Join Inner, ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34))                                       Join Inner, ((col2#33 = col1#32) &amp;amp;&amp;amp; ((col1#32 = col#34) &amp;amp;&amp;amp; (col2#33 = col#34)))
 :- Filter ((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33)))   :- Filter ((isnotnull(col1#32) &amp;amp;&amp;amp; isnotnull(col2#33)) &amp;amp;&amp;amp; ((col1#32 = 1) &amp;amp;&amp;amp; (1 = col2#33)))
 :  +- Relation[col1#32,col2#33] parquet                                                      :  +- Relation[col1#32,col2#33] parquet
 +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))                                                +- Filter ((1 = col#34) &amp;amp;&amp;amp; isnotnull(col#34))
    +- Relation[col#34] parquet                                                                  +- Relation[col#34] parquet
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13092801">SPARK-21652</key>
            <summary>Optimizer cannot reach a fixed point on certain queries</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="smilegator">Xiao Li</assignee>
                                    <reporter username="aokolnychyi">Anton Okolnychyi</reporter>
                        <labels>
                    </labels>
                <created>Mon, 7 Aug 2017 07:21:02 +0000</created>
                <updated>Fri, 25 Jan 2019 02:14:12 +0000</updated>
                            <resolved>Tue, 19 Dec 2017 17:06:54 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>Optimizer</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="16116192" author="aokolnychyi" created="Mon, 7 Aug 2017 07:28:54 +0000"  >&lt;p&gt;One option to fix this is NOT to apply ConstantPropagation to such predicates as &apos;(col1 = col2)&apos; if both sides can be replaced with a constant value.&lt;/p&gt;</comment>
                            <comment id="16116236" author="maropu" created="Mon, 7 Aug 2017 08:15:43 +0000"  >&lt;p&gt;It seems the known issue; have you tried `spark.sql.constraintPropagation.enabled`?&lt;/p&gt;</comment>
                            <comment id="16116936" author="aokolnychyi" created="Mon, 7 Aug 2017 17:54:24 +0000"  >&lt;p&gt;Yes, disabling the constraint propagation helps because `InferFiltersFromConstraints` will not apply. I found several known issues regarding the performance of `InferFiltersFromConstraints` but what about the logic of `ConstantPropagation` in the above example? Should it replace such predicates as `(a = b)` with `(1 = 1)` even if it is semantically correct?&lt;/p&gt;</comment>
                            <comment id="16118211" author="maropu" created="Tue, 8 Aug 2017 11:26:31 +0000"  >&lt;p&gt;oh, yea. I see. Probably, I think `InferFiltersFromConstraints` should not infer `col1 = col2`.&lt;/p&gt;</comment>
                            <comment id="16126917" author="maropu" created="Tue, 15 Aug 2017 08:05:22 +0000"  >&lt;p&gt;User &apos;maropu&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18882&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18882&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16149680" author="apachespark" created="Thu, 31 Aug 2017 21:58:04 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19099&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19099&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16155812" author="apachespark" created="Wed, 6 Sep 2017 18:12:03 +0000"  >&lt;p&gt;User &apos;gatorsmile&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19149&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19149&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16614664" author="pfchang" created="Fri, 14 Sep 2018 11:08:32 +0000"  >&lt;p&gt;Hi, after this change, there are some cases not supported, see follows:&lt;/p&gt;

&lt;p&gt;select * from test1, test2, test3 where test1.a = test2.a and test1.a = test3.a and test3.a =1;&lt;/p&gt;

&lt;p&gt;The filter a = 1 will only be pushed down to test1 and test3, not test2.&lt;/p&gt;

&lt;p&gt;Is this the&#160; expected behavior?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="13208288">SPARK-26569</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 9 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3ih7b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>