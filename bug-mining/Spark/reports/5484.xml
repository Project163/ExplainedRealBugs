<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:58:13 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-22465] Cogroup of two disproportionate RDDs could lead into 2G limit BUG</title>
                <link>https://issues.apache.org/jira/browse/SPARK-22465</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;While running my spark pipeline, it failed with the following exception&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2017-11-03 04:49:09,776 [Executor task launch worker for task 58670] ERROR org.apache.spark.executor.Executor  - Exception in task 630.0 in stage 28.0 (TID 58670)
java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE
	at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:869)
	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:103)
	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:91)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1303)
	at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:105)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:469)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:705)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:334)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:285)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:324)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;After debugging I found that the issue lies with how spark handles cogroup of two RDDs.&lt;br/&gt;
Here is the relevant code from apache spark&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt; /**
   * For each key k in `this` or `other`, return a resulting RDD that contains a tuple with the
   * list of values for that key in `this` as well as `other`.
   */
  def cogroup[W](other: RDD[(K, W)]): RDD[(K, (Iterable[V], Iterable[W]))] = self.withScope {
    cogroup(other, defaultPartitioner(self, other))
  }


/**
   * Choose a partitioner to use for a cogroup-like operation between a number of RDDs.
   *
   * If any of the RDDs already has a partitioner, choose that one.
   *
   * Otherwise, we use a default HashPartitioner. For the number of partitions, if
   * spark.default.parallelism is set, then we&apos;ll use the value from SparkContext
   * defaultParallelism, otherwise we&apos;ll use the max number of upstream partitions.
   *
   * Unless spark.default.parallelism is set, the number of partitions will be the
   * same as the number of partitions in the largest upstream RDD, as this should
   * be least likely to cause out-of-memory errors.
   *
   * We use two method parameters (rdd, others) to enforce callers passing at least 1 RDD.
   */
  def defaultPartitioner(rdd: RDD[_], others: RDD[_]*): Partitioner = {
    val rdds = (Seq(rdd) ++ others)
    val hasPartitioner = rdds.filter(_.partitioner.exists(_.numPartitions &amp;gt; 0))
    if (hasPartitioner.nonEmpty) {
      hasPartitioner.maxBy(_.partitions.length).partitioner.get
    } else {
      if (rdd.context.conf.contains(&quot;spark.default.parallelism&quot;)) {
        new HashPartitioner(rdd.context.defaultParallelism)
      } else {
        new HashPartitioner(rdds.map(_.partitions.length).max)
      }
    }
  }

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Given this  suppose we have two  pair RDDs.&lt;br/&gt;
RDD1 : A small RDD which fewer data and partitions&lt;br/&gt;
RDD2: A huge RDD which has loads of data and partitions&lt;/p&gt;

&lt;p&gt;Now in the code if we were to have a cogroup&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;val RDD3 = RDD1.cogroup(RDD2)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;there is a case where this could lead to the &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-6235&quot; title=&quot;Address various 2G limits&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-6235&quot;&gt;&lt;del&gt;SPARK-6235&lt;/del&gt;&lt;/a&gt; Bug which is If RDD1 has a partitioner when it is being called into a cogroup. This is because the cogroups partitions are then decided by the partitioner and could lead to the huge RDD2 being shuffled into a small number of partitions.&lt;/p&gt;

&lt;p&gt;One way is probably to add a safety check here that would ignore the partitioner if the number of partitions on the two RDDs are very different in magnitude.&lt;/p&gt;


</description>
                <environment></environment>
        <key id="13116757">SPARK-22465</key>
            <summary>Cogroup of two disproportionate RDDs could lead into 2G limit BUG</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="amitkumar">Amit Kumar</reporter>
                        <labels>
                    </labels>
                <created>Tue, 7 Nov 2017 17:46:34 +0000</created>
                <updated>Wed, 23 Jan 2019 02:29:52 +0000</updated>
                            <resolved>Sun, 24 Dec 2017 19:15:05 +0000</resolved>
                                    <version>1.0.0</version>
                    <version>1.0.1</version>
                    <version>1.0.2</version>
                    <version>1.1.0</version>
                    <version>1.1.1</version>
                    <version>1.2.0</version>
                    <version>1.2.1</version>
                    <version>1.2.2</version>
                    <version>1.3.0</version>
                    <version>1.3.1</version>
                    <version>1.4.0</version>
                    <version>1.4.1</version>
                    <version>1.5.0</version>
                    <version>1.5.1</version>
                    <version>1.5.2</version>
                    <version>1.6.0</version>
                    <version>1.6.1</version>
                    <version>1.6.2</version>
                    <version>1.6.3</version>
                    <version>2.0.0</version>
                    <version>2.0.1</version>
                    <version>2.0.2</version>
                    <version>2.1.0</version>
                    <version>2.1.1</version>
                    <version>2.1.2</version>
                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16242856" author="srowen" created="Tue, 7 Nov 2017 20:54:05 +0000"  >&lt;p&gt;Is this not indeed just the 2G limit again?&lt;br/&gt;
You can work around this by repartitioning the larger RDD, right?&lt;/p&gt;</comment>
                            <comment id="16246595" author="tgraves" created="Thu, 9 Nov 2017 21:37:52 +0000"  >&lt;p&gt;Its not strictly the 2G limit.  He did hit that but he hit it because of the default behavior of cogroup.  I think this jira was filed to look at that to make the behavior better.  So I think the last couple sentences in the description refer to that.&lt;/p&gt;
</comment>
                            <comment id="16292327" author="suj1th" created="Fri, 15 Dec 2017 10:44:54 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tgraves&quot; class=&quot;user-hover&quot; rel=&quot;tgraves&quot;&gt;tgraves&lt;/a&gt;, is there a plan to resolve this behaviour of cogroup, outside of the umbrella ticket for fixing 2G limit (&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-6235&quot; title=&quot;Address various 2G limits&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-6235&quot;&gt;&lt;del&gt;SPARK-6235&lt;/del&gt;&lt;/a&gt;). I wish to chip in if that is the case. Thank you.&lt;/p&gt;</comment>
                            <comment id="16292569" author="tgraves" created="Fri, 15 Dec 2017 14:03:36 +0000"  >&lt;p&gt;I don&apos;t have time at the moment to work on this so if you want to pick it up that would be great.&lt;/p&gt;</comment>
                            <comment id="16292581" author="suj1th" created="Fri, 15 Dec 2017 14:10:19 +0000"  >&lt;p&gt;Would something along the lines of  &apos;add a safety-check that ignores the partitioner if the number of partitions on the RDDs are very different in magnitude&apos;, as the reporter suggests, be a satisfactory solution? Any pointers here would be very helpful.&lt;/p&gt;</comment>
                            <comment id="16292608" author="tgraves" created="Fri, 15 Dec 2017 14:34:45 +0000"  >&lt;p&gt;Yes I think that makes sense.  &lt;/p&gt;</comment>
                            <comment id="16293795" author="apachespark" created="Sat, 16 Dec 2017 12:57:04 +0000"  >&lt;p&gt;User &apos;sujithjay&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/20002&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/20002&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16302929" author="mridulm80" created="Sun, 24 Dec 2017 19:15:05 +0000"  >&lt;p&gt;Issue resolved by pull request 20002&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/20002&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/20002&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16304569" author="apachespark" created="Wed, 27 Dec 2017 14:25:03 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/20091&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/20091&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 46 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3mi7j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311620" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Shepherd</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>tgraves</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </customfields>
    </item>
</channel>
</rss>