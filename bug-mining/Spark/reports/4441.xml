<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:50:29 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17237] DataFrame fill after pivot causing org.apache.spark.sql.AnalysisException</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17237</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I am trying to run a pivot transformation which I ran on a spark1.6 cluster, &lt;br/&gt;
namely&lt;/p&gt;

&lt;p&gt;sc.parallelize(Seq((2,3,4), (3,4,5))).toDF(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)&lt;br/&gt;
res1: org.apache.spark.sql.DataFrame = &lt;span class=&quot;error&quot;&gt;&amp;#91;a: int, b: int, c: int&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; res1.groupBy(&quot;a&quot;).pivot(&quot;b&quot;).agg(count(&quot;c&quot;), avg(&quot;c&quot;)).na.fill(0)&lt;br/&gt;
res2: org.apache.spark.sql.DataFrame = &lt;span class=&quot;error&quot;&gt;&amp;#91;a: int, 3_count(c): bigint, 3_avg(c): double, 4_count(c): bigint, 4_avg(c): double&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; res1.groupBy(&quot;a&quot;).pivot(&quot;b&quot;).agg(count(&quot;c&quot;), avg(&quot;c&quot;)).na.fill(0).show&lt;br/&gt;
&lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--------&lt;del&gt;&lt;ins&gt;&lt;/del&gt;------&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--------&lt;del&gt;&lt;ins&gt;&lt;/del&gt;-------&lt;/ins&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  a&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3_count(c)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;3_avg(c)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4_count(c)&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;4_avg(c)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--------&lt;del&gt;&lt;ins&gt;&lt;/del&gt;------&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--------&lt;del&gt;&lt;ins&gt;&lt;/del&gt;-------&lt;/ins&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;         1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     4.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;         0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;         0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     0.0&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;         1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     5.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--------&lt;del&gt;&lt;ins&gt;&lt;/del&gt;------&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--------&lt;del&gt;&lt;ins&gt;&lt;/del&gt;-------&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;after upgrade the environment to spark2.0, got an error while executing .na.fill method&lt;/p&gt;

&lt;p&gt;scala&amp;gt; sc.parallelize(Seq((2,3,4), (3,4,5))).toDF(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)&lt;br/&gt;
res3: org.apache.spark.sql.DataFrame = &lt;span class=&quot;error&quot;&gt;&amp;#91;a: int, b: int ... 1 more field&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;scala&amp;gt; res3.groupBy(&quot;a&quot;).pivot(&quot;b&quot;).agg(count(&quot;c&quot;), avg(&quot;c&quot;)).na.fill(0)&lt;br/&gt;
org.apache.spark.sql.AnalysisException: syntax error in attribute name: `3_count(`c`)`;&lt;br/&gt;
  at org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute$.e$1(unresolved.scala:103)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute$.parseAttributeName(unresolved.scala:113)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveQuoted(LogicalPlan.scala:168)&lt;br/&gt;
  at org.apache.spark.sql.Dataset.resolve(Dataset.scala:218)&lt;br/&gt;
  at org.apache.spark.sql.Dataset.col(Dataset.scala:921)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameNaFunctions.org$apache$spark$sql$DataFrameNaFunctions$$fillCol(DataFrameNaFunctions.scala:411)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameNaFunctions$$anonfun$2.apply(DataFrameNaFunctions.scala:162)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameNaFunctions$$anonfun$2.apply(DataFrameNaFunctions.scala:159)&lt;br/&gt;
  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&lt;br/&gt;
  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&lt;br/&gt;
  at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)&lt;br/&gt;
  at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)&lt;br/&gt;
  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)&lt;br/&gt;
  at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameNaFunctions.fill(DataFrameNaFunctions.scala:159)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameNaFunctions.fill(DataFrameNaFunctions.scala:149)&lt;br/&gt;
  at org.apache.spark.sql.DataFrameNaFunctions.fill(DataFrameNaFunctions.scala:134)&lt;/p&gt;

</description>
                <environment></environment>
        <key id="12999979">SPARK-17237</key>
            <summary>DataFrame fill after pivot causing org.apache.spark.sql.AnalysisException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="maropu">Takeshi Yamamuro</assignee>
                                    <reporter username="tintinlotus">Jiang Qiqi</reporter>
                        <labels>
                            <label>newbie</label>
                    </labels>
                <created>Thu, 25 Aug 2016 10:42:31 +0000</created>
                <updated>Fri, 16 Jun 2017 01:57:58 +0000</updated>
                            <resolved>Fri, 13 Jan 2017 17:26:05 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.3</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15437184" author="maropu" created="Thu, 25 Aug 2016 16:36:49 +0000"  >&lt;p&gt;It seems the root cause of this bug is nested backticks in column names.&lt;br/&gt;
UnresolvedAttribute#parseAttributeName cannot handle the nested backtics.&lt;/p&gt;
</comment>
                            <comment id="15437500" author="apachespark" created="Thu, 25 Aug 2016 19:32:06 +0000"  >&lt;p&gt;User &apos;maropu&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14812&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14812&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15821983" author="apachespark" created="Fri, 13 Jan 2017 16:54:56 +0000"  >&lt;p&gt;User &apos;maropu&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16565&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16565&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16040716" author="albertofem" created="Wed, 7 Jun 2017 11:17:54 +0000"  >&lt;p&gt;Hi there,&lt;/p&gt;

&lt;p&gt;I think this change introduced a breaking change in the way the &quot;withColumnRenamed&quot; method works. I can reproduce this breaking change with the following example:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;dataframe = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM db.table&quot;&lt;/span&gt;)
another_dataframe = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM db.another_table&quot;&lt;/span&gt;)

dataframe
	.join(another_dataframe, on=[...])
	.pivot(&lt;span class=&quot;code-quote&quot;&gt;&quot;column_name&quot;&lt;/span&gt;, values=[0, 1])
	.max(&lt;span class=&quot;code-quote&quot;&gt;&quot;column1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;column2&quot;&lt;/span&gt;)
	.withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;0_max(another_table.`column1`)&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;name1&quot;&lt;/span&gt;)
	.withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;1_max(another_table.`column2`)&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;name2&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With Spark 2.1.0, the behaviour is the expected: columns get renamed.&lt;/p&gt;

&lt;p&gt;With Spark 2.1.1, and if this issue was resolved, you wouldn&apos;t need to change anything for the renames to work. However, the column doesn&apos;t get renamed at all because now you would need to use the following renames:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;dataframe = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM db.table&quot;&lt;/span&gt;)
another_dataframe = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM db.another_table&quot;&lt;/span&gt;)

dataframe
	.join(another_dataframe, on=[...])
	.pivot(&lt;span class=&quot;code-quote&quot;&gt;&quot;column_name&quot;&lt;/span&gt;, values=[0, 1])
	.max(&lt;span class=&quot;code-quote&quot;&gt;&quot;column1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;column2&quot;&lt;/span&gt;)
	.withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;0_max(column1)&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;name1&quot;&lt;/span&gt;)
	.withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;1_max(column2)&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;name2&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you can see, it seems that this PR somehow managed to removed the table name from the join context and also removed the backticks, thus introducing a breaking change.&lt;/p&gt;

&lt;p&gt;I should also notice that the original issue didn&apos;t happen when using JSON as output format. It only happens because Parquet doesn&apos;t support () characters in column names, but in JSON they work just fine. Here is an example of the error thrown by Parquet after upgrading to Spark 2.1.1 and not modifying your code.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Attribute name &lt;span class=&quot;code-quote&quot;&gt;&quot;0_max(column1)&quot;&lt;/span&gt; contains invalid character(s) among &lt;span class=&quot;code-quote&quot;&gt;&quot; ,;{}()\\n\\t=&quot;&lt;/span&gt;. Please use alias to rename it.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think the original issue was that the parseAttributeName cannot detect &quot;table.column&quot; notation, and as I understand this PR still doesn&apos;t fix this issue right?&lt;/p&gt;

&lt;p&gt;As a workaround, you can change your column renames to accomodate the new format.&lt;/p&gt;

&lt;p&gt;Any ideas? Am I missing something?&lt;/p&gt;</comment>
                            <comment id="16041434" author="maropu" created="Wed, 7 Jun 2017 19:03:53 +0000"  >&lt;p&gt;Thanks for the report.&lt;br/&gt;
I think there are two points you suggestedt: a qualifier and buck-ticks.&lt;br/&gt;
Yea, you&apos;re right and it seems my pr above wrongly drop a qualifier for aggregated column names(then, it changed the behaviour).&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// Spark-v2.1
&lt;/span&gt;scala&amp;gt; Seq((1, 2)).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;v1&quot;&lt;/span&gt;).createOrReplaceTempView(&lt;span class=&quot;code-quote&quot;&gt;&quot;s&quot;&lt;/span&gt;)

scala&amp;gt; Seq((1, 2)).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;v2&quot;&lt;/span&gt;).createOrReplaceTempView(&lt;span class=&quot;code-quote&quot;&gt;&quot;t&quot;&lt;/span&gt;)

scala&amp;gt; val df1 = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM s&quot;&lt;/span&gt;)
df1: org.apache.spark.sql.DataFrame = [id: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, v1: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; val df2 = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM t&quot;&lt;/span&gt;)
df2: org.apache.spark.sql.DataFrame = [id: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, v2: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; df1.join(df2, &lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt; :: Nil).groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).pivot(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).max(&lt;span class=&quot;code-quote&quot;&gt;&quot;v1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;v2&quot;&lt;/span&gt;).show
+---+-------------+-------------+                                               
| id|1_max(s.`v1`)|1_max(t.`v2`)|
+---+-------------+-------------+
|  1|            2|            2|
+---+-------------+-------------+

&lt;span class=&quot;code-comment&quot;&gt;// Master
&lt;/span&gt;scala&amp;gt; df1.join(df2, &lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt; :: Nil).groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).pivot(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).max(&lt;span class=&quot;code-quote&quot;&gt;&quot;v1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;v2&quot;&lt;/span&gt;).show
+---+---------+---------+                                                       
| id|1_max(v1)|1_max(v2)|
+---+---------+---------+
|  1|        2|        2|
+---+---------+---------+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We could easily fix this, but I&apos;m not 100% sure that we need to fix this. WDYT? cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// Master with a patch (https://github.com/apache/spark/compare/master...maropu:SPARK-17237-4)
&lt;/span&gt;scala&amp;gt; df1.join(df2, &lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt; :: Nil).groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).pivot(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).max(&lt;span class=&quot;code-quote&quot;&gt;&quot;v1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;v2&quot;&lt;/span&gt;).show
+---+-----------+-----------+                                                       
| id|1_max(s.v1)|1_max(t.v2)|
+---+-----------+-----------+
|  1|          2|          2|
+---+-----------+-----------+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On the other hand, IIUC back-ticks are not allowed in column names cuz they have special meaning in Spark.&lt;/p&gt;</comment>
                            <comment id="16042513" author="albertofem" created="Thu, 8 Jun 2017 10:20:39 +0000"  >&lt;p&gt;Hi there,&lt;/p&gt;

&lt;p&gt;thank you for your thorough answer.&lt;/p&gt;

&lt;p&gt;I think it would be good to fix it since the patch version bump in Spark may lead to think that you don&apos;t need to make changes in your code, and that may not be the case.&lt;/p&gt;

&lt;p&gt;Also, why are backticks not allowed since Spark 2.1.1? They seem to work fine in Spark 2.1.0.&lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;</comment>
                            <comment id="16042713" author="maropu" created="Thu, 8 Jun 2017 13:44:16 +0000"  >&lt;p&gt;sorry for confusing you, but I originally mean nested buck-ticks are not accepted as written in the description: &quot;`1_max(t.`v2`)`&quot;. Spark internally add outer buck-ticks in this case.&lt;/p&gt;</comment>
                            <comment id="16049230" author="apachespark" created="Wed, 14 Jun 2017 14:30:10 +0000"  >&lt;p&gt;User &apos;maropu&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18302&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18302&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16051288" author="maropu" created="Fri, 16 Jun 2017 01:57:58 +0000"  >&lt;p&gt;I checked the other behaviours and I probably think it seems to be correct to use aggregated column names without qualifiers (since other aggregated columns has no qualifier: &lt;a href=&quot;https://github.com/apache/spark/pull/18302/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18302/files&lt;/a&gt;). So, it seems the current master behaviour is okay to me for now.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 22 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32s27:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>