<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:01:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-25330] Permission issue after upgrade hadoop version to 2.7.7</title>
                <link>https://issues.apache.org/jira/browse/SPARK-25330</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;How to reproduce:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
# build spark
./dev/make-distribution.sh --name SPARK-25330 --tgz&#160; -Phadoop-2.7 -Phive -Phive-thriftserver -Pyarn

tar -zxf spark-2.4.0-SNAPSHOT-bin-SPARK-25330.tgz &amp;amp;&amp;amp; cd spark-2.4.0-SNAPSHOT-bin-SPARK-25330
export HADOOP_PROXY_USER=user_a
bin/spark-sql

export HADOOP_PROXY_USER=user_b
bin/spark-sql&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;main&quot; java.lang.RuntimeException: org.apache.hadoop.security.AccessControlException: Permission denied: user=user_b, access=EXECUTE, inode=&quot;/tmp/hive-$%7Buser.name%7D/user_b/668748f2-f6c5-4325-a797-fd0a7ee7f4d4&quot;:user_b:hadoop:drwx------
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:259)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:205)
at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13182749">SPARK-25330</key>
            <summary>Permission issue after upgrade hadoop version to 2.7.7</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yumwang">Yuming Wang</assignee>
                                    <reporter username="yumwang">Yuming Wang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 4 Sep 2018 08:09:12 +0000</created>
                <updated>Sat, 25 Jan 2020 06:54:41 +0000</updated>
                            <resolved>Sat, 25 Jan 2020 06:51:27 +0000</resolved>
                                    <version>2.3.2</version>
                    <version>2.4.0</version>
                                    <fixVersion>2.3.2</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>Build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16602768" author="apachespark" created="Tue, 4 Sep 2018 08:44:02 +0000"  >&lt;p&gt;User &apos;wangyum&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22327&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22327&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16605114" author="eyang" created="Thu, 6 Sep 2018 00:48:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt; Does Hadoop 2.7.5 works?  It might help us to isolate the release that started the regression to isolate the number of JIRAs that Hadoop team needs to go through.  Thanks&lt;/p&gt;</comment>
                            <comment id="16605129" author="q79969786" created="Thu, 6 Sep 2018 01:07:38 +0000"  >&lt;p&gt;No.&#160;The issue occurred in this commit:&#160;&lt;a href=&quot;https://github.com/apache/hadoop/commit/feb886f2093ea5da0cd09c69bd1360a335335c86&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;apache/hadoop@&lt;tt&gt;feb886f&lt;/tt&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16605131" author="q79969786" created="Thu, 6 Sep 2018 01:08:29 +0000"  >&lt;p&gt;I try to build Hadoop 2.7.7 with&#160;&lt;a href=&quot;https://github.com/apache/hadoop/blob/release-2.7.7-RC0/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java#L236&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;Configuration.getRestrictParserDefault(Object resource)&lt;/tt&gt;&lt;/a&gt;&#160;= true and false.&lt;br/&gt;
 It succeeded when&#160;&lt;tt&gt;Configuration.getRestrictParserDefault(Object resource)=false&lt;/tt&gt;, but failed when&#160;&lt;tt&gt;Configuration.getRestrictParserDefault(Object resource)=true&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="16605738" author="brahmareddy" created="Thu, 6 Sep 2018 12:54:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt; is it possible to share debug logs..? or did you notice when &lt;b&gt;&lt;tt&gt;getRestrictParserDefault(Object resource)&lt;/tt&gt;&lt;/b&gt; returns &lt;b&gt;true&lt;/b&gt;. Or do you&apos;ve script or testcase to reproduce this..want to dig more.&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The issue occurred in this commit:&#160;&lt;a href=&quot;https://github.com/apache/hadoop/commit/feb886f2093ea5da0cd09c69bd1360a335335c86&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;apache/hadoop@&lt;tt&gt;feb886f&lt;/tt&gt;&lt;/a&gt;.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;FYI..There is another commit on top of this which will skip the proxy user check when ugi isn&apos;t initialized.&lt;a href=&quot;https://github.com/apache/hadoop/commit/04219e55c8983f88573b10205dbca5411e744b35&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;04219e55c8983f88573b10205dbca5411e744b35&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Some more inputs will be helpful.&lt;/p&gt;</comment>
                            <comment id="16605906" author="q79969786" created="Thu, 6 Sep 2018 15:14:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brahmareddy&quot; class=&quot;user-hover&quot; rel=&quot;brahmareddy&quot;&gt;brahmareddy&lt;/a&gt; Sorry. I didn&apos;t have&#160;script&#160;because&#160;we need a kerberos env&#160;to reproduce it. I try to change&#160;&lt;tt&gt;getRestrictParserDefault&lt;/tt&gt; to&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; getRestrictParserDefault(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; resource) {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (resource &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; || !UserGroupInformation.isInitialized()) {
        &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;resource &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.&quot;&lt;/span&gt;);
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        UserGroupInformation user;
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;resource: &quot;&lt;/span&gt; + resource);
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;UserGroupInformation.isInitialized(): &quot;&lt;/span&gt; + UserGroupInformation.isInitialized());
          user = UserGroupInformation.getCurrentUser();
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;UserGroupInformation.getCurrentUser(): &quot;&lt;/span&gt; + UserGroupInformation.getCurrentUser().toString());
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;user.getRealUser(): &quot;&lt;/span&gt; + UserGroupInformation.getCurrentUser().getRealUser());
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;user.getRealUser().isFromKeytab(): &quot;&lt;/span&gt; + UserGroupInformation.getCurrentUser().isFromKeytab());
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;user.getRealUser().hasKerberosCredentials(): &quot;&lt;/span&gt; + UserGroupInformation.getCurrentUser().hasKerberosCredentials());
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;user.getLoginUser().isFromKeytab(): &quot;&lt;/span&gt; + UserGroupInformation.getLoginUser().isFromKeytab());
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;user.getLoginUser().getRealUser(): &quot;&lt;/span&gt; + UserGroupInformation.getLoginUser().getRealUser());
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;user.getLoginUser().hasKerberosCredentials(): &quot;&lt;/span&gt; + UserGroupInformation.getLoginUser().hasKerberosCredentials());
          &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.err.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;user.getLoginUser().isFromKeytab(): &quot;&lt;/span&gt; + UserGroupInformation.getLoginUser().isFromKeytab());
        } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
          &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RuntimeException(&lt;span class=&quot;code-quote&quot;&gt;&quot;Unable to determine current user&quot;&lt;/span&gt;, e);
        }
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; user.getRealUser() != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The output is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;...
resource: org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@62e6b5c8
UserGroupInformation.isInitialized(): true
UserGroupInformation.getCurrentUser(): user_b (auth:PROXY) via admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getRealUser().isFromKeytab(): false
user.getRealUser().hasKerberosCredentials(): false
user.getLoginUser().isFromKeytab(): false
user.getLoginUser().getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getLoginUser().hasKerberosCredentials(): false
user.getLoginUser().isFromKeytab(): false
resource: file:/apache/hive/conf/hive-site.xml
UserGroupInformation.isInitialized(): true
UserGroupInformation.getCurrentUser(): user_b (auth:PROXY) via admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getRealUser().isFromKeytab(): false
user.getRealUser().hasKerberosCredentials(): false
user.getLoginUser().isFromKeytab(): false
user.getLoginUser().getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getLoginUser().hasKerberosCredentials(): false
user.getLoginUser().isFromKeytab(): false
18/09/06 07:49:29 WARN HiveConf: DEPRECATED: hive.metastore.ds.retry.* no longer has any effect.  Use hive.hmshandler.retry.* instead
18/09/06 07:49:29 WARN HiveConf: HiveConf of name hive.metastore.local does not exist
18/09/06 07:49:29 WARN HiveConf: HiveConf of name hive.metastore.ds.retry.attempts does not exist
18/09/06 07:49:29 WARN HiveConf: HiveConf of name hive.metastore.ds.retry.interval does not exist
18/09/06 07:49:29 WARN HiveConf: HiveConf of name hive.server2.enable.impersonation does not exist
18/09/06 07:49:29 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
18/09/06 07:49:30 INFO ObjectStore: ObjectStore, initialize called
18/09/06 07:49:30 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
18/09/06 07:49:30 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
resource: org.apache.hadoop.hive.conf.LoopingByteArrayInputStream@ae7950d
UserGroupInformation.isInitialized(): true
UserGroupInformation.getCurrentUser(): user_b (auth:PROXY) via admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getRealUser().isFromKeytab(): false
user.getRealUser().hasKerberosCredentials(): false
user.getLoginUser().isFromKeytab(): false
user.getLoginUser().getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getLoginUser().hasKerberosCredentials(): false
user.getLoginUser().isFromKeytab(): false
resource: file:/apache/hive/conf/hive-site.xml
UserGroupInformation.isInitialized(): true
UserGroupInformation.getCurrentUser(): user_b (auth:PROXY) via admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getRealUser().isFromKeytab(): false
user.getRealUser().hasKerberosCredentials(): false
user.getLoginUser().isFromKeytab(): false
user.getLoginUser().getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)
user.getLoginUser().hasKerberosCredentials(): false
user.getLoginUser().isFromKeytab(): false
......
18/09/06 07:23:08 INFO deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
18/09/06 07:23:09 INFO SessionState: Created HDFS directory: /tmp/hive-${user.name}/user_b
18/09/06 07:23:09 INFO SessionState: Created local directory: /tmp/136f93db-8924-4366-a795-49960acde4d0_resources
Exception in thread &quot;main&quot; java.lang.RuntimeException: org.apache.hadoop.security.AccessControlException: Permission denied: user=user_b, access=EXECUTE, inode=&quot;/tmp/hive-$%7Buser.name%7D/user_b/136f93db-8924-4366-a795-49960acde4d0&quot;:user_a:hadoop:drwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The correct output should be:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;......
18/09/06 08:12:04 INFO SessionState: Created local directory: /tmp/799640f8-3d34-4cb7-90fe-5368c22881d5_resources
18/09/06 08:12:04 INFO SessionState: Created HDFS directory: /tmp/hive-admin/user_b/799640f8-3d34-4cb7-90fe-5368c22881d5
18/09/06 08:12:04 INFO SessionState: Created local directory: /tmp/admin/799640f8-3d34-4cb7-90fe-5368c22881d5
18/09/06 08:12:04 INFO SessionState: Created HDFS directory: /tmp/hive-admin/user_b/799640f8-3d34-4cb7-90fe-5368c22881d5/_tmp_space.db
......
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16605917" author="srowen" created="Thu, 6 Sep 2018 15:20:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt; does this affect basically anyone using spark-sql with a proxy user? does it affect just the command line? I&apos;m trying to get a sense of the scope of the impact. Would a normal Spark SQL job work?&lt;/p&gt;</comment>
                            <comment id="16606052" author="eyang" created="Thu, 6 Sep 2018 16:35:33 +0000"  >&lt;blockquote&gt;
&lt;p&gt;user.getRealUser(): admin@KERBEROS.MYCOM.COM (auth:KERBEROS)&lt;br/&gt;
user.getRealUser().isFromKeytab(): false&lt;br/&gt;
user.getRealUser().hasKerberosCredentials(): false&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;If I am reading this correctly, the RealUser must be from either a keytab or hasKerberosCredentials.  Both can not be false, otherwise, it is a security breach to Kerberos that RealUser was not authorized by KDC.  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=daryn&quot; class=&quot;user-hover&quot; rel=&quot;daryn&quot;&gt;daryn&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jlowe&quot; class=&quot;user-hover&quot; rel=&quot;jlowe&quot;&gt;jlowe&lt;/a&gt; thoughts?&lt;/p&gt;</comment>
                            <comment id="16606638" author="q79969786" created="Fri, 7 Sep 2018 02:22:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; It affects (Spark enable Hive support). &lt;tt&gt;spark-sql&lt;/tt&gt;, &lt;tt&gt;spark-shell&lt;/tt&gt; and &lt;tt&gt;spark-submit&#160;are all possible to using Hive&#160;with a proxy user.&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;The StackTrace:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: java.lang.RuntimeException: org.apache.hadoop.security.AccessControlException: Permission denied: user=user_b, access=EXECUTE, inode=&quot;/tmp/hive-$%7Buser.name%7D/user_b/2fa7b2a0-e8fb-4f26-ba96-61c52f0c64ee&quot;:user_a:hadoop:drwx------
   at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:319)
   at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:259)
   at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:205)
   at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:190)
   at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1780)
   at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:108)
   at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3933)
   at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1109)
   at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:851)
   at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
   at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
   at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:969)
   at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2206)
   at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2202)
   at java.security.AccessController.doPrivileged(Native Method)
   at javax.security.auth.Subject.doAs(Subject.java:422)
   at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1709)
   at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2200)

  at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:522)
  at org.apache.spark.sql.hive.client.HiveClientImpl.newState(HiveClientImpl.scala:183)
  at org.apache.spark.sql.hive.client.HiveClientImpl.&amp;lt;init&amp;gt;(HiveClientImpl.scala:117)
  at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
  at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
  at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
  at org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:272)
  at org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:384)
  at org.apache.spark.sql.hive.HiveUtils$.newClientForMetadata(HiveUtils.scala:286)
  at org.apache.spark.sql.hive.HiveExternalCatalog.client$lzycompute(HiveExternalCatalog.scala:66)
  at org.apache.spark.sql.hive.HiveExternalCatalog.client(HiveExternalCatalog.scala:65)
  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:215)
  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:215)
  at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:215)
  at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)
  ... 79 more&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16606644" author="srowen" created="Fri, 7 Sep 2018 02:33:59 +0000"  >&lt;p&gt;For clarity, you mean none of those things work with a proxy user? the example above suggests spark-sql does not work with a proxy user, but it works otherwise?&lt;/p&gt;</comment>
                            <comment id="16606659" author="q79969786" created="Fri, 7 Sep 2018 03:06:00 +0000"  >&lt;p&gt;It affects&#160;Spark&#160;enable Hive support&#160;with a proxy user.&lt;/p&gt;</comment>
                            <comment id="16606697" author="srowen" created="Fri, 7 Sep 2018 04:42:20 +0000"  >&lt;p&gt;Issue resolved by pull request 22327&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22327&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22327&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13176740">SPARK-25015</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10001">
                    <name>dependent</name>
                                            <outwardlinks description="depends upon">
                                        <issuelink>
            <issuekey id="13183174">HADOOP-15722</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 10 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3xp2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>