<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:13:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-1786] Kryo Serialization Error in GraphX</title>
                <link>https://issues.apache.org/jira/browse/SPARK-1786</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following code block will generate a serialization error when run in the spark-shell with Kryo enabled:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.storage._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.graphx._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.graphx.util._

val g = GraphGenerators.gridGraph(sc, 100, 100)
val e = g.edges
e.persist(StorageLevel.MEMORY_ONLY_SER)
e.collect().foreach(println(_)) &lt;span class=&quot;code-comment&quot;&gt;// &amp;lt;- Runs successfully the first time.
&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;// The following line will fail:
&lt;/span&gt;e.collect().foreach(println(_))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The following error is generated:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; e.collect().foreach(println(_))
14/05/09 18:31:13 INFO SparkContext: Starting job: collect at EdgeRDD.scala:59
14/05/09 18:31:13 INFO DAGScheduler: Got job 1 (collect at EdgeRDD.scala:59) with 8 output partitions (allowLocal=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)
14/05/09 18:31:13 INFO DAGScheduler: Final stage: Stage 1(collect at EdgeRDD.scala:59)
14/05/09 18:31:13 INFO DAGScheduler: Parents of &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; stage: List()
14/05/09 18:31:13 INFO DAGScheduler: Missing parents: List()
14/05/09 18:31:13 INFO DAGScheduler: Submitting Stage 1 (MappedRDD[15] at map at EdgeRDD.scala:59), which has no missing parents
14/05/09 18:31:13 INFO DAGScheduler: Submitting 8 missing tasks from Stage 1 (MappedRDD[15] at map at EdgeRDD.scala:59)
14/05/09 18:31:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 8 tasks
14/05/09 18:31:13 INFO TaskSetManager: Starting task 1.0:0 as TID 8 on executor localhost: localhost (PROCESS_LOCAL)
14/05/09 18:31:13 INFO TaskSetManager: Serialized task 1.0:0 as 1779 bytes in 3 ms
14/05/09 18:31:13 INFO TaskSetManager: Starting task 1.0:1 as TID 9 on executor localhost: localhost (PROCESS_LOCAL)
14/05/09 18:31:13 INFO TaskSetManager: Serialized task 1.0:1 as 1779 bytes in 4 ms
14/05/09 18:31:13 INFO TaskSetManager: Starting task 1.0:2 as TID 10 on executor localhost: localhost (PROCESS_LOCAL)
14/05/09 18:31:13 INFO TaskSetManager: Serialized task 1.0:2 as 1779 bytes in 4 ms
14/05/09 18:31:13 INFO TaskSetManager: Starting task 1.0:3 as TID 11 on executor localhost: localhost (PROCESS_LOCAL)
14/05/09 18:31:13 INFO TaskSetManager: Serialized task 1.0:3 as 1779 bytes in 4 ms
14/05/09 18:31:13 INFO TaskSetManager: Starting task 1.0:4 as TID 12 on executor localhost: localhost (PROCESS_LOCAL)
14/05/09 18:31:13 INFO TaskSetManager: Serialized task 1.0:4 as 1779 bytes in 3 ms
14/05/09 18:31:13 INFO TaskSetManager: Starting task 1.0:5 as TID 13 on executor localhost: localhost (PROCESS_LOCAL)
14/05/09 18:31:13 INFO TaskSetManager: Serialized task 1.0:5 as 1782 bytes in 4 ms
14/05/09 18:31:13 INFO TaskSetManager: Starting task 1.0:6 as TID 14 on executor localhost: localhost (PROCESS_LOCAL)
14/05/09 18:31:13 INFO TaskSetManager: Serialized task 1.0:6 as 1783 bytes in 4 ms
14/05/09 18:31:13 INFO TaskSetManager: Starting task 1.0:7 as TID 15 on executor localhost: localhost (PROCESS_LOCAL)
14/05/09 18:31:13 INFO TaskSetManager: Serialized task 1.0:7 as 1783 bytes in 4 ms
14/05/09 18:31:13 INFO Executor: Running task ID 9
14/05/09 18:31:13 INFO Executor: Running task ID 8
14/05/09 18:31:13 INFO Executor: Running task ID 11
14/05/09 18:31:13 INFO Executor: Running task ID 14
14/05/09 18:31:13 INFO Executor: Running task ID 10
14/05/09 18:31:13 INFO Executor: Running task ID 13
14/05/09 18:31:13 INFO Executor: Running task ID 15
14/05/09 18:31:13 INFO Executor: Running task ID 12
14/05/09 18:31:13 INFO BlockManager: Found block rdd_12_6 locally
14/05/09 18:31:13 INFO BlockManager: Found block rdd_12_4 locally
14/05/09 18:31:13 INFO BlockManager: Found block rdd_12_2 locally
14/05/09 18:31:13 INFO BlockManager: Found block rdd_12_7 locally
14/05/09 18:31:13 INFO BlockManager: Found block rdd_12_1 locally
14/05/09 18:31:13 INFO BlockManager: Found block rdd_12_3 locally
14/05/09 18:31:13 INFO BlockManager: Found block rdd_12_0 locally
14/05/09 18:31:13 INFO BlockManager: Found block rdd_12_5 locally
14/05/09 18:31:13 ERROR Executor: Exception in task ID 13
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 ERROR Executor: Exception in task ID 10
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 ERROR Executor: Exception in task ID 11
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 ERROR Executor: Exception in task ID 12
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 ERROR Executor: Exception in task ID 15
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 ERROR Executor: Exception in task ID 8
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 ERROR Executor: Exception in task ID 9
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 ERROR Executor: Exception in task ID 14
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 WARN TaskSetManager: Lost TID 11 (task 1.0:3)
14/05/09 18:31:13 WARN TaskSetManager: Loss was due to java.lang.NullPointerException
java.lang.NullPointerException
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
	at org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
	at org.apache.spark.scheduler.Task.run(Task.scala:51)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
14/05/09 18:31:13 ERROR TaskSetManager: Task 1.0:3 failed 1 times; aborting job
14/05/09 18:31:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
14/05/09 18:31:13 INFO TaskSetManager: Loss was due to java.lang.NullPointerException [duplicate 1]
14/05/09 18:31:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
14/05/09 18:31:13 INFO TaskSetManager: Loss was due to java.lang.NullPointerException [duplicate 2]
14/05/09 18:31:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
14/05/09 18:31:13 INFO TaskSetManager: Loss was due to java.lang.NullPointerException [duplicate 3]
14/05/09 18:31:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
14/05/09 18:31:13 INFO TaskSetManager: Loss was due to java.lang.NullPointerException [duplicate 4]
14/05/09 18:31:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
14/05/09 18:31:13 INFO DAGScheduler: Failed to run collect at EdgeRDD.scala:59
14/05/09 18:31:13 INFO TaskSchedulerImpl: Cancelling stage 1
14/05/09 18:31:13 INFO TaskSetManager: Loss was due to java.lang.NullPointerException [duplicate 5]
14/05/09 18:31:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
14/05/09 18:31:13 INFO TaskSetManager: Loss was due to java.lang.NullPointerException [duplicate 6]
14/05/09 18:31:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
14/05/09 18:31:13 INFO TaskSetManager: Loss was due to java.lang.NullPointerException [duplicate 7]
14/05/09 18:31:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
org.apache.spark.SparkException: Job aborted due to stage failure: Task 1.0:3 failed 1 times, most recent failure: Exception failure in TID 11 on host localhost: java.lang.NullPointerException
        org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:269)
        org.apache.spark.graphx.impl.EdgePartition$$anon$1.next(EdgePartition.scala:262)
        scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
        scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
        scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
        scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
        scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
        scala.collection.AbstractIterator.to(Iterator.scala:1157)
        scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
        scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
        scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
        scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
        org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
        org.apache.spark.rdd.RDD$$anonfun$15.apply(RDD.scala:706)
        org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
        org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1071)
        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:111)
        org.apache.spark.scheduler.Task.run(Task.scala:51)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:208)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1033)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1017)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1015)
	at scala.collection.mutable.ResizableArray$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1015)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:633)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:633)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:633)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1207)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
	at akka.actor.ActorCell.invoke(ActorCell.scala:456)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
	at akka.dispatch.Mailbox.run(Mailbox.scala:219)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We believe the error is associated with serialization of the EdgePartition.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12713430">SPARK-1786</key>
            <summary>Kryo Serialization Error in GraphX</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jegonzal">Joseph E. Gonzalez</assignee>
                                    <reporter username="jegonzal">Joseph E. Gonzalez</reporter>
                        <labels>
                    </labels>
                <created>Sat, 10 May 2014 01:29:21 +0000</created>
                <updated>Mon, 12 May 2014 02:22:01 +0000</updated>
                            <resolved>Mon, 12 May 2014 02:22:01 +0000</resolved>
                                    <version>1.0.0</version>
                                    <fixVersion>1.0.0</fixVersion>
                                    <component>GraphX</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="13994753" author="matei" created="Mon, 12 May 2014 02:22:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/724&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/724&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>391746</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 28 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1vguv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>391952</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>