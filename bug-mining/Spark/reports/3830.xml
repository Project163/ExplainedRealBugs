<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:45:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16334] SQL query on parquet table java.lang.ArrayIndexOutOfBoundsException</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16334</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Query:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select * from blabla where user_id = 415706251
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Error:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;16/06/30 14:07:27 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 0.0 (TID 3, hadoop6): java.lang.ArrayIndexOutOfBoundsException: 6934
        at org.apache.parquet.column.values.dictionary.PlainValuesDictionary$PlainBinaryDictionary.decodeToBinary(PlainValuesDictionary.java:119)
        at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.decodeDictionaryIds(VectorizedColumnReader.java:273)
        at org.apache.spark.sql.execution.datasources.parquet.VectorizedColumnReader.readBatch(VectorizedColumnReader.java:170)
        at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:230)
        at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.nextKeyValue(VectorizedParquetRecordReader.java:137)
        at org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:36)
        at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:91)
        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.scan_nextBatch$(Unknown Source)
        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
        at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
        at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:246)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240)
        at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:780)
        at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:780)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
        at org.apache.spark.scheduler.Task.run(Task.scala:85)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Work on 1.6.1&lt;/p&gt;</description>
                <environment></environment>
        <key id="12985890">SPARK-16334</key>
            <summary>SQL query on parquet table java.lang.ArrayIndexOutOfBoundsException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sameerag">Sameer Agarwal</assignee>
                                    <reporter username="epahomov">Egor Pahomov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jun 2016 21:16:31 +0000</created>
                <updated>Fri, 2 Sep 2016 23:17:08 +0000</updated>
                            <resolved>Fri, 2 Sep 2016 22:20:57 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="15358424" author="proflin" created="Fri, 1 Jul 2016 05:30:06 +0000"  >&lt;p&gt;hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=epahomov&quot; class=&quot;user-hover&quot; rel=&quot;epahomov&quot;&gt;epahomov&lt;/a&gt;, by which tool were your parquet files written, SparkSQL or ? In addition, what&apos;s the &lt;tt&gt;WriterVersion&lt;/tt&gt;, &lt;tt&gt;PARQUET_1_0 (&quot;v1&quot;)&lt;/tt&gt; or &lt;tt&gt;PARQUET_2_0 (&quot;v2&quot;)&lt;/tt&gt;?&lt;/p&gt;</comment>
                            <comment id="15363438" author="vivanov" created="Tue, 5 Jul 2016 23:11:55 +0000"  >&lt;p&gt;Hi, we discovered problem with the same stacktrace in Spark 2.0. In our case it&apos;s thrown during DataFrame.rdd.aggregate call. Moreover it somehow depends on volume of data, because it is not thrown when we change filter criteria accordingly. We used SparkSQL to write these parquet files and didn&apos;t explicitly specify WriterVersion option so I believe whatever version is set by default was used.&lt;/p&gt;</comment>
                            <comment id="15364501" author="vivanov" created="Wed, 6 Jul 2016 15:50:12 +0000"  >&lt;p&gt;Can&apos;t reproduce it on 1.6.1 too. Also in our case it looks like it fails in VectorizedColumnReader in INT96 case for TimestampType, which in turn calls PlainValuesDictionary.decodeToBinary(int id).&lt;/p&gt;</comment>
                            <comment id="15371572" author="vivanov" created="Mon, 11 Jul 2016 20:43:28 +0000"  >&lt;p&gt;I believe it relates to the following change in Spark 2.0:&lt;/p&gt;

&lt;p&gt;&quot;For example, we have implemented a new vectorized Parquet reader that does decompression and decoding in column batches. When decoding integer columns (on disk), this new reader is roughly 9 times faster than the non-vectorized one&quot; taken from this link:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Corresponding JIRA tickets:&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-12854&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-12854&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-14008&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-14008&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15371606" author="hvanhovell" created="Mon, 11 Jul 2016 20:58:08 +0000"  >&lt;p&gt;Could you try to disable the vectorized parquet reader. You can do this issuing the following SQL statement &lt;tt&gt;SET spark.sql.parquet.enableVectorizedReader = FALSE&lt;/tt&gt;, or by issuing &lt;tt&gt;spark.conf.set(&quot;spark.sql.parquet.enableVectorizedReader&quot;, &quot;false&quot;)&lt;/tt&gt; in the REPL.&lt;/p&gt;</comment>
                            <comment id="15371633" author="hvanhovell" created="Mon, 11 Jul 2016 21:13:19 +0000"  >&lt;p&gt;It would also be great if we can reproduce this. Could share an example?&lt;/p&gt;</comment>
                            <comment id="15372068" author="vivanov" created="Tue, 12 Jul 2016 02:19:10 +0000"  >&lt;p&gt;Hi Herman,&lt;/p&gt;

&lt;p&gt;Thank you for reply!&lt;/p&gt;

&lt;p&gt;I wasn&apos;t able to reproduce this error anymore with this spark.sql.parquet.enableVectorizedReader setting set to false in Spark 2.0.&lt;/p&gt;

&lt;p&gt;As for steps to reproduce: unfortunately I have reproduced it on partitioned parquet files containing client-sensitive data (we are calling SparkSession programmatically from our app), so I can&apos;t provide data here. Let&apos;s see what I can do.&lt;/p&gt;</comment>
                            <comment id="15380137" author="sameerag" created="Fri, 15 Jul 2016 21:22:26 +0000"  >&lt;p&gt;While I&apos;ve not been able to reproduce this bug, looking at the stack trace, I think one of the likely causes of this is that we&apos;re resetting the dictionary while reading every page in a row batch. This is generally okay but might cause problems if a batch has a combination of dictionary-encoded and non-dictionary-encoded pages.&lt;/p&gt;</comment>
                            <comment id="15380170" author="apachespark" created="Fri, 15 Jul 2016 21:41:05 +0000"  >&lt;p&gt;User &apos;sameeragarwal&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14225&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14225&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15380187" author="rxin" created="Fri, 15 Jul 2016 21:55:49 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=epakhomov&quot; class=&quot;user-hover&quot; rel=&quot;epakhomov&quot;&gt;epakhomov&lt;/a&gt; can you try the patch and see if it fixes your problem? &lt;a href=&quot;https://github.com/apache/spark/pull/14225&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14225&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15380249" author="epahomov" created="Fri, 15 Jul 2016 22:43:51 +0000"  >&lt;p&gt;Sure, would test on Monday.&lt;/p&gt;</comment>
                            <comment id="15380330" author="sameerag" created="Sat, 16 Jul 2016 00:01:35 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vivanov&quot; class=&quot;user-hover&quot; rel=&quot;vivanov&quot;&gt;vivanov&lt;/a&gt; too&lt;/p&gt;</comment>
                            <comment id="15384630" author="sameerag" created="Tue, 19 Jul 2016 18:21:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=epakhomov&quot; class=&quot;user-hover&quot; rel=&quot;epakhomov&quot;&gt;epakhomov&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lester&quot; class=&quot;user-hover&quot; rel=&quot;lester&quot;&gt;lester&lt;/a&gt; any luck with trying out this change? Also in order to prevent future regressions, it&apos;d be great if you can share an illustrative (anonymized) sample of data on which you&apos;re seeing this issue so that we can make it part of the test harness.&lt;/p&gt;</comment>
                            <comment id="15384736" author="epahomov" created="Tue, 19 Jul 2016 19:45:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sameerag&quot; class=&quot;user-hover&quot; rel=&quot;sameerag&quot;&gt;sameerag&lt;/a&gt; that particular case on which I experienced the problem - now working for me. It&apos;s hard for me to reproduce what exactly made the bug appear before - would not go into such much trouble. &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15398130" author="keith.j.kraus" created="Thu, 28 Jul 2016 20:11:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sameerag&quot; class=&quot;user-hover&quot; rel=&quot;sameerag&quot;&gt;sameerag&lt;/a&gt; I have just built branch-2.0 which should have included your patch, but I am still experiencing this issue. The parquet file I am using was written using Spark 1.6 and has ~450 columns.&lt;/p&gt;

&lt;p&gt;Issuing &lt;tt&gt;spark.conf.set(&quot;spark.sql.parquet.enableVectorizedReader&quot;, &quot;false&quot;)&lt;/tt&gt; prevents the issue from occurring, so it&apos;s definitely the vectorized parquet reader.&lt;/p&gt;

&lt;p&gt;Let me know if I can provide any additional information to help resolve this issue.&lt;/p&gt;</comment>
                            <comment id="15407607" author="sebastianherold" created="Thu, 4 Aug 2016 11:47:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sameer&quot; class=&quot;user-hover&quot; rel=&quot;sameer&quot;&gt;sameer&lt;/a&gt; We can reproduce the problem as well. &lt;tt&gt;spark.conf.set(&quot;spark.sql.parquet.enableVectorizedReader&quot;, &quot;false&quot;)&lt;/tt&gt; help us, too. We let you know, when we tried the patch.&lt;/p&gt;</comment>
                            <comment id="15408334" author="sameerag" created="Thu, 4 Aug 2016 19:01:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=keith.j.kraus&quot; class=&quot;user-hover&quot; rel=&quot;keith.j.kraus&quot;&gt;keith.j.kraus&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sebastianherold&quot; class=&quot;user-hover&quot; rel=&quot;sebastianherold&quot;&gt;sebastianherold&lt;/a&gt; &amp;#8211; would it be possible for you share the subset of data that&apos;s causing this bug (privately, if you&apos;d like)? If that&apos;s not really an option, can you please share some more information about its format (row group/ page encoding etc.) by running &lt;a href=&quot;https://github.com/apache/parquet-mr/blob/master/parquet-tools/src/main/scripts/parquet-dump&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;parquet-dump &lt;/a&gt; on your data?&lt;/p&gt;</comment>
                            <comment id="15408520" author="keith.j.kraus" created="Thu, 4 Aug 2016 21:27:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sameerag&quot; class=&quot;user-hover&quot; rel=&quot;sameerag&quot;&gt;sameerag&lt;/a&gt; Sharing even a subset of the data would be very difficult as it has confidential information. I&apos;ve gone ahead and ran parquet-dump on one part of the parquet (seems like the tool requires pointing it to a specific .parquet file rather than the directory of parts). I&apos;d prefer to share this privately if possible, how can I send you the command output?&lt;/p&gt;</comment>
                            <comment id="15408531" author="sameerag" created="Thu, 4 Aug 2016 21:37:32 +0000"  >&lt;p&gt;Thanks Keith, that&apos;ll work. You can mail it to me at sameer@databricks.com.&lt;/p&gt;</comment>
                            <comment id="15432038" author="epahomov" created="Tue, 23 Aug 2016 02:56:07 +0000"  >&lt;p&gt;Seems like a lot of people still have a problem even after suggested fix&lt;/p&gt;</comment>
                            <comment id="15432040" author="epahomov" created="Tue, 23 Aug 2016 02:56:43 +0000"  >&lt;p&gt;(just reason for reopen)&lt;/p&gt;</comment>
                            <comment id="15453040" author="tradersancho" created="Wed, 31 Aug 2016 18:48:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sameerag&quot; class=&quot;user-hover&quot; rel=&quot;sameerag&quot;&gt;sameerag&lt;/a&gt; I just upgraded to spark 2.0 from 1.6.2 and I am now experiencing this issue too.&lt;br/&gt;
My parquet file was generated in Pig (running on Tez 0.8.4) using pig-parquet-bundle 1.8.1.&lt;br/&gt;
If you have not been able to reproduce this issue yet, I could send you a sample of data.&lt;/p&gt;</comment>
                            <comment id="15453066" author="sameerag" created="Wed, 31 Aug 2016 18:57:58 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tradersancho&quot; class=&quot;user-hover&quot; rel=&quot;tradersancho&quot;&gt;tradersancho&lt;/a&gt; that&apos;d really help. The bug is most likely in a particular ordering of plain and dictionary encoded pages within a row-group but in absence of a repro, we&apos;re not quite able to lay a finger on it.&lt;/p&gt;</comment>
                            <comment id="15454644" author="sebastianherold" created="Thu, 1 Sep 2016 07:45:42 +0000"  >&lt;p&gt;Sorry for the late response. We noticed the error on some intermediate results during a hackathon and couldn&#8217;t reproduce it until now. But quite sure the error occurred when we wanted to open Spark 1.6-generated Parquet files with thousands or rows (don&#8217;t ask) in Spark 2.0. The data was very sparse, because it has been generated out of ugly JSON files. Maybe this helps others for reproduction.&lt;/p&gt;

</comment>
                            <comment id="15459479" author="apachespark" created="Fri, 2 Sep 2016 20:12:07 +0000"  >&lt;p&gt;User &apos;sameeragarwal&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14941&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14941&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15459507" author="sameerag" created="Fri, 2 Sep 2016 20:26:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tradersancho&quot; class=&quot;user-hover&quot; rel=&quot;tradersancho&quot;&gt;tradersancho&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=keith.j.kraus&quot; class=&quot;user-hover&quot; rel=&quot;keith.j.kraus&quot;&gt;keith.j.kraus&lt;/a&gt; - Thank you once again for sharing your datasets!&lt;/p&gt;

&lt;p&gt;It seems that the exception was caused by re-using the same dictionary column vector while reading multiple row groups one after the other. What made this particularly hard to catch was that this issue manifested only for a particular type of distribution of dictionary/plain encoded data while we read/populate the underlying bit packed dictionary data into a (reusable) column batch. While I&apos;ve manually verified that this patch fixes the issues that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tradersancho&quot; class=&quot;user-hover&quot; rel=&quot;tradersancho&quot;&gt;tradersancho&lt;/a&gt; experienced, it&apos;d be great if others can try out the fix as well: &lt;a href=&quot;https://github.com/apache/spark/pull/14941&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14941&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the meantime, we should also look into adding some randomized parquet distribution generators that can proactively catch edge cases like this.&lt;/p&gt;</comment>
                            <comment id="15459744" author="davies" created="Fri, 2 Sep 2016 22:20:57 +0000"  >&lt;p&gt;Issue resolved by pull request 14941&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14941&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14941&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15459859" author="apachespark" created="Fri, 2 Sep 2016 23:17:08 +0000"  >&lt;p&gt;User &apos;sameeragarwal&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14944&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14944&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 11 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30e5j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>