<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:22:45 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4846] When the vocabulary size is large, Word2Vec may yield &quot;OutOfMemoryError: Requested array size exceeds VM limit&quot;</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4846</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Exception in thread &quot;Driver&quot; java.lang.reflect.InvocationTargetException&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;br/&gt;
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
    at java.lang.reflect.Method.invoke(Method.java:606)&lt;br/&gt;
    at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:162)&lt;br/&gt;
Caused by: java.lang.OutOfMemoryError: Requested array size exceeds VM limit &lt;br/&gt;
    at java.util.Arrays.copyOf(Arrays.java:2271)&lt;br/&gt;
    at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:113)&lt;br/&gt;
    at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)&lt;br/&gt;
    at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:140)&lt;br/&gt;
    at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1870)&lt;br/&gt;
    at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1779)&lt;br/&gt;
    at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1186)&lt;br/&gt;
    at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)&lt;br/&gt;
    at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:42)&lt;br/&gt;
    at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:73)&lt;br/&gt;
    at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:164)&lt;br/&gt;
    at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158)&lt;br/&gt;
    at org.apache.spark.SparkContext.clean(SparkContext.scala:1242)&lt;br/&gt;
    at org.apache.spark.rdd.RDD.mapPartitionsWithIndex(RDD.scala:610)&lt;br/&gt;
    at org.apache.spark.mllib.feature.Word2Vec$$anonfun$fit$1.apply$mcVI$sp(Word2Vec.scala:291)&lt;br/&gt;
    at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)&lt;br/&gt;
    at org.apache.spark.mllib.feature.Word2Vec.fit(Word2Vec.scala:290)&lt;/p&gt;</description>
                <environment>&lt;p&gt;Use Word2Vec to process a corpus(sized 3.5G) with one partition.&lt;br/&gt;
The corpus contains about 300 million words and its vocabulary size is about 10 million.&lt;/p&gt;</environment>
        <key id="12761684">SPARK-4846</key>
            <summary>When the vocabulary size is large, Word2Vec may yield &quot;OutOfMemoryError: Requested array size exceeds VM limit&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="josephtang">Joseph Tang</assignee>
                                    <reporter username="josephtang">Joseph Tang</reporter>
                        <labels>
                    </labels>
                <created>Mon, 15 Dec 2014 05:26:32 +0000</created>
                <updated>Fri, 29 Jan 2016 02:15:40 +0000</updated>
                            <resolved>Fri, 30 Jan 2015 18:07:36 +0000</resolved>
                                    <version>1.1.1</version>
                    <version>1.2.0</version>
                                    <fixVersion>1.3.0</fixVersion>
                                    <component>MLlib</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14246337" author="apachespark" created="Mon, 15 Dec 2014 05:38:28 +0000"  >&lt;p&gt;User &apos;jinntrance&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3697&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3697&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14246665" author="srowen" created="Mon, 15 Dec 2014 14:11:30 +0000"  >&lt;p&gt;I think you&apos;re just running out of memory on your driver. It fails to have enough memory to copy and serialize two data structures, syn0Global and syn1Global which contain (vocab size * vector length) floats. With a default vector length of 100, and 10M vocab, that&apos;s at least 8GB of RAM, and the default for the driver isn&apos;t nearly that big.&lt;/p&gt;

&lt;p&gt;I think this is just a matter of increasing your driver memory. I imagine you will need 16GB+&lt;/p&gt;</comment>
                            <comment id="14246720" author="josephtang" created="Mon, 15 Dec 2014 15:06:18 +0000"  >&lt;p&gt;In the very beginning, either I thought it&apos;s an issue of memory shortage in the driver or in the executors . But after I increase the driver&apos;s memory to 16G and all the executors&apos; memory to 15G, this issue occurred in the same way.&lt;/p&gt;

&lt;p&gt;Actually in the RDD.mapPartitionsWithIndex(higher-order-function), firstly SparkContext.clean() is invoked and then ClosureCleaner.ensureSerializable() tries to serialize the higher-order-function(including the initialized syn0Global and syn1Global) using ByteArrayOutputStream before it is executed. &lt;/p&gt;

&lt;p&gt;Because the ByteArrayOutputStream has a maximum size limit of Int.MaxValue(2^31), which means the higher-order-function can not be larger than 2GB.  So in this case, I&apos;m trying to make syn0Global and syn1Global lazy, avoiding being serialized.&lt;/p&gt;</comment>
                            <comment id="14246732" author="srowen" created="Mon, 15 Dec 2014 15:21:20 +0000"  >&lt;p&gt;But being lazy doesn&apos;t really change whether it is serialized, right? one way or the other the recipients of the higher-order function have to get the same data. The function does use the data structures; it&apos;s not a question of simply keeping something out of the closure that shouldn&apos;t be there.&lt;/p&gt;

&lt;p&gt;Is the problem that only part of this large data structure should go to each partition?&lt;/p&gt;</comment>
                            <comment id="14247487" author="josephkb" created="Tue, 16 Dec 2014 00:24:15 +0000"  >&lt;p&gt;I agree with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; that the current implementation has to serialize those big data structures, no matter what.  Splitting the big syn0Global and syn1Global data structures across partitions sounds possible, but I would guess that the Word2VecModel itself would then need to be distributed as well since it occupies the same order of memory.  A distributed Word2VecModel sounds like a much bigger PR.&lt;/p&gt;

&lt;p&gt;In the meantime, a simpler &amp;amp; faster solution might be nice.  The easiest would be to catch the error and print a warning.  A fancier but better solution might be to automatically minCount as much as necessary (and print a warning about this automatic change).&lt;/p&gt;</comment>
                            <comment id="14248262" author="josephtang" created="Tue, 16 Dec 2014 13:51:06 +0000"  >&lt;p&gt;Hi  &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=josephkb&quot; class=&quot;user-hover&quot; rel=&quot;josephkb&quot;&gt;josephkb&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You are right. I had another test about the &apos;lazy&apos; and then found my misunderstanding of the object serialization in JVM. The &apos;lazy&apos; does not work. I&apos;ll remove the &apos;lazy&apos; later. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=josephkb&quot; class=&quot;user-hover&quot; rel=&quot;josephkb&quot;&gt;josephkb&lt;/a&gt;&apos;s good advice about automatic minCount should work, meanwhile it costs less memory.  However, one potential issue may be that in the worst case we have to try many times to find the best minCount when changing the minCount step by step.&lt;br/&gt;
Also I think a quick fix can be automatically decreasing the vectorSize, but in this case it has lower accuracy. &lt;/p&gt;

&lt;p&gt;Or else, if a Spark user changes one of minCount and vectorSize, we automatically change the other one.  If  a user change neither, we just auto change vectorSize by default.  How do you think? &lt;/p&gt;
</comment>
                            <comment id="14248802" author="josephkb" created="Tue, 16 Dec 2014 19:50:44 +0000"  >&lt;p&gt;Changing vectorSize sounds too aggressive to me.  I&apos;d vote for either the simple solution (throw a nice error), or an efficient method which chooses minCount automatically.  For the latter, this might work:&lt;/p&gt;

&lt;p&gt;1. Try the current method.  Catch errors during the collect() for vocab and during the array allocations.  If there is no error, skip step 2.&lt;br/&gt;
2. If there is an error, do 1 pass over the data to collect stats (e.g., a histogram).  Use those stats to choose a reasonable minCount.  Choose the vocab again, etc.&lt;br/&gt;
3. After the big array allocations, the algorithm can continue as before.&lt;/p&gt;</comment>
                            <comment id="14256852" author="josephtang" created="Tue, 23 Dec 2014 11:05:06 +0000"  >&lt;p&gt;It sounds accomplishable.&lt;/p&gt;

&lt;p&gt;I&apos;ll try this and make a PR later if it works pretty well .&lt;/p&gt;</comment>
                            <comment id="14261621" author="mengxr" created="Tue, 30 Dec 2014 23:11:03 +0000"  >&lt;p&gt;We merged `setMinCount()` in PR #3693. For this issue, throwing an error and asking users to try a larger minCount or a smaller vectorSize should be sufficient for now.&lt;/p&gt;</comment>
                            <comment id="14292718" author="mengxr" created="Tue, 27 Jan 2015 00:29:26 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=josephtang&quot; class=&quot;user-hover&quot; rel=&quot;josephtang&quot;&gt;josephtang&lt;/a&gt; Are you working on this issue? If not, do you mind me sending a PR that throwing an exception if vectorSize is beyond limit?&lt;/p&gt;</comment>
                            <comment id="14292853" author="josephtang" created="Tue, 27 Jan 2015 02:14:27 +0000"  >&lt;p&gt;Sorry about the procrastination. I just thought you meant there is no need to implement a dynamic strategy. I&apos;m still working on it and I&apos;d like to quickly fix this issue.&lt;/p&gt;

&lt;p&gt;Regarding your previous comment, should I throw a customized error in Spark or just an OOM besides the hint about minCount and vectorSize? &lt;/p&gt;</comment>
                            <comment id="14292886" author="josephtang" created="Tue, 27 Jan 2015 02:43:01 +0000"  >&lt;p&gt;Hi Xiangrui, here is a problem.&lt;/p&gt;

&lt;p&gt;PR #3693 that added the `setMinCount ` was merged to the branch `master`, while my PR #3697 was sent to `branch-1.1`.&lt;/p&gt;

&lt;p&gt;Should I better close  PR #3697 and send a new PR based on PR #3693?&lt;/p&gt;</comment>
                            <comment id="14292926" author="josephtang" created="Tue, 27 Jan 2015 03:35:39 +0000"  >&lt;p&gt;I&apos;ve added some code at &lt;a href=&quot;https://github.com/jinntrance/spark/compare/w2v-fix?diff=split&amp;amp;name=w2v-fix&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/jinntrance/spark/compare/w2v-fix?diff=split&amp;amp;name=w2v-fix&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If it&apos;s OK, I would send a new PR to the branch `master`.&lt;/p&gt;

&lt;p&gt;BTW, sorry for the horrible readability of the difference because of the space indent.&lt;/p&gt;</comment>
                            <comment id="14294884" author="mengxr" created="Wed, 28 Jan 2015 08:45:33 +0000"  >&lt;p&gt;We should throw a RuntimeException before allocating memory. Yes, it is easier to close #3697 and send a new PR to `master`.&lt;/p&gt;</comment>
                            <comment id="14295011" author="apachespark" created="Wed, 28 Jan 2015 11:14:06 +0000"  >&lt;p&gt;User &apos;jinntrance&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4247&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4247&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14295020" author="josephtang" created="Wed, 28 Jan 2015 11:23:30 +0000"  >&lt;p&gt;OK. I&apos;ve added a piece of RuntimeException code and have sent a new PR as below.&lt;/p&gt;</comment>
                            <comment id="14298959" author="mengxr" created="Fri, 30 Jan 2015 18:07:36 +0000"  >&lt;p&gt;Issue resolved by pull request 4247&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4247&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4247&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15035427" author="3cham" created="Wed, 2 Dec 2015 07:55:19 +0000"  >&lt;p&gt;I have a question regarding this issue: as far as I understand, word2vec.fit(input) will return a Word2VecModel object which will be stored on the driver&apos;s memory only? &lt;/p&gt;

&lt;p&gt;This leads to a painful consequence when experimenting on yarn-client mode, my driver (my computer) has limited memory and the object cannot fit into it. How could I improve the situation?&lt;/p&gt;
</comment>
                            <comment id="15045713" author="josephkb" created="Mon, 7 Dec 2015 20:56:15 +0000"  >&lt;p&gt;This sounds like a limitation of using yarn-client mode, if the client/driver has limited memory.&lt;/p&gt;

&lt;p&gt;Eventually, we could support a distributed representation of the model, but that would make the algorithm slower for many use cases.  It&apos;d be worth adding at some point, though, perhaps with a switching mechanism.  But I don&apos;t think it would be high priority unless there were many such problems.&lt;/p&gt;

&lt;p&gt;Is this something you can get around by changing modes, or by using a different client computer?&lt;/p&gt;</comment>
                            <comment id="15121503" author="3cham" created="Thu, 28 Jan 2016 13:59:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=josephkb&quot; class=&quot;user-hover&quot; rel=&quot;josephkb&quot;&gt;josephkb&lt;/a&gt;: I have changed the mode to yarn-cluster, however it seems that the implementation of word2vec has some problem with memory management. I give you some details about my experiment:&lt;/p&gt;

&lt;p&gt;The dataset is only 2.8GB big with about 700K different words and vector length is only 200, so syn0Global and syn1Global should be around 1.2GB. For spark 1.5.1, I contantly receive this exception even with 100GB for driver (-Xmx80G), 120GB for each worker (10 total). I then switched to 1.6.0, it worked with just 8G for driver and 20GB for each worker (what I expected). However, if I increase the vector length to 400, I receive this exception again even with 100GB driver and 120GB worker.&lt;/p&gt;

&lt;p&gt;The word2vec model should not be that big. Could you please give me some hint how I could solve this problem?&lt;/p&gt;</comment>
                            <comment id="15122775" author="josephtang" created="Fri, 29 Jan 2016 02:15:40 +0000"  >&lt;p&gt;Hi Tung,&lt;/p&gt;

&lt;p&gt;As far as I can remember, the data is serialized by ByteArray that has the&lt;br/&gt;
length limit Integer.MAX_VALUE, which means ByteArray can only serialize&lt;br/&gt;
data less than 2GB.&lt;/p&gt;

&lt;p&gt;May this piece of information help.&lt;/p&gt;

&lt;p&gt;Joseph&lt;/p&gt;

</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12767661">SPARK-5261</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 42 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i23fav:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12328982">1.1.2</customfieldvalue>
    <customfieldvalue id="12329029">1.2.1</customfieldvalue>
    <customfieldvalue id="12327642">1.3.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>