<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:28:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-37598] Pyspark&apos;s newAPIHadoopRDD() method fails with ShortWritables</title>
                <link>https://issues.apache.org/jira/browse/SPARK-37598</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;If sc. newAPIHadoopRDD() is called from Pyspark using an InputFormat that has a ShortWritable as a field, then the call to newAPIHadoopRDD() fails. The reason is that shortWritable is not explicitly handled by PythonHadoopUtil the way that other numeric writables are (like LongWritable). The result is that the ShortWritable is not converted to an object that can be serialized by spark, and a serialization error occurs. Below is an example stack trace from within the pyspark shell:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; rdd = sc.newAPIHadoopRDD(inputFormatClass=&lt;span class=&quot;code-quote&quot;&gt;&quot;[org.elasticsearch.hadoop.mr|http:&lt;span class=&quot;code-comment&quot;&gt;//org.elasticsearch.hadoop.mr/].EsInputFormat&quot;&lt;/span&gt;,
&lt;/span&gt;...&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;keyClass=&lt;span class=&quot;code-quote&quot;&gt;&quot;[org.apache.hadoop.io|http:&lt;span class=&quot;code-comment&quot;&gt;//org.apache.hadoop.io/].NullWritable&quot;&lt;/span&gt;,
&lt;/span&gt;...&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;valueClass=&lt;span class=&quot;code-quote&quot;&gt;&quot;[org.elasticsearch.hadoop.mr|http:&lt;span class=&quot;code-comment&quot;&gt;//org.elasticsearch.hadoop.mr/].LinkedMapWritable&quot;&lt;/span&gt;,
&lt;/span&gt;...&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;conf=conf)
2021-12-08 14:38:40,439 ERROR scheduler.TaskSetManager: task 0.0 in stage 15.0 (TID 31) had a not serializable result: org.apache.hadoop.io.ShortWritable
Serialization stack:
- object not serializable (class:&#160;[org.apache.hadoop.io|http:&lt;span class=&quot;code-comment&quot;&gt;//org.apache.hadoop.io/].ShortWritable, value: 1)
&lt;/span&gt;- writeObject data (class: java.util.HashMap)
- object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.HashMap, \{price=1})
- field (class: scala.Tuple2, name: _2, type: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;)
- object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;scala.Tuple2, (1,\{price=1}))
- element of array (index: 0)
- array (class [Lscala.Tuple2;, size 1); not retrying
Traceback (most recent call last):
&#160;File &lt;span class=&quot;code-quote&quot;&gt;&quot;&amp;lt;stdin&amp;gt;&quot;&lt;/span&gt;, line 4, in &amp;lt;module&amp;gt;
&#160;File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/hduser/spark-3.1.2-bin-hadoop3.2/python/pyspark/context.py&quot;&lt;/span&gt;, line 853, in newAPIHadoopRDD
&#160;&#160;jconf, batchSize)
&#160;File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/hduser/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;&lt;/span&gt;, line 1305, in __call__
&#160;File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/hduser/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/utils.py&quot;&lt;/span&gt;, line 111, in deco
&#160;&#160;&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; f(*a, **kw)
&#160;File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/hduser/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py&quot;&lt;/span&gt;, line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling z:org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD.
: org.apache.spark.SparkException: Job aborted due to stage failure: task 0.0 in stage 15.0 (TID 31) had a not serializable result: org.apache.hadoop.io.ShortWritable
Serialization stack:
- object not serializable (class:&#160;[org.apache.hadoop.io|http:&lt;span class=&quot;code-comment&quot;&gt;//org.apache.hadoop.io/].ShortWritable, value: 1)
&lt;/span&gt;- writeObject data (class: java.util.HashMap)
- object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.HashMap, \{price=1})
- field (class: scala.Tuple2, name: _2, type: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;)
- object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;scala.Tuple2, (1,\{price=1}))
- element of array (index: 0)
- array (class [Lscala.Tuple2;, size 1)
at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)
at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)
at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)
at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)
at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)
at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)
at scala.Option.foreach(Option.scala:407)
at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)
at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)
at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)
at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)
at org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1449)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)
at org.apache.spark.rdd.RDD.take(RDD.scala:1422)
at org.apache.spark.api.python.SerDeUtil$.pairRDDToPython(SerDeUtil.scala:173)
at org.apache.spark.api.python.PythonRDD$.newAPIHadoopRDD(PythonRDD.scala:385)
at org.apache.spark.api.python.PythonRDD.newAPIHadoopRDD(PythonRDD.scala)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
at py4j.Gateway.invoke(Gateway.java:282)
at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
at py4j.commands.CallCommand.execute(CallCommand.java:79)
at py4j.GatewayConnection.run(GatewayConnection.java:238)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <environment></environment>
        <key id="13416352">SPARK-37598</key>
            <summary>Pyspark&apos;s newAPIHadoopRDD() method fails with ShortWritables</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="keith.massey">Keith Massey</assignee>
                                    <reporter username="keith.massey">Keith Massey</reporter>
                        <labels>
                    </labels>
                <created>Thu, 9 Dec 2021 17:56:59 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:52 +0000</updated>
                            <resolved>Mon, 13 Dec 2021 00:07:49 +0000</resolved>
                                    <version>2.4.8</version>
                    <version>3.0.3</version>
                    <version>3.1.2</version>
                    <version>3.2.0</version>
                                    <fixVersion>3.3.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17456622" author="apachespark" created="Thu, 9 Dec 2021 18:02:24 +0000"  >&lt;p&gt;User &apos;masseyke&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34838&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34838&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17456623" author="apachespark" created="Thu, 9 Dec 2021 18:03:26 +0000"  >&lt;p&gt;User &apos;masseyke&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34838&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34838&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17458097" author="gurwls223" created="Mon, 13 Dec 2021 00:07:49 +0000"  >&lt;p&gt;Issue resolved by pull request 34838&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34838&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34838&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 48 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0xio8:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>