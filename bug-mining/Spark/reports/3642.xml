<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:44:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-15489] Dataset kryo encoder won&apos;t load custom user settings </title>
                <link>https://issues.apache.org/jira/browse/SPARK-15489</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When setting a custom &quot;spark.kryo.registrator&quot; (or any other configuration for that matter) through the API, this configuration will not propagate to the encoder that uses a KryoSerializer since it instantiates with &quot;new SparkConf()&quot;.&lt;br/&gt;
See:  &lt;a href=&quot;https://github.com/apache/spark/blob/07c36a2f07fcf5da6fb395f830ebbfc10eb27dcc/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/objects/objects.scala#L554&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/07c36a2f07fcf5da6fb395f830ebbfc10eb27dcc/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/objects/objects.scala#L554&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This could be hacked by providing those configurations as System properties, but this probably should be passed to the encoder and set in the SerializerInstance after creation.&lt;/p&gt;

&lt;p&gt;Example:&lt;br/&gt;
When using Encoders with kryo to encode generically typed Objects in the following manner:&lt;/p&gt;

&lt;p&gt;public static &amp;lt;T&amp;gt; Encoder&amp;lt;T&amp;gt; encoder() {&lt;br/&gt;
  return Encoders.kryo((Class&amp;lt;T&amp;gt;) Object.class);&lt;br/&gt;
}&lt;/p&gt;

&lt;p&gt;I get a decoding exception when trying to decode `java.util.Collections$UnmodifiableCollection`, which probably comes from Guava&apos;s `ImmutableList`.&lt;/p&gt;

&lt;p&gt;This happens when running with master = local&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;. Same code had no problems with RDD api.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12972162">SPARK-15489</key>
            <summary>Dataset kryo encoder won&apos;t load custom user settings </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="amitsela">Amit Sela</assignee>
                                    <reporter username="amitsela">Amit Sela</reporter>
                        <labels>
                    </labels>
                <created>Mon, 23 May 2016 19:41:06 +0000</created>
                <updated>Mon, 13 Jun 2016 08:53:36 +0000</updated>
                            <resolved>Fri, 10 Jun 2016 21:37:06 +0000</resolved>
                                    <version>1.6.1</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15296950" author="amitsela" created="Mon, 23 May 2016 19:41:48 +0000"  >&lt;p&gt;I&apos;ve tried registering `UnmodifiableCollectionsSerializer` and `ImmutableListSerializer` from: &lt;a href=&quot;https://github.com/magro/kryo-serializers&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/magro/kryo-serializers&lt;/a&gt; &lt;br/&gt;
but no luck there..&lt;/p&gt;</comment>
                            <comment id="15296951" author="amitsela" created="Mon, 23 May 2016 19:42:09 +0000"  >&lt;p&gt;Serialization trace:&lt;br/&gt;
tupleTags (org.apache.beam.sdk.values.TupleTagList)&lt;br/&gt;
tupleTagList (org.apache.beam.sdk.transforms.join.CoGbkResultSchema)&lt;br/&gt;
schema (org.apache.beam.sdk.transforms.join.CoGbkResult)&lt;br/&gt;
value (org.apache.beam.sdk.values.KV)&lt;br/&gt;
value (org.apache.beam.sdk.util.WindowedValue$TimestampedValueInGlobalWindow)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:626)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)&lt;br/&gt;
at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)&lt;br/&gt;
at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)&lt;br/&gt;
at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)&lt;br/&gt;
at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:221)&lt;br/&gt;
at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:729)&lt;br/&gt;
at org.apache.spark.serializer.KryoSerializerInstance.deserialize(KryoSerializer.scala:311)&lt;br/&gt;
at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificSafeProjection.apply(Unknown Source)&lt;br/&gt;
at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.fromRow(ExpressionEncoder.scala:230)&lt;br/&gt;
... 44 more&lt;br/&gt;
Caused by: java.lang.UnsupportedOperationException&lt;br/&gt;
at java.util.Collections$UnmodifiableCollection.add(Collections.java:1075)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:109)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:18)&lt;br/&gt;
at com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:648)&lt;br/&gt;
at com.esotericsoftware.kryo.serializers.FieldSerializer$ObjectField.read(FieldSerializer.java:605)&lt;br/&gt;
... 61 more&lt;/p&gt;</comment>
                            <comment id="15296963" author="marmbrus" created="Mon, 23 May 2016 19:49:10 +0000"  >&lt;p&gt;Is your registration making into the instance of kryo that we use for encoders?  Is possible we aren&apos;t propagating stuff correctly.&lt;/p&gt;</comment>
                            <comment id="15296964" author="marmbrus" created="Mon, 23 May 2016 19:49:26 +0000"  >&lt;p&gt;Also, does this problem exist in the 2.0 preview?&lt;/p&gt;</comment>
                            <comment id="15296989" author="amitsela" created="Mon, 23 May 2016 20:01:46 +0000"  >&lt;p&gt;In 2.0.0-SNAPSHOT it manifests as:&lt;/p&gt;

&lt;p&gt;java.lang.AssertionError: assertion failed: copyAndReset must return a zero value copy&lt;br/&gt;
	at scala.Predef$.assert(Predef.scala:179)&lt;br/&gt;
	at org.apache.spark.util.AccumulatorV2.writeReplace(AccumulatorV2.scala:157)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.io.ObjectStreamClass.invokeWriteReplace(ObjectStreamClass.java:1075)&lt;br/&gt;
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1134)&lt;br/&gt;
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)&lt;br/&gt;
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)&lt;br/&gt;
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)&lt;br/&gt;
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)&lt;br/&gt;
.................&lt;br/&gt;
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)&lt;br/&gt;
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:133)&lt;br/&gt;
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:114)&lt;br/&gt;
	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:240)&lt;br/&gt;
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:287)&lt;br/&gt;
	at org.apache.spark.sql.Dataset$$anonfun$collectAsList$1$$anonfun$apply$12.apply(Dataset.scala:2115)&lt;br/&gt;
	at org.apache.spark.sql.Dataset$$anonfun$collectAsList$1$$anonfun$apply$12.apply(Dataset.scala:2114)&lt;br/&gt;
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)&lt;br/&gt;
	at org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2436)&lt;br/&gt;
	at org.apache.spark.sql.Dataset$$anonfun$collectAsList$1.apply(Dataset.scala:2114)&lt;br/&gt;
	at org.apache.spark.sql.Dataset$$anonfun$collectAsList$1.apply(Dataset.scala:2113)&lt;br/&gt;
	at org.apache.spark.sql.Dataset.withCallback(Dataset.scala:2449)&lt;br/&gt;
	at org.apache.spark.sql.Dataset.collectAsList(Dataset.scala:2113)&lt;br/&gt;
..................&lt;/p&gt;</comment>
                            <comment id="15297087" author="amitsela" created="Mon, 23 May 2016 21:09:05 +0000"  >&lt;p&gt;This is my registrator:&lt;/p&gt;

&lt;p&gt;public class ImmutableRegistrator implements KryoRegistrator {&lt;/p&gt;

&lt;p&gt;  @Override&lt;br/&gt;
  public void registerClasses(Kryo kryo) {&lt;br/&gt;
    try &lt;/p&gt;
{
      kryo.register(Class.forName(&quot;java.util.Collections$UnmodifiableCollection&quot;),
              new UnmodifiableCollectionsSerializer());
      kryo.register(ImmutableList.class, new ImmutableListSerializer());
    }
&lt;p&gt; catch (ClassNotFoundException e) &lt;/p&gt;
{
      //
    }
&lt;p&gt;  }&lt;br/&gt;
}&lt;/p&gt;

&lt;p&gt;And I register with: &lt;br/&gt;
conf.set(&quot;spark.kryo.registrator&quot;, ImmutableRegistrator.class.getCanonicalName())&lt;/p&gt;

&lt;p&gt;When KryoSerializer.deserializeStream is called I see my registrar in KryoSerializerInstance, but when KryoSerializer.deserialize&lt;span class=&quot;error&quot;&gt;&amp;#91;T: ClassTag&amp;#93;&lt;/span&gt;(bytes: ByteBuffer) is called I&apos;m not so sure, if the instance is this.ks then no, I don&apos;t see my registrar.&lt;/p&gt;</comment>
                            <comment id="15297095" author="marmbrus" created="Mon, 23 May 2016 21:14:03 +0000"  >&lt;p&gt;Wild guess... &lt;a href=&quot;https://github.com/apache/spark/blob/07c36a2f07fcf5da6fb395f830ebbfc10eb27dcc/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/objects/objects.scala#L554&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/07c36a2f07fcf5da6fb395f830ebbfc10eb27dcc/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/objects/objects.scala#L554&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That is probably not using spark&apos;s config correctly.&lt;/p&gt;</comment>
                            <comment id="15298847" author="amitsela" created="Tue, 24 May 2016 20:38:14 +0000"  >&lt;p&gt;Well it looks like the codegen creates a `new SparkConf()`, instead of deserializing a &quot;broadcasted&quot; one. &lt;br/&gt;
I&apos;ve tried adding the registrator configuration as a System parameter (-D), but it didn&apos;t catch. Is the generated code executed in the JVM ? in the same one if running in standalone ?&lt;/p&gt;</comment>
                            <comment id="15298883" author="marmbrus" created="Tue, 24 May 2016 20:51:27 +0000"  >&lt;p&gt;It should run in the same JVM when running in local mode, otherwise it&apos;ll run in an executor.&lt;/p&gt;

&lt;p&gt;I think that when we construct an encoder, we should probably be passing this kind of information in.&lt;/p&gt;</comment>
                            <comment id="15304222" author="amitsela" created="Fri, 27 May 2016 15:50:33 +0000"  >&lt;p&gt;I would expect this to be related to KryoSerializer not registering the user-provided registrator, but I&apos;ve added a print in &lt;a href=&quot;https://github.com/apache/spark/blob/07c36a2f07fcf5da6fb395f830ebbfc10eb27dcc/core/src/main/scala/org/apache/spark/serializer/KryoSerializer.scala#L123&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/07c36a2f07fcf5da6fb395f830ebbfc10eb27dcc/core/src/main/scala/org/apache/spark/serializer/KryoSerializer.scala#L123&lt;/a&gt; to check if any new Kryo is created without the provided registrator, but it seems that all instances have a user-provided registrator (if one is provided).&lt;/p&gt;</comment>
                            <comment id="15304886" author="amitsela" created="Fri, 27 May 2016 22:03:27 +0000"  >&lt;p&gt;Got it!&lt;/p&gt;

&lt;p&gt;So I wasn&apos;t using the custom registrator correctly, it works better like this:&lt;/p&gt;

&lt;p&gt;public class ImmutablesRegistrator implements KryoRegistrator {&lt;/p&gt;

&lt;p&gt;  @Override&lt;br/&gt;
  public void registerClasses(Kryo kryo) &lt;/p&gt;
{
    UnmodifiableCollectionsSerializer.registerSerializers(kryo);
    // Guava
    ImmutableListSerializer.registerSerializers(kryo);
    ImmutableSetSerializer.registerSerializers(kryo);
    ImmutableMapSerializer.registerSerializers(kryo);
    ImmutableMultimapSerializer.registerSerializers(kryo);
  }
&lt;p&gt;}&lt;/p&gt;</comment>
                            <comment id="15304893" author="amitsela" created="Fri, 27 May 2016 22:07:21 +0000"  >&lt;p&gt;The issue here is the fact that setting the SparkConf does not propagate to the KryoSerializer used by the encoder.&lt;br/&gt;
I managed to make this work by using Java System properties instead of SparkConf#set since the SparkConf constructor will take them into account, but it&apos;s a hack...&lt;/p&gt;

&lt;p&gt;For now I think I&apos;ll change the description of the issue, and propose this as a temporary solution.&lt;/p&gt;</comment>
                            <comment id="15305997" author="amitsela" created="Sun, 29 May 2016 17:07:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt; you can assign this one to me.&lt;/p&gt;</comment>
                            <comment id="15306826" author="marmbrus" created="Mon, 30 May 2016 17:08:24 +0000"  >&lt;p&gt;As soon as you open a PR it will auto assign.&lt;/p&gt;</comment>
                            <comment id="15308794" author="apachespark" created="Tue, 31 May 2016 22:49:11 +0000"  >&lt;p&gt;User &apos;amitsela&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/13424&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/13424&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15325327" author="marmbrus" created="Fri, 10 Jun 2016 21:37:06 +0000"  >&lt;p&gt;Issue resolved by pull request 13424&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/13424&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/13424&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 23 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2ydwn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>