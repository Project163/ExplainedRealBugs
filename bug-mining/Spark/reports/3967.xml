<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:46:57 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16533] Spark application not handling preemption messages</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16533</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Here is the scenario:&lt;br/&gt;
I launch job 1 into Q1 and allow it to grow to 100% cluster utilization.&lt;br/&gt;
I wait between 15-30 mins ( for this job to complete with 100% of the cluster available takes about 1hr so job 1 is between 25-50% complete). Note that if I wait less time then the issue sometimes does not occur, it appears to be only after the job 1 is at least 25% complete.&lt;br/&gt;
I launch job 2 into Q2 and preemption occurs on the Q1 shrinking the job to allow 70% of cluster utilization.&lt;br/&gt;
At this point job 1 basically halts progress while job 2 continues to execute as normal and finishes. Job 2 either:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Fails its attempt and restarts. By the time this attempt fails the other job is already complete meaning the second attempt has full cluster availability and finishes.&lt;/li&gt;
	&lt;li&gt;The job remains at its current progress and simply does not finish ( I have waited ~6 hrs until finally killing the application ).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Looking into the error log there is this constant error message:&lt;br/&gt;
WARN NettyRpcEndpointRef: Error sending message &lt;span class=&quot;error&quot;&gt;&amp;#91;message = RemoveExecutor(454,Container container_1468422920649_0001_01_000594 on host: ip-NUMBERS.ec2.internal was preempted.)&amp;#93;&lt;/span&gt; in X attempts&lt;/p&gt;

&lt;p&gt;My observations have led me to believe that the application master does not know about this container being killed and continuously asks the container to remove the executor until eventually failing the attempt or continue trying to remove the executor.&lt;/p&gt;

&lt;p&gt;I have done much digging online for anyone else experiencing this issue but have come up with nothing.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Yarn version: Hadoop 2.7.1-amzn-0&lt;/p&gt;

&lt;p&gt;AWS EMR Cluster running:&lt;br/&gt;
1 x r3.8xlarge (Master)&lt;br/&gt;
52 x r3.8xlarge (Core)&lt;/p&gt;

&lt;p&gt;Spark version : 1.6.0&lt;br/&gt;
Scala version: 2.10.5&lt;br/&gt;
Java version: 1.8.0_51&lt;/p&gt;

&lt;p&gt;Input size: ~10 tb&lt;br/&gt;
Input coming from S3&lt;/p&gt;

&lt;p&gt;Queue Configuration:&lt;br/&gt;
Dynamic allocation: enabled&lt;br/&gt;
Preemption: enabled&lt;br/&gt;
Q1: 70% capacity with max of 100%&lt;br/&gt;
Q2: 30% capacity with max of 100%&lt;/p&gt;

&lt;p&gt;Job Configuration:&lt;br/&gt;
Driver memory = 10g&lt;br/&gt;
Executor cores = 6&lt;br/&gt;
Executor memory = 10g&lt;br/&gt;
Deploy mode = cluster&lt;br/&gt;
Master = yarn&lt;br/&gt;
maxResultSize = 4g&lt;br/&gt;
Shuffle manager = hash&lt;/p&gt;</environment>
        <key id="12989252">SPARK-16533</key>
            <summary>Spark application not handling preemption messages</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="angolon@gmail.com">Angus Gerry</assignee>
                                    <reporter username="LucasW">Lucas Winkelmann</reporter>
                        <labels>
                    </labels>
                <created>Wed, 13 Jul 2016 21:13:36 +0000</created>
                <updated>Sun, 17 May 2020 17:46:52 +0000</updated>
                            <resolved>Thu, 1 Sep 2016 17:37:49 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>EC2</component>
                    <component>Input/Output</component>
                    <component>Optimizer</component>
                    <component>Scheduler</component>
                    <component>Spark Core</component>
                    <component>Spark Submit</component>
                    <component>YARN</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="15381616" author="emaadmanzoor" created="Mon, 18 Jul 2016 01:38:12 +0000"  >&lt;p&gt;I had the same issue running on EC2 with single-core (m3.medium) nodes.&lt;/p&gt;

&lt;p&gt;I was able to resolve it using the workaround mentioned in this issue: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-13906&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-13906&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In &lt;tt&gt;spark-defaults.conf&lt;/tt&gt; set &lt;tt&gt;spark.rpc.netty.dispatcher.numThreads 2&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="15384760" author="lucasw" created="Tue, 19 Jul 2016 20:01:27 +0000"  >&lt;p&gt;I have changed this configuration value to 2 as well as 3 and I am still experiencing the same error messages, once again only if the first job is more than ~50% complete the job fails, yet the other job continues with no problems.&lt;/p&gt;</comment>
                            <comment id="15384780" author="emaadmanzoor" created="Tue, 19 Jul 2016 20:12:20 +0000"  >&lt;p&gt;It appears to be unresolved for me too.&lt;/p&gt;

&lt;p&gt;I did not see the 50% trend but I did face this issue when my cluster was slightly overloaded (for example, 4 cores with 4 Spark applications running). I observed that my application was thrashing; the queue that was preempted reclaimed its resources immediately and then got re-preempted.&lt;/p&gt;

&lt;p&gt;You may be facing the same issue if you also see very high container ID&apos;s (in your case, &lt;tt&gt;container_1468422920649_0001_01_000594&lt;/tt&gt; which probably points to your application 1&apos;s attempt 1 being preempted over 500 times). Could you check the YARN resource manager logs to see if your application rapidly releases and reclaims resources? Does this also happen to you when your cluster is overloaded?&lt;/p&gt;

&lt;p&gt;I have not dug further but the thrashing appears related to this YARN issue: &lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-4059&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/YARN-4059&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think setting &lt;tt&gt;yarn.scheduler.fair.locality.threshold.node&lt;/tt&gt; in &lt;tt&gt;yarn-site.xml&lt;/tt&gt; may help avoid thrashing: this is the number of scheduling opportunities to miss since the last container assignment (as a fraction of the cluster size).&lt;/p&gt;


</comment>
                            <comment id="15384820" author="lucasw" created="Tue, 19 Jul 2016 20:36:56 +0000"  >&lt;p&gt;Looking into the container ID&apos;s I did find some extremely high numbers. I will increase in the threshold.node configuration and see what the results are.&lt;/p&gt;</comment>
                            <comment id="15385045" author="lucasw" created="Tue, 19 Jul 2016 23:12:09 +0000"  >&lt;p&gt;Increasing this number also did not change anything. Although I am not using the fair scheduler I am using the capacity scheduler so this attribute does not work anyway. I used the capacity scheduler alternative and still no luck&lt;/p&gt;</comment>
                            <comment id="15385048" author="emaadmanzoor" created="Tue, 19 Jul 2016 23:15:18 +0000"  >&lt;p&gt;Hopefully someone with more experience with Spark chimes in on this. I&apos;ll work on reproducing it and collecting the complete logs.&lt;/p&gt;

&lt;p&gt;Note that I am experiencing this on Spark 2.0.0 too.&lt;/p&gt;</comment>
                            <comment id="15385051" author="lucasw" created="Tue, 19 Jul 2016 23:18:02 +0000"  >&lt;p&gt;Glad I am not the only one. I would attach my error logs but unfortunately they are above the maximum file size that is allowed for upload. If anyone wants more information on this I can provide it.&lt;/p&gt;</comment>
                            <comment id="15421006" author="lenhattan86@gmail.com" created="Mon, 15 Aug 2016 14:10:03 +0000"  >&lt;p&gt;This issue happens very often with large jobs.  &lt;br/&gt;
This one must be a critical issue.&lt;br/&gt;
I hope this will be solved soon to make Spark works well with Yarn dynamic allocation.&lt;/p&gt;</comment>
                            <comment id="15427625" author="apachespark" created="Fri, 19 Aug 2016 04:44:05 +0000"  >&lt;p&gt;User &apos;angolon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14710&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14710&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15456416" author="apachespark" created="Thu, 1 Sep 2016 19:43:07 +0000"  >&lt;p&gt;User &apos;vanzin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14925&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14925&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15457493" author="apachespark" created="Fri, 2 Sep 2016 04:30:08 +0000"  >&lt;p&gt;User &apos;angolon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14933&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14933&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12992136">SPARK-16702</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 11 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30xvz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>