<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:44:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-50581] Dataset.observe() is not working with UDAF</title>
                <link>https://issues.apache.org/jira/browse/SPARK-50581</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Dataset.observe() supports generic aggregation expressions for collected metrics, but it doesn&apos;t work when trying to use custom UDAF.&lt;br/&gt;
It fails on serialization exception (the fix may be very small: annotate inputProjection field in ScalaAggregator as @transient).&#160;&lt;br/&gt;
&#160;&lt;br/&gt;
Failure example:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.lang.{&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; =&amp;gt; JLong}

spark.udf.register(&lt;span class=&quot;code-quote&quot;&gt;&quot;someUdaf&quot;&lt;/span&gt;, udaf(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Aggregator[JLong, JLong, JLong] {
  def zero: JLong = 0L
  def reduce(b: JLong, a: JLong): JLong = a + b
  def merge(b1: JLong, b2: JLong): JLong = b1 + b2
  def finish(r: JLong): JLong = r
  def bufferEncoder: Encoder[JLong] = Encoders.LONG
  def outputEncoder: Encoder[JLong] = Encoders.LONG
}))

val df = spark.range(100)

&lt;span class=&quot;code-comment&quot;&gt;// regular udaf usage is working
&lt;/span&gt;df.agg(expr(&lt;span class=&quot;code-quote&quot;&gt;&quot;someUdaf(id)&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;agg&quot;&lt;/span&gt;)).show()

&lt;span class=&quot;code-comment&quot;&gt;// udaf usage in observe is not working (serialization exception)
&lt;/span&gt;df.observe(
    name = &lt;span class=&quot;code-quote&quot;&gt;&quot;my_metrics&quot;&lt;/span&gt;,
    expr(&lt;span class=&quot;code-quote&quot;&gt;&quot;someUdaf(id)&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;agg&quot;&lt;/span&gt;)
  )
  .collect()&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Exception&#160;&lt;br/&gt;
(used Encoders.javaSerialization&lt;span class=&quot;error&quot;&gt;&amp;#91;Long&amp;#93;&lt;/span&gt; just for the serialization stack):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Job aborted due to stage failure: task 0.0 in stage 3.0 (TID 3) had a not serializable result: org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection
Serialization stack:
  - object not serializable (class: org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection, value: &amp;lt;function1&amp;gt;)
  - field (class: org.apache.spark.sql.execution.aggregate.ScalaAggregator, name: inputProjection, type: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.sql.catalyst.expressions.UnsafeProjection)
  - object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.sql.execution.aggregate.ScalaAggregator, someUdaf(input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;]))
  - element of array (index: 0)
  - array (class [Lorg.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate;, size 1)
  - field (class: org.apache.spark.sql.execution.AggregatingAccumulator, name: typedImperatives, type: class [Lorg.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate;)
  - object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.sql.execution.AggregatingAccumulator, AggregatingAccumulator(id: 136, name: Some(Collected metrics), value: [empty row]))
  - writeExternal data
  - externalizable object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.scheduler.DirectTaskResult, org.apache.spark.scheduler.DirectTaskResult@31bbb9d7)
  org.apache.spark.SparkException: Job aborted due to stage failure: task 0.0 in stage 3.0 (TID 3) had a not serializable result: org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection
  Serialization stack:
  - object not serializable (class: org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection, value: &amp;lt;function1&amp;gt;)
    - field (class: org.apache.spark.sql.execution.aggregate.ScalaAggregator, name: inputProjection, type: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.sql.catalyst.expressions.UnsafeProjection)
    - object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.sql.execution.aggregate.ScalaAggregator, someUdaf(input[0, bigint, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;]))
    - element of array (index: 0)
    - array (class [Lorg.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate;, size 1)
    - field (class: org.apache.spark.sql.execution.AggregatingAccumulator, name: typedImperatives, type: class [Lorg.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate;)
    - object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.sql.execution.AggregatingAccumulator, AggregatingAccumulator(id: 136, name: Some(Collected metrics), value: [empty row]))
    - writeExternal data
    - externalizable object (&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.scheduler.DirectTaskResult, org.apache.spark.scheduler.DirectTaskResult@31bbb9d7)
    at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)
    at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)
    at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)
    at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
    at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
    at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
    at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)
    at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)
    at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)
    at scala.Option.foreach(Option.scala:407)
    at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)
    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)
    at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
    at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)
    at org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)
    at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1022)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
    at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
    at org.apache.spark.rdd.RDD.withScope(RDD.scala:408)
    at org.apache.spark.rdd.RDD.collect(RDD.scala:1021)
    at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)
    at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4218)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13602173">SPARK-50581</key>
            <summary>Dataset.observe() is not working with UDAF</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tomsisso">Tom Sisso</assignee>
                                    <reporter username="tomsisso">Tom Sisso</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Sun, 15 Dec 2024 13:15:02 +0000</created>
                <updated>Mon, 16 Dec 2024 11:37:02 +0000</updated>
                            <resolved>Mon, 16 Dec 2024 11:37:02 +0000</resolved>
                                    <version>3.0.0</version>
                    <version>3.5.3</version>
                                    <fixVersion>4.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="17905999" author="gurwls223" created="Mon, 16 Dec 2024 11:37:02 +0000"  >&lt;p&gt;Issue resolved by pull request 49190&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/49190&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/49190&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            47 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1t4u0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>