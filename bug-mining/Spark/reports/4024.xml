<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:47:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17465] Inappropriate memory management in `org.apache.spark.storage.MemoryStore` may lead to memory leak</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17465</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;After updating Spark from 1.5.0 to 1.6.0, I found that it seems to have a memory leak on my Spark streaming application.&lt;/p&gt;

&lt;p&gt;Here is the head of the heap histogram of my application, which has been running about 160 hours:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; num     #instances         #bytes  &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;name
----------------------------------------------
   1:         28094       71753976  [B
   2:       1188086       28514064  java.lang.&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;
   3:       1183844       28412256  scala.collection.mutable.DefaultEntry
   4:        102242       13098768  &amp;lt;methodKlass&amp;gt;
   5:        102242       12421000  &amp;lt;constMethodKlass&amp;gt;
   6:          8184        9199032  &amp;lt;constantPoolKlass&amp;gt;
   7:            38        8391584  [Lscala.collection.mutable.HashEntry;
   8:          8184        7514288  &amp;lt;instanceKlassKlass&amp;gt;
   9:          6651        4874080  &amp;lt;constantPoolCacheKlass&amp;gt;
  10:         37197        3438040  [C
  11:          6423        2445640  &amp;lt;methodDataKlass&amp;gt;
  12:          8773        1044808  java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;
  13:         36869         884856  java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;
  14:         15715         848368  [[I
  15:         13690         782808  [S
  16:         18903         604896  java.util.concurrent.ConcurrentHashMap$HashEntry
  17:            13         426192  [Lscala.concurrent.forkjoin.ForkJoinTask;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;It shows that &lt;b&gt;scala.collection.mutable.DefaultEntry&lt;/b&gt; and &lt;b&gt;java.lang.Long&lt;/b&gt; have unexpected big numbers of instances. In fact, the numbers started growing at streaming process began, and keep growing proportional to total number of tasks.&lt;/p&gt;



&lt;p&gt;After some further investigation, I found that the problem is caused by some inappropriate memory management in &lt;em&gt;releaseUnrollMemoryForThisTask&lt;/em&gt; and &lt;em&gt;unrollSafely&lt;/em&gt; method of class &lt;a href=&quot;https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/storage/MemoryStore.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;org.apache.spark.storage.MemoryStore&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In Spark 1.6.x, a &lt;em&gt;releaseUnrollMemoryForThisTask&lt;/em&gt; operation will be processed only with the parameter &lt;em&gt;memoryToRelease&lt;/em&gt; &amp;gt; 0:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/storage/MemoryStore.scala#L530-L537&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/storage/MemoryStore.scala#L530-L537&lt;/a&gt;&lt;br/&gt;
But in fact, if a task successfully unrolled all its blocks in memory by &lt;em&gt;unrollSafely&lt;/em&gt; method, the memory saved in &lt;em&gt;unrollMemoryMap&lt;/em&gt; would be set to zero:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/storage/MemoryStore.scala#L322&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/branch-1.6/core/src/main/scala/org/apache/spark/storage/MemoryStore.scala#L322&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So the result is, the memory saved in &lt;em&gt;unrollMemoryMap&lt;/em&gt; will be released, but the key of that part of memory will never be removed from the hash map. The hash table will keep increasing, while new tasks keep incoming. Although the speed of increase is comparatively slow (about dozens of bytes per task), it is possible that result into OOM after weeks or months.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13003767">SPARK-17465</key>
            <summary>Inappropriate memory management in `org.apache.spark.storage.MemoryStore` may lead to memory leak</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="saturday_s">Xing Shi</assignee>
                                    <reporter username="saturday_s">Xing Shi</reporter>
                        <labels>
                    </labels>
                <created>Fri, 9 Sep 2016 06:35:19 +0000</created>
                <updated>Wed, 15 Mar 2017 01:41:05 +0000</updated>
                            <resolved>Wed, 14 Sep 2016 20:47:55 +0000</resolved>
                                    <version>1.6.0</version>
                    <version>1.6.1</version>
                    <version>1.6.2</version>
                                    <fixVersion>1.6.3</fixVersion>
                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="15476348" author="apachespark" created="Fri, 9 Sep 2016 08:36:09 +0000"  >&lt;p&gt;User &apos;saturday-shi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15022&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15022&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15486680" author="saturday_s" created="Tue, 13 Sep 2016 08:43:23 +0000"  >&lt;p&gt;It seems that the issue has some negative side effects on processing time.&lt;/p&gt;

&lt;p&gt;When I ran a streaming application using &lt;em&gt;updateStateByKey&lt;/em&gt; on Spark 1.6.0, it showed a strange gradual increasing of processing time: the processing time of a 2s-interval-batch would increase from &amp;lt; 0.1s to 2 ~ 3s after 10 ~ 20 days. (similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-13288&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;this issue&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;But after I fixed the issue described in this JIRA, the problem seems disappeared. The processing time stably keeping at &amp;lt; 0.1s, and shows no tendency to increase.&lt;/p&gt;

&lt;p&gt;I have no idea of why it happens, but the issue - described in this JIRA - seems to have an actual effect on processing time of applications that using &lt;em&gt;updateStateByKey&lt;/em&gt; (or checkpoint).&lt;/p&gt;</comment>
                            <comment id="15491421" author="joshrosen" created="Wed, 14 Sep 2016 20:47:56 +0000"  >&lt;p&gt;Issue resolved by pull request 15022&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15022&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15022&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15541946" author="saturday_s" created="Mon, 3 Oct 2016 09:16:17 +0000"  >&lt;p&gt;Resolved.&lt;/p&gt;

&lt;p&gt;In every task, method &lt;em&gt;currentUnrollMemory&lt;/em&gt; will be called several times. It will scan all keys of &lt;em&gt;unrollMemoryMap&lt;/em&gt; and &lt;em&gt;pendingUnrollMemoryMap&lt;/em&gt;, so the processing time is proportional to the map size.&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/v1.6.0/core/src/main/scala/org/apache/spark/storage/MemoryStore.scala#L540-L542&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v1.6.0/core/src/main/scala/org/apache/spark/storage/MemoryStore.scala#L540-L542&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have checked the processing time of &lt;em&gt;currentUnrollMemory&lt;/em&gt;. It just equals to the time increased from before.&lt;/p&gt;

&lt;p&gt;Hope this will help someone who has a similar issue of increasing processing time when upgrade Spark to 1.6.0 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15925394" author="agateaaa" created="Wed, 15 Mar 2017 01:41:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saturday_s&quot; class=&quot;user-hover&quot; rel=&quot;saturday_s&quot;&gt;saturday_s&lt;/a&gt; Thanks for this fix! It really helped us. We were using 1.6.1 and were seeing processing times increase gradually over period of several days. With 1.6.3 this increase does not happen. Thank you!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 35 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i33fen:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>