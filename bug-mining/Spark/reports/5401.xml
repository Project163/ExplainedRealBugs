<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:57:41 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21657] Spark has exponential time complexity to explode(array of structs)</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21657</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;It can take up to half a day to explode a modest-sized nested collection (0.5m).&lt;br/&gt;
On a recent Xeon processors.&lt;/p&gt;

&lt;p&gt;See attached pyspark script that reproduces this problem.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;cached_df = sqlc.sql(&lt;span class=&quot;code-quote&quot;&gt;&apos;select individ, hholdid, explode(amft) from &apos;&lt;/span&gt; + table_name).cache()
print sqlc.count()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This script generate a number of tables, with the same total number of records across all nested collection (see `scaling` variable in loops). `scaling` variable scales up how many nested elements in each record, but by the same factor scales down number of records in the table. So total number of records stays the same.&lt;/p&gt;

&lt;p&gt;Time grows exponentially (notice log-10 vertical axis scale):&lt;br/&gt;
&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12880674/12880674_ExponentialTimeGrowth.PNG&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;At scaling of 50,000 (see attached pyspark script), it took 7 hours to explode the nested collections (&amp;#33;) of 8k records.&lt;/p&gt;

&lt;p&gt;After 1000 elements in nested collection, time grows exponentially.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13092970">SPARK-21657</key>
            <summary>Spark has exponential time complexity to explode(array of structs)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="uzadude">Ohad Raviv</assignee>
                                    <reporter username="Tagar">Ruslan Dautkhanov</reporter>
                        <labels>
                            <label>cache</label>
                            <label>caching</label>
                            <label>collections</label>
                            <label>nested_types</label>
                            <label>performance</label>
                            <label>pyspark</label>
                            <label>sparksql</label>
                            <label>sql</label>
                    </labels>
                <created>Mon, 7 Aug 2017 18:21:33 +0000</created>
                <updated>Wed, 31 Jan 2018 18:57:09 +0000</updated>
                            <resolved>Fri, 29 Dec 2017 13:09:52 +0000</resolved>
                                    <version>2.0.0</version>
                    <version>2.1.0</version>
                    <version>2.1.1</version>
                    <version>2.2.0</version>
                    <version>2.3.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>4</votes>
                                    <watches>18</watches>
                                                                                                                <comments>
                            <comment id="16117011" author="srowen" created="Mon, 7 Aug 2017 18:38:09 +0000"  >&lt;p&gt;(Not a bug)&lt;br/&gt;
I doubt this is meant to be efficient at the scale you&apos;re using it. Is this a real use case?&lt;br/&gt;
What change are you proposing?&lt;/p&gt;</comment>
                            <comment id="16117051" author="tagar" created="Mon, 7 Aug 2017 18:46:38 +0000"  >&lt;p&gt;Absolutely, this is a real use case. &lt;br/&gt;
We have a lot of production data that rely on that kind of schema for BI reporting. &lt;br/&gt;
Other Hadoop sql engines, including Hive and Impala scale its time to explode nested collections linearly. &lt;br/&gt;
Spark has exponential complexity to explode nested collection.&lt;br/&gt;
There is definitely a room for improvement, as after ~40k+ records in a nested collection, most time of the job&lt;br/&gt;
is spent in exploding; after ~200k+ records in a nested collection, Spark is not usable.&lt;/p&gt;</comment>
                            <comment id="16121801" author="tagar" created="Thu, 10 Aug 2017 15:31:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bjornjons&quot; class=&quot;user-hover&quot; rel=&quot;bjornjons&quot;&gt;bjornjons&lt;/a&gt; confirms this problem pertains to Spark 2.2 too.&lt;/p&gt;</comment>
                            <comment id="16123050" author="viirya" created="Fri, 11 Aug 2017 08:54:49 +0000"  >&lt;p&gt;Maybe not very related to this issue. But I&apos;m exploring Generate related code to get hint about this issue. I&apos;m curious why we still don&apos;t enable codegen of Generate for now. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hvanhovell&quot; class=&quot;user-hover&quot; rel=&quot;hvanhovell&quot;&gt;hvanhovell&lt;/a&gt; Maybe you know why it is disabled? Thanks.&lt;/p&gt;</comment>
                            <comment id="16126877" author="maropu" created="Tue, 15 Aug 2017 07:11:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=viirya&quot; class=&quot;user-hover&quot; rel=&quot;viirya&quot;&gt;viirya&lt;/a&gt; Probably, this is what you want? &lt;a href=&quot;https://github.com/apache/spark/commit/b5c5bd98ea5e8dbfebcf86c5459bdf765f5ceb53&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/b5c5bd98ea5e8dbfebcf86c5459bdf765f5ceb53&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16127511" author="tagar" created="Tue, 15 Aug 2017 16:49:28 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maropu&quot; class=&quot;user-hover&quot; rel=&quot;maropu&quot;&gt;maropu&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=viirya&quot; class=&quot;user-hover&quot; rel=&quot;viirya&quot;&gt;viirya&lt;/a&gt;, that commit is for Spark 2.2 so this problem might be worse in 2.2, but I don&apos;t think it&apos;s a root cause.&lt;br/&gt;
As we see the same exponential time complexity to explode a nested array in Spark 2.0 and 2.1.&lt;/p&gt;</comment>
                            <comment id="16128242" author="viirya" created="Wed, 16 Aug 2017 03:16:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maropu&quot; class=&quot;user-hover&quot; rel=&quot;maropu&quot;&gt;maropu&lt;/a&gt; I&apos;ve noticed that change. There is a hotfix trying to revert that: &lt;a href=&quot;https://github.com/apache/spark/pull/17425&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17425&lt;/a&gt;. But in the end the hotfix doesn&apos;t revert it back.&lt;/p&gt;

&lt;p&gt;Actually I&apos;ve tried to enable codegen for GenerateExec and ran those tests without failure in local. So I&apos;m wondering why we still disable it.&lt;/p&gt;</comment>
                            <comment id="16220450" author="uzadude" created="Thu, 26 Oct 2017 13:51:44 +0000"  >&lt;p&gt;Hi,&lt;br/&gt;
Wanted to add that we&apos;re facing exactly the same issue. 6 hours work for one row that contains 250k array (of struct of 4 strings).&lt;br/&gt;
Just wanted to state that if we explode only the array, e.g, in your example:&lt;br/&gt;
cached_df = sqlc.sql(&apos;select explode(amft) from &apos; + table_name)&lt;/p&gt;

&lt;p&gt;it finishes in about 3 mins. &lt;br/&gt;
it happens in Spark 2.1 and also 2.2, eventhough &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16998&quot; title=&quot;select($&amp;quot;column1&amp;quot;, explode($&amp;quot;column2&amp;quot;)) is extremely slow&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-16998&quot;&gt;&lt;del&gt;SPARK-16998&lt;/del&gt;&lt;/a&gt; was resolved.&lt;/p&gt;</comment>
                            <comment id="16220469" author="srowen" created="Thu, 26 Oct 2017 14:06:16 +0000"  >&lt;p&gt;I suspect that something somewhere is doing something that&apos;s linear-time that looks like it should be constant-time, like referencing a linked list by index. See &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-22330&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-22330&lt;/a&gt; for a similar type of thing (though don&apos;t think it&apos;s the same issue as this one)&lt;/p&gt;</comment>
                            <comment id="16222312" author="uzadude" created="Fri, 27 Oct 2017 12:52:55 +0000"  >&lt;p&gt;Hi,&lt;br/&gt;
Just ran a profiler for this code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val BASE = 100000000
val N = 100000
val df = sc.parallelize(List((&lt;span class=&quot;code-quote&quot;&gt;&quot;1234567890&quot;&lt;/span&gt;, (BASE to (BASE+N)).map(x =&amp;gt; (x.toString, (x+1).toString, (x+2).toString, (x+3).toString)).toList ))).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;c1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;c_arr&quot;&lt;/span&gt;)
val df_exploded = df.select(expr(&lt;span class=&quot;code-quote&quot;&gt;&quot;c1&quot;&lt;/span&gt;), explode($&lt;span class=&quot;code-quote&quot;&gt;&quot;c_arr&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;c2&quot;&lt;/span&gt;))
df_exploded.write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).format(&lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;).save(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/blah_explode&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and it looks like &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; is right, most of the time is spent in scala.collection.immutable.List.apply()	 (72.1%). inside:&lt;br/&gt;
org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext()  (100%)&lt;/p&gt;

&lt;p&gt;I logged the generated code and found the problematic code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (serializefromobject_funcResult1 != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
             serializefromobject_value5 = (scala.collection.immutable.List) serializefromobject_funcResult1;
           } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
             serializefromobject_isNull5 = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;
         }
.
.
.
 &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (serializefromobject_loopIndex &amp;lt; serializefromobject_dataLength) {
           MapObjects_loopValue0 = (scala.Tuple4) (serializefromobject_value5.apply(serializefromobject_loopIndex));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so that causes the quadratic time complexity.&lt;br/&gt;
However, I&apos;m not sure where is the code that generates this list instead of array for the exploded array.&lt;/p&gt;</comment>
                            <comment id="16222346" author="srowen" created="Fri, 27 Oct 2017 13:21:12 +0000"  >&lt;p&gt;What if you call toArray in your code, and explode that? if it&apos;s just assuming the column type is constant-time to access at an index, then that would work around it. &lt;br/&gt;
Ideally it would generate code that traversed the collection if it doesn&apos;t support fast RandomAccess, or implements like this otherwise (instance of IndexedSeq or something). But that might help narrow down the issue.&lt;/p&gt;</comment>
                            <comment id="16223902" author="uzadude" created="Sun, 29 Oct 2017 09:14:19 +0000"  >&lt;p&gt;I Switched to toArray instead of toList in the above code and I did get an improvement by factor of 2. but we still remain with the main bottleneck.&lt;br/&gt;
now the diff in the above example between:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val df_exploded = df.select(expr(&lt;span class=&quot;code-quote&quot;&gt;&quot;c1&quot;&lt;/span&gt;), explode($&lt;span class=&quot;code-quote&quot;&gt;&quot;c_arr&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;c2&quot;&lt;/span&gt;))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val df_exploded = df.select(explode($&lt;span class=&quot;code-quote&quot;&gt;&quot;c_arr&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;c2&quot;&lt;/span&gt;))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is 128 secs vs. 3 secs.&lt;/p&gt;

&lt;p&gt;Again I profiled the former and saw that all the time got consumed in:&lt;br/&gt;
org.apache.spark.unsafe.Platform.copyMemory()	97.548096	23,991 ms (97.5%)	&lt;/p&gt;

&lt;p&gt;the obvious diff between the execution plans is that the former has two WholeStageCodeGen plans and the later just one.&lt;br/&gt;
I didn&apos;t exactly understood the generated code but I would guess that what happens is that in the problematic case the generated explode code is actually multiplying the long array to all the exploded rows and only filters it in the end.&lt;br/&gt;
Please see if you can verify it or think on a workaround for it.&lt;/p&gt;
</comment>
                            <comment id="16223927" author="srowen" created="Sun, 29 Oct 2017 09:43:27 +0000"  >&lt;p&gt;Can you paste the plans? this difference might be down to a different cause.&lt;/p&gt;

&lt;p&gt;The linear-time-access List issue still look worth solving. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hvanhovell&quot; class=&quot;user-hover&quot; rel=&quot;hvanhovell&quot;&gt;hvanhovell&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt; are either of you familiar with how the explode code is generated? I also couldn&apos;t quite figure out what was generating access to a linked list (immutable.List) where a random-access collection looks more appropriate.&lt;/p&gt;</comment>
                            <comment id="16223946" author="uzadude" created="Sun, 29 Oct 2017 10:46:45 +0000"  >&lt;p&gt;Sure,&lt;br/&gt;
the plan for&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val df_exploded = df.select(expr(&lt;span class=&quot;code-quote&quot;&gt;&quot;c1&quot;&lt;/span&gt;), explode($&lt;span class=&quot;code-quote&quot;&gt;&quot;c_arr&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;c2&quot;&lt;/span&gt;)).selectExpr(&lt;span class=&quot;code-quote&quot;&gt;&quot;c1&quot;&lt;/span&gt; ,&lt;span class=&quot;code-quote&quot;&gt;&quot;c2.*&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;== Parsed Logical Plan ==
&apos;Project [unresolvedalias(&apos;c1, None), ArrayBuffer(c2).*]
+- Project [c1#6, c2#25]
   +- Generate explode(c_arr#7), true, false, [c2#25]
      +- Project [_1#3 AS c1#6, _2#4 AS c_arr#7]
         +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1, true) AS _1#3, mapobjects(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), if (isnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))) null else named_struct(_1, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._1, true), _2, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._2, true), _3, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._3, true), _4, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._4, true)), assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, None) AS _2#4]
            +- ExternalRDD [obj#2]

== Analyzed Logical Plan ==
c1: string, _1: string, _2: string, _3: string, _4: string
Project [c1#6, c2#25._1 AS _1#40, c2#25._2 AS _2#41, c2#25._3 AS _3#42, c2#25._4 AS _4#43]
+- Project [c1#6, c2#25]
   +- Generate explode(c_arr#7), true, false, [c2#25]
      +- Project [_1#3 AS c1#6, _2#4 AS c_arr#7]
         +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1, true) AS _1#3, mapobjects(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), if (isnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))) null else named_struct(_1, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._1, true), _2, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._2, true), _3, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._3, true), _4, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._4, true)), assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, None) AS _2#4]
            +- ExternalRDD [obj#2]

== Optimized Logical Plan ==
Project [c1#6, c2#25._1 AS _1#40, c2#25._2 AS _2#41, c2#25._3 AS _3#42, c2#25._4 AS _4#43]
+- Generate explode(c_arr#7), true, false, [c2#25]
   +- Project [_1#3 AS c1#6, _2#4 AS c_arr#7]
      +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(input[0, scala.Tuple2, true])._1, true) AS _1#3, mapobjects(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), if (isnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))) null else named_struct(_1, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._1, true), _2, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._2, true), _3, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._3, true), _4, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._4, true)), assertnotnull(input[0, scala.Tuple2, true])._2, None) AS _2#4]
         +- ExternalRDD [obj#2]

== Physical Plan ==
*Project [c1#6, c2#25._1 AS _1#40, c2#25._2 AS _2#41, c2#25._3 AS _3#42, c2#25._4 AS _4#43]
+- Generate explode(c_arr#7), true, false, [c2#25]
   +- *Project [_1#3 AS c1#6, _2#4 AS c_arr#7]
      +- *SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(input[0, scala.Tuple2, true])._1, true) AS _1#3, mapobjects(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), if (isnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))) null else named_struct(_1, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._1, true), _2, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._2, true), _3, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._3, true), _4, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._4, true)), assertnotnull(input[0, scala.Tuple2, true])._2, None) AS _2#4]
         +- Scan ExternalRDDScan[obj#2]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and for:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val df_exploded = df.select(explode($&lt;span class=&quot;code-quote&quot;&gt;&quot;c_arr&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;c2&quot;&lt;/span&gt;)).selectExpr(&lt;span class=&quot;code-quote&quot;&gt;&quot;c2.*&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;== Parsed Logical Plan ==
&apos;Project [ArrayBuffer(c2).*]
+- Project [c2#25]
   +- Generate explode(c_arr#7), false, false, [c2#25]
      +- Project [_1#3 AS c1#6, _2#4 AS c_arr#7]
         +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1, true) AS _1#3, mapobjects(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), if (isnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))) null else named_struct(_1, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._1, true), _2, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._2, true), _3, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._3, true), _4, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._4, true)), assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, None) AS _2#4]
            +- ExternalRDD [obj#2]

== Analyzed Logical Plan ==
_1: string, _2: string, _3: string, _4: string
Project [c2#25._1 AS _1#38, c2#25._2 AS _2#39, c2#25._3 AS _3#40, c2#25._4 AS _4#41]
+- Project [c2#25]
   +- Generate explode(c_arr#7), false, false, [c2#25]
      +- Project [_1#3 AS c1#6, _2#4 AS c_arr#7]
         +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._1, true) AS _1#3, mapobjects(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), if (isnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))) null else named_struct(_1, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._1, true), _2, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._2, true), _3, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._3, true), _4, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._4, true)), assertnotnull(assertnotnull(input[0, scala.Tuple2, true]))._2, None) AS _2#4]
            +- ExternalRDD [obj#2]

== Optimized Logical Plan ==
Project [c2#25._1 AS _1#38, c2#25._2 AS _2#39, c2#25._3 AS _3#40, c2#25._4 AS _4#41]
+- Generate explode(c_arr#7), false, false, [c2#25]
   +- Project [_2#4 AS c_arr#7]
      +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(input[0, scala.Tuple2, true])._1, true) AS _1#3, mapobjects(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), if (isnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))) null else named_struct(_1, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._1, true), _2, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._2, true), _3, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._3, true), _4, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._4, true)), assertnotnull(input[0, scala.Tuple2, true])._2, None) AS _2#4]
         +- ExternalRDD [obj#2]

== Physical Plan ==
*Project [c2#25._1 AS _1#38, c2#25._2 AS _2#39, c2#25._3 AS _3#40, c2#25._4 AS _4#41]
+- Generate explode(c_arr#7), false, false, [c2#25]
   +- *Project [_2#4 AS c_arr#7]
      +- *SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(input[0, scala.Tuple2, true])._1, true) AS _1#3, mapobjects(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), if (isnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))) null else named_struct(_1, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._1, true), _2, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._2, true), _3, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._3, true), _4, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, assertnotnull(lambdavariable(MapObjects_loopValue0, MapObjects_loopIsNull0, ObjectType(class scala.Tuple4), true))._4, true)), assertnotnull(input[0, scala.Tuple2, true])._2, None) AS _2#4]
         +- Scan ExternalRDDScan[obj#2]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16223971" author="srowen" created="Sun, 29 Oct 2017 12:39:33 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt; for the fast look. You&apos;re saying that &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-22385&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-22385&lt;/a&gt; is a superset of this issue?&lt;/p&gt;</comment>
                            <comment id="16223987" author="cloud_fan" created="Sun, 29 Oct 2017 13:10:36 +0000"  >&lt;p&gt;I&apos;d say they are different issues, and I haven&apos;t figured out the reason for this issue yet, and wanna fix that small issue first.&lt;/p&gt;</comment>
                            <comment id="16224365" author="uzadude" created="Mon, 30 Oct 2017 04:18:07 +0000"  >&lt;p&gt;After futher investigating I believe that my assesment is correct, the former case creates a generator with join=true while the later with join=false, as you can see in plans above (I also debugged). this causes the very long array of size 100k to be duplicated 100k times and afterwards get pruned because its column is not in the final projection. &lt;br/&gt;
I&apos;m not sure what&apos;s the best way to address this issue - ammend the generate operator according to the projection.&lt;br/&gt;
in the meanwhile, in our case, I worked around that by manually adding the outer fields into each of structs of the array and then exploded only the array. it&apos;s an ugly solution but reduces our query time from 6 hours to about 2 mins.&lt;/p&gt;</comment>
                            <comment id="16224374" author="uzadude" created="Mon, 30 Oct 2017 04:36:50 +0000"  >&lt;p&gt;ok i found the relevant rule:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;Optimizer.scala.java&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// Turn off `join` &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Generate &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; no column from it&apos;s child is used
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; p @ Project(_, g: Generate)
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; g.join &amp;amp;&amp;amp; !g.&lt;span class=&quot;code-keyword&quot;&gt;outer&lt;/span&gt; &amp;amp;&amp;amp; p.references.subsetOf(g.generatedSet) =&amp;gt;
      p.copy(child = g.copy(join = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I&apos;m not sure yet why it doesn&apos;t work.&lt;/p&gt;</comment>
                            <comment id="16224420" author="uzadude" created="Mon, 30 Oct 2017 06:25:22 +0000"  >&lt;p&gt;After some debugging, I think I understand the tricky part here.&lt;br/&gt;
because there are outer fields in the query we set join=true for the Generate class, and because the Generator uses the array as child it can&apos;t be removed from the Generate output.&lt;br/&gt;
I that because omitting the original column is so common it would make sense to add another attribute to the Generate class, like &lt;tt&gt;omitChild: Boolean&lt;/tt&gt; and let the Optimizer turn it on with appropriate Rule.&lt;br/&gt;
what do you think?&lt;/p&gt;</comment>
                            <comment id="16241883" author="apachespark" created="Tue, 7 Nov 2017 11:54:04 +0000"  >&lt;p&gt;User &apos;uzadude&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19683&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19683&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16241887" author="uzadude" created="Tue, 7 Nov 2017 11:54:51 +0000"  >&lt;p&gt;Hi,&lt;br/&gt;
I created a pull request: &lt;a href=&quot;https://github.com/apache/spark/pull/19683&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19683&lt;/a&gt;&lt;br/&gt;
would appreciate if you could take a look.&lt;/p&gt;</comment>
                            <comment id="16245240" author="tagar" created="Thu, 9 Nov 2017 05:46:44 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=uzadude&quot; class=&quot;user-hover&quot; rel=&quot;uzadude&quot;&gt;uzadude&lt;/a&gt; - great investigative work.&lt;br/&gt;
Would be great if this patch can make it to the 2.3 release.&lt;/p&gt;</comment>
                            <comment id="16306264" author="cloud_fan" created="Fri, 29 Dec 2017 13:09:53 +0000"  >&lt;p&gt;Issue resolved by pull request 19683&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19683&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19683&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16306361" author="tagar" created="Fri, 29 Dec 2017 16:39:34 +0000"  >&lt;p&gt;Thank you everyone involved. It would be the most exciting fix in 2.3 release for us.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12996323">SPARK-16998</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13111260">SPARK-22330</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12965895">SPARK-15214</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13112872">SPARK-22385</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12756594">SPARK-4502</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12880674" name="ExponentialTimeGrowth.PNG" size="55773" author="Tagar" created="Mon, 7 Aug 2017 18:21:52 +0000"/>
                            <attachment id="12880673" name="nested-data-generator-and-test.py" size="3004" author="Tagar" created="Mon, 7 Aug 2017 18:22:05 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 46 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3ii93:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>