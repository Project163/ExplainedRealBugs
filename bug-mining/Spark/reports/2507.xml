<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:33:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-10741] Hive Query Having/OrderBy against Parquet table is not working </title>
                <link>https://issues.apache.org/jira/browse/SPARK-10741</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Failed Query with Having Clause&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  def testParquetHaving() {
    val ddl =
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;CREATE TABLE IF NOT EXISTS test ( c1 string, c2 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ) STORED AS PARQUET&quot;&lt;/span&gt;&quot;&quot;
    val failedHaving =
      &quot;&quot;&quot; SELECT c1, avg ( c2 ) as c_avg
        | FROM test
        | GROUP BY c1
        | HAVING ( avg ( c2 ) &amp;gt; 5)  ORDER BY c1&quot;&quot;&quot;.stripMargin
    TestHive.sql(ddl)
    TestHive.sql(failedHaving).collect
  }

org.apache.spark.sql.AnalysisException: resolved attribute(s) c2#16 missing from c1#17,c2#18 in &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; !Aggregate [c1#17], [&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((avg(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c2#16 as bigint)) &amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(5 as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;)) as &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt;) AS havingCondition#12,c1#17,avg(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c2#18 as bigint)) AS c_avg#9];
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;failAnalysis(CheckAnalysis.scala:37)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.failAnalysis(Analyzer.scala:44)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:154)
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:49)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Failed Query with OrderBy&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  def testParquetOrderBy() {
    val ddl =
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;CREATE TABLE IF NOT EXISTS test ( c1 string, c2 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ) STORED AS PARQUET&quot;&lt;/span&gt;&quot;&quot;
    val failedOrderBy =
      &quot;&quot;&quot; SELECT c1, avg ( c2 ) c_avg
        | FROM test
        | GROUP BY c1
        | ORDER BY avg ( c2 )&quot;&quot;&quot;.stripMargin
    TestHive.sql(ddl)
    TestHive.sql(failedOrderBy).collect
  }

org.apache.spark.sql.AnalysisException: resolved attribute(s) c2#33 missing from c1#34,c2#35 in &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; !Aggregate [c1#34], [avg(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c2#33 as bigint)) AS aggOrder#31,c1#34,avg(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c2#35 as bigint)) AS c_avg#28];
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;failAnalysis(CheckAnalysis.scala:37)
	at org.apache.spark.sql.catalyst.analysis.Analyzer.failAnalysis(Analyzer.scala:44)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12895302">SPARK-10741</key>
            <summary>Hive Query Having/OrderBy against Parquet table is not working </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cloud_fan">Wenchen Fan</assignee>
                                    <reporter username="ianlcsd">Ian</reporter>
                        <labels>
                    </labels>
                <created>Tue, 22 Sep 2015 01:33:28 +0000</created>
                <updated>Sun, 27 Sep 2015 16:10:43 +0000</updated>
                            <resolved>Sun, 27 Sep 2015 16:10:43 +0000</resolved>
                                    <version>1.5.0</version>
                                    <fixVersion>1.5.2</fixVersion>
                    <fixVersion>1.6.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14905069" author="cloud_fan" created="Wed, 23 Sep 2015 19:16:51 +0000"  >&lt;p&gt;This bug is caused by a conflict between 2 tricky part in our Analyzer. Let me explain it a little more.&lt;/p&gt;

&lt;p&gt;We have a special rule for Sort on Aggregate in &lt;a href=&quot;https://github.com/apache/spark/blob/v1.5.0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala#L563-L604&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v1.5.0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala#L563-L604&lt;/a&gt;&lt;br/&gt;
In this rule, we put sort ordering expressions in Aggregate and call Analyzer to resolve this Aggregate again(which means we go through all rules).&lt;/p&gt;

&lt;p&gt;We also have a special rule for parquet in &lt;a href=&quot;https://github.com/apache/spark/blob/v1.5.0/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala#L580-L612&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v1.5.0/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala#L580-L612&lt;/a&gt;&lt;br/&gt;
In this rule, we convert hive&apos;s MetastoreRelation to LogicalRelation of parquet, which means we replaced leaf node and changed the output attribute ids. At the end of this rule, we go through the whole tree to replace old AttributeRefence of MetastoreRelation with new ones of LogicalRelation.&lt;/p&gt;

&lt;p&gt;Then these 2 rules get conflicted. At the point when we resolve Sort on Aggregate, we only have MetastoreRelation, but when we resolve sort ordering expressions with Aggregate, we go through all rules and these ordering expressions will reference to parquet&apos;s LogicalRelation whose output attribute ids are different from the old MetastoreRelations. Finally oops, our ordering expressions are referencing something doesn&apos;t  exist.&lt;/p&gt;

&lt;p&gt;One solution is: do not go through all rules when resolve Sort on Aggregate(thus the parquet relation conversion won&apos;t happen).&lt;br/&gt;
Another is: keep the attribute ids when convert MetastoreRelation to LogicalRelation.&lt;/p&gt;

&lt;p&gt;Personally I prefer the second one, what do you think?&lt;/p&gt;
</comment>
                            <comment id="14905166" author="yhuai" created="Wed, 23 Sep 2015 20:12:17 +0000"  >&lt;p&gt;The second options sounds better.&lt;/p&gt;</comment>
                            <comment id="14905327" author="ianlcsd" created="Wed, 23 Sep 2015 21:36:46 +0000"  >&lt;p&gt;Yes, going through all rules when resolve Sort on Aggregate is a correct approach.&lt;/p&gt;

&lt;p&gt;The main problem appeared to be that the execute call at (&lt;a href=&quot;https://github.com/apache/spark/blob/v1.5.0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala#L571&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v1.5.0/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala#L571&lt;/a&gt;) is resolving to different attribute ids, and causing confusion at  &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/v1.5.0/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala#L592-L611&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v1.5.0/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveMetastoreCatalog.scala#L592-L611&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;just for me to understand a bit more:&lt;br/&gt;
the second approach you are proposing is to remove the confusion by changing how ids are resolved in Analyzer.scala#L571, right? &lt;/p&gt;

</comment>
                            <comment id="14905479" author="apachespark" created="Wed, 23 Sep 2015 23:14:02 +0000"  >&lt;p&gt;User &apos;cloud-fan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8889&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8889&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14906618" author="yhuai" created="Thu, 24 Sep 2015 16:43:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ianlcsd&quot; class=&quot;user-hover&quot; rel=&quot;ianlcsd&quot;&gt;ianlcsd&lt;/a&gt; Can you try the following queries to see if you can workaround this issue for now?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;// First query
&lt;/span&gt;SELECT c1, avg ( c2 ) as c_avg
FROM test10741
GROUP BY c1
HAVING ( c_avg &amp;gt; 5)  ORDER BY c1

&lt;span class=&quot;code-comment&quot;&gt;// Second query
&lt;/span&gt;SELECT c1, avg ( c2 ) c_avg
FROM test10741
GROUP BY c1
ORDER BY c_avg
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14906768" author="ianlcsd" created="Thu, 24 Sep 2015 18:16:57 +0000"  >&lt;p&gt;The org.apache.spark.sql.AnalysisException is fixed, but the write path seemed broken.&lt;br/&gt;
The &quot;INSERT INTO/OVERWRITE&quot; statement seems not populating data now.&lt;/p&gt;</comment>
                            <comment id="14906786" author="yhuai" created="Thu, 24 Sep 2015 18:24:16 +0000"  >&lt;p&gt;Any error?&lt;/p&gt;</comment>
                            <comment id="14906801" author="ianlcsd" created="Thu, 24 Sep 2015 18:39:38 +0000"  >&lt;p&gt;Two of my tests failed. The query returns nothing. &lt;br/&gt;
Also see &lt;a href=&quot;https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/42962/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/42962/testReport/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;these two could be related. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  test(&lt;span class=&quot;code-quote&quot;&gt;&quot;test insert overwrite parquet &quot;&lt;/span&gt;) {
    val ddl= List(
      &lt;span class=&quot;code-quote&quot;&gt;&quot;DROP TABLE IF EXISTS tmp&quot;&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;DROP TABLE IF EXISTS test&quot;&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;CREATE TABLE IF NOT EXISTS tmp ( c1 string, c2 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; )&quot;&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;INSERT INTO TABLE tmp select &quot;&lt;/span&gt;test1&lt;span class=&quot;code-quote&quot;&gt;&quot; as c1, (count(*)+1) *10 as c2 from tmp&quot;&lt;/span&gt;&quot;&quot;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;INSERT INTO TABLE tmp select &quot;&lt;/span&gt;test1&lt;span class=&quot;code-quote&quot;&gt;&quot; as c1, (count(*)+1) *10 as c2 from tmp&quot;&lt;/span&gt;&quot;&quot;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;INSERT INTO TABLE tmp select &quot;&lt;/span&gt;test2&lt;span class=&quot;code-quote&quot;&gt;&quot; as c1, (count(*)+1) *10 as c2 from tmp&quot;&lt;/span&gt;&quot;&quot;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;INSERT INTO TABLE tmp select &quot;&lt;/span&gt;test2&lt;span class=&quot;code-quote&quot;&gt;&quot; as c1, (count(*)+1) *10 as c2 from tmp&quot;&lt;/span&gt;&quot;&quot;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;CREATE TABLE IF NOT EXISTS test ( c1 string, c2 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ) STORED AS PARQUET&quot;&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;INSERT OVERWRITE TABLE test SELECT * FROM tmp&quot;&lt;/span&gt;
    )

    ddl.foreach{ x =&amp;gt;
      TestHive.sql(x).collect()
    }

    val tmp = TestHive.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select c1, c2 from tmp&quot;&lt;/span&gt;).collect()
    val test = TestHive.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select c1, c2 from test&quot;&lt;/span&gt;).collect()
    &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt;(tmp === test)
  }

Array([test1,10], [test1,20], [test2,30], [test2,40]) did not equal Array()
ScalaTestFailureLocation: org.apache.spark.sql.hive.ParquetRelationTestSuite$$anonfun$1 at (ParquetRelationTestSuite.scala:29)
org.scalatest.exceptions.TestFailedException: Array([test1,10], [test1,20], [test2,30], [test2,40]) did not equal Array()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  test(&lt;span class=&quot;code-quote&quot;&gt;&quot;test insert into parquet &quot;&lt;/span&gt;) {
    val ddl= List(
      &lt;span class=&quot;code-quote&quot;&gt;&quot;DROP TABLE IF EXISTS tmp&quot;&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;DROP TABLE IF EXISTS test&quot;&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;CREATE TABLE IF NOT EXISTS tmp ( c1 string, c2 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; )&quot;&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;CREATE TABLE IF NOT EXISTS test ( c1 string, c2 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ) STORED AS PARQUET&quot;&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;INSERT INTO TABLE test select &quot;&lt;/span&gt;test1&lt;span class=&quot;code-quote&quot;&gt;&quot; as c1, (count(*)+1) *10 as c2 from test&quot;&lt;/span&gt;&quot;&quot;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;INSERT INTO TABLE test select &quot;&lt;/span&gt;test1&lt;span class=&quot;code-quote&quot;&gt;&quot; as c1, (count(*)+1) *10 as c2 from test&quot;&lt;/span&gt;&quot;&quot;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;INSERT INTO TABLE test select &quot;&lt;/span&gt;test2&lt;span class=&quot;code-quote&quot;&gt;&quot; as c1, (count(*)+1) *10 as c2 from test&quot;&lt;/span&gt;&quot;&quot;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;INSERT INTO TABLE test select &quot;&lt;/span&gt;test2&lt;span class=&quot;code-quote&quot;&gt;&quot; as c1, (count(*)+1) *10 as c2 from test&quot;&lt;/span&gt;&quot;&quot;
    )
    ddl.foreach{ x =&amp;gt;
      TestHive.sql(x).collect()
    }

    val test = TestHive.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select c1, c2 from test&quot;&lt;/span&gt;).collect()
    &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt;(test.length == 4)
  }

Array() had length 0 instead of expected length 4
ScalaTestFailureLocation: org.apache.spark.sql.hive.ParquetRelationTestSuite$$anonfun$2 at (ParquetRelationTestSuite.scala:48)
org.scalatest.exceptions.TestFailedException: Array() had length 0 instead of expected length 4

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14906820" author="yhuai" created="Thu, 24 Sep 2015 18:49:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ianlcsd&quot; class=&quot;user-hover&quot; rel=&quot;ianlcsd&quot;&gt;ianlcsd&lt;/a&gt; Does &lt;tt&gt;select &quot;test1&quot; as c1, (count&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/star_yellow.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;+1) *10 as c2 from tmp&lt;/tt&gt; give you the expected result? You may hit a limitation that we cannot select from a table and then insert data back to itself. Can you try creating another table &lt;tt&gt;tmp1&lt;/tt&gt;? So, for your &lt;tt&gt;INSERT&lt;/tt&gt; command, the source and destination are different.&lt;/p&gt;</comment>
                            <comment id="14906835" author="ianlcsd" created="Thu, 24 Sep 2015 19:01:40 +0000"  >&lt;p&gt;yup, it works.&lt;/p&gt;

&lt;p&gt;The following insert select statement works for non parquet table.   &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;INSERT INTO TABLE tmp select &lt;span class=&quot;code-quote&quot;&gt;&quot;test1&quot;&lt;/span&gt; as c1, (count(*)+1) *10 as c2 from tmp
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but the INSERT OVERWRITE into parquet table does not seem populating.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;INSERT OVERWRITE TABLE test SELECT * FROM tmp
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Therefore in the test of &quot;test insert overwrite parquet&quot;, the assert said:&lt;br/&gt;
&quot;Array(&lt;span class=&quot;error&quot;&gt;&amp;#91;test1,10&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;test1,20&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;test2,30&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;test2,40&amp;#93;&lt;/span&gt;) did not equal Array()&quot;&lt;/p&gt;
</comment>
                            <comment id="14909790" author="yhuai" created="Sun, 27 Sep 2015 16:10:43 +0000"  >&lt;p&gt;This issue has been resolved by &lt;a href=&quot;https://github.com/apache/spark/pull/8889&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8889&lt;/a&gt;.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 8 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2ldk7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>