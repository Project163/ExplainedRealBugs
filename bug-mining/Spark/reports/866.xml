<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:18:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3803] ArrayIndexOutOfBoundsException found in executing computePrincipalComponents</title>
                <link>https://issues.apache.org/jira/browse/SPARK-3803</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When I executed computePrincipalComponents method of RowMatrix, I got java.lang.ArrayIndexOutOfBoundsException.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;14/10/05 20:16:31 INFO DAGScheduler: Failed to run reduce at RDDFunctions.scala:111
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 31.0 failed 1 times, most recent failure: Lost task 0.0 in stage 31.0 (TID 611, localhost): java.lang.ArrayIndexOutOfBoundsException: 4878161
        org.apache.spark.mllib.linalg.distributed.RowMatrix$.org$apache$spark$mllib$linalg$distributed$RowMatrix$$dspr(RowMatrix.scala:460)
        org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$3.apply(RowMatrix.scala:114)
        org.apache.spark.mllib.linalg.distributed.RowMatrix$$anonfun$3.apply(RowMatrix.scala:113)
        scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:144)
        scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:144)
        scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
        scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
        scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(TraversableOnce.scala:144)
        scala.collection.AbstractIterator.foldLeft(Iterator.scala:1157)
        scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;aggregate(TraversableOnce.scala:201)
        scala.collection.AbstractIterator.aggregate(Iterator.scala:1157)
        org.apache.spark.mllib.rdd.RDDFunctions$$anonfun$4.apply(RDDFunctions.scala:99)
        org.apache.spark.mllib.rdd.RDDFunctions$$anonfun$4.apply(RDDFunctions.scala:99)
        org.apache.spark.mllib.rdd.RDDFunctions$$anonfun$5.apply(RDDFunctions.scala:100)
        org.apache.spark.mllib.rdd.RDDFunctions$$anonfun$5.apply(RDDFunctions.scala:100)
        org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
        org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)
        org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
        org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
        org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)
        org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
        org.apache.spark.scheduler.Task.run(Task.scala:54)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:177)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The RowMatrix instance was generated from the result of TF-IDF like the following.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; val hashingTF = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashingTF()
scala&amp;gt; val tf = hashingTF.transform(texts)
scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.mllib.feature.IDF
scala&amp;gt; tf.cache()
scala&amp;gt; val idf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IDF().fit(tf)
scala&amp;gt; val tfidf: RDD[Vector] = idf.transform(tf)

scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.mllib.linalg.distributed.RowMatrix
scala&amp;gt; val mat = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RowMatrix(tfidf)
scala&amp;gt; val pc = mat.computePrincipalComponents(2)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think this was because I created HashingTF instance with default numFeatures and Array is used in RowMatrix#computeGramianMatrix method&lt;br/&gt;
like the following.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  /**
   * Computes the Gramian matrix `A^T A`.
   */
  def computeGramianMatrix(): Matrix = {
    val n = numCols().toInt
    val nt: Int = n * (n + 1) / 2

    &lt;span class=&quot;code-comment&quot;&gt;// Compute the upper triangular part of the gram matrix.
&lt;/span&gt;    val GU = rows.treeAggregate(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BDV[&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;](&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Array[&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;](nt)))(
      seqOp = (U, v) =&amp;gt; {
        RowMatrix.dspr(1.0, v, U.data)
        U
      }, combOp = (U1, U2) =&amp;gt; U1 += U2)

    RowMatrix.triuToFull(n, GU.data)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;When the size of Vectors generated by TF-IDF is too large, it makes &quot;nt&quot; to have undesirable value (and undesirable size of Array used in treeAggregate),&lt;br/&gt;
since n * (n + 1) / 2 exceeded Int.MaxValue.&lt;/p&gt;


&lt;p&gt;Is this surmise correct?&lt;/p&gt;

&lt;p&gt;And, of course, I could avoid this situation by creating instance of HashingTF with smaller numFeatures.&lt;br/&gt;
But this may not be fundamental solution.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12745982">SPARK-3803</key>
            <summary>ArrayIndexOutOfBoundsException found in executing computePrincipalComponents</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="dobachi">Masaru Dobashi</reporter>
                        <labels>
                    </labels>
                <created>Sun, 5 Oct 2014 11:27:51 +0000</created>
                <updated>Thu, 15 Jan 2015 09:08:38 +0000</updated>
                            <resolved>Tue, 14 Oct 2014 21:42:25 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.2.0</fixVersion>
                                    <component>MLlib</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14159587" author="srowen" created="Sun, 5 Oct 2014 16:43:18 +0000"  >&lt;p&gt;I agree with your assessment. It would take some work, though not terribly much, to rewrite this method to correctly handle A with more than 46340 columns. At n = 46340, the Gramian already consumes about 8.5GB of memory, so it&apos;s kinda getting big to realistically use in core anyway. At the least, an error should be raised if n is too large. Any one else think this should be supported though? Would be nice, but, practically helpful?&lt;/p&gt;</comment>
                            <comment id="14161281" author="mengxr" created="Tue, 7 Oct 2014 00:41:35 +0000"  >&lt;p&gt;In `computeCovariance`, we generate a warning message if `numCols &amp;gt; 10000`. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/linalg/distributed/RowMatrix.scala#L307&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/linalg/distributed/RowMatrix.scala#L307&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We could do the same in `Gram`, or we can throw an exception if `numCols` is too big.&lt;/p&gt;</comment>
                            <comment id="14161982" author="dobachi" created="Tue, 7 Oct 2014 15:13:57 +0000"  >&lt;p&gt;Thank you for your comments.&lt;br/&gt;
I agree with the idea to throw an exception.&lt;/p&gt;

&lt;p&gt;This is because exiting with an appropriate exception and messages seems to be kind for users of MLlib.&lt;br/&gt;
It helps them to recognize which part of application they should change.&lt;/p&gt;

&lt;p&gt;How about using sys.error() to throw RuntimeException in the same way as handling of empty rows.&lt;/p&gt;</comment>
                            <comment id="14170832" author="apachespark" created="Tue, 14 Oct 2014 11:58:12 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2801&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2801&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14171579" author="mengxr" created="Tue, 14 Oct 2014 21:42:25 +0000"  >&lt;p&gt;Issue resolved by pull request 2801&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2801&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2801&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 5 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i20t8n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>