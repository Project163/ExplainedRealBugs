<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:27:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-36568] Missed broadcast join in V2 plan</title>
                <link>https://issues.apache.org/jira/browse/SPARK-36568</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;There are some joins that use broadcast hash join with DataSourceV1 but sort merge join with DataSourceV2, even though the two joins are loading the same files &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;p&gt;Create data:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;import scala.util.Random

val rand = new Random(245665L)

val df = spark.range(1, 20000).map { x =&amp;gt;
  (x,
   rand.alphanumeric.take(20).mkString,
   rand.alphanumeric.take(20).mkString,
   rand.alphanumeric.take(20).mkString
  )
}.toDF(&quot;key&quot;, &quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;)

df.write.mode(&quot;overwrite&quot;).format(&quot;parquet&quot;).save(&quot;/tmp/tbl&quot;)
df.write.mode(&quot;overwrite&quot;).format(&quot;parquet&quot;).save(&quot;/tmp/lookup&quot;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Run this code:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;bin/spark-shell --conf spark.sql.autoBroadcastJoinThreshold=400000

spark.read.format(&quot;parquet&quot;).load(&quot;/tmp/tbl&quot;).createOrReplaceTempView(&quot;tbl&quot;)
spark.read.format(&quot;parquet&quot;).load(&quot;/tmp/lookup&quot;).createOrReplaceTempView(&quot;lookup&quot;)

sql(&quot;&quot;&quot;select t.key, t.col1, t.col2, t.col3
from tbl t
join lookup l
on t.key = l.key&quot;&quot;&quot;).explain
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For V2, do the same, except set &lt;tt&gt;spark.sql.sources.useV1SourceList=&quot;&quot;&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;For V1, the result is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- Project [key#0L, col1#1, col2#2, col3#3]
   +- BroadcastHashJoin [key#0L], [key#8L], Inner, BuildRight, false
      :- Filter isnotnull(key#0L)
      :  +- FileScan parquet [key#0L,col1#1,col2#2,col3#3] Batched: true, DataFilters: [isnotnull(key#0L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/tmp/tbl], PartitionFilters: [], PushedFilters: [IsNotNull(key)], ReadSchema: struct&amp;lt;key:bigint,col1:string,col2:string,col3:string&amp;gt;
      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [id=#32]
         +- Filter isnotnull(key#8L)
            +- FileScan parquet [key#8L] Batched: true, DataFilters: [isnotnull(key#8L)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/tmp/lookup], PartitionFilters: [], PushedFilters: [IsNotNull(key)], ReadSchema: struct&amp;lt;key:bigint&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For V2, the result is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=false
+- Project [key#0L, col1#1, col2#2, col3#3]
   +- SortMergeJoin [key#0L], [key#8L], Inner
      :- Sort [key#0L ASC NULLS FIRST], false, 0
      :  +- Exchange hashpartitioning(key#0L, 200), ENSURE_REQUIREMENTS, [id=#33]
      :     +- Filter isnotnull(key#0L)
      :        +- BatchScan[key#0L, col1#1, col2#2, col3#3] ParquetScan DataFilters: [isnotnull(key#0L)], Format: parquet, Location: InMemoryFileIndex(1 paths)[file:/tmp/tbl], PartitionFilters: [], PushedFilters: [IsNotNull(key)], ReadSchema: struct&amp;lt;key:bigint,col1:string,col2:string,col3:string&amp;gt;, PushedFilters: [IsNotNull(key)] RuntimeFilters: []
      +- Sort [key#8L ASC NULLS FIRST], false, 0
         +- Exchange hashpartitioning(key#8L, 200), ENSURE_REQUIREMENTS, [id=#34]
            +- Filter isnotnull(key#8L)
               +- BatchScan[key#8L] ParquetScan DataFilters: [isnotnull(key#8L)], Format: parquet, Location: InMemoryFileIndex(1 paths)[file:/tmp/lookup], PartitionFilters: [], PushedFilters: [IsNotNull(key)], ReadSchema: struct&amp;lt;key:bigint&amp;gt;, PushedFilters: [IsNotNull(key)] RuntimeFilters: []
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The initial plan with V1 uses broadcast hash join, but the initial plan with V2 uses sort merge join.&lt;/p&gt;

&lt;p&gt;The V1 logical plan contains a projection over the relation for &lt;tt&gt;lookup&lt;/tt&gt;, which restricts the output columns to just &lt;tt&gt;key&lt;/tt&gt;. As a result, &lt;tt&gt;SizeInBytesOnlyStatsPlanVisitor#visitUnaryNode&lt;/tt&gt;, when visiting the project node, reduces sizeInBytes based on the pruning:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Project [key#0L, col1#1, col2#2, col3#3]
+- Join Inner, (key#0L = key#8L)
   :- Filter isnotnull(key#0L)
   :  +- Relation [key#0L,col1#1,col2#2,col3#3] parquet
   +- Project [key#8L]
      +- Filter isnotnull(key#8L)
         +- Relation [key#8L,col1#9,col2#10,col3#11] parquet
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The V2 logical plan does not contain this projection:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+- Join Inner, (key#0L = key#8L)
   :- Filter isnotnull(key#0L)
   :  +- RelationV2[key#0L, col1#1, col2#2, col3#3] parquet file:/tmp/tbl
   +- Filter isnotnull(key#8L)
      +- RelationV2[key#8L] parquet file:/tmp/lookup
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; With my example, AQE converts the join to a broadcast hash join at run time for the V2 case. However, if AQE was disabled, it would obviously remain a sort merge join.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13396784">SPARK-36568</key>
            <summary>Missed broadcast join in V2 plan</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="petertoth">Peter Toth</assignee>
                                    <reporter username="bersprockets">Bruce Robbins</reporter>
                        <labels>
                    </labels>
                <created>Mon, 23 Aug 2021 23:19:38 +0000</created>
                <updated>Thu, 26 Aug 2021 03:27:47 +0000</updated>
                            <resolved>Thu, 26 Aug 2021 03:27:08 +0000</resolved>
                                    <version>3.2.0</version>
                                    <fixVersion>3.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17403863" author="apachespark" created="Tue, 24 Aug 2021 15:11:24 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/33825&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/33825&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17403866" author="apachespark" created="Tue, 24 Aug 2021 15:12:40 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/33825&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/33825&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17404880" author="cloud_fan" created="Thu, 26 Aug 2021 03:27:08 +0000"  >&lt;p&gt;Issue resolved by pull request 33825&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/33825&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/33825&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 11 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0u65s:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>