<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:50:48 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18750] spark should be able to control the number of executor and should not throw stack overslow</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18750</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When running Sql queries on large datasets. Job fails with stack overflow warning and it shows it is requesting lots of executors.&lt;/p&gt;

&lt;p&gt;Looks like there is no limit to number of executors or not even having an upperbound based on yarn available resources.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;16/11/29 15:47:47 INFO impl.ContainerManagementProtocolProxy: Opening proxy : bdtcstr61n5.svr.us.jpmchase.net:8041 
16/11/29 15:47:47 INFO impl.ContainerManagementProtocolProxy: Opening proxy : bdtcstr61n8.svr.us.jpmchase.net:8041 
16/11/29 15:47:47 INFO impl.ContainerManagementProtocolProxy: Opening proxy : bdtcstr61n2.svr.us.jpmchase.net:8041 
16/11/29 15:47:47 INFO yarn.YarnAllocator: Driver requested a total number of 32770 executor(s). 
16/11/29 15:47:47 INFO yarn.YarnAllocator: Will request 24576 executor containers, each with 1 cores and 6758 MB memory including 614 MB overhead 
16/11/29 15:49:11 INFO yarn.YarnAllocator: Driver requested a total number of 52902 executor(s). 
16/11/29 15:47:47 INFO impl.ContainerManagementProtocolProxy: Opening proxy : bdtcstr61n5.svr.us.jpmchase.net:8041
16/11/29 15:47:47 INFO impl.ContainerManagementProtocolProxy: Opening proxy : bdtcstr61n8.svr.us.jpmchase.net:8041
16/11/29 15:47:47 INFO impl.ContainerManagementProtocolProxy: Opening proxy : bdtcstr61n2.svr.us.jpmchase.net:8041
16/11/29 15:47:47 INFO yarn.YarnAllocator: Driver requested a total number of 32770 executor(s).
16/11/29 15:47:47 INFO yarn.YarnAllocator: Will request 24576 executor containers, each with 1 cores and 6758 MB memory including 614 MB overhead
16/11/29 15:49:11 INFO yarn.YarnAllocator: Driver requested a total number of 52902 executor(s).
16/11/29 15:49:11 WARN yarn.ApplicationMaster: Reporter thread fails 1 time(s) in a row.
java.lang.StackOverflowError
	at scala.collection.immutable.HashMap.$plus(HashMap.scala:57)
	at scala.collection.immutable.HashMap.$plus(HashMap.scala:36)
	at scala.collection.mutable.MapBuilder.$plus$eq(MapBuilder.scala:28)
	at scala.collection.mutable.MapBuilder.$plus$eq(MapBuilder.scala:24)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:224)
	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:403)
	at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:403)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.MapBuilder.$plus$plus$eq(MapBuilder.scala:24)
	at scala.collection.TraversableLike$class.$plus$plus(TraversableLike.scala:156)
	at scala.collection.AbstractTraversable.$plus$plus(Traversable.scala:105)
	at scala.collection.immutable.HashMap.$plus(HashMap.scala:60)
	at scala.collection.immutable.Map$Map4.updated(Map.scala:172)
	at scala.collection.immutable.Map$Map4.$plus(Map.scala:173)
	at scala.collection.immutable.Map$Map4.$plus(Map.scala:158)
	at scala.collection.mutable.MapBuilder.$plus$eq(MapBuilder.scala:28)
	at scala.collection.mutable.MapBuilder.$plus$eq(MapBuilder.scala:24)
	at scala.collection.TraversableLike$$anonfun$filter$1.apply(TraversableLike.scala:264)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
[...]
16/11/29 15:49:11 INFO yarn.YarnAllocator: Will request 44708 executor containers, each with 1 cores and 6758 MB memory including 614 MB overhead
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you notice in the error above, YARN is trying to request 24576 executor containers, whereas the available cores are 1719. The Driver is requesting for 52902 executor(s), which too high. &lt;/p&gt;

&lt;p&gt;This exception should be fixed&lt;/p&gt;</description>
                <environment></environment>
        <key id="13026134">SPARK-18750</key>
            <summary>spark should be able to control the number of executor and should not throw stack overslow</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vanzin">Marcelo Masiero Vanzin</assignee>
                                    <reporter username="neerjakhattar">Neerja Khattar</reporter>
                        <labels>
                    </labels>
                <created>Tue, 6 Dec 2016 21:50:54 +0000</created>
                <updated>Mon, 18 May 2020 03:24:29 +0000</updated>
                            <resolved>Wed, 25 Jan 2017 14:19:46 +0000</resolved>
                                                    <fixVersion>2.0.3</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15726837" author="srowen" created="Tue, 6 Dec 2016 21:54:59 +0000"  >&lt;p&gt;Hm, I am not immediately sure how these are related. Where does the overflow occur &amp;#8211; is it even in Spark? and I wonder why it would be caused by a lot of executor requests?&lt;/p&gt;

&lt;p&gt;And then why is it asking for so many executors? that seems wrong but is that the bug you are reporting?  does the app ask for that many? is dynamic allocation on, etc?&lt;/p&gt;

&lt;p&gt;This isn&apos;t enough info.&lt;/p&gt;</comment>
                            <comment id="15729226" author="neerjakhattar" created="Wed, 7 Dec 2016 16:47:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; Yes, this happens when dynamic allocation is on. Yes that&apos;s spark sql query when runs on a very large dataset.&lt;/p&gt;</comment>
                            <comment id="15729665" author="srowen" created="Wed, 7 Dec 2016 19:22:16 +0000"  >&lt;p&gt;It sounds like you&apos;re focused on the StackOverflowError, and so controlling the number of executors is actually just incidental. There&apos;s not yet an indication here that the error comes from Spark though. Where is the stack trace coming from? If it&apos;s from YARN libraries the fix would have to go there.&lt;/p&gt;</comment>
                            <comment id="15730717" author="neerjakhattar" created="Thu, 8 Dec 2016 01:25:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; I added the the full stack trace.&lt;/p&gt;</comment>
                            <comment id="15731079" author="srowen" created="Thu, 8 Dec 2016 04:46:15 +0000"  >&lt;p&gt;Yeah, I guess I should have realized that by nature it won&apos;t show the source of the exception, because the stack is too deep. It&apos;s not clear where the exception is coming from &amp;#8211; do you know and is it Spark?&lt;/p&gt;</comment>
                            <comment id="15733892" author="yibing" created="Fri, 9 Dec 2016 00:58:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; The log says:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;16/11/29 15:49:11 WARN yarn.ApplicationMaster: Reporter thread fails 1 time(s) in a row.
java.lang.StackOverflowError
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It looks like that number of executors is too high for reporter thread to deal with.&lt;/p&gt;</comment>
                            <comment id="15734028" author="srowen" created="Fri, 9 Dec 2016 02:12:37 +0000"  >&lt;p&gt;Yes, so the basic question is: where is the error coming from? Is it Spark? May be simplistic question but not sure where to look for a solution and I have the impression the reporter knows.&lt;/p&gt;</comment>
                            <comment id="15739460" author="srowen" created="Sun, 11 Dec 2016 09:46:30 +0000"  >&lt;p&gt;I&apos;m going to close this as a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-18769&quot; title=&quot; Spark to be smarter about what the upper bound is and to restrict number of executor when dynamic allocation is enabled&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-18769&quot;&gt;&lt;del&gt;SPARK-18769&lt;/del&gt;&lt;/a&gt; unless there&apos;s evidence that this is an error from Spark, and can be patched separately from the apparent underlying cause, which is in that JIRA.&lt;/p&gt;</comment>
                            <comment id="15829008" author="vanzin" created="Wed, 18 Jan 2017 23:56:17 +0000"  >&lt;p&gt;Sean, this is a separate issue. Even if Spark is changed to be smarter, it could still decide to try to allocate a bunch of containers and hit this overflow error.&lt;/p&gt;</comment>
                            <comment id="15829132" author="vanzin" created="Thu, 19 Jan 2017 01:38:34 +0000"  >&lt;p&gt;I haven&apos;t been able to reproduce this yet, but &lt;a href=&quot;http://stackoverflow.com/questions/25450887/scala-map-mapvalues-stackoverflowerror&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://stackoverflow.com/questions/25450887/scala-map-mapvalues-stackoverflowerror&lt;/a&gt; seems to imply that the use of &quot;mapValues&quot; may be related. That is used in &lt;tt&gt;LocalityPreferredContainerPlacementStrategy&lt;/tt&gt; and may be worth taking a look at.&lt;/p&gt;</comment>
                            <comment id="15832684" author="vanzin" created="Sat, 21 Jan 2017 00:52:29 +0000"  >&lt;p&gt;Yay, I can reproduce it with a unit test against &lt;tt&gt;LocalityPreferredContainerPlacementStrategy&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="15832703" author="apachespark" created="Sat, 21 Jan 2017 01:14:05 +0000"  >&lt;p&gt;User &apos;vanzin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16667&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16667&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15833386" author="jelmer" created="Sun, 22 Jan 2017 09:08:57 +0000"  >&lt;p&gt;I am seeing the exact same issue when using dynamic allocation and doing just a basic spark sql query over a large data set&lt;/p&gt;</comment>
                            <comment id="15838390" author="apachespark" created="Wed, 25 Jan 2017 19:09:06 +0000"  >&lt;p&gt;User &apos;vanzin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16704&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13305580">SPARK-31746</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 42 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3797z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>