<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:41:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-14234] Executor crashes for TaskRunner thread interruption</title>
                <link>https://issues.apache.org/jira/browse/SPARK-14234</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;If the TaskRunner thread gets interrupted while running due to task kill or any other reason, the interrupted thread will try to update the task status as part of the exception handling and fails with the below exception. This is happening from all of these catch blocks statusUpdate calls, below are the exceptions correspondingly for all these catch cases.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;Executor.scala&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _: TaskKilledException | _: InterruptedException &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; task.killed =&amp;gt;
         ......

        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; cDE: CommitDeniedException =&amp;gt;
         ......

        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; t: Throwable =&amp;gt;
         ......
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;16/03/29 17:32:33 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-2,5,main]
java.lang.Error: java.nio.channels.ClosedByInterruptException
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1151)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.nio.channels.Channels$WritableByteChannelImpl.write(Channels.java:460)
	at org.apache.spark.util.SerializableBuffer$$anonfun$writeObject$1.apply(SerializableBuffer.scala:49)
	at org.apache.spark.util.SerializableBuffer$$anonfun$writeObject$1.apply(SerializableBuffer.scala:47)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1204)
	at org.apache.spark.util.SerializableBuffer.writeObject(SerializableBuffer.scala:47)
	at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:988)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1495)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1547)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1508)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1431)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1177)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:347)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)
	at org.apache.spark.rpc.netty.NettyRpcEnv.serialize(NettyRpcEnv.scala:253)
	at org.apache.spark.rpc.netty.NettyRpcEnv.send(NettyRpcEnv.scala:192)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:513)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend.statusUpdate(CoarseGrainedExecutorBackend.scala:135)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	... 2 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;16/03/29 08:00:29 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-4,5,main]
java.lang.Error: java.nio.channels.ClosedByInterruptException
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1151)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.nio.channels.Channels$WritableByteChannelImpl.write(Channels.java:460)
	..................
	at org.apache.spark.rpc.netty.NettyRpcEnv.send(NettyRpcEnv.scala:192)
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:513)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend.statusUpdate(CoarseGrainedExecutorBackend.scala:135)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:326)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	... 2 more
16/03/29 08:00:29 INFO DiskBlockManager: Shutdown hook called
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-xml&quot;&gt;16/03/29 17:28:56 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker-3,5,main]
java.lang.Error: java.nio.channels.ClosedByInterruptException
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1151)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at java.nio.channels.Channels$WritableByteChannelImpl.write(Channels.java:460)
	..................
	at org.apache.spark.rpc.netty.NettyRpcEndpointRef.send(NettyRpcEnv.scala:513)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend.statusUpdate(CoarseGrainedExecutorBackend.scala:135)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:355)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	... 2 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12954226">SPARK-14234</key>
            <summary>Executor crashes for TaskRunner thread interruption</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="devaraj">Devaraj Kavali</assignee>
                                    <reporter username="devaraj">Devaraj Kavali</reporter>
                        <labels>
                    </labels>
                <created>Tue, 29 Mar 2016 08:04:55 +0000</created>
                <updated>Wed, 31 Aug 2016 21:28:18 +0000</updated>
                            <resolved>Tue, 3 May 2016 20:26:08 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15215679" author="apachespark" created="Tue, 29 Mar 2016 08:30:05 +0000"  >&lt;p&gt;User &apos;devaraj-kavali&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12031&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12031&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15298333" author="barrybecker4" created="Tue, 24 May 2016 15:10:56 +0000"  >&lt;p&gt;Will this fix be back-ported to 1.6.x?&lt;br/&gt;
We are encountering what appears to be this same issue when using spark 1.6.1 and jobserver 0.6.2.&lt;/p&gt;

&lt;p&gt;Looking into the logs, we narrowed down the problem to killing of a task and can successfully reproduce this by killing two tasks in a row. It appears that mesos slave gets blacklisted after a repeated failure and never gets back up.&lt;br/&gt;
First time a task is killed we can see this in the spark-job-server.log file:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[2016-04-22 10:11:56,919] INFO k.jobserver.JobStatusActor [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context/$a] - Job 0ecdbe5a-bde1-4818-ba24-b5af0fbee5af killed
&lt;/span&gt;[2016-04-22 10:11:56,921] ERROR k.jobserver.JobStatusActor [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context/$a] - No such job id 0ecdbe5a-bde1-4818-ba24-b5af0fbee5af
&lt;/span&gt;[2016-04-22 10:11:56,920] INFO cheduler.TaskSchedulerImpl [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Cancelling stage 99
&lt;/span&gt;[2016-04-22 10:11:56,920] INFO cheduler.TaskSchedulerImpl [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Stage 99 was cancelled
&lt;/span&gt;[2016-04-22 10:11:56,924] INFO he.spark.executor.Executor [] [] - Executor is trying to kill task 0.0 in stage 99.0 (TID 736)
[2016-04-22 10:11:56,924] INFO he.spark.executor.Executor [] [] - Executor is trying to kill task 1.0 in stage 99.0 (TID 737)
[2016-04-22 10:11:56,925] INFO he.spark.executor.Executor [] [] - Executor killed task 1.0 in stage 99.0 (TID 737)
[2016-04-22 10:11:56,925] INFO he.spark.executor.Executor [] [] - Executor killed task 0.0 in stage 99.0 (TID 736)
[2016-04-22 10:11:56,933] ERROR rkUncaughtExceptionHandler [] [] - Uncaught exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[Executor task launch worker-25,5,main]
java.lang.Error: java.nio.channels.ClosedByInterruptException
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1148)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.nio.channels.ClosedByInterruptException
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;A few minutes later, another task gets killed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[2016-04-22 10:16:49,890] INFO k.jobserver.JobStatusActor [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context/$a] - Job cf0c58e9-6496-4d5d-8a6f-0072ca742e33 killed
&lt;/span&gt;[2016-04-22 10:16:49,891] INFO cheduler.TaskSchedulerImpl [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Cancelling stage 101
&lt;/span&gt;[2016-04-22 10:16:49,891] INFO cheduler.TaskSchedulerImpl [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Stage 101 was cancelled
&lt;/span&gt;[2016-04-22 10:16:49,892] ERROR k.jobserver.JobStatusActor [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context/$a] - No such job id cf0c58e9-6496-4d5d-8a6f-0072ca742e33
&lt;/span&gt;[2016-04-22 10:16:50,254] ERROR cheduler.TaskSchedulerImpl [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Lost executor 20160216-173849-2066065046-5050-48639-S0 on ra.engr.sgi.com: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; WARN messages.
&lt;/span&gt;[2016-04-22 10:16:50,254] WARN k.scheduler.TaskSetManager [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Lost task 0.0 in stage 101.0 (TID 738, ra.engr.sgi.com): ExecutorLostFailure (executor 20160216-173849-2066065046-5050-48639-S0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; WARN messages.
&lt;/span&gt;[2016-04-22 10:16:50,254] WARN k.scheduler.TaskSetManager [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Lost task 1.0 in stage 101.0 (TID 739, ra.engr.sgi.com): ExecutorLostFailure (executor 20160216-173849-2066065046-5050-48639-S0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; WARN messages.
&lt;/span&gt;[2016-04-22 10:16:50,254] INFO cheduler.TaskSchedulerImpl [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Removed TaskSet 101.0, whose tasks have all completed, from pool
&lt;/span&gt;[2016-04-22 10:16:50,255] INFO BlockManagerMasterEndpoint [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Trying to remove executor 20160216-173849-2066065046-5050-48639-S0 from BlockManagerMaster.
&lt;/span&gt;[2016-04-22 10:16:50,255] INFO BlockManagerMasterEndpoint [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Removing block manager BlockManagerId(20160216-173849-2066065046-5050-48639-S0, ra.engr.sgi.com, 46374)
&lt;/span&gt;[2016-04-22 10:16:50,255] INFO storage.BlockManagerMaster [] [akka:&lt;span class=&quot;code-comment&quot;&gt;//JobServer/user/context-supervisor/sql-context] - Removed 20160216-173849-2066065046-5050-48639-S0 successfully in removeExecutor
&lt;/span&gt;[2016-04-22 10:16:50,283] INFO oarseMesosSchedulerBackend [] [] - Mesos task 1 is now TASK_FAILED
[2016-04-22 10:16:50,284] INFO oarseMesosSchedulerBackend [] [] - Blacklisting Mesos slave 20160216-173849-2066065046-5050-48639-S0 due to too many failures; is Spark installed on it?
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15379041" author="jotsif" created="Fri, 15 Jul 2016 08:55:18 +0000"  >&lt;p&gt;+1 for backporting&lt;/p&gt;</comment>
                            <comment id="15453414" author="barrybecker4" created="Wed, 31 Aug 2016 21:28:18 +0000"  >&lt;p&gt;Is it a lot of work to backport this fix 1.6.3?&lt;br/&gt;
We have an app that requires it. We also require job-server and that does not look like it will be supporting 2.0.0 anytime soon.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 11 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2vbz3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>