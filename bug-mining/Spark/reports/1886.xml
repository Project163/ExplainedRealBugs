<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:27:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-6416] Document that RDD.fold() requires the operator to be commutative</title>
                <link>https://issues.apache.org/jira/browse/SPARK-6416</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Spark&apos;s &lt;tt&gt;RDD.fold&lt;/tt&gt; operation has some confusing behaviors when a non-commutative reduce function is used.&lt;/p&gt;

&lt;p&gt;Here&apos;s an example, which was originally reported on StackOverflow (&lt;a href=&quot;https://stackoverflow.com/questions/29150202/pyspark-fold-method-output):&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://stackoverflow.com/questions/29150202/pyspark-fold-method-output):&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.parallelize([1,25,8,4,2]).fold(0,lambda a,b:a+1 )
8
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To understand what&apos;s going on here, let&apos;s look at the definition of Spark&apos;s `fold` operation.  &lt;/p&gt;

&lt;p&gt;I&apos;m going to show the Python version of the code, but the Scala version exhibits the exact same behavior (you can also &lt;a href=&quot;https://github.com/apache/spark/blob/8cb23a1f9a3ed08e57865bcb6cc1cc7902881073/python/pyspark/rdd.py#L780&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;browse the source on GitHub&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    def fold(self, zeroValue, op):
        &quot;&quot;&quot;
        Aggregate the elements of each partition, and then the results &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all
        the partitions, using a given associative function and a neutral &quot;zero
        value.&quot;
        The function C{op(t1, t2)} is allowed to modify C{t1} and &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; it
        as its result value to avoid object allocation; however, it should not
        modify C{t2}.
        &amp;gt;&amp;gt;&amp;gt; from &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; add
        &amp;gt;&amp;gt;&amp;gt; sc.parallelize([1, 2, 3, 4, 5]).fold(0, add)
        15
        &quot;&quot;&quot;
        def func(iterator):
            acc = zeroValue
            &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; obj in iterator:
                acc = op(obj, acc)
            yield acc
        vals = self.mapPartitions(func).collect()
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; reduce(op, vals, zeroValue)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(For comparison, see the &lt;a href=&quot;https://github.com/apache/spark/blob/8cb23a1f9a3ed08e57865bcb6cc1cc7902881073/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L943&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Scala implementation of `RDD.fold`&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Spark&apos;s `fold` operates by first folding each partition and then folding the results.  The problem is that an empty partition gets folded down to the zero element, so the final driver-side fold ends up folding one value for &lt;em&gt;every&lt;/em&gt; partition rather than one value for each &lt;em&gt;non-empty&lt;/em&gt; partition.  This means that the result of `fold` is sensitive to the number of partitions:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &amp;gt;&amp;gt;&amp;gt; sc.parallelize([1,25,8,4,2], 100).fold(0,lambda a,b:a+1 )
    100
    &amp;gt;&amp;gt;&amp;gt; sc.parallelize([1,25,8,4,2], 50).fold(0,lambda a,b:a+1 )
    50
    &amp;gt;&amp;gt;&amp;gt; sc.parallelize([1,25,8,4,2], 1).fold(0,lambda a,b:a+1 )
    1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this last case, what&apos;s happening is that the single partition is being folded down to the correct value, then that value is folded with the zero-value at the driver to yield 1.&lt;/p&gt;

&lt;p&gt;I think the underlying problem here is that our fold() operation implicitly requires the operator to be commutative in addition to associative, but this isn&apos;t documented anywhere.  Due to ordering non-determinism elsewhere in Spark, such as &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-5750&quot; title=&quot;Document that ordering of elements in shuffled partitions is not deterministic across runs&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-5750&quot;&gt;&lt;del&gt;SPARK-5750&lt;/del&gt;&lt;/a&gt;, I don&apos;t think there&apos;s an easy way to fix this.  Therefore, I think we should update the documentation and examples to clarify this requirement and explain that our fold acts more like a reduce with a default value than the type of ordering-sensitive fold() that users may expect in functional languages.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12783325">SPARK-6416</key>
            <summary>Document that RDD.fold() requires the operator to be commutative</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="joshrosen">Josh Rosen</reporter>
                        <labels>
                    </labels>
                <created>Thu, 19 Mar 2015 18:03:06 +0000</created>
                <updated>Sun, 3 Jan 2016 08:55:30 +0000</updated>
                            <resolved>Sun, 3 Jan 2016 08:55:03 +0000</resolved>
                                    <version>1.4.0</version>
                                    <fixVersion>1.5.0</fixVersion>
                                    <component>Documentation</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14547120" author="srowen" created="Sun, 17 May 2015 10:31:52 +0000"  >&lt;p&gt;Josh I&apos;m looking at the related &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7683&quot; title=&quot;Confusing behavior of fold function of RDD in pyspark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7683&quot;&gt;&lt;del&gt;SPARK-7683&lt;/del&gt;&lt;/a&gt; which will require a behavior change at some point in the future. Is this something you would change the implementation of, in the future (2.x) or sooner? &lt;/p&gt;

&lt;p&gt;I can try to document this in the short term anyway.&lt;/p&gt;</comment>
                            <comment id="14547199" author="joshrosen" created="Sun, 17 May 2015 14:59:58 +0000"  >&lt;p&gt;Hey Sean,&lt;/p&gt;

&lt;p&gt;I don&apos;t think that this will be easy to fix (efficiently) due to the ordering non-determinism issues mentioned above, so I think that we should update the docs to clarify the commutativity requirements.  &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-7683&quot; title=&quot;Confusing behavior of fold function of RDD in pyspark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-7683&quot;&gt;&lt;del&gt;SPARK-7683&lt;/del&gt;&lt;/a&gt;, on the other hand, seems like an obvious fix for 2.x.  For 2.x, we could also consider removing fold, since it seems to be a source of confusion.&lt;/p&gt;</comment>
                            <comment id="14547718" author="apachespark" created="Mon, 18 May 2015 08:38:05 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/6231&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/6231&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14554839" author="srowen" created="Thu, 21 May 2015 18:44:10 +0000"  >&lt;p&gt;The documentation update is done. Possibly worth leaving this open to track maybe removing this op in 2.0.&lt;/p&gt;</comment>
                            <comment id="14554871" author="markhamstra" created="Thu, 21 May 2015 19:02:19 +0000"  >&lt;p&gt;Why remove it?  It&apos;s very useful when used correctly.&lt;/p&gt;</comment>
                            <comment id="14554891" author="srowen" created="Thu, 21 May 2015 19:15:05 +0000"  >&lt;p&gt;I think the argument was that it is just a different form of reduce() since it can&apos;t guarantee to fold things serially, in order, into a zero value. I&apos;m not strongly advocating for further action here, myself.&lt;/p&gt;</comment>
                            <comment id="15076318" author="srowen" created="Fri, 1 Jan 2016 15:45:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markhamstra&quot; class=&quot;user-hover&quot; rel=&quot;markhamstra&quot;&gt;markhamstra&lt;/a&gt; WDYT about deprecating fold() for 2.x? or else, I think this can be closed.&lt;/p&gt;</comment>
                            <comment id="15076367" author="markhamstra" created="Fri, 1 Jan 2016 19:23:04 +0000"  >&lt;p&gt;I don&apos;t see any reason to change the API wrt `fold`.  With operations on RDDs, we generally try to achieve the same semantics as for Scala parallel collections, and that does hold true for `fold`:&lt;/p&gt;

&lt;p&gt;  scala&amp;gt; val list = (1 to 10000).toList&lt;/p&gt;

&lt;p&gt;  scala&amp;gt; list.fold(0)(_ + _)&lt;br/&gt;
  res0: Int = 50005000&lt;/p&gt;

&lt;p&gt;  scala&amp;gt; list.par.fold(0)(_ + _)&lt;br/&gt;
  res1: Int = 50005000&lt;/p&gt;

&lt;p&gt;  scala&amp;gt; list.fold(1)(_ + _)&lt;br/&gt;
  res2: Int = 50005001&lt;/p&gt;

&lt;p&gt;  scala&amp;gt; list.par.fold(1)(_ + _)&lt;br/&gt;
  res3: Int = 50005039&lt;/p&gt;


&lt;p&gt;If we need to change anything, it would simply be to change our API documentation to more closely match that of the Scala Standard Library, where the first argument to `fold` is described as: &quot;a neutral element for the fold operation, it may be added to the result an arbitrary number of times, not changing the result (e.g. Nil for list concatenation, 0 for addition, or 1 for multiplication)&quot;.&lt;/p&gt;</comment>
                            <comment id="15076474" author="srowen" created="Sat, 2 Jan 2016 09:43:24 +0000"  >&lt;p&gt;That&apos;s an interesting example, in that I wouldn&apos;t have though the 3rd and 4th examples would differ. However your example does violate the contract, since you&apos;re providing 1 as a neutral element for addition, which isn&apos;t valid. In Josh&apos;s example, he passes 0 and still gets the differing results depending on partitions. Your 1st and 2nd examples show Scala APIs would give the same answer. Does that change your thinking?&lt;/p&gt;</comment>
                            <comment id="15076704" author="markhamstra" created="Sat, 2 Jan 2016 23:44:20 +0000"  >&lt;p&gt;I still don&apos;t see RDD#fold as being out of bounds with what should be expected from the Scala parallel collections model &amp;#8211; there, too, you can get confusing results if you don&apos;t pay attention to the partitioned nature of the operation:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; val list1 = (1 to 10000).toList

scala&amp;gt; val list2 = (1 to 100).toList

scala&amp;gt; list1.fold(0){ &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (a, b) =&amp;gt; a + 1 }
res0: Int = 10000

scala&amp;gt; list1.par.fold(0){ &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (a, b) =&amp;gt; a + 1 }
res1: Int = 162

scala&amp;gt; list2.fold(0){ &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (a, b) =&amp;gt; a + 1 }
res2: Int = 100

scala&amp;gt; list2.par.fold(0){ &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (a, b) =&amp;gt; a + 1 }
res3: Int = 7
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15080369" author="srowen" created="Sun, 3 Jan 2016 08:55:03 +0000"  >&lt;p&gt;Hm! I should have tried that myself. I think that&apos;s a good argument that at least it&apos;s not inconsistent. The behavior is documented by an earlier change so calling this resolved, retroactively.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12830449">SPARK-7683</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 46 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i26zsn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>