<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:01:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-25164] Parquet reader builds entire list of columns once for each column</title>
                <link>https://issues.apache.org/jira/browse/SPARK-25164</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;tt&gt;VectorizedParquetRecordReader.initializeInternal&lt;/tt&gt; loops through each column, and for each column it calls&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;requestedSchema.getColumns().get(i)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;However, &lt;tt&gt;MessageType.getColumns&lt;/tt&gt; will build the entire column list from getPaths(0).&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  public List&amp;lt;ColumnDescriptor&amp;gt; getColumns() {
    List&amp;lt;String[]&amp;gt; paths = this.getPaths(0);
    List&amp;lt;ColumnDescriptor&amp;gt; columns = new ArrayList&amp;lt;ColumnDescriptor&amp;gt;(paths.size());
    for (String[] path : paths) {
      // TODO: optimize this                                                                                                                    
      PrimitiveType primitiveType = getType(path).asPrimitiveType();
      columns.add(new ColumnDescriptor(
                      path,
                      primitiveType,
                      getMaxRepetitionLevel(path),
                      getMaxDefinitionLevel(path)));
    }
    return columns;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This means that for each parquet file, this routine indirectly iterates colCount*colCount times.&lt;/p&gt;

&lt;p&gt;This is actually not particularly noticeable unless you have:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;many parquet files&lt;/li&gt;
	&lt;li&gt;many columns&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;To verify that this is an issue, I created&#160;a 1 million record parquet table with 6000 columns of type double and 67 files (so initializeInternal is called 67 times). I ran the following query:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;sql(&quot;select * from 6000_1m_double where id1 = 1&quot;).collect
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I used Spark from&#160;the master branch. I had 8 executor threads. The filter returns only a few thousand records. The query ran (on average) for 6.4 minutes.&lt;/p&gt;

&lt;p&gt;Then I cached the column list at the top of &lt;tt&gt;initializeInternal&lt;/tt&gt; as follows:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;List&amp;lt;ColumnDescriptor&amp;gt; columnCache = requestedSchema.getColumns();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Then I changed&#160;&lt;tt&gt;initializeInternal&lt;/tt&gt; to use &lt;tt&gt;columnCache&lt;/tt&gt; rather than &lt;tt&gt;requestedSchema.getColumns()&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;With the column cache variable, the same query runs in 5 minutes. So with my simple query, you save %22 of time by not rebuilding the column list for each column.&lt;/p&gt;

&lt;p&gt;You get additional savings with a paths cache variable, now saving 34% in total on the above query.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13180047">SPARK-25164</key>
            <summary>Parquet reader builds entire list of columns once for each column</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bersprockets">Bruce Robbins</assignee>
                                    <reporter username="bersprockets">Bruce Robbins</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Aug 2018 19:34:55 +0000</created>
                <updated>Tue, 16 Oct 2018 16:32:49 +0000</updated>
                            <resolved>Thu, 23 Aug 2018 06:53:24 +0000</resolved>
                                    <version>2.4.0</version>
                                    <fixVersion>2.2.3</fixVersion>
                    <fixVersion>2.3.2</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16588159" author="viirya" created="Tue, 21 Aug 2018 23:29:47 +0000"  >&lt;p&gt;This looks easy and good to have. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bersprockets&quot; class=&quot;user-hover&quot; rel=&quot;bersprockets&quot;&gt;bersprockets&lt;/a&gt; Do you want to submit a PR for this?&lt;/p&gt;</comment>
                            <comment id="16588168" author="bersprockets" created="Tue, 21 Aug 2018 23:46:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=viirya&quot; class=&quot;user-hover&quot; rel=&quot;viirya&quot;&gt;viirya&lt;/a&gt; Sure. I will try to get something up by tonight or tomorrow morning (Pacific Time).&lt;/p&gt;</comment>
                            <comment id="16589228" author="apachespark" created="Wed, 22 Aug 2018 18:30:04 +0000"  >&lt;p&gt;User &apos;bersprockets&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22188&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22188&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16589787" author="cloud_fan" created="Thu, 23 Aug 2018 06:53:24 +0000"  >&lt;p&gt;Issue resolved by pull request 22188&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22188&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22188&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16611089" author="tagar" created="Tue, 11 Sep 2018 18:58:20 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bersprockets&quot; class=&quot;user-hover&quot; rel=&quot;bersprockets&quot;&gt;bersprockets&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Very good find ! Thanks.&lt;/p&gt;

&lt;p&gt;As described in&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-24316&quot; title=&quot;Spark sql queries stall for  column width more than 6k for parquet based table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-24316&quot;&gt;SPARK-24316&lt;/a&gt;, &quot;even simple queries of fetching 70k rows takes 20 minutes&quot;.&#160;&lt;/p&gt;

&lt;p&gt;This PR-22188 gives 21-44% improvement, reducing total runtime to 11-16 minutes.&lt;/p&gt;

&lt;p&gt;It seems &lt;b&gt;reading&#160;70k rows for over 10 minutes&lt;/b&gt; with multiple&#160;executors is still quite slow.&#160;&lt;/p&gt;

&lt;p&gt;Do you think there might be other issue? So it seems time complexity of reading parquet files is O(num_columns * num_parquet_files)?&lt;br/&gt;
 Is there is any way to optimize this further?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16611331" author="bersprockets" created="Tue, 11 Sep 2018 22:27:27 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Tagar&quot; class=&quot;user-hover&quot; rel=&quot;Tagar&quot;&gt;Tagar&lt;/a&gt; for the feedback. I assume the 44% improvement was for a table with lots of file splits.&lt;/p&gt;

&lt;p&gt;I have thoughts on this issue, but fetching 70k rows from a wide table that has itself only 70k rows should be somewhat fast. With a table like that, I can fetch 70k rows on my laptop in under a minute.&lt;/p&gt;

&lt;p&gt;Fetching 70k rows from a table that has, say, 10m million rows, can be pretty poky, even with this fix.&lt;/p&gt;

&lt;p&gt;I have theories (or partially informed speculation) about why this is. Here is the gist:&lt;/p&gt;

&lt;p&gt;Let&apos;s say&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;your projection includes every column of a wide table (i.e., &lt;tt&gt;select *&lt;/tt&gt;)&lt;/li&gt;
	&lt;li&gt;you are filtering away most rows from a large table (e.g., &lt;tt&gt;select * from table where id1 = 1&lt;/tt&gt;, which would fetch, say, only 0.2% of the rows)&lt;/li&gt;
	&lt;li&gt;matching rows are sprinkled fairly evenly throughout the table&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In this case, Spark ends up reading (potentially) every data page from the parquet file, and realizing each wide row in memory, just to pass the row to Spark&apos;s filter operator so it can be (most likely) discarded.&lt;/p&gt;

&lt;p&gt;This is true even when Spark pushes down the filter to the parquet reader.&lt;/p&gt;

&lt;p&gt;This is because the matching rows are sprinkled evenly throughout the table, so (potentially) every data page for column id1 has at least one entry where value = 1. When a page has even a single matching entry, Spark realizes all the rows associated with that page.&lt;/p&gt;

&lt;p&gt;Realizing very wide rows in memory seems to be somewhat expensive, according to my profiling.&#160;I am not sure yet what part of realizing the rows in memory is expensive.&lt;/p&gt;

&lt;p&gt;If the matching rows tend to be clumped together in one part of the table (say, the table is sorted on id1), most data pages will not contain matching rows. Spark can skip reading most data pages, and therefore avoid realizing most rows in memory. In that case, the query will be much faster: In a test I just ran, my query on the sorted table was 3 times faster. The filter push down code seems to be intended for cases like this.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;select * from table limit nnnn&lt;/tt&gt; is also slow, although not as slow as filtering the same number of records, but I have not&#160;looked into why.&lt;/p&gt;</comment>
                            <comment id="16614020" author="tagar" created="Thu, 13 Sep 2018 20:19:35 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bersprockets&quot; class=&quot;user-hover&quot; rel=&quot;bersprockets&quot;&gt;bersprockets&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Thanks a lot for the detailed response.&lt;/p&gt;

&lt;p&gt;I totally see with what you&apos;re saying.&lt;/p&gt;

&lt;p&gt;That&apos;s interesting that Spark realizing all rows even though where filter has a predicate for just one column.&lt;/p&gt;

&lt;p&gt;I am thinking if it&apos;s feasible to lazily realize list of columns in select-clause only after filtering is complete?&lt;/p&gt;

&lt;p&gt;It seems could be a huge performance improvement for wider tables like this.&lt;/p&gt;

&lt;p&gt;In other words, if Spark would realize list of columns specified in where clause first, and only after filtering &lt;br/&gt;
realize rest of columns needed for select-clause.&lt;/p&gt;

&lt;p&gt;Thoughts?&#160;&lt;/p&gt;

&lt;p&gt;Thank you!&lt;br/&gt;
Ruslan&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16621125" author="bersprockets" created="Wed, 19 Sep 2018 20:03:37 +0000"  >&lt;blockquote&gt;&lt;p&gt;I am thinking if it&apos;s feasible to lazily realize list of columns in select-clause only after filtering is complete?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Assuming my analysis is correct, that would be the fix (or at least, the only one I can think of at the moment).&lt;/p&gt;</comment>
                            <comment id="16638803" author="bersprockets" created="Thu, 4 Oct 2018 20:14:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Tagar&quot; class=&quot;user-hover&quot; rel=&quot;Tagar&quot;&gt;Tagar&lt;/a&gt; I&apos;ve opened&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-25643&quot; title=&quot;Performance issues querying wide rows&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-25643&quot;&gt;SPARK-25643&lt;/a&gt; to keep track of the wide row issue discussed above.&lt;/p&gt;</comment>
                            <comment id="16640045" author="tagar" created="Fri, 5 Oct 2018 16:26:30 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bersprockets&quot; class=&quot;user-hover&quot; rel=&quot;bersprockets&quot;&gt;bersprockets&lt;/a&gt; - &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-25643&quot; title=&quot;Performance issues querying wide rows&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-25643&quot;&gt;SPARK-25643&lt;/a&gt; would be a huge improvement for wider datasets,&lt;br/&gt;
but will also be helpful for querying performance on normal dataframes too.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13189544">SPARK-25643</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13160353">SPARK-24316</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 6 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3x8gn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>