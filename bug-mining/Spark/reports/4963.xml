<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:54:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-13669] Job will always fail in the external shuffle service unavailable situation</title>
                <link>https://issues.apache.org/jira/browse/SPARK-13669</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Currently we are running into an issue with Yarn work preserving enabled + external shuffle service. &lt;/p&gt;

&lt;p&gt;In the work preserving enabled scenario, the failure of NM will not lead to the exit of executors, so executors can still accept and run the tasks. The problem here is when NM is failed, external shuffle service is actually inaccessible, so reduce tasks will always complain about the &#8220;Fetch failure&#8221;, and the failure of reduce stage will make the parent stage (map stage) rerun. The tricky thing here is Spark scheduler is not aware of the unavailability of external shuffle service, and will reschedule the map tasks on the executor where NM is failed, and again reduce stage will be failed with &#8220;Fetch failure&#8221;, and after 4 retries, the job is failed.&lt;/p&gt;

&lt;p&gt;So here the main problem is that we should avoid assigning tasks to those bad executors (where shuffle service is unavailable). Current Spark&apos;s blacklist mechanism could blacklist executors/nodes by failure tasks, but it doesn&apos;t handle this specific fetch failure scenario. So here propose to improve the current application blacklist mechanism to handle fetch failure issue (especially with external shuffle service unavailable issue), to blacklist the executors/nodes where shuffle fetch is unavailable.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12946904">SPARK-13669</key>
            <summary>Job will always fail in the external shuffle service unavailable situation</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jerryshao">Saisai Shao</assignee>
                                    <reporter username="jerryshao">Saisai Shao</reporter>
                        <labels>
                    </labels>
                <created>Fri, 4 Mar 2016 06:56:36 +0000</created>
                <updated>Fri, 10 Nov 2017 03:50:50 +0000</updated>
                            <resolved>Mon, 26 Jun 2017 16:17:18 +0000</resolved>
                                                    <fixVersion>2.3.0</fixVersion>
                                    <component>Scheduler</component>
                    <component>Spark Core</component>
                    <component>YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15179485" author="jerryshao" created="Fri, 4 Mar 2016 07:08:21 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=imranr&quot; class=&quot;user-hover&quot; rel=&quot;imranr&quot;&gt;imranr&lt;/a&gt;, I think you fixed this issue (&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-9439&quot; title=&quot;ExternalShuffleService should be robust to NodeManager restarts in yarn&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-9439&quot;&gt;&lt;del&gt;SPARK-9439&lt;/del&gt;&lt;/a&gt;) and have much knowledge on scheduler and blacklist things, would you please comment on this issue, thanks a lot.&lt;/p&gt;













</comment>
                            <comment id="15214398" author="tgraves" created="Mon, 28 Mar 2016 16:19:26 +0000"  >&lt;p&gt;I think there is a bigger blacklisting change required for this. &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-8425&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-8425&lt;/a&gt;.  There could be lots of things wrong with that node, including the external shuffle service. &lt;/p&gt;</comment>
                            <comment id="15889562" author="apachespark" created="Wed, 1 Mar 2017 06:04:04 +0000"  >&lt;p&gt;User &apos;jerryshao&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17113&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17113&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16111548" author="irashid" created="Wed, 2 Aug 2017 19:11:34 +0000"  >&lt;p&gt;Since I dragged my feet about the usefulness of this feature during the review, I thought in fairness I should mention that I have seen users run into the scenario where this patch would have been helpful.&lt;/p&gt;

&lt;p&gt;The cases I&apos;ve seen have been from incorrect cluster maintenance.  A disk went bad in the cluster, and node gets blacklisted by spark; at some point later on, someone attempts to fix the cluster, but instead of decommissioning the node, they just stop the NM on the node.  The executors stay up; and even if they were blacklisted, when the blacklist expires, then they try to run some tasks again.  Even with one bad disk, by chance some of those tasks succeed, but then you get fetch failures because the external shuffle service is entirely down.&lt;/p&gt;

&lt;p&gt;I still have qualms about this feature, though, because of false-positives that you might get from it.  So I&apos;m recommending users leave it off anyway.  In particular, I worry that NM restarts will trigger blacklisting.  Even if that should be covered under timeouts, users may misconfigure things, or maybe they intentionally leave small timeouts for streaming etc.  I could even see this resulting in blacklisting the entire cluster.&lt;/p&gt;

&lt;p&gt;I&apos;m still missing data points on what happens when people use this in practice, whether it ends up with false-positives, or helps prevent other issues.  I&apos;d be interested in hearing more feedback on others experience with it.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13115574">SPARK-22426</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13060672">SPARK-20178</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 15 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2u57z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>