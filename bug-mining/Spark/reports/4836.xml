<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:53:19 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17424] Dataset job fails from unsound substitution in ScalaReflect</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17424</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I have a job that uses datasets in 1.6.1 and is failing with this error:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;16/09/02 17:02:56 ERROR Driver ApplicationMaster: User &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;threw exception: java.lang.AssertionError: assertion failed: Unsound substitution from List(type T, type U) to List()
java.lang.AssertionError: assertion failed: Unsound substitution from List(type T, type U) to List()
    at scala.reflect.internal.Types$SubstMap.&amp;lt;init&amp;gt;(Types.scala:4644)
    at scala.reflect.internal.Types$SubstTypeMap.&amp;lt;init&amp;gt;(Types.scala:4761)
    at scala.reflect.internal.Types$Type.subst(Types.scala:796)
    at scala.reflect.internal.Types$TypeApiImpl.substituteTypes(Types.scala:321)
    at scala.reflect.internal.Types$TypeApiImpl.substituteTypes(Types.scala:298)
    at org.apache.spark.sql.catalyst.ScalaReflection$$anonfun$getConstructorParameters$1.apply(ScalaReflection.scala:769)
    at org.apache.spark.sql.catalyst.ScalaReflection$$anonfun$getConstructorParameters$1.apply(ScalaReflection.scala:768)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.immutable.List.foreach(List.scala:318)
    at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
    at scala.collection.AbstractTraversable.map(Traversable.scala:105)
    at org.apache.spark.sql.catalyst.ScalaReflection$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;getConstructorParameters(ScalaReflection.scala:768)
    at org.apache.spark.sql.catalyst.ScalaReflection$.getConstructorParameters(ScalaReflection.scala:30)
    at org.apache.spark.sql.catalyst.ScalaReflection$.getConstructorParameters(ScalaReflection.scala:610)
    at org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$argNames$lzycompute(TreeNode.scala:418)
    at org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$argNames(TreeNode.scala:418)
    at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$argsMap$1.apply(TreeNode.scala:415)
    at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$argsMap$1.apply(TreeNode.scala:414)
    at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
    at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
    at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
    at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toMap(TraversableOnce.scala:279)
    at scala.collection.AbstractIterator.toMap(Iterator.scala:1157)
    at org.apache.spark.sql.catalyst.trees.TreeNode.argsMap(TreeNode.scala:416)
    at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:46)
    at org.apache.spark.sql.execution.SparkPlanInfo$$anonfun$2.apply(SparkPlanInfo.scala:44)
    at org.apache.spark.sql.execution.SparkPlanInfo$$anonfun$2.apply(SparkPlanInfo.scala:44)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.immutable.List.foreach(List.scala:318)
    at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
    at scala.collection.AbstractTraversable.map(Traversable.scala:105)
    at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:44)
    at org.apache.spark.sql.execution.SparkPlanInfo$$anonfun$2.apply(SparkPlanInfo.scala:44)
    at org.apache.spark.sql.execution.SparkPlanInfo$$anonfun$2.apply(SparkPlanInfo.scala:44)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.immutable.List.foreach(List.scala:318)
    at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
    at scala.collection.AbstractTraversable.map(Traversable.scala:105)
    at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:44)
    at org.apache.spark.sql.execution.SparkPlanInfo$$anonfun$2.apply(SparkPlanInfo.scala:44)
    at org.apache.spark.sql.execution.SparkPlanInfo$$anonfun$2.apply(SparkPlanInfo.scala:44)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
    at scala.collection.immutable.List.foreach(List.scala:318)
    at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
    at scala.collection.AbstractTraversable.map(Traversable.scala:105)
    at org.apache.spark.sql.execution.SparkPlanInfo$.fromSparkPlan(SparkPlanInfo.scala:44)
    at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:51)
    at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:56)
    at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:55)
    at org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:193)
    at org.apache.spark.sql.DataFrameWriter.insertInto(DataFrameWriter.scala:166)
    at com.netflix.jobs.main(Processing.scala)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:557)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think this is the same bug as &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-13067&quot; title=&quot;DataFrameSuite.simple explode fail locally&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-13067&quot;&gt;&lt;del&gt;SPARK-13067&lt;/del&gt;&lt;/a&gt;. It looks like that issue wasn&apos;t fixed, there was just a work-around added to get the test passing.&lt;/p&gt;

&lt;p&gt;The problem is that the reflection code is trying to substitute concrete types for type parameters of &lt;tt&gt;MapPartitions&lt;span class=&quot;error&quot;&gt;&amp;#91;T, U&amp;#93;&lt;/span&gt;&lt;/tt&gt;, but the concrete types aren&apos;t known. So Spark ends up calling &lt;tt&gt;substituteTypes&lt;/tt&gt; to substitute &lt;tt&gt;T&lt;/tt&gt; and &lt;tt&gt;U&lt;/tt&gt; with &lt;tt&gt;Nil&lt;/tt&gt; (which gets shown as &lt;tt&gt;List()&lt;/tt&gt;).&lt;/p&gt;

&lt;p&gt;An easy fix that works for me is this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-scala&quot;&gt;    &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there are &lt;span class=&quot;code-keyword&quot;&gt;type&lt;/span&gt; variables to fill in, &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; the substitution (SomeClass[T] -&amp;gt; SomeClass[Int])
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (actualTypeArgs.nonEmpty) {
      params.map { p =&amp;gt;
        p.name.toString -&amp;gt; p.typeSignature.substituteTypes(formalTypeArgs, actualTypeArgs)
      }
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      params.map { p =&amp;gt;
        p.name.toString -&amp;gt; p.typeSignature
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Does this sound like a reasonable solution?&lt;/p&gt;

&lt;p&gt;Edit: I think this affects 2.0.0 because the call to &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/ScalaReflection.scala#L788-L790&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;substituteTypes&lt;/tt&gt; is unchanged&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13003076">SPARK-17424</key>
            <summary>Dataset job fails from unsound substitution in ScalaReflect</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rdblue">Ryan Blue</assignee>
                                    <reporter username="rdblue">Ryan Blue</reporter>
                        <labels>
                    </labels>
                <created>Tue, 6 Sep 2016 23:10:57 +0000</created>
                <updated>Fri, 12 May 2017 12:41:11 +0000</updated>
                            <resolved>Fri, 12 May 2017 12:40:44 +0000</resolved>
                                    <version>1.6.1</version>
                    <version>2.0.0</version>
                                    <fixVersion>2.0.3</fixVersion>
                    <fixVersion>2.1.2</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15484715" author="apachespark" created="Mon, 12 Sep 2016 17:31:06 +0000"  >&lt;p&gt;User &apos;rdblue&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15062&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15062&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15484718" author="rdblue" created="Mon, 12 Sep 2016 17:32:09 +0000"  >&lt;p&gt;I&apos;m adding the above fix in a PR. This fix works for us (the job succeeds) and doesn&apos;t change the behavior of cases where the concrete type arguments are known.&lt;/p&gt;</comment>
                            <comment id="16008052" author="cloud_fan" created="Fri, 12 May 2017 12:40:44 +0000"  >&lt;p&gt;Issue resolved by pull request 15062&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15062&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15062&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="12934943">SPARK-13067</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 27 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i33b5b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>