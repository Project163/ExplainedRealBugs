<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:40:23 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-13955] Spark in yarn mode fails</title>
                <link>https://issues.apache.org/jira/browse/SPARK-13955</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I ran spark-shell in yarn client, but from the logs seems the spark assembly jar is not uploaded to HDFS. This may be known issue in the process of &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-11157&quot; title=&quot;Allow Spark to be built without assemblies&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-11157&quot;&gt;&lt;del&gt;SPARK-11157&lt;/del&gt;&lt;/a&gt;, create this ticket to track this issue. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;16/03/17 17:57:48 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
16/03/17 17:57:48 INFO Client: Setting up container launch context for our AM
16/03/17 17:57:48 INFO Client: Setting up the launch environment for our AM container
16/03/17 17:57:48 INFO Client: Preparing resources for our AM container
16/03/17 17:57:48 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
16/03/17 17:57:48 INFO Client: Uploading resource file:/Users/jzhang/github/spark/lib/apache-rat-0.10.jar -&amp;gt; hdfs://localhost:9000/user/jzhang/.sparkStaging/application_1458187008455_0006/apache-rat-0.10.jar
16/03/17 17:57:49 INFO Client: Uploading resource file:/Users/jzhang/github/spark/lib/apache-rat-0.11.jar -&amp;gt; hdfs://localhost:9000/user/jzhang/.sparkStaging/application_1458187008455_0006/apache-rat-0.11.jar
16/03/17 17:57:49 INFO Client: Uploading resource file:/private/var/folders/dp/hmchg5dd3vbcvds26q91spdw0000gp/T/spark-abed04bf-6ac2-448b-91a9-dcc1c401a18f/__spark_conf__4163776487351314654.zip -&amp;gt; hdfs://localhost:9000/user/jzhang/.sparkStaging/application_1458187008455_0006/__spark_conf__4163776487351314654.zip
16/03/17 17:57:49 INFO SecurityManager: Changing view acls to: jzhang
16/03/17 17:57:49 INFO SecurityManager: Changing modify acls to: jzhang
16/03/17 17:57:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jzhang); users with modify permissions: Set(jzhang)
16/03/17 17:57:49 INFO Client: Submitting application 6 to ResourceManager
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;message in AM container&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Error: Could not find or load main class org.apache.spark.deploy.yarn.ExecutorLauncher
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12951081">SPARK-13955</key>
            <summary>Spark in yarn mode fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vanzin">Marcelo Masiero Vanzin</assignee>
                                    <reporter username="zjffdu">Jeff Zhang</reporter>
                        <labels>
                    </labels>
                <created>Thu, 17 Mar 2016 04:24:49 +0000</created>
                <updated>Sun, 17 May 2020 18:17:02 +0000</updated>
                            <resolved>Wed, 30 Mar 2016 20:59:32 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                    <component>YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15199198" author="srowen" created="Thu, 17 Mar 2016 09:26:11 +0000"  >&lt;p&gt;Is this likely? the YARN tests succeed. There isn&apos;t detail here like what you are running.&lt;/p&gt;</comment>
                            <comment id="15199201" author="zjffdu" created="Thu, 17 Mar 2016 09:27:53 +0000"  >&lt;p&gt;I just run spark-shell in yarn-client mode. &lt;/p&gt;</comment>
                            <comment id="15199927" author="vanzin" created="Thu, 17 Mar 2016 16:59:14 +0000"  >&lt;p&gt;How did you build Spark? Did you do &quot;mvn package&quot; or &quot;sbt assembly&quot;? I see the code is trying to upload &quot;file:/Users/jzhang/github/spark/lib/&quot;, do you have a file called RELEASE on your repo&apos;s root? (That triggers a different code path, since that file is only expected to exist in a Spark distribution, not in a Spark source repo.)&lt;/p&gt;</comment>
                            <comment id="15201840" author="vanzin" created="Fri, 18 Mar 2016 17:40:17 +0000"  >&lt;p&gt;Actually, this was an oversight. I need to change the code to look in the build directory when the &lt;tt&gt;RELEASE&lt;/tt&gt; file is not present.&lt;/p&gt;</comment>
                            <comment id="15202411" author="zjffdu" created="Sat, 19 Mar 2016 00:27:27 +0000"  >&lt;p&gt;I can reproduce it with both sbt and mvn.  The scenario is the same that spark assembly jar is not uploaded to hdfs.  &lt;/p&gt;</comment>
                            <comment id="15203774" author="jerryshao" created="Mon, 21 Mar 2016 06:05:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zjffdu&quot; class=&quot;user-hover&quot; rel=&quot;zjffdu&quot;&gt;zjffdu&lt;/a&gt;, I think way to fix this is to specify assembly jar uses &lt;tt&gt;spark.yarn.jars&lt;/tt&gt;, that will upload assembly jar into HDFS. Actually the behavior now is changed after &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-11157&quot; title=&quot;Allow Spark to be built without assemblies&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-11157&quot;&gt;&lt;del&gt;SPARK-11157&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15212609" author="apachespark" created="Fri, 25 Mar 2016 23:49:05 +0000"  >&lt;p&gt;User &apos;vanzin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11970&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11970&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15300014" author="jameszhouyi" created="Wed, 25 May 2016 13:16:06 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt;&lt;br/&gt;
I build a Spark 2.0 snapshot package which included a &apos;jars&apos; folder in package. so we only configure &apos;spark.yarn.jars&apos; like this spark.yarn.jars=local:/usr/lib/spark/jars/* in spark-defaults.conf , right ?&lt;/p&gt;

&lt;p&gt;Thanks&lt;br/&gt;
Yi&lt;/p&gt;</comment>
                            <comment id="15300071" author="jerryshao" created="Wed, 25 May 2016 13:43:55 +0000"  >&lt;p&gt;You will have 3 options to upload jars to distributed cache:&lt;/p&gt;

&lt;p&gt;1. spark.yarn.archive&lt;/p&gt;

&lt;p&gt;You need to zip all the jars and specify spark.yarn.archive with the path of zipped jars, yarn/client will add this to distributed cache and classpath.&lt;/p&gt;

&lt;p&gt;2. spark.yarn.jars&lt;/p&gt;

&lt;p&gt;Like what you mentioned, specify the jars through this configurations, then yarn/client will add to distributed cache and classpath.&lt;/p&gt;

&lt;p&gt;If neither 1 or 2 is specified, yarn/client will zip all the jars in jars dir and add to classpath, you don&apos;t need to take care anything.&lt;/p&gt;

&lt;p&gt;You could refer the code in yarn/Client.scala L465.&lt;/p&gt;

&lt;p&gt;Should be noted that jars with &quot;local&quot; scheme will not be uploaded into distributed cache.&lt;/p&gt;</comment>
                            <comment id="15301342" author="jameszhouyi" created="Thu, 26 May 2016 02:50:16 +0000"  >&lt;p&gt;Thanks a lot &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="15593453" author="tzachz" created="Fri, 21 Oct 2016 00:17:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=saisai_shao&quot; class=&quot;user-hover&quot; rel=&quot;saisai_shao&quot;&gt;saisai_shao&lt;/a&gt; can you clarify regarding option #1: when you say&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;You need to zip all the jars and specify spark.yarn.archive with the path of zipped jars&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;How exactly should that archive look like? &lt;br/&gt;
We&apos;re upgrading from 1.6.2 and we keep getting the same error mentioned above:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Error: Could not find or load main class org.apache.spark.deploy.yarn.ExecutorLauncher&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We&apos;ve tried using &lt;tt&gt;spark.yarn.archive&lt;/tt&gt; with:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The Spark binary downloaded from the download page (e.g. &lt;a href=&quot;http://d3kbcqa49mib13.cloudfront.net/spark-2.0.0-bin-hadoop2.6.tgz&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://d3kbcqa49mib13.cloudfront.net/spark-2.0.0-bin-hadoop2.6.tgz&lt;/a&gt;)&lt;/li&gt;
	&lt;li&gt;Creating a &lt;tt&gt;.zip&lt;/tt&gt; file with the contents of the &lt;tt&gt;jars/&lt;/tt&gt; folder from the downloaded binary&lt;/li&gt;
	&lt;li&gt;Creating a &lt;tt&gt;.tgz&lt;/tt&gt; file with the contents of the &lt;tt&gt;jars/&lt;/tt&gt; folder from the downloaded binary&lt;/li&gt;
	&lt;li&gt;All of these options while placing file either on HDFS or locally on driver machine&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;None of these resolve the issue. The only option that actually worked for us was the third one you mentioned - setting neither &lt;tt&gt;spark.yarn.jars&lt;/tt&gt; nor &lt;tt&gt;spark.yarn.archive&lt;/tt&gt; and making sure the right jars exist in &lt;tt&gt;SPARK_HOME/jars&lt;/tt&gt; on each node - but since we run several applications with different spark versions and want to simplify our provisioning - this isn&apos;t convenient for us.&lt;/p&gt;

&lt;p&gt;Any clarification would be greatly appreciated, &lt;br/&gt;
Thanks!&lt;/p&gt;</comment>
                            <comment id="15731574" author="kellyzly" created="Thu, 8 Dec 2016 08:50:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt; &amp;amp;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tzachz&quot; class=&quot;user-hover&quot; rel=&quot;tzachz&quot;&gt;tzachz&lt;/a&gt;:&lt;br/&gt;
when i try to use &quot;spark.yarn.jars&quot;, i found following ways work&lt;br/&gt;
append following in your conf/spark-defaults.conf,  you need specified the location of every jar in $SPARK_HOME/jars in spark.yarn.jars like(here i don&apos;t paste all, too long. The seperator between jars is &quot;,&quot;)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  spark.yarn.jars=/home/zly/spark-2.0.0-bin-hadoop2-without-hive/jars/activation-1.1.1.jar,
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The &lt;a href=&quot;http://spark.apache.org/docs/latest/running-on-yarn.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;document&lt;/a&gt; describes &quot;spark.yarn.jars&quot;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;List of libraries containing Spark code to distribute to YARN containers. By &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, Spark on YARN will use Spark jars installed locally, but the Spark jars can also be in a world-readable location on HDFS. This allows YARN to cache it on nodes so that it doesn&apos;t need to be distributed each time an application runs. To point to jars on HDFS, &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; example, set &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; configuration to hdfs:&lt;span class=&quot;code-comment&quot;&gt;///some/path. Globs are allowed.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but when i try to use &quot;spark.yarn.archive&quot; like above, it fails.&lt;/p&gt;</comment>
                            <comment id="15734071" author="jerryshao" created="Fri, 9 Dec 2016 02:34:06 +0000"  >&lt;p&gt;IIRC &lt;tt&gt;spark.yarn.archive&lt;/tt&gt; should be worked, I tried personally in my local machine, also our HDP distribution by default configured it.&lt;/p&gt;

&lt;p&gt;If you want to use &quot;spark.yarn.archive&quot;, you should zip all the Spark run-time required jars, put this archive either locally or on hdfs and configured the path for &quot;spark.yarn.archive&quot;. Then yarn will add it to distributed cache.&lt;/p&gt;

&lt;p&gt;Can you please tell how you configured and the error you met?&lt;/p&gt;</comment>
                            <comment id="15734082" author="kellyzly" created="Fri, 9 Dec 2016 02:40:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt;: following is the detail steps when i use &quot;spark.yarn.archive&quot;&lt;br/&gt;
1. zip all jars:  zip spark-archive.zip $SPARK_HOME/jars/*&lt;br/&gt;
2. upload the zip to hdfs: hadoop fs -copyFromLocal spark-archive.zip hdfs://bdpe42:8020/&lt;br/&gt;
3. modify the spark-defaults.conf&lt;br/&gt;
   spark.yarn.archive=hdfs://bdpe42:8020/spark-archive.zip&lt;br/&gt;
4. run pi in yarn client mode&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;   ./bin/spark-submit --&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.examples.SparkPi --master yarn-client --num-executors 3     --driver-memory 1g     --executor-memory 1g     --executor-cores 1   $spark_example_jar &amp;gt; sparkPi.log 2&amp;gt;&amp;amp;1 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The exception in container log is&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Error: Could not find or load main &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.deploy.yarn.ExecutorLauncher
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The spark version is  2.0.2.&lt;/p&gt;</comment>
                            <comment id="15734184" author="jerryshao" created="Fri, 9 Dec 2016 03:47:13 +0000"  >&lt;p&gt;Do you have spark-yarn_2.11 jar in your archive?&lt;/p&gt;</comment>
                            <comment id="15734195" author="kellyzly" created="Fri, 9 Dec 2016 03:53:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt;: yes , the archive contains spark-yarn_2.11 jar&lt;/p&gt;</comment>
                            <comment id="15734207" author="jerryshao" created="Fri, 9 Dec 2016 04:01:10 +0000"  >&lt;p&gt;Can you please check the runtime environment of launching container, it should lie in NM&apos;s local dir. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;${yarn.nodemanager.local-dirs}/usercache/${user}/appcache/application_${appid}/container_${contid}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When NM brings up container, it will create a container specific folder and put all the dependencies, files,. etc to that folder, also including launching script. You could check whether classpath is correct, or if archive is found there.&lt;/p&gt;</comment>
                            <comment id="15736236" author="kellyzly" created="Fri, 9 Dec 2016 20:14:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt;:&lt;br/&gt;
After testing, i can use &quot;spark.yarn.archive&quot; in following steps:&lt;br/&gt;
 1.cd $SPARK_HOME/jars&lt;br/&gt;
2. zip spark-archive.zip ./*  #enter the directory, then zip&lt;br/&gt;
3. when you test the spark-archive.zip by &quot;unzip -t spark-archive.zip, you will see&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; unzip -t spark-archive.zip 
Archive:  spark-archive.zip
    testing: activation-1.1.1.jar     OK
    testing: antlr4-runtime-4.5.3.jar   OK
    testing: aopalliance-1.0.jar      OK
    testing: aopalliance-repackaged-2.4.0-b34.jar   OK
    testing: apacheds-i18n-2.0.0-M15.jar   OK
    testing: apacheds-kerberos-codec-2.0.0-M15.jar   OK
    testing: api-asn1-api-1.0.0-M20.jar   OK
    testing: api-util-1.0.0-M20.jar   OK
    testing: arpack_combined_all-0.1.jar   OK
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;4. copy spark-archive.zip to hdfs like &quot;hadoop fs -copyFromLocal spark-archive.zip hdfs://bdpe42:8020/&quot;&lt;br/&gt;
5. append &quot;spark.yarn.archive=hdfs://bdpe42:8020/spark-archive.zip&quot; to conf/spark-defaults.conf&lt;/p&gt;</comment>
                            <comment id="15736957" author="jerryshao" created="Sat, 10 Dec 2016 01:41:42 +0000"  >&lt;p&gt;Yes, forgot to mention this zip file doesn&apos;t support nested directory.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 49 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2ut1j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>