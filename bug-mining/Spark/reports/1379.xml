<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:23:23 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4267] Failing to launch jobs on Spark on YARN with Hadoop 2.5.0 or later</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4267</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Currently we&apos;re trying Spark on YARN included in Hadoop 2.5.1. Hadoop 2.5 uses protobuf 2.5.0 so I compiled with protobuf 2.5.1 like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; ./make-distribution.sh --name spark-1.1.1 --tgz -Pyarn -Dhadoop.version=2.5.1 -Dprotobuf.version=2.5.0
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then Spark on YARN fails to launch jobs with NPE.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ bin/spark-shell --master yarn-client
scala&amp;gt;     sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;///user/ozawa/wordcountInput20G&quot;&lt;/span&gt;).flatMap(line =&amp;gt; line.split(&lt;span class=&quot;code-quote&quot;&gt;&quot; &quot;&lt;/span&gt;)).map(word =&amp;gt; (word, 1)).persist().reduceByKey((a, b) =&amp;gt; a + b, 16).saveAsTextFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:///user/ozawa/sparkWordcountOutNew2&quot;&lt;/span&gt;);
&lt;/span&gt;java.lang.NullPointerException                                                                                                                                                                                                                                
        at org.apache.spark.SparkContext.defaultParallelism(SparkContext.scala:1284)
        at org.apache.spark.SparkContext.defaultMinPartitions(SparkContext.scala:1291)                                                                                                                                                                        
        at org.apache.spark.SparkContext.textFile$&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;$2(SparkContext.scala:480)
        at $iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:13)                                                                                                                                                                                                           
        at $iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:18)
        at $iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:20)                                                                                                                                                                                                                     
        at $iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:22)
        at &amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:24)                                                                                                                                                                                                                               
        at .&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:28)
        at .&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)                                                                                                                                                                                                                               
        at .&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:7)
        at .&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)                                                                                                                                                                                                                               
        at $print(&amp;lt;console&amp;gt;)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                                                                                                                                                                                        
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)                                                                                                                                                              
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:789)                                                                                                                                                                          
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1062)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:615)                                                                                                                                                                             
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:646)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:610)                                                                                                                                                                                   
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:823)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:868)                                                                                                                                                                       
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:780)
        at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:625)                                                                                                                                                                               
        at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:633)
        at org.apache.spark.repl.SparkILoop.loop(SparkILoop.scala:638)                                                                                                                                                                                        
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:963)
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:911)                                                                                                                                                                    
        at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:911)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)                                                                                                                                                             
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:911)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1006)                                                                                                                                                                                    
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)                                                                                                                                                                                                        
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)                                                                                                                                                                      
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)                                                                                                                                                                                                   
        at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:329)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)                                                                                                                                                                                    
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12753331">SPARK-4267</key>
            <summary>Failing to launch jobs on Spark on YARN with Hadoop 2.5.0 or later</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="ozawa">Tsuyoshi Ozawa</reporter>
                        <labels>
                    </labels>
                <created>Thu, 6 Nov 2014 08:37:43 +0000</created>
                <updated>Fri, 13 Feb 2015 14:26:22 +0000</updated>
                            <resolved>Mon, 9 Feb 2015 18:34:13 +0000</resolved>
                                                    <fixVersion>1.2.2</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14201959" author="ozawa" created="Fri, 7 Nov 2014 11:45:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sandyr&quot; class=&quot;user-hover&quot; rel=&quot;sandyr&quot;&gt;sandyr&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pwendell&quot; class=&quot;user-hover&quot; rel=&quot;pwendell&quot;&gt;pwendell&lt;/a&gt; do you have any workarounds to deal with this problem?&lt;/p&gt;</comment>
                            <comment id="14202319" author="sandyr" created="Fri, 7 Nov 2014 17:32:56 +0000"  >&lt;p&gt;Strange.  Checked in the code and it seems like this must mean the taskScheduler is null.  Did you see any errors farther up in the shell before this happened?  Does it work in local mode?&lt;/p&gt;</comment>
                            <comment id="14208595" author="sarutak" created="Wed, 12 Nov 2014 20:07:20 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ozawa&quot; class=&quot;user-hover&quot; rel=&quot;ozawa&quot;&gt;ozawa&lt;/a&gt;, On my YARN 2.5.1(JDK 1.7.0_60) cluster, Spark Shell works well.&lt;/p&gt;

&lt;p&gt;I built with following command.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sbt/sbt -Dhadoop.version=2.5.1 -Pyarn  assembly
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And launched Spark Shell with following command.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;bin/spark-shell --master yarn --deploy-mode client --executor-cores 1 --driver-memory 512M --executor-memory 512M --num-executors 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then, I ran job with following script.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;///user/kou/LICENSE.txt&quot;&lt;/span&gt;).flatMap(line =&amp;gt; line.split(&lt;span class=&quot;code-quote&quot;&gt;&quot; &quot;&lt;/span&gt;)).map(word =&amp;gt; (word, 1)).persist().reduceByKey((a, b) =&amp;gt; a + b, 16).saveAsTextFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:///user/kou/LICENSE.txt.count&quot;&lt;/span&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So I think the problem is not caused by the version of Hadoop.&lt;br/&gt;
One possible case is that SparkContext#stop is called between instantiating SparkContext and running job accidentally.&lt;br/&gt;
Did you see any ERROR log on the shell?&lt;/p&gt;</comment>
                            <comment id="14209183" author="mdaniel" created="Thu, 13 Nov 2014 03:24:12 +0000"  >&lt;p&gt;Apologies, I don&apos;t know if we want log verbiage inline or as an attachment.&lt;/p&gt;

&lt;p&gt;I experienced this NPE on an EMR cluster, AMI 3.3.0 which is Amazon Hadoop 2.4.0 against a &lt;tt&gt;make-distribution.sh&lt;/tt&gt; version with &lt;tt&gt;-Pyarn&lt;/tt&gt; and &lt;tt&gt;-Phadoop-2.2&lt;/tt&gt; with &lt;tt&gt;-Dhadoop.version=2.2.0&lt;/tt&gt;. I built it against 2.2 because some of our jobs run on 2.2, and I thought 2.4 would be backwards compatible.&lt;/p&gt;

&lt;p&gt;I will try building as you said, using &lt;tt&gt;sbt assembly&lt;/tt&gt;, but I wanted to reply to your comment that yes, I do see an &lt;tt&gt;ERROR&lt;/tt&gt; line but it isn&apos;t helpful to me, so I hope it&apos;s meaningful to others.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;14/11/13 02:58:23 INFO cluster.YarnClientSchedulerBackend: Application report from ASM:
	 appMasterRpcPort: -1
	 appStartTime: 1415847498993
	 yarnAppState: ACCEPTED

14/11/13 02:58:23 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, PROXY_HOST=10.166.39.198,PROXY_URI_BASE=http://10.166.39.198:9046/proxy/application_1415840940647_0001, /proxy/application_1415840940647_0001
14/11/13 02:58:23 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
14/11/13 02:58:24 INFO cluster.YarnClientSchedulerBackend: Application report from ASM:
	 appMasterRpcPort: 0
	 appStartTime: 1415847498993
	 yarnAppState: RUNNING

14/11/13 02:58:29 ERROR cluster.YarnClientSchedulerBackend: Yarn application already ended: FINISHED
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
14/11/13 02:58:29 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
14/11/13 02:58:29 INFO ui.SparkUI: Stopped Spark web UI at http://ip-10-166-39-198.ec2.internal:4040
14/11/13 02:58:29 INFO scheduler.DAGScheduler: Stopping DAGScheduler
14/11/13 02:58:29 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
14/11/13 02:58:29 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
14/11/13 02:58:29 INFO cluster.YarnClientSchedulerBackend: Stopped
14/11/13 02:58:30 INFO spark.MapOutputTrackerMasterActor: MapOutputTrackerActor stopped!
14/11/13 02:58:30 INFO network.ConnectionManager: Selector thread was interrupted!
14/11/13 02:58:30 INFO network.ConnectionManager: ConnectionManager stopped
14/11/13 02:58:30 INFO storage.MemoryStore: MemoryStore cleared
14/11/13 02:58:30 INFO storage.BlockManager: BlockManager stopped
14/11/13 02:58:30 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
14/11/13 02:58:30 INFO spark.SparkContext: Successfully stopped SparkContext
14/11/13 02:58:30 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
14/11/13 02:58:30 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
14/11/13 02:58:30 INFO Remoting: Remoting shut down
14/11/13 02:58:30 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
14/11/13 02:58:47 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14209231" author="mdaniel" created="Thu, 13 Nov 2014 04:05:53 +0000"  >&lt;p&gt;I rebuilt the assembly using &lt;tt&gt;./sbt/sbt -Dhadoop.version=2.4.0 -Pyarn assembly&lt;/tt&gt; and moved the old jars out of the &lt;tt&gt;lib&lt;/tt&gt; in the unpacked distribution directory and moved the new &lt;tt&gt;assembly/target/scala-2.10/spark-assembly-1.1.0-hadoop2.4.0.jar&lt;/tt&gt; into their place. Running &lt;tt&gt;bin/spark-shell&lt;/tt&gt; yields the same output, and (as one might expect) the same NPE.&lt;/p&gt;

&lt;p&gt;I&apos;ve tried to trim the log output to be contextual without being verbose, so please let me know if there are more details that would help with the diagnosis.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;14/11/13 03:57:13 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, PROXY_HOST=10.166.39.198,PROXY_URI_BASE=http://10.166.39.198:9046/proxy/application_1415840940647_0002, /proxy/application_1415840940647_0002
14/11/13 03:57:13 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
14/11/13 03:57:13 INFO cluster.YarnClientSchedulerBackend: Application report from ASM:
	 appMasterRpcPort: 0
	 appStartTime: 1415851029508
	 yarnAppState: RUNNING

14/11/13 03:57:18 ERROR cluster.YarnClientSchedulerBackend: Yarn application already ended: FINISHED
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/metrics/json,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/static,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors/json,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/executors,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment/json,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/environment,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/rdd,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage/json,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/storage,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool/json,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/pool,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage/json,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/stage,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages/json,null}
14/11/13 03:57:18 INFO handler.ContextHandler: stopped o.e.j.s.ServletContextHandler{/stages,null}
14/11/13 03:57:18 INFO ui.SparkUI: Stopped Spark web UI at http://ip-10-166-39-198.ec2.internal:4040
14/11/13 03:57:18 INFO scheduler.DAGScheduler: Stopping DAGScheduler
14/11/13 03:57:18 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
14/11/13 03:57:18 INFO cluster.YarnClientSchedulerBackend: Asking each executor to shut down
14/11/13 03:57:18 INFO cluster.YarnClientSchedulerBackend: Stopped
14/11/13 03:57:19 INFO spark.MapOutputTrackerMasterActor: MapOutputTrackerActor stopped!
14/11/13 03:57:19 INFO network.ConnectionManager: Selector thread was interrupted!
14/11/13 03:57:19 INFO network.ConnectionManager: ConnectionManager stopped
14/11/13 03:57:19 INFO storage.MemoryStore: MemoryStore cleared
14/11/13 03:57:19 INFO storage.BlockManager: BlockManager stopped
14/11/13 03:57:19 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
14/11/13 03:57:19 INFO spark.SparkContext: Successfully stopped SparkContext
14/11/13 03:57:19 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
14/11/13 03:57:19 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
14/11/13 03:57:19 INFO Remoting: Remoting shut down
14/11/13 03:57:19 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
14/11/13 03:57:37 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
14/11/13 03:57:37 INFO repl.SparkILoop: Created spark context..
Spark context available as sc.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14209239" author="sarutak" created="Thu, 13 Nov 2014 04:17:42 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bugzilla%40mdaniel.scdi.com&quot; class=&quot;user-hover&quot; rel=&quot;bugzilla@mdaniel.scdi.com&quot;&gt;bugzilla@mdaniel.scdi.com&lt;/a&gt;.&lt;br/&gt;
The NPE is caused by SparkContext stopped because Application finished accidentally.&lt;br/&gt;
I don&apos;t know why your application finished before running job for now.&lt;br/&gt;
Can you see some ERROR message on the logs of ApplicationMaster or ResourceManager?&lt;/p&gt;</comment>
                            <comment id="14209325" author="mdaniel" created="Thu, 13 Nov 2014 05:52:16 +0000"  >&lt;p&gt;My searches for &lt;tt&gt;ERROR&lt;/tt&gt; didn&apos;t yield anything, but I found the text at the bottom of this comment in a file &lt;tt&gt;yarn-hadoop-nodemanager-ip-10-171-57-176.ec2.internal.log.2014-11-13-03&lt;/tt&gt; on one of the yarn slaves which sheds light on the situation.&lt;/p&gt;

&lt;p&gt;I reverted &lt;tt&gt;spark-defaults.conf&lt;/tt&gt; to just the bare bones:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;spark.master yarn
spark.driver.memory 1G
spark.executor.memory 5G
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and then the &lt;tt&gt;SparkContext&lt;/tt&gt; was initialized as expected. To be honest, I perhaps should not have uncommented the &lt;tt&gt;# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers=&quot;one two three&quot;&lt;/tt&gt; but I wanted to see what it did. Now I know what it does: bring down yarn containers. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;It&apos;s too bad such a grave &lt;b&gt;error&lt;/b&gt; is reported at &lt;em&gt;warn&lt;/em&gt; level, and I hope in the master branch that NPE has been cleaned up because those exceptions are not helpful at all.&lt;/p&gt;

&lt;p&gt;Nevertheless, I hope this helps the original submitter track down their problem, too.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2014-11-13 03:57:14,085 WARN org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor (ContainersLauncher #3): Exception from container-launch with container ID: container_1415840940647_0002_01_000002 and exit code: 1
org.apache.hadoop.util.Shell$ExitCodeException: Usage: java [-options] class [args...]
           (to execute a class)
   or  java [-options] -jar jarfile [args...]
           (to execute a jar file)
where options include:
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14290742" author="srowen" created="Sat, 24 Jan 2015 18:09:03 +0000"  >&lt;p&gt;The warning is from YARN, I believe, rather than Spark. Yeah maybe should be an error. &lt;/p&gt;

&lt;p&gt;Your info however points to the problem; I&apos;m sure it&apos;s &lt;tt&gt;-Dnumbers=&quot;one two three&quot;&lt;/tt&gt;. &lt;tt&gt;Utils.splitCommandString&lt;/tt&gt; strips quotes as it parses them, so will turn it into &lt;tt&gt;-Dnumbers=one two three&lt;/tt&gt; so the command is becoming &lt;tt&gt;java -Dnumbers=one two three ...&lt;/tt&gt; and this isn&apos;t valid.&lt;/p&gt;

&lt;p&gt;I suggest that &lt;tt&gt;Utils.splitCommandString&lt;/tt&gt; not strip the quotes that it parses, so that the reconstructed command line is exactly like the original. It&apos;s just splitting, not interpreting the command. This also seems less surprising. PR coming to demonstrate.&lt;/p&gt;</comment>
                            <comment id="14290744" author="apachespark" created="Sat, 24 Jan 2015 18:11:00 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4188&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4188&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14310753" author="apachespark" created="Sat, 7 Feb 2015 15:01:38 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4452&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4452&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14319018" author="apachespark" created="Thu, 12 Feb 2015 21:34:51 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4575&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4575&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 40 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i221on:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>