<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:21:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4498] Standalone Master can fail to recognize completed/failed applications</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4498</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We observe the spark standalone master not detecting that a driver application has completed after the driver process has shut down indefinitely, leaving that driver&apos;s resources consumed indefinitely. The master reports applications as Running, but the driver process has long since terminated. The master continually spawns one executor for the application. It boots, times out trying to connect to the driver application, and then dies with the exception below. The master then spawns another executor on a different worker, which does the same thing. The application lives until the master (and workers) are restarted. &lt;/p&gt;

&lt;p&gt;This happens to many jobs at once, all right around the same time, two or three times a day, where they all get suck. Before and after this &quot;blip&quot; applications start, get resources, finish, and are marked as finished properly. The &quot;blip&quot; is mostly conjecture on my part, I have no hard evidence that it exists other than my identification of the pattern in the Running Applications table. See &lt;a href=&quot;http://cl.ly/image/2L383s0e2b3t/Screen%20Shot%202014-11-19%20at%203.43.09%20PM.png&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://cl.ly/image/2L383s0e2b3t/Screen%20Shot%202014-11-19%20at%203.43.09%20PM.png&lt;/a&gt; : the applications started before the blip at 1.9 hours ago still have active drivers. All the applications started 1.9 hours ago do not, and the applications started less than 1.9 hours ago (at the top of the table) do in fact have active drivers.&lt;/p&gt;


&lt;p&gt;Deploy mode:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;PySpark drivers running on one node outside the cluster, scheduled by a cron-like application, not master supervised&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Other factoids:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In most places, we call sc.stop() explicitly before shutting down our driver process&lt;/li&gt;
	&lt;li&gt;Here&apos;s the sum total of spark configuration options we don&apos;t set to the default:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.cores.max&quot;&lt;/span&gt;: 30
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.eventLog.dir&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//nn.shopify.com:8020/&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;/spark/event-logs&quot;&lt;/span&gt;
&lt;/span&gt;    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.eventLog.enabled&quot;&lt;/span&gt;: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.executor.memory&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;7g&quot;&lt;/span&gt;
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.hadoop.fs.defaultFS&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//nn.shopify.com:8020/&quot;&lt;/span&gt;
&lt;/span&gt;    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.io.compression.codec&quot;&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&quot;lzf&quot;&lt;/span&gt;
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.ui.killEnabled&quot;&lt;/span&gt;: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;The exception the executors die with is this:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;14/11/19 19:42:37 INFO CoarseGrainedExecutorBackend: Registered signal handlers &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; [TERM, HUP, INT]
14/11/19 19:42:37 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
14/11/19 19:42:37 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: spark,azkaban
14/11/19 19:42:37 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: spark,azkaban
14/11/19 19:42:37 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users with view permissions: Set(spark, azkaban); users with modify permissions: Set(spark, azkaban)
14/11/19 19:42:37 INFO Slf4jLogger: Slf4jLogger started
14/11/19 19:42:37 INFO Remoting: Starting remoting
14/11/19 19:42:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//driverPropsFetcher@dn13.chi.shopify.com:37682]
&lt;/span&gt;14/11/19 19:42:38 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;driverPropsFetcher&apos;&lt;/span&gt; on port 37682.
14/11/19 19:42:38 WARN Remoting: Tried to associate with unreachable remote address [akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@spark-etl1.chi.shopify.com:58849]. Address is now gated &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 5000 ms, all messages to &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; address will be delivered to dead letters. Reason: Connection refused: spark-etl1.chi.shopify.com/172.16.126.88:58849
&lt;/span&gt;14/11/19 19:43:08 ERROR UserGroupInformation: PriviledgedActionException as:azkaban (auth:SIMPLE) cause:java.util.concurrent.TimeoutException: Futures timed out after [30 seconds]
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.reflect.UndeclaredThrowableException: Unknown exception in doAs
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1421)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:59)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:115)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:163)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend.main(CoarseGrainedExecutorBackend.scala)
Caused by: java.security.PrivilegedActionException: java.util.concurrent.TimeoutException: Futures timed out after [30 seconds]
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)
	... 4 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [30 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:107)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:107)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1.apply$mcV$sp(CoarseGrainedExecutorBackend.scala:127)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:60)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:59)
	... 7 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Cluster history:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;We run spark versions built from apache/spark#master snapshots. We did not observe this behaviour on &lt;tt&gt;7eb9cbc273d758522e787fcb2ef68ef65911475f&lt;/tt&gt; (sorry its so old), but now observe it on &lt;tt&gt;c6e0c2ab1c29c184a9302d23ad75e4ccd8060242&lt;/tt&gt;. We can try new versions to assist debugging.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment>&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Linux dn11.chi.shopify.com 3.2.0-57-generic #87-Ubuntu SMP 3 x86_64 x86_64 x86_64 GNU/Linux&lt;/li&gt;
	&lt;li&gt;Standalone Spark built from apache/spark#c6e0c2ab1c29c184a9302d23ad75e4ccd8060242&lt;/li&gt;
	&lt;li&gt;Python 2.7.3&lt;br/&gt;
java version &quot;1.7.0_71&quot;&lt;br/&gt;
Java(TM) SE Runtime Environment (build 1.7.0_71-b14)&lt;br/&gt;
Java HotSpot(TM) 64-Bit Server VM (build 24.71-b01, mixed mode)&lt;/li&gt;
	&lt;li&gt;1 Spark master, 40 Spark workers with 32 cores a piece and 60-90 GB of memory a piece&lt;/li&gt;
	&lt;li&gt;All client code is PySpark&lt;/li&gt;
&lt;/ul&gt;
</environment>
        <key id="12756532">SPARK-4498</key>
            <summary>Standalone Master can fail to recognize completed/failed applications</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="markhamstra">Mark Hamstra</assignee>
                                    <reporter username="airhorns">Harry Brundage</reporter>
                        <labels>
                    </labels>
                <created>Wed, 19 Nov 2014 20:48:46 +0000</created>
                <updated>Wed, 3 Dec 2014 23:11:47 +0000</updated>
                            <resolved>Wed, 3 Dec 2014 23:08:48 +0000</resolved>
                                    <version>1.1.1</version>
                    <version>1.2.0</version>
                                    <fixVersion>1.1.2</fixVersion>
                    <fixVersion>1.2.0</fixVersion>
                                    <component>Deploy</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="14218478" author="airhorns" created="Wed, 19 Nov 2014 20:49:27 +0000"  >&lt;p&gt;These are the logs from the standalone master for one of the applications started when a recent blip happened&lt;/p&gt;</comment>
                            <comment id="14218479" author="airhorns" created="Wed, 19 Nov 2014 20:49:52 +0000"  >&lt;p&gt;These are all the master logs around a recent blip&lt;/p&gt;</comment>
                            <comment id="14218491" author="airhorns" created="Wed, 19 Nov 2014 20:56:49 +0000"  >&lt;p&gt;For the simple canary spark application (who&apos;s master logs are attached), the first executor does exactly what it is supposed to, and then the driver shuts down and it disassociates. Then, a second executor is started, when it never should have been. The first executors stderr:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;14/11/19 18:48:16 INFO CoarseGrainedExecutorBackend: Registered signal handlers &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; [TERM, HUP, INT]
14/11/19 18:48:16 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
14/11/19 18:48:16 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: spark,azkaban
14/11/19 18:48:16 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: spark,azkaban
14/11/19 18:48:16 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users with view permissions: Set(spark, azkaban); users with modify permissions: Set(spark, azkaban)
14/11/19 18:48:17 INFO Slf4jLogger: Slf4jLogger started
14/11/19 18:48:17 INFO Remoting: Starting remoting
14/11/19 18:48:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//driverPropsFetcher@dn42.chi.shopify.com:36365]
&lt;/span&gt;14/11/19 18:48:17 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;driverPropsFetcher&apos;&lt;/span&gt; on port 36365.
14/11/19 18:48:18 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: spark,azkaban
14/11/19 18:48:18 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: spark,azkaban
14/11/19 18:48:18 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users with view permissions: Set(spark, azkaban); users with modify permissions: Set(spark, azkaban)
14/11/19 18:48:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
14/11/19 18:48:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
14/11/19 18:48:18 INFO Slf4jLogger: Slf4jLogger started
14/11/19 18:48:18 INFO Remoting: Starting remoting
14/11/19 18:48:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkExecutor@dn42.chi.shopify.com:39974]
&lt;/span&gt;14/11/19 18:48:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
14/11/19 18:48:18 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;sparkExecutor&apos;&lt;/span&gt; on port 39974.
14/11/19 18:48:18 INFO CoarseGrainedExecutorBackend: Connecting to driver: akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@spark-etl1.chi.shopify.com:58849/user/CoarseGrainedScheduler
&lt;/span&gt;14/11/19 18:48:18 INFO WorkerWatcher: Connecting to worker akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkWorker@dn42.chi.shopify.com:41095/user/Worker
&lt;/span&gt;14/11/19 18:48:18 INFO WorkerWatcher: Successfully connected to akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkWorker@dn42.chi.shopify.com:41095/user/Worker
&lt;/span&gt;14/11/19 18:48:18 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
14/11/19 18:48:18 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: spark,azkaban
14/11/19 18:48:18 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: spark,azkaban
14/11/19 18:48:18 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users with view permissions: Set(spark, azkaban); users with modify permissions: Set(spark, azkaban)
14/11/19 18:48:18 INFO AkkaUtils: Connecting to MapOutputTracker: akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@spark-etl1.chi.shopify.com:58849/user/MapOutputTracker
&lt;/span&gt;14/11/19 18:48:18 INFO AkkaUtils: Connecting to BlockManagerMaster: akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@spark-etl1.chi.shopify.com:58849/user/BlockManagerMaster
&lt;/span&gt;14/11/19 18:48:18 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20141119184818-e5ae
14/11/19 18:48:18 INFO MemoryStore: MemoryStore started with capacity 265.4 MB
14/11/19 18:48:18 INFO LogReporter: Creating metrics output file: /tmp/spark-metrics
14/11/19 18:48:18 INFO NettyBlockTransferService: Server created on 44406
14/11/19 18:48:18 INFO BlockManagerMaster: Trying to register BlockManager
14/11/19 18:48:18 INFO BlockManagerMaster: Registered BlockManager
14/11/19 18:48:18 INFO AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@spark-etl1.chi.shopify.com:58849/user/HeartbeatReceiver
&lt;/span&gt;14/11/19 18:48:18 INFO CoarseGrainedExecutorBackend: Got assigned task 0
14/11/19 18:48:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
14/11/19 18:48:18 INFO Executor: Fetching hdfs:&lt;span class=&quot;code-comment&quot;&gt;//nn01.chi.shopify.com:8020/tmp/starscream_pyfiles_cache/packages-68badf293ff9e4d13929073572892d7f3d0a3546.egg with timestamp 1416422896241
&lt;/span&gt;14/11/19 18:48:19 INFO TorrentBroadcast: Started reading broadcast variable 1
14/11/19 18:48:19 INFO MemoryStore: ensureFreeSpace(3391) called with curMem=0, maxMem=278302556
14/11/19 18:48:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 265.4 MB)
14/11/19 18:48:19 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
14/11/19 18:48:19 INFO BlockManager: Got told to re-register updating block broadcast_1_piece0
14/11/19 18:48:19 INFO BlockManager: BlockManager re-registering with master
14/11/19 18:48:19 INFO BlockManagerMaster: Trying to register BlockManager
14/11/19 18:48:19 INFO TorrentBroadcast: Reading broadcast variable 1 took 218 ms
14/11/19 18:48:19 INFO BlockManagerMaster: Registered BlockManager
14/11/19 18:48:19 INFO BlockManager: Reporting 1 blocks to the master.
14/11/19 18:48:19 INFO BlockManagerMaster: Updated info of block broadcast_1_piece0
14/11/19 18:48:20 INFO MemoryStore: ensureFreeSpace(5288) called with curMem=3391, maxMem=278302556
14/11/19 18:48:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.2 KB, free 265.4 MB)
14/11/19 18:48:20 INFO HadoopRDD: Input split: hdfs:&lt;span class=&quot;code-comment&quot;&gt;//nn01.chi.shopify.com:8020/data/&lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt;/canary/part-00000:0+6
&lt;/span&gt;14/11/19 18:48:20 INFO TorrentBroadcast: Started reading broadcast variable 0
14/11/19 18:48:20 INFO MemoryStore: ensureFreeSpace(10705) called with curMem=8679, maxMem=278302556
14/11/19 18:48:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 10.5 KB, free 265.4 MB)
14/11/19 18:48:20 INFO BlockManagerMaster: Updated info of block broadcast_0_piece0
14/11/19 18:48:20 INFO TorrentBroadcast: Reading broadcast variable 0 took 17 ms
14/11/19 18:48:20 WARN Configuration: fs.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.name is deprecated. Instead, use fs.defaultFS
14/11/19 18:48:20 INFO MemoryStore: ensureFreeSpace(186596) called with curMem=19384, maxMem=278302556
14/11/19 18:48:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 182.2 KB, free 265.2 MB)
14/11/19 18:48:20 INFO PythonRDD: Times: total = 531, boot = 229, init = 302, finish = 0
14/11/19 18:48:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1847 bytes result sent to driver
14/11/19 18:48:22 ERROR CoarseGrainedExecutorBackend: Driver Disassociated [akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkExecutor@dn42.chi.shopify.com:39974] -&amp;gt; [akka.tcp://sparkDriver@spark-etl1.chi.shopify.com:58849] disassociated! Shutting down.&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and the second executor&apos;s stderr:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;14/11/19 18:48:24 INFO CoarseGrainedExecutorBackend: Registered signal handlers &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; [TERM, HUP, INT]
14/11/19 18:48:24 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
14/11/19 18:48:24 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: spark,azkaban
14/11/19 18:48:24 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: spark,azkaban
14/11/19 18:48:24 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users with view permissions: Set(spark, azkaban); users with modify permissions: Set(spark, azkaban)
14/11/19 18:48:25 INFO Slf4jLogger: Slf4jLogger started
14/11/19 18:48:25 INFO Remoting: Starting remoting
14/11/19 18:48:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//driverPropsFetcher@dn42.chi.shopify.com:56495]
&lt;/span&gt;14/11/19 18:48:25 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;driverPropsFetcher&apos;&lt;/span&gt; on port 56495.
14/11/19 18:48:25 WARN Remoting: Tried to associate with unreachable remote address [akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@spark-etl1.chi.shopify.com:58849]. Address is now gated &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 5000 ms, all messages to &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; address will be delivered to dead letters. Reason: Connection refused: spark-etl1.chi.shopify.com/172.16.126.88:58849
&lt;/span&gt;14/11/19 18:48:55 ERROR UserGroupInformation: PriviledgedActionException as:azkaban (auth:SIMPLE) cause:java.util.concurrent.TimeoutException: Futures timed out after [30 seconds]
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.reflect.UndeclaredThrowableException: Unknown exception in doAs
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1421)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:59)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:115)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:163)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend.main(CoarseGrainedExecutorBackend.scala)
Caused by: java.security.PrivilegedActionException: java.util.concurrent.TimeoutException: Futures timed out after [30 seconds]
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408)
	... 4 more
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [30 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at scala.concurrent.Await$$anonfun$result$1.apply(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:107)
	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
	at scala.concurrent.Await$.result(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:107)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1.apply$mcV$sp(CoarseGrainedExecutorBackend.scala:127)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:60)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:59)
	... 7 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14228937" author="joshrosen" created="Sat, 29 Nov 2014 20:55:07 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=airhorns&quot; class=&quot;user-hover&quot; rel=&quot;airhorns&quot;&gt;airhorns&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I finally got a chance to look into this and, based on reading the code, I have a theory about what might be happening.  If you look at the &lt;a href=&quot;https://github.com/apache/spark/blob/317e114e11669899618c7c06bbc0091b36618f36/core/src/main/scala/org/apache/spark/deploy/master/Master.scala#L668&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;current Master.scala file&lt;/a&gt;, you&apos;ll notice that there are only two situations where the standalone Master removes applications:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The master receives a DisassociatedEvent due to the application actor shutting down and calls &lt;tt&gt;finishApplication&lt;/tt&gt;.&lt;/li&gt;
	&lt;li&gt;An executor exited with a non-zero exit status and the maximum number of executor failures has been succeeded.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Now, imagine that for some reason the standalone Master does not receive a DisassociatedEvent.  When executors eventually start to die, the standalone master will discover this via ExecutorStateChanged.  If it hasn&apos;t hit the maximum number of executor failures, &lt;a href=&quot;https://github.com/apache/spark/blob/317e114e11669899618c7c06bbc0091b36618f36/core/src/main/scala/org/apache/spark/deploy/master/Master.scala#L325&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;it will attempt to re-schedule the application&lt;/a&gt; and obtain new resources.  If a new executor is granted, this will &lt;a href=&quot;https://github.com/apache/spark/blob/317e114e11669899618c7c06bbc0091b36618f36/core/src/main/scala/org/apache/spark/deploy/master/Master.scala#L313&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;cause the &quot;maximum failed executors count&quot; to reset to zero&lt;/a&gt;, leading to a sort of livelock behavior where executors die because they can&apos;t contact the application but keep being launched because executors keep entering the ExecutorState.RUNNING state (&lt;a href=&quot;https://github.com/apache/spark/blob/317e114e11669899618c7c06bbc0091b36618f36/core/src/main/scala/org/apache/spark/deploy/worker/ExecutorRunner.scala#L148&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;it looks like&lt;/a&gt; executors transition to this state when they launch, not once they&apos;ve registered with the driver).&lt;/p&gt;

&lt;p&gt;It looks like the line&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (state == ExecutorState.RUNNING) { appInfo.resetRetryCount() }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;was introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt;.  It looks like this was introduced after the earliest commit that you mentioned, so it seems like this is be a regression in 1.2.0.  I don&apos;t think that we should revert &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt;, since that fixes another fairly important bug.  Instead, I&apos;d like to try to figure out how an application could fail without a DisassociatedEvent causing it to be removed.&lt;/p&gt;

&lt;p&gt;Could this be due to our use of non-standard Akka timeout / failure detector settings?  I would think that we&apos;d still get a DisassociatedEvent when a network connection was closed or something.  Maybe we could switch to relying on our own explicit heartbeats for failure detection, like we do elsewhere in Spark.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markhamstra&quot; class=&quot;user-hover&quot; rel=&quot;markhamstra&quot;&gt;markhamstra&lt;/a&gt;, do you have any ideas here?&lt;/p&gt;</comment>
                            <comment id="14228943" author="joshrosen" created="Sat, 29 Nov 2014 21:03:44 +0000"  >&lt;p&gt;Adding 1.1.1 as an affected version, too, since &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt; was backported to that release, too.&lt;/p&gt;</comment>
                            <comment id="14228947" author="markhamstra" created="Sat, 29 Nov 2014 21:33:55 +0000"  >&lt;p&gt;On a quick look-through, your analysis looks likely to be correct, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Making sure that failed applications are always accompanied by a DisassociatedEvent would be a good thing.  The belt-and-suspenders fix would be to also change the executor state-change semantics so that either RUNNING means not just that the executor process is running, but also that it has successfully connected to the application, or else introduce an additional executor state (perhaps REGISTERED) along with state transitions and finer-grained state logic controlling executor restart and application removal.&lt;/p&gt;</comment>
                            <comment id="14228952" author="joshrosen" created="Sat, 29 Nov 2014 22:13:56 +0000"  >&lt;p&gt;In addition to exploring the &quot;missing DisassociatedEvent&quot; theory, it might also be worthwhile to brainstorm whether problems at other steps in the cleanup process could cause an application to fail to be removed.  I&apos;m not sure that a single missing DisassociatedEvent could explain the &quot;blip&quot; behavior observed here, where an entire group of applications fail to be marked as completed / failed.&lt;/p&gt;

&lt;p&gt;In the DisassociatedEvent handler, we index into &lt;tt&gt;addressToApp&lt;/tt&gt; to determine which app corresponded to the DisassociatedEvent:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; DisassociatedEvent(_, address, _) =&amp;gt; {
      &lt;span class=&quot;code-comment&quot;&gt;// The disconnected client could&apos;ve been either a worker or an app; remove whichever it was
&lt;/span&gt;      logInfo(s&lt;span class=&quot;code-quote&quot;&gt;&quot;$address got disassociated, removing it.&quot;&lt;/span&gt;)
      addressToWorker.get(address).foreach(removeWorker)
      addressToApp.get(address).foreach(finishApplication)
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (state == RecoveryState.RECOVERING &amp;amp;&amp;amp; canCompleteRecovery) { completeRecovery() }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If the &lt;tt&gt;addressToApp&lt;/tt&gt; entry was empty / wrong, then we wouldn&apos;t properly clean up the app.  However, I don&apos;t think that there should be any problems here because each application actor system should have its own distinct address and Akka&apos;s &lt;tt&gt;Address&lt;/tt&gt; class properly implements hashCode / equals.  Even if drivers run on the same host, their actor systems should have different port numbers.&lt;/p&gt;

&lt;p&gt;Continuing along:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  def removeApplication(app: ApplicationInfo, state: ApplicationState.Value) {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (apps.contains(app)) {
      logInfo(&lt;span class=&quot;code-quote&quot;&gt;&quot;Removing app &quot;&lt;/span&gt; + app.id)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Is there any way that the &lt;tt&gt;apps&lt;/tt&gt; HashSet could fail to contain &lt;tt&gt;app&lt;/tt&gt;?  I don&apos;t think so: &lt;tt&gt;ApplicationInfo&lt;/tt&gt; doesn&apos;t override equals/hashCode, but I don&apos;t think that&apos;s a problem since we only create one ApplicationInfo per app, so the default object identity comparison should be fine.  We should probably log an error if we call &lt;tt&gt;removeApplication&lt;/tt&gt; on an application that has already been removed, though.  (Also, why do we need the &lt;tt&gt;apps&lt;/tt&gt; HashSet when we could just use &lt;tt&gt;idToApp.values&lt;/tt&gt;?)&lt;/p&gt;</comment>
                            <comment id="14228966" author="joshrosen" created="Sat, 29 Nov 2014 22:50:44 +0000"  >&lt;p&gt;Here&apos;s an interesting pattern to grep for in all-master-logs-around-blip.txt: &lt;tt&gt;sparkDriver@spark-etl1.chi.shopify.com:52047&lt;/tt&gt;.  Note that this log is in reverse-chronological order.&lt;/p&gt;

&lt;p&gt;The earliest occurrence is in a DisassociatedEvent log message:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;14-11-19_18:48:31.34508 14/11/19 18:48:31 ERROR EndpointWriter: AssociationError [akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkMaster@dn05.chi.shopify.com:7077] &amp;lt;- [akka.tcp://sparkDriver@spark-etl1.chi.shopify.com:52047]: Error [Shut down address: akka.tcp://sparkDriver@spark-etl1.chi.shopify.com:52047] [
&lt;/span&gt;2014-11-19_18:48:31.34510 akka.remote.ShutDownAssociation: Shut down address: akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@spark-etl1.chi.shopify.com:52047
&lt;/span&gt;2014-11-19_18:48:31.34511 Caused by: akka.remote.transport.Transport$InvalidAssociationException: The remote system terminated the association because it is shutting down.
2014-11-19_18:48:31.34512 ]
2014-11-19_18:48:31.34521 14/11/19 18:48:31 INFO LocalActorRef: Message [akka.remote.transport.AssociationHandle$Disassociated] from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.16.126.88%3A48040-1355#-59270061] was not delivered. [2859] dead letters encountered. This logging can be turned off or adjusted with configuration settings &lt;span class=&quot;code-quote&quot;&gt;&apos;akka.log-dead-letters&apos;&lt;/span&gt; and &lt;span class=&quot;code-quote&quot;&gt;&apos;akka.log-dead-letters-during-shutdown&apos;&lt;/span&gt;.
&lt;/span&gt;2014-11-19_18:48:31.34603 14/11/19 18:48:31 INFO Master: akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@spark-etl1.chi.shopify.com:52047 got disassociated, removing it.
&lt;/span&gt;2014-11-19_18:48:31.20255 14/11/19 18:48:31 INFO Master: Removing executor app-20141119184815-1316/7 because it is EXITED
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Even though INFO-level logging is enabled, there&apos;s no &quot;INFO: master: Removing app ....&quot; message near this event.  The entire log contains many repetitions of this same DisassociatedEvent log.&lt;/p&gt;

&lt;p&gt;The same log also contains many executors that launch and immediately fail:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2014-11-19_18:52:51.84000 14/11/19 18:52:51 INFO Master: Launching executor app-20141119184815-1313/75 on worker worker-20141118172622-dn19.chi.shopify.com-38498
2014-11-19_18:52:51.83981 14/11/19 18:52:51 INFO Master: Removing executor app-20141119184815-1313/67 because it is EXITED
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I couldn&apos;t find a &lt;tt&gt;removing app app-20141119184815-1313&lt;/tt&gt; event.&lt;/p&gt;

&lt;p&gt;Another interesting thing: even though it looks like this log contains information for 39 drivers, there are 100 disassociated events:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[joshrosen ~]$ cat /Users/joshrosen/Desktop/all-master-logs-around-blip.txt | grep -e &lt;span class=&quot;code-quote&quot;&gt;&quot;\d\d\d\d\d got disassociated&quot;&lt;/span&gt; -o | cut -d &lt;span class=&quot;code-quote&quot;&gt;&apos; &apos;&lt;/span&gt; -f 1 | sort | uniq | wc -l
      39

[joshrosen ~]$ cat /Users/joshrosen/Desktop/all-master-logs-around-blip.txt | grep -e &lt;span class=&quot;code-quote&quot;&gt;&quot;\d\d\d\d\d got disassociated&quot;&lt;/span&gt; -o | cut -d &lt;span class=&quot;code-quote&quot;&gt;&apos; &apos;&lt;/span&gt; -f 1 | sort | wc -l
     100
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14230807" author="joshrosen" created="Tue, 2 Dec 2014 01:31:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrewor14&quot; class=&quot;user-hover&quot; rel=&quot;andrewor14&quot;&gt;andrewor14&lt;/a&gt; and I just had a long discussion about this.  To recap things, I think that there are two distinct bugs:&lt;/p&gt;

&lt;p&gt;1. Driver disconnection is not properly detected by the Master.&lt;br/&gt;
2. The application failure detection logic &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt; is broken.&lt;/p&gt;

&lt;p&gt;The second bug can mask the first one.  If something is wrong with the logic for detecting a disconnected application / driver, then the application still might eventually be removed if the &quot;fail an application when its executors fail&quot; logic worked correctly, since every executor assigned to the exited driver will fail.&lt;/p&gt;

&lt;p&gt;To simulate bugs in the driver disconnected logic, we can simply comment out the relevant line in the Master&apos;s &lt;tt&gt;DisassociatedEvent&lt;/tt&gt; handler.  After doing this, I was able to reproduce behavior similar to the issue reported in this ticket.  With a local standalone cluster with one master, one worker, and two executor slots, I was able to start &lt;tt&gt;spark-shell&lt;/tt&gt;, kill it with &lt;tt&gt;kill -9&lt;/tt&gt;, then browse to the Master web UI and see that executors were continually launching and failing even though the driver had exited (this continued for 30+ minutes; it&apos;s still happening).&lt;/p&gt;

&lt;p&gt;I think that the logic for &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt; is completely broken in the sense that there are some cluster configurations for which it will &lt;em&gt;never&lt;/em&gt; kill an application even though every executor that it launches fails, and that there are very few scenarios where it will ever fail an application.  To help explain this, I&apos;ve created a commit that factors out the failure detection logic into its own class: &lt;a href=&quot;https://github.com/JoshRosen/spark/commit/87d7960d660b218a9a965fd7d344e2aae0250128&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/JoshRosen/spark/commit/87d7960d660b218a9a965fd7d344e2aae0250128&lt;/a&gt;.  That commit also includes unit tests of the failure detection logic in isolation, which helps to illustrate the current bugs.&lt;/p&gt;

&lt;p&gt;If you look at the current (broken) failure detection logic, two conditions must be met for an application to be marked as failed:&lt;/p&gt;

&lt;p&gt;1. No executor can be running: &lt;tt&gt;!execs.exists(_.state == ExecutorState.RUNNING)&lt;/tt&gt;&lt;br/&gt;
2. More than &lt;tt&gt;MAX_NUM_RETRY&lt;/tt&gt; consecutive executor failure events must have been received: &lt;tt&gt;!appInfo.incrementRetryCount() &amp;lt; ApplicationState.MAX_NUM_RETRY&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;With the current logic, though, these conditions can almost never be met.  The current (hardcoded) value of &lt;tt&gt;MAX_NUM_RETRY&lt;/tt&gt; is 10.  Imagine that I have a cluster that only has room for 2 concurrent executors and imagine that all executors fail immediately after launching.  In order for the retry count to be incremented past the threshold, we must have at least 10 executor failures.  In order for this to happen, though, executor launches must occur in between some of those failures, since we can only have 2 executors running at the same time.  When an executor fails and a new one is relaunched, the new executor enters the RUNNING state and sends a message back to the Master, which causes the master to reset the retry count back to 0.  Therefore, it&apos;s impossible for the failure detector to report failure in a cluster with fewer than 10 executor slots, even if every executor crashes.&lt;/p&gt;

&lt;p&gt;Even for larger clusters, it&apos;s still nearly impossible for the current logic to declare failure.  Because of the &quot;no executor can be running&quot; condition, all executors must be dead in order for it to declare failure.  The Master immediately calls &lt;tt&gt;schedule()&lt;/tt&gt; after an executor failure, though, so in most cases a new executor will launch before we can see 10 consecutive failures (the test suite in my commit includes a contrived execution where it does declare failure, though).&lt;/p&gt;

&lt;p&gt;So, what do we do, considering that we need to fix this before 1.2.0 and as a bugfix to be included in 1.1.2?  I don&apos;t think that we should just revert &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt;, since it&apos;s not okay to introduce one regression to fix another.  A correct application failure detector needs to strike this balance between protecting long-running applications from failures and quickly detecting buggy applications that will never work.  Long running applications imply that we can&apos;t have counters / state that monotonically progresses towards failure, since we can assume that over an infinite execution there will be an infinite number of executor failures.  Intuitively, I think we want something that&apos;s window-based: if a large fraction of &quot;recently&quot; launched executors have failed, then declare that the application has failed.&lt;/p&gt;

&lt;p&gt;Unfortunately, the master does not receive any signals about non-faulty executors (until they exit cleanly).  One solution would be to add a driver -&amp;gt; master RPC that acknowledges that launched executors are in a good state (e.g. after a task has been sent to that executor).  This would allow us to properly implement a &quot;fail the application if the last &lt;em&gt;n&lt;/em&gt; launched executors failed&quot; condition.  However, this is still prone to false-positives if a single large, buggy host crashes every executor launched on it.  Therefore, we might want to also incorporate some notion of worker-blacklisting in to the master.  This would still have to be application-specific, since executors could exit uncleanly due to application bugs, so we don&apos;t want one buggy application to impact other applications&apos; blacklists.&lt;/p&gt;

&lt;p&gt;This proposal is getting fairly complex, though, so I&apos;d like to see if we can come up with a narrower fix to replace the current logic.&lt;/p&gt;

&lt;p&gt;Separately, I think that we should implement an explicit Driver -&amp;gt; Master heartbeat as an extra layer of defense against driver disconnection detection errors, as well as adding lots of additional debug logging in those code paths.&lt;/p&gt;</comment>
                            <comment id="14230895" author="pwendell" created="Tue, 2 Dec 2014 03:03:06 +0000"  >&lt;p&gt;Hey Josh,&lt;/p&gt;

&lt;p&gt;The proposal you gave here seems to be complex. Why not just revert &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt;? It&apos;s only a &quot;regression&quot; from something that was released in the last few days and which we may need to revert anyways for a quick Spark 1.1.2 release due to its severity. It seems like it might be worth it to just revert &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt; and put out a quick 1.1.2 release without the feature, then revert it in the 1.2 branch also.&lt;/p&gt;</comment>
                            <comment id="14230910" author="markhamstra" created="Tue, 2 Dec 2014 03:15:56 +0000"  >&lt;p&gt;I&apos;d argue against reverting 2425 on the grounds that a long-running application being killed when it is still able to make progress is a worse bug than Executors repeatedly trying to run an application that no longer exists.&lt;/p&gt;

&lt;p&gt;Either way, it seems to me that the existing logic may not be too far from being right.  The flaw simply seems to be that an Executor process starting and successfully connecting to stderr and stdout are necessary but not sufficient conditions for that Executor to be transitioned to RUNNING.  If the Executor doesn&apos;t become RUNNING until it succeeds in connecting to its Application, then I think the problem is almost entirely and perhaps completely solved.  (Although I think &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2424&quot; title=&quot;ApplicationState.MAX_NUM_RETRY should be configurable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2424&quot;&gt;&lt;del&gt;SPARK-2424&lt;/del&gt;&lt;/a&gt; should also be implemented.) &lt;/p&gt;</comment>
                            <comment id="14230926" author="andrewor14" created="Tue, 2 Dec 2014 03:44:06 +0000"  >&lt;p&gt;Ok, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt; and I talked about this more offline.&lt;/p&gt;

&lt;p&gt;In summary, there are two problems:&lt;br/&gt;
(1) If enough executors fail over time, the application dies unconditionally. This is fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
(2) If the application exited and the Master doesn&apos;t know that, then the Master might keep on launching executors for that application indefinitely. This is caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The goal of this issue is to fix both. This means we can&apos;t just revert &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt; because that does not address (1) (and this patch was released in 1.1.1 so it will be a regression if we reverted it). We came up with the following solution that addresses both problems:&lt;/p&gt;

&lt;p&gt;Driver periodically sends a heartbeat to Master to indicate whether it is healthy and ready to schedule tasks (i.e. whether at least one executor has registered). Meanwhile, as in the existing code, the Master keeps a counter of how many executors have failed. This counter is reset whenever the Master receives a &quot;healthy&quot; message from the driver. When the counter reaches a configurable threshold, meaning the driver has not reported &quot;healthy&quot; in a while, then the Master fails the application. Additionally, when the Master hasn&apos;t received a heartbeat from the driver after some time, it fails the application.&lt;/p&gt;

&lt;p&gt;In a nutshell, this prevents the following from happening:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BEFORE &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt;, we never reset the counter&lt;/li&gt;
	&lt;li&gt;AFTER &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2425&quot; title=&quot;Standalone Master is too aggressive in removing Applications&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2425&quot;&gt;&lt;del&gt;SPARK-2425&lt;/del&gt;&lt;/a&gt;, we always reset the counter&lt;/li&gt;
	&lt;li&gt;Instead, we reset it periodically whenever we get a heartbeat from the driver&lt;/li&gt;
	&lt;li&gt;The heartbeat also provides a mechanism for the Master to detect whether an application has exited in addition to relying on the akka DisassociatedEvent&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14230928" author="andrewor14" created="Tue, 2 Dec 2014 03:45:31 +0000"  >&lt;p&gt;Yes &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markhamstra&quot; class=&quot;user-hover&quot; rel=&quot;markhamstra&quot;&gt;markhamstra&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2424&quot; title=&quot;ApplicationState.MAX_NUM_RETRY should be configurable&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2424&quot;&gt;&lt;del&gt;SPARK-2424&lt;/del&gt;&lt;/a&gt; will actually be included in this proposal.&lt;/p&gt;</comment>
                            <comment id="14230938" author="pwendell" created="Tue, 2 Dec 2014 04:04:31 +0000"  >&lt;p&gt;Going back to the original comment by Josh. Just wondering - what is the basis you have for assuming that driver disassociation is not working in master? Is there a known reason for this or is it just speculation based on observed logs.&lt;/p&gt;</comment>
                            <comment id="14230948" author="joshrosen" created="Tue, 2 Dec 2014 04:14:32 +0000"  >&lt;blockquote&gt;
&lt;p&gt;What is the basis you have for assuming that driver disassociation is not working in master? Is there a known reason for this or is it just speculation based on observed logs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I suppose it&apos;s just speculation, but I think it&apos;s a good idea to include a defensive / preemptive fix for this.  We don&apos;t know for sure whether driver disassociation was broken / buggy in earlier releases, since the application would still eventually get killed when running with the old failure detection code; it&apos;s possible that the executor failure handling bug might have uncovered a long-standing bug that was masked by correct failure handling code.&lt;/p&gt;

&lt;p&gt;Based on chatting with Andrew, I think that we can ship a pretty small patch that adds a heartbeat mechanism and solves both issues.  I&apos;m working on a prototype now and hope to have a really rough version out soon for an initial round of reviews.&lt;/p&gt;</comment>
                            <comment id="14230987" author="apachespark" created="Tue, 2 Dec 2014 05:00:52 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3548&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3548&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14230989" author="joshrosen" created="Tue, 2 Dec 2014 05:02:27 +0000"  >&lt;p&gt;I&apos;ve submitted a really rough-draft WIP PR for the heartbeat mechanism that we&apos;ve discussed.  I&apos;ll be back later tonight to address any comments and finish writing tests.  If you have any spare review time, please take a look.&lt;/p&gt;</comment>
                            <comment id="14231119" author="apachespark" created="Tue, 2 Dec 2014 07:42:08 +0000"  >&lt;p&gt;User &apos;markhamstra&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3550&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3550&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14233645" author="joshrosen" created="Wed, 3 Dec 2014 23:08:48 +0000"  >&lt;p&gt;Issue resolved by pull request 3550&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3550&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3550&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12682484" name="all-master-logs-around-blip.txt" size="6212223" author="airhorns" created="Wed, 19 Nov 2014 20:49:52 +0000"/>
                            <attachment id="12682483" name="one-applications-master-logs.txt" size="77679" author="airhorns" created="Wed, 19 Nov 2014 20:49:27 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 50 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i22kun:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12328982">1.1.2</customfieldvalue>
    <customfieldvalue id="12327369">1.2.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>