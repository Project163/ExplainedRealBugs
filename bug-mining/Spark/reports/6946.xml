<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:09:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-30553] Fix structured-streaming java example error</title>
                <link>https://issues.apache.org/jira/browse/SPARK-30553</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#handling-late-data-and-watermarking&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#handling-late-data-and-watermarking&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I write code according to this by java and scala.&lt;/p&gt;

&lt;p&gt;java&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; StreamingQueryException {
        SparkSession spark = SparkSession.builder().appName(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;).master(&lt;span class=&quot;code-quote&quot;&gt;&quot;local[*]&quot;&lt;/span&gt;)
                .config(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.sql.shuffle.partitions&quot;&lt;/span&gt;, 1)
                .getOrCreate();        Dataset&amp;lt;Row&amp;gt; lines = spark.readStream().format(&lt;span class=&quot;code-quote&quot;&gt;&quot;socket&quot;&lt;/span&gt;)
                .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;host&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;skynet&quot;&lt;/span&gt;)
                .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;includeTimestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
                .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;port&quot;&lt;/span&gt;, 8888).load();
        Dataset&amp;lt;Row&amp;gt; words = lines.select(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;);
        Dataset&amp;lt;Row&amp;gt; count = words.withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;)
                .groupBy(functions.window(words.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;)
                        , words.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;)).count();
        StreamingQuery start = count.writeStream()
                .outputMode(&lt;span class=&quot;code-quote&quot;&gt;&quot;update&quot;&lt;/span&gt;)
                .format(&lt;span class=&quot;code-quote&quot;&gt;&quot;console&quot;&lt;/span&gt;).start();
        start.awaitTermination();    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;scala&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 def main(args: Array[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;]): Unit = {
    val spark = SparkSession.builder.appName(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;).
      master(&lt;span class=&quot;code-quote&quot;&gt;&quot;local[*]&quot;&lt;/span&gt;).
      config(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.sql.shuffle.partitions&quot;&lt;/span&gt;, 1)
      .getOrCreate
    &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; spark.implicits._
    val lines = spark.readStream.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;socket&quot;&lt;/span&gt;).
      option(&lt;span class=&quot;code-quote&quot;&gt;&quot;host&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;skynet&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;includeTimestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;).
      option(&lt;span class=&quot;code-quote&quot;&gt;&quot;port&quot;&lt;/span&gt;, 8888).load
    val words = lines.select(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;)
    val count = words.withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;).
      groupBy(window($&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;), $&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;)
      .count()
    val start = count.writeStream.outputMode(&lt;span class=&quot;code-quote&quot;&gt;&quot;update&quot;&lt;/span&gt;).format(&lt;span class=&quot;code-quote&quot;&gt;&quot;console&quot;&lt;/span&gt;).start
    start.awaitTermination()
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is according to official documents. written in Java I found metrics &quot;stateOnCurrentVersionSizeBytes&quot;&#160;always increase .but scala is ok.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;java&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
== Physical Plan ==
WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4176a001
+- *(4) HashAggregate(keys=[window#11, value#0], functions=[count(1)], output=[window#11, value#0, count#10L])
   +- StateStoreSave [window#11, value#0], state info [ checkpoint = file:/C:/Users/chenhao/AppData/Local/Temp/temporary-63acf9b1-9249-40db-ab33-9dcadf5736aa/state, runId = d38b8fee-6cd0-441c-87da-a4e3660856a3, opId = 0, ver = 5, numPartitions = 1], Update, 1579274372624, 2
      +- *(3) HashAggregate(keys=[window#11, value#0], functions=[merge_count(1)], output=[window#11, value#0, count#21L])
         +- StateStoreRestore [window#11, value#0], state info [ checkpoint = file:/C:/Users/chenhao/AppData/Local/Temp/temporary-63acf9b1-9249-40db-ab33-9dcadf5736aa/state, runId = d38b8fee-6cd0-441c-87da-a4e3660856a3, opId = 0, ver = 5, numPartitions = 1], 2
            +- *(2) HashAggregate(keys=[window#11, value#0], functions=[merge_count(1)], output=[window#11, value#0, count#21L])
               +- Exchange hashpartitioning(window#11, value#0, 1)
                  +- *(1) HashAggregate(keys=[window#11, value#0], functions=[partial_count(1)], output=[window#11, value#0, count#21L])
                     +- *(1) Project [named_struct(start, precisetimestampconversion(((((CASE WHEN (&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) = (&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) THEN (CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) + 1) ELSE CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) END + 0) - 1) * 10000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) = (&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) THEN (CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) + 1) ELSE CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) END + 0) - 1) * 10000000) + 10000000), LongType, TimestampType)) AS window#11, value#0]
                        +- *(1) Filter isnotnull(timestamp#1)
                           +- EventTimeWatermark timestamp#1: timestamp, interval 10 seconds
                              +- LocalTableScan &amp;lt;empty&amp;gt;, [timestamp#1, value#0]

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;scala&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
WriteToDataSourceV2 org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@4149892c
+- *(4) HashAggregate(keys=[window#11-T10000ms, value#0], functions=[count(1)], output=[window#6-T10000ms, value#0, count#10L])
   +- StateStoreSave [window#11-T10000ms, value#0], state info [ checkpoint = file:/C:/Users/chenhao/AppData/Local/Temp/temporary-8b17f74b-0963-4fee-82cd-2c1e63a75a98/state, runId = dac4413d-5a82-4d61-b134-c81bfab704d8, opId = 0, ver = 7, numPartitions = 1], Update, 1579275214256, 2
      +- *(3) HashAggregate(keys=[window#11-T10000ms, value#0], functions=[merge_count(1)], output=[window#11-T10000ms, value#0, count#21L])
         +- StateStoreRestore [window#11-T10000ms, value#0], state info [ checkpoint = file:/C:/Users/chenhao/AppData/Local/Temp/temporary-8b17f74b-0963-4fee-82cd-2c1e63a75a98/state, runId = dac4413d-5a82-4d61-b134-c81bfab704d8, opId = 0, ver = 7, numPartitions = 1], 2
            +- *(2) HashAggregate(keys=[window#11-T10000ms, value#0], functions=[merge_count(1)], output=[window#11-T10000ms, value#0, count#21L])
               +- Exchange hashpartitioning(window#11-T10000ms, value#0, 1)
                  +- *(1) HashAggregate(keys=[window#11-T10000ms, value#0], functions=[partial_count(1)], output=[window#11-T10000ms, value#0, count#21L])
                     +- *(1) Project [named_struct(start, precisetimestampconversion(((((CASE WHEN (&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1-T10000ms, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) = (&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1-T10000ms, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) THEN (CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1-T10000ms, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) + 1) ELSE CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1-T10000ms, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) END + 0) - 1) * 10000000) + 0), LongType, TimestampType), end, precisetimestampconversion(((((CASE WHEN (&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1-T10000ms, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) = (&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1-T10000ms, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) THEN (CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1-T10000ms, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) + 1) ELSE CEIL((&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;((precisetimestampconversion(timestamp#1-T10000ms, TimestampType, LongType) - 0) as &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;) / 1.0E7)) END + 0) - 1) * 10000000) + 10000000), LongType, TimestampType)) AS window#11-T10000ms, value#0]
                        +- *(1) Filter isnotnull(timestamp#1-T10000ms)
                           +- EventTimeWatermark timestamp#1: timestamp, interval 10 seconds
                              +- LocalTableScan &amp;lt;empty&amp;gt;, [timestamp#1, value#0]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;you also can debug in&#160;statefulOperators.scala&#160;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; def removeKeysOlderThanWatermark(
      storeManager: StreamingAggregationStateManager,
      store: StateStore): Unit = {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (watermarkPredicateForKeys.nonEmpty) {
      storeManager.keys(store).foreach { keyRow =&amp;gt;
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (watermarkPredicateForKeys.get.eval(keyRow)) {
          storeManager.remove(store, keyRow)  &lt;span class=&quot;code-comment&quot;&gt;//&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; line
&lt;/span&gt;        }
      }
    }
  }
}

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;you will find java does not remove old state.&lt;/p&gt;

&lt;p&gt;&#160;I think java should write like this&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
        SparkSession spark = SparkSession.builder().appName(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;).master(&lt;span class=&quot;code-quote&quot;&gt;&quot;local[*]&quot;&lt;/span&gt;)
                .config(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.sql.shuffle.partitions&quot;&lt;/span&gt;, 1)
                .getOrCreate();        Dataset&amp;lt;Row&amp;gt; lines = spark.readStream().format(&lt;span class=&quot;code-quote&quot;&gt;&quot;socket&quot;&lt;/span&gt;)
                .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;host&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;skynet&quot;&lt;/span&gt;)
                .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;includeTimestamp&quot;&lt;/span&gt;,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
                .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;port&quot;&lt;/span&gt;, 8888).load();
        Dataset&amp;lt;Row&amp;gt; words = lines.select(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;);
        Dataset&amp;lt;Row&amp;gt; wordsWatermark = words.withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;);
        Dataset&amp;lt;Row&amp;gt; count = wordsWatermark
                .groupBy(functions.window(wordsWatermark.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;)
                        , wordsWatermark.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;)).count();
        StreamingQuery start = count.writeStream()
                .outputMode(&lt;span class=&quot;code-quote&quot;&gt;&quot;update&quot;&lt;/span&gt;)
                .format(&lt;span class=&quot;code-quote&quot;&gt;&quot;console&quot;&lt;/span&gt;).start();
        start.awaitTermination();    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13280168">SPARK-30553</key>
            <summary>Fix structured-streaming java example error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="5" iconUrl="https://issues.apache.org/jira/images/icons/priorities/trivial.svg">Trivial</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bettermouse">bettermouse</assignee>
                                    <reporter username="bettermouse">bettermouse</reporter>
                        <labels>
                    </labels>
                <created>Fri, 17 Jan 2020 15:48:16 +0000</created>
                <updated>Wed, 22 Jan 2020 05:45:09 +0000</updated>
                            <resolved>Wed, 22 Jan 2020 05:38:53 +0000</resolved>
                                    <version>2.1.1</version>
                    <version>2.2.3</version>
                    <version>2.3.4</version>
                    <version>2.4.4</version>
                                    <fixVersion>2.4.5</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17020789" author="dongjoon" created="Wed, 22 Jan 2020 05:38:53 +0000"  >&lt;p&gt;Issue resolved by pull request 27268&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/27268&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/27268&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13024709">SPARK-18669</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 42 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0amh4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>