<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:27:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-36827] Task/Stage/Job data remain in memory leads memory leak</title>
                <link>https://issues.apache.org/jira/browse/SPARK-36827</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Noticing memory-leak like behavior, steady increase of heap after GC and eventually it leads to a service failure. &lt;/p&gt;

&lt;p&gt;The GC histogram shows very high number of Task/Data/Job data&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 num     #instances         #bytes  &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;name 
---------------------------------------------- 
   6:       7835346     2444627952  org.apache.spark.status.TaskDataWrapper 
  25:       3765152      180727296  org.apache.spark.status.StageDataWrapper 
  88:        232255        9290200  org.apache.spark.status.JobDataWrapper 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thread dumps show clearly the clean up thread is always doing cleanupStages&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;element-tracking-store-worker&quot;&lt;/span&gt; #355 daemon prio=5 os_prio=0 tid=0x00007f31b0014800 nid=0x409 runnable [0x00007f2f25783000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.util.kvstore.KVTypeInfo$MethodAccessor.get(KVTypeInfo.java:162)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryView.compare(InMemoryStore.java:434)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryView.lambda$iterator$0(InMemoryStore.java:375)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryView$$Lambda$9000/574018760.compare(Unknown Source)
	at java.util.TimSort.gallopLeft(TimSort.java:542)
	at java.util.TimSort.mergeLo(TimSort.java:752)
	at java.util.TimSort.mergeAt(TimSort.java:514)
	at java.util.TimSort.mergeCollapse(TimSort.java:439)
	at java.util.TimSort.sort(TimSort.java:245)
	at java.util.Arrays.sort(Arrays.java:1512)
	at java.util.ArrayList.sort(ArrayList.java:1464)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryView.iterator(InMemoryStore.java:375)
	at org.apache.spark.util.kvstore.KVStoreView.closeableIterator(KVStoreView.java:117)
	at org.apache.spark.status.AppStatusListener.$anonfun$cleanupStages$2(AppStatusListener.scala:1269)
	at org.apache.spark.status.AppStatusListener$$Lambda$9126/608388595.apply(Unknown Source)
	at scala.collection.immutable.List.map(List.scala:297)
	at org.apache.spark.status.AppStatusListener.cleanupStages(AppStatusListener.scala:1260)
	at org.apache.spark.status.AppStatusListener.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$3(AppStatusListener.scala:98)
	at org.apache.spark.status.AppStatusListener$$Lambda$646/596139882.apply$mcVJ$sp(Unknown Source)
	at org.apache.spark.status.ElementTrackingStore.$anonfun$write$3(ElementTrackingStore.scala:135)
	at org.apache.spark.status.ElementTrackingStore.$anonfun$write$3$adapted(ElementTrackingStore.scala:133)
	at org.apache.spark.status.ElementTrackingStore$$Lambda$986/162337848.apply(Unknown Source)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.status.ElementTrackingStore.$anonfun$write$2(ElementTrackingStore.scala:133)
	at org.apache.spark.status.ElementTrackingStore.$anonfun$write$2$adapted(ElementTrackingStore.scala:131)
	at org.apache.spark.status.ElementTrackingStore$$Lambda$984/600376389.apply(Unknown Source)
	at org.apache.spark.status.ElementTrackingStore$LatchedTriggers.$anonfun$fireOnce$1(ElementTrackingStore.scala:58)
	at org.apache.spark.status.ElementTrackingStore$LatchedTriggers$$Lambda$985/1187323214.apply$mcV$sp(Unknown Source)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.util.Utils$.tryLog(Utils.scala:2013)
	at org.apache.spark.status.ElementTrackingStore$$anon$1.run(ElementTrackingStore.scala:117)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <environment></environment>
        <key id="13402743">SPARK-36827</key>
            <summary>Task/Stage/Job data remain in memory leads memory leak</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Gengliang.Wang">Gengliang Wang</assignee>
                                    <reporter username="taroplus">Kohki Nishio</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Sep 2021 17:27:02 +0000</created>
                <updated>Fri, 24 Sep 2021 09:25:17 +0000</updated>
                            <resolved>Fri, 24 Sep 2021 09:25:05 +0000</resolved>
                                    <version>3.1.2</version>
                                    <fixVersion>3.2.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17418742" author="taroplus" created="Wed, 22 Sep 2021 17:47:54 +0000"  >&lt;p&gt;one thread shows slightly different codepoint&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;element-tracking-store-worker&quot;&lt;/span&gt; #355 daemon prio=5 os_prio=0 tid=0x00007f31b0014800 nid=0x409 runnable [0x00007f2f25783000]
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE
	at java.util.concurrent.ConcurrentHashMap$Traverser.advance(ConcurrentHashMap.java:3318)
	at java.util.concurrent.ConcurrentHashMap$ValueIterator.next(ConcurrentHashMap.java:3439)
	at java.util.concurrent.ConcurrentHashMap$CollectionView.toArray(ConcurrentHashMap.java:4417)
	at java.util.ArrayList.&amp;lt;init&amp;gt;(ArrayList.java:178)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryView.copyElements(InMemoryStore.java:428)
	at org.apache.spark.util.kvstore.InMemoryStore$InMemoryView.iterator(InMemoryStore.java:374)
	at org.apache.spark.util.kvstore.KVStoreView.closeableIterator(KVStoreView.java:117)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;this loop seems to be very expensive if there are millions of entries&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
stages.map .. (AppStatusListener - N)
        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; List&amp;lt;T&amp;gt; sorted = copyElements();  (InMemoryStore)
        sorted.sort((e1, e2) -&amp;gt; modifier * compare(e1, e2, getter)); (InMemoryStore)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so it gets out of control quickly&lt;/p&gt;</comment>
                            <comment id="17418813" author="srowen" created="Wed, 22 Sep 2021 20:23:12 +0000"  >&lt;p&gt;Those are stack dumps not heap dumps. Do you know anything about what is hanging on to the reference? I would see whether turning down retained jobs and tasks in the UI does anything to narrow it down. What you have here at best suggests an allocation hotspot. &lt;/p&gt;

&lt;p&gt;I recall this change which might possibly be related but not sure. Could be worth trying 3.2.0 when released. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/33859&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/33859&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17418829" author="taroplus" created="Wed, 22 Sep 2021 21:00:00 +0000"  >&lt;p&gt;I do have multiple heap dumps, however it won&apos;t help the problem. Those are just stage/task/job data piling up (from completed jobs). Spark has a limit (e.g. spark.ui.retainedStages) and it&apos;s kicking off the clean up task. (which runs in element-tracking-store-worker thread).&lt;/p&gt;

&lt;p&gt;However Spark is doing somewhat O(N*N) type of operation inside of the thread, the speed of deletion gets slower and slower as it gets more stages. As a result, the deletion speed is way slower than the creation of tasks. I have identified the part doing O(N*N) and testing a fix.&lt;/p&gt;</comment>
                            <comment id="17418832" author="taroplus" created="Wed, 22 Sep 2021 21:03:59 +0000"  >&lt;p&gt;this line&lt;br/&gt;
 &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/status/AppStatusListener.scala#L1276&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/status/AppStatusListener.scala#L1276&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;does &lt;em&gt;copy all stages to a new list and sort it&lt;/em&gt;&#160; for every single stage to delete (which is almost everything for my case)&lt;/p&gt;</comment>
                            <comment id="17418842" author="srowen" created="Wed, 22 Sep 2021 21:42:14 +0000"  >&lt;p&gt;Looks promising yeah. This loop seems like it could instead iterate once, remembering which stages it has seen, and then use that info to clean up, rather than iterating for each stage.&lt;/p&gt;</comment>
                            <comment id="17418849" author="taroplus" created="Wed, 22 Sep 2021 21:56:05 +0000"  >&lt;p&gt;i still need to ramp up the process for getting a PR, but i believe handling&#160;remainingStages can be done later, here&apos;s what i&apos;m testing ...&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;

&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def cleanupStages(count: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;): Unit = {
  val countToDelete = calculateNumberToRemove(count, conf.get(MAX_RETAINED_STAGES))
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (countToDelete &amp;lt;= 0L) {
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
  }

  &lt;span class=&quot;code-comment&quot;&gt;// As the completion time of a skipped stage is always -1, we will remove skipped stages first.
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// This is safe since the job itself contains enough information to render skipped stages in the
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// UI.
&lt;/span&gt;  val view = kvstore.view(classOf[StageDataWrapper]).index(&lt;span class=&quot;code-quote&quot;&gt;&quot;completionTime&quot;&lt;/span&gt;)
  val stages = KVUtils.viewToSeq(view, countToDelete.toInt) { s =&amp;gt;
    s.info.status != v1.StageStatus.ACTIVE &amp;amp;&amp;amp; s.info.status != v1.StageStatus.PENDING
  }

  val stageIds = stages.map { s =&amp;gt;
    val key = Array(s.info.stageId, s.info.attemptId)
    kvstore.delete(s.getClass(), key)
    cleanupCachedQuantiles(key)
    key
  }

  &lt;span class=&quot;code-comment&quot;&gt;// create remaining set of stages.
&lt;/span&gt;  val iter = view.closeableIterator()
  val remainingStages = &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
    iter.asScala.map(_.info.stageId).toSet
  } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
    iter.close()
  }
  stageIds.foreach(key =&amp;gt; {
    &lt;span class=&quot;code-comment&quot;&gt;// Check whether there are remaining attempts &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the same stage. If there aren&apos;t, then
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// also delete the RDD graph data.
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!remainingStages.contains(key(0))) {
      kvstore.delete(classOf[RDDOperationGraphWrapper], key(0))
    }
  })

  &lt;span class=&quot;code-comment&quot;&gt;// Delete summaries in one pass, as deleting them &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; each stage is slow
&lt;/span&gt;  kvstore.removeAllByIndexValues(classOf[ExecutorStageSummaryWrapper], &lt;span class=&quot;code-quote&quot;&gt;&quot;stage&quot;&lt;/span&gt;, stageIds)

  &lt;span class=&quot;code-comment&quot;&gt;// Delete tasks &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; all stages in one pass, as deleting them &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; each stage individually is slow
&lt;/span&gt;  kvstore.removeAllByIndexValues(classOf[TaskDataWrapper], TaskIndexNames.STAGE, stageIds)
}

 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17419547" author="apachespark" created="Fri, 24 Sep 2021 03:32:57 +0000"  >&lt;p&gt;User &apos;taroplus&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34090&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34090&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17419561" author="apachespark" created="Fri, 24 Sep 2021 04:57:02 +0000"  >&lt;p&gt;User &apos;gengliangwang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34092&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34092&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17419631" author="tenglei" created="Fri, 24 Sep 2021 07:53:26 +0000"  >&lt;p&gt;I met the same problem in spark 2.3.x, and find a pull request from&#160;&lt;a href=&quot;https://github.com/apache/spark/pull/24616&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24616&lt;/a&gt;&#160;it seem to relate to this problem and it should work.How much time you spend to occur this problem?&lt;/p&gt;</comment>
                            <comment id="17419682" author="gengliang.wang" created="Fri, 24 Sep 2021 09:25:05 +0000"  >&lt;p&gt;Issue resolved by pull request 34092&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34092&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34092&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="13034043" name="mem1.txt" size="4784" author="taroplus" created="Wed, 22 Sep 2021 17:29:55 +0000"/>
                            <attachment id="13034042" name="worker.txt" size="117432" author="taroplus" created="Wed, 22 Sep 2021 17:28:37 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 7 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0v6ww:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>