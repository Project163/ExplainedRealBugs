<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:30:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-9236] Left Outer Join with empty JavaPairRDD returns empty RDD</title>
                <link>https://issues.apache.org/jira/browse/SPARK-9236</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When the &lt;b&gt;left outer join&lt;/b&gt; is performed on a non-empty &lt;tt&gt;JavaPairRDD&lt;/tt&gt; with a &lt;tt&gt;JavaPairRDD&lt;/tt&gt; which was created with the &lt;tt&gt;emptyRDD()&lt;/tt&gt; method the resulting RDD is empty. In the following unit test the latest assert fails.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; org.assertj.core.api.Assertions.assertThat;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Collections;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; lombok.val;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.SparkConf;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.api.java.JavaSparkContext;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.junit.Test;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.Tuple2;

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;SparkTest {

  @Test
  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void joinEmptyRDDTest() {
    val sparkConf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkConf().setAppName(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;).setMaster(&lt;span class=&quot;code-quote&quot;&gt;&quot;local&quot;&lt;/span&gt;);

    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; (val sparkContext = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; JavaSparkContext(sparkConf)) {
      val oneRdd = sparkContext.parallelize(Collections.singletonList(&lt;span class=&quot;code-quote&quot;&gt;&quot;one&quot;&lt;/span&gt;));
      val twoRdd = sparkContext.parallelize(Collections.singletonList(&lt;span class=&quot;code-quote&quot;&gt;&quot;two&quot;&lt;/span&gt;));
      val threeRdd = sparkContext.emptyRDD();

      val onePair = oneRdd.mapToPair(t -&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Tuple2&amp;lt;&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;(1, t));
      val twoPair = twoRdd.groupBy(t -&amp;gt; 1);
      val threePair = threeRdd.groupBy(t -&amp;gt; 1);

      assertThat(onePair.leftOuterJoin(twoPair).collect()).isNotEmpty();
      assertThat(onePair.leftOuterJoin(threePair).collect()).isNotEmpty();
    }
  }

}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12846737">SPARK-9236</key>
            <summary>Left Outer Join with empty JavaPairRDD returns empty RDD</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="huitseeker">Fran&#231;ois Garillot</assignee>
                                    <reporter username="slovit">Vitalii Slobodianyk</reporter>
                        <labels>
                    </labels>
                <created>Wed, 22 Jul 2015 01:51:49 +0000</created>
                <updated>Thu, 22 Oct 2015 10:55:29 +0000</updated>
                            <resolved>Fri, 24 Jul 2015 14:41:17 +0000</resolved>
                                    <version>1.3.1</version>
                    <version>1.4.1</version>
                                    <fixVersion>1.3.2</fixVersion>
                    <fixVersion>1.4.2</fixVersion>
                    <fixVersion>1.5.0</fixVersion>
                                    <component>Java API</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14636752" author="huitseeker" created="Wed, 22 Jul 2015 11:39:41 +0000"  >&lt;p&gt;I have added two tests as the last commit of a personal &lt;a href=&quot;https://github.com/huitseeker/spark/tree/issue/SPARK-9236&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;branch&lt;/a&gt;:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/compare/master...huitseeker:issue/SPARK-9236?expand=1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/compare/master...huitseeker:issue/SPARK-9236?expand=1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;They both succeed, so i can&apos;t reproduce this issue.&lt;/p&gt;</comment>
                            <comment id="14636853" author="slovit" created="Wed, 22 Jul 2015 12:37:33 +0000"  >&lt;p&gt;It&apos;s reproducible  in Java, not in Scala&lt;/p&gt;</comment>
                            <comment id="14636872" author="huitseeker" created="Wed, 22 Jul 2015 12:57:47 +0000"  >&lt;p&gt;Note that of my two added tests, one is a Java test, which does not fail.&lt;/p&gt;

&lt;p&gt;I&apos;d appreciate a spark branch with that test added to one of the java suites (hence without its dependencies on assertJ &amp;amp; the lobok package), so that we can talk specifics.&lt;/p&gt;</comment>
                            <comment id="14636926" author="slovit" created="Wed, 22 Jul 2015 13:45:56 +0000"  >&lt;p&gt;Sure, I created a repo &lt;a href=&quot;https://github.com/slovit/SPARK-9236&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/slovit/SPARK-9236&lt;/a&gt; with a test case.&lt;/p&gt;

&lt;p&gt;Output when run:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  $ mvn test
[INFO] Scanning for projects...
[INFO]
[INFO] ------------------------------------------------------------------------
[INFO] Building spark 0.0.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO]
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark ---
[WARNING] Using platform encoding (US-ASCII actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] Copying 0 resource
[INFO]
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ spark ---
[INFO] Nothing to compile - all classes are up to date
[INFO]
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ spark ---
[WARNING] Using platform encoding (US-ASCII actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] Copying 0 resource
[INFO]
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ spark ---
[INFO] Changes detected - recompiling the module!
[WARNING] File encoding has not been set, using platform encoding US-ASCII, i.e. build is platform dependent!
[INFO] Compiling 1 source file to /private/tmp/SPARK-9236/target/test-classes
[INFO]
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ spark ---
[INFO] Surefire report directory: /private/tmp/SPARK-9236/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.slovit.spark.SparkTest
Using Spark&apos;s default log4j profile: org/apache/spark/log4j-defaults.properties
15/07/22 09:44:39 INFO SparkContext: Running Spark version 1.3.1
15/07/22 09:44:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/07/22 09:44:39 INFO SecurityManager: Changing view acls to: vslobodianyk
15/07/22 09:44:39 INFO SecurityManager: Changing modify acls to: vslobodianyk
15/07/22 09:44:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(vslobodianyk); users with modify permissions: Set(vslobodianyk)
15/07/22 09:44:39 INFO Slf4jLogger: Slf4jLogger started
15/07/22 09:44:39 INFO Remoting: Starting remoting
15/07/22 09:44:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@10.0.25.41:59548]
15/07/22 09:44:39 INFO Utils: Successfully started service &apos;sparkDriver&apos; on port 59548.
15/07/22 09:44:39 INFO SparkEnv: Registering MapOutputTracker
15/07/22 09:44:39 INFO SparkEnv: Registering BlockManagerMaster
15/07/22 09:44:39 INFO DiskBlockManager: Created local directory at /var/folders/z3/xg2wdwlx5h7bqyb7bzqj8nfh0000gp/T/spark-84779120-c6e3-41a3-874e-a7576831c296/blockmgr-98df3937-7029-4e28-b6c0-0f49edee8db9
15/07/22 09:44:39 INFO MemoryStore: MemoryStore started with capacity 1966.1 MB
15/07/22 09:44:39 INFO HttpFileServer: HTTP File server directory is /var/folders/z3/xg2wdwlx5h7bqyb7bzqj8nfh0000gp/T/spark-ec226035-59b5-4180-92df-19c5da0f36be/httpd-94b3b9d2-9302-49f4-be2b-2df7c01aba25
15/07/22 09:44:39 INFO HttpServer: Starting HTTP Server
15/07/22 09:44:40 INFO Server: jetty-8.y.z-SNAPSHOT
15/07/22 09:44:40 INFO AbstractConnector: Started SocketConnector@0.0.0.0:59549
15/07/22 09:44:40 INFO Utils: Successfully started service &apos;HTTP file server&apos; on port 59549.
15/07/22 09:44:40 INFO SparkEnv: Registering OutputCommitCoordinator
15/07/22 09:44:40 INFO Server: jetty-8.y.z-SNAPSHOT
15/07/22 09:44:40 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
15/07/22 09:44:40 INFO Utils: Successfully started service &apos;SparkUI&apos; on port 4040.
15/07/22 09:44:40 INFO SparkUI: Started SparkUI at http://10.0.25.41:4040
15/07/22 09:44:40 INFO Executor: Starting executor ID &amp;lt;driver&amp;gt; on host localhost
15/07/22 09:44:40 INFO AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@10.0.25.41:59548/user/HeartbeatReceiver
15/07/22 09:44:40 INFO NettyBlockTransferService: Server created on 59550
15/07/22 09:44:40 INFO BlockManagerMaster: Trying to register BlockManager
15/07/22 09:44:40 INFO BlockManagerMasterActor: Registering block manager localhost:59550 with 1966.1 MB RAM, BlockManagerId(&amp;lt;driver&amp;gt;, localhost, 59550)
15/07/22 09:44:40 INFO BlockManagerMaster: Registered BlockManager
15/07/22 09:44:40 INFO SparkContext: Starting job: collect at SparkTest.java:27
15/07/22 09:44:40 INFO DAGScheduler: Job 0 finished: collect at SparkTest.java:27, took 0.001723 s
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
15/07/22 09:44:40 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
15/07/22 09:44:40 INFO SparkUI: Stopped Spark web UI at http://10.0.25.41:4040
15/07/22 09:44:40 INFO DAGScheduler: Stopping DAGScheduler
15/07/22 09:44:40 INFO MapOutputTrackerMasterActor: MapOutputTrackerActor stopped!
15/07/22 09:44:40 INFO MemoryStore: MemoryStore cleared
15/07/22 09:44:40 INFO BlockManager: BlockManager stopped
15/07/22 09:44:40 INFO BlockManagerMaster: BlockManagerMaster stopped
15/07/22 09:44:40 INFO SparkContext: Successfully stopped SparkContext
15/07/22 09:44:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorActor: OutputCommitCoordinator stopped!
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 1.864 sec &amp;lt;&amp;lt;&amp;lt; FAILURE!
joinEmptyRDDTest(org.slovit.spark.SparkTest)  Time elapsed: 1.819 sec  &amp;lt;&amp;lt;&amp;lt; FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertFalse(Assert.java:64)
	at org.junit.Assert.assertFalse(Assert.java:74)
	at org.slovit.spark.SparkTest.joinEmptyRDDTest(SparkTest.java:27)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)


Results :

Failed tests:   joinEmptyRDDTest(org.slovit.spark.SparkTest)

Tests run: 1, Failures: 1, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 3.994 s
[INFO] Finished at: 2015-07-22T09:44:41-04:00
[INFO] Final Memory: 30M/329M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test (default-test) on project spark: There are test failures.
[ERROR]
[ERROR] Please refer to /private/tmp/SPARK-9236/target/surefire-reports for the individual test results.
[ERROR] -&amp;gt; [Help 1]
[ERROR]
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR]
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14638527" author="huitseeker" created="Thu, 23 Jul 2015 09:12:13 +0000"  >&lt;p&gt;Very nice catch !! So, this is actually a bug you can observe with Scala, and that you can simply observe with &lt;tt&gt;cogroup&lt;/tt&gt;. But it&apos;s not due to your &lt;tt&gt;emptyRDD&lt;/tt&gt;, it&apos;s due to your use of &lt;tt&gt;groupBy&lt;/tt&gt;. Thanks for the detailed test case, it was instrumental in catching this. &lt;/p&gt;

&lt;p&gt;What happens is that when you use &lt;tt&gt;groupBy&lt;/tt&gt;, the result sets the partitioner of the transformed RDD, and that partitioner has, in a very logical fashion, zero partitions. However, the &lt;tt&gt;cogroup&lt;/tt&gt; operation that comes afterwards tries to reuse any set partitioner of the RDDs it&apos;s trying to &lt;tt&gt;cogroup&lt;/tt&gt;. It falls on this one, and with it having 0 partitions, doesn&apos;t even start the iteration that would return elements. The fix is to check that a partitioner has &amp;gt; 0 partitions before trying to reuse it.&lt;/p&gt;</comment>
                            <comment id="14638530" author="apachespark" created="Thu, 23 Jul 2015 09:13:09 +0000"  >&lt;p&gt;User &apos;huitseeker&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7616&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7616&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14640515" author="srowen" created="Fri, 24 Jul 2015 14:41:17 +0000"  >&lt;p&gt;Issue resolved by pull request 7616&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7616&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7616&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12834745">SPARK-8048</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 17 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2hj1r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>