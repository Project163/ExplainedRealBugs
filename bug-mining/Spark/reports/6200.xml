<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26372] CSV parsing uses previous good value for bad input field</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26372</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;For example:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;bash-3.2$ cat test.csv 
&quot;hello&quot;,1999-08-01
&quot;there&quot;,&quot;bad date&quot;
&quot;again&quot;,&quot;2017-11-22&quot;
bash-3.2$ bin/spark-shell
..etc..
scala&amp;gt; import org.apache.spark.sql.types._
scala&amp;gt; import org.apache.spark.sql.SaveMode
scala&amp;gt; var schema = StructType(StructField(&quot;col1&quot;, StringType) ::
     |   StructField(&quot;col2&quot;, DateType) ::
     |   Nil)
schema: org.apache.spark.sql.types.StructType = StructType(StructField(col1,StringType,true), StructField(col2,DateType,true))
scala&amp;gt; val df = spark.read.schema(schema).csv(&quot;test.csv&quot;)
df: org.apache.spark.sql.DataFrame = [col1: string, col2: date]
scala&amp;gt; df.show
+-----+----------+                                                              
| col1|      col2|
+-----+----------+
|hello|1999-08-01|
|there|1999-08-01|
|again|2017-11-22|
+-----+----------+
scala&amp;gt; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;col2 from the second row contains &quot;1999-08-01&quot;, when it should contain null.&lt;/p&gt;

&lt;p&gt;This is because UnivocityParser reuses the same Row object for each input record. If there is an exception converting an input field, the code simply skips over that field, leaving the existing value in the Row object.&lt;/p&gt;

&lt;p&gt;The simple fix is to set the column to null in the Row object whenever there is a badRecordException while converting the input field.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13204519">SPARK-26372</key>
            <summary>CSV parsing uses previous good value for bad input field</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bersprockets">Bruce Robbins</assignee>
                                    <reporter username="bersprockets">Bruce Robbins</reporter>
                        <labels>
                    </labels>
                <created>Fri, 14 Dec 2018 16:38:45 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:57 +0000</updated>
                            <resolved>Sun, 16 Dec 2018 03:03:02 +0000</resolved>
                                    <version>3.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16721593" author="bersprockets" created="Fri, 14 Dec 2018 16:45:55 +0000"  >&lt;p&gt;I can prep a PR, unless someone thinks this needs a different solution than the one I proposed.&lt;/p&gt;</comment>
                            <comment id="16721858" author="githubbot" created="Fri, 14 Dec 2018 23:02:48 +0000"  >&lt;p&gt;bersprockets opened a new pull request #23323: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26372&quot; title=&quot;CSV parsing uses previous good value for bad input field&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26372&quot;&gt;&lt;del&gt;SPARK-26372&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;SQL&amp;#93;&lt;/span&gt; Don&apos;t reuse value from previous row when parsing bad CSV input field&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/spark/pull/23323&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23323&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What changes were proposed in this pull request?&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   CSV parsing accidentally uses the previous good value for a bad input field. See example in Jira.&lt;/p&gt;

&lt;p&gt;   This PR ensures that the associated column is set to null when an input field cannot be converted.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;How was this patch tested?&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Added new test.&lt;br/&gt;
   Ran all SQL unit tests (testOnly org.apache.spark.sql.*).&lt;br/&gt;
   Ran pyspark tests for pyspark-sql&lt;/p&gt;


&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16722365" author="gurwls223" created="Sun, 16 Dec 2018 03:03:02 +0000"  >&lt;p&gt;Issue resolved by pull request 23323&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23323&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23323&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16722367" author="githubbot" created="Sun, 16 Dec 2018 03:05:33 +0000"  >&lt;p&gt;asfgit closed pull request #23323: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26372&quot; title=&quot;CSV parsing uses previous good value for bad input field&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26372&quot;&gt;&lt;del&gt;SPARK-26372&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;SQL&amp;#93;&lt;/span&gt; Don&apos;t reuse value from previous row when parsing bad CSV input field&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/spark/pull/23323&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23323&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/csv/UnivocityParser.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/csv/UnivocityParser.scala&lt;br/&gt;
index 0f375e036029c..aafc9ebdcaa12 100644&lt;br/&gt;
&amp;#8212; a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/csv/UnivocityParser.scala&lt;br/&gt;
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/csv/UnivocityParser.scala&lt;br/&gt;
@@ -239,6 +239,7 @@ class UnivocityParser(&lt;br/&gt;
         } catch &lt;/p&gt;
{
           case NonFatal(e) =&amp;gt;
             badRecordException = badRecordException.orElse(Some(e))
+            row.setNullAt(i)
         }
&lt;p&gt;         i += 1&lt;br/&gt;
       }&lt;br/&gt;
diff --git a/sql/core/src/test/resources/test-data/bad_after_good.csv b/sql/core/src/test/resources/test-data/bad_after_good.csv&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 0000000000000..4621a7d23714d&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sql/core/src/test/resources/test-data/bad_after_good.csv&lt;br/&gt;
@@ -0,0 +1,2 @@&lt;br/&gt;
+&quot;good record&quot;,1999-08-01&lt;br/&gt;
+&quot;bad record&quot;,1999-088-01&lt;br/&gt;
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala&lt;br/&gt;
index 3b977d74053e6..d9e5d7af19671 100644&lt;br/&gt;
&amp;#8212; a/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala&lt;br/&gt;
+++ b/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala&lt;br/&gt;
@@ -63,6 +63,7 @@ class CSVSuite extends QueryTest with SharedSQLContext with SQLTestUtils with Te&lt;br/&gt;
   private val datesFile = &quot;test-data/dates.csv&quot;&lt;br/&gt;
   private val unescapedQuotesFile = &quot;test-data/unescaped-quotes.csv&quot;&lt;br/&gt;
   private val valueMalformedFile = &quot;test-data/value-malformed.csv&quot;&lt;br/&gt;
+  private val badAfterGoodFile = &quot;test-data/bad_after_good.csv&quot;&lt;/p&gt;

&lt;p&gt;   /** Verifies data and schema. */&lt;br/&gt;
   private def verifyCars(&lt;br/&gt;
@@ -2012,4 +2013,22 @@ class CSVSuite extends QueryTest with SharedSQLContext with SQLTestUtils with Te&lt;br/&gt;
       assert(!files.exists(_.getName.endsWith(&quot;csv&quot;)))&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
+&lt;br/&gt;
+  test(&quot;Do not reuse last good value for bad input field&quot;) &lt;/p&gt;
{
+    val schema = StructType(
+      StructField(&quot;col1&quot;, StringType) ::
+      StructField(&quot;col2&quot;, DateType) ::
+      Nil
+    )
+    val rows = spark.read
+      .schema(schema)
+      .format(&quot;csv&quot;)
+      .load(testFile(badAfterGoodFile))
+
+    val expectedRows = Seq(
+      Row(&quot;good record&quot;, java.sql.Date.valueOf(&quot;1999-08-01&quot;)),
+      Row(&quot;bad record&quot;, null))
+
+    checkAnswer(rows, expectedRows)
+  }
&lt;p&gt; }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 48 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s01j8w:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>