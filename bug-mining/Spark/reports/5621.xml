<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:59:12 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18371] Spark Streaming backpressure bug - generates a batch with large number of records</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18371</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When the streaming job is configured with backpressureEnabled=true, it generates a GIANT batch of records if the processing time + scheduled delay is (much) larger than batchDuration. This creates a backlog of records like no other and results in batches queueing for hours until it chews through this giant batch.&lt;br/&gt;
Expectation is that it should reduce the number of records per batch in some time to whatever it can really process.&lt;br/&gt;
Attaching some screen shots where it seems that this issue is quite easily reproducible.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13019420">SPARK-18371</key>
            <summary>Spark Streaming backpressure bug - generates a batch with large number of records</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="seb.arzt">Sebastian Arzt</assignee>
                                    <reporter username="mapreduced">mapreduced</reporter>
                        <labels>
                    </labels>
                <created>Wed, 9 Nov 2016 00:26:38 +0000</created>
                <updated>Sun, 29 Sep 2019 13:14:41 +0000</updated>
                            <resolved>Fri, 16 Mar 2018 17:33:06 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>DStreams</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="15649409" author="mapreduced" created="Wed, 9 Nov 2016 01:01:49 +0000"  >&lt;p&gt;I worked the math for &lt;a href=&quot;https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/rate/PIDRateEstimator.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PIDRateEstimator&lt;/a&gt; and I found that when there are long scheduling delays it increases the &apos;historicalError&apos; by a LOT, which even when multiplied by integral (=0.2 default), results in a large negative in the formula:&lt;br/&gt;
val newRate = (latestRate - proportional * error - integral * historicalError - derivative * dError).max(minRate)&lt;/p&gt;

&lt;p&gt;As a result, minRate (=100 default) becomes the newRate. Now, when it comes in &lt;a href=&quot;https://github.com/apache/spark/blob/master/external/kafka-0-8/src/main/scala/org/apache/spark/streaming/kafka/DirectKafkaInputDStream.scala#L107&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;DirectKafkaInputDStream&lt;/a&gt; , if you have more than 100 partitions in your kafka topics, you&apos;re almost guaranteed to get Math.rounded backpressureRate = 0.  Which then &lt;a href=&quot;https://github.com/apache/spark/blob/master/external/kafka-0-8/src/main/scala/org/apache/spark/streaming/kafka/DirectKafkaInputDStream.scala#L114&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt; leads to returning None. That as a result returns &lt;a href=&quot;https://github.com/apache/spark/blob/master/external/kafka-0-8/src/main/scala/org/apache/spark/streaming/kafka/DirectKafkaInputDStream.scala#L149&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;leaderOffsets&lt;/a&gt; for that batch - hence the giant batch with all records from last batch till head of the queue (leaderOffsets).&lt;/p&gt;

&lt;p&gt;Proposed solution: Not sure, maybe the minRate could be defaulted to Total number of Partitions in all your kafka topics + some constant. Not sure if anyone has any suggestions to changes in PIDRateEstimator itself.&lt;/p&gt;

&lt;p&gt;Here&apos;s the math I did from the example in Look_at_batch_at_22_14.png : &lt;/p&gt;

&lt;p&gt;&lt;b&gt;Run1&lt;/b&gt; :&lt;/p&gt;

&lt;p&gt;latestRate = -1&lt;br/&gt;
latestTime = -1&lt;br/&gt;
latestError = -1&lt;br/&gt;
time = 1478587297000&lt;br/&gt;
processingDelay = 342000&lt;br/&gt;
delaySinceUpdate = 1478587298&lt;/p&gt;

&lt;p&gt;processingRate = (10800000/342000) * 1000 = 31578.94&lt;/p&gt;

&lt;p&gt;error = -1 -31579 = -31580&lt;br/&gt;
historicalError = 8 *  31579 / 60000 = 4.21&lt;br/&gt;
dError = (-31580 - 4.21)/ 1478587298 = 0.00002136107254&lt;/p&gt;

&lt;p&gt;newRate =  (-1 -(1*-31580) - (0.2*4.21) - (0 * 0.00002136107254)).max(100) = (31578.158).max(100) = 31578.158&lt;/p&gt;

&lt;p&gt;latestTime = 1478587297&lt;br/&gt;
latestError = 0&lt;br/&gt;
latestRate = 31578.94&lt;br/&gt;
Returns None - which results in picking up maxRatePerPartition&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Run 2&lt;/b&gt; :&lt;br/&gt;
time = 1478587615000&lt;br/&gt;
processingDelay = 5.3 * 60 * 1000 = 318000&lt;br/&gt;
schedulingDelay = 282000&lt;/p&gt;

&lt;p&gt;delaySinceUpdate = (1478587615000 - 1478587297000) = 318&lt;br/&gt;
processingRate = 10800000/318000 * 1000 = 33962.2&lt;br/&gt;
error = 31578 - 33962 = -2384&lt;br/&gt;
historicalError = 282000 * 33962 / 60000 = 159621.4&lt;/p&gt;

&lt;p&gt;dError = doesnt matter since multiplied by 0&lt;/p&gt;

&lt;p&gt;newRate = (31578 - (1*-2384) - (0.2*159621) - (0 * dError)).max(100) = (2037.72).max(100) = 2037.72&lt;/p&gt;

&lt;p&gt;latestRate = 2037.72&lt;br/&gt;
latestError = -2384&lt;br/&gt;
latestTime = 1478587615000&lt;br/&gt;
Returns newRate = 2037.72&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Run 3&lt;/b&gt; :&lt;br/&gt;
totalLag = 1972830183&lt;br/&gt;
perpartition lag = 6576100.61&lt;br/&gt;
backpressureRate = 126000 - 129000&lt;/p&gt;

&lt;p&gt;time = 1478587795000&lt;br/&gt;
delaySinceUpdate = 1478587795000 - 1478587615000 = 180&lt;/p&gt;

&lt;p&gt;processingRate = 10800000/180000 * 1000 = 60000&lt;br/&gt;
error = 2037 - 60000 = -57963&lt;br/&gt;
historicalError = 540000 * 60000 / 60000 = 540000&lt;br/&gt;
dError = doesntMatter&lt;/p&gt;

&lt;p&gt;newRate = (2037.72 - (1*-57963) -(0.2*540000) - 0).max(100) = (-48000).max(100) = 100&lt;/p&gt;

&lt;p&gt;latestTime = 1478587795000&lt;br/&gt;
latestRate = 100&lt;br/&gt;
latestError = -62384&lt;/p&gt;

&lt;p&gt;Returns newRate = 100&lt;/p&gt;</comment>
                            <comment id="15649638" author="cody@koeninger.org" created="Wed, 9 Nov 2016 02:59:07 +0000"  >&lt;p&gt;Thanks for digging into this.  The other thing I noticed when working on&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/15132&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15132&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;is that the return value of getLatestRate was cast to Int, which seems wrong and possibly subject to overflow.&lt;/p&gt;

&lt;p&gt;If you have the ability to test that PR (shouldn&apos;t require a spark redeploy, since the kafka jar is standalone), may want to test it out.&lt;/p&gt;</comment>
                            <comment id="15649891" author="mapreduced" created="Wed, 9 Nov 2016 05:48:14 +0000"  >&lt;p&gt;I&apos;ll try to test it out hopefully soon.&lt;/p&gt;</comment>
                            <comment id="15984776" author="seb.arzt" created="Wed, 26 Apr 2017 13:22:12 +0000"  >&lt;p&gt;I deep dived into it and found a simple solution. The problem is that &lt;a href=&quot;https://github.com/apache/spark/blob/branch-2.0/external/kafka-0-8/src/main/scala/org/apache/spark/streaming/kafka/DirectKafkaInputDStream.scala#L94&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;maxRateLimitPerPartition&lt;/a&gt; returns &lt;tt&gt;None&lt;/tt&gt; for an unintended case. &lt;tt&gt;None&lt;/tt&gt; should only be returned if there is no lag as indicated by this &lt;a href=&quot;https://github.com/apache/spark/blob/branch-2.0/external/kafka-0-8/src/main/scala/org/apache/spark/streaming/kafka/DirectKafkaInputDStream.scala#L114&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;condition&lt;/a&gt;. However, this condition is also true if all backpressureRates are &lt;a href=&quot;https://github.com/apache/spark/blob/branch-2.0/external/kafka-0-8/src/main/scala/org/apache/spark/streaming/kafka/DirectKafkaInputDStream.scala#L107&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;rounded&lt;/a&gt; to zero. I propose a solution, where rounding is omitted at all. This has the nice side-effect that backpressure is more fine-grained and not only an integral multiple of the &lt;a href=&quot;https://github.com/apache/spark/blob/branch-2.0/external/kafka-0-8/src/main/scala/org/apache/spark/streaming/kafka/DirectKafkaInputDStream.scala#L117&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;batchDuration&lt;/a&gt; in seconds. I will open a pull request for it soon.&lt;/p&gt;</comment>
                            <comment id="15984962" author="apachespark" created="Wed, 26 Apr 2017 15:08:03 +0000"  >&lt;p&gt;User &apos;arzt&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17774&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17774&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15984975" author="seb.arzt" created="Wed, 26 Apr 2017 15:13:50 +0000"  >&lt;p&gt;Screenshots:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12865156/01.png&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;before&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12865158/02.png&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;after&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16932158" author="rkarthikeyan" created="Wed, 18 Sep 2019 07:28:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=seb.arzt&quot; class=&quot;user-hover&quot; rel=&quot;seb.arzt&quot;&gt;seb.arzt&lt;/a&gt;&#160;Isnt this the same problem will come with kinesis connectors too?. Looks like your fix is only on the kafka part. We are using kinesis with spark streaming and we are seeing the exact same problem. attaching screenshot for reference.&#160; &lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12980581/12980581_Screen+Shot+2019-09-16+at+12.27.25+PM.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="16940405" author="seb.arzt" created="Sun, 29 Sep 2019 13:14:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rkarthikeyan&quot; class=&quot;user-hover&quot; rel=&quot;rkarthikeyan&quot;&gt;rkarthikeyan&lt;/a&gt; at a first glace I cannot find back pressure support in the kinesis receiver yet. I think your problem should be investigated independently. I suggest to create a new ticket with instructions to reproduce your findings.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12865156" name="01.png" size="80066" author="seb.arzt" created="Wed, 26 Apr 2017 15:10:24 +0000"/>
                            <attachment id="12865158" name="02.png" size="98613" author="seb.arzt" created="Wed, 26 Apr 2017 15:10:39 +0000"/>
                            <attachment id="12838094" name="GiantBatch2.png" size="217929" author="mapreduced" created="Wed, 9 Nov 2016 00:28:42 +0000"/>
                            <attachment id="12838095" name="GiantBatch3.png" size="295746" author="mapreduced" created="Wed, 9 Nov 2016 00:29:09 +0000"/>
                            <attachment id="12838096" name="Giant_batch_at_23_00.png" size="191972" author="mapreduced" created="Wed, 9 Nov 2016 00:29:38 +0000"/>
                            <attachment id="12838093" name="Look_at_batch_at_22_14.png" size="273237" author="mapreduced" created="Wed, 9 Nov 2016 00:27:59 +0000"/>
                            <attachment id="12980581" name="Screen Shot 2019-09-16 at 12.27.25 PM.png" size="88319" author="rkarthikeyan" created="Wed, 18 Sep 2019 07:28:08 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 7 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i363s7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>