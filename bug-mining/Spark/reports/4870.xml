<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:53:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18406] Race between end-of-task and completion iterator read lock release</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18406</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following log comes from a production streaming job where executors periodically die due to uncaught exceptions during block release:&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;16/11/07 17:11:06 INFO CoarseGrainedExecutorBackend: Got assigned task 7921
16/11/07 17:11:06 INFO Executor: Running task 0.0 in stage 2390.0 (TID 7921)
16/11/07 17:11:06 INFO CoarseGrainedExecutorBackend: Got assigned task 7922
16/11/07 17:11:06 INFO Executor: Running task 1.0 in stage 2390.0 (TID 7922)
16/11/07 17:11:06 INFO CoarseGrainedExecutorBackend: Got assigned task 7923
16/11/07 17:11:06 INFO Executor: Running task 2.0 in stage 2390.0 (TID 7923)
16/11/07 17:11:06 INFO TorrentBroadcast: Started reading broadcast variable 2721
16/11/07 17:11:06 INFO CoarseGrainedExecutorBackend: Got assigned task 7924
16/11/07 17:11:06 INFO Executor: Running task 3.0 in stage 2390.0 (TID 7924)
16/11/07 17:11:06 INFO MemoryStore: Block broadcast_2721_piece0 stored as bytes in memory (estimated size 5.0 KB, free 4.9 GB)
16/11/07 17:11:06 INFO TorrentBroadcast: Reading broadcast variable 2721 took 3 ms
16/11/07 17:11:06 INFO MemoryStore: Block broadcast_2721 stored as values in memory (estimated size 9.4 KB, free 4.9 GB)
16/11/07 17:11:06 INFO BlockManager: Found block rdd_2741_1 locally
16/11/07 17:11:06 INFO BlockManager: Found block rdd_2741_3 locally
16/11/07 17:11:06 INFO BlockManager: Found block rdd_2741_2 locally
16/11/07 17:11:06 INFO BlockManager: Found block rdd_2741_4 locally
16/11/07 17:11:06 INFO PythonRunner: Times: total = 2, boot = -566, init = 567, finish = 1
16/11/07 17:11:06 INFO PythonRunner: Times: total = 7, boot = -540, init = 541, finish = 6
16/11/07 17:11:06 INFO Executor: Finished task 2.0 in stage 2390.0 (TID 7923). 1429 bytes result sent to driver
16/11/07 17:11:06 INFO PythonRunner: Times: total = 8, boot = -532, init = 533, finish = 7
16/11/07 17:11:06 INFO Executor: Finished task 3.0 in stage 2390.0 (TID 7924). 1429 bytes result sent to driver
16/11/07 17:11:06 ERROR Executor: Exception in task 0.0 in stage 2390.0 (TID 7921)
java.lang.AssertionError: assertion failed
	at scala.Predef$.&lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt;(Predef.scala:165)
	at org.apache.spark.storage.BlockInfo.checkInvariants(BlockInfoManager.scala:84)
	at org.apache.spark.storage.BlockInfo.readerCount_$eq(BlockInfoManager.scala:66)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:362)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:361)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:361)
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:356)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at org.apache.spark.storage.BlockInfoManager.releaseAllLocksForTask(BlockInfoManager.scala:356)
	at org.apache.spark.storage.BlockManager.releaseAllLocksForTask(BlockManager.scala:646)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:281)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
16/11/07 17:11:06 INFO CoarseGrainedExecutorBackend: Got assigned task 7925
16/11/07 17:11:06 INFO Executor: Running task 0.1 in stage 2390.0 (TID 7925)
16/11/07 17:11:06 INFO BlockManager: Found block rdd_2741_1 locally
16/11/07 17:11:06 INFO PythonRunner: Times: total = 41, boot = -536, init = 576, finish = 1
16/11/07 17:11:06 INFO Executor: Finished task 1.0 in stage 2390.0 (TID 7922). 1429 bytes result sent to driver
16/11/07 17:11:06 ERROR Utils: Uncaught exception in thread stdout writer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /databricks/python/bin/python
java.lang.AssertionError: assertion failed: Block rdd_2741_1 is not locked &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; reading
	at scala.Predef$.&lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt;(Predef.scala:179)
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:294)
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager$$anonfun$1.apply$mcV$sp(BlockManager.scala:434)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:46)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:35)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1882)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
16/11/07 17:11:06 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[stdout writer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /databricks/python/bin/python,5,main]
java.lang.AssertionError: assertion failed: Block rdd_2741_1 is not locked &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; reading
	at scala.Predef$.&lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt;(Predef.scala:179)
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:294)
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:630)
	at org.apache.spark.storage.BlockManager$$anonfun$1.apply$mcV$sp(BlockManager.scala:434)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:46)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:35)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1882)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think that there&apos;s some sort of internal race condition between a task finishing (TID 7921) and automatically releasing locks and between some &quot;automatically release locks on hitting the end of an iterator&quot; logic running in a separate thread. The log above came from a production streaming job where executors periodically died with this type of error.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13019949">SPARK-18406</key>
            <summary>Race between end-of-task and completion iterator read lock release</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jiangxb1987">Xingbo Jiang</assignee>
                                    <reporter username="joshrosen">Josh Rosen</reporter>
                        <labels>
                    </labels>
                <created>Thu, 10 Nov 2016 21:11:00 +0000</created>
                <updated>Wed, 22 May 2019 02:25:50 +0000</updated>
                            <resolved>Wed, 24 May 2017 07:55:12 +0000</resolved>
                                    <version>2.0.0</version>
                    <version>2.0.1</version>
                                    <fixVersion>2.0.3</fixVersion>
                    <fixVersion>2.1.2</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>Block Manager</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="15830294" author="myjay610" created="Thu, 19 Jan 2017 17:24:10 +0000"  >&lt;p&gt;Similar issue in doing basic RDD operations (like checking for empty RDD&apos;s) within streaming jobs:&lt;/p&gt;

&lt;p&gt;17/01/19 16:43:45 WARN BlockManager: Block input-0-1484840671538 replicated to only 0 peer(s) instead of 1 peers&lt;br/&gt;
17/01/19 16:43:46 WARN MetricsHelper: No metrics scope set in thread RecurringTimer - Kinesis Checkpointer - Worker localhost:65fe618d-c0a7-4fea-b710-0f1b5c6498f2, getMetricsScope returning NullMetricsScope.&lt;br/&gt;
17/01/19 16:44:51 ERROR Executor: Exception in task 0.0 in stage 212.0 (TID 4180)&lt;br/&gt;
java.lang.AssertionError: assertion failed&lt;br/&gt;
	at scala.Predef$.assert(Predef.scala:156)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfo.checkInvariants(BlockInfoManager.scala:84)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfo.readerCount_$eq(BlockInfoManager.scala:66)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:362)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:361)&lt;br/&gt;
	at scala.Option.foreach(Option.scala:257)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:361)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:356)&lt;br/&gt;
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager.releaseAllLocksForTask(BlockInfoManager.scala:356)&lt;br/&gt;
	at org.apache.spark.storage.BlockManager.releaseAllLocksForTask(BlockManager.scala:646)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:281)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
17/01/19 16:44:51 WARN TaskSetManager: Lost task 0.0 in stage 212.0 (TID 4180, localhost): java.lang.AssertionError: assertion failed&lt;br/&gt;
	at scala.Predef$.assert(Predef.scala:156)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfo.checkInvariants(BlockInfoManager.scala:84)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfo.readerCount_$eq(BlockInfoManager.scala:66)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:362)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:361)&lt;br/&gt;
	at scala.Option.foreach(Option.scala:257)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:361)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:356)&lt;br/&gt;
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager.releaseAllLocksForTask(BlockInfoManager.scala:356)&lt;br/&gt;
	at org.apache.spark.storage.BlockManager.releaseAllLocksForTask(BlockManager.scala:646)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:281)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;17/01/19 16:44:51 ERROR TaskSetManager: Task 0 in stage 212.0 failed 1 times; aborting job&lt;br/&gt;
17/01/19 16:44:51 ERROR JobScheduler: Error running job streaming job 1484844270000 ms.0&lt;br/&gt;
org.apache.spark.SparkException: An exception was raised by Python:&lt;br/&gt;
Traceback (most recent call last):&lt;br/&gt;
  File &quot;/root/spark/python/lib/pyspark.zip/pyspark/streaming/util.py&quot;, line 65, in call&lt;br/&gt;
    r = self.func(t, *rdds)&lt;br/&gt;
  File &quot;/root/spark/python/lib/pyspark.zip/pyspark/streaming/dstream.py&quot;, line 159, in &amp;lt;lambda&amp;gt;&lt;br/&gt;
    func = lambda t, rdd: old_func(rdd)&lt;br/&gt;
  File &quot;/root/streamtest.py&quot;, line 519, in multiplex&lt;br/&gt;
    if not flow_rdd.isEmpty():&lt;br/&gt;
  File &quot;/root/spark/python/lib/pyspark.zip/pyspark/rdd.py&quot;, line 1343, in isEmpty&lt;br/&gt;
    return self.getNumPartitions() == 0 or len(self.take(1)) == 0&lt;br/&gt;
  File &quot;/root/spark/python/lib/pyspark.zip/pyspark/rdd.py&quot;, line 1310, in take&lt;br/&gt;
    res = self.context.runJob(self, takeUpToNumLeft, p)&lt;br/&gt;
  File &quot;/root/spark/python/lib/pyspark.zip/pyspark/context.py&quot;, line 933, in runJob&lt;br/&gt;
    port = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)&lt;br/&gt;
  File &quot;/root/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py&quot;, line 1133, in _&lt;em&gt;call&lt;/em&gt;_&lt;br/&gt;
    answer, self.gateway_client, self.target_id, self.name)&lt;br/&gt;
  File &quot;/root/spark/python/lib/pyspark.zip/pyspark/sql/utils.py&quot;, line 63, in deco&lt;br/&gt;
    return f(*a, **kw)&lt;br/&gt;
  File &quot;/root/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py&quot;, line 319, in get_return_value&lt;br/&gt;
    format(target_id, &quot;.&quot;, name), value)&lt;br/&gt;
Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.&lt;/p&gt;</comment>
                            <comment id="15969384" author="yxiao" created="Fri, 14 Apr 2017 18:51:17 +0000"  >&lt;p&gt;The same JIRA is found under &lt;a href=&quot;https://issues-test.apache.org/jira/browse/SPARK-18406&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues-test.apache.org/jira/browse/SPARK-18406&lt;/a&gt;.&lt;br/&gt;
Same issue observed in spark 2.1.0 as well.&lt;/p&gt;

&lt;p&gt;The issue is observed on some simple spark query that compiles into 3 stages. I have some custom RDD being used in this case, and it is registered for persistence. In the compute() method of the custom RDD, I spawn a new thread to compute the data in the background, and then immediately return an abstract iterator (wrapped under a InterruptibleIterator) that gets data from the background computation on demand. The assertion happens when iterator of the parent RDD reaches the end of the data. This issue doesn&apos;t always happen when the custom RDD is used in the query, regardless being used once or multiple times.&lt;/p&gt;

&lt;p&gt;The issue is related to the new thread I created which accesses data from the input iterator of parent RDD. The new thread is missing the TSS(thread-specific-storage) for TaskContext. I see BlockInfoManager is using this TSS TaskContext as key to search the storage.&lt;/p&gt;

&lt;p&gt;Here is log showing the task ID being unset in this thread: Line 1819: 2017/04/13 15:01:01.674 &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-33&amp;#93;&lt;/span&gt;: TRACE storage.BlockInfoManager: Task -1024 releasing lock for rdd_25_0&lt;/p&gt;

&lt;p&gt;However, I have no way to set TSS for my thread now because the method is made protected as below:&lt;br/&gt;
object TaskContext {&lt;br/&gt;
 ...&lt;br/&gt;
private&lt;span class=&quot;error&quot;&gt;&amp;#91;this&amp;#93;&lt;/span&gt; val taskContext: ThreadLocal&lt;span class=&quot;error&quot;&gt;&amp;#91;TaskContext&amp;#93;&lt;/span&gt; = new ThreadLocal&lt;span class=&quot;error&quot;&gt;&amp;#91;TaskContext&amp;#93;&lt;/span&gt;&lt;br/&gt;
// Note: protected&lt;span class=&quot;error&quot;&gt;&amp;#91;spark&amp;#93;&lt;/span&gt; instead of private&lt;span class=&quot;error&quot;&gt;&amp;#91;spark&amp;#93;&lt;/span&gt; to prevent the following two from&lt;br/&gt;
 // showing up in JavaDoc.&lt;br/&gt;
 /** Set the thread local TaskContext. Internal to Spark. */&lt;br/&gt;
 protected&lt;span class=&quot;error&quot;&gt;&amp;#91;spark&amp;#93;&lt;/span&gt; def setTaskContext(tc: TaskContext): Unit = taskContext.set(tc)&lt;/p&gt;

&lt;p&gt;Just to confirm my theory, I made the TaskContext.setTaskContext public, and called it in the beginning of my thread. The use cases that were failing consistently with assertion on lock-release now run successful in all scenarios I have tried, which include having different number of src/shuffle partitions, number of executors, async vs. sequential execution (for having multiple downstream custom RDDs pulling data from upstream RDD).&lt;/p&gt;</comment>
                            <comment id="15970235" author="joshrosen" created="Sun, 16 Apr 2017 04:33:08 +0000"  >&lt;p&gt;I can see how allowing user-level code to call setTaskContext() can fix this issue but it&apos;s not ideal because it still places the burden on the end users to call the setTaskContext() method in their code.&lt;/p&gt;

&lt;p&gt;Instead, I think a cleaner fix would be to have the CompletionIterator record the task ID when it&apos;s instantiated so that the same task ID can be used even if the completion occurs in a different thread (the idea is to reduce our reliance on thread locals: there are reasons why we couldn&apos;t completely remove them (API changes), but there are parts of the internals where we can propagate more efficiently).&lt;/p&gt;

&lt;p&gt;To move forward here, my suggestion is that we write a failing regression test based on the description provided by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yxiao&quot; class=&quot;user-hover&quot; rel=&quot;yxiao&quot;&gt;yxiao&lt;/a&gt;, then experiment on my suggested approach of more explicit threading of task ids into closeable objects when they&apos;re first created.&lt;/p&gt;

&lt;p&gt;I&apos;m on vacation this week and won&apos;t be able to help with this until Monday, April 24th, so someone else will need to help / review if this is urgent.&lt;/p&gt;</comment>
                            <comment id="15970496" author="yxiao" created="Sun, 16 Apr 2017 19:16:59 +0000"  >&lt;p&gt;Thanks Josh for the quick response!&lt;br/&gt;
This issue is critical to my company&apos;s use cases, where for the purpose of performance we have to use custom RDD to take input from multiple parent RDDs, and use existing computation logic (in a black box) in the background to pull the result.&lt;/p&gt;</comment>
                            <comment id="16022067" author="apachespark" created="Tue, 23 May 2017 23:24:04 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18076&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18076&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16022077" author="yxiao" created="Tue, 23 May 2017 23:29:36 +0000"  >&lt;p&gt;Thanks for the fix. What spark release will have it?&lt;br/&gt;
Can we get a patch on top of spark 2.1.0?&lt;/p&gt;</comment>
                            <comment id="16022477" author="cloud_fan" created="Wed, 24 May 2017 07:55:30 +0000"  >&lt;p&gt;we will backport this to 2.1 and 2.0 later&lt;/p&gt;</comment>
                            <comment id="16023462" author="apachespark" created="Wed, 24 May 2017 19:06:03 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18096&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18096&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16023759" author="apachespark" created="Wed, 24 May 2017 21:54:03 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18099&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18099&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16113702" author="taichi.sano" created="Thu, 3 Aug 2017 23:38:25 +0000"  >&lt;p&gt;Hello,&lt;br/&gt;
I am experiencing an issue very similar to this. I am currently trying to do a groupByKeyAndWindow() with batch size of 1, window size of 80, and shift size of 1 from data that is being streamed from Kafka (ver 0.10) with Direct Streaming. Every once in a while, I encounter the AssertionError like so:&lt;/p&gt;

&lt;p&gt;17/08/03 22:32:19 ERROR org.apache.spark.executor.Executor: Exception in task 0.0 in stage 20936.0 (TID 4409)&lt;br/&gt;
java.lang.AssertionError: assertion failed&lt;br/&gt;
	at scala.Predef$.assert(Predef.scala:156)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfo.checkInvariants(BlockInfoManager.scala:84)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfo.readerCount_$eq(BlockInfoManager.scala:66)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:367)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:366)&lt;br/&gt;
	at scala.Option.foreach(Option.scala:257)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:366)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:361)&lt;br/&gt;
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager.releaseAllLocksForTask(BlockInfoManager.scala:361)&lt;br/&gt;
	at org.apache.spark.storage.BlockManager.releaseAllLocksForTask(BlockManager.scala:736)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:342)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
17/08/03 22:32:19 ERROR org.apache.spark.executor.Executor: Exception in task 0.1 in stage 20936.0 (TID 4410)&lt;br/&gt;
java.lang.AssertionError: assertion failed&lt;br/&gt;
	at scala.Predef$.assert(Predef.scala:156)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfo.checkInvariants(BlockInfoManager.scala:84)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfo.readerCount_$eq(BlockInfoManager.scala:66)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:367)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2$$anonfun$apply$2.apply(BlockInfoManager.scala:366)&lt;br/&gt;
	at scala.Option.foreach(Option.scala:257)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:366)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager$$anonfun$releaseAllLocksForTask$2.apply(BlockInfoManager.scala:361)&lt;br/&gt;
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager.releaseAllLocksForTask(BlockInfoManager.scala:361)&lt;br/&gt;
	at org.apache.spark.storage.BlockManager.releaseAllLocksForTask(BlockManager.scala:736)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:342)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
17/08/03 22:32:19 ERROR org.apache.spark.util.Utils: Uncaught exception in thread stdout writer for /opt/conda/bin/python&lt;br/&gt;
java.lang.AssertionError: assertion failed: Block rdd_30291_0 is not locked for reading&lt;br/&gt;
	at scala.Predef$.assert(Predef.scala:170)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:299)&lt;br/&gt;
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:720)&lt;br/&gt;
	at org.apache.spark.storage.BlockManager$$anonfun$1.apply$mcV$sp(BlockManager.scala:516)&lt;br/&gt;
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:46)&lt;br/&gt;
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:35)&lt;br/&gt;
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)&lt;br/&gt;
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)&lt;br/&gt;
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:509)&lt;br/&gt;
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:333)&lt;br/&gt;
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)&lt;br/&gt;
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)&lt;br/&gt;
17/08/03 22:32:19 ERROR org.apache.spark.util.SparkUncaughtExceptionHandler: Uncaught exception in thread Thread&lt;span class=&quot;error&quot;&gt;&amp;#91;stdout writer for /opt/conda/bin/python,5,main&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.lang.AssertionError: assertion failed: Block rdd_30291_0 is not locked for reading&lt;br/&gt;
	at scala.Predef$.assert(Predef.scala:170)&lt;br/&gt;
	at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:299)&lt;br/&gt;
	at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:720)&lt;br/&gt;
	at org.apache.spark.storage.BlockManager$$anonfun$1.apply$mcV$sp(BlockManager.scala:516)&lt;br/&gt;
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:46)&lt;br/&gt;
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:35)&lt;br/&gt;
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)&lt;br/&gt;
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)&lt;br/&gt;
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:509)&lt;br/&gt;
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:333)&lt;br/&gt;
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)&lt;br/&gt;
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)&lt;/p&gt;

&lt;p&gt;which also kills the executor. Sometimes a new executor is spawned to pick up where the dead executor left off but sometimes the whole Spark job also crashes due to this error. I&apos;m running version 2.2.0 on Google Dataproc on a single node cluster. &lt;/p&gt;</comment>
                            <comment id="16169586" author="hadoopqa" created="Mon, 18 Sep 2017 05:00:00 +0000"  >
&lt;p&gt;    [ &lt;a href=&quot;https://issues-test.apache.org/jira/browse/SPARK-18406?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=16167180#comment-16167180&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues-test.apache.org/jira/browse/SPARK-18406?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=16167180#comment-16167180&lt;/a&gt; ] &lt;/p&gt;

&lt;p&gt;Yongqin Xiao commented on &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-18406&quot; title=&quot;Race between end-of-task and completion iterator read lock release&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-18406&quot;&gt;&lt;del&gt;SPARK-18406&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
--------------------------------------&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;, I see there are 3 check-ins for this issue, touching multiple files. You mentioned the fix will be backport to spark2.1.0. Can you let me know which single submission in spark2.1.0 will address the issue?&lt;br/&gt;
The reason I am asking is that my company may not update spark version to 2.2 very soon, I will have to port your fix to our company&apos;s version of spark 2.1.0 and 2.0.1. I cannot just use latest spark 2.1.0 even after you backport the fix because we have other patches on top of spark 2.1.0, some were fixed by ourselves.&lt;br/&gt;
Thanks for your help.&lt;/p&gt;




&lt;p&gt;&amp;#8211;&lt;br/&gt;
This message was sent by Atlassian JIRA&lt;br/&gt;
(v6.4.14#64029)&lt;/p&gt;

&lt;p&gt;---------------------------------------------------------------------&lt;br/&gt;
To unsubscribe, e-mail: issues-unsubscribe@spark.apache.org&lt;br/&gt;
For additional commands, e-mail: issues-help@spark.apache.org&lt;/p&gt;
</comment>
                            <comment id="16169661" author="hadoopqa" created="Mon, 18 Sep 2017 06:56:00 +0000"  >
&lt;p&gt;    [ &lt;a href=&quot;https://issues-test.apache.org/jira/browse/SPARK-18406?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=16167181#comment-16167181&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues-test.apache.org/jira/browse/SPARK-18406?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&amp;amp;focusedCommentId=16167181#comment-16167181&lt;/a&gt; ] &lt;/p&gt;

&lt;p&gt;Wenchen Fan commented on &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-18406&quot; title=&quot;Race between end-of-task and completion iterator read lock release&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-18406&quot;&gt;&lt;del&gt;SPARK-18406&lt;/del&gt;&lt;/a&gt;:&lt;br/&gt;
-------------------------------------&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/18099&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18099&lt;/a&gt; is the PR that backported the fix to 2.1&lt;/p&gt;




&lt;p&gt;&amp;#8211;&lt;br/&gt;
This message was sent by Atlassian JIRA&lt;br/&gt;
(v6.4.14#64029)&lt;/p&gt;

&lt;p&gt;---------------------------------------------------------------------&lt;br/&gt;
To unsubscribe, e-mail: issues-unsubscribe@spark.apache.org&lt;br/&gt;
For additional commands, e-mail: issues-help@spark.apache.org&lt;/p&gt;
</comment>
                            <comment id="16254839" author="david_zhang" created="Thu, 16 Nov 2017 06:51:05 +0000"  >&lt;p&gt;we still find this issue in Spark 2.2,  I check this case change code and find spark version 2.2 contain these change. but our error log:&lt;br/&gt;
17/11/03 08:00:10 ERROR Utils: Uncaught exception in thread stdout writer for python&lt;br/&gt;
java.lang.AssertionError: assertion failed: Block input-0-1508745006978 is not locked for reading&lt;br/&gt;
at scala.Predef$.assert(Predef.scala:170)&lt;br/&gt;
at org.apache.spark.storage.BlockInfoManager.unlock(BlockInfoManager.scala:299)&lt;br/&gt;
at org.apache.spark.storage.BlockManager.releaseLock(BlockManager.scala:720)&lt;br/&gt;
at org.apache.spark.storage.BlockManager$$anonfun$1.apply$mcV$sp(BlockManager.scala:516)&lt;br/&gt;
at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:46)&lt;br/&gt;
at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:35)&lt;br/&gt;
at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
at org.apache.spark.util.CompletionIterator.foreach(CompletionIterator.scala:26)&lt;br/&gt;
at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:509)&lt;br/&gt;
at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:333)&lt;br/&gt;
at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954)&lt;br/&gt;
at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)&lt;/p&gt;</comment>
                            <comment id="16830770" author="jiangxb1987" created="Wed, 1 May 2019 00:12:19 +0000"  >&lt;p&gt;This problem still exists in PythonRunner, since python side uses a pre-fetch model to consume the upstream data, and open another thread to serve output data to downstream operators, thus it&apos;s possible the Task finishes first and trigger the task cleanup logic, and then the CompletionIterator try to release the write lock it holds on some blocks and found the lock has already been released. I&apos;ll submit a PR to bypass the issue later.&lt;/p&gt;</comment>
                            <comment id="16834276" author="apachespark" created="Mon, 6 May 2019 23:39:10 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24542&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24542&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16834277" author="apachespark" created="Mon, 6 May 2019 23:39:26 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24542&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24542&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16835339" author="apachespark" created="Wed, 8 May 2019 06:13:40 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24552&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24552&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16845431" author="apachespark" created="Wed, 22 May 2019 02:25:50 +0000"  >&lt;p&gt;User &apos;rezasafi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24670&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24670&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13179513">SPARK-25139</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 25 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3671j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>