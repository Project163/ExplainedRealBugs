<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:53:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17914] Spark SQL casting to TimestampType with nanosecond results in incorrect timestamp</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17914</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;In some cases when timestamps contain nanoseconds they will be parsed incorrectly. &lt;/p&gt;

&lt;p&gt;Examples: &lt;/p&gt;

&lt;p&gt;&quot;2016-05-14T15:12:14.0034567Z&quot; -&amp;gt; &quot;2016-05-14 15:12:14.034567&quot;&lt;br/&gt;
&quot;2016-05-14T15:12:14.000345678Z&quot; -&amp;gt; &quot;2016-05-14 15:12:14.345678&quot;&lt;/p&gt;

&lt;p&gt;The issue seems to be happening in DateTimeUtils.stringToTimestamp(). It assumes that only 6 digit fraction of a second will be passed.&lt;/p&gt;

&lt;p&gt;With this being the case I would suggest either discarding nanoseconds automatically, or throw an exception prompting to pre-format timestamps to microsecond precision first before casting to the Timestamp.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13012079">SPARK-17914</key>
            <summary>Spark SQL casting to TimestampType with nanosecond results in incorrect timestamp</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="aokolnychyi">Anton Okolnychyi</assignee>
                                    <reporter username="oromankova@cardlytics.com">Oksana Romankova</reporter>
                        <labels>
                    </labels>
                <created>Thu, 13 Oct 2016 17:36:05 +0000</created>
                <updated>Mon, 16 Nov 2020 10:31:14 +0000</updated>
                            <resolved>Mon, 12 Jun 2017 20:08:26 +0000</resolved>
                                    <version>1.6.1</version>
                                    <fixVersion>2.2.0</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="15572730" author="srowen" created="Thu, 13 Oct 2016 18:09:05 +0000"  >&lt;p&gt;I think this is a duplicate of one of a couple possible issues, like &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-14428&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-14428&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15572758" author="oromankova@cardlytics.com" created="Thu, 13 Oct 2016 18:17:11 +0000"  >&lt;p&gt;You are correct. It is related to what has been proposed in &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-14428&quot; title=&quot;[SQL] Allow more flexibility when parsing dates and timestamps in json datasources&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-14428&quot;&gt;&lt;del&gt;SPARK-14428&lt;/del&gt;&lt;/a&gt;. However, current behavior is defective. If &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-14428&quot; title=&quot;[SQL] Allow more flexibility when parsing dates and timestamps in json datasources&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-14428&quot;&gt;&lt;del&gt;SPARK-14428&lt;/del&gt;&lt;/a&gt; is not going to be approved to be supported, then at least the defect deserves  consideration to be addressed. &lt;/p&gt;</comment>
                            <comment id="15572885" author="srowen" created="Thu, 13 Oct 2016 19:09:51 +0000"  >&lt;p&gt;Does the ISO8601 format support nanoseconds even? I thought we had a discussion about it but don&apos;t recall the conclusion&lt;/p&gt;</comment>
                            <comment id="15572957" author="oromankova@cardlytics.com" created="Thu, 13 Oct 2016 19:41:44 +0000"  >&lt;p&gt;Sean, I can&apos;t find any evidence of ISO8601 not supporting nanoseconds. All it says that it supports fraction of a second that should be supplied following comma or dot. Different parsing libraries that support ISO8601 have different precision limitations. For instance in Python, datetime.strptime() only supports precision down to microseconds and will throw an exception if nanoseconds were supplied in input string. While it may not be ideal for those who need to be able to retain nanosecond precision after parsing, it is an acceptable behavior. Those who do not need to retain nanosecond precision can catch, or, preemptively, truncate input string. Spark sql DateTimeUtils.stringToTimestamp() doesn&apos;t throw, and doesn&apos;t truncate properly, which results in incorrect timestamp. In the example above, the acceptable truncation would be:&lt;/p&gt;

&lt;p&gt;&quot;2016-05-14T15:12:14.0034567Z&quot; -&amp;gt; &quot;2016-05-14 15:12:14.003456&quot;&lt;br/&gt;
&quot;2016-05-14T15:12:14.000345678Z&quot; -&amp;gt; &quot;2016-05-14 15:12:14.000345&quot;&lt;/p&gt;</comment>
                            <comment id="16044350" author="apachespark" created="Fri, 9 Jun 2017 12:00:05 +0000"  >&lt;p&gt;User &apos;aokolnychyi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18252&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16047004" author="ueshin" created="Mon, 12 Jun 2017 20:08:26 +0000"  >&lt;p&gt;Issue resolved by pull request 18252&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18252&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18252&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16750292" author="cchandurkar" created="Wed, 23 Jan 2019 18:19:15 +0000"  >&lt;p&gt;I&apos;m still seeing this issue in Spark 2.4.0 when using from_json() function. In&#160;ISO Zulu format datetime, it is not interpreting the timezone accurately after certain number of digits. Every digit added after 3rd digit in the timestamp is adding up more seconds to the parsed datetime.&#8194;&#8194;For example, This datetime: &quot;2019-01-23T17:50:29.9991Z&quot; when parsed using spark&apos;s build-in from_json() function results in &quot;2019-01-23T17:50:38.991+0000&quot; ( Note the number of seconds added )&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;If I&apos;m not wrong from_json() internally uses the Jackson JSON library. I&apos;m not sure if the bug is within that or within spark.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// Create Schema to Parse JSON
&lt;/span&gt;val sc = StructType(
  StructField(
   &lt;span class=&quot;code-quote&quot;&gt;&quot;date&quot;&lt;/span&gt;, TimestampType
  ):: Nil
)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// Sample JSON Parsing using schema created
&lt;/span&gt;Seq( &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;{&quot;&lt;/span&gt;date&lt;span class=&quot;code-quote&quot;&gt;&quot;: &quot;&lt;/span&gt;2019-01-22T18:33:39.134232733Z&lt;span class=&quot;code-quote&quot;&gt;&quot;}&quot;&lt;/span&gt;&quot;&quot; )
.toDF( &lt;span class=&quot;code-quote&quot;&gt;&quot;data&quot;&lt;/span&gt; )
.withColumn( &lt;span class=&quot;code-quote&quot;&gt;&quot;parsed&quot;&lt;/span&gt;, from_json( $&lt;span class=&quot;code-quote&quot;&gt;&quot;data&quot;&lt;/span&gt;, sc ) )
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This results in date being &quot;2019-01-24T07:50:51.733+0000&quot; ( Note the difference of 2 days )&#160;&lt;/p&gt;</comment>
                            <comment id="16801795" author="jurriaanpruis" created="Tue, 26 Mar 2019 14:35:12 +0000"  >&lt;p&gt;I&apos;m also seeing this issue where the millisecond part &apos;overflows&apos; into the rest of the timestamp in Spark 2.4.0 as described in the comment above. To me it seems like this issue isn&apos;t resolved yet. cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ueshin&quot; class=&quot;user-hover&quot; rel=&quot;ueshin&quot;&gt;ueshin&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16950932" author="agattiker" created="Mon, 14 Oct 2019 11:35:44 +0000"  >&lt;p&gt;As reported by other commenters, the issue is still outstanding with from_json in Spark 2.4.3 (Azure Databricks 5.5 LTS):&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;sc.parallelize(List(&quot;2019-10-14T&lt;font color=&quot;#00875a&quot;&gt;09:39&lt;/font&gt;:07.3220000Z&quot;)).toDF&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;.select(&apos;value.cast(&quot;timestamp&quot;))&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;// 2019-10-14T&lt;font color=&quot;#00875a&quot;&gt;09:39&lt;/font&gt;:07.322+0000&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;// correct time parsing outside of from_json&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;val schema = StructType(StructField(&quot;a&quot;, TimestampType, false) :: Nil)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;sc.parallelize(List(&quot;&quot;&quot;{&quot;a&quot;:&quot;2019-10-14T&lt;/tt&gt;&lt;font color=&quot;#00875a&quot;&gt;&lt;tt&gt;09:39&lt;/tt&gt;&lt;/font&gt;&lt;tt&gt;:07.3220000Z&quot;}&quot;&quot;&quot;)).toDF&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;.select(from_json(&apos;value, schema))&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;// {&quot;a&quot;:&quot;2019-10-14T&lt;font color=&quot;#de350b&quot;&gt;10:32&lt;/font&gt;:47.000+0000&quot;&lt;/tt&gt;}&lt;br/&gt;
&lt;tt&gt;// wrong time, corresponds to 09:39+3220 seconds&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;val schema = StructType(StructField(&quot;a&quot;, TimestampType, false) :: Nil)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;sc.parallelize(List(&quot;&quot;&quot;{&quot;a&quot;:&quot;2019-10-14T&lt;font color=&quot;#00875a&quot;&gt;09:39&lt;/font&gt;:322000Z&quot;}&quot;&quot;&quot;)).toDF&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;.select(from_json(&apos;value, schema))&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;// {&quot;a&quot;:&quot;2019-10-14T&lt;font color=&quot;#de350b&quot;&gt;09:44&lt;/font&gt;:29.000+0000&quot;&lt;/tt&gt;}&lt;br/&gt;
&lt;tt&gt;// wrong time, corresponds to 09:39+322 seconds&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;val schema = StructType(StructField(&quot;a&quot;, TimestampType, false) :: Nil)&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;sc.parallelize(List(&quot;&quot;&quot;{&quot;a&quot;:&quot;2019-10-14T&lt;font color=&quot;#00875a&quot;&gt;09:39&lt;/font&gt;:322Z&quot;}&quot;&quot;&quot;)).toDF&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;.select(from_json(&apos;value, schema))&lt;/tt&gt;&lt;br/&gt;
&lt;tt&gt;// {&quot;a&quot;:&quot;2019-10-14T&lt;font color=&quot;#00875a&quot;&gt;09:39&lt;/font&gt;:07.322+0000&quot;&lt;/tt&gt;}&lt;br/&gt;
&lt;tt&gt;// correct time&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="17232671" author="pcocko" created="Mon, 16 Nov 2020 10:31:14 +0000"  >&lt;p&gt;I think that the solution only apply if there are more than 6 digits as miliseconds.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/18252/commits/2f232a7bda28fb42759ee35923044f886a1ff19e&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18252/commits/2f232a7bda28fb42759ee35923044f886a1ff19e&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12956474">SPARK-14428</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i34ulz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>