<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:41 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26576] Broadcast hint not applied to partitioned table</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26576</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Broadcast hint is not applied to partitioned Parquet table.&#160;Below &quot;SortMergeJoin&quot; is chosen incorrectly and &quot;ResolvedHit(broadcast)&quot; is removed in Optimized Plan.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; spark.sql(&quot;CREATE TABLE jzhuge.parquet_with_part (val STRING) PARTITIONED BY (dateint INT) STORED AS parquet&quot;)

scala&amp;gt; spark.conf.set(&quot;spark.sql.autoBroadcastJoinThreshold&quot;, &quot;-1&quot;)

scala&amp;gt; Seq(spark.table(&quot;jzhuge.parquet_with_part&quot;)).map(df =&amp;gt; df.join(broadcast(df), &quot;dateint&quot;).explain(true))

== Parsed Logical Plan ==
&apos;Join UsingJoin(Inner,List(dateint))
:- SubqueryAlias `jzhuge`.`parquet_with_part`
:  +- Relation[val#28,dateint#29] parquet
+- ResolvedHint (broadcast)
   +- SubqueryAlias `jzhuge`.`parquet_with_part`
      +- Relation[val#32,dateint#33] parquet

== Analyzed Logical Plan ==
dateint: int, val: string, val: string
Project [dateint#29, val#28, val#32]
+- Join Inner, (dateint#29 = dateint#33)
   :- SubqueryAlias `jzhuge`.`parquet_with_part`
   :  +- Relation[val#28,dateint#29] parquet
   +- ResolvedHint (broadcast)
      +- SubqueryAlias `jzhuge`.`parquet_with_part`
         +- Relation[val#32,dateint#33] parquet

== Optimized Logical Plan ==
Project [dateint#29, val#28, val#32]
+- Join Inner, (dateint#29 = dateint#33)
   :- Project [val#28, dateint#29]
   :  +- Filter isnotnull(dateint#29)
   :     +- Relation[val#28,dateint#29] parquet
   +- Project [val#32, dateint#33]
      +- Filter isnotnull(dateint#33)
         +- Relation[val#32,dateint#33] parquet

== Physical Plan ==
*(5) Project [dateint#29, val#28, val#32]
+- *(5) SortMergeJoin [dateint#29], [dateint#33], Inner
   :- *(2) Sort [dateint#29 ASC NULLS FIRST], false, 0
   :  +- Exchange(coordinator id: 55629191) hashpartitioning(dateint#29, 500), coordinator[target post-shuffle partition size: 67108864]
   :     +- *(1) FileScan parquet jzhuge.parquet_with_part[val#28,dateint#29] Batched: true, Format: Parquet, Location: PrunedInMemoryFileIndex[], PartitionCount: 0, PartitionFilters: [isnotnull(dateint#29)], PushedFilters: [], ReadSchema: struct&amp;lt;val:string&amp;gt;
   +- *(4) Sort [dateint#33 ASC NULLS FIRST], false, 0
      +- ReusedExchange [val#32, dateint#33], Exchange(coordinator id: 55629191) hashpartitioning(dateint#29, 500), coordinator[target post-shuffle partition size: 67108864]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Broadcast hint is applied to Parquet table without partition. Below &quot;BroadcastHashJoin&quot; is chosen as expected.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; spark.sql(&quot;CREATE TABLE jzhuge.parquet_no_part (val STRING, dateint INT) STORED AS parquet&quot;)

scala&amp;gt; spark.conf.set(&quot;spark.sql.autoBroadcastJoinThreshold&quot;, &quot;-1&quot;)

scala&amp;gt; Seq(spark.table(&quot;jzhuge.parquet_no_part&quot;)).map(df =&amp;gt; df.join(broadcast(df), &quot;dateint&quot;).explain(true))

== Parsed Logical Plan ==
&apos;Join UsingJoin(Inner,List(dateint))
:- SubqueryAlias `jzhuge`.`parquet_no_part`
:  +- Relation[val#44,dateint#45] parquet
+- ResolvedHint (broadcast)
   +- SubqueryAlias `jzhuge`.`parquet_no_part`
      +- Relation[val#50,dateint#51] parquet

== Analyzed Logical Plan ==
dateint: int, val: string, val: string
Project [dateint#45, val#44, val#50]
+- Join Inner, (dateint#45 = dateint#51)
   :- SubqueryAlias `jzhuge`.`parquet_no_part`
   :  +- Relation[val#44,dateint#45] parquet
   +- ResolvedHint (broadcast)
      +- SubqueryAlias `jzhuge`.`parquet_no_part`
         +- Relation[val#50,dateint#51] parquet

== Optimized Logical Plan ==
Project [dateint#45, val#44, val#50]
+- Join Inner, (dateint#45 = dateint#51)
   :- Filter isnotnull(dateint#45)
   :  +- Relation[val#44,dateint#45] parquet
   +- ResolvedHint (broadcast)
      +- Filter isnotnull(dateint#51)
         +- Relation[val#50,dateint#51] parquet

== Physical Plan ==
*(2) Project [dateint#45, val#44, val#50]
+- *(2) BroadcastHashJoin [dateint#45], [dateint#51], Inner, BuildRight
   :- *(2) Project [val#44, dateint#45]
   :  +- *(2) Filter isnotnull(dateint#45)
   :     +- *(2) FileScan parquet jzhuge.parquet_no_part[val#44,dateint#45] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [IsNotNull(dateint)], ReadSchema: struct&amp;lt;val:string,dateint:int&amp;gt;
   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)))
      +- *(1) Project [val#50, dateint#51]
         +- *(1) Filter isnotnull(dateint#51)
            +- *(1) FileScan parquet jzhuge.parquet_no_part[val#50,dateint#51] Batched: true, Format: Parquet, Location: InMemoryFileIndex[...], PartitionFilters: [], PushedFilters: [IsNotNull(dateint)], ReadSchema: struct&amp;lt;val:string,dateint:int&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Observed similar issue with partitioned Orc table. SequenceFile is fine.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13208453">SPARK-26576</key>
            <summary>Broadcast hint not applied to partitioned table</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jzhuge">John Zhuge</assignee>
                                    <reporter username="jzhuge">John Zhuge</reporter>
                        <labels>
                    </labels>
                <created>Wed, 9 Jan 2019 02:17:53 +0000</created>
                <updated>Mon, 18 Feb 2019 06:13:39 +0000</updated>
                            <resolved>Fri, 11 Jan 2019 17:23:45 +0000</resolved>
                                    <version>2.2.2</version>
                    <version>2.3.2</version>
                    <version>2.4.0</version>
                                    <fixVersion>2.4.1</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16737765" author="jzhuge" created="Wed, 9 Jan 2019 02:28:07 +0000"  >&lt;p&gt;The &quot;ResolvedHint&quot; node is removed by the following code introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-14581&quot; title=&quot;Improve filter push down&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-14581&quot;&gt;&lt;del&gt;SPARK-14581&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;PhysicalOperation.collectProjectsAndFilters&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; h: ResolvedHint =&amp;gt;
  collectProjectsAndFilters(h.child)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;, What scenario does the above code&#160;try to cover? Is there any unit test covering this code path?&lt;/p&gt;</comment>
                            <comment id="16737769" author="cloud_fan" created="Wed, 9 Jan 2019 02:33:36 +0000"  >&lt;p&gt;can you reproduce it with the master branch? There is a major refactor on master branch about how to deal with `ResolvedHint`.&lt;/p&gt;</comment>
                            <comment id="16737964" author="jzhuge" created="Wed, 9 Jan 2019 08:20:38 +0000"  >&lt;p&gt;No issue on the master branch. Please note &quot;rightHint=(broadcast)&quot; for the Join in Optimized Plan.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; Seq(spark.table(&quot;jzhuge.parquet_with_part&quot;)).map(df =&amp;gt; df.join(broadcast(df), &quot;dateint&quot;).explain(true))

== Parsed Logical Plan ==
&apos;Join UsingJoin(Inner,List(dateint))
:- SubqueryAlias `jzhuge`.`parquet_with_part`
:  +- Relation[val#34,dateint#35] parquet
+- ResolvedHint (broadcast)
   +- SubqueryAlias `jzhuge`.`parquet_with_part`
      +- Relation[val#40,dateint#41] parquet

== Analyzed Logical Plan ==
dateint: int, val: string, val: string
Project [dateint#35, val#34, val#40]
+- Join Inner, (dateint#35 = dateint#41)
   :- SubqueryAlias `jzhuge`.`parquet_with_part`
   :  +- Relation[val#34,dateint#35] parquet
   +- ResolvedHint (broadcast)
      +- SubqueryAlias `jzhuge`.`parquet_with_part`
         +- Relation[val#40,dateint#41] parquet

== Optimized Logical Plan ==
Project [dateint#35, val#34, val#40]
+- Join Inner, (dateint#35 = dateint#41), rightHint=(broadcast)
   :- Project [val#34, dateint#35]
   :  +- Filter isnotnull(dateint#35)
   :     +- Relation[val#34,dateint#35] parquet
   +- Project [val#40, dateint#41]
      +- Filter isnotnull(dateint#41)
         +- Relation[val#40,dateint#41] parquet

== Physical Plan ==
*(2) Project [dateint#35, val#34, val#40]
+- *(2) BroadcastHashJoin [dateint#35], [dateint#41], Inner, BuildRight
   :- *(2) FileScan parquet jzhuge.parquet_with_part[val#34,dateint#35] Batched: true, DataFilters: [], Format: Parquet, Location: PrunedInMemoryFileIndex[], PartitionCount: 0, PartitionFilters: [isnotnull(dateint#35)], PushedFilters: [], ReadSchema: struct&amp;lt;val:string&amp;gt;
   +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)))
      +- *(1) FileScan parquet jzhuge.parquet_with_part[val#40,dateint#41] Batched: true, DataFilters: [], Format: Parquet, Location: PrunedInMemoryFileIndex[], PartitionCount: 0, PartitionFilters: [isnotnull(dateint#41)], PushedFilters: [], ReadSchema: struct&amp;lt;val:string&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;From a quick look at the source, EliminateResolvedHint pulls broadcast hint into Join and eliminates the ResolvedHint node. It is called before PruneFileSourcePartitions so the above code in PhysicalOperation.collectProjectsAndFilters is&#160;never called on master branch for the few cases I tried.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13208936">SPARK-26599</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 44 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|u00nh4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>