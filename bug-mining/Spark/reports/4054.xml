<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:47:34 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17512] Specifying remote files for Python based Spark jobs in Yarn cluster mode not working</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17512</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When I run a python application, and specify a remote path for the extra files to be included in the PYTHON_PATH using the &apos;--py-files&apos; or &apos;spark.submit.pyFiles&apos; configuration option in YARN Cluster mode I get the following error:&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: Launching Python applications through spark-submit is currently only supported for local files: s3://xxxx/app.py&lt;br/&gt;
at org.apache.spark.deploy.PythonRunner$.formatPath(PythonRunner.scala:104)&lt;br/&gt;
at org.apache.spark.deploy.PythonRunner$$anonfun$formatPaths$3.apply(PythonRunner.scala:136)&lt;br/&gt;
at org.apache.spark.deploy.PythonRunner$$anonfun$formatPaths$3.apply(PythonRunner.scala:136)&lt;br/&gt;
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&lt;br/&gt;
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)&lt;br/&gt;
at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)&lt;br/&gt;
at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)&lt;br/&gt;
at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)&lt;br/&gt;
at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)&lt;br/&gt;
at org.apache.spark.deploy.PythonRunner$.formatPaths(PythonRunner.scala:136)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$10.apply(SparkSubmit.scala:636)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$10.apply(SparkSubmit.scala:634)&lt;br/&gt;
at scala.Option.foreach(Option.scala:257)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit$.prepareSubmitEnvironment(SparkSubmit.scala:634)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:158)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala) &lt;/p&gt;

&lt;p&gt;Here are sample commands which would throw this error in Spark 2.0 (sparkApp.py requires app.py):&lt;/p&gt;

&lt;p&gt;spark-submit --deploy-mode cluster --py-files s3://xxxx/app.py s3://xxxx/sparkApp.py (works fine in 1.6)&lt;/p&gt;

&lt;p&gt;spark-submit --deploy-mode cluster --conf spark.submit.pyFiles=s3://xxxx/app.py s3://xxxx/sparkApp1.py (not working in 1.6)&lt;/p&gt;

&lt;p&gt;This would work fine if app.py is downloaded locally and specified.&lt;/p&gt;

&lt;p&gt;This was working correctly using &#8216;&#8212;py-files&#8217; option in earlier version of Spark, but not using the &#8216;spark.submit.pyFiles&#8217; configuration option. But now, it does not work through either of the ways.&lt;/p&gt;

&lt;p&gt;The following diff shows the comment which states that it should work with &#8216;non-local&#8217; paths for the YARN cluster mode, and we are specifically doing separate validation to fail if YARN client mode is used with remote paths:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala#L309&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala#L309&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And then this code gets triggered at the end of each run, irrespective of whether we are using Client or Cluster mode, and internally validates that the paths should be non-local:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala#L634&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala#L634&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This above validation was not getting triggered in earlier version of Spark using &#8216;&#8212;py-files&#8217; option because we were not storing the arguments passed to &#8216;&#8212;py-files&#8217; in the &#8216;spark.submit.pyFiles&#8217; configuration for YARN. However, the following code was newly added in 2.0 which now stores it and hence this validation gets triggered even if we specify files through &#8216;&#8212;py-files&#8217; option:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala#L545&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala#L545&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also, we changed the logic in YARN client, to read values directly from &#8216;spark.submit.pyFiles&#8217; configuration instead of from &#8216;&#8212;py-files&#8217; (earlier):&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/commit/8ba2b7f28fee39c4839e5ea125bd25f5091a3a1e#diff-b050df3f55b82065803d6e83453b9706R543&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/8ba2b7f28fee39c4839e5ea125bd25f5091a3a1e#diff-b050df3f55b82065803d6e83453b9706R543&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So now its broken whether we use &#8216;&#8212;py-files&#8217; or &#8216;spark.submit.pyFiles&#8217; as the validation gets triggered in both cases irrespective of whether we use Client or Cluster mode with YARN.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13004454">SPARK-17512</key>
            <summary>Specifying remote files for Python based Spark jobs in Yarn cluster mode not working</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jerryshao">Saisai Shao</assignee>
                                    <reporter username="uditme">Udit Mehrotra</reporter>
                        <labels>
                    </labels>
                <created>Tue, 13 Sep 2016 00:08:18 +0000</created>
                <updated>Sun, 17 May 2020 18:14:37 +0000</updated>
                            <resolved>Mon, 3 Oct 2016 12:54:42 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>PySpark</component>
                    <component>Spark Core</component>
                    <component>Spark Submit</component>
                    <component>YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="15500178" author="jerryshao" created="Sun, 18 Sep 2016 03:47:12 +0000"  >&lt;p&gt;This is due to some behavior changes during submitting spark applications on yarn with client or cluster deloy mode. In 2.0 we convert most of the arguments to use system properties, while in 1.6 for &quot;--py-files&quot; we still use command arguments for yarn cluster mode, and for &lt;tt&gt;PythonRunner&lt;/tt&gt; it only checks system property &lt;tt&gt;spark.submit.pyFiles&lt;/tt&gt;, so that&apos;s why it works under 1.6. It is really a issue should be fixed, let me handle it.&lt;/p&gt;</comment>
                            <comment id="15500489" author="apachespark" created="Sun, 18 Sep 2016 07:39:08 +0000"  >&lt;p&gt;User &apos;jerryshao&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15137&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15137&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15542366" author="srowen" created="Mon, 3 Oct 2016 12:54:42 +0000"  >&lt;p&gt;Resolved by &lt;a href=&quot;https://github.com/apache/spark/pull/15137&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15137&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13005542">SPARK-17566</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 7 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i33jn3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>