<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:25:36 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-35009] Avoid creating multiple Monitor threads for reused python workers for the same TaskContext</title>
                <link>https://issues.apache.org/jira/browse/SPARK-35009</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Currently this code will stop because of the high number of created threads:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    import pyspark

    conf=pyspark.SparkConf().setMaster(&quot;local[64]&quot;).setAppName(&quot;Test1&quot;)
    sc=pyspark.SparkContext.getOrCreate(conf)
    rows=70000
    data=list(range(rows))
    rdd=sc.parallelize(data,rows)
    assert rdd.getNumPartitions()==rows
    rdd0=rdd.filter(lambda x:False)
    assert rdd0.getNumPartitions()==rows
    rdd00=rdd0.coalesce(1)
    data=rdd00.collect()
    assert data==[]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;The error is:&lt;/p&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;1/04/08 12:12:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/04/08 12:12:29 WARN TaskSetManager: Stage 0 contains a task of very large size (4732 KiB). The maximum recommended task size is 1000 KiB.
[Stage 0:&amp;gt;                                                          (0 + 1) / 1][423.190s][warning][os,thread] Attempt to protect stack guard pages failed (0x00007f43d23ff000-0x00007f43d2403000).
[423.190s][warning][os,thread] Attempt to deallocate stack guard pages failed.
OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f43d300b000, 16384, 0) failed; error=&apos;Not enough space&apos; (errno=12)
[423.231s][warning][os,thread] Failed to start thread - pthread_create failed (EAGAIN) for attributes: stacksize: 1024k, guardsize: 0k, detached.
#
# There is insufficient memory for the Java Runtime Environment to continue.
# Native memory allocation (mmap) failed to map 16384 bytes for committing reserved memory.
# An error report file with more information is saved as:
# /home/ubuntu/PycharmProjects/&amp;lt;projekt-dir&amp;gt;/tests/hs_err_pid17755.log
[thread 17966 also had an error]
OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f4b7bd81000, 262144, 0) failed; error=&apos;Not enough space&apos; (errno=12)
ERROR:root:Exception while sending command.
Traceback (most recent call last):
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1207, in send_command
    raise Py4JNetworkError(&quot;Answer from Java side is empty&quot;)
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1033, in send_command
    response = connection.send_command(command)
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1211, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while receiving
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:42439)
Traceback (most recent call last):
  File &quot;/opt/spark/python/pyspark/rdd.py&quot;, line 889, in collect
    sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1304, in __call__
    return_value = get_return_value(
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py&quot;, line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 977, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1115, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
Traceback (most recent call last):
  File &quot;/opt/spark/python/pyspark/rdd.py&quot;, line 889, in collect
    sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1304, in __call__
    return_value = get_return_value(
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py&quot;, line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 977, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1115, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [Errno 111] Connection refused
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;&amp;lt;input&amp;gt;&quot;, line 3, in &amp;lt;module&amp;gt;
  File &quot;/opt/pycharm-2020.2.3/plugins/python/helpers/pydev/_pydev_bundle/pydev_umd.py&quot;, line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File &quot;/opt/pycharm-2020.2.3/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py&quot;, line 18, in execfile
    exec(compile(contents+&quot;\n&quot;, file, &apos;exec&apos;), glob, loc)
  File &quot;/home/ubuntu/PycharmProjects/SPO_as_a_Service/tests/test_modeling_paf.py&quot;, line 992, in &amp;lt;module&amp;gt;
    test_70000()
  File &quot;/home/ubuntu/PycharmProjects/SPO_as_a_Service/tests/test_modeling_paf.py&quot;, line 974, in test_70000
    data=rdd00.collect()
  File &quot;/opt/spark/python/pyspark/rdd.py&quot;, line 889, in collect
    sock_info = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File &quot;/opt/spark/python/pyspark/traceback_utils.py&quot;, line 78, in __exit__
    self._context._jsc.setCallSite(None)
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1303, in __call__
    answer = self.gateway_client.send_command(command)
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1031, in send_command
    connection = self._get_connection()
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 979, in _get_connection
    connection = self._create_connection()
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 985, in _create_connection
    connection.start()
  File &quot;/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py&quot;, line 1127, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:42439)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <environment></environment>
        <key id="13370695">SPARK-35009</key>
            <summary>Avoid creating multiple Monitor threads for reused python workers for the same TaskContext</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="attilapiros">Attila Zsolt Piros</assignee>
                                    <reporter username="attilapiros">Attila Zsolt Piros</reporter>
                        <labels>
                    </labels>
                <created>Fri, 9 Apr 2021 15:50:37 +0000</created>
                <updated>Thu, 29 Apr 2021 16:39:24 +0000</updated>
                            <resolved>Thu, 29 Apr 2021 16:39:24 +0000</resolved>
                                    <version>3.0.3</version>
                    <version>3.1.0</version>
                    <version>3.1.1</version>
                    <version>3.1.2</version>
                    <version>3.2.0</version>
                                    <fixVersion>3.2.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17318097" author="attilapiros" created="Fri, 9 Apr 2021 15:51:47 +0000"  >&lt;p&gt;I am working on this&lt;/p&gt;</comment>
                            <comment id="17321065" author="apachespark" created="Wed, 14 Apr 2021 14:54:50 +0000"  >&lt;p&gt;User &apos;attilapiros&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/32169&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/32169&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17335664" author="attilapiros" created="Thu, 29 Apr 2021 16:39:24 +0000"  >&lt;p&gt;Issue resolved by pull request 32169&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/32169&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/32169&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 28 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0pq2o:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>