<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:01:21 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-24721] Failed to use PythonUDF with literal inputs in filter with data sources</title>
                <link>https://issues.apache.org/jira/browse/SPARK-24721</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; random
from pyspark.sql.functions &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; *
from pyspark.sql.types &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; *

def random_probability(label):
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; label == 1.0:
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; random.uniform(0.5, 1.0)
    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; random.uniform(0.0, 0.4999)

def randomize_label(ratio):
    
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; random.random() &amp;gt;= ratio:
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; 1.0
    &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; 0.0

random_probability = udf(random_probability, DoubleType())
randomize_label = udf(randomize_label, DoubleType())

spark.range(10).write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).format(&lt;span class=&quot;code-quote&quot;&gt;&apos;csv&apos;&lt;/span&gt;).save(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/tab3&quot;&lt;/span&gt;)
babydf = spark.read.csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/tab3&quot;&lt;/span&gt;)
data_modified_label = babydf.withColumn(
  &lt;span class=&quot;code-quote&quot;&gt;&apos;random_label&apos;&lt;/span&gt;, randomize_label(lit(1 - 0.1))
)


data_modified_random = data_modified_label.withColumn(
  &lt;span class=&quot;code-quote&quot;&gt;&apos;random_probability&apos;&lt;/span&gt;, 
  random_probability(col(&lt;span class=&quot;code-quote&quot;&gt;&apos;random_label&apos;&lt;/span&gt;))
)

data_modified_label.filter(col(&lt;span class=&quot;code-quote&quot;&gt;&apos;random_label&apos;&lt;/span&gt;) == 0).show()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The above code will generate the following exception:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Py4JJavaError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling o446.showString.
: java.lang.RuntimeException: Invalid PythonUDF randomize_label(0.9), requires attributes from more than one child.
	at scala.sys.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.error(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:27)
	at org.apache.spark.sql.execution.python.ExtractPythonUDFs$$anonfun$org$apache$spark$sql$execution$python$ExtractPythonUDFs$$extract$2.apply(ExtractPythonUDFs.scala:166)
	at org.apache.spark.sql.execution.python.ExtractPythonUDFs$$anonfun$org$apache$spark$sql$execution$python$ExtractPythonUDFs$$extract$2.apply(ExtractPythonUDFs.scala:165)
	at scala.collection.immutable.Stream.foreach(Stream.scala:594)
	at org.apache.spark.sql.execution.python.ExtractPythonUDFs$.org$apache$spark$sql$execution$python$ExtractPythonUDFs$$extract(ExtractPythonUDFs.scala:165)
	at org.apache.spark.sql.execution.python.ExtractPythonUDFs$$anonfun$apply$2.applyOrElse(ExtractPythonUDFs.scala:116)
	at org.apache.spark.sql.execution.python.ExtractPythonUDFs$$anonfun$apply$2.applyOrElse(ExtractPythonUDFs.scala:112)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:310)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:310)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:77)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:309)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:327)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:208)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:325)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:327)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:208)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:325)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:327)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:208)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:325)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:307)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:327)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:208)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:325)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:307)
	at org.apache.spark.sql.execution.python.ExtractPythonUDFs$.apply(ExtractPythonUDFs.scala:112)
	at org.apache.spark.sql.execution.python.ExtractPythonUDFs$.apply(ExtractPythonUDFs.scala:92)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$prepareForExecution$1.apply(QueryExecution.scala:119)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$prepareForExecution$1.apply(QueryExecution.scala:119)
	at scala.collection.LinearSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(LinearSeqOptimized.scala:124)
	at scala.collection.immutable.List.foldLeft(List.scala:84)
	at org.apache.spark.sql.execution.QueryExecution.prepareForExecution(QueryExecution.scala:119)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:109)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:109)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3016)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:2216)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:2429)
	at org.apache.spark.sql.Dataset.showString(Dataset.scala:248)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)
	at py4j.Gateway.invoke(Gateway.java:293)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:226)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13169581">SPARK-24721</key>
            <summary>Failed to use PythonUDF with literal inputs in filter with data sources</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="icexelloss">Li Jin</assignee>
                                    <reporter username="smilegator">Xiao Li</reporter>
                        <labels>
                    </labels>
                <created>Mon, 2 Jul 2018 17:56:30 +0000</created>
                <updated>Tue, 28 Aug 2018 02:58:33 +0000</updated>
                            <resolved>Tue, 28 Aug 2018 02:58:33 +0000</resolved>
                                    <version>2.3.1</version>
                                    <fixVersion>2.4.0</fixVersion>
                                    <component>PySpark</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16530241" author="smilegator" created="Mon, 2 Jul 2018 17:57:09 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=icexelloss&quot; class=&quot;user-hover&quot; rel=&quot;icexelloss&quot;&gt;icexelloss&lt;/a&gt; Are you interested in this?&lt;/p&gt;</comment>
                            <comment id="16530462" author="icexelloss" created="Mon, 2 Jul 2018 21:30:02 +0000"  >&lt;p&gt;Yep I can take a look&lt;/p&gt;</comment>
                            <comment id="16544656" author="icexelloss" created="Sun, 15 Jul 2018 19:58:34 +0000"  >&lt;p&gt;I am currently traveling but will try to take a look when I get back&lt;/p&gt;</comment>
                            <comment id="16560283" author="icexelloss" created="Fri, 27 Jul 2018 20:25:48 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
from pyspark.sql.functions &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; udf, lit, col

spark.range(1).write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).format(&lt;span class=&quot;code-quote&quot;&gt;&apos;csv&apos;&lt;/span&gt;).save(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/tab3&quot;&lt;/span&gt;)
df = spark.read.csv(&lt;span class=&quot;code-quote&quot;&gt;&apos;/tmp/tab3&apos;&lt;/span&gt;)
df2 = df.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&apos;v1&apos;&lt;/span&gt;, udf(lambda x: x, &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&apos;&lt;/span&gt;)(lit(1)))
df2 = df2.filter(df2[&lt;span class=&quot;code-quote&quot;&gt;&apos;v1&apos;&lt;/span&gt;] == 0)

df2.explain()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is a simpler reproduce&lt;/p&gt;</comment>
                            <comment id="16560337" author="icexelloss" created="Fri, 27 Jul 2018 21:14:31 +0000"  >&lt;p&gt;I think the issue is the UDF is being pushed down to the PartitionFilter in FileScan physical node and then ExtractPythonUDFs&#160;rule throws the exception (this is the Spark plan before execution the ExtractPythonUDFs rule):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Project [_c0#17, &amp;lt;lambda&amp;gt;(1) AS v1#20]
+- Filter (&amp;lt;lambda&amp;gt;(1) = 0)
&#160;&#160; +- FileScan csv [_c0#17] Batched: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, Format: CSV, Location: InMemoryFileIndex[file:/tmp/tab3], PartitionFilters: [(&amp;lt;lambda&amp;gt;(1) = 0)], PushedFilters: [], ReadSchema: struct&amp;lt;_c0:string&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I am not familiar with how PartiionFilters pushdown is supposed to work. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt; could you guys maybe point me to the right direction? Should we not push down the filter &amp;lt;lambda(1) = 0&amp;gt; to FileScan? Or should we ignore it in the&#160;ExtractPythonUDFs rule?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16560537" author="cloud_fan" created="Sat, 28 Jul 2018 01:29:45 +0000"  >&lt;p&gt;good catch! I think we should filter out python UDFs when picking partition predicates in `FileSourceStrategy`&lt;/p&gt;</comment>
                            <comment id="16579883" author="apachespark" created="Tue, 14 Aug 2018 14:30:04 +0000"  >&lt;p&gt;User &apos;icexelloss&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22104&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22104&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16579956" author="icexelloss" created="Tue, 14 Aug 2018 15:26:51 +0000"  >&lt;p&gt;Updated Jira title to reflect the actual issue&lt;/p&gt;</comment>
                            <comment id="16593857" author="apachespark" created="Mon, 27 Aug 2018 15:50:05 +0000"  >&lt;p&gt;User &apos;cloud-fan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22244&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22244&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16594441" author="cloud_fan" created="Tue, 28 Aug 2018 02:58:33 +0000"  >&lt;p&gt;Issue resolved by pull request 22104&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22104&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22104&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 12 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3vgif:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12342385">2.4.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>