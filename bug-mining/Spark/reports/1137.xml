<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:21:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4759] Deadlock in complex spark job in local mode</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4759</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The attached test class runs two identical jobs that perform some iterative computation on an RDD&lt;span class=&quot;error&quot;&gt;&amp;#91;(Int, Int)&amp;#93;&lt;/span&gt;. This computation involves &lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;taking new data merging it with the previous result&lt;/li&gt;
	&lt;li&gt;caching and checkpointing the new result&lt;/li&gt;
	&lt;li&gt;rinse and repeat&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The first time the job is run, it runs successfully, and the spark context is shut down. The second time the job is run with a new spark context in the same process, the job hangs indefinitely, only having scheduled a subset of the necessary tasks for the final stage.&lt;/p&gt;

&lt;p&gt;Ive been able to produce a test case that reproduces the issue, and I&apos;ve added some comments where some knockout experimentation has left some breadcrumbs as to where the issue might be.  &lt;/p&gt;</description>
                <environment>&lt;p&gt;Java version &quot;1.7.0_51&quot;&lt;br/&gt;
Java(TM) SE Runtime Environment (build 1.7.0_51-b13)&lt;br/&gt;
Java HotSpot(TM) 64-Bit Server VM (build 24.51-b03, mixed mode)&lt;/p&gt;

&lt;p&gt;Mac OSX 10.10.1&lt;br/&gt;
Using local spark context&lt;/p&gt;</environment>
        <key id="12759611">SPARK-4759</key>
            <summary>Deadlock in complex spark job in local mode</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="andrewor14">Andrew Or</assignee>
                                    <reporter username="dgshep">Davis Shepherd</reporter>
                        <labels>
                            <label>backport-needed</label>
                    </labels>
                <created>Fri, 5 Dec 2014 07:43:24 +0000</created>
                <updated>Wed, 21 Jan 2015 18:49:49 +0000</updated>
                            <resolved>Wed, 21 Jan 2015 18:49:43 +0000</resolved>
                                    <version>1.1.1</version>
                    <version>1.2.0</version>
                    <version>1.3.0</version>
                                    <fixVersion>1.1.2</fixVersion>
                    <fixVersion>1.2.1</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14235509" author="srowen" created="Fri, 5 Dec 2014 14:15:41 +0000"  >&lt;p&gt;Can you dump the thread state with &quot;kill -QUIT&quot; and attach the stack traces of the deadlocked threads? Or at least that would help determine whether it&apos;s really a deadlock.&lt;/p&gt;</comment>
                            <comment id="14235651" author="dgshep" created="Fri, 5 Dec 2014 15:47:58 +0000"  >&lt;p&gt;Here is a thread dump with superfluous threads omitted (namely jetty qtp threads)&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;sparkDriver-akka.actor.default-dispatcher-18&quot; daemon prio=5 tid=7fc3853ef800 nid=0x119e87000 waiting on condition [119e86000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-akka.actor.default-dispatcher-17&quot; daemon prio=5 tid=7fc38c007000 nid=0x119d84000 waiting on condition [119d83000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-akka.actor.default-dispatcher-14&quot; daemon prio=5 tid=7fc38b003800 nid=0x119b96000 waiting on condition [119b95000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.idleAwaitWork(ForkJoinPool.java:1626)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1579)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-akka.actor.default-dispatcher-15&quot; daemon prio=5 tid=7fc38b003000 nid=0x119a93000 waiting on condition [119a92000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-akka.actor.default-dispatcher-16&quot; daemon prio=5 tid=7fc38c006000 nid=0x11971d000 waiting on condition [11971c000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-akka.actor.default-dispatcher-13&quot; daemon prio=5 tid=7fc38681f000 nid=0x1193d1000 waiting on condition [1193d0000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;task-result-getter-3&quot; daemon prio=5 tid=7fc3871a7800 nid=0x1192ce000 waiting on condition [1192cd000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbeaace0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1987)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;task-result-getter-2&quot; daemon prio=5 tid=7fc3871a6800 nid=0x1191cb000 waiting on condition [1191ca000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbeaace0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1987)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;task-result-getter-1&quot; daemon prio=5 tid=7fc3871a6000 nid=0x1190c8000 waiting on condition [1190c7000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbeaace0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1987)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;task-result-getter-0&quot; daemon prio=5 tid=7fc38d164800 nid=0x118fc5000 waiting on condition [118fc4000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbeaace0&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1987)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:957)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-8&quot; daemon prio=5 tid=7fc385409800 nid=0x118ec2000 waiting on condition [118ec1000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-7&quot; daemon prio=5 tid=7fc386b4b800 nid=0x118dbf000 waiting on condition [118dbe000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-6&quot; daemon prio=5 tid=7fc388013800 nid=0x118cbc000 waiting on condition [118cbb000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-5&quot; daemon prio=5 tid=7fc3869e3800 nid=0x118bb9000 waiting on condition [118bb8000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-4&quot; daemon prio=5 tid=7fc38689b800 nid=0x118ab6000 waiting on condition [118ab5000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-3&quot; daemon prio=5 tid=7fc38c005000 nid=0x1189b3000 waiting on condition [1189b2000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-2&quot; daemon prio=5 tid=7fc38b001800 nid=0x1188b0000 waiting on condition [1188af000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-1&quot; daemon prio=5 tid=7fc3871a5000 nid=0x1187ad000 waiting on condition [1187ac000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Executor task launch worker-0&quot; daemon prio=5 tid=7fc38d164000 nid=0x1146c9000 waiting on condition [1146c8000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7bbed5360&amp;gt; (a java.util.concurrent.SynchronousQueue$TransferStack)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:424)
	at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:323)
	at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:874)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:955)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:917)
	at java.lang.Thread.run(Thread.java:695)

&quot;Driver Heartbeater&quot; daemon prio=5 tid=7fc385572800 nid=0x114223000 waiting on condition [114222000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:383)

&quot;Spark Context Cleaner&quot; daemon prio=5 tid=7fc38d163000 nid=0x114120000 in Object.wait() [11411f000]
   java.lang.Thread.State: TIMED_WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;7bbea0748&amp;gt; (a java.lang.ref.ReferenceQueue$Lock)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:118)
	- locked &amp;lt;7bbea0748&amp;gt; (a java.lang.ref.ReferenceQueue$Lock)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:136)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply(ContextCleaner.scala:134)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply(ContextCleaner.scala:134)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1364)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:133)
	at org.apache.spark.ContextCleaner$$anon$3.run(ContextCleaner.scala:65)

&quot;Timer-1&quot; daemon prio=5 tid=7fc38689a800 nid=0x11401d000 in Object.wait() [11401c000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;7bbec0758&amp;gt; (a java.util.TaskQueue)
	at java.lang.Object.wait(Object.java:485)
	at java.util.TimerThread.mainLoop(Timer.java:483)
	- locked &amp;lt;7bbec0758&amp;gt; (a java.util.TaskQueue)
	at java.util.TimerThread.run(Timer.java:462)

&quot;SparkListenerBus&quot; daemon prio=5 tid=7fc387085800 nid=0x113f1a000 waiting on condition [113f19000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c3360168&amp;gt; (a java.util.concurrent.Semaphore$NonfairSync)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:156)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:811)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:969)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1281)
	at java.util.concurrent.Semaphore.acquire(Semaphore.java:286)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1.apply$mcV$sp(LiveListenerBus.scala:48)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1.apply(LiveListenerBus.scala:47)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1$$anonfun$run$1.apply(LiveListenerBus.scala:47)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1364)
	at org.apache.spark.scheduler.LiveListenerBus$$anon$1.run(LiveListenerBus.scala:46)

&quot;SPARK_CONTEXT cleanup timer&quot; daemon prio=5 tid=7fc387201000 nid=0x1135ff000 in Object.wait() [1135fe000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;7c330c2d0&amp;gt; (a java.util.TaskQueue)
	at java.lang.Object.wait(Object.java:485)
	at java.util.TimerThread.mainLoop(Timer.java:483)
	- locked &amp;lt;7c330c2d0&amp;gt; (a java.util.TaskQueue)
	at java.util.TimerThread.run(Timer.java:462)

&quot;BROADCAST_VARS cleanup timer&quot; daemon prio=5 tid=7fc385423800 nid=0x112bad000 in Object.wait() [112bac000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;7c330c2e8&amp;gt; (a java.util.TaskQueue)
	at java.lang.Object.wait(Object.java:485)
	at java.util.TimerThread.mainLoop(Timer.java:483)
	- locked &amp;lt;7c330c2e8&amp;gt; (a java.util.TaskQueue)
	at java.util.TimerThread.run(Timer.java:462)

&quot;BLOCK_MANAGER cleanup timer&quot; daemon prio=5 tid=7fc3868a8000 nid=0x112aaa000 in Object.wait() [112aa9000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;7c330c300&amp;gt; (a java.util.TaskQueue)
	at java.lang.Object.wait(Object.java:485)
	at java.util.TimerThread.mainLoop(Timer.java:483)
	- locked &amp;lt;7c330c300&amp;gt; (a java.util.TaskQueue)
	at java.util.TimerThread.run(Timer.java:462)

&quot;connection-manager-thread&quot; daemon prio=5 tid=7fc3869ea800 nid=0x1129a7000 runnable [1129a6000]
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method)
	at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:136)
	at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:69)
	at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
	- locked &amp;lt;7c332e678&amp;gt; (a sun.nio.ch.Util$2)
	- locked &amp;lt;7c332e690&amp;gt; (a java.util.Collections$UnmodifiableSet)
	- locked &amp;lt;7c33228f8&amp;gt; (a sun.nio.ch.KQueueSelectorImpl)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)
	at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:84)
	at org.apache.spark.network.ConnectionManager.run(ConnectionManager.scala:332)
	at org.apache.spark.network.ConnectionManager$$anon$4.run(ConnectionManager.scala:145)

&quot;SHUFFLE_BLOCK_MANAGER cleanup timer&quot; daemon prio=5 tid=7fc3871d7000 nid=0x1128a4000 in Object.wait() [1128a3000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;7c330c318&amp;gt; (a java.util.TaskQueue)
	at java.lang.Object.wait(Object.java:485)
	at java.util.TimerThread.mainLoop(Timer.java:483)
	- locked &amp;lt;7c330c318&amp;gt; (a java.util.TaskQueue)
	at java.util.TimerThread.run(Timer.java:462)

&quot;MAP_OUTPUT_TRACKER cleanup timer&quot; daemon prio=5 tid=7fc3871b1800 nid=0x1127a1000 in Object.wait() [1127a0000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;7c330c330&amp;gt; (a java.util.TaskQueue)
	at java.lang.Object.wait(Object.java:485)
	at java.util.TimerThread.mainLoop(Timer.java:483)
	- locked &amp;lt;7c330c330&amp;gt; (a java.util.TaskQueue)
	at java.util.TimerThread.run(Timer.java:462)

&quot;sparkDriver-akka.actor.default-dispatcher-5&quot; daemon prio=5 tid=7fc3871d4000 nid=0x11208c000 waiting on condition [11208b000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-akka.actor.default-dispatcher-4&quot; daemon prio=5 tid=7fc38d088000 nid=0x111f89000 waiting on condition [111f88000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-akka.actor.default-dispatcher-3&quot; daemon prio=5 tid=7fc385541800 nid=0x111e86000 waiting on condition [111e85000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-akka.actor.default-dispatcher-2&quot; daemon prio=5 tid=7fc385579800 nid=0x111d83000 waiting on condition [111d82000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  &amp;lt;7c33229d0&amp;gt; (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool)
	at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:1594)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1478)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)

&quot;sparkDriver-scheduler-1&quot; daemon prio=5 tid=7fc387086800 nid=0x111acf000 waiting on condition [111ace000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
	at java.lang.Thread.sleep(Native Method)
	at akka.actor.LightArrayRevolverScheduler.waitNanos(Scheduler.scala:226)
	at akka.actor.LightArrayRevolverScheduler$$anon$12.nextTick(Scheduler.scala:393)
	at akka.actor.LightArrayRevolverScheduler$$anon$12.run(Scheduler.scala:363)
	at java.lang.Thread.run(Thread.java:695)

&quot;main&quot; prio=5 tid=7fc385001000 nid=0x1052ca000 in Object.wait() [1052c7000]
   java.lang.Thread.State: WAITING (on object monitor)
	at java.lang.Object.wait(Native Method)
	- waiting on &amp;lt;7bbed5f38&amp;gt; (a org.apache.spark.scheduler.JobWaiter)
	at java.lang.Object.wait(Object.java:485)
	at org.apache.spark.scheduler.JobWaiter.awaitResult(JobWaiter.scala:73)
	- locked &amp;lt;7bbed5f38&amp;gt; (a org.apache.spark.scheduler.JobWaiter)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:511)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1110)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1129)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1143)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1157)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:774)
	at org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:595)
	at com.conviva.go.test.SparkBugReplicator$$anonfun$runJob$1.apply(SparkBugReplicator.scala:73)
	at com.conviva.go.test.SparkBugReplicator$$anonfun$runJob$1.apply(SparkBugReplicator.scala:47)
	at scala.collection.immutable.Range.foreach(Range.scala:141)
	at com.conviva.go.test.SparkBugReplicator$.runJob(SparkBugReplicator.scala:47)
	at com.conviva.go.test.SparkBugReplicator.job2(SparkBugReplicator.scala:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14235673" author="srowen" created="Fri, 5 Dec 2014 16:12:27 +0000"  >&lt;p&gt;I don&apos;t see a deadlock here, so maybe that&apos;s not the cause or the right term here, but of course may still be some issue.&lt;/p&gt;</comment>
                            <comment id="14235703" author="dgshep" created="Fri, 5 Dec 2014 16:37:08 +0000"  >&lt;p&gt;Fair enough. As far as I can work out, it appears that there are 9 expected tasks in the final stage, but only 6 ever get scheduled.  I suppose that leaves only one thread waiting on something that will never happen. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14236257" author="pwendell" created="Fri, 5 Dec 2014 22:50:46 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dgshep&quot; class=&quot;user-hover&quot; rel=&quot;dgshep&quot;&gt;dgshep&lt;/a&gt; a ton for creating a repro of this. I&apos;ve asked &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrewor14&quot; class=&quot;user-hover&quot; rel=&quot;andrewor14&quot;&gt;andrewor14&lt;/a&gt; to take a look at it and see if we can reproduce it on our side.&lt;/p&gt;</comment>
                            <comment id="14236301" author="andrewor14" created="Fri, 5 Dec 2014 23:30:13 +0000"  >&lt;p&gt;Hey just wanted to let you know that I am able to reproduce this locally. It is stuck at task 6/9 exactly as you pointed out. Investigating.&lt;/p&gt;</comment>
                            <comment id="14236517" author="andrewor14" created="Sat, 6 Dec 2014 02:41:09 +0000"  >&lt;p&gt;Quick update, I was only able to reproduce this in local mode when multiple cores are used. This doesn&apos;t happen if I only use 1 core in local mode, in local-cluster mode, or in standalone mode. It probably has something to do with how we allocate cores to executors in local mode. Still investigating.&lt;/p&gt;</comment>
                            <comment id="14237264" author="dgshep" created="Sun, 7 Dec 2014 20:44:08 +0000"  >&lt;p&gt;It is possible to reproduce the issue with single core local mode.&lt;/p&gt;

&lt;p&gt;Simply change the partitions parameter to &amp;gt; 1 (in the attached version it uses the defaultParallelism of the spark context, which in single core mode is 1) in either of the coalesce calls.&lt;/p&gt;</comment>
                            <comment id="14237321" author="andrewor14" created="Sun, 7 Dec 2014 23:51:02 +0000"  >&lt;p&gt;Hey I came up with a much smaller reproduction for this from your program.&lt;/p&gt;

&lt;p&gt;1. Start spark-shell with --master local&lt;span class=&quot;error&quot;&gt;&amp;#91;N&amp;#93;&lt;/span&gt; where N can be anything (or simply local with 1 core)&lt;br/&gt;
2. Copy and paste the following into your REPL&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    def runMyJob(): Unit = {
      val rdd = sc.parallelize(1 to 100).repartition(5).cache()
      rdd.count()
      val rdd2 = sc.parallelize(1 to 100).repartition(12)
      rdd.union(rdd2).count()
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3. runMyJob()&lt;/p&gt;

&lt;p&gt;It should be stuck at task 5/17. Note that with local-cluster and (local) standalone mode, it pauses a little at 5/17 too, but finishes shortly afterwards.&lt;/p&gt;

&lt;p&gt;=== EDIT ===&lt;br/&gt;
This seems to reproduce it only on the master branch, but not 1.1.&lt;/p&gt;</comment>
                            <comment id="14237371" author="dgshep" created="Mon, 8 Dec 2014 02:29:53 +0000"  >&lt;p&gt;This doesn&apos;t seem to reproduce the issue for me. The job finishes regardless of how many times I call runMyJob()&lt;/p&gt;</comment>
                            <comment id="14237372" author="andrewor14" created="Mon, 8 Dec 2014 02:31:41 +0000"  >&lt;p&gt;Found the issue. The task scheduler schedules tasks based on the preferred locations specified by the partition. In CoalescedRDD&apos;s partitions, we use the empty string as the default preferred location, even though this does not actually represent a real host: &lt;a href=&quot;https://github.com/apache/spark/blob/e895e0cbecbbec1b412ff21321e57826d2d0a982/core/src/main/scala/org/apache/spark/rdd/CoalescedRDD.scala#L41&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/e895e0cbecbbec1b412ff21321e57826d2d0a982/core/src/main/scala/org/apache/spark/rdd/CoalescedRDD.scala#L41&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As a result, the task scheduler doesn&apos;t schedule a subset of the tasks on the local executor because these tasks are supposed to be scheduled on the host &quot;&quot; (empty string) that doesn&apos;t actually exist. I have not dug into the details of PartitionCoalescer as to why this is only specific to local mode.&lt;/p&gt;

&lt;p&gt;I&apos;ll submit a fix shortly.&lt;/p&gt;</comment>
                            <comment id="14237374" author="andrewor14" created="Mon, 8 Dec 2014 02:33:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dgshep&quot; class=&quot;user-hover&quot; rel=&quot;dgshep&quot;&gt;dgshep&lt;/a&gt; That&apos;s strange. I am able to reproduce this every time, and I only need to call &quot;runMyJob&quot; once. What master are you running?&lt;/p&gt;

&lt;p&gt;I just tried local, local&lt;span class=&quot;error&quot;&gt;&amp;#91;6&amp;#93;&lt;/span&gt;, and local&lt;span class=&quot;error&quot;&gt;&amp;#91;*&amp;#93;&lt;/span&gt; and they all reproduced the deadlock. I am running the master branch with this commit: 6eb1b6f6204ea3c8083af3fb9cd990d9f3dac89d&lt;/p&gt;</comment>
                            <comment id="14237376" author="dgshep" created="Mon, 8 Dec 2014 02:34:33 +0000"  >&lt;p&gt;local&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; on the latest commit of branch 1.1&lt;/p&gt;</comment>
                            <comment id="14237377" author="andrewor14" created="Mon, 8 Dec 2014 02:37:34 +0000"  >&lt;p&gt;Hm I&apos;ll try branch 1.1 again later tonight. There might very well be more than one issue that causes this.&lt;/p&gt;</comment>
                            <comment id="14237383" author="dgshep" created="Mon, 8 Dec 2014 02:52:34 +0000"  >&lt;p&gt;Ok your version does reproduce the issue against the spark-core 1.1.1 artifact if I copy and paste your code into the original SparkBugReplicator, but it only seems to hang on the second time the job is run &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/tongue.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;. This smells of a race condition...&lt;/p&gt;</comment>
                            <comment id="14237393" author="dgshep" created="Mon, 8 Dec 2014 03:14:58 +0000"  >&lt;p&gt;I still cannot reproduce the issue with your snippet in the spark shell on tag v1.1.1&lt;/p&gt;</comment>
                            <comment id="14237550" author="andrewor14" created="Mon, 8 Dec 2014 07:26:33 +0000"  >&lt;p&gt;Ok yeah you&apos;re right, I can&apos;t reproduce it from the code snippet in branch 1.1 either. There seems to be at least two issues going on here... Can you confirm that the snippet does reproduce the lock in master branch?&lt;/p&gt;</comment>
                            <comment id="14237587" author="apachespark" created="Mon, 8 Dec 2014 08:06:28 +0000"  >&lt;p&gt;User &apos;andrewor14&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3633&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3633&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14237597" author="andrewor14" created="Mon, 8 Dec 2014 08:16:05 +0000"  >&lt;p&gt;Hey I have opened the following PR to fix the symptom I described earlier: &lt;a href=&quot;https://github.com/apache/spark/pull/3633&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3633&lt;/a&gt;. I will spend some more time trying to understand why there is a discrepancy in reproducibility between master and 1.1, but in both cases the patch should be sufficient in preventing this from happening again. Can you try it out?&lt;/p&gt;</comment>
                            <comment id="14238221" author="dgshep" created="Mon, 8 Dec 2014 18:40:16 +0000"  >&lt;p&gt;The fix appears to resolve the issue in master for both repros.&lt;/p&gt;</comment>
                            <comment id="14238289" author="andrewor14" created="Mon, 8 Dec 2014 19:13:45 +0000"  >&lt;p&gt;I have a smaller reproduction for branch-1.1. It seems that we need to run the two jobs in two different SparkContexts in tandem to reproduce it here:&lt;/p&gt;

&lt;p&gt;1. Run bin/spark-shell. The master doesn&apos;t matter here.&lt;br/&gt;
2. Copy and paste the following into the REPL&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.{SparkConf, SparkContext}
  sc.stop()

  def setup(): SparkContext = {
    val conf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkConf
    conf.setMaster(&lt;span class=&quot;code-quote&quot;&gt;&quot;local[8]&quot;&lt;/span&gt;)
    conf.setAppName(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;)
    &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkContext(conf)
  }

  def runMyJob(sc: SparkContext): Unit = {
    val rdd = sc.parallelize(1 to 100).repartition(5).cache()
    rdd.count()
    val rdd2 = sc.parallelize(1 to 100).repartition(12)
    rdd.union(rdd2).count()
  }

  def test(): Unit = {
    &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; sc = setup()
    runMyJob(sc)
    sc.stop()
    println(&lt;span class=&quot;code-quote&quot;&gt;&quot;\n========== FINISHED FIRST JOB ==========\n&quot;&lt;/span&gt;)
    sc = setup()
    runMyJob(sc) &lt;span class=&quot;code-comment&quot;&gt;// This will get stuck at task 5/17 and never finish
&lt;/span&gt;    sc.stop()
    println(&lt;span class=&quot;code-quote&quot;&gt;&quot;\n========== FINISHED SECOND JOB ==========\n&quot;&lt;/span&gt;)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3. Call test().&lt;/p&gt;</comment>
                            <comment id="14240079" author="joshrosen" created="Tue, 9 Dec 2014 21:14:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrewor14&quot; class=&quot;user-hover&quot; rel=&quot;andrewor14&quot;&gt;andrewor14&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;If you wanted to run the reproduction in the shell without the &quot;multiple SparkContexts&quot; warning, couldn&apos;t you just call sc.stop() to stop the shell&apos;s default SparkContext prior to running your reproduction code?&lt;/p&gt;</comment>
                            <comment id="14240238" author="andrewor14" created="Tue, 9 Dec 2014 23:00:39 +0000"  >&lt;p&gt;Aha, that is a great idea. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12685280" name="SparkBugReplicator.scala" size="1862" author="dgshep" created="Fri, 5 Dec 2014 07:53:15 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 49 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2335r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12328982">1.1.2</customfieldvalue>
    <customfieldvalue id="12329029">1.2.1</customfieldvalue>
    <customfieldvalue id="12327642">1.3.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>