<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:57:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-22891] NullPointerException when use udf</title>
                <link>https://issues.apache.org/jira/browse/SPARK-22891</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;In my application,i use multi threads. Each thread has a SparkSession and use SparkSession.sqlContext.udf.register to register my udf. Sometimes there throws exception like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.lang.IllegalArgumentException: Error &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; instantiating &lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.spark.sql.hive.HiveSessionStateBuilder&apos;&lt;/span&gt;:
	at org.apache.spark.sql.SparkSession$.org$apache$spark$sql$SparkSession$$instantiateSessionState(SparkSession.scala:1062)
	at org.apache.spark.sql.SparkSession$$anonfun$sessionState$2.apply(SparkSession.scala:137)
	at org.apache.spark.sql.SparkSession$$anonfun$sessionState$2.apply(SparkSession.scala:136)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:136)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:133)
	at org.apache.spark.sql.SparkSession.udf(SparkSession.scala:207)
	at org.apache.spark.sql.SQLContext.udf(SQLContext.scala:203)
	at com.game.data.stat.clusterTask.tools.standard.IpConverterRegister$.run(IpConverterRegister.scala:63)
	at 
	... 20 more
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.spark.sql.hive.client.IsolatedClientLoader.createClient(IsolatedClientLoader.scala:264)
	at org.apache.spark.sql.hive.client.HiveClientImpl.newSession(HiveClientImpl.scala:789)
	at org.apache.spark.sql.hive.client.HiveClientImpl.newSession(HiveClientImpl.scala:79)
	at org.apache.spark.sql.hive.HiveSessionStateBuilder.resourceLoader$lzycompute(HiveSessionStateBuilder.scala:45)
	at org.apache.spark.sql.hive.HiveSessionStateBuilder.resourceLoader(HiveSessionStateBuilder.scala:44)
	at org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog$lzycompute(HiveSessionStateBuilder.scala:61)
	at org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog(HiveSessionStateBuilder.scala:52)
	at org.apache.spark.sql.hive.HiveSessionStateBuilder.catalog(HiveSessionStateBuilder.scala:35)
	at org.apache.spark.sql.internal.BaseSessionStateBuilder.build(BaseSessionStateBuilder.scala:289)
	at org.apache.spark.sql.SparkSession$.org$apache$spark$sql$SparkSession$$instantiateSessionState(SparkSession.scala:1059)
	... 20 more
Caused by: java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:744)
	at org.apache.hadoop.hive.ql.session.SessionState.getAuthenticator(SessionState.java:1391)
	at org.apache.spark.sql.hive.client.HiveClientImpl.&amp;lt;init&amp;gt;(HiveClientImpl.scala:210)
	... 34 more
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException
	at org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:769)
	at org.apache.hadoop.hive.ql.session.SessionState.setupAuth(SessionState.java:736)
	... 36 more
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.isCompatibleWith(HiveMetaStoreClient.java:287)
	at sun.reflect.GeneratedMethodAccessor45.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:156)
	at com.sun.proxy.$Proxy25.isCompatibleWith(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:206)
	at org.apache.hadoop.hive.ql.session.SessionState.setAuthorizerV2Config(SessionState.java:765)
	... 37 more

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Also, i use apache hive 2.1.1 in my cluster.&lt;br/&gt;
When i use spark 2.1.x, the exception above never happends again.&lt;/p&gt;</description>
                <environment>&lt;p&gt;hadoop 2.7.2&lt;/p&gt;</environment>
        <key id="13126949">SPARK-22891</key>
            <summary>NullPointerException when use udf</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="fengliu@databricks.com">Feng Liu</assignee>
                                    <reporter username="hellodoge">gaoyang</reporter>
                        <labels>
                    </labels>
                <created>Sat, 23 Dec 2017 07:12:23 +0000</created>
                <updated>Fri, 29 Dec 2017 07:09:30 +0000</updated>
                            <resolved>Fri, 29 Dec 2017 07:09:30 +0000</resolved>
                                    <version>2.2.0</version>
                    <version>2.2.1</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16302456" author="srowen" created="Sat, 23 Dec 2017 14:21:46 +0000"  >&lt;p&gt;It sounds like it was resolved, then, by some other change?&lt;br/&gt;
It also looks like a Hive bug, related to &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-11935&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-11935&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16303092" author="hellodoge" created="Mon, 25 Dec 2017 06:30:33 +0000"  >&lt;p&gt;It happends in spark 2.2.x, not in spark 2.1.x.&lt;/p&gt;</comment>
                            <comment id="16303877" author="srowen" created="Tue, 26 Dec 2017 14:40:57 +0000"  >&lt;p&gt;It looks like a Hive problem, primarily? just not sure if it&apos;s something that can be resolved in Spark. How do you reproduce it?&lt;/p&gt;</comment>
                            <comment id="16305862" author="liufeng.ee@gmail.com" created="Fri, 29 Dec 2017 00:48:21 +0000"  >&lt;p&gt;This is definitely caused by the race from &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-11935&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-11935&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;In spark 2.1, spark creates the `metadataHive` lazily until `addJar`(&lt;a href=&quot;https://github.com/apache/spark/blob/branch-2.1/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionState.scala#L40&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/branch-2.1/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionState.scala#L40&lt;/a&gt;), so this can only be triggered by concurrent `addJar` (can&apos;t imagine this will happen in practice)&lt;/p&gt;

&lt;p&gt;In spark 2.2, the `metadataHive` creation is tied to the `resourceLoader` creation (see the stack trace), so it starts to be triggered by new spark session creation. In &lt;a href=&quot;https://github.com/apache/spark/pull/20029&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/20029&lt;/a&gt;, I&apos;m trying to make an argument that it is safe to remove the new hive client creation. Besides this change, I think we should also make the hive client creation thread safe: &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala#L251&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/IsolatedClientLoader.scala#L251&lt;/a&gt;&lt;/p&gt;
</comment>
                            <comment id="16305874" author="apachespark" created="Fri, 29 Dec 2017 01:04:04 +0000"  >&lt;p&gt;User &apos;liufengdb&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/20109&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/20109&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16305881" author="liufeng.ee@gmail.com" created="Fri, 29 Dec 2017 01:09:21 +0000"  >&lt;p&gt;A side note: if we don&apos;t want to merge &lt;a href=&quot;https://github.com/apache/spark/pull/20029&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/20029&lt;/a&gt;, we should make the creation of hive client lazy inside the HiveSessionResourceLoader: &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala#L123&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/HiveSessionStateBuilder.scala#L123&lt;/a&gt; as we know the hive client creation is expensive, so it does not make sense to materialize it if we don&apos;t use it. &lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 46 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3o8tz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>