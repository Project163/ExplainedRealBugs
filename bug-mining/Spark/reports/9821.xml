<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:43:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-48463] MLLib function unable to handle nested data</title>
                <link>https://issues.apache.org/jira/browse/SPARK-48463</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I am trying to use feature transformer on nested data after flattening, but it fails.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val structureData = Seq(
  Row(Row(10, 12), 1000),
  Row(Row(12, 14), 4300),
  Row( Row(37, 891), 1400),
  Row(Row(8902, 12), 4000),
  Row(Row(12, 89), 1000)
)

val structureSchema = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructType()
  .add(&lt;span class=&quot;code-quote&quot;&gt;&quot;location&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructType()
    .add(&lt;span class=&quot;code-quote&quot;&gt;&quot;longitude&quot;&lt;/span&gt;, IntegerType)
    .add(&lt;span class=&quot;code-quote&quot;&gt;&quot;latitude&quot;&lt;/span&gt;, IntegerType))
  .add(&lt;span class=&quot;code-quote&quot;&gt;&quot;salary&quot;&lt;/span&gt;, IntegerType) 
val df = spark.createDataFrame(spark.sparkContext.parallelize(structureData), structureSchema) 

def flattenSchema(schema: StructType, prefix: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, prefixSelect: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;):
Array[Column] = {
  schema.fields.flatMap(f =&amp;gt; {
    val colName = &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (prefix == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) f.name &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; (prefix + &lt;span class=&quot;code-quote&quot;&gt;&quot;.&quot;&lt;/span&gt; + f.name)
    val colnameSelect = &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (prefix == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) f.name &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; (prefixSelect + &lt;span class=&quot;code-quote&quot;&gt;&quot;.&quot;&lt;/span&gt; + f.name)

    f.dataType match {
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; st: StructType =&amp;gt; flattenSchema(st, colName, colnameSelect)
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt;
        Array(col(colName).as(colnameSelect))
    }
  })
}

val flattenColumns = flattenSchema(df.schema)
val flattenedDf = df.select(flattenColumns: _*)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now using the string indexer on the DOT notation.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val si = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringIndexer().setInputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;location.longitude&quot;&lt;/span&gt;).setOutputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;longitutdee&quot;&lt;/span&gt;)
val pipeline = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Pipeline().setStages(Array(si))
pipeline.fit(flattenedDf).transform(flattenedDf).show() &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above code fails&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
xception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; org.apache.spark.sql.AnalysisException: Cannot resolve column name &lt;span class=&quot;code-quote&quot;&gt;&quot;location.longitude&quot;&lt;/span&gt; among (location.longitude, location.latitude, salary); did you mean to quote the `location.longitude` column?
&#160; &#160; at org.apache.spark.sql.errors.QueryCompilationErrors$.cannotResolveColumnNameAmongFieldsError(QueryCompilationErrors.scala:2261)
&#160; &#160; at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(Dataset.scala:258)
&#160; &#160; at org.apache.spark.sql.Dataset.$anonfun$resolve$1(Dataset.scala:250)
..... &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This points to the same failure as when we try to select dot notation columns in a spark dataframe, which is solved using BACKTICKS &lt;b&gt;`column.name`.&lt;/b&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/a/51430335/11688337&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://stackoverflow.com/a/51430335/11688337&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;so next&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;I use the back ticks while defining stringIndexer&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val si = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringIndexer().setInputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;`location.longitude`&quot;&lt;/span&gt;).setOutputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;longitutdee&quot;&lt;/span&gt;) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In this case &lt;b&gt;it again fails&lt;/b&gt; (with a diff reason) in the stringIndexer code itself&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; org.apache.spark.SparkException: Input column `location.longitude` does not exist.
&#160; &#160; at org.apache.spark.ml.feature.StringIndexerBase.$anonfun$validateAndTransformSchema$2(StringIndexer.scala:128)
&#160; &#160; at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:244)
&#160; &#160; at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
&#160; &#160; at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;This blocks me to use feature transformation functions on nested columns.&#160;&lt;br/&gt;
Any help in solving this problem will be highly appreciated.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13580916">SPARK-48463</key>
            <summary>MLLib function unable to handle nested data</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="3" iconUrl="https://issues.apache.org/jira/images/icons/statuses/inprogress.png" description="This issue is being actively worked on at the moment by the assignee.">In Progress</status>
                    <statusCategory id="4" key="indeterminate" colorName="yellow"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="weichenxu123">Weichen Xu</assignee>
                                    <reporter username="chhavibansal">Chhavi Bansal</reporter>
                        <labels>
                            <label>ML</label>
                            <label>MLPipelines</label>
                            <label>mllib</label>
                            <label>nested</label>
                            <label>pull-request-available</label>
                    </labels>
                <created>Wed, 29 May 2024 18:28:28 +0000</created>
                <updated>Tue, 13 Aug 2024 07:49:31 +0000</updated>
                                            <version>3.5.1</version>
                                                    <component>ML</component>
                    <component>MLlib</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="17852751" author="skale1990" created="Thu, 6 Jun 2024 11:49:29 +0000"  >&lt;p&gt;As a temporary fix you may consider renaming the columns by adding a transformer as below-&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.ml.Transformer
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.ml.param.shared.{HasInputCol, HasOutputCol}
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.ml.param.{ParamMap, Params}
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.ml.util.{DefaultParamsReadable, DefaultParamsWritable, Identifiable}
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.{DataFrame, Dataset}
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.types.{StructField, StructType}

&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;RenameColumn(val uid: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Transformer with Params
  with HasInputCol with HasOutputCol with DefaultParamsWritable  {
  def &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;() = &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;(Identifiable.randomUID(&lt;span class=&quot;code-quote&quot;&gt;&quot;RenameColumn&quot;&lt;/span&gt;))

  &lt;span class=&quot;code-comment&quot;&gt;/** @group setParam */&lt;/span&gt;
  def setInputCol(value: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.type = set(inputCol, value)

  &lt;span class=&quot;code-comment&quot;&gt;/** @group setParam */&lt;/span&gt;
  def setOutputCol(value: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.type = set(outputCol, value)

  def validateAndTransformSchema(schema: StructType): StructType = {
    val col = schema(getInputCol)
    schema.add(StructField(getOutputCol, col.dataType, col.nullable, col.metadata))
  }

  def transformSchema(schema: StructType): StructType = validateAndTransformSchema(schema)

  def copy(extra: ParamMap): RenameColumn = defaultCopy(extra)

  override def transform(dataset: Dataset[_]): DataFrame = {
    transformSchema(dataset.schema, logging = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
    dataset.toDF().withColumnRenamed(getInputCol, getOutputCol)
  }
}

object RenameColumn &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; DefaultParamsReadable[RenameColumn] {
  override def load(path: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): RenameColumn = &lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;.load(path)
} &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and use the above transformer in the pipeline as below-&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val structureData = Seq(
  Row(Row(10, 12), 1000),
  Row(Row(12, 14), 4300),
  Row( Row(37, 891), 1400),
  Row(Row(8902, 12), 4000),
  Row(Row(12, 89), 1000)
)

val structureSchema = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructType()
  .add(&lt;span class=&quot;code-quote&quot;&gt;&quot;location&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructType()
    .add(&lt;span class=&quot;code-quote&quot;&gt;&quot;longitude&quot;&lt;/span&gt;, IntegerType)
    .add(&lt;span class=&quot;code-quote&quot;&gt;&quot;latitude&quot;&lt;/span&gt;, IntegerType))
  .add(&lt;span class=&quot;code-quote&quot;&gt;&quot;salary&quot;&lt;/span&gt;, IntegerType)
val df = spark.createDataFrame(spark.sparkContext.parallelize(structureData), structureSchema)

def flattenSchema(schema: StructType, prefix: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, prefixSelect: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;):
Array[Column] = {
  schema.fields.flatMap(f =&amp;gt; {
    val colName = &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (prefix == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) f.name &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; (prefix + &lt;span class=&quot;code-quote&quot;&gt;&quot;.&quot;&lt;/span&gt; + f.name)
    val colnameSelect = &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (prefix == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) f.name &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; (prefixSelect + &lt;span class=&quot;code-quote&quot;&gt;&quot;.&quot;&lt;/span&gt; + f.name)

    f.dataType match {
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; st: StructType =&amp;gt; flattenSchema(st, colName, colnameSelect)
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt;
        Array(col(colName).as(colnameSelect))
    }
  })
}

val flattenColumns = flattenSchema(df.schema)
val flattenedDf = df.select(flattenColumns: _*)

flattenedDf.printSchema
flattenedDf.show()

val renameColumn = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; RenameColumn().setInputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;location.longitude&quot;&lt;/span&gt;).setOutputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;location_longitude&quot;&lt;/span&gt;)
val si = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringIndexer().setInputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;location_longitude&quot;&lt;/span&gt;).setOutputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;longitutdee&quot;&lt;/span&gt;)
val pipeline = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Pipeline().setStages(Array(renameColumn, si))
pipeline.fit(flattenedDf).transform(flattenedDf).show()

/**
 * +------------------+-----------------+------+-----------+
 * |location_longitude|location.latitude|salary|longitutdee|
 * +------------------+-----------------+------+-----------+
 * |                10|               12|  1000|        1.0|
 * |                12|               14|  4300|        0.0|
 * |                37|              891|  1400|        2.0|
 * |              8902|               12|  4000|        3.0|
 * |                12|               89|  1000|        0.0|
 * +------------------+-----------------+------+-----------+
 */ &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17853332" author="JIRAUSER304338" created="Sat, 8 Jun 2024 06:28:11 +0000"  >&lt;p&gt;hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=skale1990&quot; class=&quot;user-hover&quot; rel=&quot;skale1990&quot;&gt;skale1990&lt;/a&gt;&#160;&lt;/p&gt;

&lt;p&gt;Thanks for responding. Yes, this seems like a valid workaround, but the columns in the dataset are huge, nearly 200+ so that would mean an addition of 200 stages for renaming. Also,&#160; the other problem would be that since the original columns would be renamed and when I display the data back to the users I would have to convert it back to DOT notation ( since that&apos;s what they are familiar with ), that would mean an additional overhead.&lt;/p&gt;</comment>
                            <comment id="17853363" author="skale1990" created="Sat, 8 Jun 2024 11:43:13 +0000"  >&lt;p&gt;I don&apos;t think renaming 200+ (simple metadata modification) columns causes addition 200+ stages. Spark is enough intelligent to handle that well. Please check exec plan for more details.&lt;/p&gt;

&lt;p&gt;Also, you can improve rename columns to rename multiple columns at once. This is, i think, least to do to unblock you till the bug is resolved.&lt;/p&gt;</comment>
                            <comment id="17853459" author="skale1990" created="Sun, 9 Jun 2024 04:07:29 +0000"  >&lt;p&gt;Currently there is no way to handle backtick(`) spark StructType. Hence the field name a.b and `a.b` are completely different within StructType.&#160;&lt;/p&gt;

&lt;p&gt;To handle that, I have added a custom implementation fixing StringIndexer#validateAndTransformSchema.&#160;You can refer to the code on&#160;&lt;a href=&quot;https://github.com/skale1990/LearnSpark/blob/main/src/main/java/com/som/learnspark/TestCustomStringIndexer.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;my github&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17854053" author="weichenxu123" created="Tue, 11 Jun 2024 13:37:25 +0000"  >&lt;p&gt;I think you don&#8217;t need to flatten the original dataframe.&lt;/p&gt;

&lt;p&gt;according to StringIndexer code,&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;private def getSelectedCols(dataset: Dataset&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;, inputCols: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;): Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Column&amp;#93;&lt;/span&gt; = {&lt;br/&gt;
&#160; inputCols.map &lt;/p&gt;
{ colName =&amp;gt;
&#160; &#160; val col = dataset.col(colName)
&#160; &#160; ...
&#160; }
&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;.setInputCol(&quot;location.longitude&quot;)&lt;/p&gt;

&lt;p&gt;should be able to work on original dataframe with nested column. But if you flatten it, the code is broken&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;</comment>
                            <comment id="17854153" author="JIRAUSER304338" created="Tue, 11 Jun 2024 18:32:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=weichenxu123&quot; class=&quot;user-hover&quot; rel=&quot;weichenxu123&quot;&gt;weichenxu123&lt;/a&gt; I tried using&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringIndexer().setInputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;location.longitude&quot;&lt;/span&gt;).setOutputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;longitutdee&quot;&lt;/span&gt;) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;without flattening the dataset, but it fails before going to &lt;b&gt;getSelectedCols() function,&lt;/b&gt;&#160;inside the&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
validateAndTransformSchema$2(StringIndexer.scala:128) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;code itself. did it work for you ?&lt;/p&gt;</comment>
                            <comment id="17854214" author="weichenxu123" created="Wed, 12 Jun 2024 01:03:38 +0000"  >&lt;p&gt;ah got it. then it is not supported &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;as a workaround, I think you can flatten the original dataframe and rename the new column like `location_longitude`(avoid using `.` in column name), then it should work.&lt;/p&gt;</comment>
                            <comment id="17854962" author="JIRAUSER304338" created="Fri, 14 Jun 2024 07:48:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=weichenxu123&quot; class=&quot;user-hover&quot; rel=&quot;weichenxu123&quot;&gt;weichenxu123&lt;/a&gt;&#160; do you think this should be taken as a feature enhancement ticket? Because Using an `_` is not always convenient, for ex: Customers would expect column name in dot notation, while we might be internally renaming to _, hence we would have to convert back to &apos;.&apos; (dot notation) causing an overhead.&lt;br/&gt;
Can you please let me know how this feature request could be created?&lt;/p&gt;</comment>
                            <comment id="17855160" author="weichenxu123" created="Sat, 15 Jun 2024 01:00:59 +0000"  >&lt;p&gt;I reopened this. I will improve mllib code to support this feature request&lt;/p&gt;</comment>
                            <comment id="17855714" author="JIRAUSER304338" created="Mon, 17 Jun 2024 19:19:16 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=weichenxu123&quot; class=&quot;user-hover&quot; rel=&quot;weichenxu123&quot;&gt;weichenxu123&lt;/a&gt; for reopening the ticket, is there some estimation of the task?&lt;/p&gt;</comment>
                            <comment id="17856713" author="weichenxu123" created="Fri, 21 Jun 2024 09:46:20 +0000"  >&lt;p&gt;I will try to do it this sprint. (and then cherrypick it to databricks runtime)&lt;/p&gt;</comment>
                            <comment id="17856832" author="JIRAUSER304338" created="Fri, 21 Jun 2024 17:32:16 +0000"  >&lt;p&gt;Thank you for the update.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 20 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1pi4o:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>