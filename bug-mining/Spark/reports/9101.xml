<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:33:43 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-44040] Incorrect result after count distinct</title>
                <link>https://issues.apache.org/jira/browse/SPARK-44040</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When i try to call count after distinct function for Decimal null field, spark return incorrect result starting from spark 3.4.0.&lt;br/&gt;
A minimal example to reproduce:&lt;/p&gt;

&lt;p&gt;import org.apache.spark.sql.types._&lt;br/&gt;
import org.apache.spark.sql.{Column, DataFrame, Dataset, Row, SparkSession}&lt;br/&gt;
import org.apache.spark.sql.types.{StringType, StructField, StructType}&lt;br/&gt;
val schema = StructType( Array(&lt;br/&gt;
StructField(&quot;money&quot;, DecimalType(38,6), true),&lt;br/&gt;
StructField(&quot;reference_id&quot;, StringType, true)&lt;br/&gt;
))&lt;/p&gt;

&lt;p&gt;val payDf = spark.createDataFrame(sc.emptyRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;Row&amp;#93;&lt;/span&gt;, schema)&lt;/p&gt;

&lt;p&gt;val aggDf = payDf.agg(sum(&quot;money&quot;).as(&quot;money&quot;)).withColumn(&quot;name&quot;, lit(&quot;df1&quot;))&lt;br/&gt;
val aggDf1 = payDf.agg(sum(&quot;money&quot;).as(&quot;money&quot;)).withColumn(&quot;name&quot;, lit(&quot;df2&quot;))&lt;br/&gt;
val unionDF: DataFrame = aggDf.union(aggDf1)&lt;br/&gt;
unionDF.select(&quot;money&quot;).distinct.show // return correct result&lt;br/&gt;
unionDF.select(&quot;money&quot;).distinct.count // return 2 instead of 1&lt;br/&gt;
unionDF.select(&quot;money&quot;).distinct.count == 1 // return false&lt;/p&gt;


&lt;p&gt;This block of code returns some assertion error and after that an incorrect count (in spark 3.2.1 everything works fine and i get correct result = 1):&lt;/p&gt;

&lt;p&gt;&lt;b&gt;scala&amp;gt; unionDF.select(&quot;money&quot;).distinct.show // return correct result&lt;/b&gt;&lt;br/&gt;
java.lang.AssertionError: assertion failed:&lt;br/&gt;
Decimal$DecimalIsFractional&lt;br/&gt;
while compiling: &amp;lt;console&amp;gt;&lt;br/&gt;
during phase: globalPhase=terminal, enteringPhase=jvm&lt;br/&gt;
library version: version 2.12.17&lt;br/&gt;
compiler version: version 2.12.17&lt;br/&gt;
reconstructed args: -classpath /Users/aleksandrov/.ivy2/jars/org.apache.spark_spark-connect_2.12-3.4.0.jar:/Users/aleksandrov/.ivy2/jars/io.delta_delta-core_2.12-2.4.0.jar:/Users/aleksandrov/.ivy2/jars/io.delta_delta-storage-2.4.0.jar:/Users/aleksandrov/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar:/Users/aleksandrov/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar -Yrepl-class-based -Yrepl-outdir /private/var/folders/qj/_dn4xbp14jn37qmdk7ylyfwc0000gr/T/spark-f37bb154-75f3-4db7-aea8-3c4363377bd8/repl-350f37a1-1df1-4816-bd62-97929c60a6c1&lt;/p&gt;

&lt;p&gt;last tree to typer: TypeTree(class Byte)&lt;br/&gt;
tree position: line 6 of &amp;lt;console&amp;gt;&lt;br/&gt;
tree tpe: Byte&lt;br/&gt;
symbol: (final abstract) class Byte in package scala&lt;br/&gt;
symbol definition: final abstract class Byte extends (a ClassSymbol)&lt;br/&gt;
symbol package: scala&lt;br/&gt;
symbol owners: class Byte&lt;br/&gt;
call site: constructor $eval in object $eval in package $line19&lt;/p&gt;

&lt;p&gt;== Source file context for tree position ==&lt;/p&gt;

&lt;p&gt;3&lt;br/&gt;
4object $eval {&lt;br/&gt;
5lazyval $result = $line19.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.res0&lt;br/&gt;
6lazyval $print: &lt;em&gt;root&lt;/em&gt;.java.lang.String = {&lt;br/&gt;
7 $line19.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw&lt;br/&gt;
8&lt;br/&gt;
9&quot;&quot;&lt;br/&gt;
at scala.reflect.internal.SymbolTable.throwAssertionError(SymbolTable.scala:185)&lt;br/&gt;
at scala.reflect.internal.Symbols$Symbol.completeInfo(Symbols.scala:1525)&lt;br/&gt;
at scala.reflect.internal.Symbols$Symbol.info(Symbols.scala:1514)&lt;br/&gt;
at scala.reflect.internal.Symbols$Symbol.flatOwnerInfo(Symbols.scala:2353)&lt;br/&gt;
at scala.reflect.internal.Symbols$ClassSymbol.companionModule0(Symbols.scala:3346)&lt;br/&gt;
at scala.reflect.internal.Symbols$ClassSymbol.companionModule(Symbols.scala:3348)&lt;br/&gt;
at scala.reflect.internal.Symbols$ModuleClassSymbol.sourceModule(Symbols.scala:3487)&lt;br/&gt;
at scala.reflect.internal.Symbols.$anonfun$forEachRelevantSymbols$1$adapted(Symbols.scala:3802)&lt;br/&gt;
at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)&lt;br/&gt;
at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)&lt;br/&gt;
at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)&lt;br/&gt;
at scala.reflect.internal.Symbols.markFlagsCompleted(Symbols.scala:3799)&lt;br/&gt;
at scala.reflect.internal.Symbols.markFlagsCompleted$(Symbols.scala:3805)&lt;br/&gt;
at scala.reflect.internal.SymbolTable.markFlagsCompleted(SymbolTable.scala:28)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.finishSym$1(UnPickler.scala:324)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.readSymbol(UnPickler.scala:342)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.readSymbolRef(UnPickler.scala:645)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.readType(UnPickler.scala:413)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.$anonfun$readSymbol$10(UnPickler.scala:357)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.at(UnPickler.scala:188)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.readSymbol(UnPickler.scala:357)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.$anonfun$run$1(UnPickler.scala:96)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler$Scan.run(UnPickler.scala:88)&lt;br/&gt;
at scala.reflect.internal.pickling.UnPickler.unpickle(UnPickler.scala:47)&lt;br/&gt;
at scala.tools.nsc.symtab.classfile.ClassfileParser.unpickleOrParseInnerClasses(ClassfileParser.scala:1173)&lt;br/&gt;
at scala.tools.nsc.symtab.classfile.ClassfileParser.parseClass(ClassfileParser.scala:467)&lt;br/&gt;
at scala.tools.nsc.symtab.classfile.ClassfileParser.$anonfun$parse$2(ClassfileParser.scala:160)&lt;br/&gt;
at scala.tools.nsc.symtab.classfile.ClassfileParser.$anonfun$parse$1(ClassfileParser.scala:146)&lt;br/&gt;
at scala.tools.nsc.symtab.classfile.ClassfileParser.parse(ClassfileParser.scala:129)&lt;br/&gt;
at scala.tools.nsc.symtab.SymbolLoaders$ClassfileLoader.doComplete(SymbolLoaders.scala:343)&lt;br/&gt;
at scala.tools.nsc.symtab.SymbolLoaders$SymbolLoader.complete(SymbolLoaders.scala:250)&lt;br/&gt;
at scala.tools.nsc.symtab.SymbolLoaders$SymbolLoader.load(SymbolLoaders.scala:269)&lt;br/&gt;
at scala.reflect.internal.Symbols$Symbol.exists(Symbols.scala:1104)&lt;br/&gt;
at scala.reflect.internal.Symbols$Symbol.toOption(Symbols.scala:2609)&lt;br/&gt;
at scala.tools.nsc.interpreter.IMain.translateSimpleResource(IMain.scala:340)&lt;br/&gt;
at scala.tools.nsc.interpreter.IMain$TranslatingClassLoader.findAbstractFile(IMain.scala:354)&lt;br/&gt;
at scala.reflect.internal.util.AbstractFileClassLoader.findResource(AbstractFileClassLoader.scala:76)&lt;br/&gt;
at java.base/java.lang.ClassLoader.getResource(ClassLoader.java:1401)&lt;br/&gt;
at java.base/java.lang.ClassLoader.getResourceAsStream(ClassLoader.java:1737)&lt;br/&gt;
at scala.reflect.internal.util.RichClassLoader$.classAsStream$extension(ScalaClassLoader.scala:89)&lt;br/&gt;
at scala.reflect.internal.util.RichClassLoader$.classBytes$extension(ScalaClassLoader.scala:81)&lt;br/&gt;
at scala.reflect.internal.util.ScalaClassLoader.classBytes(ScalaClassLoader.scala:131)&lt;br/&gt;
at scala.reflect.internal.util.ScalaClassLoader.classBytes$(ScalaClassLoader.scala:131)&lt;br/&gt;
at scala.reflect.internal.util.AbstractFileClassLoader.classBytes(AbstractFileClassLoader.scala:41)&lt;br/&gt;
at scala.reflect.internal.util.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:70)&lt;br/&gt;
at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)&lt;br/&gt;
at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:576)&lt;br/&gt;
at org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40)&lt;br/&gt;
at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)&lt;br/&gt;
at org.codehaus.janino.ClassLoaderIClassLoader.findIClass(ClassLoaderIClassLoader.java:75)&lt;br/&gt;
at org.codehaus.janino.IClassLoader.loadIClass(IClassLoader.java:317)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.findTypeByName(UnitCompiler.java:8895)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.reclassifyName(UnitCompiler.java:9115)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.reclassifyName(UnitCompiler.java:8806)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.reclassify(UnitCompiler.java:8667)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:7194)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$18100(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$26.visitAmbiguousName(UnitCompiler.java:6785)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$26.visitAmbiguousName(UnitCompiler.java:6784)&lt;br/&gt;
at org.codehaus.janino.Java$AmbiguousName.accept(Java.java:4603)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6784)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$15100(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$25.visitLvalue(UnitCompiler.java:6745)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$25.visitLvalue(UnitCompiler.java:6742)&lt;br/&gt;
at org.codehaus.janino.Java$Lvalue.accept(Java.java:4528)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6742)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$14400(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$23.visitRvalue(UnitCompiler.java:6690)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$23.visitRvalue(UnitCompiler.java:6681)&lt;br/&gt;
at org.codehaus.janino.Java$Rvalue.accept(Java.java:4495)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6681)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.findIMethod(UnitCompiler.java:9392)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.getType2(UnitCompiler.java:7486)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$16100(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$25.visitMethodInvocation(UnitCompiler.java:6756)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$25.visitMethodInvocation(UnitCompiler.java:6742)&lt;br/&gt;
at org.codehaus.janino.Java$MethodInvocation.accept(Java.java:5470)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.getType(UnitCompiler.java:6742)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.findMostSpecificIInvocable(UnitCompiler.java:9590)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.findIMethod(UnitCompiler.java:9475)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.findIMethod(UnitCompiler.java:9391)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileGet2(UnitCompiler.java:5232)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$9300(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$16.visitMethodInvocation(UnitCompiler.java:4735)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$16.visitMethodInvocation(UnitCompiler.java:4711)&lt;br/&gt;
at org.codehaus.janino.Java$MethodInvocation.accept(Java.java:5470)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileGet(UnitCompiler.java:4711)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileGetValue(UnitCompiler.java:5854)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:4101)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$6300(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$13.visitAssignment(UnitCompiler.java:4057)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$13.visitAssignment(UnitCompiler.java:4040)&lt;br/&gt;
at org.codehaus.janino.Java$Assignment.accept(Java.java:4864)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:4040)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2523)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$1800(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitExpressionStatement(UnitCompiler.java:1580)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitExpressionStatement(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.Java$ExpressionStatement.accept(Java.java:3209)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1661)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1646)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$1700(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1579)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.Java$Block.accept(Java.java:3115)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2659)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$1900(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitIfStatement(UnitCompiler.java:1581)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitIfStatement(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.Java$IfStatement.accept(Java.java:3284)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1661)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1646)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$1700(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1579)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.Java$Block.accept(Java.java:3115)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2637)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$1900(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitIfStatement(UnitCompiler.java:1581)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitIfStatement(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.Java$IfStatement.accept(Java.java:3284)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1661)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1646)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$1700(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1579)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitBlock(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.Java$Block.accept(Java.java:3115)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2001)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$2200(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitWhileStatement(UnitCompiler.java:1584)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$6.visitWhileStatement(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.Java$WhileStatement.accept(Java.java:3389)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1575)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1661)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:3658)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:3329)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1447)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1420)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:829)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:1026)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$700(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$3.visitMemberClassDeclaration(UnitCompiler.java:425)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$3.visitMemberClassDeclaration(UnitCompiler.java:418)&lt;br/&gt;
at org.codehaus.janino.Java$MemberClassDeclaration.accept(Java.java:1533)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:418)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileDeclaredMemberTypes(UnitCompiler.java:1397)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:864)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:442)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$3.visitPackageMemberClassDeclaration(UnitCompiler.java:422)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$3.visitPackageMemberClassDeclaration(UnitCompiler.java:418)&lt;br/&gt;
at org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1688)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:418)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:392)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.access$000(UnitCompiler.java:236)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$2.visitCompilationUnit(UnitCompiler.java:363)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler$2.visitCompilationUnit(UnitCompiler.java:361)&lt;br/&gt;
at org.codehaus.janino.Java$CompilationUnit.accept(Java.java:371)&lt;br/&gt;
at org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:361)&lt;br/&gt;
at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:264)&lt;br/&gt;
at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:294)&lt;br/&gt;
at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:288)&lt;br/&gt;
at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:267)&lt;br/&gt;
at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:82)&lt;br/&gt;
at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:1496)&lt;br/&gt;
at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1586)&lt;br/&gt;
at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1583)&lt;br/&gt;
at org.sparkproject.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)&lt;br/&gt;
at org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)&lt;br/&gt;
at org.sparkproject.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)&lt;br/&gt;
at org.sparkproject.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)&lt;br/&gt;
at org.sparkproject.guava.cache.LocalCache.get(LocalCache.java:4000)&lt;br/&gt;
at org.sparkproject.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)&lt;br/&gt;
at org.sparkproject.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)&lt;br/&gt;
at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:1443)&lt;br/&gt;
at org.apache.spark.sql.execution.WholeStageCodegenExec.liftedTree1$1(WholeStageCodegenExec.scala:726)&lt;br/&gt;
at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:725)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)&lt;br/&gt;
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)&lt;br/&gt;
at org.apache.spark.sql.execution.UnionExec.$anonfun$doExecute$5(basicPhysicalOperators.scala:699)&lt;br/&gt;
at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)&lt;br/&gt;
at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)&lt;br/&gt;
at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)&lt;br/&gt;
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)&lt;br/&gt;
at scala.collection.TraversableLike.map(TraversableLike.scala:286)&lt;br/&gt;
at scala.collection.TraversableLike.map$(TraversableLike.scala:279)&lt;br/&gt;
at scala.collection.AbstractTraversable.map(Traversable.scala:108)&lt;br/&gt;
at org.apache.spark.sql.execution.UnionExec.doExecute(basicPhysicalOperators.scala:699)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)&lt;br/&gt;
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)&lt;br/&gt;
at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:527)&lt;br/&gt;
at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:455)&lt;br/&gt;
at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:454)&lt;br/&gt;
at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:498)&lt;br/&gt;
at org.apache.spark.sql.execution.aggregate.AggregateCodegenSupport.inputRDDs(AggregateCodegenSupport.scala:89)&lt;br/&gt;
at org.apache.spark.sql.execution.aggregate.AggregateCodegenSupport.inputRDDs$(AggregateCodegenSupport.scala:88)&lt;br/&gt;
at org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:47)&lt;br/&gt;
at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:751)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)&lt;br/&gt;
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)&lt;br/&gt;
at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:135)&lt;br/&gt;
at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:135)&lt;br/&gt;
at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture$lzycompute(ShuffleExchangeExec.scala:140)&lt;br/&gt;
at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture(ShuffleExchangeExec.scala:139)&lt;br/&gt;
at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.$anonfun$submitShuffleJob$1(ShuffleExchangeExec.scala:68)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)&lt;br/&gt;
at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)&lt;br/&gt;
at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)&lt;br/&gt;
at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob(ShuffleExchangeExec.scala:68)&lt;br/&gt;
at org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob$(ShuffleExchangeExec.scala:67)&lt;br/&gt;
at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.submitShuffleJob(ShuffleExchangeExec.scala:115)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture$lzycompute(QueryStageExec.scala:181)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture(QueryStageExec.scala:181)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.doMaterialize(QueryStageExec.scala:183)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.QueryStageExec.materialize(QueryStageExec.scala:82)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5(AdaptiveSparkPlanExec.scala:266)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5$adapted(AdaptiveSparkPlanExec.scala:264)&lt;br/&gt;
at scala.collection.Iterator.foreach(Iterator.scala:943)&lt;br/&gt;
at scala.collection.Iterator.foreach$(Iterator.scala:943)&lt;br/&gt;
at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)&lt;br/&gt;
at scala.collection.IterableLike.foreach(IterableLike.scala:74)&lt;br/&gt;
at scala.collection.IterableLike.foreach$(IterableLike.scala:73)&lt;br/&gt;
at scala.collection.AbstractIterable.foreach(Iterable.scala:56)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:264)&lt;br/&gt;
at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:236)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:381)&lt;br/&gt;
at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:354)&lt;br/&gt;
at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4177)&lt;br/&gt;
at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3161)&lt;br/&gt;
at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4167)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526)&lt;br/&gt;
at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4165)&lt;br/&gt;
at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)&lt;br/&gt;
at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)&lt;br/&gt;
at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)&lt;br/&gt;
at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)&lt;br/&gt;
at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)&lt;br/&gt;
at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4165)&lt;br/&gt;
at org.apache.spark.sql.Dataset.head(Dataset.scala:3161)&lt;br/&gt;
at org.apache.spark.sql.Dataset.take(Dataset.scala:3382)&lt;br/&gt;
at org.apache.spark.sql.Dataset.getRows(Dataset.scala:284)&lt;br/&gt;
at org.apache.spark.sql.Dataset.showString(Dataset.scala:323)&lt;br/&gt;
at org.apache.spark.sql.Dataset.show(Dataset.scala:809)&lt;br/&gt;
at org.apache.spark.sql.Dataset.show(Dataset.scala:768)&lt;br/&gt;
at org.apache.spark.sql.Dataset.show(Dataset.scala:777)&lt;br/&gt;
at $line19.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:29)&lt;br/&gt;
at $line19.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:33)&lt;br/&gt;
at $line19.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:35)&lt;br/&gt;
at $line19.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:37)&lt;br/&gt;
at $line19.$read$$iw$$iw$$iw$$iw$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:39)&lt;br/&gt;
at $line19.$read$$iw$$iw$$iw$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:41)&lt;br/&gt;
at $line19.$read$$iw$$iw$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:43)&lt;br/&gt;
at $line19.$read$$iw$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:45)&lt;br/&gt;
at $line19.$read$$iw$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:47)&lt;br/&gt;
at $line19.$read$$iw.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:49)&lt;br/&gt;
at $line19.$read.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:51)&lt;br/&gt;
at $line19.$read$.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:55)&lt;br/&gt;
at $line19.$read$.&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)&lt;br/&gt;
at $line19.$eval$.$print$lzycompute(&amp;lt;console&amp;gt;:7)&lt;br/&gt;
at $line19.$eval$.$print(&amp;lt;console&amp;gt;:6)&lt;br/&gt;
at $line19.$eval.$print(&amp;lt;console&amp;gt;)&lt;br/&gt;
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
at java.base/java.lang.reflect.Method.invoke(Method.java:566)&lt;br/&gt;
at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:747)&lt;br/&gt;
at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1020)&lt;br/&gt;
at scala.tools.nsc.interpreter.IMain.$anonfun$interpret$1(IMain.scala:568)&lt;br/&gt;
at scala.reflect.internal.util.ScalaClassLoader.asContext(ScalaClassLoader.scala:36)&lt;br/&gt;
at scala.reflect.internal.util.ScalaClassLoader.asContext$(ScalaClassLoader.scala:116)&lt;br/&gt;
at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:41)&lt;br/&gt;
at scala.tools.nsc.interpreter.IMain.loadAndRunReq$1(IMain.scala:567)&lt;br/&gt;
at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:594)&lt;br/&gt;
at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:564)&lt;br/&gt;
at scala.tools.nsc.interpreter.ILoop.interpretStartingWith(ILoop.scala:865)&lt;br/&gt;
at scala.tools.nsc.interpreter.ILoop.command(ILoop.scala:733)&lt;br/&gt;
at scala.tools.nsc.interpreter.ILoop.processLine(ILoop.scala:435)&lt;br/&gt;
at scala.tools.nsc.interpreter.ILoop.loop(ILoop.scala:456)&lt;br/&gt;
at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:239)&lt;br/&gt;
at org.apache.spark.repl.Main$.doMain(Main.scala:78)&lt;br/&gt;
at org.apache.spark.repl.Main$.main(Main.scala:58)&lt;br/&gt;
at org.apache.spark.repl.Main.main(Main.scala)&lt;br/&gt;
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
at java.base/java.lang.reflect.Method.invoke(Method.java:566)&lt;br/&gt;
at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1020)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:192)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:215)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:91)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1111)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1120)&lt;br/&gt;
at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)&lt;br/&gt;
error: error while loading Decimal, class file &apos;/Users/aleksandrov/Projects/apache/spark-3.4.0-bin-hadoop3/jars/spark-catalyst_2.12-3.4.0.jar(org/apache/spark/sql/types/Decimal.class)&apos; is broken&lt;br/&gt;
(class java.lang.RuntimeException/error reading Scala signature of Decimal.class: assertion failed:&lt;br/&gt;
Decimal$DecimalIsFractional&lt;br/&gt;
while compiling: &amp;lt;console&amp;gt;&lt;br/&gt;
during phase: globalPhase=terminal, enteringPhase=jvm&lt;br/&gt;
library version: version 2.12.17&lt;br/&gt;
compiler version: version 2.12.17&lt;br/&gt;
reconstructed args: -classpath /Users/aleksandrov/.ivy2/jars/org.apache.spark_spark-connect_2.12-3.4.0.jar:/Users/aleksandrov/.ivy2/jars/io.delta_delta-core_2.12-2.4.0.jar:/Users/aleksandrov/.ivy2/jars/io.delta_delta-storage-2.4.0.jar:/Users/aleksandrov/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar:/Users/aleksandrov/.ivy2/jars/org.antlr_antlr4-runtime-4.9.3.jar -Yrepl-class-based -Yrepl-outdir /private/var/folders/qj/_dn4xbp14jn37qmdk7ylyfwc0000gr/T/spark-f37bb154-75f3-4db7-aea8-3c4363377bd8/repl-350f37a1-1df1-4816-bd62-97929c60a6c1&lt;/p&gt;

&lt;p&gt;last tree to typer: TypeTree(class Byte)&lt;br/&gt;
tree position: line 6 of &amp;lt;console&amp;gt;&lt;br/&gt;
tree tpe: Byte&lt;br/&gt;
symbol: (final abstract) class Byte in package scala&lt;br/&gt;
symbol definition: final abstract class Byte extends (a ClassSymbol)&lt;br/&gt;
symbol package: scala&lt;br/&gt;
symbol owners: class Byte&lt;br/&gt;
call site: constructor $eval in object $eval in package $line19&lt;/p&gt;

&lt;p&gt;== Source file context for tree position ==&lt;/p&gt;

&lt;p&gt;3&lt;br/&gt;
4object $eval {&lt;br/&gt;
5lazyval $result = res0&lt;br/&gt;
6lazyval $print: &lt;em&gt;root&lt;/em&gt;.java.lang.String = {&lt;br/&gt;
7 $iw&lt;br/&gt;
8&lt;br/&gt;
9&quot;&quot; )&lt;br/&gt;
&lt;ins&gt;-----&lt;/ins&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;money&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;-----&lt;/ins&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;null&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;-----&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;scala&amp;gt; unionDF.select(&quot;money&quot;).distinct.count // return 2 instead of 1&lt;/b&gt;&lt;br/&gt;
res1: Long = 2&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;scala&amp;gt; unionDF.select(&quot;money&quot;).distinct.count == 1 // return False&lt;/b&gt;&lt;br/&gt;
res2: Boolean = false&lt;/p&gt;</description>
                <environment></environment>
        <key id="13539864">SPARK-44040</key>
            <summary>Incorrect result after count distinct</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yumwang">Yuming Wang</assignee>
                                    <reporter username="boltonidze">Aleksandr Aleksandrov</reporter>
                        <labels>
                    </labels>
                <created>Tue, 13 Jun 2023 13:42:01 +0000</created>
                <updated>Fri, 16 Jun 2023 04:07:40 +0000</updated>
                            <resolved>Fri, 16 Jun 2023 04:07:40 +0000</resolved>
                                    <version>3.3.2</version>
                    <version>3.4.0</version>
                                    <fixVersion>3.3.3</fixVersion>
                    <fixVersion>3.4.1</fixVersion>
                    <fixVersion>3.5.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17732159" author="q79969786" created="Tue, 13 Jun 2023 16:15:54 +0000"  >&lt;p&gt;Thanks for reporting this bug. We will fix it soon.&lt;/p&gt;</comment>
                            <comment id="17732163" author="bersprockets" created="Tue, 13 Jun 2023 16:29:47 +0000"  >&lt;p&gt;It seems this can be reproduced in &lt;tt&gt;spark-sql&lt;/tt&gt; as well.&lt;/p&gt;

&lt;p&gt;Interestingly, turning off AQE seems to fix the issue (for both the above dataframe version and the below SQL version):&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;spark-sql (default)&amp;gt; create or replace temp view v1 as
select 1 as c1 limit 0;
Time taken: 0.959 seconds
spark-sql (default)&amp;gt; create or replace temp view agg1 as
select sum(c1) as c1, &quot;agg1&quot; as name
from v1;
Time taken: 0.16 seconds
spark-sql (default)&amp;gt; create or replace temp view agg2 as
select sum(c1) as c1, &quot;agg2&quot; as name
from v1;
Time taken: 0.035 seconds
spark-sql (default)&amp;gt; create or replace temp view union1 as
select * from agg1
union
select * from agg2;
Time taken: 0.088 seconds
spark-sql (default)&amp;gt; -- the following incorrectly produces 2 rows
select distinct c1 from union1;
NULL
NULL
Time taken: 1.649 seconds, Fetched 2 row(s)
spark-sql (default)&amp;gt; set spark.sql.adaptive.enabled=false;
spark.sql.adaptive.enabled	false
Time taken: 0.019 seconds, Fetched 1 row(s)
spark-sql (default)&amp;gt; -- the following correctly produces 1 row
select distinct c1 from union1;
NULL
Time taken: 1.372 seconds, Fetched 1 row(s)
spark-sql (default)&amp;gt; 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17732170" author="q79969786" created="Tue, 13 Jun 2023 16:35:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/41576&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/41576&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17732461" author="githubbot" created="Wed, 14 Jun 2023 09:16:57 +0000"  >&lt;p&gt;User &apos;wangyum&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/41576&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/41576&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17733309" author="q79969786" created="Fri, 16 Jun 2023 04:07:40 +0000"  >&lt;p&gt;Issue resolved by pull request 41576&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/41576&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/41576&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13427451">SPARK-38162</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 21 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1iipk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12352874">3.4.1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>