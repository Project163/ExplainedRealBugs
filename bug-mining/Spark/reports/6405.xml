<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:04:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-27338] Deadlock between TaskMemoryManager and UnsafeExternalSorter$SpillableIterator</title>
                <link>https://issues.apache.org/jira/browse/SPARK-27338</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We saw similar deadlock like this &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26265&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-26265&lt;/a&gt; happening between TaskMemoryManager and UnsafeExternalSorted$SpillableIterator&lt;/p&gt;

&lt;p&gt;Jstack output:&lt;/p&gt;

&lt;p&gt;jstack information as follow:&lt;/p&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Found one Java-level deadlock:
=============================
&lt;span class=&quot;code-quote&quot;&gt;&quot;stdout writer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /usr/lib/envs/env-1923-ver-1755-a-4.2.9-py-3.5.3/bin/python&quot;&lt;/span&gt;:
  waiting to lock monitor 0x00007fce56409088 (object 0x00000005700a2f98, a org.apache.spark.memory.TaskMemoryManager),
  which is held by &lt;span class=&quot;code-quote&quot;&gt;&quot;Executor task launch worker &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; task 2203&quot;&lt;/span&gt;
&lt;span class=&quot;code-quote&quot;&gt;&quot;Executor task launch worker &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; task 2203&quot;&lt;/span&gt;:
  waiting to lock monitor 0x00000000007cd878 (object 0x00000005701a0eb0, a org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator),
  which is held by &lt;span class=&quot;code-quote&quot;&gt;&quot;stdout writer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /usr/lib/envs/env-1923-ver-1755-a-4.2.9-py-3.5.3/bin/python&quot;&lt;/span&gt;

Java stack information &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the threads listed above:
===================================================
&lt;span class=&quot;code-quote&quot;&gt;&quot;stdout writer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /usr/lib/envs/env-1923-ver-1755-a-4.2.9-py-3.5.3/bin/python&quot;&lt;/span&gt;:
	at org.apache.spark.memory.TaskMemoryManager.freePage(TaskMemoryManager.java:334)
	- waiting to lock &amp;lt;0x00000005700a2f98&amp;gt; (a org.apache.spark.memory.TaskMemoryManager)
	at org.apache.spark.memory.MemoryConsumer.freePage(MemoryConsumer.java:130)
	at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.access$1100(UnsafeExternalSorter.java:48)
	at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator.loadNext(UnsafeExternalSorter.java:583)
	- locked &amp;lt;0x00000005701a0eb0&amp;gt; (a org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator)
	at org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:187)
	at org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:174)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.findNextInnerJoinRows$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage10.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$2.hasNext(WholeStageCodegenExec.scala:638)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	at scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2067)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
&lt;span class=&quot;code-quote&quot;&gt;&quot;Executor task launch worker &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; task 2203&quot;&lt;/span&gt;:
	at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator.spill(UnsafeExternalSorter.java:525)
	- waiting to lock &amp;lt;0x00000005701a0eb0&amp;gt; (a org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator)
	at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.spill(UnsafeExternalSorter.java:200)
	at org.apache.spark.memory.TaskMemoryManager.acquireExecutionMemory(TaskMemoryManager.java:177)
	- locked &amp;lt;0x00000005700a2f98&amp;gt; (a org.apache.spark.memory.TaskMemoryManager)
	at org.apache.spark.memory.TaskMemoryManager.allocatePage(TaskMemoryManager.java:285)
	at org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:117)
	at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:383)
	at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:407)
	at org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:135)
	at org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:217)
	at org.apache.spark.sql.execution.SortExec$$anonfun$1.apply(SortExec.scala:108)
	at org.apache.spark.sql.execution.SortExec$$anonfun$1.apply(SortExec.scala:101)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:403)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1473)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)

Found 1 deadlock.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13225316">SPARK-27338</key>
            <summary>Deadlock between TaskMemoryManager and UnsafeExternalSorter$SpillableIterator</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vsowrirajan">Venkata krishnan Sowrirajan</assignee>
                                    <reporter username="vsowrirajan">Venkata krishnan Sowrirajan</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Apr 2019 16:17:07 +0000</created>
                <updated>Thu, 4 Apr 2019 14:52:42 +0000</updated>
                            <resolved>Thu, 4 Apr 2019 02:05:56 +0000</resolved>
                                    <version>2.4.0</version>
                                    <fixVersion>2.3.4</fixVersion>
                    <fixVersion>2.4.2</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16806946" author="vsowrirajan" created="Mon, 1 Apr 2019 16:17:49 +0000"  >&lt;p&gt;We found this issue in one of the customer workload. Will file a PR for this issue shortly.&lt;/p&gt;</comment>
                            <comment id="16809435" author="cloud_fan" created="Thu, 4 Apr 2019 02:05:56 +0000"  >&lt;p&gt;Issue resolved by pull request 24265&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24265&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24265&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 32 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z01buw:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>