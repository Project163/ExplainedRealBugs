<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:56:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-19644] Memory leak in Spark Streaming (Encoder/Scala Reflection)</title>
                <link>https://issues.apache.org/jira/browse/SPARK-19644</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I am using streaming on the production for some aggregation and fetching data from cassandra and saving data back to cassandra. &lt;/p&gt;

&lt;p&gt;I see a gradual increase in old generation heap capacity from 1161216 Bytes to 1397760 Bytes over a period of six hours.&lt;/p&gt;

&lt;p&gt;After 50 hours of processing instances of class scala.collection.immutable.$colon$colon incresed to 12,811,793 which is a huge number. &lt;/p&gt;

&lt;p&gt;I think this is a clear case of memory leak&lt;/p&gt;

&lt;p&gt;Updated: The root cause is when creating an encoder object, it leaks several Scala internal objects due to a Scala memory leak issue: &lt;a href=&quot;https://github.com/scala/bug/issues/8302&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/scala/bug/issues/8302&lt;/a&gt;&lt;/p&gt;</description>
                <environment>&lt;p&gt;3 AWS EC2 c3.xLarge&lt;br/&gt;
Number of cores - 3&lt;br/&gt;
Number of executors 3 &lt;br/&gt;
Memory to each executor 2GB&lt;/p&gt;</environment>
        <key id="13043870">SPARK-19644</key>
            <summary>Memory leak in Spark Streaming (Encoder/Scala Reflection)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zsxwing">Shixiong Zhu</assignee>
                                    <reporter username="deenbandhu">Deenbandhu Agarwal</reporter>
                        <labels>
                            <label>memory_leak</label>
                            <label>performance</label>
                    </labels>
                <created>Fri, 17 Feb 2017 06:00:30 +0000</created>
                <updated>Fri, 10 Nov 2017 22:15:27 +0000</updated>
                            <resolved>Fri, 10 Nov 2017 22:15:27 +0000</resolved>
                                    <version>2.0.2</version>
                                    <fixVersion>2.2.1</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>DStreams</component>
                    <component>SQL</component>
                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>4</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="15871232" author="deenbandhu" created="Fri, 17 Feb 2017 06:06:33 +0000"  >&lt;p&gt;Snap shot of heap dump after 50 hours&lt;/p&gt;</comment>
                            <comment id="15871436" author="srowen" created="Fri, 17 Feb 2017 08:38:53 +0000"  >&lt;p&gt;What you have described so far is not a memory leak in Spark. It&apos;s normal for the heap to grow unless it has reason to even garbage collect. You&apos;re not evidently running out of memory. You&apos;re talking about a heap change of 1.1 to 1.3MB, which is trivial (is this a typo?). I&apos;d close this unless you have a clearer case.&lt;/p&gt;</comment>
                            <comment id="15871444" author="deenbandhu" created="Fri, 17 Feb 2017 08:43:50 +0000"  >&lt;p&gt;you can ignore that change in memory but if you look in the snapshot the number of instances of class scala.collection.immutable.$colon$colon it had increased too high and it keep on increasing over the period of time&lt;/p&gt;</comment>
                            <comment id="15871452" author="srowen" created="Fri, 17 Feb 2017 08:50:10 +0000"  >&lt;p&gt;There are just linked list objects. Why are they too high? if you have plenty of heap, Java won&apos;t bother GCing  until it needs to.&lt;/p&gt;</comment>
                            <comment id="15871477" author="deenbandhu" created="Fri, 17 Feb 2017 09:03:26 +0000"  >&lt;p&gt;No i had just given 2 GB driver memory and if there is not any reference to them the Full GC should clean them but it is not get cleaned thats why i think there is memory leak&lt;/p&gt;</comment>
                            <comment id="15871494" author="deenbandhu" created="Fri, 17 Feb 2017 09:14:52 +0000"  >&lt;p&gt;And after 40-50 hours full gc is too frequent that all cores of machines are over utilized and batches start to queue up in streaming and I need to restart the streaming&lt;/p&gt;</comment>
                            <comment id="15871503" author="srowen" created="Fri, 17 Feb 2017 09:19:09 +0000"  >&lt;p&gt;You only show 400MB of lists in your screen dump.&lt;br/&gt;
Running out of memory doesn&apos;t mean a leak. The question is what is holding on to the memory? This isn&apos;t a big heap to begin with.&lt;/p&gt;</comment>
                            <comment id="15871515" author="deenbandhu" created="Fri, 17 Feb 2017 09:28:18 +0000"  >&lt;p&gt;Yes that&apos;s right running out of memory doesn&apos;t mean a leak but gradual increase in heap size and inability of GC to clear the memory is a memory leak. Ideally the number of linked list objects should not be increasing over the period of time and that increase is suggesting that there is a memory leak. &lt;/p&gt;</comment>
                            <comment id="15871519" author="srowen" created="Fri, 17 Feb 2017 09:29:56 +0000"  >&lt;p&gt;This is still not necessarily true in general. Your app could be retaining state. This is why this isn&apos;t actionable as-is.&lt;/p&gt;</comment>
                            <comment id="15871528" author="deenbandhu" created="Fri, 17 Feb 2017 09:34:06 +0000"  >&lt;p&gt;We are not using any state or window operation and not using any check pointing so i don&apos;t think  that app is retaining state.&lt;/p&gt;</comment>
                            <comment id="15872672" author="zsxwing" created="Fri, 17 Feb 2017 22:39:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=deenbandhu&quot; class=&quot;user-hover&quot; rel=&quot;deenbandhu&quot;&gt;deenbandhu&lt;/a&gt; Could you check the GC root, please? These objects are from Scala reflection. Did you run the job in Spark shell?&lt;/p&gt;</comment>
                            <comment id="15874614" author="deenbandhu" created="Mon, 20 Feb 2017 14:39:44 +0000"  >&lt;p&gt;Sorry for the delayed response.&lt;/p&gt;

&lt;p&gt;No, I didn&apos;t run in spark shell. I ran using spark submit in client deploy mode on a standalone spark cluster.&lt;br/&gt;
I ran eclipse MAT on heap dump and attached the screenshot of dominator tree. I hope this will help you out to find the cause of memory leak. &lt;/p&gt;

&lt;p&gt;Also attached Path to GC root of the object of `scala.reflect.runtime.JavaUniverse` (for smaller heap dump taken at the application start).&lt;/p&gt;

&lt;p&gt;When I checked the path to GC root for an object of `scala.collection.immutable.$colon$colon` the path contains the same object(`scala.reflect.runtime.JavaUniverse`)&lt;/p&gt;</comment>
                            <comment id="15875702" author="deenbandhu" created="Tue, 21 Feb 2017 09:53:46 +0000"  >&lt;p&gt;I have analysed the issue more. I performed some of the experiments as follows and analysed the heapdump using jvisualvm at some intervals.&lt;/p&gt;

&lt;p&gt;1. Dstream.foreachRdd(rdd =&amp;gt; rdd.map(r =&amp;gt; someCaseClass(r)).take(10).foreach(println))&lt;/p&gt;

&lt;p&gt;2. Dstream.foreachRdd(rdd =&amp;gt; rdd.map(r =&amp;gt; someCaseClass(r)).toDF.show(10,false))&lt;/p&gt;

&lt;p&gt;3. Dstream.foreachRdd(rdd =&amp;gt; rdd.map(r =&amp;gt; someCaseClass(r)).toDS.show(10,false))&lt;/p&gt;

&lt;p&gt;I Observed that the number of instances of scala.collection.immutable.$colon$colon remain constant in 1 scenario but it keeps on increasing in 2 and 3 scenario. So I think there is something leaky in toDS or toDF function this may help you out to find out the issue.&lt;/p&gt;</comment>
                            <comment id="15879397" author="zsxwing" created="Wed, 22 Feb 2017 22:44:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=deenbandhu&quot; class=&quot;user-hover&quot; rel=&quot;deenbandhu&quot;&gt;deenbandhu&lt;/a&gt; Do you use Scala 2.10 or Scala 2.11?&lt;/p&gt;</comment>
                            <comment id="15879823" author="deenbandhu" created="Thu, 23 Feb 2017 04:12:28 +0000"  >&lt;p&gt;I am using scala 2.11&lt;/p&gt;</comment>
                            <comment id="15929979" author="deenbandhu" created="Fri, 17 Mar 2017 13:35:13 +0000"  >&lt;p&gt;Any updates ??&lt;/p&gt;</comment>
                            <comment id="15931150" author="srowen" created="Sat, 18 Mar 2017 09:50:54 +0000"  >&lt;p&gt;I don&apos;t think there is evidence of a memory leak here. It&apos;s not even clear it has GCed&lt;/p&gt;</comment>
                            <comment id="15931765" author="deenbandhu" created="Sun, 19 Mar 2017 15:58:37 +0000"  >&lt;p&gt;It&apos;s not even clear it has GCed ?&lt;/p&gt;

&lt;p&gt;The increase in total GC time is a clear indication of GC &lt;/p&gt;</comment>
                            <comment id="15931768" author="srowen" created="Sun, 19 Mar 2017 16:03:38 +0000"  >&lt;p&gt;I don&apos;t see any GC time here. &lt;br/&gt;
Is this not simple stuff like you have lots of old jobs and stage metrics info in the driver? There is not much memory used here compared to normal operation. Unless you&apos;ve tried stuff like restricting the number of retained jobs in the UI I don&apos;t think there is evidence of a problem. The dumps don&apos;t show anything that odd. &lt;/p&gt;</comment>
                            <comment id="15931771" author="deenbandhu" created="Sun, 19 Mar 2017 16:07:43 +0000"  >&lt;p&gt;Yes i have tried restricting the number of jobs retained in UI to 200 and moreover the default value is 1000 for number of retained batches and my batch interval is 10s so for 1000 batches it will take somewhere around 10000 sec which is equal to 3-4 hrs but it keeps on accumulating after that. I think there is something else which is creating problem &lt;/p&gt;</comment>
                            <comment id="15931774" author="srowen" created="Sun, 19 Mar 2017 16:09:39 +0000"  >&lt;p&gt;Use jcmd to trigger a full GC on the process to see what happens. &lt;/p&gt;</comment>
                            <comment id="15931778" author="deenbandhu" created="Sun, 19 Mar 2017 16:11:28 +0000"  >&lt;p&gt;full gc is trigger so many times and its frequency increases with time because of accumulated memory of that big object &lt;/p&gt;</comment>
                            <comment id="15931785" author="srowen" created="Sun, 19 Mar 2017 16:17:06 +0000"  >&lt;p&gt;The weird thing is memory retained by Scala runtime universe. I am still not clear if you are saying you run out memory or not. I also don&apos;t recall any other reports like this. If you have leads, post them here. &lt;/p&gt;</comment>
                            <comment id="16053494" author="dongjoon" created="Mon, 19 Jun 2017 05:49:53 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=deenbandhu&quot; class=&quot;user-hover&quot; rel=&quot;deenbandhu&quot;&gt;deenbandhu&lt;/a&gt;.&lt;br/&gt;
Could you try this with the latest versions like 2.1.1 or 2.2.0-RC4?&lt;/p&gt;</comment>
                            <comment id="16053498" author="deenbandhu" created="Mon, 19 Jun 2017 05:51:38 +0000"  >&lt;p&gt;yes i can try but is there any report of such events in that particular version &lt;/p&gt;</comment>
                            <comment id="16053502" author="deenbandhu" created="Mon, 19 Jun 2017 05:55:01 +0000"  >&lt;p&gt;And the spark cassandra connector is also not out for those spark version. which is a dependency for us&lt;/p&gt;</comment>
                            <comment id="16053509" author="dongjoon" created="Mon, 19 Jun 2017 06:02:23 +0000"  >&lt;p&gt;I see. Thank you anyway, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=deenbandhu&quot; class=&quot;user-hover&quot; rel=&quot;deenbandhu&quot;&gt;deenbandhu&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16233756" author="djh4230" created="Wed, 1 Nov 2017 07:57:20 +0000"  >&lt;p&gt;did the issue has been fixed? I am using spark 2.1.0 and i also encount the same scene. The driver memory keep increasing. I analysis the dump heap and find the class scala.collection.immutable.$colon$colon keep increasing.&lt;/p&gt;</comment>
                            <comment id="16234638" author="zsxwing" created="Wed, 1 Nov 2017 19:54:13 +0000"  >&lt;p&gt;I happened to investigate a similar issue and found out the leak is caused by Scala reflection. Please see my comment in &lt;a href=&quot;https://github.com/scala/bug/issues/8302&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/scala/bug/issues/8302&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My workaround is calling &quot;scala.reflect.runtime.universe.asInstanceOf&lt;span class=&quot;error&quot;&gt;&amp;#91;scala.reflect.runtime.JavaUniverse&amp;#93;&lt;/span&gt;.undoLog.clear()&quot; manually to clean up these garbage objects. You need to put this line in the same thread that you create Dataset/DataFrame as the leak happens in a thread local object. I think the best place in Spark streaming is foreachRDD.&lt;/p&gt;</comment>
                            <comment id="16234643" author="zsxwing" created="Wed, 1 Nov 2017 19:58:53 +0000"  >&lt;p&gt;By the way, you can confirm this issue by checking if the number of &quot;scala.reflect.internal.tpe.TypeConstraints$TypeConstraint&quot; is large.&lt;/p&gt;</comment>
                            <comment id="16234655" author="zsxwing" created="Wed, 1 Nov 2017 20:05:27 +0000"  >&lt;p&gt;I added more components since it also affects them. The major issue is when creating an encoder object, it leaks several Scala internal objects due to a Scala memory leak issue.&lt;/p&gt;</comment>
                            <comment id="16243171" author="apachespark" created="Wed, 8 Nov 2017 00:38:05 +0000"  >&lt;p&gt;User &apos;zsxwing&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19687&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19687&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16247973" author="apachespark" created="Fri, 10 Nov 2017 19:49:03 +0000"  >&lt;p&gt;User &apos;zsxwing&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19718&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19718&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12853565" name="Dominator_tree.png" size="276744" author="deenbandhu" created="Mon, 20 Feb 2017 14:31:05 +0000"/>
                            <attachment id="12853566" name="Path2GCRoot.png" size="322472" author="deenbandhu" created="Mon, 20 Feb 2017 14:34:41 +0000"/>
                            <attachment id="12853218" name="heapdump.png" size="117851" author="deenbandhu" created="Fri, 17 Feb 2017 06:06:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 1 week, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3a7vb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>