<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:30:54 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-9340] CatalystSchemaConverter and CatalystRowConverter don&apos;t handle unannotated repeated fields correctly</title>
                <link>https://issues.apache.org/jira/browse/SPARK-9340</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-6776&quot; title=&quot;Implement backwards-compatibility rules in Catalyst converters (which convert Parquet record to rows)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-6776&quot;&gt;&lt;del&gt;SPARK-6776&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-6777&quot; title=&quot;Implement backwards-compatibility rules in Parquet schema converters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-6777&quot;&gt;&lt;del&gt;SPARK-6777&lt;/del&gt;&lt;/a&gt; followed &lt;tt&gt;parquet-avro&lt;/tt&gt; to implement backwards-compatibility rules defined in &lt;tt&gt;parquet-format&lt;/tt&gt; spec. However, both Spark SQL and &lt;tt&gt;parquet-avro&lt;/tt&gt; neglected the following statement in &lt;tt&gt;parquet-format&lt;/tt&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This does not affect repeated fields that are not annotated: A repeated field that is neither contained by a &lt;tt&gt;LIST&lt;/tt&gt;- or &lt;tt&gt;MAP&lt;/tt&gt;-annotated group nor annotated by &lt;tt&gt;LIST&lt;/tt&gt; or &lt;tt&gt;MAP&lt;/tt&gt; should be interpreted as a required list of required elements where the element type is the type of the field.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;One of the consequences is that, Parquet files generated by &lt;tt&gt;parquet-protobuf&lt;/tt&gt; containing unannotated repeated fields are not correctly converted to Catalyst arrays.&lt;/p&gt;

&lt;p&gt;For example, the following Parquet schema&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;message root {
  repeated int32 f1
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; should be converted to&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;StructType(StructField(&quot;f1&quot;, ArrayType(IntegerType, containsNull = false), nullable = false) :: Nil)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;But now it triggers an &lt;tt&gt;AnalysisException&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12849085">SPARK-9340</key>
            <summary>CatalystSchemaConverter and CatalystRowConverter don&apos;t handle unannotated repeated fields correctly</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lian cheng">Cheng Lian</assignee>
                                    <reporter username="damianguy">Damian Guy</reporter>
                        <labels>
                    </labels>
                <created>Sat, 25 Jul 2015 11:33:28 +0000</created>
                <updated>Tue, 11 Aug 2015 04:47:25 +0000</updated>
                            <resolved>Tue, 11 Aug 2015 04:47:25 +0000</resolved>
                                    <version>1.2.0</version>
                    <version>1.3.0</version>
                    <version>1.4.0</version>
                    <version>1.5.0</version>
                                    <fixVersion>1.5.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="14641550" author="damianguy" created="Sat, 25 Jul 2015 11:35:20 +0000"  >&lt;p&gt;Failing test&lt;/p&gt;</comment>
                            <comment id="14641916" author="viirya" created="Sun, 26 Jul 2015 11:09:08 +0000"  >&lt;p&gt;Your test will cause org.apache.spark.sql.AnalysisException: REPEATED not supported outside LIST or MAP.&lt;/p&gt;

&lt;p&gt;I think that repeated type is only supported in a LIST or MAP. You can check CatalystSchemaConverter.convert.&lt;/p&gt;</comment>
                            <comment id="14642035" author="damianguy" created="Sun, 26 Jul 2015 17:20:10 +0000"  >&lt;p&gt;We have protubuf/parquet files (parquet 1.4.3) generated from M/R jobs that represent lists like this:&lt;br/&gt;
repeated int32 repeated_field;&lt;/p&gt;

&lt;p&gt;With Spark 1.2 &amp;amp; 1.4 we are unable to read these fields as the schema spark produces, i.e, optional int32 repeated_field is not correct for these files. It looks to me that Spark reads the schema from the file, converts it to its internal representation, Attributes, and then coverts the attributes into the schema that is used when trying to read. It then fails due to to a schema mismatch.&lt;/p&gt;</comment>
                            <comment id="14661830" author="apachespark" created="Fri, 7 Aug 2015 13:35:10 +0000"  >&lt;p&gt;User &apos;dguy&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8032&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8032&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14661831" author="damianguy" created="Fri, 7 Aug 2015 13:35:38 +0000"  >&lt;p&gt;I created a pull request against the 1.3 branch (closest to what i am using) &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8032&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8032&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14679351" author="apachespark" created="Sun, 9 Aug 2015 21:14:05 +0000"  >&lt;p&gt;User &apos;dguy&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8063&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8063&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14679684" author="lian cheng" created="Mon, 10 Aug 2015 07:09:03 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=damianguy&quot; class=&quot;user-hover&quot; rel=&quot;damianguy&quot;&gt;damianguy&lt;/a&gt; This is actually a Parquet complex type interoperability issue rather than Spark issue alone. The root cause is that, parquet-format spec didn&apos;t specify how LIST and MAP should be exactly represented. So in the early days, different Parquet libraries write Parquet LIST and MAP values in different formats. The unfortunate consequence is that, Parquet files generated by different libraries/systems are not fully interoperable. And I believe the case you&apos;ve faced is just one of those broken interoperability cases.&lt;/p&gt;

&lt;p&gt;From parquet-format spec side, this issue has been addressed by &lt;a href=&quot;https://issues.apache.org/jira/browse/PARQUET-113&quot; title=&quot;Clarify parquet-format specification for LIST and MAP structures.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PARQUET-113&quot;&gt;&lt;del&gt;PARQUET-113&lt;/del&gt;&lt;/a&gt;, which clearly specified how LIST and MAP should be represented, and how different Parquet data models should deal with legacy data systematically via various backwards-compatibility rules.&lt;/p&gt;

&lt;p&gt;From Spark side, the new spec together with all backwards-compatibility rules have been implemented in 1.5  via &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-6775&quot; title=&quot;Simplify CatalystConverter class hierarchy and pass in Parquet schema&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-6775&quot;&gt;&lt;del&gt;SPARK-6775&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-6776&quot; title=&quot;Implement backwards-compatibility rules in Catalyst converters (which convert Parquet record to rows)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-6776&quot;&gt;&lt;del&gt;SPARK-6776&lt;/del&gt;&lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-6777&quot; title=&quot;Implement backwards-compatibility rules in Parquet schema converters&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-6777&quot;&gt;&lt;del&gt;SPARK-6777&lt;/del&gt;&lt;/a&gt;. So, would you please try branch-1.5 and see whether it fixes your problem? PR #8063 was opened against the master branch, which should have already fixed this issue.&lt;/p&gt;</comment>
                            <comment id="14679719" author="lian cheng" created="Mon, 10 Aug 2015 07:39:14 +0000"  >&lt;p&gt;Would like to add that, from the perspective of read path, Spark 1.5 and parquet-avro 1.7.0+ are two of the most standard Parquet data model implementations which implement all backwards-compatibility rules defined in parquet-format spec, and are able to read legacy Parquet data generated by various systems. IIRC, no other libraries are capable to do so for now.&lt;/p&gt;

&lt;p&gt;As for write path, parquet-avro 1.8.1+ is the only library I know that writes fully standard Parquet data according the most recent parquet-format spec. Spark SQL is also refactoring its own Parquet write path in &lt;a href=&quot;https://github.com/apache/spark/pull/7679&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7679&lt;/a&gt;, but it probably won&apos;t be part of Spark 1.5.&lt;/p&gt;

&lt;p&gt;In general, we can categorize existing Parquet libraries into 3 categories:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Libraries that don&apos;t write data in standard Parquet format, and don&apos;t implement backwards-compatibility rules&lt;br/&gt;
  Using these libraries will probably hit similar issues you suffered when reading Parquet data with LIST and MAP generated by other systems. parquet-protobuf 1.4.3 and Spark SQL (&amp;lt;= 1.4) are both in this category.  That&apos;s why they don&apos;t play well with each other. Unfortunately, most Parquet libraries out there are in this category at this moment.&lt;/li&gt;
	&lt;li&gt;Libraries that don&apos;t write data in standard Parquet format, but implement backwards-compatibility rules&lt;br/&gt;
  Using these libraries, you&apos;ll be able to read legacy Parquet data generated by various systems. Although they don&apos;t write standard Parquet data, the format they use are also covered by the backwards-compatibility rules, so it&apos;s still fine.&lt;br/&gt;
  Spark 1.5-SNAPSHOT and parquet-avro 1.7.0 are the only two that I know of in this category up until now.&lt;/li&gt;
	&lt;li&gt;Libraries that write standard Parquet data, and implement backwards-compatibility rules&lt;br/&gt;
  They are the best citizens among all Parquet libraries.  Unfortunately, parquet-avro 1.8.1 is the only one that I know of up until now.  Hopefully Spark 1.6 will join this category.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;As a summary, some rules to be aware of if you want true Parquet interoperability:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;parquet-avro is usually the most standard Parquet data model out there, partly because there are Parquet committers who are also Avro committers (e.g. Ryan Blue).&lt;/li&gt;
	&lt;li&gt;Always use libraries of category 3, or at least category 2 whenver possible.&lt;/li&gt;
	&lt;li&gt;If you have to use libraries of category 1, don&apos;t use them to read Parquet data generated by other libraries.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ll leave this issue open for now until you confirm that 1.5 solves your problem. If it doesn&apos;t, let&apos;s investigate further. But I&apos;m removing 1.5.0 from &quot;Affects Version/s&quot; field.&lt;/p&gt;</comment>
                            <comment id="14679792" author="damianguy" created="Mon, 10 Aug 2015 08:34:48 +0000"  >&lt;p&gt;Hi, I did try it against the 1.5 and the problem still exists - hence the fix. You can try it for yourself if you run just the tests I added without making the other changes.&lt;/p&gt;

&lt;p&gt;The part of the parquet spec that matters in this case is here:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#nested-types&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#nested-types&lt;/a&gt;&lt;br/&gt;
In particular:&lt;br/&gt;
&quot;This does not affect repeated fields that are not annotated: A repeated field that is neither contained by a LIST- or MAP-annotated group nor annotated by LIST or MAP should be interpreted as a required list of required elements where the element type is the type of the field.&quot;&lt;/p&gt;

&lt;p&gt;parquet-protobuf does a 1 - 1 mapping and does not have annotations. It is compliant with the spec. &lt;br/&gt;
Whilst i feel the spec should be tighter and the schema should be consistent no matter the original data format, this is not the case. &lt;/p&gt;</comment>
                            <comment id="14680277" author="lian cheng" created="Mon, 10 Aug 2015 15:43:37 +0000"  >&lt;p&gt;Ah, thanks a lot!  I see the problem now.  &lt;tt&gt;parquet-avro&lt;/tt&gt; doesn&apos;t allow &lt;tt&gt;repeated&lt;/tt&gt; fields outside &lt;tt&gt;LIST&lt;/tt&gt; or &lt;tt&gt;MAP&lt;/tt&gt;, and I was following &lt;tt&gt;parquet-avro&lt;/tt&gt; when implementing all the compatibility rules.&lt;/p&gt;

&lt;p&gt;So I think the real problematic position is &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/parquet/CatalystSchemaConverter.scala#L102-L104&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt; (and &lt;a href=&quot;https://github.com/apache/parquet-mr/blob/apache-parquet-1.8.1/parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java#L217&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt; in &lt;tt&gt;parquet-avro&lt;/tt&gt;).&lt;/p&gt;

&lt;p&gt;This issue could have a simpler solution, especially the schema conversion part. Row converter needs bigger changes though.  I&apos;m working on a simplified version of PR #8063.  Will attribute this issue to you since you spot this issue and #8063 inspired me a lot!&lt;/p&gt;</comment>
                            <comment id="14680281" author="damianguy" created="Mon, 10 Aug 2015 15:50:04 +0000"  >&lt;p&gt;Thanks. I&apos;m sure there is a simpler solution to someone more familiar with the code! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Thanks for looking further into it, appreciated.&lt;/p&gt;</comment>
                            <comment id="14680355" author="rdblue" created="Mon, 10 Aug 2015 16:53:30 +0000"  >&lt;p&gt;Sorry to jump in late on this issue... I think you&apos;re on the right track here, but just to be sure I&apos;ll clarify things as I see them.&lt;/p&gt;

&lt;p&gt;The specs written for &lt;a href=&quot;https://issues.apache.org/jira/browse/PARQUET-113&quot; title=&quot;Clarify parquet-format specification for LIST and MAP structures.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;PARQUET-113&quot;&gt;&lt;del&gt;PARQUET-113&lt;/del&gt;&lt;/a&gt; allow non-LIST/MAP repeated fields because that&apos;s what parquet-protobuf uses. But, we didn&apos;t implement support for unannotated repeated groups because we wanted to address the compatibility issues between Hive, Thrift, and Avro as quickly as possible (which are still being cleaned up). So for now, unannotated repeated groups throw the AnalysisException noted above. Those should eventually map to required lists of required elements to give the exact same view of the data that you have in parquet-protobuf.&lt;/p&gt;

&lt;p&gt;I believe &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=damianguy&quot; class=&quot;user-hover&quot; rel=&quot;damianguy&quot;&gt;damianguy&lt;/a&gt;, would like to discuss a different mapping from the protobuf schema to a parquet schema, which is a great discussion to have in the upstream Parquet project. That sounds like a reasonable extension to me, but I want to see what the protobuf model maintainers think of it.&lt;/p&gt;</comment>
                            <comment id="14680385" author="apachespark" created="Mon, 10 Aug 2015 17:15:03 +0000"  >&lt;p&gt;User &apos;liancheng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8070&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8070&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14680389" author="lian cheng" created="Mon, 10 Aug 2015 17:17:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=damianguy&quot; class=&quot;user-hover&quot; rel=&quot;damianguy&quot;&gt;damianguy&lt;/a&gt; Would you mind to help reviewing &lt;a href=&quot;https://github.com/apache/spark/pull/8070&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PR #8070&lt;/a&gt; and check whether it works for your case? Thanks in advance!&lt;/p&gt;</comment>
                            <comment id="14680418" author="lian cheng" created="Mon, 10 Aug 2015 17:37:31 +0000"  >&lt;p&gt;Thanks for the clarification.  In &lt;a href=&quot;https://github.com/apache/spark/pull/8070&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PR #8070&lt;/a&gt; I just try to do the &quot;required list of required elements&quot; conversion.&lt;/p&gt;

&lt;p&gt;I understand that cleaning up all those compatibility stuff can be super time consuming, and making sure the most common scenarios work first totally makes sense.  I&apos;m so glad that all the backwards-compatibility rules had already been figured out there when I started to investigate these issues.  These rules definitely saved my world!&lt;/p&gt;</comment>
                            <comment id="14680492" author="damianguy" created="Mon, 10 Aug 2015 18:17:47 +0000"  >&lt;p&gt;Code looks good and it works as expected. Tests pass. Thanks for your assistance with this.&lt;/p&gt;</comment>
                            <comment id="14680523" author="lian cheng" created="Mon, 10 Aug 2015 18:34:27 +0000"  >&lt;p&gt;Great, would you mind to leave a LGTM on the GitHub PR page? Appreciated!&lt;/p&gt;</comment>
                            <comment id="14680978" author="rdblue" created="Mon, 10 Aug 2015 23:57:05 +0000"  >&lt;p&gt;I just took a look at PR #8070 and it looks good to me. I&apos;ll probably copy the start/end back into parquet-avro for similar support.&lt;/p&gt;</comment>
                            <comment id="14681235" author="lian cheng" created="Tue, 11 Aug 2015 04:47:25 +0000"  >&lt;p&gt;Issue resolved by pull request 8070&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8070&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8070&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12747175" name="ParquetTypesConverterTest.scala" size="959" author="damianguy" created="Sat, 25 Jul 2015 11:35:20 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 15 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2hxfr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310921" key="com.pyxis.greenhopper.jira:gh-sprint">
                        <customfieldname>Sprint</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="168">Spark 1.5 doc/QA sprint</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12332078">1.5.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>