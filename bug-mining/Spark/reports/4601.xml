<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:51:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18699] Spark CSV parsing types other than String throws exception when malformed</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18699</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;If CSV is read and the schema contains any other type than String, exception is thrown when the string value in CSV is malformed; e.g. if the timestamp does not match the defined one, an exception is thrown:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: java.lang.IllegalArgumentException
	at java.sql.Date.valueOf(Date.java:143)
	at org.apache.spark.sql.catalyst.util.DateTimeUtils$.stringToTime(DateTimeUtils.scala:137)
	at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply$mcJ$sp(CSVInferSchema.scala:272)
	at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply(CSVInferSchema.scala:272)
	at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$6.apply(CSVInferSchema.scala:272)
	at scala.util.Try.getOrElse(Try.scala:79)
	at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$.castTo(CSVInferSchema.scala:269)
	at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:116)
	at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:85)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:128)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:127)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:91)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply$mcV$sp(WriterContainer.scala:253)
	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252)
	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348)
	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:258)
	... 8 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It behaves similarly with Integer and Long types, from what I&apos;ve seen.&lt;/p&gt;

&lt;p&gt;To my understanding modes PERMISSIVE and DROPMALFORMED should just null the value or drop the line, but instead they kill the job.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13025335">SPARK-18699</key>
            <summary>Spark CSV parsing types other than String throws exception when malformed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="maropu">Takeshi Yamamuro</assignee>
                                    <reporter username="jsnowacki">Jakub Nowacki</reporter>
                        <labels>
                    </labels>
                <created>Sat, 3 Dec 2016 16:33:28 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:49 +0000</updated>
                            <resolved>Thu, 23 Feb 2017 20:09:50 +0000</resolved>
                                    <version>2.0.2</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="15719863" author="maropu" created="Sun, 4 Dec 2016 12:26:26 +0000"  >&lt;p&gt;you mean a query below and you&apos;d like to load the second line only?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&amp;gt;&amp;gt; test.csv &amp;lt;&amp;lt;
1 0,2014-xx-xx
2 1,2014-01-01  

scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.types._
scala&amp;gt; val schema = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructType().add(&lt;span class=&quot;code-quote&quot;&gt;&quot;a&quot;&lt;/span&gt;, IntegerType).add(&lt;span class=&quot;code-quote&quot;&gt;&quot;b&quot;&lt;/span&gt;, DateType)
scala&amp;gt; spark.read.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;).schema(schema).load(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.csv&quot;&lt;/span&gt;).show

16/12/04 21:21:56 ERROR Executor: Exception in task 0.0 in stage 32.0 (TID 32)
java.lang.NumberFormatException: For input string: &lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt;
        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.parseInt(&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.java:580)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.parseInt(&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.java:615)
        at java.sql.Date.valueOf(Date.java:134)
        at org.apache.spark.sql.catalyst.util.DateTimeUtils$.stringToTime(DateTimeUtils.scala:137)
        at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$9.apply$mcI$sp(CSVInferSchema.scala:290)
        at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$8.apply(CSVInferSchema.scala:290)
        at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$$anonfun$castTo$8.apply(CSVInferSchema.scala:290)
        at scala.util.Try.getOrElse(Try.scala:79)
        at org.apache.spark.sql.execution.datasources.csv.CSVTypeCast$.castTo(CSVInferSchema.scala:287)
        at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:121)
        at org.apache.spark.sql.execution.datasources.csv.CSVRelation$$anonfun$csvParser$3.apply(CSVRelation.scala:90)
        at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:173)
        at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anonfun$buildReader$1$$anonfun$apply$2.apply(CSVFileFormat.scala:172)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15719887" author="jsnowacki" created="Sun, 4 Dec 2016 12:43:09 +0000"  >&lt;p&gt;Yes, my understanding was that it should put nullify the value if it fails to parse it in PERMISSIVE mode or drop the whole row (line) in DROPMALFORMED as described in the docs: &lt;a href=&quot;http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameReader&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameReader&lt;/a&gt;, i.e.: &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;mode (default PERMISSIVE): allows a mode for dealing with corrupt records during parsing.
	&lt;ul&gt;
		&lt;li&gt;PERMISSIVE : sets other fields to null when it meets a corrupted record. When a schema is set by user, it sets null for extra fields.&lt;/li&gt;
		&lt;li&gt;DROPMALFORMED : ignores the whole corrupted records.&lt;/li&gt;
		&lt;li&gt;FAILFAST : throws an exception when it meets corrupted records.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15719993" author="maropu" created="Sun, 4 Dec 2016 14:02:51 +0000"  >&lt;p&gt;`DROPMALFORMED` works well in this query though, `PERMISSIVE` still throws the exception. But, `PERMISSIVE` mode just fills null in case that the number of fields spark parses is lower than a given schema length (IIUC, in the spark doc., this case is called `corrupted records`). Since the current implementation does not fill null for malformed  fields (the format errors above, or something), it seems this is an expected behaviour. cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15720033" author="maropu" created="Sun, 4 Dec 2016 14:30:58 +0000"  >&lt;p&gt;Additionally, in our basic stance, it seems this csv format keeps almost the same behavior with `com.databricks.spark.csv`. I quickly checked that the databricks one throws an exception in this query;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; sqlContext.read.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;com.databricks.spark.csv&quot;&lt;/span&gt;).schema(schema).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;mode&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;PERMISSIVE&quot;&lt;/span&gt;).load(&lt;span class=&quot;code-quote&quot;&gt;&quot;../test.csv&quot;&lt;/span&gt;).show
16/12/04 23:17:43 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.NumberFormatException: For input string: &lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt;
        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.parseInt(&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.java:580)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.parseInt(&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;.java:615)
        at java.sql.Date.valueOf(Date.java:134)
        at com.databricks.spark.csv.util.TypeCast$.castTo(TypeCast.scala:74)
        at com.databricks.spark.csv.CsvRelation$$anonfun$buildScan$2.apply(CsvRelation.scala:121)
        at com.databricks.spark.csv.CsvRelation$$anonfun$buildScan$2.apply(CsvRelation.scala:108)
       ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15720069" author="maropu" created="Sun, 4 Dec 2016 14:55:13 +0000"  >&lt;p&gt;Anyway, we can easily fix this like this: &lt;a href=&quot;https://github.com/apache/spark/compare/master...maropu:SPARK-18699&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/compare/master...maropu:SPARK-18699&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; spark.read.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;).schema(schema).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;mode&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;PERMISSIVE&quot;&lt;/span&gt;).load(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.csv&quot;&lt;/span&gt;).show
16/12/04 23:46:55 WARN CSVRelation: Fill NULL in a field because a malformed token detected: 2014-xx-xx
+---+----------+
|  a|         b|
+---+----------+
|  0|      &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|
|  1|2014-01-01|
+---+----------+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15720128" author="gurwls223" created="Sun, 4 Dec 2016 15:34:11 +0000"  >&lt;p&gt;Thank you for cc&apos;ing me. Yup, I noticed this but I decided to just leave as is because I noticed that this is not a regression comparing to the external CSV library as you said below.&lt;/p&gt;

&lt;p&gt;I persuaded myself and was thinking that the parse mode is related with parsing itself. JSON has some standard JSON types so IIRC JSON loads the data as null in &lt;tt&gt;PERMISSIVE&lt;/tt&gt; mode in this case but parsing CSV is not related with types not within plain texts so it throws an exception.&lt;/p&gt;

&lt;p&gt;However, if this sounds odds in practice, I agree with fixing this although I still am worried of changing the exiting behaviour.&lt;/p&gt;

&lt;p&gt;Could I ask what you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=falaki&quot; class=&quot;user-hover&quot; rel=&quot;falaki&quot;&gt;falaki&lt;/a&gt; please?&lt;/p&gt;</comment>
                            <comment id="15720710" author="jsnowacki" created="Sun, 4 Dec 2016 22:24:58 +0000"  >&lt;p&gt;While I don&apos;t argue that some other packages have similar behaviour, I think the PERMISSIVE mode should be, well, as permissive as possible, since CSVs have very little standards and no types. In ma case I had just one odd value in almost 1 TB set and the job crushed at the very end after about an hour. To go around the issue one needs to manually parse each line, which is not the end of the world, but I wanted to use CSV reader exactly for the confidence of not writing extra code. IMO the mode for error detection should be FAILFAST. Moreover, if I really need to check the data, I read it differently anyway.&lt;br/&gt;
BTW thanks for looking into this.&lt;/p&gt;</comment>
                            <comment id="15734318" author="maropu" created="Fri, 9 Dec 2016 04:55:27 +0000"  >&lt;p&gt;yea, I&apos;m also working on large csv files now and, certainly, I think this current behavior makes  it difficult to find incorrect records in them. Logging with meaningful waning messages (e.g., including the incorrect records and line numbers) helps much to me.&lt;/p&gt;</comment>
                            <comment id="15748886" author="rkamaleswaran" created="Wed, 14 Dec 2016 17:13:23 +0000"  >&lt;p&gt;This issue is also seen in cases where a timestamp field (among many) is empty (just &quot; &quot;). If I use permissive mode, then any instances where one of those timestamp fields are empty automatically results in the entire row getting dropped. In my case that&apos;s over 90% of the rows.&lt;/p&gt;</comment>
                            <comment id="15750050" author="gurwls223" created="Thu, 15 Dec 2016 01:37:20 +0000"  >&lt;p&gt;BTW, maybe you could try to set &lt;tt&gt;nullValue&lt;/tt&gt; to &lt;tt&gt;&quot; &quot;&lt;/tt&gt; or set &lt;tt&gt;ignoreLeadingWhiteSpace&lt;/tt&gt; and &lt;tt&gt;ignoreTrailingWhiteSpace&lt;/tt&gt; to &lt;tt&gt;true&lt;/tt&gt; for now.&lt;/p&gt;</comment>
                            <comment id="15750163" author="rkamaleswaran" created="Thu, 15 Dec 2016 02:33:58 +0000"  >&lt;p&gt;Thanks for the reply! Unfortunately neither of those options work in my case.&lt;/p&gt;</comment>
                            <comment id="15756170" author="kubatyszko" created="Sat, 17 Dec 2016 03:05:24 +0000"  >&lt;p&gt;Fixed in PR &lt;a href=&quot;https://github.com/apache/spark/pull/16319&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16319&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(not merged into the tree as of now).&lt;/p&gt;

&lt;p&gt;Enjoy&lt;/p&gt;</comment>
                            <comment id="15756175" author="apachespark" created="Sat, 17 Dec 2016 03:07:05 +0000"  >&lt;p&gt;User &apos;kubatyszko&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16319&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16319&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15863122" author="maropu" created="Mon, 13 Feb 2017 02:25:58 +0000"  >&lt;p&gt;This fix makes some sensible to me and what do you think? cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt;&lt;br/&gt;
If yes, I try to make a pr based on this (&lt;a href=&quot;https://github.com/apache/spark/compare/master...maropu:SPARK-18699&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/compare/master...maropu:SPARK-18699&lt;/a&gt;). If no, I think it&apos;s okay to set &quot;Won&apos;t Fix&quot;.&lt;/p&gt;</comment>
                            <comment id="15863426" author="gurwls223" created="Mon, 13 Feb 2017 10:18:20 +0000"  >&lt;p&gt;Thanks for cc&apos;ing me. For me, it is reasonable to me too (although I am not supposed to decide what to add into Spark). Maybe, it might be even nicer if we could have some references such as similar libraries e.g., read.csv in R if applicable and/or good explanations for potential use cases.&lt;/p&gt;</comment>
                            <comment id="15865959" author="apachespark" created="Tue, 14 Feb 2017 15:29:04 +0000"  >&lt;p&gt;User &apos;maropu&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16928&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16928&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15881140" author="cloud_fan" created="Thu, 23 Feb 2017 20:09:50 +0000"  >&lt;p&gt;Issue resolved by pull request 16928&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16928&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16928&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15892679" author="apachespark" created="Thu, 2 Mar 2017 17:48:03 +0000"  >&lt;p&gt;User &apos;HyukjinKwon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17142&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13065031">SPARK-20387</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13028789">SPARK-18906</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12988945">SPARK-16512</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 37 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i374af:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>