<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:46:34 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16700] StructType doesn&apos;t accept Python dicts anymore</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16700</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I found this issue while testing my codebase with 2.0.0-rc5&lt;/p&gt;

&lt;p&gt;StructType in Spark 1.6.2 accepts the Python &amp;lt;dict&amp;gt; type, which is very handy. 2.0.0-rc5 does not and throws an error.&lt;/p&gt;

&lt;p&gt;I don&apos;t know if this was intended but I&apos;d advocate for this behaviour to remain the same. MapType is probably wasteful when your key names never change and switching to Python tuples would be cumbersome.&lt;/p&gt;

&lt;p&gt;Here is a minimal script to reproduce the issue: &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;from pyspark &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; SparkContext
from pyspark.sql &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; types as SparkTypes
from pyspark.sql &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; SQLContext


sc = SparkContext()
sqlc = SQLContext(sc)

struct_schema = SparkTypes.StructType([
    SparkTypes.StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, SparkTypes.LongType())
])

rdd = sc.parallelize([{&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;: 0}, {&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;: 1}])

df = sqlc.createDataFrame(rdd, struct_schema)

print df.collect()

# 1.6.2 prints [Row(id=0), Row(id=1)]

# 2.0.0-rc5 raises TypeError: StructType can not accept object {&lt;span class=&quot;code-quote&quot;&gt;&apos;id&apos;&lt;/span&gt;: 0} in type &amp;lt;type &lt;span class=&quot;code-quote&quot;&gt;&apos;dict&apos;&lt;/span&gt;&amp;gt;

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</description>
                <environment></environment>
        <key id="12992127">SPARK-16700</key>
            <summary>StructType doesn&apos;t accept Python dicts anymore</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="sylvinus">Sylvain Zimmer</reporter>
                        <labels>
                            <label>releasenotes</label>
                    </labels>
                <created>Mon, 25 Jul 2016 01:44:52 +0000</created>
                <updated>Thu, 25 Aug 2016 21:59:52 +0000</updated>
                            <resolved>Mon, 15 Aug 2016 19:41:48 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15392200" author="sylvinus" created="Mon, 25 Jul 2016 16:16:42 +0000"  >&lt;p&gt;I dug into this a bit more: &lt;/p&gt;

&lt;p&gt;&lt;tt&gt;_verify_type({}, struct_schema)&lt;/tt&gt; was already raising a similar exception in Spark 1.6.2, however schema validation wasn&apos;t being enforced at all by &lt;tt&gt;createDataFrame&lt;/tt&gt; : &lt;a href=&quot;https://github.com/apache/spark/blob/branch-1.6/python/pyspark/sql/context.py#L418&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/branch-1.6/python/pyspark/sql/context.py#L418&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In 2.0.0, it seems that it is done over each row of the data:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/master/python/pyspark/sql/session.py#L504&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/python/pyspark/sql/session.py#L504&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I think there are 2 issues that should be fixed here:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;tt&gt;_verify_type({}, struct_schema)&lt;/tt&gt; shouldn&apos;t raise, because as far as I can tell dicts behave as expected and have their items correctly mapped as struct fields.&lt;/li&gt;
	&lt;li&gt;There should be a way to go back to 1.6.x-like behaviour and disable schema verification in &lt;tt&gt;createDataFrame&lt;/tt&gt;. The &lt;tt&gt;prepare()&lt;/tt&gt; function is being map()&apos;d over all the data coming from Python, which I think will definitely hurt performance for large datasets and complex schemas. Leaving it on by default but adding a flag to disable it would be a good solution. Without this users will probably have to implement their own &lt;tt&gt;createDataFrame&lt;/tt&gt; function like I did.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15400658" author="jaycode" created="Sat, 30 Jul 2016 12:32:50 +0000"  >&lt;p&gt;When using `Row` object, but with multiple struct types, also returns similar error:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;_struct = [
  SparkTypes.StructField(&lt;span class=&quot;code-quote&quot;&gt;&apos;string_field&apos;&lt;/span&gt;, SparkTypes.StringType(), True),
  SparkTypes.StructField(&lt;span class=&quot;code-quote&quot;&gt;&apos;long_field&apos;&lt;/span&gt;, SparkTypes.LongType(), True),
  SparkTypes.StructField(&lt;span class=&quot;code-quote&quot;&gt;&apos;double_field&apos;&lt;/span&gt;, SparkTypes.DoubleType(), True)
]
_rdd = sc.parallelize([Row(string_field=&lt;span class=&quot;code-quote&quot;&gt;&apos;1&apos;&lt;/span&gt;, long_field=1, double_field=1.1)])

## Both methods &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; not work:
# _schema = SparkTypes.StructType()
# &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; _s in _struct:
#   _schema.add(_s)
_schema = SparkTypes.StructType(_struct)

_df = sqlContext.createDataFrame(_rdd, schema=_schema)
_df.take(1)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Returned error:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;DoubleType can not accept object &lt;span class=&quot;code-quote&quot;&gt;&apos;1&apos;&lt;/span&gt; in type &amp;lt;type &lt;span class=&quot;code-quote&quot;&gt;&apos;str&apos;&lt;/span&gt;&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15402739" author="davies" created="Mon, 1 Aug 2016 20:18:36 +0000"  >&lt;p&gt;There are two separate problems here:&lt;/p&gt;

&lt;p&gt;1) Spark 2.0 enforce data type checking when creating a DataFrame, it&apos;s safer but slower. It makes sense to have a flag for that (on by default)&lt;/p&gt;

&lt;p&gt;2) Row object is similar to named tuple (not dict), the columns are ordered. When it&apos;s created in a way like dict, we have no way to know the order of columns, so they are sorted by name, then it does not match with the schema provided. We should check the schema (order of columns) when create a DataFrame from RDD of Row (we assume they matched)&lt;/p&gt;</comment>
                            <comment id="15405043" author="davies" created="Tue, 2 Aug 2016 23:51:04 +0000"  >&lt;p&gt;Sent PR &lt;a href=&quot;https://github.com/apache/spark/pull/14469&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14469&lt;/a&gt; to address these, could you help to test and review them?&lt;/p&gt;</comment>
                            <comment id="15405044" author="apachespark" created="Tue, 2 Aug 2016 23:51:06 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14469&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14469&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15406754" author="sylvinus" created="Wed, 3 Aug 2016 22:43:48 +0000"  >&lt;p&gt;The verifySchema flag works great, and the &lt;tt&gt;dict&lt;/tt&gt; issue seems to be fixed for me. Thanks a lot!!&lt;/p&gt;</comment>
                            <comment id="15421539" author="joshrosen" created="Mon, 15 Aug 2016 19:41:49 +0000"  >&lt;p&gt;Issue resolved by pull request 14469&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14469&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14469&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 14 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i31fmf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>