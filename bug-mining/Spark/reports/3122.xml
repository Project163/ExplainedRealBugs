<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:38:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-12546] Writing to partitioned parquet table can fail with OOM</title>
                <link>https://issues.apache.org/jira/browse/SPARK-12546</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;It is possible to have jobs fail with OOM when writing to a partitioned parquet table. While this was probably always possible, it is more likely in 1.6 due to the memory manager changes. The unified memory manager enables Spark to use more of the process memory (in particular, for execution) which gets us in this state more often. This issue can happen for libraries that consume a lot of memory, such as parquet. Prior to 1.6, these libraries would more likely use memory that spark was not using (i.e. from the storage pool). In 1.6, this storage memory can now be used for execution.&lt;/p&gt;

&lt;p&gt;There are a couple of configs that can help with this issue.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;parquet.memory.pool.ratio: This is a parquet config on how much of the heap the parquet writers should use. This default to .95. Consider a much lower value (e.g. 0.1)&lt;/li&gt;
	&lt;li&gt;spark.memory.faction: This is a spark config to control how much of the memory should be allocated to spark. Consider setting this to 0.6.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This should cause jobs to potentially spill more but require less memory. More aggressive tuning will control this trade off.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12924587">SPARK-12546</key>
            <summary>Writing to partitioned parquet table can fail with OOM</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="marmbrus">Michael Armbrust</assignee>
                                    <reporter username="nongli">Nong Li</reporter>
                        <labels>
                            <label>releasenotes</label>
                    </labels>
                <created>Tue, 29 Dec 2015 00:52:47 +0000</created>
                <updated>Tue, 15 Mar 2016 18:55:24 +0000</updated>
                            <resolved>Mon, 22 Feb 2016 23:27:57 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>1.6.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>19</watches>
                                                                                                                <comments>
                            <comment id="15107258" author="nongli" created="Tue, 19 Jan 2016 19:28:39 +0000"  >&lt;p&gt;A better workaround might be to figure the max number of concurrent output files to 1. This can be done by setting &quot;spark.sql.sources.maxConcurrentWrites=1&quot;&lt;/p&gt;</comment>
                            <comment id="15157605" author="apachespark" created="Mon, 22 Feb 2016 20:05:04 +0000"  >&lt;p&gt;User &apos;marmbrus&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11308&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11308&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15157942" author="marmbrus" created="Mon, 22 Feb 2016 23:27:57 +0000"  >&lt;p&gt;Issue resolved by pull request 11308&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11308&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11308&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15195157" author="l154k" created="Tue, 15 Mar 2016 11:59:42 +0000"  >&lt;p&gt;Hey, I migrated to 1.6.0, is it possible that it somehow relates to this really weird problem? Because there are plenty of resources and the sample data is really really tiny : &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;val coreRdd = sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;s3n:&lt;span class=&quot;code-comment&quot;&gt;//gwiq-views-p/external/core/tsv/*.tsv&quot;&lt;/span&gt;).map(_.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;)).map( fields =&amp;gt; Row(fields:_*) )
&lt;/span&gt;val coreDataFrame = sqlContext.createDataFrame(coreRdd, schema)
coreDataFrame.registerTempTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;core&quot;&lt;/span&gt;)
coreDataFrame.persist(StorageLevel.DISK_ONLY)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SELECT COUNT(*) FROM core
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;------ Create &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkContext spark:&lt;span class=&quot;code-comment&quot;&gt;//master:7077 -------
&lt;/span&gt;Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;pool-1-thread-5&quot;&lt;/span&gt; java.lang.OutOfMemoryError: GC overhead limit exceeded
	at com.google.gson.internal.bind.ObjectTypeAdapter.read(ObjectTypeAdapter.java:66)
	at com.google.gson.internal.bind.ObjectTypeAdapter.read(ObjectTypeAdapter.java:69)
	at com.google.gson.internal.bind.TypeAdapterRuntimeTypeWrapper.read(TypeAdapterRuntimeTypeWrapper.java:40)
	at com.google.gson.internal.bind.MapTypeAdapterFactory$Adapter.read(MapTypeAdapterFactory.java:188)
	at com.google.gson.internal.bind.MapTypeAdapterFactory$Adapter.read(MapTypeAdapterFactory.java:146)
	at com.google.gson.Gson.fromJson(Gson.java:791)
	at com.google.gson.Gson.fromJson(Gson.java:757)
	at com.google.gson.Gson.fromJson(Gson.java:706)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer.convert(RemoteInterpreterServer.java:417)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer.getProgress(RemoteInterpreterServer.java:384)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Processor$getProgress.getResult(RemoteInterpreterService.java:1376)
	at org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Processor$getProgress.getResult(RemoteInterpreterService.java:1361)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:285)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15195967" author="marmbrus" created="Tue, 15 Mar 2016 18:55:24 +0000"  >&lt;p&gt;There is no partitioning in that example so it is not the same problem.  Also, stacktrace is in zeplin code, not spark.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 35 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2qctz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12334009">1.6.1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>