<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:37:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-13087] Grouping by a complex expression may lead to incorrect AttributeReferences in aggregations</title>
                <link>https://issues.apache.org/jira/browse/SPARK-13087</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;This is a regression from 1.5.&lt;/p&gt;

&lt;p&gt;An example of the failure:&lt;/p&gt;

&lt;p&gt;Working with this table...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//10.1.3.203:10000&amp;gt; DESCRIBE csd_0ae1abc1_a3af_4c63_95b0_9599faca6c3d;
&lt;/span&gt;+-----------------------+------------+----------+--+
|       col_name        | data_type  | comment  |
+-----------------------+------------+----------+--+
| c_date                | timestamp  | NULL     |
| c_count               | &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;        | NULL     |
| c_location_fips_code  | string     | NULL     |
| c_airtemp             | &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;      | NULL     |
| c_dewtemp             | &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;      | NULL     |
| c_pressure            | &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;        | NULL     |
| c_rain                | &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;      | NULL     |
| c_snow                | &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;      | NULL     |
+-----------------------+------------+----------+--+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;...and this query (which isn&apos;t necessarily all that sensical or useful, but has been adapted from a similarly failing query that uses a custom UDF where the Spark SQL built-in `day` function has been substituted into this query)...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SELECT day ( c_date )  AS c_date, percentile_approx(c_rain, 0.5) AS c_expr_1256887735 FROM csd_0ae1abc1_a3af_4c63_95b0_9599faca6c3d GROUP BY day ( c_date )  ORDER BY c_date;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Spark 1.5 produces the expected results without error.&lt;/p&gt;

&lt;p&gt;In Spark 1.6, this plan is produced...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Exchange rangepartitioning(c_date#63009 ASC,16), None
+- SortBasedAggregate(key=[dayofmonth(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c_date#63011 as date))#63020], functions=[(hiveudaffunction(HiveFunctionWrapper(org.apache.hadoop.hive.ql.udf.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.GenericUDAFPercentileApprox,org.apache.hadoop.hive.ql.udf.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Gene
ricUDAFPercentileApprox@6f211801),c_rain#63017,0.5,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;,0,0),mode=Complete,isDistinct=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)], output=[c_date#63009,c_expr_1256887735#63010])
   +- ConvertToSafe
      +- !Sort [dayofmonth(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c_date#63011 as date))#63020 ASC], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
         +- !TungstenExchange hashpartitioning(dayofmonth(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c_date#63011 as date))#63020,16), None
            +- ConvertToUnsafe
               +- HiveTableScan [c_date#63011,c_rain#63017], MetastoreRelation &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, csd_0ae1abc1_a3af_4c63_95b0_9599faca6c3d, None
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;...which fails with a TreeNodeException and stack traces that include this...&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: ! org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2842.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2842.0 (TID 15007, ip-10-1-1-59.dev.clearstory.com): org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Binding attribute, tree: dayofmonth(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c_date#63011 as date))#63020
        at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:49)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:86)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:85)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:259)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:259)
        at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:258)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:249)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:85)
        at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection$$anonfun$$init$$2.apply(Projection.scala:62)
        at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection$$anonfun$$init$$2.apply(Projection.scala:62)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.immutable.List.foreach(List.scala:318)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.&amp;lt;init&amp;gt;(Projection.scala:62)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$newMutableProjection$1.apply(SparkPlan.scala:254)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$newMutableProjection$1.apply(SparkPlan.scala:254)
        at org.apache.spark.sql.execution.Exchange.org$apache$spark$sql$execution$Exchange$$getPartitionKeyExtractor$1(Exchange.scala:196)
        at org.apache.spark.sql.execution.Exchange$$anonfun$3.apply(Exchange.scala:208)
        at org.apache.spark.sql.execution.Exchange$$anonfun$3.apply(Exchange.scala:207)
        at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$21.apply(RDD.scala:728)
        at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$21.apply(RDD.scala:728)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
        at org.apache.spark.scheduler.Task.run(Task.scala:89)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.RuntimeException: Couldn&apos;t find dayofmonth(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(c_date#63011 as date))#63020 in [c_date#63011,c_rain#63017]
        at scala.sys.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.error(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:27)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:92)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:86)
        at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:48)
        ... 33 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is possible to work around the problem by adding a Project node in case an aggregation is relying on aliases missing in the child plan (&lt;a href=&quot;https://github.com/mbautin/spark/commit/2e99064b42a6dddf6b94b989c744a1308aacaee2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/mbautin/spark/commit/2e99064b42a6dddf6b94b989c744a1308aacaee2&lt;/a&gt;), but it seems there should be a deeper fix that prevents the problem instead of covering for it.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;yhuai&lt;/a&gt; I think this problem crept in with the changes for &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-9830&quot; title=&quot;Remove AggregateExpression1 and Aggregate Operator used to evaluate AggregateExpression1s&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-9830&quot;&gt;&lt;del&gt;SPARK-9830&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12935207">SPARK-13087</key>
            <summary>Grouping by a complex expression may lead to incorrect AttributeReferences in aggregations</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="marmbrus">Michael Armbrust</assignee>
                                    <reporter username="markhamstra">Mark Hamstra</reporter>
                        <labels>
                    </labels>
                <created>Fri, 29 Jan 2016 18:30:01 +0000</created>
                <updated>Tue, 13 Nov 2018 18:39:51 +0000</updated>
                            <resolved>Tue, 2 Feb 2016 08:52:03 +0000</resolved>
                                    <version>1.6.0</version>
                    <version>2.0.0</version>
                                    <fixVersion>1.6.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>5</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="15126012" author="viirya" created="Mon, 1 Feb 2016 09:37:09 +0000"  >&lt;p&gt;On latest build, looks like there is no this problem.&lt;/p&gt;</comment>
                            <comment id="15126980" author="tleftwich" created="Mon, 1 Feb 2016 20:34:03 +0000"  >&lt;p&gt;I re-built 1.6.1 with commit ddb9633043e82fb2a34c7e0e29b487f635c3c744 this morning and I&apos;m seeing a similar error to above. Similarly we use a custom UDF and the above commit fixes the issue.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt;
   concat(t_4.firstname,&lt;span class=&quot;code-quote&quot;&gt;&quot; &quot;&lt;/span&gt;,t_4.lastname) customer_name,
  agg_cust(t_3.customercountestimate1_c2) ctd_customercountestimate1_ok
&lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt;.sales t_3
&lt;span class=&quot;code-keyword&quot;&gt;JOIN&lt;/span&gt;
   &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt;.customer t_4
&lt;span class=&quot;code-keyword&quot;&gt;ON&lt;/span&gt;
   t_3.key_c1 = t_4.customerkey
&lt;span class=&quot;code-keyword&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;BY&lt;/span&gt;
   concat(t_4.firstname,&lt;span class=&quot;code-quote&quot;&gt;&quot; &quot;&lt;/span&gt;,t_4.lastname)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Binding attribute, tree: concat(firstname#329, ,lastname#330)#339
        at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:49)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:86)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:85)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:259)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:259)
        at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:258)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:249)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:85)
        at org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection$$anonfun$bind$1.apply(GenerateMutableProjection.scala:39)
        at org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection$$anonfun$bind$1.apply(GenerateMutableProjection.scala:39)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
        at scala.collection.immutable.List.foreach(List.scala:318)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)
        at org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection$.bind(GenerateMutableProjection.scala:39)
        at org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection$.bind(GenerateMutableProjection.scala:33)
        at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:585)
        at org.apache.spark.sql.execution.SparkPlan.newMutableProjection(SparkPlan.scala:227)
        at org.apache.spark.sql.execution.Exchange.org$apache$spark$sql$execution$Exchange$$getPartitionKeyExtractor$1(Exchange.scala:197)
        at org.apache.spark.sql.execution.Exchange$$anonfun$3.apply(Exchange.scala:209)
        at org.apache.spark.sql.execution.Exchange$$anonfun$3.apply(Exchange.scala:208)
        at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$21.apply(RDD.scala:728)
        at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$21.apply(RDD.scala:728)
        at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
        at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
        at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
        at org.apache.spark.scheduler.Task.run(Task.scala:89)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.RuntimeException: Couldn&apos;t find concat(firstname#329, ,lastname#330)#339 in [firstname#329,lastname#330,customercountestimate1_c2#326]
        at scala.sys.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.error(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:27)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:92)
        at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:86)
        at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:48)
        ... 34 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15127353" author="marmbrus" created="Tue, 2 Feb 2016 00:48:39 +0000"  >&lt;p&gt;Here&apos;s a self-contained test case:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  test(&lt;span class=&quot;code-quote&quot;&gt;&quot;group by function&quot;&lt;/span&gt;) {
    Seq((1, 2)).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;a&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;b&quot;&lt;/span&gt;).registerTempTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;data&quot;&lt;/span&gt;)

    checkAnswer(
      sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT floor(a) AS a, collect_set(b) FROM data GROUP BY floor(a) ORDER BY a&quot;&lt;/span&gt;),
      Row(1, 2) :: Nil)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Looks like the problem is specific to the fallback path used when we detect a hive aggregate function.&lt;/p&gt;</comment>
                            <comment id="15127377" author="apachespark" created="Tue, 2 Feb 2016 01:14:04 +0000"  >&lt;p&gt;User &apos;marmbrus&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11011&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11011&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15127397" author="apachespark" created="Tue, 2 Feb 2016 01:26:04 +0000"  >&lt;p&gt;User &apos;marmbrus&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11013&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11013&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15127919" author="yhuai" created="Tue, 2 Feb 2016 08:51:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/11011&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11011&lt;/a&gt; has been merged into master and &lt;a href=&quot;https://github.com/apache/spark/pull/11013&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11013&lt;/a&gt; has been merged into branch 1.6.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13198118">SPARK-26041</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 42 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2s5w7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12334009">1.6.1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>