<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:40:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-14163] SumEvaluator and countApprox cannot reliably handle RDDs of size 1</title>
                <link>https://issues.apache.org/jira/browse/SPARK-14163</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The bug exists in these lines: &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/partial/SumEvaluator.scala#L59-L61&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/partial/SumEvaluator.scala#L59-L61&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In this code&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;SumEvaluator.scala&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;          val degreesOfFreedom = (counter.count - 1).toInt
          &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; TDistribution(degreesOfFreedom).inverseCumulativeProbability(1 - (1 - confidence) / 2)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If &lt;tt&gt;counter.count&lt;/tt&gt; is 1 or 0 then &lt;tt&gt;new TDistribution(degreesOfFreedom)&lt;/tt&gt; will raise an exception because &lt;tt&gt;TDistribution&lt;/tt&gt; expects its &lt;tt&gt;degreesOfFreedom&lt;/tt&gt; parameter to be 1 or greater.&lt;/p&gt;

&lt;p&gt;An example (written in pyspark):&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;gt;&amp;gt;&amp;gt; rdd = sc.parallelize([1])
&amp;gt;&amp;gt;&amp;gt; rdd.countApprox(1000,0.5)
16/03/25 18:09:36 INFO SparkContext: Starting job: sumApprox at NativeMethodAccessorImpl.java:-2
16/03/25 18:09:36 INFO DAGScheduler: Got job 1 (sumApprox at NativeMethodAccessorImpl.java:-2) with 2 output partitions
16/03/25 18:09:36 INFO DAGScheduler: Final stage: ResultStage 1(sumApprox at NativeMethodAccessorImpl.java:-2)
16/03/25 18:09:36 INFO DAGScheduler: Parents of final stage: List()
16/03/25 18:09:36 INFO DAGScheduler: Missing parents: List()
16/03/25 18:09:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at SerDeUtil.scala:147), which has no missing parents
16/03/25 18:09:36 INFO MemoryStore: ensureFreeSpace(4328) called with curMem=7140, maxMem=555755765
16/03/25 18:09:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 530.0 MB)
16/03/25 18:09:36 INFO MemoryStore: ensureFreeSpace(2821) called with curMem=11468, maxMem=555755765
16/03/25 18:09:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.8 KB, free 530.0 MB)
16/03/25 18:09:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.5.5.158:56348 (size: 2.8 KB, free: 530.0 MB)
16/03/25 18:09:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
16/03/25 18:09:36 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at mapPartitions at SerDeUtil.scala:147)
16/03/25 18:09:36 INFO YarnScheduler: Adding task set 1.0 with 2 tasks
16/03/25 18:09:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, r-hadoopeco-data-66215afe.hbinternal.com, PROCESS_LOCAL, 2071 bytes)
16/03/25 18:09:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, r-hadoopeco-data-84205b1c.hbinternal.com, PROCESS_LOCAL, 2090 bytes)
16/03/25 18:09:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on r-hadoopeco-data-66215afe.hbinternal.com:43011 (size: 2.8 KB, free: 530.0 MB)
16/03/25 18:09:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 66 ms on r-hadoopeco-data-66215afe.hbinternal.com (1/2)
16/03/25 18:09:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on r-hadoopeco-data-84205b1c.hbinternal.com:41613 (size: 2.8 KB, free: 530.0 MB)
Traceback (most recent call last):
  File &quot;&amp;lt;stdin&amp;gt;&quot;, line 1, in &amp;lt;module&amp;gt;
  File &quot;/usr/hdp/2.3.4.0-3485/spark/python/pyspark/rdd.py&quot;, line 2227, in countApprox
    return int(drdd.sumApprox(timeout, confidence))
  File &quot;/usr/hdp/2.3.4.0-3485/spark/python/pyspark/rdd.py&quot;, line 2243, in sumApprox
    r = jdrdd.sumApprox(timeout, confidence).getFinalValue()
  File &quot;/usr/hdp/2.3.4.0-3485/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py&quot;, line 538, in __call__
  File &quot;/usr/hdp/2.3.4.0-3485/spark/python/pyspark/sql/utils.py&quot;, line 36, in deco
    return f(*a, **kw)
  File &quot;/usr/hdp/2.3.4.0-3485/spark/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py&quot;, line 300, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o69.sumApprox.
: org.apache.commons.math3.exception.NotStrictlyPositiveException: degrees of freedom (0)
	at org.apache.commons.math3.distribution.TDistribution.&amp;lt;init&amp;gt;(TDistribution.java:120)
	at org.apache.commons.math3.distribution.TDistribution.&amp;lt;init&amp;gt;(TDistribution.java:86)
	at org.apache.commons.math3.distribution.TDistribution.&amp;lt;init&amp;gt;(TDistribution.java:63)
	at org.apache.spark.partial.SumEvaluator.currentResult(SumEvaluator.scala:61)
	at org.apache.spark.partial.SumEvaluator.currentResult(SumEvaluator.scala:29)
	at org.apache.spark.partial.ApproximateActionListener.awaitResult(ApproximateActionListener.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.runApproximateJob(DAGScheduler.scala:586)
	at org.apache.spark.SparkContext.runApproximateJob(SparkContext.scala:1962)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sumApprox$1.apply(DoubleRDDFunctions.scala:99)
	at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$sumApprox$1.apply(DoubleRDDFunctions.scala:96)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:310)
	at org.apache.spark.rdd.DoubleRDDFunctions.sumApprox(DoubleRDDFunctions.scala:96)
	at org.apache.spark.api.java.JavaDoubleRDD.sumApprox(JavaDoubleRDD.scala:224)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)
	at py4j.Gateway.invoke(Gateway.java:259)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:207)
	at java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that this only happens occasionally, as befits a probabilistic counting method. A good way to reproduce is:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;rdd = sc.parallelize([1]); &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; x in xrange(1000): rdd.countApprox(1+x,0.5)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12953645">SPARK-14163</key>
            <summary>SumEvaluator and countApprox cannot reliably handle RDDs of size 1</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="marcin.tustin">Marcin Tustin</assignee>
                                    <reporter username="marcin.tustin">Marcin Tustin</reporter>
                        <labels>
                    </labels>
                <created>Fri, 25 Mar 2016 18:49:25 +0000</created>
                <updated>Mon, 4 Apr 2016 00:43:38 +0000</updated>
                            <resolved>Mon, 4 Apr 2016 00:42:48 +0000</resolved>
                                    <version>1.5.2</version>
                    <version>1.6.0</version>
                    <version>1.6.1</version>
                    <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15212280" author="srowen" created="Fri, 25 Mar 2016 19:22:29 +0000"  >&lt;p&gt;Yeah, if n &amp;lt;= 1, stuff is already messed up here since the variance will be undefined. If n == 0 I suppose you&apos;d have the same case as when 0 outputs have been merged and can return the same result straight away. When n == 1 I suppose the same thing can be returned, but in that case at least sumEstimate is valid.&lt;/p&gt;</comment>
                            <comment id="15213246" author="apachespark" created="Sat, 26 Mar 2016 23:29:03 +0000"  >&lt;p&gt;User &apos;yongtang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11981&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11981&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15213248" author="apachespark" created="Sat, 26 Mar 2016 23:41:04 +0000"  >&lt;p&gt;User &apos;mtustin-handy&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11982&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11982&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15213249" author="marcin.tustin" created="Sat, 26 Mar 2016 23:41:32 +0000"  >&lt;p&gt;PR for this here: &lt;a href=&quot;https://github.com/apache/spark/pull/11982&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11982&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15215039" author="marcin.tustin" created="Mon, 28 Mar 2016 22:52:46 +0000"  >&lt;p&gt;Reworked PR here: &lt;a href=&quot;https://github.com/apache/spark/pull/12016&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12016&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15215041" author="apachespark" created="Mon, 28 Mar 2016 22:53:04 +0000"  >&lt;p&gt;User &apos;mtustin-handy&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12016&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12016&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15223569" author="srowen" created="Mon, 4 Apr 2016 00:42:48 +0000"  >&lt;p&gt;Issue resolved by pull request 12016&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12016&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12016&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 33 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2v8ef:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>