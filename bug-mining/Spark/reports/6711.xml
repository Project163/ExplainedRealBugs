<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:07:02 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-29022] SparkSQLCLI can not use &apos;ADD JAR&apos; &apos;s jar as Serde class</title>
                <link>https://issues.apache.org/jira/browse/SPARK-29022</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Spark SQL CLI can&apos;t use class in jars add by SQL &apos;ADD JAR&apos;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
spark-sql&amp;gt; add jar /root/.m2/repository/org/apache/hive/hcatalog/hive-hcatalog-core/2.3.6/hive-hcatalog-core-2.3.6.jar;
ADD JAR /root/.m2/repository/org/apache/hive/hcatalog/hive-hcatalog-core/2.3.6/hive-hcatalog-core-2.3.6.jar
spark-sql&amp;gt; CREATE TABLE addJar(key string) ROW FORMAT SERDE &lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.hive.hcatalog.data.JsonSerDe&apos;&lt;/span&gt;;
spark-sql&amp;gt; select * from addJar;
19/09/07 03:06:54 ERROR SparkSQLDriver: Failed in [select * from addJar]
java.lang.RuntimeException: java.lang.ClassNotFoundException: org.apache.hive.hcatalog.data.JsonSerDe
	at org.apache.hadoop.hive.ql.plan.TableDesc.getDeserializerClass(TableDesc.java:79)
	at org.apache.spark.sql.hive.execution.HiveTableScanExec.addColumnMetadataToConf(HiveTableScanExec.scala:123)
	at org.apache.spark.sql.hive.execution.HiveTableScanExec.hadoopConf$lzycompute(HiveTableScanExec.scala:101)
	at org.apache.spark.sql.hive.execution.HiveTableScanExec.hadoopConf(HiveTableScanExec.scala:98)
	at org.apache.spark.sql.hive.execution.HiveTableScanExec.hadoopReader$lzycompute(HiveTableScanExec.scala:110)
	at org.apache.spark.sql.hive.execution.HiveTableScanExec.hadoopReader(HiveTableScanExec.scala:105)
	at org.apache.spark.sql.hive.execution.HiveTableScanExec.$anonfun$doExecute$1(HiveTableScanExec.scala:188)
	at org.apache.spark.util.Utils$.withDummyCallSite(Utils.scala:2488)
	at org.apache.spark.sql.hive.execution.HiveTableScanExec.doExecute(HiveTableScanExec.scala:188)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:189)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:227)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:224)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:185)
	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:329)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:378)
	at org.apache.spark.sql.execution.SparkPlan.executeCollectPublic(SparkPlan.scala:408)
	at org.apache.spark.sql.execution.HiveResult$.hiveResultString(HiveResult.scala:52)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.$anonfun$run$1(SparkSQLDriver.scala:65)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$4(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:87)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLDriver.run(SparkSQLDriver.scala:65)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.processCmd(SparkSQLCLIDriver.scala:367)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:403)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:272)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:179)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:202)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:89)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:999)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1008)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.ClassNotFoundException: org.apache.hive.hcatalog.data.JsonSerDe
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:471)
	at java.base/java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:588)
	at java.base/java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:521)
	at java.base/java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
	at java.base/java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:398)
	at org.apache.hadoop.hive.ql.plan.TableDesc.getDeserializerClass(TableDesc.java:76)
	... 38 more
OptionsAttachments&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13255612">SPARK-29022</key>
            <summary>SparkSQLCLI can not use &apos;ADD JAR&apos; &apos;s jar as Serde class</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="angerszhuuu">angerszhu</assignee>
                                    <reporter username="angerszhuuu">angerszhu</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Sep 2019 11:43:37 +0000</created>
                <updated>Tue, 1 Oct 2019 15:10:34 +0000</updated>
                            <resolved>Tue, 1 Oct 2019 15:09:53 +0000</resolved>
                                    <version>2.0.2</version>
                    <version>2.1.3</version>
                    <version>2.2.3</version>
                    <version>2.3.4</version>
                    <version>2.4.4</version>
                    <version>3.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16931094" author="q79969786" created="Tue, 17 Sep 2019 04:55:57 +0000"  >&lt;p&gt;It works before Spark 2.0.&lt;/p&gt;</comment>
                            <comment id="16931116" author="angerszhuuu" created="Tue, 17 Sep 2019 05:57:36 +0000"  >&lt;p&gt;Since after spark-2.0, when we call method HiveClientImpl#withHiveState, it will set back origin classLoader of HiveClientImpl&apos;s state:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def withHiveState[A](f: =&amp;gt; A): A = retryLocked {
  val original = &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().getContextClassLoader
  val originalConfLoader = state.getConf.getClassLoader
  &lt;span class=&quot;code-comment&quot;&gt;// The classloader in clientLoader could be changed after addJar, always use the latest
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// classloader. We explicitly set the context &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;loader since &lt;span class=&quot;code-quote&quot;&gt;&quot;conf.setClassLoader&quot;&lt;/span&gt; does
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// not &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; that, and the Hive client libraries may need to load classes defined by the client&apos;s
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;loader.
&lt;/span&gt;  &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().setContextClassLoader(clientLoader.classLoader)
  state.getConf.setClassLoader(clientLoader.classLoader)
  &lt;span class=&quot;code-comment&quot;&gt;// Set the thread local metastore client to the client associated with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; HiveClientImpl.
&lt;/span&gt;  Hive.set(client)
  &lt;span class=&quot;code-comment&quot;&gt;// Replace conf in the thread local Hive with current conf
&lt;/span&gt;  Hive.get(conf)
  &lt;span class=&quot;code-comment&quot;&gt;// setCurrentSessionState will use the classLoader associated
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// with the HiveConf in `state` to override the context &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;loader of the current
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// thread.
&lt;/span&gt;  shim.setCurrentSessionState(state)
  val ret = &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; f &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
    state.getConf.setClassLoader(originalConfLoader)
    &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().setContextClassLoader(original)
    HiveCatalogMetrics.incrementHiveClientCalls(1)
  }
  ret
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Before version 2.0, it will just set state&apos;s conf&apos;s classloader as clientLoader.classLoader, won&apos;t setback.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
 * Runs `f` with ThreadLocal session state and classloaders configured &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; version of hive.
 */
def withHiveState[A](f: =&amp;gt; A): A = retryLocked {
  val original = &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().getContextClassLoader
  &lt;span class=&quot;code-comment&quot;&gt;// Set the thread local metastore client to the client associated with &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; HiveClientImpl.
&lt;/span&gt;  Hive.set(client)
  &lt;span class=&quot;code-comment&quot;&gt;// The classloader in clientLoader could be changed after addJar, always use the latest
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// classloader
&lt;/span&gt;  state.getConf.setClassLoader(clientLoader.classLoader)
  &lt;span class=&quot;code-comment&quot;&gt;// setCurrentSessionState will use the classLoader associated
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// with the HiveConf in `state` to override the context &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;loader of the current
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// thread.
&lt;/span&gt;  shim.setCurrentSessionState(state)
  val ret = &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; f &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
    &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().setContextClassLoader(original)
  }
  ret
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16932268" author="angerszhuuu" created="Wed, 18 Sep 2019 10:01:13 +0000"  >&lt;p&gt;In spark-2.0, run with hive load by &apos;maven&apos; will meet this error.&lt;/p&gt;</comment>
                            <comment id="16942056" author="srowen" created="Tue, 1 Oct 2019 15:09:53 +0000"  >&lt;p&gt;Issue resolved by pull request 25729&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/25729&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/25729&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12980463" name="image-2019-09-17-13-54-50-896.png" size="857034" author="angerszhuuu" created="Tue, 17 Sep 2019 05:54:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 7 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z06gk8:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>