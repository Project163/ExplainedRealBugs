<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:06:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-25474] Update the docs for spark.sql.statistics.fallBackToHdfs</title>
                <link>https://issues.apache.org/jira/browse/SPARK-25474</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;b&gt;Description :&lt;/b&gt; Size in bytes of the query is coming in EB in case of parquet datasource. this would impact the performance , since join queries would always go as Sort Merge Join.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Precondition :&lt;/b&gt;&#160;spark.sql.statistics.fallBackToHdfs = true&lt;/p&gt;

&lt;p&gt;Steps:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//10.xx:23040/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&amp;gt; create table t1110 (a &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, b string) using parquet PARTITIONED BY (b) ;
&lt;/span&gt;+---------+--+
| Result |
+---------+--+
+---------+--+

0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//10.1xx:23040/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&amp;gt; insert into t1110 values (2,&lt;span class=&quot;code-quote&quot;&gt;&apos;b&apos;&lt;/span&gt;);
&lt;/span&gt;+---------+--+
| Result |
+---------+--+
+---------+--+
0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//10.1xx:23040/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&amp;gt; insert into t1110 values (1,&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;);
&lt;/span&gt;+---------+--+
| Result |
+---------+--+
+---------+--+
0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//10.xx.xx:23040/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&amp;gt; select * from t1110;
&lt;/span&gt;+----+----+--+
| a | b |
+----+----+--+
| 1 | a |
| 2 | b |
+----+----+--+

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;b&gt;&lt;font color=&quot;#d04437&quot;&gt;Cost of the query shows sizeInBytes in EB&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&#160;explain cost select * from t1110;



| == Optimized Logical Plan ==
Relation[a#23,b#24] parquet, Statistics(sizeInBytes=8.0 EB, hints=none)

== Physical Plan ==
*(1) FileScan parquet open.t1110[a#23,b#24] Batched: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, Format: Parquet, Location: CatalogFileIndex[hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hacluster/user/sparkhive/warehouse/open.db/t1110], PartitionCount: 2, PartitionFilters: [], PushedFilters: [], ReadSchema: struct&amp;lt;a:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&amp;gt; |&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;b&gt;&lt;font color=&quot;#d04437&quot;&gt;This would lead to Sort Merge Join in case of join query&lt;/font&gt;&lt;/b&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//10.xx.xx:23040/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&amp;gt; create table t110 (a &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, b string) using parquet PARTITIONED BY (b) ;
&lt;/span&gt;+---------+--+
| Result |
+---------+--+
+---------+--+

0: jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//10.xx.xx:23040/&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&amp;gt; insert into t110 values (1,&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;);
&lt;/span&gt;+---------+--+
| Result |
+---------+--+
+---------+--+

&#160;explain select * from t1110 t1 join t110 t2 on t1.a=t2.a;

| == Physical Plan ==
*(5) SortMergeJoin [a#23], [a#55], Inner
:- *(2) Sort [a#23 ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
: +- Exchange hashpartitioning(a#23, 200)
: +- *(1) Project [a#23, b#24]
: +- *(1) Filter isnotnull(a#23)
: +- *(1) FileScan parquet open.t1110[a#23,b#24] Batched: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, Format: Parquet, Location: CatalogFileIndex[hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hacluster/user/sparkhive/warehouse/open.db/t1110], PartitionCount: 2, PartitionFilters: [], PushedFilters: [IsNotNull(a)], ReadSchema: struct&amp;lt;a:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&amp;gt;
&lt;/span&gt;+- *(4) Sort [a#55 ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
+- Exchange hashpartitioning(a#55, 200)
+- *(3) Project [a#55, b#56]
+- *(3) Filter isnotnull(a#55)
+- *(3) FileScan parquet open.t110[a#55,b#56] Batched: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, Format: Parquet, Location: CatalogFileIndex[hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hacluster/user/sparkhive/warehouse/open.db/t110], PartitionCount: 1, PartitionFilters: [], PushedFilters: [IsNotNull(a)], ReadSchema: struct&amp;lt;a:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&amp;gt; |
&lt;/span&gt;

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;Spark 2.3.1&lt;br/&gt;
Hadoop 2.7.2&lt;/p&gt;</environment>
        <key id="13186235">SPARK-25474</key>
            <summary>Update the docs for spark.sql.statistics.fallBackToHdfs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yumwang">Yuming Wang</assignee>
                                    <reporter username="Ayush007">Ayush Anubhava</reporter>
                        <labels>
                    </labels>
                <created>Thu, 20 Sep 2018 04:34:27 +0000</created>
                <updated>Fri, 28 Feb 2020 06:49:40 +0000</updated>
                            <resolved>Wed, 28 Aug 2019 11:17:03 +0000</resolved>
                                    <version>2.3.1</version>
                    <version>2.4.3</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="16621535" author="sandeep.katta2007" created="Thu, 20 Sep 2018 05:32:01 +0000"  >&lt;p&gt;what is the behavior for spark.sql.statistics.fallBackToHdfs = false&#160; ?&lt;/p&gt;</comment>
                            <comment id="16621539" author="ayush007" created="Thu, 20 Sep 2018 05:37:05 +0000"  >&lt;p&gt;It behaves the same even if fall back to hdfs is enabled.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16622065" author="shahid" created="Thu, 20 Sep 2018 13:45:13 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Ayush007&quot; class=&quot;user-hover&quot; rel=&quot;Ayush007&quot;&gt;Ayush007&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sandeep.katta2007&quot; class=&quot;user-hover&quot; rel=&quot;sandeep.katta2007&quot;&gt;sandeep.katta2007&lt;/a&gt;, I am working on it. I will raise a PR &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16622545" author="apachespark" created="Thu, 20 Sep 2018 19:11:34 +0000"  >&lt;p&gt;User &apos;shahidki31&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22502&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22502&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16622546" author="apachespark" created="Thu, 20 Sep 2018 19:11:55 +0000"  >&lt;p&gt;User &apos;shahidki31&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22502&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22502&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16894824" author="dongjoon" created="Sun, 28 Jul 2019 22:43:14 +0000"  >&lt;p&gt;This is resolved via &lt;a href=&quot;https://github.com/apache/spark/pull/22502&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22502&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16908660" author="q79969786" created="Fri, 16 Aug 2019 02:56:24 +0000"  >&lt;p&gt;More benchmark result about &lt;a href=&quot;https://github.com/apache/spark/pull/24715:&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24715:&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 169
Get size fall back to HDFS: 706507984, time: 228
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 161
Get size fall back to HDFS: 706507984, time: 209
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 136
Get size fall back to HDFS: 706507984, time: 188
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 149
Get size fall back to HDFS: 706507984, time: 164
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 147
Get size fall back to HDFS: 706507984, time: 184
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 140
Get size fall back to HDFS: 706507984, time: 458
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 115
Get size fall back to HDFS: 706507984, time: 375
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 142
Get size fall back to HDFS: 706507984, time: 202
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 145
Get size fall back to HDFS: 706507984, time: 206
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 385
Get size fall back to HDFS: 706507984, time: 213
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 142
Get size fall back to HDFS: 706507984, time: 194
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 159
Get size fall back to HDFS: 706507984, time: 187
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 136
Get size fall back to HDFS: 706507984, time: 188
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 180
Get size fall back to HDFS: 706507984, time: 196
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 122
Get size fall back to HDFS: 706507984, time: 176
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 179
Get size fall back to HDFS: 706507984, time: 187
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 251
Get size fall back to HDFS: 706507984, time: 192
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 132
Get size fall back to HDFS: 706507984, time: 175
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 154
Get size fall back to HDFS: 706507984, time: 188
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 142
Get size fall back to HDFS: 706507984, time: 186
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 199
Get size fall back to HDFS: 706507984, time: 256
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 220
Get size fall back to HDFS: 706507984, time: 264
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 153
Get size fall back to HDFS: 706507984, time: 300
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 157
Get size fall back to HDFS: 706507984, time: 402
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 119
Get size fall back to HDFS: 706507984, time: 220
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 126
Get size fall back to HDFS: 706507984, time: 189
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 154
Get size fall back to HDFS: 706507984, time: 213
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 132
Get size fall back to HDFS: 706507984, time: 197
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 266
Get size fall back to HDFS: 706507984, time: 220
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 135
Get size fall back to HDFS: 706507984, time: 281
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 139
Get size fall back to HDFS: 706507984, time: 204
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 112
Get size fall back to HDFS: 706507984, time: 359
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 164
Get size fall back to HDFS: 706507984, time: 363
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 139
Get size fall back to HDFS: 706507984, time: 202
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 140
Get size fall back to HDFS: 706507984, time: 195
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 137
Get size fall back to HDFS: 706507984, time: 192
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 145
Get size fall back to HDFS: 706507984, time: 201
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 111
Get size fall back to HDFS: 706507984, time: 267
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


scala&amp;gt; spark.sql(&quot;explain cost select * from test_non_partition_300000&quot;).show
Get size from relation: 706507984, time: 126
Get size fall back to HDFS: 706507984, time: 226
+--------------------+
|                plan|
+--------------------+
|== Optimized Logi...|
+--------------------+


&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Enable &lt;tt&gt;spark.sql.statistics.fallBackToHdfs&lt;/tt&gt; for partition tables:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; spark.sql(&quot;set spark.sql.statistics.fallBackToHdfs&quot;)
res1: org.apache.spark.sql.DataFrame = [key: string, value: string]

scala&amp;gt; spark.sql(&quot;explain cost select * from test_partition_10000&quot;).show(false)
Get size from relation: 9223372036854775807, time: 0
Get size fall back to HDFS: 1036799332, time: 47
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|plan                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
|== Optimized Logical Plan ==
Relation[id#15L,c3#16L,c2#17L] parquet, Statistics(sizeInBytes=988.8 MiB)

== Physical Plan ==
*(1) ColumnarToRow
+- FileScan parquet zeta_spark_dss.test_partition_10000[id#15L,c3#16L,c2#17L] Batched: true, DataFilters: [], Format: Parquet, Location: CatalogFileIndex[hdfs://hercules/sys/edw/zeta_spark_test_suite/dss/test_partition_10000], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&amp;lt;id:bigint,c3:bigint&amp;gt;

|
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16909984" author="dongjoon" created="Sun, 18 Aug 2019 14:56:17 +0000"  >&lt;p&gt;This is reverted from `branch-2.3` and `branch-2.4` to prevent VOTE failures. In `master` branch, we need to use the test cases.&lt;/p&gt;</comment>
                            <comment id="16917690" author="cloud_fan" created="Wed, 28 Aug 2019 11:17:04 +0000"  >&lt;p&gt;Issue resolved by pull request 24715&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24715&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24715&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 11 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3yaav:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>