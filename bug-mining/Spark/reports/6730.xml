<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:07:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-27259] Allow setting -1 as split size for InputFileBlock</title>
                <link>https://issues.apache.org/jira/browse/SPARK-27259</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;From spark 2.2.x versions, when spark job processing any compressed HDFS files with custom input file format then spark jobs are failing with error &quot;java.lang.IllegalArgumentException: requirement failed: length (-1) cannot be negative&quot;, the custom input file format will return the number of bytes length value as -1 for compressed file formats due to the compressed HDFS file are non splitable, so for compressed input file format the split will be offset as 0 and number of bytes length as -1, spark should consider the bytes length value -1 as valid split for the compressed file formats.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;We observed that earlier versions of spark doesn&#8217;t have this validation, and found that from spark 2.2.x new validation got introduced in the class InputFileBlockHolder, so spark should accept the number of bytes length value -1 as valid length for input splits from spark 2.2.x as well.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;ins&gt;Below is the stack trace.&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;&#160;Caused by: java.lang.IllegalArgumentException: requirement failed: length (-1) cannot be negative&lt;/p&gt;

&lt;p&gt;&#160; at scala.Predef$.require(Predef.scala:224)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.rdd.InputFileBlockHolder$.set(InputFileBlockHolder.scala:70)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.rdd.HadoopRDD$$anon$1.&amp;lt;init&amp;gt;(HadoopRDD.scala:226)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:214)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:94)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.scheduler.Task.run(Task.scala:109)&lt;/p&gt;

&lt;p&gt;&#160; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)&lt;/p&gt;

&lt;p&gt;&#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;/p&gt;

&lt;p&gt;&#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;/p&gt;

&lt;p&gt;&#160; at java.lang.Thread.run(Thread.java:748)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;ins&gt;Below is the code snippet which caused this issue.&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;&#160;&#160;&#160;**&#160;&#160;&#160; &lt;font color=&quot;#ff0000&quot;&gt;require(length &amp;gt;= 0, s&quot;length ($length) cannot be negative&quot;)&lt;/font&gt; // This validation caused the issue.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// code placeholder
&lt;/span&gt;
&#160;org.apache.spark.rdd.InputFileBlockHolder - spark-core

&#160;

def set(filePath: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, startOffset: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;, length: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;): Unit = {

&#160;&#160;&#160; require(filePath != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;filePath cannot be &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;&quot;&lt;/span&gt;)

&#160;&#160;&#160; require(startOffset &amp;gt;= 0, s&lt;span class=&quot;code-quote&quot;&gt;&quot;startOffset ($startOffset) cannot be negative&quot;&lt;/span&gt;)

&#160;&#160;&#160; require(length &amp;gt;= 0, s&lt;span class=&quot;code-quote&quot;&gt;&quot;length ($length) cannot be negative&quot;&lt;/span&gt;)  

&#160;&#160;&#160; inputBlock.set(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; FileBlock(UTF8String.fromString(filePath), startOffset, length))

&#160; }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;ins&gt;Steps to reproduce the issue.&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;&#160;Please refer the below code to reproduce the issue.&#160;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// code placeholder
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.mapred.JobConf

val hadoopConf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; JobConf()

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.mapred.FileInputFormat

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.hadoop.fs.Path

FileInputFormat.setInputPaths(hadoopConf, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(&lt;span class=&quot;code-quote&quot;&gt;&quot;/output656/part-r-00000.gz&quot;&lt;/span&gt;))&#160; &#160;&#160;

val records = sc.hadoopRDD(hadoopConf,classOf[com.platform.custom.storagehandler.INFAInputFormat], classOf[org.apache.hadoop.io.LongWritable], classOf[org.apache.hadoop.io.Writable])&#160;

records.count()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13223523">SPARK-27259</key>
            <summary>Allow setting -1 as split size for InputFileBlock</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="praneetsharma">Praneet Sharma</assignee>
                                    <reporter username="Simon_poortman@icloud.com">Simon poortman</reporter>
                        <labels>
                    </labels>
                <created>Sat, 23 Mar 2019 17:35:14 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:48 +0000</updated>
                            <resolved>Wed, 16 Oct 2019 07:25:23 +0000</resolved>
                                    <version>2.2.1</version>
                    <version>2.2.2</version>
                    <version>2.2.3</version>
                    <version>2.3.0</version>
                    <version>2.3.1</version>
                    <version>2.3.2</version>
                    <version>2.3.3</version>
                    <version>2.4.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="16800341" author="gurwls223" created="Mon, 25 Mar 2019 01:38:06 +0000"  >&lt;p&gt;Please avoid to set Ciritical+ which is usually reserved for committers.&lt;/p&gt;</comment>
                            <comment id="16951608" author="praneetsharma" created="Tue, 15 Oct 2019 05:07:38 +0000"  >&lt;p&gt;Submitted a PR for this issue:&#160;&lt;a href=&quot;https://github.com/apache/spark/pull/26123&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/26123&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16952164" author="dongjoon" created="Tue, 15 Oct 2019 17:48:18 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=praneetsharma&quot; class=&quot;user-hover&quot; rel=&quot;praneetsharma&quot;&gt;praneetsharma&lt;/a&gt;. Thank you for making a JIRA, but we cannot reproduce your problem due to the following.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
com.platform.custom.storagehandler.INFAInputFormat
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16952574" author="praneetsharma" created="Wed, 16 Oct 2019 07:25:23 +0000"  >&lt;p&gt;Fixed with&#160;&lt;a href=&quot;https://github.com/apache/spark/pull/26123&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/26123&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13223257">SPARK-27239</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 4 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z010vk:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>