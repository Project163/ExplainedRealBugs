<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:47 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26228] OOM issue encountered when computing Gramian matrix </title>
                <link>https://issues.apache.org/jira/browse/SPARK-26228</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;blockquote&gt;&lt;p&gt;/**&lt;/p&gt;

&lt;p&gt;&#160;* Computes the Gramian matrix `A^T A`.&lt;br/&gt;
 &#160;*&lt;/p&gt;

&lt;p&gt;&#160;* @note This cannot be computed on matrices with more than 65535 columns.&lt;br/&gt;
 &#160;*/&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As the above annotation of computeGramianMatrix in RowMatrix.scala said, it supports computing on matrices with no more than 65535 columns.&lt;/p&gt;

&lt;p&gt;However, we&#160;find that it will throw OOM(Request Array Size Exceeds VM Limit) when computing on matrices with 16000 columns.&lt;/p&gt;

&lt;p&gt;The root casue seems that the TreeAggregate writes a&#160; very long buffer array (16000*16000*8) which exceeds jvm limit(2^31 - 1).&lt;/p&gt;

&lt;p&gt;Does RowMatrix really supports computing on matrices with no more than 65535 columns?&lt;/p&gt;

&lt;p&gt;I doubt that&#160;computeGramianMatrix has a very serious performance issue.&lt;/p&gt;

&lt;p&gt;Do anyone has done some performance expriments before?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13201508">SPARK-26228</key>
            <summary>OOM issue encountered when computing Gramian matrix </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="hibayesian">Chen Lin</reporter>
                        <labels>
                    </labels>
                <created>Fri, 30 Nov 2018 04:16:05 +0000</created>
                <updated>Fri, 29 Mar 2019 20:13:14 +0000</updated>
                            <resolved>Wed, 23 Jan 2019 01:27:28 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.3.3</fixVersion>
                    <fixVersion>2.4.1</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>MLlib</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16706667" author="shahid" created="Mon, 3 Dec 2018 05:21:06 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hibayesian&quot; class=&quot;user-hover&quot; rel=&quot;hibayesian&quot;&gt;hibayesian&lt;/a&gt;, could you please share the full log of the error, if you have. Thanks&lt;/p&gt;

&lt;p&gt;(btw 16000*16000*8 &amp;lt; 2^31 -1 )&lt;/p&gt;</comment>
                            <comment id="16706701" author="hibayesian" created="Mon, 3 Dec 2018 06:00:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shahid&quot; class=&quot;user-hover&quot; rel=&quot;shahid&quot;&gt;shahid&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have upload the screenshot of log.&#160;&#160;&lt;/p&gt;

&lt;p&gt;I doubt there are extra costs when writing a size of 16000*16000*8 byte array.&lt;/p&gt;</comment>
                            <comment id="16706706" author="hibayesian" created="Mon, 3 Dec 2018 06:02:22 +0000"  >&lt;p&gt;Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Requested array size exceeds VM limit&lt;br/&gt;
	at java.util.Arrays.copyOf(Arrays.java:3236)&lt;br/&gt;
	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:113)&lt;br/&gt;
	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)&lt;br/&gt;
	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:140)&lt;br/&gt;
	at org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)&lt;br/&gt;
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1877)&lt;br/&gt;
	at java.io.ObjectOutputStream$BlockDataOutputStream.setBlockDataMode(ObjectOutputStream.java:1786)&lt;br/&gt;
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1189)&lt;br/&gt;
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)&lt;br/&gt;
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)&lt;br/&gt;
	at org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:100)&lt;br/&gt;
	at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:342)&lt;br/&gt;
	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:335)&lt;br/&gt;
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:159)&lt;br/&gt;
	at org.apache.spark.SparkContext.clean(SparkContext.scala:2292)&lt;br/&gt;
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)&lt;br/&gt;
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2124)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1092)&lt;br/&gt;
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)&lt;br/&gt;
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.fold(RDD.scala:1086)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1155)&lt;br/&gt;
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)&lt;br/&gt;
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1131)&lt;br/&gt;
	at org.apache.spark.mllib.linalg.distributed.RowMatrix.computeGramianMatrix(RowMatrix.scala:123)&lt;br/&gt;
	at org.apache.spark.mllib.linalg.distributed.RowMatrix.computeCovariance(RowMatrix.scala:345)&lt;br/&gt;
	at org.apache.spark.mllib.stat.correlation.PearsonCorrelation$.computeCorrelationMatrix(PearsonCorrelation.scala:49)&lt;br/&gt;
	at org.apache.spark.mllib.stat.correlation.Correlations$.corrMatrix(Correlation.scala:66)&lt;br/&gt;
	at org.apache.spark.mllib.stat.Statistics$.corr(Statistics.scala:57)&lt;/p&gt;</comment>
                            <comment id="16706721" author="shahid" created="Mon, 3 Dec 2018 06:24:24 +0000"  >&lt;p&gt;could you please increase the driver memory and check. &lt;/p&gt;</comment>
                            <comment id="16706751" author="hibayesian" created="Mon, 3 Dec 2018 06:45:56 +0000"  >&lt;p&gt;I have tried to set&#160;spark.driver.memory from 8g to 16g.&lt;/p&gt;

&lt;p&gt;It doesn&apos;t work.&lt;/p&gt;</comment>
                            <comment id="16747603" author="srowen" created="Mon, 21 Jan 2019 01:29:25 +0000"  >&lt;p&gt;Yep this is a real problem. The issue is the &apos;zeroValue&quot; to treeAggregate. It allocates a huge dense matrix of 0s, which must then be serialized several times. This includes a simple check to see if it&apos;s serializable, which serializes with JavaSerializer, and at some point that takes so much memory that more than 2GB of bytes are needed somewhere in a ByteArrayOutputStream and it fails. It won&apos;t matter how much memory the driver has.&lt;/p&gt;

&lt;p&gt;I think the fix is easy; the zero value should just be null, and the seqOp and combOp can easily handle this situation. At least, I tried it locally and it works fine, and doesn&apos;t fail upfront at about a 16000x16000 Gramian. It ought to be faster too.&lt;/p&gt;</comment>
                            <comment id="16749371" author="srowen" created="Wed, 23 Jan 2019 01:27:28 +0000"  >&lt;p&gt;Issue resolved by pull request 23600&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23600&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23600&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13219809">SPARK-27069</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12950346" name="1.jpeg" size="117028" author="hibayesian" created="Mon, 3 Dec 2018 05:54:31 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 42 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s010u0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>