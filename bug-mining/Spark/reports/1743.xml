<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:26:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-6967] Internal DateType not handled correctly in caching</title>
                <link>https://issues.apache.org/jira/browse/SPARK-6967</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;From the user list.  It looks like data is not implemented correctly in in-memory caching.  We should also check the JDBC datasource support for date.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Stack trace of an exception being reported since upgrade to 1.3.0:
java.lang.ClassCastException: java.sql.Date cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to
java.lang.&lt;span class=&quot;code-object&quot;&gt;Integer&lt;/span&gt;
        at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:105)
~[scala-library-2.11.6.jar:na]
        at
org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:83)
~[spark-catalyst_2.11-1.3.0.jar:1.3.0]
        at
org.apache.spark.sql.columnar.IntColumnStats.gatherStats(ColumnStats.scala:191)
~[spark-sql_2.11-1.3.0.jar:1.3.0]
        at
org.apache.spark.sql.columnar.NullableColumnBuilder$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;appendFrom(NullableColumnBuilder.scala:56)
~[spark-sql_2.11-1.3.0.jar:1.3.0]
        at
org.apache.spark.sql.columnar.NativeColumnBuilder.org$apache$spark$sql$columnar$compression$CompressibleColumnBuilder$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$appendFrom(ColumnBuilder.scala:87)
~[spark-sql_2.11-1.3.0.jar:1.3.0]
        at
org.apache.spark.sql.columnar.compression.CompressibleColumnBuilder$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;appendFrom(CompressibleColumnBuilder.scala:78)
~[spark-sql_2.11-1.3.0.jar:1.3.0]
        at
org.apache.spark.sql.columnar.NativeColumnBuilder.appendFrom(ColumnBuilder.scala:87)
~[spark-sql_2.11-1.3.0.jar:1.3.0]
        at
org.apache.spark.sql.columnar.InMemoryRelation$$anonfun$3$$anon$1.next(InMemoryColumnarTableScan.scala:135)
~[spark-sql_2.11-1.3.0.jar:1.3.0]
        at
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12821630">SPARK-6967</key>
            <summary>Internal DateType not handled correctly in caching</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="adrian-wang">Adrian Wang</assignee>
                                    <reporter username="marmbrus">Michael Armbrust</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 Apr 2015 18:49:52 +0000</created>
                <updated>Thu, 23 Apr 2015 02:19:23 +0000</updated>
                            <resolved>Thu, 23 Apr 2015 02:18:39 +0000</resolved>
                                                    <fixVersion>1.3.2</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14499574" author="rkrist" created="Fri, 17 Apr 2015 10:06:15 +0000"  >&lt;p&gt;steps to reproduce the same problem in JdbcRDD (hope it helps):&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;create a table containig Date field in your favourite DBMS, I used PostgreSQL:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;CREATE TABLE spark_test
(
  pk_spark_test integer NOT NULL,
  text character varying(25),
  date1 date,
  CONSTRAINT pk PRIMARY KEY (pk_spark_test)
)
WITH (
  OIDS=FALSE
);
ALTER TABLE spark_test
  OWNER TO postgres;
GRANT ALL ON TABLE spark_test TO postgres;
GRANT ALL ON TABLE spark_test TO &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;fill it with data:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;insert into spark_test(pk_spark_test, text, date1) values (1, &lt;span class=&quot;code-quote&quot;&gt;&apos;one&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;2014-04-01&apos;&lt;/span&gt;)
insert into spark_test(pk_spark_test, text, date1) values (2, &lt;span class=&quot;code-quote&quot;&gt;&apos;two&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;2014-04-02&apos;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;from scala REPL, try the following:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.SQLContext

val sqc = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SQLContext(sc)
sqc.jdbc(&lt;span class=&quot;code-quote&quot;&gt;&quot;jdbc:postgresql:&lt;span class=&quot;code-comment&quot;&gt;//localhost:5432/ebx_repository?schema=ebx_repository&amp;amp;user=abc&amp;amp;password=def&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;spark_test&quot;&lt;/span&gt;).cache.registerTempTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark_test&quot;&lt;/span&gt;)  // don&#8217;t forget the cache method
&lt;/span&gt;
sqc.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select * from spark_test&quot;&lt;/span&gt;).foreach(println)

the last command will produce the following error (&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; you don&#8217;t use cache, it will produce correct results as expected):

11:50:27.306 [Executor task launch worker-0] ERROR org.apache.spark.executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.MutableAny cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to org.apache.spark.sql.catalyst.expressions.MutableInt
                at org.apache.spark.sql.catalyst.expressions.SpecificMutableRow.getInt(SpecificMutableRow.scala:248) ~[spark-catalyst_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.sql.columnar.IntColumnStats.gatherStats(ColumnStats.scala:191) ~[spark-sql_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.sql.columnar.NullableColumnBuilder$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;appendFrom(NullableColumnBuilder.scala:56) ~[spark-sql_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.sql.columnar.NativeColumnBuilder.org$apache$spark$sql$columnar$compression$CompressibleColumnBuilder$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$appendFrom(ColumnBuilder.scala:87) ~[spark-sql_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.sql.columnar.compression.CompressibleColumnBuilder$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;appendFrom(CompressibleColumnBuilder.scala:78) ~[spark-sql_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.sql.columnar.NativeColumnBuilder.appendFrom(ColumnBuilder.scala:87) ~[spark-sql_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.sql.columnar.InMemoryRelation$$anonfun$3$$anon$1.next(InMemoryColumnarTableScan.scala:135) ~[spark-sql_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.sql.columnar.InMemoryRelation$$anonfun$3$$anon$1.next(InMemoryColumnarTableScan.scala:111) ~[spark-sql_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:249) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:172) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:79) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:242) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:244) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:244) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.scheduler.Task.run(Task.scala:64) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203) ~[spark-core_2.11-1.3.0.jar:1.3.0]
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_11]
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_11]
                at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745) [na:1.8.0_11]
11:50:27.318 [task-result-getter-0] WARN  o.a.spark.scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.MutableAny cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to org.apache.spark.sql.catalyst.expressions.MutableInt
                at org.apache.spark.sql.catalyst.expressions.SpecificMutableRow.getInt(SpecificMutableRow.scala:248)
                at org.apache.spark.sql.columnar.IntColumnStats.gatherStats(ColumnStats.scala:191)
                at org.apache.spark.sql.columnar.NullableColumnBuilder$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;appendFrom(NullableColumnBuilder.scala:56)
                at org.apache.spark.sql.columnar.NativeColumnBuilder.org$apache$spark$sql$columnar$compression$CompressibleColumnBuilder$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$appendFrom(ColumnBuilder.scala:87)
                at org.apache.spark.sql.columnar.compression.CompressibleColumnBuilder$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;appendFrom(CompressibleColumnBuilder.scala:78)
                at org.apache.spark.sql.columnar.NativeColumnBuilder.appendFrom(ColumnBuilder.scala:87)
                at org.apache.spark.sql.columnar.InMemoryRelation$$anonfun$3$$anon$1.next(InMemoryColumnarTableScan.scala:135)
                at org.apache.spark.sql.columnar.InMemoryRelation$$anonfun$3$$anon$1.next(InMemoryColumnarTableScan.scala:111)
                at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:249)
                at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:172)
                at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:79)
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:242)
                at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
                at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)
                at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
                at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)
                at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
                at org.apache.spark.scheduler.Task.run(Task.scala:64)
                at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
                at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

11:50:27.320 [task-result-getter-0] ERROR o.a.spark.scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost): java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.MutableAny cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to org.apache.spark.sql.catalyst.expressions.MutableInt
                at org.apache.spark.sql.catalyst.expressions.SpecificMutableRow.getInt(SpecificMutableRow.scala:248)
                at org.apache.spark.sql.columnar.IntColumnStats.gatherStats(ColumnStats.scala:191)
                at org.apache.spark.sql.columnar.NullableColumnBuilder$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;appendFrom(NullableColumnBuilder.scala:56)
                at org.apache.spark.sql.columnar.NativeColumnBuilder.org$apache$spark$sql$columnar$compression$CompressibleColumnBuilder$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$appendFrom(ColumnBuilder.scala:87)
                at org.apache.spark.sql.columnar.compression.CompressibleColumnBuilder$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;appendFrom(CompressibleColumnBuilder.scala:78)
                at org.apache.spark.sql.columnar.NativeColumnBuilder.appendFrom(ColumnBuilder.scala:87)
                at org.apache.spark.sql.columnar.InMemoryRelation$$anonfun$3$$anon$1.next(InMemoryColumnarTableScan.scala:135)
                at org.apache.spark.sql.columnar.InMemoryRelation$$anonfun$3$$anon$1.next(InMemoryColumnarTableScan.scala:111)
                at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:249)
                at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:172)
                at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:79)
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:242)
                at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
                at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)
                at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
                at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:277)
                at org.apache.spark.rdd.RDD.iterator(RDD.scala:244)
                at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
                at org.apache.spark.scheduler.Task.run(Task.scala:64)
                at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:203)
                at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
                at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
                at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1203)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1192)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1191)
  at scala.collection.mutable.ResizableArray$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1191)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:693)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:693)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:693)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1393)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1354)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14500249" author="yhuai" created="Fri, 17 Apr 2015 17:34:20 +0000"  >&lt;p&gt;I think the the problem is &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/jdbc/JDBCRDD.scala#L352&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/jdbc/JDBCRDD.scala#L352&lt;/a&gt;. &lt;/p&gt;</comment>
                            <comment id="14502614" author="apachespark" created="Mon, 20 Apr 2015 10:30:28 +0000"  >&lt;p&gt;User &apos;adrian-wang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5590&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5590&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 31 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2dd33:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329871">1.3.2</customfieldvalue>
    <customfieldvalue id="12329359">1.4.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>