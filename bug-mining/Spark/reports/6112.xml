<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:02:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-25767] Error reported in Spark logs when using the org.apache.spark:spark-sql_2.11:2.3.2 Java library</title>
                <link>https://issues.apache.org/jira/browse/SPARK-25767</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;Here is a bug I found using the latest version of spark-sql_2.11:2.2.0. Note that this case was also tested with spark-sql_2.11:2.3.2 and the bug is also present.&lt;/p&gt;

&lt;p&gt;This issue is a duplicate of the &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-25582&quot; title=&quot;Error in Spark logs when using the org.apache.spark:spark-sql_2.11:2.2.0 Java library&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-25582&quot;&gt;&lt;del&gt;SPARK-25582&lt;/del&gt;&lt;/a&gt; issue that I had to close after an accidental manipulation from another developer (was linked to a wrong PR)&lt;/p&gt;

&lt;p&gt;You will find attached three small sample CSV files with the minimal content to raise the bug.&lt;/p&gt;

&lt;p&gt;Find below a reproducer code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.SparkConf;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.Dataset;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.Row;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.SparkSession;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.collection.JavaConverters;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.collection.Seq;

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.Arrays;


&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;SparkBug {

    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &amp;lt;T&amp;gt; Seq&amp;lt;T&amp;gt; arrayToSeq(T[] input) {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; JavaConverters.asScalaIteratorConverter(Arrays.asList(input).iterator()).asScala().toSeq();
    }

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {
        SparkConf conf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkConf().setAppName(&lt;span class=&quot;code-quote&quot;&gt;&quot;SparkBug&quot;&lt;/span&gt;).setMaster(&lt;span class=&quot;code-quote&quot;&gt;&quot;local&quot;&lt;/span&gt;);
        SparkSession sparkSession = SparkSession.builder().config(conf).getOrCreate();
        Dataset&amp;lt;Row&amp;gt; df_a = sparkSession.read().option(&lt;span class=&quot;code-quote&quot;&gt;&quot;header&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;).csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;local/fileA.csv&quot;&lt;/span&gt;).dropDuplicates();
        Dataset&amp;lt;Row&amp;gt; df_b = sparkSession.read().option(&lt;span class=&quot;code-quote&quot;&gt;&quot;header&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;).csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;local/fileB.csv&quot;&lt;/span&gt;).dropDuplicates();
        Dataset&amp;lt;Row&amp;gt; df_c = sparkSession.read().option(&lt;span class=&quot;code-quote&quot;&gt;&quot;header&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;).csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;local/fileC.csv&quot;&lt;/span&gt;).dropDuplicates();

        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] key_join_1 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[]{&lt;span class=&quot;code-quote&quot;&gt;&quot;colA&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colB&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colC&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colD&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colE&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colF&quot;&lt;/span&gt;};
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] key_join_2 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[]{&lt;span class=&quot;code-quote&quot;&gt;&quot;colA&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colB&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colC&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colD&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;colE&quot;&lt;/span&gt;};

        Dataset&amp;lt;Row&amp;gt; df_inventory_1 = df_a.join(df_b, arrayToSeq(key_join_1), &lt;span class=&quot;code-quote&quot;&gt;&quot;left&quot;&lt;/span&gt;);
        Dataset&amp;lt;Row&amp;gt; df_inventory_2 = df_inventory_1.join(df_c, arrayToSeq(key_join_2), &lt;span class=&quot;code-quote&quot;&gt;&quot;left&quot;&lt;/span&gt;);

        df_inventory_2.show();
    }

}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When running this code, I can see the exception below:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
18/10/18 09:25:49 ERROR CodeGenerator: failed to compile: org.codehaus.commons.compiler.CompileException: File &lt;span class=&quot;code-quote&quot;&gt;&apos;generated.java&apos;&lt;/span&gt;, Line 202, Column 18: Expression &lt;span class=&quot;code-quote&quot;&gt;&quot;agg_isNull_28&quot;&lt;/span&gt; is not an rvalue
org.codehaus.commons.compiler.CompileException: File &lt;span class=&quot;code-quote&quot;&gt;&apos;generated.java&apos;&lt;/span&gt;, Line 202, Column 18: Expression &lt;span class=&quot;code-quote&quot;&gt;&quot;agg_isNull_28&quot;&lt;/span&gt; is not an rvalue
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compileError(UnitCompiler.java:11821)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.toRvalueOrCompileException(UnitCompiler.java:7170)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.getConstantValue2(UnitCompiler.java:5332)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.access$9400(UnitCompiler.java:212)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler$13$1.visitAmbiguousName(UnitCompiler.java:5287)
&#160;&#160; &#160;at org.codehaus.janino.Java$AmbiguousName.accept(Java.java:4053)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler$13.visitLvalue(UnitCompiler.java:5284)
&#160;&#160; &#160;at org.codehaus.janino.Java$Lvalue.accept(Java.java:3977)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.getConstantValue(UnitCompiler.java:5280)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:2391)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.access$1900(UnitCompiler.java:212)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler$6.visitIfStatement(UnitCompiler.java:1474)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler$6.visitIfStatement(UnitCompiler.java:1466)
&#160;&#160; &#160;at org.codehaus.janino.Java$IfStatement.accept(Java.java:2926)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:1466)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compileStatements(UnitCompiler.java:1546)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:3075)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1336)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compileDeclaredMethods(UnitCompiler.java:1309)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:799)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:958)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.access$700(UnitCompiler.java:212)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler$2.visitMemberClassDeclaration(UnitCompiler.java:393)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler$2.visitMemberClassDeclaration(UnitCompiler.java:385)
&#160;&#160; &#160;at org.codehaus.janino.Java$MemberClassDeclaration.accept(Java.java:1286)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:385)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compileDeclaredMemberTypes(UnitCompiler.java:1285)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:825)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile2(UnitCompiler.java:411)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.access$400(UnitCompiler.java:212)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:390)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler$2.visitPackageMemberClassDeclaration(UnitCompiler.java:385)
&#160;&#160; &#160;at org.codehaus.janino.Java$PackageMemberClassDeclaration.accept(Java.java:1405)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compile(UnitCompiler.java:385)
&#160;&#160; &#160;at org.codehaus.janino.UnitCompiler.compileUnit(UnitCompiler.java:357)
&#160;&#160; &#160;at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:234)
&#160;&#160; &#160;at org.codehaus.janino.SimpleCompiler.compileToClassLoader(SimpleCompiler.java:446)
&#160;&#160; &#160;at org.codehaus.janino.ClassBodyEvaluator.compileToClass(ClassBodyEvaluator.java:313)
&#160;&#160; &#160;at org.codehaus.janino.ClassBodyEvaluator.cook(ClassBodyEvaluator.java:235)
&#160;&#160; &#160;at org.codehaus.janino.SimpleCompiler.cook(SimpleCompiler.java:204)
&#160;&#160; &#160;at org.codehaus.commons.compiler.Cookable.cook(Cookable.java:80)
&#160;&#160; &#160;at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:1417)
&#160;&#160; &#160;at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1493)
&#160;&#160; &#160;at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anon$1.load(CodeGenerator.scala:1490)
&#160;&#160; &#160;at org.spark_project.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)
&#160;&#160; &#160;at org.spark_project.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)
&#160;&#160; &#160;at org.spark_project.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)
&#160;&#160; &#160;at org.spark_project.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)
&#160;&#160; &#160;at org.spark_project.guava.cache.LocalCache.get(LocalCache.java:4000)
&#160;&#160; &#160;at org.spark_project.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)
&#160;&#160; &#160;at org.spark_project.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)
&#160;&#160; &#160;at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.compile(CodeGenerator.scala:1365)
&#160;&#160; &#160;at org.apache.spark.sql.execution.WholeStageCodegenExec.liftedTree1$1(WholeStageCodegenExec.scala:579)
&#160;&#160; &#160;at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:578)
&#160;&#160; &#160;at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
&#160;&#160; &#160;at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
&#160;&#160; &#160;at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
&#160;&#160; &#160;at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
&#160;&#160; &#160;at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
&#160;&#160; &#160;at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
&#160;&#160; &#160;at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)
&#160;&#160; &#160;at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:337)
&#160;&#160; &#160;at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3278)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2489)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2489)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)
&#160;&#160; &#160;at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset.head(Dataset.scala:2489)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset.take(Dataset.scala:2703)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset.showString(Dataset.scala:254)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset.show(Dataset.scala:723)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset.show(Dataset.scala:682)
&#160;&#160; &#160;at org.apache.spark.sql.Dataset.show(Dataset.scala:691)
&#160;&#160; &#160;at SparkBug.main(SparkBug.java:30)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13192539">SPARK-25767</key>
            <summary>Error reported in Spark logs when using the org.apache.spark:spark-sql_2.11:2.3.2 Java library</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="petertoth">Peter Toth</assignee>
                                    <reporter username="onyssius">Thomas Brugiere</reporter>
                        <labels>
                    </labels>
                <created>Thu, 18 Oct 2018 13:27:41 +0000</created>
                <updated>Tue, 27 Oct 2020 11:01:29 +0000</updated>
                            <resolved>Mon, 29 Oct 2018 15:50:26 +0000</resolved>
                                    <version>2.2.0</version>
                    <version>2.3.2</version>
                                    <fixVersion>2.3.3</fixVersion>
                    <fixVersion>2.4.1</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16655366" author="mgaido" created="Thu, 18 Oct 2018 14:59:41 +0000"  >&lt;p&gt;I tried on current master branch but I wasn&apos;t able to reproduce. Could you try it on master branch too? Thanks.&lt;/p&gt;</comment>
                            <comment id="16655374" author="onyssius" created="Thu, 18 Oct 2018 15:04:22 +0000"  >&lt;p&gt;Hi Marco,&lt;/p&gt;

&lt;p&gt;I have noticed the bug using the jar coming from the mavenCentral repository (&lt;a href=&quot;http://central.maven.org/maven2/org/apache/spark/spark-sql_2.11/2.3.2/spark-sql_2.11-2.3.2.jar)&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://central.maven.org/maven2/org/apache/spark/spark-sql_2.11/2.3.2/spark-sql_2.11-2.3.2.jar)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Find below the &lt;b&gt;build.gradle&lt;/b&gt; I&apos;m using for reference:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
buildscript {
    ext {
        sparkVersion = &lt;span class=&quot;code-quote&quot;&gt;&apos;2.3.2&apos;&lt;/span&gt;
    }
}

plugins {
    id &lt;span class=&quot;code-quote&quot;&gt;&apos;java&apos;&lt;/span&gt;
}

group &lt;span class=&quot;code-quote&quot;&gt;&apos;spark&apos;&lt;/span&gt;
version &lt;span class=&quot;code-quote&quot;&gt;&apos;1.0-SNAPSHOT&apos;&lt;/span&gt;

sourceCompatibility = 1.8

repositories {
    mavenCentral()
}

dependencies {
    compile group: &lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.spark&apos;&lt;/span&gt;, name: &lt;span class=&quot;code-quote&quot;&gt;&apos;spark-sql_2.11&apos;&lt;/span&gt;, version: &lt;span class=&quot;code-quote&quot;&gt;&quot;${sparkVersion}&quot;&lt;/span&gt;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16655391" author="onyssius" created="Thu, 18 Oct 2018 15:14:13 +0000"  >&lt;p&gt;If it can help, I have created a github repo with the problematic code: &lt;a href=&quot;https://github.com/onyssius/spark-troubleshooting-bug&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/onyssius/spark-troubleshooting-bug&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Once I run the SparkBug.main() function, I can see the error mentioned in the description in the application logs (search ERROR)&lt;/p&gt;

&lt;p&gt;Note that the exception doesn&apos;t reach the main thread, but it appears in the logs&lt;/p&gt;</comment>
                            <comment id="16655418" author="mgaido" created="Thu, 18 Oct 2018 15:23:01 +0000"  >&lt;p&gt;It is interesting, I can reproduce with the Java API but not with the Scala one...&lt;/p&gt;</comment>
                            <comment id="16655428" author="onyssius" created="Thu, 18 Oct 2018 15:25:28 +0000"  >&lt;p&gt;It looks like it&apos;s not stopping the processing but I would like to make sure there is has no side effect in the data processing&lt;/p&gt;</comment>
                            <comment id="16655440" author="mgaido" created="Thu, 18 Oct 2018 15:33:22 +0000"  >&lt;p&gt;So I tracked down the issue. The problem is that you are passing a Stream as parameter for the join keys. The easy workaround is to use a Buffer instead of it.&lt;/p&gt;</comment>
                            <comment id="16655445" author="onyssius" created="Thu, 18 Oct 2018 15:36:34 +0000"  >&lt;p&gt;Please can you provide an example? I don&apos;t see any Stream in my code&lt;/p&gt;</comment>
                            <comment id="16655530" author="mgaido" created="Thu, 18 Oct 2018 16:24:51 +0000"  >&lt;p&gt;Your conversion of a Java array in a Scala Seq creates a Stream.&lt;/p&gt;</comment>
                            <comment id="16656779" author="onyssius" created="Fri, 19 Oct 2018 13:00:07 +0000"  >&lt;p&gt;I confirm that changing from &lt;b&gt;.toSeq()&lt;/b&gt; to &lt;b&gt;.toBuffer()&lt;/b&gt; in my &lt;b&gt;arrayToSeq&lt;/b&gt; function fixed the issue, thanks Marco!&lt;/p&gt;

&lt;p&gt;Is there a reason that justifies why the signature of the &lt;b&gt;join&lt;/b&gt; function is:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def join(right: Dataset[_], usingColumns: Seq[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], joinType: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): DataFrame
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and not&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def join(right: Dataset[_], usingColumns: Buffer[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;], joinType: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): DataFrame
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;since using a &lt;em&gt;scala.collection.immutable.Stream&lt;/em&gt; generates an exception ?&lt;/p&gt;</comment>
                            <comment id="16656861" author="mgaido" created="Fri, 19 Oct 2018 14:35:43 +0000"  >&lt;p&gt;I think it is a bug (thanks for reporting this): indeed I have not closed this issue because I think it needs to be addressed. I just included my analysis here in order to provide a workaround and some hint for people who might want to fix it (currently I am not sure I have the bandwidth for doing myself).&lt;/p&gt;</comment>
                            <comment id="16658393" author="petertoth" created="Sun, 21 Oct 2018 21:18:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mgaido&quot; class=&quot;user-hover&quot; rel=&quot;mgaido&quot;&gt;mgaido&lt;/a&gt;, I submitted a PR based on your analysis.&lt;/p&gt;</comment>
                            <comment id="16658395" author="apachespark" created="Sun, 21 Oct 2018 21:19:22 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22789&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22789&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16658396" author="apachespark" created="Sun, 21 Oct 2018 21:20:14 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22789&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22789&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16751605" author="apachespark" created="Thu, 24 Jan 2019 21:31:47 +0000"  >&lt;p&gt;User &apos;bersprockets&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23642&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23642&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13337398">SPARK-33260</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12944536" name="fileA.csv" size="373" author="onyssius" created="Thu, 18 Oct 2018 13:27:49 +0000"/>
                            <attachment id="12944537" name="fileB.csv" size="864" author="onyssius" created="Thu, 18 Oct 2018 13:27:49 +0000"/>
                            <attachment id="12944538" name="fileC.csv" size="86" author="onyssius" created="Thu, 18 Oct 2018 13:27:49 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 42 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3zczj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>