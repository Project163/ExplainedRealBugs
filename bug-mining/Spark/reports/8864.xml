<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:32:14 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-42250] predict_batch_udf with float fails when the batch size consists of single value</title>
                <link>https://issues.apache.org/jira/browse/SPARK-42250</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; numpy as np
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pandas as pd
from pyspark.ml.functions &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; predict_batch_udf
from pyspark.sql.types &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; ArrayType, FloatType, StructType, StructField
from typing &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; Mapping

df = spark.createDataFrame([[[0.0, 1.0, 2.0, 3.0], [0.0, 1.0, 2.0]], [[4.0, 5.0, 6.0, 7.0], [4.0, 5.0, 6.0]]], schema=[&lt;span class=&quot;code-quote&quot;&gt;&quot;t1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;t2&quot;&lt;/span&gt;])

def make_multi_sum_fn():
    def predict(x1: np.ndarray, x2: np.ndarray) -&amp;gt; np.ndarray:
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; np.sum(x1, axis=1) + np.sum(x2, axis=1)
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; predict

multi_sum_udf = predict_batch_udf(
    make_multi_sum_fn,
    return_type=FloatType(),
    batch_size=1,
    input_tensor_shapes=[[4], [3]],
)

df.select(multi_sum_udf(&lt;span class=&quot;code-quote&quot;&gt;&quot;t1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;t2&quot;&lt;/span&gt;)).collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;fails as below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/worker.py&quot;&lt;/span&gt;, line 829, in main
    process()
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/worker.py&quot;&lt;/span&gt;, line 821, in process
    serializer.dump_stream(out_iter, outfile)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/sql/pandas/serializers.py&quot;&lt;/span&gt;, line 345, in dump_stream
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; ArrowStreamSerializer.dump_stream(self, init_stream_yield_batches(), stream)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/sql/pandas/serializers.py&quot;&lt;/span&gt;, line 86, in dump_stream
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; batch in iterator:
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/sql/pandas/serializers.py&quot;&lt;/span&gt;, line 339, in init_stream_yield_batches
    batch = self._create_batch(series)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/sql/pandas/serializers.py&quot;&lt;/span&gt;, line 275, in _create_batch
    arrs.append(create_array(s, t))
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/sql/pandas/serializers.py&quot;&lt;/span&gt;, line 245, in create_array
    raise e
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/sql/pandas/serializers.py&quot;&lt;/span&gt;, line 233, in create_array
    array = pa.Array.from_pandas(s, mask=mask, type=t, safe=self._safecheck)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/array.pxi&quot;&lt;/span&gt;, line 1044, in pyarrow.lib.Array.from_pandas
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/array.pxi&quot;&lt;/span&gt;, line 316, in pyarrow.lib.array
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/array.pxi&quot;&lt;/span&gt;, line 83, in pyarrow.lib._ndarray_to_array
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyarrow/error.pxi&quot;&lt;/span&gt;, line 100, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: Could not convert array(569.) with type numpy.ndarray: tried to convert to float32

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:554)
	at org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:118)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:507)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:391)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:888)
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:888)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:328)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:139)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1520)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13522150">SPARK-42250</key>
            <summary>predict_batch_udf with float fails when the batch size consists of single value</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gurwls223">Hyukjin Kwon</assignee>
                                    <reporter username="gurwls223">Hyukjin Kwon</reporter>
                        <labels>
                    </labels>
                <created>Tue, 31 Jan 2023 03:31:59 +0000</created>
                <updated>Tue, 31 Jan 2023 10:42:21 +0000</updated>
                            <resolved>Tue, 31 Jan 2023 10:42:20 +0000</resolved>
                                    <version>3.4.0</version>
                                    <fixVersion>3.4.0</fixVersion>
                                    <component>ML</component>
                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17682368" author="apachespark" created="Tue, 31 Jan 2023 03:57:03 +0000"  >&lt;p&gt;User &apos;HyukjinKwon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39817&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39817&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17682482" author="gurwls223" created="Tue, 31 Jan 2023 10:42:21 +0000"  >&lt;p&gt;Issue resolved by pull request 39817&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39817&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39817&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 41 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1fhug:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>