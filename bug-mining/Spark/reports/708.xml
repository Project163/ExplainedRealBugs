<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:17:21 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3455] **HotFix** Unit test failed due to can not resolve the attribute references</title>
                <link>https://issues.apache.org/jira/browse/SPARK-3455</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The test case &quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-3349&quot; title=&quot;Incorrect partitioning after LIMIT operator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-3349&quot;&gt;&lt;del&gt;SPARK-3349&lt;/del&gt;&lt;/a&gt; partitioning after limit&quot; failed, the exception as :&lt;/p&gt;
&lt;div class=&quot;panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;panelContent&quot;&gt;
&lt;p&gt;23:10:04.117 ERROR org.apache.spark.scheduler.TaskSetManager: Task 0 in stage 274.0 failed 1 times; aborting job&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt; - &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-3349&quot; title=&quot;Incorrect partitioning after LIMIT operator&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-3349&quot;&gt;&lt;del&gt;SPARK-3349&lt;/del&gt;&lt;/a&gt; partitioning after limit *** FAILED ***&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Exception thrown while executing query:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   == Parsed Logical Plan ==&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Project &lt;span class=&quot;error&quot;&gt;&amp;#91;*&amp;#93;&lt;/span&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;    Join Inner, Some((&apos;subset1.n = &apos;lowerCaseData.n))&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     UnresolvedRelation None, lowerCaseData, None&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     UnresolvedRelation None, subset1, None&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   == Analyzed Logical Plan ==&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Project &lt;a href=&quot;#605,l#606,n#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#605,l#606,n#12&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;    Join Inner, Some((n#12 = n#605))&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     SparkLogicalPlan (ExistingRdd &lt;a href=&quot;#605,l#606&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#605,l#606&lt;/a&gt;, MapPartitionsRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;13&amp;#93;&lt;/span&gt; at mapPartitions at basicOperators.scala:219)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     Limit 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;      Sort &lt;a href=&quot;#12 DESC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12 DESC&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;       Distinct &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;        Project &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;         SparkLogicalPlan (ExistingRdd &lt;a href=&quot;#607,l#608&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#607,l#608&lt;/a&gt;, MapPartitionsRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;13&amp;#93;&lt;/span&gt; at mapPartitions at basicOperators.scala:219)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   == Optimized Logical Plan ==&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Project &lt;a href=&quot;#605,l#606,n#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#605,l#606,n#12&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;    Join Inner, Some((n#12 = n#605))&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     SparkLogicalPlan (ExistingRdd &lt;a href=&quot;#605,l#606&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#605,l#606&lt;/a&gt;, MapPartitionsRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;13&amp;#93;&lt;/span&gt; at mapPartitions at basicOperators.scala:219)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     Limit 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;      Sort &lt;a href=&quot;#12 DESC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12 DESC&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;       Distinct &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;        Project &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;         SparkLogicalPlan (ExistingRdd &lt;a href=&quot;#607,l#608&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#607,l#608&lt;/a&gt;, MapPartitionsRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;13&amp;#93;&lt;/span&gt; at mapPartitions at basicOperators.scala:219)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   == Physical Plan ==&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Project &lt;a href=&quot;#605,l#606,n#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#605,l#606,n#12&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;    ShuffledHashJoin &lt;a href=&quot;#605&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#605&lt;/a&gt;, &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;, BuildRight&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     Exchange (HashPartitioning &lt;a href=&quot;#605&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#605&lt;/a&gt;, 10)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;      ExistingRdd &lt;a href=&quot;#605,l#606&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#605,l#606&lt;/a&gt;, MapPartitionsRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;13&amp;#93;&lt;/span&gt; at mapPartitions at basicOperators.scala:219&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     Exchange (HashPartitioning &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;, 10)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;      TakeOrdered 2, &lt;a href=&quot;#12 DESC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12 DESC&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;       Distinct false&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;        Exchange (HashPartitioning &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;, 10)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;         Distinct true&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;          Project &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           ExistingRdd &lt;a href=&quot;#607,l#608&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#607,l#608&lt;/a&gt;, MapPartitionsRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;13&amp;#93;&lt;/span&gt; at mapPartitions at basicOperators.scala:219&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Code Generation: false&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   == RDD ==&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   == Exception ==&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Exchange (HashPartitioning &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;, 10)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;    TakeOrdered 2, &lt;a href=&quot;#12 DESC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12 DESC&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     Distinct false&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;      Exchange (HashPartitioning &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;, 10)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;       Distinct true&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;        Project &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;         ExistingRdd &lt;a href=&quot;#607,l#608&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#607,l#608&lt;/a&gt;, MapPartitionsRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;13&amp;#93;&lt;/span&gt; at mapPartitions at basicOperators.scala:219&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Exchange (HashPartitioning &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;, 10)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;    TakeOrdered 2, &lt;a href=&quot;#12 DESC&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12 DESC&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;     Distinct false&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;      Exchange (HashPartitioning &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;, 10)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;       Distinct true&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;        Project &lt;a href=&quot;#12&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#12&lt;/a&gt;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;         ExistingRdd &lt;a href=&quot;#607,l#608&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;n#607,l#608&lt;/a&gt;, MapPartitionsRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;13&amp;#93;&lt;/span&gt; at mapPartitions at basicOperators.scala:219&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:47)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.execution.Exchange.execute(Exchange.scala:44)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.execution.ShuffledHashJoin.execute(joins.scala:354)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.execution.Project.execute(basicOperators.scala:42)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:85)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.SchemaRDD.collect(SchemaRDD.scala:438)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.QueryTest.checkAnswer(QueryTest.scala:40)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.SQLQuerySuite$$anonfun$31.apply$mcV$sp(SQLQuerySuite.scala:369)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.SQLQuerySuite$$anonfun$31.apply(SQLQuerySuite.scala:362)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.SQLQuerySuite$$anonfun$31.apply(SQLQuerySuite.scala:362)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.Transformer$$anonfun$apply$1.apply(Transformer.scala:22)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.Transformer$$anonfun$apply$1.apply(Transformer.scala:22)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.Transformer.apply(Transformer.scala:22)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.Transformer.apply(Transformer.scala:20)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:158)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.Suite$class.withFixture(Suite.scala:1121)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1559)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:155)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:167)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:167)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:167)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuite.runTest(FunSuite.scala:1559)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:200)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:200)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at scala.collection.immutable.List.foreach(List.scala:318)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:200)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuite.runTests(FunSuite.scala:1559)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.Suite$class.run(Suite.scala:1423)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1559)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:204)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:204)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:204)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.SQLQuerySuite.org$scalatest$BeforeAndAfterAll$$super$run(SQLQuerySuite.scala:29)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.BeforeAndAfterAll$class.liftedTree1$1(BeforeAndAfterAll.scala:257)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.BeforeAndAfterAll$class.run(BeforeAndAfterAll.scala:256)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.sql.SQLQuerySuite.run(SQLQuerySuite.scala:29)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:444)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:651)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at sbt.ForkMain$Run$2.call(ForkMain.java:294)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at sbt.ForkMain$Run$2.call(ForkMain.java:284)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at java.util.concurrent.FutureTask.run(FutureTask.java:262)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 274.0 failed 1 times, most recent failure: Lost task 0.0 in stage 274.0 (TID 911, localhost): org.apache.spark.sql.catalyst.errors.package$TreeNodeException: Binding attribute, tree: n#12&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:47)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:47)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:46)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:144)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:135)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:46)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection$$anonfun$$init$$2.apply(Projection.scala:52)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection$$anonfun$$init$$2.apply(Projection.scala:52)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           scala.collection.immutable.List.foreach(List.scala:318)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           scala.collection.TraversableLike$class.map(TraversableLike.scala:244)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           scala.collection.AbstractTraversable.map(Traversable.scala:105)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.&amp;lt;init&amp;gt;(Projection.scala:52)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.execution.SparkPlan$$anonfun$newMutableProjection$1.apply(SparkPlan.scala:106)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.execution.SparkPlan$$anonfun$newMutableProjection$1.apply(SparkPlan.scala:106)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.execution.Project$$anonfun$1.apply(basicOperators.scala:43)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.sql.execution.Project$$anonfun$1.apply(basicOperators.scala:42)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:596)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.scheduler.Task.run(Task.scala:54)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;           java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   Driver stacktrace:&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1185)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1174)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1173)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1173)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:688)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:688)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at scala.Option.foreach(Option.scala:236)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:688)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1391)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at akka.actor.ActorCell.invoke(ActorCell.scala:456)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at akka.dispatch.Mailbox.run(Mailbox.scala:219)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;info&amp;#93;&lt;/span&gt;   	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) (QueryTest.scala:42)&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12740114">SPARK-3455</key>
            <summary>**HotFix** Unit test failed due to can not resolve the attribute references</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="chenghao">Cheng Hao</reporter>
                        <labels>
                    </labels>
                <created>Tue, 9 Sep 2014 11:34:47 +0000</created>
                <updated>Sat, 13 Sep 2014 06:03:45 +0000</updated>
                            <resolved>Sat, 13 Sep 2014 06:03:45 +0000</resolved>
                                                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="14126909" author="apachespark" created="Tue, 9 Sep 2014 11:48:08 +0000"  >&lt;p&gt;User &apos;chenghao-intel&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2334&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2334&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 11 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1ztxr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>