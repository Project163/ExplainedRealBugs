<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:00:32 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-24739] PySpark does not work with Python 3.7.0</title>
                <link>https://issues.apache.org/jira/browse/SPARK-24739</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Python 3.7 is released in few days ago and our PySpark does not work. For example&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
sc.parallelize([1, 2]).take(1)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 1343, in __main__.RDD.take
Failed example:
    sc.parallelize(range(100), 100).filter(lambda x: x &amp;gt; 90).take(3)
Exception raised:
    Traceback (most recent call last):
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../3.7/lib/python3.7/doctest.py&quot;&lt;/span&gt;, line 1329, in __run
        compileflags, 1), test.globs)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;&amp;lt;doctest __main__.RDD.take[2]&amp;gt;&quot;&lt;/span&gt;, line 1, in &amp;lt;module&amp;gt;
        sc.parallelize(range(100), 100).filter(lambda x: x &amp;gt; 90).take(3)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 1377, in take
        res = self.context.runJob(self, takeUpToNumLeft, p)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/pyspark/context.py&quot;&lt;/span&gt;, line 1013, in runJob
        sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py&quot;&lt;/span&gt;, line 1257, in __call__
        answer, self.gateway_client, self.target_id, self.name)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py&quot;&lt;/span&gt;, line 328, in get_return_value
        format(target_id, &lt;span class=&quot;code-quote&quot;&gt;&quot;.&quot;&lt;/span&gt;, name), value)
    py4j.protocol.Py4JJavaError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling z:org.apache.spark.api.python.PythonRDD.runJob.
    : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 143.0 failed 1 times, most recent failure: Lost task 0.0 in stage 143.0 (TID 688, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 1373, in takeUpToNumLeft
        yield next(iterator)
    StopIteration

    The above exception was the direct cause of the following exception:

    Traceback (most recent call last):
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/worker.py&quot;&lt;/span&gt;, line 320, in main
        process()
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/worker.py&quot;&lt;/span&gt;, line 315, in process
        serializer.dump_stream(func(split_index, iterator), outfile)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/serializers.py&quot;&lt;/span&gt;, line 378, in dump_stream
        vs = list(itertools.islice(iterator, batch))
    RuntimeError: generator raised StopIteration

    	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:309)
    	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:449)
    	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:432)
    	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:263)
    	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
    	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:891)
    	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
    	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:59)
    	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
    	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
    	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:310)
    	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
    	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:302)
    	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
    	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:289)
    	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
    	at org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)
    	at org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)
    	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2071)
    	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2071)
    	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
    	at org.apache.spark.scheduler.Task.run(Task.scala:109)
    	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
    	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)

    Driver stacktrace:
    	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1607)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1595)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1594)
    	at scala.collection.mutable.ResizableArray$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(ResizableArray.scala:59)
    	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
    	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1594)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
    	at scala.Option.foreach(Option.scala:257)
    	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1828)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1777)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1766)
    	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
    	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2031)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2052)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2071)
    	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:149)
    	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.lang.reflect.Method.invoke(Method.java:498)
    	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    	at py4j.Gateway.invoke(Gateway.java:282)
    	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    	at py4j.GatewayConnection.run(GatewayConnection.java:238)
    	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
    Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 1373, in takeUpToNumLeft
        yield next(iterator)
    StopIteration

    The above exception was the direct cause of the following exception:

    Traceback (most recent call last):
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/worker.py&quot;&lt;/span&gt;, line 320, in main
        process()
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/worker.py&quot;&lt;/span&gt;, line 315, in process
        serializer.dump_stream(func(split_index, iterator), outfile)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/.../spark/python/lib/pyspark.zip/pyspark/serializers.py&quot;&lt;/span&gt;, line 378, in dump_stream
        vs = list(itertools.islice(iterator, batch))
    RuntimeError: generator raised StopIteration

    	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:309)
    	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:449)
    	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:432)
    	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:263)
    	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
    	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:891)
    	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
    	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:59)
    	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
    	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
    	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:310)
    	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
    	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:302)
    	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
    	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:289)
    	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
    	at org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)
    	at org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:149)
    	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2071)
    	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2071)
    	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
    	at org.apache.spark.scheduler.Task.run(Task.scala:109)
    	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:367)
    	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    	... 1 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Should check the behaviour changes or bugs in Python and PySpark.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13170077">SPARK-24739</key>
            <summary>PySpark does not work with Python 3.7.0</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gurwls223">Hyukjin Kwon</assignee>
                                    <reporter username="gurwls223">Hyukjin Kwon</reporter>
                        <labels>
                    </labels>
                <created>Wed, 4 Jul 2018 13:47:02 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:41 +0000</updated>
                            <resolved>Sat, 7 Jul 2018 03:38:32 +0000</resolved>
                                    <version>2.1.3</version>
                    <version>2.2.2</version>
                    <version>2.3.1</version>
                                    <fixVersion>2.3.2</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16532771" author="gurwls223" created="Wed, 4 Jul 2018 13:47:22 +0000"  >&lt;p&gt;I am working on this.&lt;/p&gt;</comment>
                            <comment id="16532912" author="apachespark" created="Wed, 4 Jul 2018 16:05:06 +0000"  >&lt;p&gt;User &apos;HyukjinKwon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21714&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21714&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16533189" author="jerryshao" created="Thu, 5 Jul 2018 02:23:52 +0000"  >&lt;p&gt;Do we have to fix it in 2.3.2? I don&apos;t think it is even critical. For example Java 9 is out for a long time, but we still don&apos;t support Java 9. So this seems not a big problem.&#160;&lt;/p&gt;</comment>
                            <comment id="16533191" author="gurwls223" created="Thu, 5 Jul 2018 02:26:29 +0000"  >&lt;p&gt;For this fix particularly, the fix is small and safe. In case of &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-19019&quot; title=&quot;PySpark does not work with Python 3.6.0&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-19019&quot;&gt;&lt;del&gt;SPARK-19019&lt;/del&gt;&lt;/a&gt;, it was merged to from 1.6, 2.0, 2.1 and 2.2. I expect the similar situation with this JIRA&apos;s case with many stackoverflow questions.&lt;/p&gt;</comment>
                            <comment id="16535599" author="gurwls223" created="Sat, 7 Jul 2018 03:38:32 +0000"  >&lt;p&gt;Issue resolved by pull request 21714&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21714&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21714&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 19 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3vjkn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12343289">2.3.2</customfieldvalue>
    <customfieldvalue id="12342385">2.4.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>