<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:47:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17673] Reused Exchange Aggregations Produce Incorrect Results</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17673</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://datastax-oss.atlassian.net/browse/SPARKC-429&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://datastax-oss.atlassian.net/browse/SPARKC-429&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Was brought to my attention where the following code produces incorrect results&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; val data = List(TestData(&lt;span class=&quot;code-quote&quot;&gt;&quot;A&quot;&lt;/span&gt;, 1, 7))
    val frame = session.sqlContext.createDataFrame(session.sparkContext.parallelize(data))

    frame.createCassandraTable(
      keySpaceName,
      table,
      partitionKeyColumns = Some(Seq(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;)))

    frame
      .write
      .format(&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.spark.sql.cassandra&quot;&lt;/span&gt;)
      .mode(SaveMode.Append)
      .options(Map(&lt;span class=&quot;code-quote&quot;&gt;&quot;table&quot;&lt;/span&gt; -&amp;gt; table, &lt;span class=&quot;code-quote&quot;&gt;&quot;keyspace&quot;&lt;/span&gt; -&amp;gt; keySpaceName))
      .save()

val loaded = sparkSession.sqlContext
  .read
  .format(&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.spark.sql.cassandra&quot;&lt;/span&gt;)
  .options(Map(&lt;span class=&quot;code-quote&quot;&gt;&quot;table&quot;&lt;/span&gt; -&amp;gt; table, &lt;span class=&quot;code-quote&quot;&gt;&quot;keyspace&quot;&lt;/span&gt; -&amp;gt; ks))
  .load()
  .select(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;col2&quot;&lt;/span&gt;)
val min1 = loaded.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).agg(min(&lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;min&quot;&lt;/span&gt;))
val min2 = loaded.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).agg(min(&lt;span class=&quot;code-quote&quot;&gt;&quot;col2&quot;&lt;/span&gt;).as(&lt;span class=&quot;code-quote&quot;&gt;&quot;min&quot;&lt;/span&gt;))
 min1.union(min2).show()
    /* prints:
      +---+---+
      | id|min|
      +---+---+
      |  A|  1|
      |  A|  1|
      +---+---+
     Should be 
      | A| 1|
      | A| 7|
     */
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I looked into the explain pattern and saw &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Union
:- *HashAggregate(keys=[id#93], functions=[min(col1#94)])
:  +- Exchange hashpartitioning(id#93, 200)
:     +- *HashAggregate(keys=[id#93], functions=[partial_min(col1#94)])
:        +- *Scan org.apache.spark.sql.cassandra.CassandraSourceRelation@7ec20844 [id#93,col1#94]
+- *HashAggregate(keys=[id#93], functions=[min(col2#95)])
   +- ReusedExchange [id#93, min#153], Exchange hashpartitioning(id#93, 200)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which was different than using a parallelized collection as the DF backing. So I tested the same code with a Parquet backed DF and saw the same results.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    frame.write.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;garbagetest&quot;&lt;/span&gt;)
    val parquet = sparkSession.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;garbagetest&quot;&lt;/span&gt;).select(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;col2&quot;&lt;/span&gt;)
    println(&lt;span class=&quot;code-quote&quot;&gt;&quot;PDF&quot;&lt;/span&gt;)
    parquetmin1.union(parquetmin2).explain()
    parquetmin1.union(parquetmin2).show()
    /* prints:
      +---+---+
      | id|min|
      +---+---+
      |  A|  1|
      |  A|  1|
      +---+---+
*/
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which leads me to believe there is something wrong with the reused exchange. &lt;/p&gt;</description>
                <environment></environment>
        <key id="13007762">SPARK-17673</key>
            <summary>Reused Exchange Aggregations Produce Incorrect Results</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ekhliang">Eric Liang</assignee>
                                    <reporter username="rspitzer">Russell Spitzer</reporter>
                        <labels>
                            <label>correctness</label>
                    </labels>
                <created>Mon, 26 Sep 2016 23:42:37 +0000</created>
                <updated>Wed, 28 Sep 2016 23:44:50 +0000</updated>
                            <resolved>Wed, 28 Sep 2016 20:23:34 +0000</resolved>
                                    <version>2.0.0</version>
                    <version>2.0.1</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="15524581" author="hvanhovell" created="Tue, 27 Sep 2016 00:15:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rspitzer&quot; class=&quot;user-hover&quot; rel=&quot;rspitzer&quot;&gt;rspitzer&lt;/a&gt; Are you using Spark 2.0 or the latest master?&lt;/p&gt;</comment>
                            <comment id="15524641" author="rspitzer" created="Tue, 27 Sep 2016 00:42:51 +0000"  >&lt;p&gt;I only ran this on 2.0.0 and 2.0.1&lt;/p&gt;</comment>
                            <comment id="15524687" author="rxin" created="Tue, 27 Sep 2016 01:12:33 +0000"  >&lt;p&gt;Can you help create a repro (without the need to connect Cassandra)?&lt;/p&gt;</comment>
                            <comment id="15524722" author="rspitzer" created="Tue, 27 Sep 2016 01:30:54 +0000"  >&lt;p&gt;Ugh I made a typo in my Parquet Example I don&apos;t see it repoing there now. Let me run investigate a little more as to why this would affect the C* Source...&lt;/p&gt;</comment>
                            <comment id="15524725" author="rxin" created="Tue, 27 Sep 2016 01:32:54 +0000"  >&lt;p&gt;It&apos;s possible if hashCode and equals are not defined properly in the Cassandra data source.&lt;/p&gt;</comment>
                            <comment id="15524734" author="rspitzer" created="Tue, 27 Sep 2016 01:37:34 +0000"  >&lt;p&gt;Well in this case they are equal correct? We are using the same Dataframe with two different aggregation steps.&lt;/p&gt;

&lt;p&gt;The Parquet example doesn&apos;t end up using the reusedExchange. It does the same plan as the parallelized one&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;PDF
== Physical Plan ==
Union
:- *HashAggregate(keys=[id#112], functions=[min(col1#113)])
:  +- Exchange hashpartitioning(id#112, 200)
:     +- *HashAggregate(keys=[id#112], functions=[partial_min(col1#113)])
:        +- *BatchedScan parquet [id#112,col1#113] Format: ParquetFormat, InputPaths: file:/Users/russellspitzer/repos/spark-cassandra-connector/&#43006;&#47859;&#16142;&#40609;&#19496;&#53974;&#12759;&#3944;&#5034;&#36140;, PartitionFilters: [], PushedFilters: [], ReadSchema: struct&amp;lt;id:string,col1:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&amp;gt;
+- *HashAggregate(keys=[id#112], functions=[min(col2#114)])
   +- Exchange hashpartitioning(id#112, 200)
      +- *HashAggregate(keys=[id#112], functions=[partial_min(col2#114)])
         +- *BatchedScan parquet [id#112,col2#114] Format: ParquetFormat, InputPaths: file:/Users/russellspitzer/repos/spark-cassandra-connector/&#43006;&#47859;&#16142;&#40609;&#19496;&#53974;&#12759;&#3944;&#5034;&#36140;, PartitionFilters: [], PushedFilters: [], ReadSchema: struct&amp;lt;id:string,col2:&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15524848" author="rspitzer" created="Tue, 27 Sep 2016 02:43:53 +0000"  >&lt;p&gt;I couldn&apos;t get this to happen without C*, hopefully tomorrow I can get some guidance tomorrow :/ It could be a hashcode / equals thing but we don&apos;t override those in the base class. Also i&apos;m a little confused because this should be the same &quot;grouping&quot; operation on the RDD just with a different aggregate. I don&apos;t know enough about the ReusedExchange to know when it&apos;s applied and why.&lt;/p&gt;</comment>
                            <comment id="15524993" author="hvanhovell" created="Tue, 27 Sep 2016 04:06:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rspitzer&quot; class=&quot;user-hover&quot; rel=&quot;rspitzer&quot;&gt;rspitzer&lt;/a&gt; we only reuse an exchange when they produce the same result. You can find the implementation for row datasource scans (what you are probably using) here &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/DataSourceScanExec.scala#L124-L128&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/DataSourceScanExec.scala#L124-L128&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have taken a look at the cassandra datasource code, but that does not seem to implement equals at all and should not cause a problem. Do you cache instances of CassandraRelation at some point?&lt;/p&gt;</comment>
                            <comment id="15524999" author="rspitzer" created="Tue, 27 Sep 2016 04:08:43 +0000"  >&lt;p&gt;We shouldn&apos;t be ... The only thing we cache are underlying database connections and queries which shouldn&apos;t factor into this I would think :/&lt;/p&gt;</comment>
                            <comment id="15525000" author="rxin" created="Tue, 27 Sep 2016 04:09:33 +0000"  >&lt;p&gt;RowDataSourceScanExec.sameResult is probably the problem:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-comment&quot;&gt;// Ignore rdd when checking results
&lt;/span&gt;  override def sameResult(plan: SparkPlan): &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = plan match {
    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; other: RowDataSourceScanExec =&amp;gt; relation == other.relation &amp;amp;&amp;amp; metadata == other.metadata
    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;First glance &amp;#8211; it looks like it ignores predicate pushdown or column pruning entirely.&lt;/p&gt;</comment>
                            <comment id="15525007" author="rspitzer" created="Tue, 27 Sep 2016 04:12:14 +0000"  >&lt;p&gt;Looking at this plan &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;```
Union
:- *HashAggregate(keys=[id#93], functions=[min(col1#94)])
:  +- Exchange hashpartitioning(id#93, 200)
:     +- *HashAggregate(keys=[id#93], functions=[partial_min(col1#94)])
:        +- *Scan org.apache.spark.sql.cassandra.CassandraSourceRelation@7ec20844 [id#93,col1#94]
+- *HashAggregate(keys=[id#93], functions=[min(col2#95)])
   +- ReusedExchange [id#93, min#153], Exchange hashpartitioning(id#93, 200)```
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I see it reuses the hash aggregate from the partial min on col1 even though the hash aggregate that runs it does min col2. Am I reading that right? The column names don&apos;t even match so I&apos;m confused how that gets through?&lt;/p&gt;</comment>
                            <comment id="15525011" author="rxin" created="Tue, 27 Sep 2016 04:14:39 +0000"  >&lt;p&gt;The only thing differentiating the two sides of the plan is column pruning right? It is possible the issue I mentioned earlier is the culprit.&lt;/p&gt;</comment>
                            <comment id="15525036" author="hvanhovell" created="Tue, 27 Sep 2016 04:31:36 +0000"  >&lt;p&gt;Could you also share the optimized plan &lt;tt&gt;df.explain(true)&lt;/tt&gt;? I am wondering if the attributes are the same.&lt;/p&gt;</comment>
                            <comment id="15525096" author="rspitzer" created="Tue, 27 Sep 2016 05:12:30 +0000"  >&lt;p&gt;Ah yeah there would definitely be different pruning in both &quot;source&quot;s  Getting the optimized plan now&lt;/p&gt;</comment>
                            <comment id="15525101" author="rspitzer" created="Tue, 27 Sep 2016 05:16:19 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;== Parsed Logical Plan ==
Union
:- Aggregate [id#101], [id#101, min(col1#102) AS min#128]
:  +- Project [id#101, col1#102, col2#103]
:     +- Relation[id#101,col1#102,col2#103] org.apache.spark.sql.cassandra.CassandraSourceRelation@486a9118
+- Aggregate [id#101], [id#101, min(col2#103) AS min#137]
   +- Project [id#101, col1#102, col2#103]
      +- Relation[id#101,col1#102,col2#103] org.apache.spark.sql.cassandra.CassandraSourceRelation@486a9118

== Analyzed Logical Plan ==
id: string, min: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;
Union
:- Aggregate [id#101], [id#101, min(col1#102) AS min#128]
:  +- Project [id#101, col1#102, col2#103]
:     +- Relation[id#101,col1#102,col2#103] org.apache.spark.sql.cassandra.CassandraSourceRelation@486a9118
+- Aggregate [id#101], [id#101, min(col2#103) AS min#137]
   +- Project [id#101, col1#102, col2#103]
      +- Relation[id#101,col1#102,col2#103] org.apache.spark.sql.cassandra.CassandraSourceRelation@486a9118

== Optimized Logical Plan ==
Union
:- Aggregate [id#101], [id#101, min(col1#102) AS min#128]
:  +- Project [id#101, col1#102]
:     +- Relation[id#101,col1#102,col2#103] org.apache.spark.sql.cassandra.CassandraSourceRelation@486a9118
+- Aggregate [id#101], [id#101, min(col2#103) AS min#137]
   +- Project [id#101, col2#103]
      +- Relation[id#101,col1#102,col2#103] org.apache.spark.sql.cassandra.CassandraSourceRelation@486a9118

== Physical Plan ==
Union
:- *HashAggregate(keys=[id#101], functions=[min(col1#102)], output=[id#101, min#128])
:  +- Exchange hashpartitioning(id#101, 200)
:     +- *HashAggregate(keys=[id#101], functions=[partial_min(col1#102)], output=[id#101, min#182])
:        +- *Scan org.apache.spark.sql.cassandra.CassandraSourceRelation@486a9118 [id#101,col1#102]
+- *HashAggregate(keys=[id#101], functions=[min(col2#103)], output=[id#101, min#137])
   +- ReusedExchange [id#101, min#190], Exchange hashpartitioning(id#101, 200)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So the relations do look exactly the same (even though they are not) in the optimized plan&lt;/p&gt;</comment>
                            <comment id="15527327" author="rxin" created="Tue, 27 Sep 2016 20:31:41 +0000"  >&lt;p&gt;I&apos;m upgrading this to a blocker level issue.&lt;/p&gt;</comment>
                            <comment id="15527339" author="ekhliang" created="Tue, 27 Sep 2016 20:34:49 +0000"  >&lt;p&gt;I&apos;m looking at this now.&lt;/p&gt;</comment>
                            <comment id="15528142" author="apachespark" created="Wed, 28 Sep 2016 02:23:05 +0000"  >&lt;p&gt;User &apos;ericl&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15273&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15273&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15528145" author="ekhliang" created="Wed, 28 Sep 2016 02:24:43 +0000"  >&lt;p&gt;Russell, could you try applying this patch (wip) to see if it resolves the issue? &lt;a href=&quot;https://github.com/apache/spark/pull/15273/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15273/files&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It fixes equality comparison for row datasource scans to take into account the output schema of the scan.&lt;/p&gt;</comment>
                            <comment id="15530769" author="rxin" created="Wed, 28 Sep 2016 20:24:09 +0000"  >&lt;p&gt;I merged this in master. There was a conflict with branch-2.0.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ekhliang&quot; class=&quot;user-hover&quot; rel=&quot;ekhliang&quot;&gt;ekhliang&lt;/a&gt; can you submit a pr for 2.0?&lt;/p&gt;</comment>
                            <comment id="15530797" author="apachespark" created="Wed, 28 Sep 2016 20:35:09 +0000"  >&lt;p&gt;User &apos;ericl&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15282&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15282&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15531265" author="rspitzer" created="Wed, 28 Sep 2016 23:44:50 +0000"  >&lt;p&gt;Looks good on my end&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt;     min2.union(min1).show()
+---+---+
| id|min|
+---+---+
|  A|  7|
|  A|  1|
+---+---+


scala&amp;gt;     min1.union(min2).show()
+---+---+
| id|min|
+---+---+
|  A|  1|
|  A|  7|
+---+---+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 7 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3440n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>