<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:47:53 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17549] InMemoryRelation doesn&apos;t scale to large tables</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17549</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;An &lt;tt&gt;InMemoryRelation&lt;/tt&gt; is created when you cache a table; but if the table is large, defined by either having a really large amount of columns, or a really large amount of partitions (in the file split sense, not the &quot;table partition&quot; sense), or both, it causes an immense amount of memory to be used in the driver.&lt;/p&gt;

&lt;p&gt;The reason is that it uses an accumulator to collect statistics about each partition, and instead of summarizing the data in the driver, it keeps &lt;b&gt;all&lt;/b&gt; entries in memory.&lt;/p&gt;

&lt;p&gt;I&apos;m attaching a script I used to create a parquet file with 20,000 columns and a single row, which I then copied 500 times so I&apos;d have 500 partitions.&lt;/p&gt;

&lt;p&gt;When doing the following:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sqlContext.read.parquet(...).count()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Everything works fine, both in Spark 1.6 and 2.0. (It&apos;s super slow with the settings I used, but it works.)&lt;/p&gt;

&lt;p&gt;I ran spark-shell like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;./bin/spark-shell --master &lt;span class=&quot;code-quote&quot;&gt;&apos;local-cluster[4,1,4096]&apos;&lt;/span&gt; --driver-memory 2g --conf spark.executor.memory=2g
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And ran:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sqlContext.read.parquet(...).cache().count()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You&apos;ll see the results in screenshot &lt;tt&gt;example_1.6_pre_patch.png&lt;/tt&gt;. After 40 partitions were processed, there were 40 GenericInternalRow objects with&lt;br/&gt;
100,000 items each (5 stat info fields * 20,000 columns). So, memory usage was:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  40 * 100000 * (4 * 20 + 24) = 416000000 =~ 400MB
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(Note: Integer = 20 bytes, Long = 24 bytes.)&lt;/p&gt;

&lt;p&gt;If I waited until the end, there would be 500 partitions, so ~ 5GB of memory to hold the stats.&lt;/p&gt;


&lt;p&gt;I&apos;m also attaching a patch I made on top of 1.6 that uses just a long accumulator to capture the table size; with that patch memory usage on the driver doesn&apos;t keep growing. Also note in the patch that I&apos;m multiplying the column size by the row count, which I think is a different bug in the existing code (those stats should be for the whole batch, not just a single row, right?). I also added &lt;tt&gt;example_1.6_post_patch.png&lt;/tt&gt; to show the &lt;tt&gt;InMemoryRelation&lt;/tt&gt; with the patch.&lt;/p&gt;


&lt;p&gt;I also applied a very similar patch on top of Spark 2.0. But there things blow up even more spectacularly when I try to run the count on the cached table. It starts with this error:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;14:19:43 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 1.0 (TID 2, vanzin-st1-3.gce.cloudera.com): java.util.concurrent.ExecutionException: java.lang.Exception: failed to compile: java.lang.IndexOutOfBoundsException: Index: 63235, Size: 1
(lots of generated code here...)
Caused by: java.lang.IndexOutOfBoundsException: Index: 63235, Size: 1
	at java.util.ArrayList.rangeCheck(ArrayList.java:635)
	at java.util.ArrayList.get(ArrayList.java:411)
	at org.codehaus.janino.util.ClassFile.getConstantPoolInfo(ClassFile.java:556)
	at org.codehaus.janino.util.ClassFile.getConstantUtf8(ClassFile.java:572)
	at org.codehaus.janino.util.ClassFile.loadAttribute(ClassFile.java:1513)
	at org.codehaus.janino.util.ClassFile.loadAttributes(ClassFile.java:644)
	at org.codehaus.janino.util.ClassFile.loadFields(ClassFile.java:623)
	at org.codehaus.janino.util.ClassFile.&amp;lt;init&amp;gt;(ClassFile.java:280)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1.apply(CodeGenerator.scala:913)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$$anonfun$recordCompilationStats$1.apply(CodeGenerator.scala:911)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.recordCompilationStats(CodeGenerator.scala:911)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator$.org$apache$spark$sql$catalyst$expressions$codegen$CodeGenerator$$doCompile(CodeGenerator.scala:883)
	... 54 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And basically a lot of that going on making the output unreadable, so I just killed the shell. Anyway, I believe the same fix should work there, but I can&apos;t be sure because the test doesn&apos;t work for different reasons, it seems.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13005028">SPARK-17549</key>
            <summary>InMemoryRelation doesn&apos;t scale to large tables</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vanzin">Marcelo Masiero Vanzin</assignee>
                                    <reporter username="vanzin">Marcelo Masiero Vanzin</reporter>
                        <labels>
                    </labels>
                <created>Wed, 14 Sep 2016 23:29:05 +0000</created>
                <updated>Tue, 4 Oct 2016 16:40:50 +0000</updated>
                            <resolved>Tue, 4 Oct 2016 16:40:49 +0000</resolved>
                                    <version>1.6.0</version>
                    <version>2.0.0</version>
                                    <fixVersion>2.0.2</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15491793" author="vanzin" created="Wed, 14 Sep 2016 23:48:12 +0000"  >&lt;p&gt;Just noticed there&apos;s already a more accurate count of the batch size in the code, so uploading an updated patch.&lt;/p&gt;

&lt;p&gt;I&apos;ll try to figure out what&apos;s wrong in Spark 2 but not really familiar with that area of the code where the exceptions are coming from.&lt;/p&gt;</comment>
                            <comment id="15491834" author="vanzin" created="Thu, 15 Sep 2016 00:06:16 +0000"  >&lt;p&gt;Attaching a Spark 2 patch that silences the error (looks like a Janino bug and is in an area that should not affect functionality from what I understand).&lt;/p&gt;

&lt;p&gt;It&apos;d be great if someone more familiar with this area could take a look at whether my changes are sane, before I go out and file a PR.&lt;/p&gt;</comment>
                            <comment id="15493929" author="apachespark" created="Thu, 15 Sep 2016 16:58:36 +0000"  >&lt;p&gt;User &apos;vanzin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15112&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15112&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15497357" author="yhuai" created="Fri, 16 Sep 2016 21:03:35 +0000"  >&lt;p&gt;Issue resolved by pull request 15112&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15112&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15112&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15504950" author="vanzin" created="Mon, 19 Sep 2016 22:59:40 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;yhuai&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There was something that was bothering me about my fix and the test below (modified version of the test in the patch) shows it:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  test(&lt;span class=&quot;code-quote&quot;&gt;&quot;SPARK-17549: cached table size should be correctly calculated&quot;&lt;/span&gt;) {
    val data = spark.sparkContext.parallelize(1 to 10, 5).map { i =&amp;gt; (i, i) }.toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;col2&quot;&lt;/span&gt;)
    val plan = spark.sessionState.executePlan(data.logicalPlan).sparkPlan
    val cached = InMemoryRelation(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 5, MEMORY_ONLY, plan, None)

    &lt;span class=&quot;code-comment&quot;&gt;// Materialize the data.
&lt;/span&gt;    val expectedAnswer = data.collect()
    checkAnswer(cached, expectedAnswer)

    &lt;span class=&quot;code-comment&quot;&gt;// Check that the right size was calculated.
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt;(cached.batchStats.value === 2 * expectedAnswer.size * INT.defaultSize)

    &lt;span class=&quot;code-comment&quot;&gt;// Create a projection of the cached data and make sure the statistics are kept correctly
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; each plan.
&lt;/span&gt;    val projected = cached.withOutput(Seq(plan.output.head))
    val expectedAnswer2 = data.select(&lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;).collect()
    checkAnswer(projected, expectedAnswer2)
    &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt;(projected.batchStats.value === expectedAnswer.size * INT.defaultSize)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Basically, my patch has a problem in that now any relations derived from the cached data (both &lt;tt&gt;newInstance&lt;/tt&gt; and &lt;tt&gt;withOutput&lt;/tt&gt; methods of &lt;tt&gt;InMemoryRelation&lt;/tt&gt;) share the same accumulator with the original instance. So if the original table is materialized before those transformations occur, there will be a problem. I&apos;m also not sure how to fix that - going back to the original code is bad; the other option I see is calculating the stats for the new instance by transforming the cached RDD, but that&apos;s kinda wasteful (will cause unnecessary tasks to be executed, and will waste cache memory by caching the same blocks twice).&lt;/p&gt;

&lt;p&gt;But that assumes that I understand the problem properly; since I&apos;m not that familiar with the SQL code, could you confirm whether the above is a problem or not?&lt;/p&gt;</comment>
                            <comment id="15505060" author="vanzin" created="Mon, 19 Sep 2016 23:47:21 +0000"  >&lt;p&gt;Replying to myself: yes, this seems to be a real problem. If you cache some transformation on a cached relation, that will trigger the &quot;withOutput&quot; path, and the stats for the new cached relation will be wrong (they&apos;ll be the same as the original cached relation), even though the output is different.&lt;/p&gt;

&lt;p&gt;So either we should revert my patch, or make another small patch on top of it to use default stats for these child tables, unless someone has some idea of how to properly fix this.&lt;/p&gt;

&lt;p&gt;Pinging &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt; here also in case he has some ideas.&lt;/p&gt;</comment>
                            <comment id="15505404" author="yhuai" created="Tue, 20 Sep 2016 02:56:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt; Let&apos;s revert this patch for now. So, this part will be the same as 2.0.0. Then, we can see how to fix the problem.&lt;/p&gt;</comment>
                            <comment id="15505409" author="apachespark" created="Tue, 20 Sep 2016 03:00:05 +0000"  >&lt;p&gt;User &apos;yhuai&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15157&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15157&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15505411" author="yhuai" created="Tue, 20 Sep 2016 03:00:29 +0000"  >&lt;p&gt;Forgot to say. Thank you for the investigation! Should we first get a test in to prevent the issue of having wrong stats?&lt;/p&gt;</comment>
                            <comment id="15506949" author="vanzin" created="Tue, 20 Sep 2016 15:56:13 +0000"  >&lt;p&gt;Wouldn&apos;t hurt.&lt;/p&gt;</comment>
                            <comment id="15507440" author="yhuai" created="Tue, 20 Sep 2016 18:55:46 +0000"  >&lt;p&gt;I have merged it to revert the original change.&lt;/p&gt;</comment>
                            <comment id="15511459" author="apachespark" created="Wed, 21 Sep 2016 22:59:04 +0000"  >&lt;p&gt;User &apos;vanzin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15189&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15189&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15528029" author="dongjoon" created="Wed, 28 Sep 2016 01:28:51 +0000"  >&lt;p&gt;Hi, All.&lt;br/&gt;
Could we add this into RC4 or remove `2.0.1` from the fixed version?&lt;br/&gt;
I just noticed that this was shown in RC3 VOTE email.&lt;/p&gt;

&lt;p&gt;&amp;gt; This release candidate resolves 290 issues:&lt;br/&gt;
&amp;gt; &lt;a href=&quot;https://s.apache.org/spark-2.0.1-jira&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://s.apache.org/spark-2.0.1-jira&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15528035" author="vanzin" created="Wed, 28 Sep 2016 01:31:33 +0000"  >&lt;p&gt;Done. Forgot to update the bug after the patch was reverted.&lt;/p&gt;</comment>
                            <comment id="15528040" author="dongjoon" created="Wed, 28 Sep 2016 01:33:32 +0000"  >&lt;p&gt;Thank you, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="15534135" author="apachespark" created="Thu, 29 Sep 2016 21:40:24 +0000"  >&lt;p&gt;User &apos;vanzin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15304&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15304&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12828543" name="create_parquet.scala" size="1521" author="vanzin" created="Wed, 14 Sep 2016 23:29:47 +0000"/>
                            <attachment id="12828544" name="example_1.6_post_patch.png" size="50510" author="vanzin" created="Wed, 14 Sep 2016 23:29:47 +0000"/>
                            <attachment id="12828545" name="example_1.6_pre_patch.png" size="51518" author="vanzin" created="Wed, 14 Sep 2016 23:29:47 +0000"/>
                            <attachment id="12828549" name="spark-1.6-2.patch" size="3394" author="vanzin" created="Wed, 14 Sep 2016 23:48:12 +0000"/>
                            <attachment id="12828546" name="spark-1.6.patch" size="3523" author="vanzin" created="Wed, 14 Sep 2016 23:29:47 +0000"/>
                            <attachment id="12828554" name="spark-2.0.patch" size="4704" author="vanzin" created="Thu, 15 Sep 2016 00:06:16 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>6.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 7 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i33n6v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>