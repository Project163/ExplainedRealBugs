<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:13:21 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-1556] jets3t dep doesn&apos;t update properly with newer Hadoop versions</title>
                <link>https://issues.apache.org/jira/browse/SPARK-1556</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;In Hadoop 2.2.x or newer, Jet3st 0.9.0 which defines S3ServiceException/ServiceException is introduced, however, Spark still relies on Jet3st 0.7.x which has no definition of these classes&lt;/p&gt;

&lt;p&gt;What I met is that &lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;code&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;14/04/21 19:30:53 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id&lt;br/&gt;
14/04/21 19:30:53 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id&lt;br/&gt;
14/04/21 19:30:53 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id&lt;br/&gt;
14/04/21 19:30:53 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap&lt;br/&gt;
14/04/21 19:30:53 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition&lt;br/&gt;
java.lang.NoClassDefFoundError: org/jets3t/service/S3ServiceException&lt;br/&gt;
	at org.apache.hadoop.fs.s3native.NativeS3FileSystem.createDefaultStore(NativeS3FileSystem.java:280)&lt;br/&gt;
	at org.apache.hadoop.fs.s3native.NativeS3FileSystem.initialize(NativeS3FileSystem.java:270)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2316)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:90)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2350)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2332)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:369)&lt;br/&gt;
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)&lt;br/&gt;
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:221)&lt;br/&gt;
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:270)&lt;br/&gt;
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:140)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)&lt;br/&gt;
	at scala.Option.getOrElse(Option.scala:120)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)&lt;br/&gt;
	at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)&lt;br/&gt;
	at scala.Option.getOrElse(Option.scala:120)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)&lt;br/&gt;
	at org.apache.spark.rdd.MappedRDD.getPartitions(MappedRDD.scala:28)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:207)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:205)&lt;br/&gt;
	at scala.Option.getOrElse(Option.scala:120)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:205)&lt;br/&gt;
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:891)&lt;br/&gt;
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:741)&lt;br/&gt;
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:692)&lt;br/&gt;
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:574)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:900)&lt;br/&gt;
	at $iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:15)&lt;br/&gt;
	at $iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:20)&lt;br/&gt;
	at $iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:22)&lt;br/&gt;
	at $iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:24)&lt;br/&gt;
	at &amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:26)&lt;br/&gt;
	at .&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:30)&lt;br/&gt;
	at .&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)&lt;br/&gt;
	at .&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:7)&lt;br/&gt;
	at .&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)&lt;br/&gt;
	at $print(&amp;lt;console&amp;gt;)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:606)&lt;br/&gt;
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:772)&lt;br/&gt;
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1040)&lt;br/&gt;
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:609)&lt;br/&gt;
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:640)&lt;br/&gt;
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:604)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:793)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:838)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:750)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:598)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:605)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop.loop(SparkILoop.scala:608)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply$mcZ$sp(SparkILoop.scala:931)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:881)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop$$anonfun$process$1.apply(SparkILoop.scala:881)&lt;br/&gt;
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:881)&lt;br/&gt;
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:973)&lt;br/&gt;
	at org.apache.spark.repl.Main$.main(Main.scala:31)&lt;br/&gt;
	at org.apache.spark.repl.Main.main(Main.scala)&lt;br/&gt;
Caused by: java.lang.ClassNotFoundException: org.jets3t.service.S3ServiceException&lt;br/&gt;
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)&lt;br/&gt;
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)&lt;br/&gt;
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)&lt;br/&gt;
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)&lt;br/&gt;
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)&lt;br/&gt;
	... 63 more&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;/code&amp;#93;&lt;/span&gt;&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12709611">SPARK-1556</key>
            <summary>jets3t dep doesn&apos;t update properly with newer Hadoop versions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="codingcat">Nan Zhu</reporter>
                        <labels>
                    </labels>
                <created>Mon, 21 Apr 2014 19:52:05 +0000</created>
                <updated>Mon, 27 Apr 2015 06:47:51 +0000</updated>
                            <resolved>Mon, 5 May 2014 17:34:58 +0000</resolved>
                                    <version>0.8.1</version>
                    <version>0.9.0</version>
                    <version>1.0.0</version>
                                    <fixVersion>1.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="13989744" author="pwendell" created="Mon, 5 May 2014 17:34:59 +0000"  >&lt;p&gt;Issue resolved by pull request 629&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/629&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/629&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14003582" author="rafal.kwasny" created="Tue, 20 May 2014 16:25:35 +0000"  >&lt;p&gt;If you&apos;re running spark on cdh5 there is a dirty hotfix:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;cd /usr/lib/spark/assembly/lib/ &amp;amp;&amp;amp; ln -s /usr/lib/hadoop/lib/jets3t-0.9.0.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;You have to do this on all nodes, this will put jets3t-0.9.0 before spark_assembly .jar on a classpath&lt;br/&gt;
Fortunately &quot;j&quot; is before &quot;s&quot; in the alphabet &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14003588" author="darose" created="Tue, 20 May 2014 16:28:48 +0000"  >&lt;p&gt;Good tip!!! Many thanks! Will give that a shot.&lt;/p&gt;</comment>
                            <comment id="14042332" author="darose" created="Tue, 24 Jun 2014 16:37:42 +0000"  >&lt;p&gt;Thanks again for the tip.  I didn&apos;t seem to have the /usr/lib/spark/assembly/lib directory in my installation, but adding the symlink in /usr/lib/shark/lib did the trick as well.&lt;/p&gt;</comment>
                            <comment id="14060443" author="mengxr" created="Mon, 14 Jul 2014 08:41:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; I saw you set jets3t&apos;s scope to runtime. Any particular reason for that setting? Now sbt reads deps info from pom. The assembly jar won&apos;t include jets3t if its scope is runtime only. &lt;/p&gt;</comment>
                            <comment id="14060462" author="srowen" created="Mon, 14 Jul 2014 09:12:13 +0000"  >&lt;p&gt;Yeah see PR comments &amp;#8211; runtime is correct because Spark code should not compile against it. Ideally sbt assembly should include runtime dependencies since they are needed exactly at, well, runtime!&lt;/p&gt;</comment>
                            <comment id="14513624" author="apachespark" created="Mon, 27 Apr 2015 06:47:51 +0000"  >&lt;p&gt;User &apos;CodingCat&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/468&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/468&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12712491">SPARK-1735</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12727050">SPARK-2471</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>387933</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 30 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1utsf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>388193</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>