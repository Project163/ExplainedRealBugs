<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26629] Error with multiple file stream in a query + restart on a batch that has no data for one file stream</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26629</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When a streaming query has multiple file streams, and there is a batch where one of the file streams dont have data in that batch, then if the query has to restart from that, it will throw the following error.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.lang.IllegalStateException: batch 1 doesn&apos;t exist
	at org.apache.spark.sql.execution.streaming.HDFSMetadataLog$.verifyBatchIds(HDFSMetadataLog.scala:300)
	at org.apache.spark.sql.execution.streaming.FileStreamSourceLog.get(FileStreamSourceLog.scala:120)
	at org.apache.spark.sql.execution.streaming.FileStreamSource.getBatch(FileStreamSource.scala:181)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$populateStartOffsets$2.apply(MicroBatchExecution.scala:294)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$populateStartOffsets$2.apply(MicroBatchExecution.scala:291)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IterableLike.scala:72)
	at org.apache.spark.sql.execution.streaming.StreamProgress.foreach(StreamProgress.scala:25)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$populateStartOffsets(MicroBatchExecution.scala:291)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:178)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:175)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:175)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;reportTimeTaken(ProgressReporter.scala:251)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:61)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:175)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:169)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:295)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:205)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;*&lt;b&gt;Reason&lt;/b&gt;*&lt;br/&gt;
Existing &lt;tt&gt;HDFSMetadata.verifyBatchIds&lt;/tt&gt; throws error whenever the batchIds list was empty. In the context of &lt;tt&gt;FileStreamSource.getBatch&lt;/tt&gt; (where verify is called) and FileStreamSourceLog (subclass of HDFSMetadata), this is usually okay because, in a streaming query with one file stream, the batchIds can never be empty:&lt;/p&gt;

&lt;p&gt;A batch is planned only when the FileStreamSourceLog has seen new offset (that is, there are new data files).&lt;br/&gt;
So FileStreamSource.getBatch will be called on X to Y where X will always be &amp;gt; Y. This calls internally &lt;tt&gt;HDFSMetadata.verifyBatchIds (X+1, Y)&lt;/tt&gt; with X+1-Y ids.&lt;br/&gt;
For example, &lt;tt&gt;FileStreamSource.getBatch(4, 5)&lt;/tt&gt; will call &lt;tt&gt;verify(batchIds = Seq(5), start = 5, end = 5)&lt;/tt&gt;. However, the invariant of X &amp;gt; Y is not true when there are two file stream sources, as a batch may be planned even when only one of the file streams has data. So one of the file stream may not have data, which can call &lt;tt&gt;FileStreamSource.getBatch(X, X) -&amp;gt; verify(batchIds = Seq.empty, start = X+1, end = X) -&amp;gt; failure&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Note that FileStreamSource.getBatch(X, X) gets called only when restarting a query in a batch where a file source did not have data. This is because, in normal planning of batches, MicroBatchExecution avoids calling &lt;tt&gt;FileStreamSource.getBatch(X, X)&lt;/tt&gt; when offset X has not changed. However, when restarting a stream at such a batch, &lt;tt&gt;MicroBatchExecution.populateStartOffsets()&lt;/tt&gt; calls &lt;tt&gt;FileStreamSource.getBatch(X, X)&lt;/tt&gt; (DataSource V1 hack to initialize the source with last known offsets) thus hitting this issue.&lt;/p&gt;


&lt;p&gt;*&lt;b&gt;Solution&lt;/b&gt;*&lt;br/&gt;
The minimum solution (that can be backported) here is to skip verification when FileStreamSource.getBatch(X, X).&lt;/p&gt;</description>
                <environment></environment>
        <key id="13209777">SPARK-26629</key>
            <summary>Error with multiple file stream in a query + restart on a batch that has no data for one file stream</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="tdas">Tathagata Das</assignee>
                                    <reporter username="tdas">Tathagata Das</reporter>
                        <labels>
                    </labels>
                <created>Wed, 16 Jan 2019 03:02:25 +0000</created>
                <updated>Wed, 16 Jan 2019 18:04:47 +0000</updated>
                            <resolved>Wed, 16 Jan 2019 17:48:24 +0000</resolved>
                                    <version>2.3.0</version>
                    <version>2.3.1</version>
                    <version>2.3.2</version>
                    <version>2.3.3</version>
                    <version>2.4.0</version>
                    <version>2.4.1</version>
                                    <fixVersion>2.4.1</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                        <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 43 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|y001rc:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12344117">2.4.1</customfieldvalue>
    <customfieldvalue id="12339177">3.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>