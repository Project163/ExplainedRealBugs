<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:26:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-6677] pyspark.sql nondeterministic issue with row fields</title>
                <link>https://issues.apache.org/jira/browse/SPARK-6677</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following issue happens only when running pyspark in the python interpreter, it works correctly with spark-submit.&lt;/p&gt;

&lt;p&gt;Reading two json files containing objects with a different structure leads sometimes to the definition of wrong Rows, where the fields of a file are used for the other one.&lt;/p&gt;

&lt;p&gt;I was able to write a sample code that reproduce this issue one out of three times; the code snippet is available at the following link, together with some (very simple) data samples:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/armisael/e08bb4567d0a11efe2db&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/armisael/e08bb4567d0a11efe2db&lt;/a&gt;&lt;/p&gt;</description>
                <environment>&lt;p&gt;spark version: spark-1.3.0-bin-hadoop2.4&lt;br/&gt;
python version: Python 2.7.6&lt;br/&gt;
operating system: MacOS, x86_64 x86_64 x86_64 GNU/Linux&lt;/p&gt;</environment>
        <key id="12787640">SPARK-6677</key>
            <summary>pyspark.sql nondeterministic issue with row fields</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="parmesan">Stefano Parmesan</reporter>
                        <labels>
                            <label>pyspark</label>
                            <label>row</label>
                            <label>sql</label>
                    </labels>
                <created>Thu, 2 Apr 2015 10:25:39 +0000</created>
                <updated>Sun, 12 Apr 2015 13:01:38 +0000</updated>
                            <resolved>Sun, 12 Apr 2015 05:34:00 +0000</resolved>
                                    <version>1.3.0</version>
                                    <fixVersion>1.3.1</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14484835" author="parmesan" created="Wed, 8 Apr 2015 06:47:31 +0000"  >&lt;p&gt;An update: on a more complex script I&apos;m using, the same issue arises even with spark-submit.&lt;/p&gt;</comment>
                            <comment id="14485521" author="davies" created="Wed, 8 Apr 2015 16:52:56 +0000"  >&lt;p&gt;What is the expected output?&lt;/p&gt;

&lt;p&gt;I got this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;key: a
res1 data as row: [Row(foo=1, key=u&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;)]
res2 data as row: [Row(bar=3, key=u&lt;span class=&quot;code-quote&quot;&gt;&apos;a&apos;&lt;/span&gt;, other=u&lt;span class=&quot;code-quote&quot;&gt;&apos;foobar&apos;&lt;/span&gt;)]
res1 and res2 fields: (u&lt;span class=&quot;code-quote&quot;&gt;&apos;foo&apos;&lt;/span&gt;, u&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;) (u&lt;span class=&quot;code-quote&quot;&gt;&apos;bar&apos;&lt;/span&gt;, u&lt;span class=&quot;code-quote&quot;&gt;&apos;key&apos;&lt;/span&gt;, u&lt;span class=&quot;code-quote&quot;&gt;&apos;other&apos;&lt;/span&gt;)
res1 data as tuple: 1 a
res2 data as tuple: 3 a foobar
key: c
res1 data as row: []
res2 data as row: [Row(bar=4, key=u&lt;span class=&quot;code-quote&quot;&gt;&apos;c&apos;&lt;/span&gt;, other=u&lt;span class=&quot;code-quote&quot;&gt;&apos;barfoo&apos;&lt;/span&gt;)]
key: b
res1 data as row: [Row(foo=2, key=u&lt;span class=&quot;code-quote&quot;&gt;&apos;b&apos;&lt;/span&gt;)]
res2 data as row: []
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14485772" author="parmesan" created="Wed, 8 Apr 2015 18:43:15 +0000"  >&lt;p&gt;Hi Davies,&lt;/p&gt;

&lt;p&gt;Thanks for taking the time to look into this; that&apos;s the expected output, in fact. The point is that back then it happened to me randomly, once every five executions or so. Now I&apos;m not able to reproduce it anymore with the data I posted, but I was able to reproduce it again (100% of the times) with the data I just added to the gist; the exception I&apos;m getting is:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ ./bin/pyspark ./spark_test.py
[...]
key: 31491
res1 data as row: [Row(foo=31491, key=u&apos;31491&apos;)]
res2 data as row: [Row(bar=1574550000, key=u&apos;31491&apos;, other=u&apos;foobar&apos;, some=u&apos;thing&apos;, that=u&apos;this&apos;, this=u&apos;that&apos;)]
res1 and res2 fields: (u&apos;foo&apos;, u&apos;key&apos;) (u&apos;bar&apos;, u&apos;key&apos;, u&apos;other&apos;, u&apos;some&apos;, u&apos;that&apos;, u&apos;this&apos;)
res1 data as tuple: 31491 31491
res2 data as tuple: 1574550000 31491 foobar
key: 31497
res1 data as row: []
res2 data as row: [Row(foo=1574850000, key=u&apos;31497&apos;)]
key: 31495
res1 data as row: [Traceback (most recent call last):
  File &quot;/path/to/spark-1.3.0-bin-hadoop2.4/./spark_test.py&quot;, line 25, in &amp;lt;module&amp;gt;
    print &quot;res1 data as row:&quot;, list(res_x)
  File &quot;/path/to/spark-1.3.0-bin-hadoop2.4/python/pyspark/sql/types.py&quot;, line 1214, in __repr__
    for n in self.__FIELDS__))
  File &quot;/path/to/spark-1.3.0-bin-hadoop2.4/python/pyspark/sql/types.py&quot;, line 1214, in &amp;lt;genexpr&amp;gt;
    for n in self.__FIELDS__))
IndexError: tuple index out of range
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which is the same I&apos;m getting in my more complex script.&lt;/p&gt;

&lt;p&gt;Some considerations:&lt;br/&gt;
1) it may be that this particular input leads to the issue only on my machine, therefore I&apos;ve added another file to generate some random inputs; I&apos;ve got this exception on two over three randomly-generated samples, please go ahead and run it with different values of &lt;tt&gt;N&lt;/tt&gt; if the uploaded data does not make pyspark crash in your environment;&lt;br/&gt;
2) interestingly, given the sample data, it always crashes on the same key: &lt;tt&gt;31495&lt;/tt&gt;; however, they do not seem &quot;magic&quot; to me (and of course input files containing just those two elements does not make pyspark crash in any way):&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;data/sample_a.json:{&quot;foo&quot;: 31495, &quot;key&quot;: &quot;31495&quot;}
data/sample_b.json:{&quot;other&quot;: &quot;foobar&quot;, &quot;bar&quot;: 1574750000, &quot;key&quot;: &quot;31495&quot;, &quot;that&quot;: &quot;this&quot;, &quot;this&quot;: &quot;that&quot;, &quot;some&quot;: &quot;thing&quot;}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;3) what happens is that either &lt;tt&gt;res_x.data[0].__&lt;em&gt;FIELDS&lt;/em&gt;_&lt;em&gt;&lt;/tt&gt; or &lt;tt&gt;res_y.data[0].&lt;/em&gt;_&lt;em&gt;FIELDS&lt;/em&gt;__&lt;/tt&gt; get the wrong field names, leading to the &lt;tt&gt;IndexError&lt;/tt&gt; (the fields are too many and the row does not contain enough data).&lt;/p&gt;</comment>
                            <comment id="14486081" author="davies" created="Wed, 8 Apr 2015 21:22:15 +0000"  >&lt;p&gt;I still can not reproduce in on master, will retry with 1.3.0.&lt;/p&gt;</comment>
                            <comment id="14486097" author="davies" created="Wed, 8 Apr 2015 21:27:54 +0000"  >&lt;p&gt;Spark 1.3.0 also works fine here, tried different N.&lt;/p&gt;</comment>
                            <comment id="14487010" author="parmesan" created="Thu, 9 Apr 2015 09:02:13 +0000"  >&lt;p&gt;Uhm, don&apos;t know what to say. Let&apos;s try with this: I&apos;ve created a docker that reproduces the issue, its available here:&lt;br/&gt;
&lt;a href=&quot;https://github.com/armisael/SPARK-6677&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/armisael/SPARK-6677&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I tested it on three different machines, and the issue appeared on all of them. Can you give it a try?&lt;/p&gt;</comment>
                            <comment id="14488347" author="davies" created="Thu, 9 Apr 2015 21:49:54 +0000"  >&lt;p&gt;That&apos;s cool, I will test it.&lt;/p&gt;</comment>
                            <comment id="14488677" author="apachespark" created="Fri, 10 Apr 2015 00:58:45 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5445&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5445&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14488678" author="davies" created="Fri, 10 Apr 2015 00:58:46 +0000"  >&lt;p&gt;This will be fixed by &lt;a href=&quot;https://github.com/apache/spark/pull/5445&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5445&lt;/a&gt;, thanks to help to reproduce it.&lt;/p&gt;</comment>
                            <comment id="14491333" author="joshrosen" created="Sun, 12 Apr 2015 05:34:00 +0000"  >&lt;p&gt;Issue resolved by pull request 5445&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5445&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5445&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14491335" author="joshrosen" created="Sun, 12 Apr 2015 05:35:28 +0000"  >&lt;p&gt;Thanks again for the reproduction; this was a tricky issue!&lt;/p&gt;</comment>
                            <comment id="14491459" author="parmesan" created="Sun, 12 Apr 2015 13:01:38 +0000"  >&lt;p&gt;glad it helped! we&apos;re very eager to try it out&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 32 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i27p2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>