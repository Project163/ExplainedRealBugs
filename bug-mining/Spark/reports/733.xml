<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:17:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-2951] SerDeUtils.pythonToPairRDD fails on RDDs of pickled array.arrays in Python 2.6</title>
                <link>https://issues.apache.org/jira/browse/SPARK-2951</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;With Python 2.6, calling SerDeUtils.pythonToPairRDD() on an RDD of pickled Python array.arrays will fail with this exception:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ava.lang.ClassCastException: java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to java.util.ArrayList
        net.razorvine.pickle.objects.ArrayConstructor.construct(ArrayConstructor.java:33)
        net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:617)
        net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:170)
        net.razorvine.pickle.Unpickler.load(Unpickler.java:84)
        net.razorvine.pickle.Unpickler.loads(Unpickler.java:97)
        org.apache.spark.api.python.SerDeUtil$$anonfun$pythonToPairRDD$1$$anonfun$5.apply(SerDeUtil.scala:106)
        org.apache.spark.api.python.SerDeUtil$$anonfun$pythonToPairRDD$1$$anonfun$5.apply(SerDeUtil.scala:106)
        scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:898)
        org.apache.spark.rdd.PairRDDFunctions$$anonfun$12.apply(PairRDDFunctions.scala:880)
        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
        org.apache.spark.scheduler.Task.run(Task.scala:54)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:199)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think this is due to a difference in how array.array is pickled in Python 2.6 vs. Python 2.7.  To see this, run the following script:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;from pickletools &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; dis, optimize
from pickle &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; dumps, loads, HIGHEST_PROTOCOL
from array &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; array

arr = array(&lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;, [1, 2, 3])

#protocol = HIGHEST_PROTOCOL
protocol = 0

pickled = dumps(arr, protocol=protocol)
pickled = optimize(pickled)
unpickled = loads(pickled)

print arr
print unpickled

print dis(pickled)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In Python 2.7, this outputs&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;array(&lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;, [1.0, 2.0, 3.0])
array(&lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;, [1.0, 2.0, 3.0])
    0: c    GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;array array&apos;&lt;/span&gt;
   13: (    MARK
   14: S        STRING     &lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;
   19: (        MARK
   20: l            LIST       (MARK at 19)
   21: F        FLOAT      1.0
   26: a        APPEND
   27: F        FLOAT      2.0
   32: a        APPEND
   33: F        FLOAT      3.0
   38: a        APPEND
   39: t        TUPLE      (MARK at 13)
   40: R    REDUCE
   41: .    STOP
highest protocol among opcodes = 0
None
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;whereas 2.6 outputs&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;array(&lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;, [1.0, 2.0, 3.0])
array(&lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;, [1.0, 2.0, 3.0])
    0: c    GLOBAL     &lt;span class=&quot;code-quote&quot;&gt;&apos;array array&apos;&lt;/span&gt;
   13: (    MARK
   14: S        STRING     &lt;span class=&quot;code-quote&quot;&gt;&apos;d&apos;&lt;/span&gt;
   19: S        STRING     &lt;span class=&quot;code-quote&quot;&gt;&apos;\x00\x00\x00\x00\x00\x00\xf0?\x00\x00\x00\x00\x00\x00\x00@\x00\x00\x00\x00\x00\x00\x08@&apos;&lt;/span&gt;
  110: t        TUPLE      (MARK at 13)
  111: R    REDUCE
  112: .    STOP
highest protocol among opcodes = 0
None
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think the Java-side depickling library doesn&apos;t expect this pickled format, causing this failure.&lt;/p&gt;

&lt;p&gt;I noticed this when running PySpark&apos;s unit tests on 2.6 because the TestOuputFormat.test_newhadoop test failed.&lt;/p&gt;

&lt;p&gt;I think that this issue affects all of the methods that might need to depickle arrays in Java, including all of the Hadoop output format methods.&lt;/p&gt;

&lt;p&gt;How should we try to fix this?  Require that users upgrade to 2.7 if they want to use code that requires this?  Open a bug with the depickling library maintainers?  Try to hack in our own pickling routines for arrays if we detect that we&apos;re using 2.6?&lt;/p&gt;</description>
                <environment></environment>
        <key id="12733079">SPARK-2951</key>
            <summary>SerDeUtils.pythonToPairRDD fails on RDDs of pickled array.arrays in Python 2.6</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="joshrosen">Josh Rosen</reporter>
                        <labels>
                    </labels>
                <created>Sun, 10 Aug 2014 01:29:44 +0000</created>
                <updated>Mon, 4 May 2015 03:53:42 +0000</updated>
                            <resolved>Tue, 16 Sep 2014 01:57:41 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.2.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="14130878" author="apachespark" created="Thu, 11 Sep 2014 23:50:43 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2365&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2365&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14134828" author="joshrosen" created="Tue, 16 Sep 2014 01:57:41 +0000"  >&lt;p&gt;Issue resolved by pull request 2365&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2365&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2365&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14241654" author="apachespark" created="Wed, 10 Dec 2014 20:17:08 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3668&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3668&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12733818">SPARK-3013</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12826659">SPARK-7314</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>411107</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 49 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1yq87:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>411099</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>