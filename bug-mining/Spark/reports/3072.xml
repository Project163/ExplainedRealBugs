<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:37:41 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-13195] PairDStreamFunctions.mapWithState fails in case timeout is set without updating State[S]</title>
                <link>https://issues.apache.org/jira/browse/SPARK-13195</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Using the new spark mapWithState API, I&apos;ve encountered a bug when setting a timeout for mapWithState but no explicit state handling.&lt;/p&gt;

&lt;h1&gt;&lt;a name=&quot;Stepstoreproduce%3A&quot;&gt;&lt;/a&gt;Steps to reproduce:&lt;/h1&gt;

&lt;p&gt;1. Create a method which conforms to the StateSpec signature, make sure to not update any state inside it using &lt;b&gt;state.update&lt;/b&gt;. Simply create a &quot;pass through&quot; method, may even be empty.&lt;br/&gt;
2. Create a StateSpec object with method from step 1, which explicitly sets a timeout using &lt;b&gt;StateSpec.timeout&lt;/b&gt; method.&lt;br/&gt;
3. Create a DStream pipeline that uses mapWithState with the given StateSpec.&lt;br/&gt;
4. Run code using spark-submit. You&apos;ll see that the method ends up throwing the following exception:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 136.0 failed 4 times, most recent failure: Lost task 0.3 in stage 136.0 (TID 176, ****): java.util.NoSuchElementException: State is not set
	at org.apache.spark.streaming.StateImpl.get(State.scala:150)
	at org.apache.spark.streaming.rdd.MapWithStateRDDRecord$$anonfun$updateRecordWithData$1.apply(MapWithStateRDD.scala:61)
	at org.apache.spark.streaming.rdd.MapWithStateRDDRecord$$anonfun$updateRecordWithData$1.apply(MapWithStateRDD.scala:55)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at org.apache.spark.streaming.rdd.MapWithStateRDDRecord$.updateRecordWithData(MapWithStateRDD.scala:55)
	at org.apache.spark.streaming.rdd.MapWithStateRDD.compute(MapWithStateRDD.scala:154)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;h1&gt;&lt;a name=&quot;Samplecodetoreproducetheissue%3A&quot;&gt;&lt;/a&gt;Sample code to reproduce the issue:&lt;/h1&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.streaming._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.{SparkConf, SparkContext}
/**
  * Created by yuvali on 04/02/2016.
  */
object Program {

  def main(args: Array[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;]): Unit = {
    
    val sc = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkConf().setAppName(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapWithState bug reproduce&quot;&lt;/span&gt;)
    val sparkContext = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkContext(sc)

    val ssc = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StreamingContext(sparkContext, Seconds(4))
    val stateSpec = StateSpec.function(trackStateFunc _).timeout(Seconds(60))

    &lt;span class=&quot;code-comment&quot;&gt;// Create a stream that generates 1000 lines per second
&lt;/span&gt;    val stream = ssc.receiverStream(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DummySource(10))

    &lt;span class=&quot;code-comment&quot;&gt;// Split the lines into words, and create a paired (key-value) dstream
&lt;/span&gt;    val wordStream = stream.flatMap {
      _.split(&lt;span class=&quot;code-quote&quot;&gt;&quot; &quot;&lt;/span&gt;)
    }.map(word =&amp;gt; (word, 1))

    &lt;span class=&quot;code-comment&quot;&gt;// This represents the emitted stream from the trackStateFunc. Since we emit every input record with the updated value,
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; stream will contain the same # of records as the input dstream.
&lt;/span&gt;    val wordCountStateStream = wordStream.mapWithState(stateSpec)
    wordCountStateStream.print()

    ssc.remember(Minutes(1)) &lt;span class=&quot;code-comment&quot;&gt;// To make sure data is not deleted by the time we query it interactively
&lt;/span&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// Don&apos;t forget to set checkpoint directory
&lt;/span&gt;    ssc.checkpoint(&quot;&quot;)
    ssc.start()
    ssc.awaitTermination()
  }

  def trackStateFunc(batchTime: Time, key: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, value: Option[Int], state: State[&lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;]): Option[(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;)] = {
    val sum = value.getOrElse(0).toLong + state.getOption.getOrElse(0L)
    val output = (key, sum)
    Some(output)
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
  * Created by yuvali on 04/02/2016.
  */

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.storage.StorageLevel
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.util.Random
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.streaming.receiver._

&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;DummySource(ratePerSec: Int) &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Receiver[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;](StorageLevel.MEMORY_AND_DISK_2) {

  def onStart() {
    &lt;span class=&quot;code-comment&quot;&gt;// Start the thread that receives data over a connection
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&quot;Dummy Source&quot;&lt;/span&gt;) {
      override def run() { receive() }
    }.start()
  }

  def onStop() {
    &lt;span class=&quot;code-comment&quot;&gt;// There is nothing much to &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; as the thread calling receive()
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// is designed to stop by itself isStopped() returns &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&lt;/span&gt;  }

  &lt;span class=&quot;code-comment&quot;&gt;/** Create a socket connection and receive data until receiver is stopped */&lt;/span&gt;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def receive() {
    &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt;(!isStopped()) {
      store(&lt;span class=&quot;code-quote&quot;&gt;&quot;I am a dummy source &quot;&lt;/span&gt; + Random.nextInt(10))
      &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep((1000.toDouble / ratePerSec).toInt)
    }
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The given issue resides in the following &lt;b&gt;MapWithStateRDDRecord.updateRecordWithData&lt;/b&gt;, starting line 55, in the following code block:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;dataIterator.foreach { &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (key, value) =&amp;gt;
      wrappedState.wrap(newStateMap.get(key))
      val returned = mappingFunction(batchTime, key, Some(value), wrappedState)
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (wrappedState.isRemoved) {
        newStateMap.remove(key)
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (wrappedState.isUpdated || timeoutThresholdTime.isDefined) &lt;span class=&quot;code-comment&quot;&gt;/* &amp;lt;--- problem is here */&lt;/span&gt; {
        newStateMap.put(key, wrappedState.get(), batchTime.milliseconds)
      }
      mappedData ++= returned
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In case the stream has a timeout set, but the state wasn&apos;t set at all, the &quot;else-if&quot; will still follow through because the timeout is defined but &quot;wrappedState&quot; is empty and wasn&apos;t set.&lt;/p&gt;

&lt;p&gt;If it is mandatory to update state for each entry of &lt;b&gt;mapWithState&lt;/b&gt;, then this code should throw a better exception than &quot;NoSuchElementException&quot;, which doesn&apos;t really saw anything to the developer.&lt;/p&gt;

&lt;p&gt;I haven&apos;t provided a fix myself because I&apos;m not familiar with the spark implementation, but it seems to be there needs to either be an extra check if the state is set, or as previously stated a better exception message.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12936734">SPARK-13195</key>
            <summary>PairDStreamFunctions.mapWithState fails in case timeout is set without updating State[S]</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zsxwing">Shixiong Zhu</assignee>
                                    <reporter username="Yuval.Itzchakov">Yuval Itzchakov</reporter>
                        <labels>
                    </labels>
                <created>Thu, 4 Feb 2016 14:00:02 +0000</created>
                <updated>Thu, 4 Feb 2016 20:45:29 +0000</updated>
                            <resolved>Thu, 4 Feb 2016 20:45:29 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>1.6.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>DStreams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15132797" author="apachespark" created="Thu, 4 Feb 2016 19:05:04 +0000"  >&lt;p&gt;User &apos;zsxwing&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11081&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11081&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10431"><![CDATA[Important]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 41 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2sfaf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>