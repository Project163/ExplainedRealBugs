<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26379] Use dummy TimeZoneId for CurrentTimestamp to avoid UnresolvedException in CurrentBatchTimestamp</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26379</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;While using withColumn to add a column to a structured streaming Dataset, I am getting following exception:&#160;&lt;/p&gt;

&lt;p&gt;org.apache.spark.sql.catalyst.analysis.UnresolvedException: Invalid call to dataType on unresolved object, tree: &apos;timestamp&lt;/p&gt;

&lt;p&gt;Following is sample code&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; path = &lt;span class=&quot;code-quote&quot;&gt;&quot;path_to_input_directory&quot;&lt;/span&gt;;

&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; StructType schema = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructType(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructField[] { &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;word&quot;&lt;/span&gt;, StringType, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, Metadata.empty()), &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;count&quot;&lt;/span&gt;, DataTypes.IntegerType, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, Metadata.empty()) });

SparkSession sparkSession = SparkSession.builder().appName(&lt;span class=&quot;code-quote&quot;&gt;&quot;StructuredStreamingIssue&quot;&lt;/span&gt;).master(&lt;span class=&quot;code-quote&quot;&gt;&quot;local&quot;&lt;/span&gt;).getOrCreate();
Dataset&amp;lt;Row&amp;gt; words = sparkSession.readStream().option(&lt;span class=&quot;code-quote&quot;&gt;&quot;sep&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;,&quot;&lt;/span&gt;).schema(schema).csv(path);

Dataset&amp;lt;Row&amp;gt; wordsWithTimestamp = words.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, functions.current_timestamp());

&lt;span class=&quot;code-comment&quot;&gt;// wordsWithTimestamp.explain(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;);
&lt;/span&gt;
StreamingQuery query = wordsWithTimestamp.writeStream().outputMode(&lt;span class=&quot;code-quote&quot;&gt;&quot;update&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;truncate&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;).format(&lt;span class=&quot;code-quote&quot;&gt;&quot;console&quot;&lt;/span&gt;).trigger(Trigger.ProcessingTime(&lt;span class=&quot;code-quote&quot;&gt;&quot;2 seconds&quot;&lt;/span&gt;)).start();

query.awaitTermination();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Following are the contents of the file present at &lt;em&gt;path&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
a,2
c,4
d,2
r,1
t,9
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This seems working with 2.2.0 release, but not with 2.3.0 and 2.4.0&lt;/p&gt;</description>
                <environment></environment>
        <key id="13204739">SPARK-26379</key>
            <summary>Use dummy TimeZoneId for CurrentTimestamp to avoid UnresolvedException in CurrentBatchTimestamp</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kabhwan">Jungtaek Lim</assignee>
                                    <reporter username="kailashgupta1012">Kailash Gupta</reporter>
                        <labels>
                    </labels>
                <created>Sun, 16 Dec 2018 16:36:32 +0000</created>
                <updated>Tue, 29 Jan 2019 01:04:45 +0000</updated>
                            <resolved>Sun, 27 Jan 2019 21:47:53 +0000</resolved>
                                    <version>2.3.0</version>
                    <version>2.3.1</version>
                    <version>2.3.2</version>
                    <version>2.4.0</version>
                    <version>3.0.0</version>
                                    <fixVersion>2.3.3</fixVersion>
                    <fixVersion>2.4.1</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16722524" author="kailashgupta1012" created="Sun, 16 Dec 2018 16:43:47 +0000"  >&lt;p&gt;Full exception stack trace&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
18/12/16 22:09:32 ERROR MicroBatchExecution: Query [id = ca9aaed4-e750-453a-88f9-2807365efcf2, runId = e346ac1d-3873-4922-a327-d539dfdc44bc] terminated with error
org.apache.spark.sql.catalyst.analysis.UnresolvedException: Invalid call to dataType on unresolved object, tree: &apos;timestamp
at org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.dataType(unresolved.scala:105)
at org.apache.spark.sql.types.StructType$$anonfun$fromAttributes$1.apply(StructType.scala:435)
at org.apache.spark.sql.types.StructType$$anonfun$fromAttributes$1.apply(StructType.scala:435)
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
at scala.collection.immutable.List.foreach(List.scala:381)
at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
at scala.collection.immutable.List.map(List.scala:285)
at org.apache.spark.sql.types.StructType$.fromAttributes(StructType.scala:435)
at org.apache.spark.sql.catalyst.plans.QueryPlan.schema$lzycompute(QueryPlan.scala:157)
at org.apache.spark.sql.catalyst.plans.QueryPlan.schema(QueryPlan.scala:157)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:447)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:133)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:121)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:121)
at org.apache.spark.sql.execution.streaming.ProgressReporter$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;reportTimeTaken(ProgressReporter.scala:271)
at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:121)
at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:117)
at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:279)
at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:189)
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; org.apache.spark.sql.streaming.StreamingQueryException: Invalid call to dataType on unresolved object, tree: &apos;timestamp
=== Streaming Query ===
Identifier: [id = ca9aaed4-e750-453a-88f9-2807365efcf2, runId = e346ac1d-3873-4922-a327-d539dfdc44bc]
Current Committed Offsets: {}
Current Available Offsets: {FileStreamSource[file:/input]: {&lt;span class=&quot;code-quote&quot;&gt;&quot;logOffset&quot;&lt;/span&gt;:0}}

Current State: ACTIVE
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; State: RUNNABLE

Logical Plan:
Project [word#0, count#1, current_timestamp() AS timestamp#4]
+- StreamingExecutionRelation FileStreamSource[file:/input], [word#0, count#1]

at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:295)
at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:189)
Caused by: org.apache.spark.sql.catalyst.analysis.UnresolvedException: Invalid call to dataType on unresolved object, tree: &apos;timestamp
at org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute.dataType(unresolved.scala:105)
at org.apache.spark.sql.types.StructType$$anonfun$fromAttributes$1.apply(StructType.scala:435)
at org.apache.spark.sql.types.StructType$$anonfun$fromAttributes$1.apply(StructType.scala:435)
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
at scala.collection.immutable.List.foreach(List.scala:381)
at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
at scala.collection.immutable.List.map(List.scala:285)
at org.apache.spark.sql.types.StructType$.fromAttributes(StructType.scala:435)
at org.apache.spark.sql.catalyst.plans.QueryPlan.schema$lzycompute(QueryPlan.scala:157)
at org.apache.spark.sql.catalyst.plans.QueryPlan.schema(QueryPlan.scala:157)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:447)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:133)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:121)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:121)
at org.apache.spark.sql.execution.streaming.ProgressReporter$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;reportTimeTaken(ProgressReporter.scala:271)
at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:121)
at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:117)
at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:279)
... 1 more
18/12/16 22:09:32 INFO SparkContext: Invoking stop() from shutdown hook&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16722525" author="kailashgupta1012" created="Sun, 16 Dec 2018 16:55:25 +0000"  >&lt;p&gt;Explain result&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
== Parsed Logical Plan ==
Project [word#0, count#1, current_timestamp() AS timestamp#4]
+- AnalysisBarrier
+- StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c11d32,csv,List(),Some(StructType(StructField(word,StringType,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;), StructField(count,IntegerType,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;))),List(),None,Map(sep -&amp;gt; ,, path -&amp;gt; /input),None), FileSource[/input], [word#0, count#1]

== Analyzed Logical Plan ==
word: string, count: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, timestamp: timestamp
Project [word#0, count#1, current_timestamp() AS timestamp#4]
+- StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c11d32,csv,List(),Some(StructType(StructField(word,StringType,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;), StructField(count,IntegerType,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;))),List(),None,Map(sep -&amp;gt; ,, path -&amp;gt; /input),None), FileSource[/input], [word#0, count#1]

== Optimized Logical Plan ==
Project [word#0, count#1, 1544979190083000 AS timestamp#4]
+- StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c11d32,csv,List(),Some(StructType(StructField(word,StringType,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;), StructField(count,IntegerType,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;))),List(),None,Map(sep -&amp;gt; ,, path -&amp;gt; /input),None), FileSource[/input], [word#0, count#1]

== Physical Plan ==
*(1) Project [word#0, count#1, 1544979190083000 AS timestamp#4]
+- StreamingRelation FileSource[/input], [word#0, count#1]&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16748458" author="kabhwan" created="Tue, 22 Jan 2019 07:36:58 +0000"  >&lt;p&gt;This looks like also occurred on the master branch. Simpler to reproduce.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.functions._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.SparkSession
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; spark.implicits._
val lines = spark.readStream.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;socket&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;host&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;localhost&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;port&quot;&lt;/span&gt;, 9999).load()
val final_df = lines.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;ts&quot;&lt;/span&gt;,lit(current_timestamp())) 
val query = final_df.writeStream.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;console&quot;&lt;/span&gt;).start()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ll quickly submit a patch soon.&lt;/p&gt;</comment>
                            <comment id="16750304" author="dongjoon" created="Wed, 23 Jan 2019 18:34:19 +0000"  >&lt;p&gt;Thank you, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kailashgupta1012&quot; class=&quot;user-hover&quot; rel=&quot;kailashgupta1012&quot;&gt;kailashgupta1012&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan&quot; class=&quot;user-hover&quot; rel=&quot;kabhwan&quot;&gt;kabhwan&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16752782" author="dongjoon" created="Fri, 25 Jan 2019 23:03:48 +0000"  >&lt;p&gt;This is resolved via &lt;a href=&quot;https://github.com/apache/spark/pull/23609&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23609&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 42 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|u000ts:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>