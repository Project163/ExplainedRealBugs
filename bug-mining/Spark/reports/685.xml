<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:17:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3335] [Spark SQL] In pyspark, cannot use broadcast variables in UDF </title>
                <link>https://issues.apache.org/jira/browse/SPARK-3335</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Running pyspark on a spark cluster with standalone master, spark sql cannot use broadcast variables in UDF. But we can use broadcast variable in spark in scala.&lt;/p&gt;

&lt;p&gt;For example,&lt;br/&gt;
bar=&lt;/p&gt;
{&quot;a&quot;:&quot;aa&quot;, &quot;b&quot;:&quot;bb&quot;, &quot;c&quot;:&quot;abc&quot;}
&lt;p&gt;foo=sc.broadcast(bar)&lt;br/&gt;
sqlContext.registerFunction(&quot;MYUDF&quot;, lambda x: foo.value&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt; if x else &apos;&apos;).&lt;br/&gt;
q= sqlContext.sql(&apos;SELECT MYUDF(c)  FROM foobar&apos;)&lt;br/&gt;
out = q.collect()&lt;/p&gt;

&lt;p&gt;Got the following exception:&lt;br/&gt;
Py4JJavaError: An error occurred while calling o169.collect.&lt;br/&gt;
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 51.0 failed 4 times, most recent failure: Lost task 4.3 in stage 51.0 (TID 13040, ip-10-33-9-144.us-west-2.compute.internal): org.apache.spark.api.python.PythonException: Traceback (most recent call last):&lt;br/&gt;
  File &quot;/root/spark/python/pyspark/worker.py&quot;, line 75, in main&lt;br/&gt;
    command = pickleSer._read_with_length(infile)&lt;br/&gt;
  File &quot;/root/spark/python/pyspark/serializers.py&quot;, line 150, in _read_with_length&lt;br/&gt;
    return self.loads(obj)&lt;br/&gt;
  File &quot;/root/spark/python/pyspark/broadcast.py&quot;, line 41, in _from_id&lt;br/&gt;
    raise Exception(&quot;Broadcast variable &apos;%s&apos; not loaded!&quot; % bid)&lt;br/&gt;
Exception: (Exception(&quot;Broadcast variable &apos;21&apos; not loaded!&quot;,), &amp;lt;function _from_id at 0x35042a8&amp;gt;, (21L,))&lt;/p&gt;

&lt;p&gt;        org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:124)&lt;br/&gt;
        org.apache.spark.api.python.PythonRDD$$anon$1.&amp;lt;init&amp;gt;(PythonRDD.scala:154)&lt;br/&gt;
        org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:87)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:87)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)&lt;br/&gt;
        org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)&lt;br/&gt;
        org.apache.spark.scheduler.Task.run(Task.scala:54)&lt;br/&gt;
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:177)&lt;br/&gt;
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
        java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Driver stacktrace:&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1185)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1174)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1173)&lt;br/&gt;
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)&lt;br/&gt;
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1173)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:688)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:688)&lt;br/&gt;
	at scala.Option.foreach(Option.scala:236)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:688)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1391)&lt;br/&gt;
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)&lt;br/&gt;
	at akka.actor.ActorCell.invoke(ActorCell.scala:456)&lt;br/&gt;
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)&lt;br/&gt;
	at akka.dispatch.Mailbox.run(Mailbox.scala:219)&lt;br/&gt;
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)&lt;br/&gt;
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)&lt;br/&gt;
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)&lt;br/&gt;
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)&lt;br/&gt;
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)&lt;/p&gt;

</description>
                <environment></environment>
        <key id="12738218">SPARK-3335</key>
            <summary>[Spark SQL] In pyspark, cannot use broadcast variables in UDF </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="kayfeng">kay feng</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Sep 2014 08:21:08 +0000</created>
                <updated>Thu, 4 Sep 2014 02:10:42 +0000</updated>
                            <resolved>Thu, 4 Sep 2014 02:10:42 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.2.0</fixVersion>
                                    <component>PySpark</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14119186" author="apachespark" created="Wed, 3 Sep 2014 02:00:28 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2243&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2243&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 11 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1zjl3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12327369">1.2.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>