<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:31:29 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-10038] TungstenProject code generation fails when applied to array&lt;binary&gt;</title>
                <link>https://issues.apache.org/jira/browse/SPARK-10038</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;During fuzz testing, I discovered that TungstenProject can crash when applied to schemas that contain &lt;tt&gt;array&amp;lt;binary&amp;gt;&lt;/tt&gt; columns.  As a minimal example, the following code crashes in spark-shell:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.parallelize(Seq((Array(Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;](1)), 1))).toDF.select(&lt;span class=&quot;code-quote&quot;&gt;&quot;_1&quot;&lt;/span&gt;).rdd.count()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here&apos;s the stacktrace:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/08/16 17:11:49 ERROR Executor: Exception in task 3.0 in stage 29.0 (TID 144)
java.util.concurrent.ExecutionException: java.lang.Exception: failed to compile: org.codehaus.commons.compiler.CompileException: Line 53, Column 63: &lt;span class=&quot;code-quote&quot;&gt;&apos;{&apos;&lt;/span&gt; expected instead of &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt;

&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; generate(org.apache.spark.sql.catalyst.expressions.Expression[] exprs) {
  &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SpecificUnsafeProjection(exprs);
}

&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;SpecificUnsafeProjection &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; org.apache.spark.sql.catalyst.expressions.UnsafeProjection {

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; org.apache.spark.sql.catalyst.expressions.Expression[] expressions;

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; UnsafeRow convertedStruct2;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] buffer3;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; cursor4;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; UnsafeArrayData convertedArray6;
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] buffer7;


  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; SpecificUnsafeProjection(org.apache.spark.sql.catalyst.expressions.Expression[] expressions) {
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.expressions = expressions;
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.convertedStruct2 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; UnsafeRow();
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.buffer3 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[16];
    &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.cursor4 = 0;
    convertedArray6 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; UnsafeArrayData();
    buffer7 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[64];
  }

  &lt;span class=&quot;code-comment&quot;&gt;// Scala.Function1 need &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; apply(&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; row) {
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; apply((InternalRow) row);
  }

  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; UnsafeRow apply(InternalRow i) {

    cursor4 = 16;
    convertedStruct2.pointTo(buffer3, Platform.BYTE_ARRAY_OFFSET, 1, cursor4);


    &lt;span class=&quot;code-comment&quot;&gt;/* input[0, ArrayType(BinaryType,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)] */&lt;/span&gt;

    &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isNull0 = i.isNullAt(0);
    ArrayData primitive1 = isNull0 ? &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; : (i.getArray(0));

    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; isNull8 = isNull0;
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!isNull8) {
      &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ArrayData tmp9 = primitive1;
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (tmp9 &lt;span class=&quot;code-keyword&quot;&gt;instanceof&lt;/span&gt; UnsafeArrayData) {
        convertedArray6 = (UnsafeArrayData) tmp9;
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; numElements10 = tmp9.numElements();
        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; fixedSize11 = 4 * numElements10;
        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; numBytes12 = fixedSize11;


        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[][] elements13 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[][numElements10];
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; index15 = 0; index15 &amp;lt; numElements10; index15++) {

          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (!tmp9.isNullAt(index15)) {
            elements13[index15] = tmp9.getBinary(index15);
            numBytes12 += org.apache.spark.sql.catalyst.expressions.UnsafeWriters$BinaryWriter.getSize(elements13[index15]);
          }
        }


        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (numBytes12 &amp;gt; buffer7.length) {
          buffer7 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[numBytes12];
        }

        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; cursor14 = fixedSize11;
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; index15 = 0; index15 &amp;lt; numElements10; index15++) {
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (elements13[index15] == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
            &lt;span class=&quot;code-comment&quot;&gt;// If element is &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, write the negative value address into offset region.
&lt;/span&gt;            Platform.putInt(buffer7, Platform.BYTE_ARRAY_OFFSET + 4 * index15, -cursor14);
          } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
            Platform.putInt(buffer7, Platform.BYTE_ARRAY_OFFSET + 4 * index15, cursor14);

            cursor14 += org.apache.spark.sql.catalyst.expressions.UnsafeWriters$BinaryWriter.write(
              buffer7,
              Platform.BYTE_ARRAY_OFFSET + cursor14,
              elements13[index15]);

          }
        }

        convertedArray6.pointTo(
          buffer7,
          Platform.BYTE_ARRAY_OFFSET,
          numElements10,
          numBytes12);
      }
    }


    &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; numBytes16 = cursor4 + (isNull8 ? 0 : org.apache.spark.sql.catalyst.expressions.UnsafeRowWriters$ArrayWriter.getSize(convertedArray6));
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (buffer3.length &amp;lt; numBytes16) {
      &lt;span class=&quot;code-comment&quot;&gt;// This will not happen frequently, because the buffer is re-used.
&lt;/span&gt;      &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] tmpBuffer5 = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[numBytes16 * 2];
      Platform.copyMemory(buffer3, Platform.BYTE_ARRAY_OFFSET,
        tmpBuffer5, Platform.BYTE_ARRAY_OFFSET, buffer3.length);
      buffer3 = tmpBuffer5;
    }
    convertedStruct2.pointTo(buffer3, Platform.BYTE_ARRAY_OFFSET, 1, numBytes16);


    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (isNull8) {
      convertedStruct2.setNullAt(0);
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      cursor4 += org.apache.spark.sql.catalyst.expressions.UnsafeRowWriters$ArrayWriter.write(convertedStruct2, 0, cursor4, convertedArray6);
    }



    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; convertedStruct2;
  }
}


	at com.google.common.util.concurrent.AbstractFuture$Sync.getValue(AbstractFuture.java:306)
	at com.google.common.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:293)
	at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:116)
	at com.google.common.util.concurrent.Uninterruptibles.getUninterruptibly(Uninterruptibles.java:135)
	at com.google.common.cache.LocalCache$LoadingValueReference.waitForValue(LocalCache.java:3620)
	at com.google.common.cache.LocalCache$Segment.waitForLoadingValue(LocalCache.java:2362)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2251)
	at com.google.common.cache.LocalCache.get(LocalCache.java:4000)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:4004)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.compile(CodeGenerator.scala:362)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:469)
	at org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection$.create(GenerateUnsafeProjection.scala:32)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:425)
	at org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:124)
	at org.apache.spark.sql.catalyst.expressions.UnsafeProjection$.create(Projection.scala:134)
	at org.apache.spark.sql.execution.TungstenProject$$anonfun$2.apply(basicOperators.scala:85)
	at org.apache.spark.sql.execution.TungstenProject$$anonfun$2.apply(basicOperators.scala:80)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here&apos;s the &lt;tt&gt;explain&lt;/tt&gt; output:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; sc.parallelize(Seq((Array(Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;](1)), 1))).toDF.select(&lt;span class=&quot;code-quote&quot;&gt;&quot;_1&quot;&lt;/span&gt;).explain(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
== Parsed Logical Plan ==
&lt;span class=&quot;code-quote&quot;&gt;&apos;Project [unresolvedalias(&apos;&lt;/span&gt;_1)]
 LogicalRDD [_1#161,_2#162], MapPartitionsRDD[187] at rddToDataFrameHolder at &amp;lt;console&amp;gt;:22

== Analyzed Logical Plan ==
_1: array&amp;lt;binary&amp;gt;
Project [_1#161]
 LogicalRDD [_1#161,_2#162], MapPartitionsRDD[187] at rddToDataFrameHolder at &amp;lt;console&amp;gt;:22

== Optimized Logical Plan ==
Project [_1#161]
 LogicalRDD [_1#161,_2#162], MapPartitionsRDD[187] at rddToDataFrameHolder at &amp;lt;console&amp;gt;:22

== Physical Plan ==
TungstenProject [_1#161]
 Scan PhysicalRDD[_1#161,_2#162]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12856483">SPARK-10038</key>
            <summary>TungstenProject code generation fails when applied to array&lt;binary&gt;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="joshrosen">Josh Rosen</reporter>
                        <labels>
                    </labels>
                <created>Mon, 17 Aug 2015 00:17:32 +0000</created>
                <updated>Tue, 18 Aug 2015 06:28:08 +0000</updated>
                            <resolved>Tue, 18 Aug 2015 06:28:08 +0000</resolved>
                                    <version>1.5.0</version>
                                    <fixVersion>1.5.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14700186" author="apachespark" created="Mon, 17 Aug 2015 20:43:03 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8250&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8250&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 14 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2ize7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12332078">1.5.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>