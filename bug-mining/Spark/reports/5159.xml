<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:55:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-20427] Issue with Spark interpreting Oracle datatype NUMBER</title>
                <link>https://issues.apache.org/jira/browse/SPARK-20427</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;In Oracle exists data type NUMBER. When defining a filed in a table of type NUMBER the field has two components, precision and scale.&lt;br/&gt;
For example, NUMBER(p,s) has precision p and scale s. &lt;br/&gt;
Precision can range from 1 to 38.&lt;br/&gt;
Scale can range from -84 to 127.&lt;br/&gt;
When reading such a filed Spark can create numbers with precision exceeding 38. In our case it has created fields with precision 44,&lt;br/&gt;
calculated as sum of the precision (in our case 34 digits) and the scale (10):&lt;/p&gt;

&lt;p&gt;&quot;...java.lang.IllegalArgumentException: requirement failed: Decimal precision 44 exceeds max precision 38...&quot;.&lt;/p&gt;

&lt;p&gt;The result was, that a data frame was read from a table on one schema but could not be inserted in the identical table on other schema.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13065800">SPARK-20427</key>
            <summary>Issue with Spark interpreting Oracle datatype NUMBER</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yumwang">Yuming Wang</assignee>
                                    <reporter username="alextornado">Alexander Andrushenko</reporter>
                        <labels>
                    </labels>
                <created>Fri, 21 Apr 2017 08:04:02 +0000</created>
                <updated>Sun, 20 Jun 2021 12:16:58 +0000</updated>
                            <resolved>Wed, 13 Sep 2017 23:34:59 +0000</resolved>
                                    <version>2.1.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>15</watches>
                                                                                                                <comments>
                            <comment id="15978265" author="srowen" created="Fri, 21 Apr 2017 08:06:16 +0000"  >&lt;p&gt;Are you describing an error from Oracle?&lt;/p&gt;</comment>
                            <comment id="15978270" author="alextornado" created="Fri, 21 Apr 2017 08:09:43 +0000"  >&lt;p&gt;No, I describe error from Spark.&lt;/p&gt;</comment>
                            <comment id="15978271" author="srowen" created="Fri, 21 Apr 2017 08:10:49 +0000"  >&lt;p&gt;OK, please update the description, because you say it&apos;s related to an Oracle precision limit. This needs a reproduction, if possible.&lt;/p&gt;</comment>
                            <comment id="15978283" author="alextornado" created="Fri, 21 Apr 2017 08:14:58 +0000"  >&lt;p&gt;Here is the full stacktrace of the error we have encountered:&lt;br/&gt;
java.lang.IllegalArgumentException: requirement failed: Decimal precision 44 exceeds max precision 38&lt;br/&gt;
	at scala.Predef$.require(Predef.scala:224)&lt;br/&gt;
	at org.apache.spark.sql.types.Decimal.set(Decimal.scala:113)&lt;br/&gt;
	at org.apache.spark.sql.types.Decimal$.apply(Decimal.scala:426)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$org$apache$spark$sql$execution$datasources$jdbc$JdbcUtils$$makeGetter$3$$anonfun$9.apply(JdbcUtils.scala:337)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$org$apache$spark$sql$execution$datasources$jdbc$JdbcUtils$$makeGetter$3$$anonfun$9.apply(JdbcUtils.scala:337)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.org$apache$spark$sql$execution$datasources$jdbc$JdbcUtils$$nullSafeConvert(JdbcUtils.scala:438)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$org$apache$spark$sql$execution$datasources$jdbc$JdbcUtils$$makeGetter$3.apply(JdbcUtils.scala:337)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$org$apache$spark$sql$execution$datasources$jdbc$JdbcUtils$$makeGetter$3.apply(JdbcUtils.scala:335)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:286)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anon$1.getNext(JdbcUtils.scala:268)&lt;br/&gt;
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)&lt;br/&gt;
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)&lt;br/&gt;
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)&lt;br/&gt;
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)&lt;br/&gt;
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:377)&lt;br/&gt;
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438)&lt;br/&gt;
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)&lt;br/&gt;
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:578)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$saveTable$1.apply(JdbcUtils.scala:670)&lt;br/&gt;
	at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$saveTable$1.apply(JdbcUtils.scala:670)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:925)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:925)&lt;br/&gt;
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944)&lt;br/&gt;
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1944)&lt;br/&gt;
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)&lt;br/&gt;
	at org.apache.spark.scheduler.Task.run(Task.scala:99)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;</comment>
                            <comment id="15978320" author="srowen" created="Fri, 21 Apr 2017 08:40:11 +0000"  >&lt;p&gt;What does it have to do with Oracle?&lt;br/&gt;
What code produces this decimal?&lt;/p&gt;</comment>
                            <comment id="15978451" author="ogonchar" created="Fri, 21 Apr 2017 10:20:04 +0000"  >&lt;p&gt;Hi Sean,&lt;br/&gt;
What we&apos;ve spotted is that by default Oracle&apos;s NUMBER type is translated as Decimal(38,10). And if value has no zeroes - Spark still adds those.&lt;br/&gt;
Therefore imagine you have number which is 30 digits long, e.g. = 12312321321321312312312312123. When Spark SQL (in Java) reads such value from Oracle&apos;s NUMBER column - it perceives it as 12312321321321312312312312123,0000000000 (10 zeroes). Then somehow precision is counted as 30 + 10 = 40, which is higher than specified in Decimal(38,10). Even though zeros shouldn&apos;t be counted as precision (see &lt;a href=&quot;http://stackoverflow.com/questions/35435691/bigdecimal-precision-and-scale&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://stackoverflow.com/questions/35435691/bigdecimal-precision-and-scale&lt;/a&gt;).&lt;br/&gt;
That is an issue. And the only solution we have found so far is to change Column&apos;s type to INTEGER (so that it interprets it as Decimal(38.0)). But unfortunately, we do not have a control over all of tables.&lt;/p&gt;

&lt;p&gt;Hope it clarifies&lt;/p&gt;</comment>
                            <comment id="15983440" author="smilegator" created="Tue, 25 Apr 2017 18:55:25 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tsuresh&quot; class=&quot;user-hover&quot; rel=&quot;tsuresh&quot;&gt;tsuresh&lt;/a&gt; Are you interested in this? &lt;/p&gt;</comment>
                            <comment id="16045783" author="apachespark" created="Sun, 11 Jun 2017 02:27:03 +0000"  >&lt;p&gt;User &apos;wangyum&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18266&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18266&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16156829" author="sobusiak" created="Thu, 7 Sep 2017 11:33:29 +0000"  >&lt;p&gt;You can have very big and very small numbers at the same time in Oracle&apos;s NUMBER if precision and scale is not specified.&lt;br/&gt;
Oracle documentation says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The following numbers can be stored in a NUMBER column:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Positive numbers in the range 1 x 10^-130 to 9.99...9 x 10^125 with up to 38 significant digits&lt;/li&gt;
	&lt;li&gt;Negative numbers from -1 x 10^-130 to 9.99...99 x 10^125 with up to 38 significant digits&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;As was already noted before, currently Spark throws an exception for very big numbers (like &quot;Decimal precision 61 exceeds max precision 38&quot; for 1E+50).&lt;br/&gt;
What was not noted is that it also truncates very small numbers to 0 (like 1E-50).&lt;/p&gt;

&lt;p&gt;As far as I understand you cannot fit all these numbers at the same time in &lt;tt&gt;DecimalType&lt;/tt&gt; whatever precision and scale you set. I believe the default Spark type for Oracle&apos;s NUMBER should be &lt;tt&gt;DoubleType&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Last but not least, this issue is not Oracle-specific! I have confirmed that the very same problems occur for NUMERIC of PostgreSQL. BTW, PostgreSQL documentation states explicitly:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Specifying NUMERIC without any precision or scale creates a column in which numeric values of any precision and scale can be stored, up to the implementation limit on precision. A column of this kind will not coerce input values to any particular scale, whereas numeric columns with a declared scale will coerce input values to that scale.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So basically NUMBER/NUMERIC &lt;b&gt;without&lt;/b&gt; precision and scale is very different from NUMBER/NUMERIC &lt;b&gt;with&lt;/b&gt; precision and scale.&lt;/p&gt;</comment>
                            <comment id="16156966" author="sobusiak" created="Thu, 7 Sep 2017 13:44:46 +0000"  >&lt;p&gt;As far as Oracle is concerned this is the code to blame:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; object OracleDialect &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; JdbcDialect {

  override def canHandle(url: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = url.startsWith(&lt;span class=&quot;code-quote&quot;&gt;&quot;jdbc:oracle&quot;&lt;/span&gt;)

  override def getCatalystType(
      sqlType: Int, typeName: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, size: Int, md: MetadataBuilder): Option[DataType] = {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (sqlType == Types.NUMERIC) {
      val scale = &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; != md) md.build().getLong(&lt;span class=&quot;code-quote&quot;&gt;&quot;scale&quot;&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; 0L
      size match {
        &lt;span class=&quot;code-comment&quot;&gt;// Handle NUMBER fields that have no precision/scale in special way
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// because JDBC ResultSetMetaData converts &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; to 0 precision and -127 scale
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// For more details, please see
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// https://github.com/apache/spark/pull/8780#issuecomment-145598968
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// and
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// https://github.com/apache/spark/pull/8780#issuecomment-144541760
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; 0 =&amp;gt; Option(DecimalType(DecimalType.MAX_PRECISION, 10))
        &lt;span class=&quot;code-comment&quot;&gt;// Handle FLOAT fields in a special way because JDBC ResultSetMetaData converts
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; to NUMERIC with -127 scale
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// Not sure &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; there is a more robust way to identify the field as a &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt; (or other
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// numeric types that &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; not specify a scale.
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; scale == -127L =&amp;gt; Option(DecimalType(DecimalType.MAX_PRECISION, 10))
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; None
      }
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      None
    }
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16529005" author="orichard" created="Sun, 1 Jul 2018 07:51:25 +0000"  >&lt;p&gt;I&apos;m still getting the same problem even in newest version!.&lt;/p&gt;</comment>
                            <comment id="16529013" author="q79969786" created="Sun, 1 Jul 2018 08:25:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ORichard&quot; class=&quot;user-hover&quot; rel=&quot;ORichard&quot;&gt;ORichard&lt;/a&gt;. Please try to use &lt;tt&gt;customSchema&lt;/tt&gt; to specifying the custom data types of the read schema.  &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/v2.3.1/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala#L197&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v2.3.1/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala#L197&lt;/a&gt;&lt;/p&gt;

</comment>
                            <comment id="16942090" author="zwu.net@gmail.com" created="Tue, 1 Oct 2019 15:48:12 +0000"  >&lt;p&gt;Some one asked me this problem months ago and I found a solution for him , but I forgot the solution when another one in my team asked me again yesterday. I had to spend several hours on this since her query was quite complex.&#160; For a record and my own reference, I would like to put the solution&#160; here (inspired by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sobusiak&quot; class=&quot;user-hover&quot; rel=&quot;sobusiak&quot;&gt;sobusiak&lt;/a&gt;&#160; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt; ):&#160; Add the customSchema option after the read() that specifies all potential trouble makers as Double types.&#160; It can probably resolve most cases in real applications.&#160; Surely, this is supposed that one does not particularly concern about the exact significant digits in his/her applications.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
.read()
.option(&lt;span class=&quot;code-quote&quot;&gt;&quot;customSchema&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;col1 &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;, col2 &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;&quot;&lt;/span&gt;) &lt;span class=&quot;code-comment&quot;&gt;//where col1, col2... are columns that could cause the trouble.
&lt;/span&gt;    
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;Also, some may think their issues come from the .write() operation, but the issues are in fact from the .read() operation. The col1, col2...column names are not necessarily from the original tables. They could be the calculated fields for output in the queries. &#160; One could mistakenly bark at a wrong place to try to fix the issues. &lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17054482" author="sunayansaikia" created="Sun, 8 Mar 2020 18:04:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt; &lt;br/&gt;
Seems this fix broke the way we could get the column name with the&#160;&lt;em&gt;&apos;name&apos;&lt;/em&gt;&#160; key via the MetadataBuiler map inside&#160;getCatalystType()&lt;br/&gt;
 Is there a way I could get the column name now while I&apos;m overriding the getCatalystType() method?&lt;/p&gt;

&lt;p&gt;Please check the Java code below for which things broke.&lt;br/&gt;
 public Option&amp;lt;DataType&amp;gt; getCatalystType(int sqlJdbcType, String typeName, int size, MetadataBuilder md) {&lt;br/&gt;
 String columnName = String.valueOf(md.getMap().get(&quot;name&quot;).get());&lt;/p&gt;</comment>
                            <comment id="17076114" author="sunayansaikia" created="Mon, 6 Apr 2020 08:06:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt;: Hi - sorry to bug again but any solution to the things I asked above? I&apos;m kind of blocked for one of my use cases.&lt;/p&gt;</comment>
                            <comment id="17107376" author="kyrdan" created="Thu, 14 May 2020 14:49:23 +0000"  >&lt;p&gt;Hey guys,&#160;&lt;br/&gt;
 I encountered an issue related to precision issues.&lt;/p&gt;

&lt;p&gt;Now the code expects the Decimal type we need to have in&#160;JDBC metadata precision and scale.&#160;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils.scala#L402-L414&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils.scala#L402-L414&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I found out that in the OracleDB it is valid to have Decimal without these data. When I do a query read metadata for such column I&apos;m getting DATA_PRECISION = Null, and DATA_SCALE = Null.&lt;/p&gt;

&lt;p&gt;Then when I run the `spark-sql` I&apos;m getting such error:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
java.lang.IllegalArgumentException: requirement failed: Decimal precision 45 exceeds max precision 38
        at scala.Predef$.require(Predef.scala:224)
        at org.apache.spark.sql.types.Decimal.set(Decimal.scala:114)
        at org.apache.spark.sql.types.Decimal$.apply(Decimal.scala:465)
        at org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$$anonfun$org$apache$spark$sql$execution$datasources$jdbc$JdbcUtils$$makeGetter$3$$anonfun$12.apply(JdbcUtils.scala:407)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Do you have a work around how spark-sql can work with such cases?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;UPDATE:&lt;/p&gt;

&lt;p&gt;Solved with the custom scheme.&lt;/p&gt;</comment>
                            <comment id="17163288" author="abhijitcaps" created="Thu, 23 Jul 2020 07:38:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Kyrdan&quot; class=&quot;user-hover&quot; rel=&quot;Kyrdan&quot;&gt;Kyrdan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Can you explain your implementation ?&lt;/p&gt;

&lt;p&gt;Have you used custom&#160;JdbcDialect&#160; or OracleDialect ?&lt;/p&gt;</comment>
                            <comment id="17366173" author="sgejun" created="Sun, 20 Jun 2021 12:02:31 +0000"  >&lt;p&gt;When you use custom scheme, problem solved according to my test.&#160;&lt;/p&gt;

&lt;p&gt;But spark&apos;s max precision 38 seems still have some gap with oracle. For oracle, I believe there could be 39-40 for 10g version.&lt;/p&gt;

&lt;p&gt;From oracle document.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;p is the precision, or the maximum number of significant decimal digits, where the most significant digit is the left-most nonzero digit, and the least significant digit is the right-most known digit. Oracle guarantees the portability of numbers with precision of up to 20 base-100 digits, which is equivalent to 39 or 40 decimal digits depending on the position of the decimal point.&lt;/em&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                            <outwardlinks description="contains">
                                        <issuelink>
            <issuekey id="13075789">SPARK-20921</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13102137">SPARK-22002</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 21 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3dx07:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>