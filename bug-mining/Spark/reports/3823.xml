<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:45:55 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16613] RDD.pipe returns values for empty partitions</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16613</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Suppose we have such Spark code&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;object PipeExample {
  def main(args: Array[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;]) {

    val fstRdd = sc.parallelize(List(&lt;span class=&quot;code-quote&quot;&gt;&quot;hi&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;hello&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;how&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;are&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;you&quot;&lt;/span&gt;))
    val pipeRdd = fstRdd.pipe(&lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/finkel/spark-pipe-example/src/main/resources/len.sh&quot;&lt;/span&gt;)

    pipeRdd.collect.foreach(println)
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It uses a bash script to convert a string to its length.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;#!/bin/sh
read input
len=${#input}
echo $len
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So far so good, but when I run the code, it prints incorrect output. For example:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;0
2
0
5
3
0
3
3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I expect to see&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2
5
3
3
3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which is correct output for the app. I think it&apos;s a bug. It&apos;s expected to see only positive integers and avoid zeros.&lt;/p&gt;

&lt;p&gt;Environment:&lt;/p&gt;

&lt;p&gt;1. Spark version is 1.6.2&lt;br/&gt;
2. Scala version is 2.11.6&lt;/p&gt;</description>
                <environment></environment>
        <key id="12990565">SPARK-16613</key>
            <summary>RDD.pipe returns values for empty partitions</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="finkel">Alex Krasnyansky</reporter>
                        <labels>
                    </labels>
                <created>Mon, 18 Jul 2016 21:37:03 +0000</created>
                <updated>Wed, 20 Jul 2016 16:49:00 +0000</updated>
                            <resolved>Wed, 20 Jul 2016 16:49:00 +0000</resolved>
                                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15383630" author="dongjoon" created="Tue, 19 Jul 2016 06:08:05 +0000"  >&lt;p&gt;Thank you for amazingly clean reporting. I could easily regenerate that. In 1.6 branch, the problem still exists. In the current master, I experienced `StackOverflowError`.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; val fstRdd = sc.parallelize(List(&lt;span class=&quot;code-quote&quot;&gt;&quot;hi&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;hello&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;how&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;are&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;you&quot;&lt;/span&gt;))
fstRdd: org.apache.spark.rdd.RDD[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;] = ParallelCollectionRDD[0] at parallelize at &amp;lt;console&amp;gt;:24

scala&amp;gt; val pipeRdd = fstRdd.pipe(&lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/dongjoon/spark/len.sh&quot;&lt;/span&gt;)
java.lang.StackOverflowError
  at com.fasterxml.jackson.databind.deser.impl.PropertyBasedCreator.startBuilding(PropertyBasedCreator.java:130)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;It&apos;s not final investigation, but it&apos;s worth to look inside.&lt;/p&gt;</comment>
                            <comment id="15383687" author="proflin" created="Tue, 19 Jul 2016 07:04:12 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=finkel&quot; class=&quot;user-hover&quot; rel=&quot;finkel&quot;&gt;finkel&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;, I think this relates to how many partitions we&apos;ll get after we &lt;tt&gt;sc.parallelize(...)&lt;/tt&gt;.&lt;br/&gt;
For instance, &lt;tt&gt;sc.parallelize(..., 5)&lt;/tt&gt; produces:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2
5
3
3
3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;tt&gt;sc.parallelize(..., 8)&lt;/tt&gt; produces:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;0
2
0
5
3
0
3
3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And be careful, &lt;tt&gt;sc.parallelize(..., 1)&lt;/tt&gt; produces only:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15383691" author="dongjoon" created="Tue, 19 Jul 2016 07:07:15 +0000"  >&lt;p&gt;Oh. Thank you for analysis!&lt;/p&gt;</comment>
                            <comment id="15383694" author="dongjoon" created="Tue, 19 Jul 2016 07:08:10 +0000"  >&lt;p&gt;Then, it seems not a bug in 1.6.2.&lt;/p&gt;</comment>
                            <comment id="15383700" author="proflin" created="Tue, 19 Jul 2016 07:17:24 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;, at about the same time we reproduced the &lt;tt&gt;StackOverflowError&lt;/tt&gt; from &lt;tt&gt;RDD.pipe()&lt;/tt&gt;, &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
And besides that stack overflow, &lt;tt&gt;RDD.pipe(String)&lt;/tt&gt; also doesn&apos;t work with commands with options like &quot;wc -l&quot; in 2.0, so I filed &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16620&quot; title=&quot;RDD.pipe(command: String) in Spark 2.0 does not work when command is specified with some options&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-16620&quot;&gt;&lt;del&gt;SPARK-16620&lt;/del&gt;&lt;/a&gt; aiming to fix both issues.&lt;/p&gt;</comment>
                            <comment id="15383714" author="dongjoon" created="Tue, 19 Jul 2016 07:26:41 +0000"  >&lt;p&gt;Yep. I thought so. You&apos;re very fast! Great.&lt;/p&gt;</comment>
                            <comment id="15383836" author="srowen" created="Tue, 19 Jul 2016 09:11:27 +0000"  >&lt;p&gt;Interesting, I think an issue here is that the semantics of RDD.pipe() are unclear. Input and output are RDD&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;, and it seems like each element of the output must be stdout of running the command on a single input element.&lt;/p&gt;

&lt;p&gt;In reality, the process is run once per partition, and each input element is sent to the stdin, separated by newlines. The lines of the output are parsed as the output of the partition &amp;#8211; which means that a process which outputs many lines of output results in many elements of the RDD.&lt;/p&gt;

&lt;p&gt;Right now, the process is still invoked for an empty partition, and for this script, correctly results in &quot;0&quot;.&lt;/p&gt;

&lt;p&gt;The docs do say &quot;pipes elements to an external process&quot; which sort of implies the current behavior.&lt;/p&gt;

&lt;p&gt;I think we should, in any event, clarify docs and probably also modify the behavior to output nothing for an empty partition &amp;#8211; not even the result of the process when presented with no input.&lt;/p&gt;

&lt;p&gt;I&apos;m reluctant to change the semantics of the method to run one process per input, even if that strikes me as more logical. This means we&apos;re kind of stuck with this problem that it&apos;s not necessarily possible to match outputs 1:1 with inputs, but that&apos;s just a constraint on the type of command you can use with this I guess.&lt;/p&gt;

&lt;p&gt;CC &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrewor14&quot; class=&quot;user-hover&quot; rel=&quot;andrewor14&quot;&gt;andrewor14&lt;/a&gt; if available, but moreso &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tejasp&quot; class=&quot;user-hover&quot; rel=&quot;tejasp&quot;&gt;tejasp&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15383937" author="apachespark" created="Tue, 19 Jul 2016 10:49:04 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14260&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14260&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15384623" author="rxin" created="Tue, 19 Jul 2016 18:14:15 +0000"  >&lt;p&gt;After thinking about this more I don&apos;t think we should break the old semantics. We can document it though&lt;/p&gt;</comment>
                            <comment id="15385235" author="tejasp" created="Wed, 20 Jul 2016 03:05:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; , &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt; : I feel that invoking the pipe command even for empty partitions is bad. Users should be exposed to Spark partitions. Leaving the existing behavior as it is might mean that if number of partitions change OR partitioning scheme changes, the results generated for the same input data can differ. This might be annoying. One would expect Spark&apos;s behavior to be same as running the pipe command in standalone way over terminal in which case there won&apos;t be any empty partitions as partition is a Spark internal concept.&lt;/p&gt;

&lt;p&gt;Hive&apos;s ScriptOperator invokes the user binary only when it sees a row : &lt;a href=&quot;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java#L339&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/exec/ScriptOperator.java#L339&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Spark&apos;s ScriptTransformation as well follows the same convention:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformation.scala#L244&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/ScriptTransformation.scala#L244&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15385350" author="rxin" created="Wed, 20 Jul 2016 05:13:38 +0000"  >&lt;p&gt;But the problem of result changing depending on partitioning always exist &amp;#8211; it is there because how the underlying commands are handling the inputs; it&apos;s not there because Spark calls the command based on the input. &lt;/p&gt;

&lt;p&gt;We can add a flag to control it if we really want that behavior.&lt;/p&gt;</comment>
                            <comment id="15385552" author="srowen" created="Wed, 20 Jul 2016 08:43:36 +0000"  >&lt;p&gt;Yeah it&apos;s a tough call. The current behavior is at least consistent: entirely partition-oriented, one process per partition exactly, always. I agree it&apos;s not quite what I&apos;d expect, but maybe the first thing we can do now is at least update the docs without changing the behavior.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12990657">SPARK-16620</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 17 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i315zj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>