<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:52:57 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-12868] ADD JAR via sparkSQL JDBC will fail when using a HDFS URL</title>
                <link>https://issues.apache.org/jira/browse/SPARK-12868</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When trying to add a jar with a HDFS URI, i.E&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;ADD&lt;/span&gt; JAR hdfs:///tmp/foo.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Via the spark sql JDBC interface it will fail with:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;java.net.MalformedURLException: &lt;span class=&quot;code-keyword&quot;&gt;unknown&lt;/span&gt; protocol: hdfs
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.net.URL.&amp;lt;init&amp;gt;(URL.java:593)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.net.URL.&amp;lt;init&amp;gt;(URL.java:483)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.net.URL.&amp;lt;init&amp;gt;(URL.java:432)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.net.URI.toURL(URI.java:1089)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.hive.client.ClientWrapper.addJar(ClientWrapper.scala:578)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.hive.HiveContext.addJar(HiveContext.scala:652)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.hive.execution.AddJar.run(commands.scala:89)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:58)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.execution.ExecutedCommand.sideEffectResult(commands.scala:56)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.execution.ExecutedCommand.doExecute(commands.scala:70)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.execution.SparkPlan$$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;execute&lt;/span&gt;$5.apply(SparkPlan.scala:132)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.execution.SparkPlan$$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;execute&lt;/span&gt;$5.apply(SparkPlan.scala:130)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.execution.SparkPlan.&lt;span class=&quot;code-keyword&quot;&gt;execute&lt;/span&gt;(SparkPlan.scala:130)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:55)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.execution.QueryExecution.toRdd(QueryExecution.scala:55)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.DataFrame.&amp;lt;init&amp;gt;(DataFrame.scala:145)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.DataFrame.&amp;lt;init&amp;gt;(DataFrame.scala:130)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.DataFrame$.apply(DataFrame.scala:52)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.SQLContext.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;(SQLContext.scala:817)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;$hive$thriftserver$SparkExecuteStatementOperation$$&lt;span class=&quot;code-keyword&quot;&gt;execute&lt;/span&gt;(SparkExecuteStatementOperation.scala:211)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.hive.thriftserver.SparkExecuteStatementOperation$$anon$1$$anon$2.run(SparkExecuteStatementOperation.scala:154)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.hive.thriftserver.SparkExecuteStatementOperation$$anon$1$$anon$2.run(SparkExecuteStatementOperation.scala:151)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.&lt;span class=&quot;code-keyword&quot;&gt;security&lt;/span&gt;.AccessController.doPrivileged(Native &lt;span class=&quot;code-keyword&quot;&gt;Method&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; javax.&lt;span class=&quot;code-keyword&quot;&gt;security&lt;/span&gt;.auth.Subject.doAs(Subject.java:422)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.hadoop.&lt;span class=&quot;code-keyword&quot;&gt;security&lt;/span&gt;.UserGroupInformation.doAs(UserGroupInformation.java:1628)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; org.apache.spark.&lt;span class=&quot;code-keyword&quot;&gt;sql&lt;/span&gt;.hive.thriftserver.SparkExecuteStatementOperation$$anon$1.run(SparkExecuteStatementOperation.scala:164)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.util.concurrent.Executors$RunnableAdapter.&lt;span class=&quot;code-keyword&quot;&gt;call&lt;/span&gt;(Executors.java:511)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.util.concurrent.FutureTask.run(FutureTask.java:266)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        &lt;span class=&quot;code-keyword&quot;&gt;at&lt;/span&gt; java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12931808">SPARK-12868</key>
            <summary>ADD JAR via sparkSQL JDBC will fail when using a HDFS URL</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="WeiqingYang">Weiqing Yang</assignee>
                                    <reporter username="tleftwich">Trystan Leftwich</reporter>
                        <labels>
                    </labels>
                <created>Sun, 17 Jan 2016 21:33:39 +0000</created>
                <updated>Fri, 1 Nov 2019 19:27:45 +0000</updated>
                            <resolved>Wed, 26 Apr 2017 20:56:03 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>6</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="15103935" author="apachespark" created="Sun, 17 Jan 2016 21:38:02 +0000"  >&lt;p&gt;User &apos;trystanleftwich&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10797&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10797&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15128443" author="apachespark" created="Tue, 2 Feb 2016 16:00:05 +0000"  >&lt;p&gt;User &apos;trystanleftwich&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11026&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11026&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15128445" author="tleftwich" created="Tue, 2 Feb 2016 16:00:58 +0000"  >&lt;p&gt;Added:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11026&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11026&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;specifically for branch 1.6&lt;/p&gt;

&lt;p&gt;and updated:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10797&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10797&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;to be up to date with master.&lt;/p&gt;

</comment>
                            <comment id="15428519" author="apachespark" created="Fri, 19 Aug 2016 17:43:10 +0000"  >&lt;p&gt;User &apos;Parth-Brahmbhatt&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14720&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14720&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15931351" author="apachespark" created="Sat, 18 Mar 2017 19:26:07 +0000"  >&lt;p&gt;User &apos;weiqingy&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17342&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17342&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16049814" author="dyzhou" created="Wed, 14 Jun 2017 23:39:02 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tleftwich&quot; class=&quot;user-hover&quot; rel=&quot;tleftwich&quot;&gt;tleftwich&lt;/a&gt; and all,&lt;br/&gt;
I was using Spark 2.0 and when I tried to invoke Hive UDTF, I got the following error:&lt;/p&gt;

&lt;p&gt;Undefined function: &apos;...&apos;. This function is neither a registered temporary function nor a permanent function registered in the database &apos;default&apos;.; &lt;/p&gt;

&lt;p&gt;Then I picked up Spark 2.2 with this fix and the above error went away, which is good.  However, when I tried to create new UDTFs and invoke them, I again ran into the above error.  Any idea why?  Any help appreciated.&lt;/p&gt;</comment>
                            <comment id="16065448" author="stevel@apache.org" created="Tue, 27 Jun 2017 20:54:36 +0000"  >&lt;p&gt;I think this is the case of &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-14598&quot; title=&quot;Blacklist Http/HttpsFileSystem in FsUrlStreamHandlerFactory&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-14598&quot;&gt;&lt;del&gt;HADOOP-14598&lt;/del&gt;&lt;/a&gt;: once the FS has been set to &lt;tt&gt;FsUrlStreamHandlerFactory&lt;/tt&gt; in &lt;tt&gt;org.apache.spark.sql.internal.SharedState&lt;/tt&gt;, you can&apos;t talk to Azure. &lt;/p&gt;</comment>
                            <comment id="16068301" author="stevel@apache.org" created="Thu, 29 Jun 2017 13:03:50 +0000"  >&lt;p&gt;It&apos;s actually not the cause of that, merely the messenger. Cause is &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-14383&quot; title=&quot;Implement FileSystem that reads from HTTP / HTTPS endpoints&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-14383&quot;&gt;&lt;del&gt;HADOOP-14383&lt;/del&gt;&lt;/a&gt;: a combination of spark 2.2 &amp;amp; Hadoop 2.9+ will trigger the problem. Fix belongs in Hadoop.&lt;/p&gt;</comment>
                            <comment id="16123192" author="stevel@apache.org" created="Fri, 11 Aug 2017 11:11:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-21697&quot; title=&quot;NPE &amp;amp; ExceptionInInitializerError trying to load UDF from HDFS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-21697&quot;&gt;&lt;del&gt;SPARK-21697&lt;/del&gt;&lt;/a&gt;: harder than it would initially seem&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13028860">SPARK-18910</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13093901">SPARK-21697</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13082920">HADOOP-14598</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13190500">SPARK-25694</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 14 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2rkyv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>