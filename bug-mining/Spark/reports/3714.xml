<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:45:09 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-15725] Dynamic allocation hangs YARN app when executors time out</title>
                <link>https://issues.apache.org/jira/browse/SPARK-15725</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We&apos;ve had a problem with a dynamic allocation and YARN (since 1.6) where a large stage will cause a lot of executors to get killed around the same time, causing the driver and AM to lock up and wait forever. This can happen even with a small number of executors (~100).&lt;/p&gt;

&lt;p&gt;When executors are killed by the driver, the &lt;a href=&quot;https://github.com/apache/spark/blob/master/yarn/src/main/scala/org/apache/spark/scheduler/cluster/YarnSchedulerBackend.scala#L201&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;network connection to the driver disconnects&lt;/a&gt;. That results in a call to the AM to find out why the executor died, followed by a &lt;a href=&quot;https://github.com/apache/spark/blob/master/yarn/src/main/scala/org/apache/spark/scheduler/cluster/YarnSchedulerBackend.scala#L227&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;blocking and retrying `RemoveExecutor` RPC call&lt;/a&gt; that results in a second `KillExecutor` call to the AM. When a lot of executors are killed around the same time, the driver&apos;s AM threads are all taken up blocking and waiting on the AM (see the stack trace below, which was the same for 42 threads). I think this behavior, the network disconnect and subsequent cleanup, is unique to YARN.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;Driver AM thread stack&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sun.misc.Unsafe.park(Native Method)
java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)
java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:208)
scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:218)
scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
scala.concurrent.Await$$anonfun$result$1.apply(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:190)
scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53)
scala.concurrent.Await$.result(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:190)
org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:81)
org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:102)
org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:78)
org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply$mcV$sp(YarnSchedulerBackend.scala:286)
org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(YarnSchedulerBackend.scala:286)
org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(YarnSchedulerBackend.scala:286)
scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The RPC calls to the AM aren&apos;t returning because the `YarnAllocator` is spending all of its time in the `allocateResources` method. That class&apos;s public methods are synchronized so only one RPC can be satisfied at a time. The reason why it is constantly calling `allocateResources` is because &lt;a href=&quot;https://github.com/apache/spark/blob/master/yarn/src/main/scala/org/apache/spark/deploy/yarn/ApplicationMaster.scala#L467&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;its thread&lt;/a&gt; is &lt;a href=&quot;https://github.com/apache/spark/blob/master/yarn/src/main/scala/org/apache/spark/deploy/yarn/ApplicationMaster.scala#L686&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;woken up&lt;/a&gt; by calls to get the failure reason for an executor &amp;#8211; which is part of the chain of events in the driver for each executor that goes down.&lt;/p&gt;

&lt;p&gt;The final result is that the `YarnAllocator` doesn&apos;t respond to RPC calls for long enough that calls time out and replies for non-blocking calls are dropped. Then the application is unable to do any work because everything retries or exits and the application &lt;b&gt;hangs for 24+ hours&lt;/b&gt;, until enough errors accumulate that it dies.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12975006">SPARK-15725</key>
            <summary>Dynamic allocation hangs YARN app when executors time out</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rdblue">Ryan Blue</assignee>
                                    <reporter username="rdblue">Ryan Blue</reporter>
                        <labels>
                    </labels>
                <created>Thu, 2 Jun 2016 01:34:10 +0000</created>
                <updated>Thu, 22 Dec 2016 08:03:16 +0000</updated>
                            <resolved>Thu, 23 Jun 2016 18:55:28 +0000</resolved>
                                    <version>1.6.1</version>
                    <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="15311567" author="rdblue" created="Thu, 2 Jun 2016 01:40:19 +0000"  >&lt;p&gt;I&apos;m linking to a work-around that ensures the AM thread that drives the YarnAllocator sleeps its minimum interval. While there are still problems because of the YarnAllocator&apos;s locking strategy and the driver threads waiting on a kill RPC to the AM, this avoids calling &lt;tt&gt;allocateResources&lt;/tt&gt; too often and the calls return quickly enough that the application can progress.&lt;/p&gt;

&lt;p&gt;The logs from running with this patch confirm that the allocator is called too often:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;&quot;&gt;&lt;b&gt;AM log with work-around&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;16/06/01 18:30:42 INFO yarn.ApplicationMaster$AMEndpoint: Driver requested to kill executor(s) 24.
16/06/01 18:30:50 INFO yarn.YarnAllocator: Driver requested a total number of 266 executor(s).
16/06/01 18:30:50 INFO yarn.ApplicationMaster: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of pending allocations is 0. Slept &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 1/3000.
16/06/01 18:30:50 INFO yarn.ApplicationMaster: Going back to sleep &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 199 ms
16/06/01 18:30:50 INFO yarn.ApplicationMaster$AMEndpoint: Driver requested to kill executor(s) 134.
16/06/01 18:30:50 INFO yarn.YarnAllocator: Driver requested a total number of 265 executor(s).
16/06/01 18:30:50 INFO yarn.ApplicationMaster$AMEndpoint: Driver requested to kill executor(s) 74.
16/06/01 18:30:50 INFO yarn.YarnAllocator: Driver requested a total number of 264 executor(s).
16/06/01 18:30:50 INFO yarn.ApplicationMaster$AMEndpoint: Driver requested to kill executor(s) 89.
16/06/01 18:30:50 INFO yarn.YarnAllocator: Driver requested a total number of 263 executor(s).
16/06/01 18:30:50 INFO yarn.ApplicationMaster$AMEndpoint: Driver requested to kill executor(s) 122.
16/06/01 18:30:50 INFO yarn.YarnAllocator: Driver requested a total number of 262 executor(s).
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15313285" author="apachespark" created="Thu, 2 Jun 2016 23:22:04 +0000"  >&lt;p&gt;User &apos;rdblue&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/13482&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/13482&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15769384" author="jinxing6042@126.com" created="Thu, 22 Dec 2016 07:46:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=blue%40cloudera.com&quot; class=&quot;user-hover&quot; rel=&quot;blue@cloudera.com&quot;&gt;blue@cloudera.com&lt;/a&gt;&lt;br/&gt;
My spark version is 1.6.2; May I ask two questions?&lt;br/&gt;
1. &quot;a large stage will cause a lot of executors to get killed around the same time&quot;: &lt;br/&gt;
    Lots of executors are killed because they are idle for over &quot;spark.dynamicAllocation.executorIdleTimeout&quot; seconds, am I right?&lt;/p&gt;

&lt;p&gt;2. &quot; That results in a call to the AM to find out why the executor died, followed by a blocking and retrying `RemoveExecutor` RPC call that results in a second `KillExecutor` call to the AM.&quot;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;YarnSchedulerBackend.scala&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    val &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; = am.ask[ExecutorLossReason](lossReasonRequest, askTimeout)
    &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; onSuccess {
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; reason: ExecutorLossReason =&amp;gt; {
            driverEndpoint.askWithRetry[&lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;](RemoveExecutor(executorId, reason))
        }
    }
    &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; onFailure {
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; NonFatal(e) =&amp;gt; {
            logWarning(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Attempted to get executor loss reason&quot;&lt;/span&gt; +
                s&lt;span class=&quot;code-quote&quot;&gt;&quot; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; executor id ${executorId} at RPC address ${executorRpcAddress},&quot;&lt;/span&gt; +
                s&lt;span class=&quot;code-quote&quot;&gt;&quot; but got no response. Marking as slave lost.&quot;&lt;/span&gt;, e)
            driverEndpoint.askWithRetry[&lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;](RemoveExecutor(executorId, SlaveLost()))
        }
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; t =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; t
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;    If ExecutorLossReason request are timeout, it will go to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;driverEndpoint.askWithRetry[&lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;](RemoveExecutor(executorId, SlaveLost()))&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;    My question is why and how it will result in a second &apos;KillExecutor&apos; ?&lt;br/&gt;
    It&apos;s great if you can reply~&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 47 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2yv2n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>