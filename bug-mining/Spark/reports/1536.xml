<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:24:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-6136] Docker client library introduces Guava 17.0, which causes runtime binary incompatibilities</title>
                <link>https://issues.apache.org/jira/browse/SPARK-6136</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Integration test suites in the JDBC data source (&lt;tt&gt;MySQLIntegration&lt;/tt&gt; and &lt;tt&gt;PostgresIntegration&lt;/tt&gt;) depend on docker-client 2.7.5, which transitively depends on Guava 17.0. Unfortunately, Guava 17.0 is causing runtime binary incompatibility issues when Spark is compiled against Hadoop 2.4.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ ./build/sbt -Pyarn,hadoop-2.4,hive,hive-0.12.0,scala-2.10 -Dhadoop.version=2.4.1
...
&amp;gt; sql/test-only *.ParquetDataSourceOffIOSuite
...
[info] ParquetDataSourceOffIOSuite:
[info] Exception encountered when attempting to run a suite with &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;name: org.apache.spark.sql.parquet.ParquetDataSourceOffIOSuite *** ABORTED *** (134 milliseconds)
[info]   java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.&amp;lt;init&amp;gt;()V from &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.mapreduce.lib.input.FileInputFormat
[info]   at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:261)
[info]   at parquet.hadoop.ParquetInputFormat.listStatus(ParquetInputFormat.java:277)
[info]   at org.apache.spark.sql.parquet.FilteringParquetRowInputFormat.getSplits(ParquetTableOperations.scala:437)
[info]   at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:95)
[info]   at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)
[info]   at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)
[info]   at scala.Option.getOrElse(Option.scala:120)
[info]   at org.apache.spark.rdd.RDD.partitions(RDD.scala:217)
[info]   at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:32)
[info]   at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)
[info]   at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)
[info]   at scala.Option.getOrElse(Option.scala:120)
[info]   at org.apache.spark.rdd.RDD.partitions(RDD.scala:217)
[info]   at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:32)
[info]   at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:219)
[info]   at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:217)
[info]   at scala.Option.getOrElse(Option.scala:120)
[info]   at org.apache.spark.rdd.RDD.partitions(RDD.scala:217)
[info]   at org.apache.spark.SparkContext.runJob(SparkContext.scala:1525)
[info]   at org.apache.spark.rdd.RDD.collect(RDD.scala:813)
[info]   at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:83)
[info]   at org.apache.spark.sql.DataFrame.collect(DataFrame.scala:797)
[info]   at org.apache.spark.sql.QueryTest$.checkAnswer(QueryTest.scala:115)
[info]   at org.apache.spark.sql.QueryTest.checkAnswer(QueryTest.scala:60)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase$$anonfun$checkParquetFile$1.apply(ParquetIOSuite.scala:76)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase$$anonfun$checkParquetFile$1.apply(ParquetIOSuite.scala:76)
[info]   at org.apache.spark.sql.parquet.ParquetTest$$anonfun$withParquetDataFrame$1.apply(ParquetTest.scala:105)
[info]   at org.apache.spark.sql.parquet.ParquetTest$$anonfun$withParquetDataFrame$1.apply(ParquetTest.scala:105)
[info]   at org.apache.spark.sql.parquet.ParquetTest$$anonfun$withParquetFile$1.apply(ParquetTest.scala:94)
[info]   at org.apache.spark.sql.parquet.ParquetTest$$anonfun$withParquetFile$1.apply(ParquetTest.scala:92)
[info]   at org.apache.spark.sql.parquet.ParquetTest$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;withTempPath(ParquetTest.scala:71)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase.withTempPath(ParquetIOSuite.scala:67)
[info]   at org.apache.spark.sql.parquet.ParquetTest$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;withParquetFile(ParquetTest.scala:92)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase.withParquetFile(ParquetIOSuite.scala:67)
[info]   at org.apache.spark.sql.parquet.ParquetTest$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;withParquetDataFrame(ParquetTest.scala:105)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase.withParquetDataFrame(ParquetIOSuite.scala:67)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase.checkParquetFile(ParquetIOSuite.scala:76)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase$$anonfun$1.apply$mcV$sp(ParquetIOSuite.scala:83)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase$$anonfun$1.apply(ParquetIOSuite.scala:79)
[info]   at org.apache.spark.sql.parquet.ParquetIOSuiteBase$$anonfun$1.apply(ParquetIOSuite.scala:79)
[info]   at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
[info]   at org.scalatest.OutcomeOf$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;outcomeOf(OutcomeOf.scala:85)
[info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
[info]   at org.scalatest.Transformer.apply(Transformer.scala:22)
[info]   at org.scalatest.Transformer.apply(Transformer.scala:20)
[info]   at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
[info]   at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;withFixture(Suite.scala:1122)
[info]   at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
[info]   at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;invokeWithFixture$1(FunSuiteLike.scala:163)
[info]   at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
[info]   at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
[info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
[info]   at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runTest(FunSuiteLike.scala:175)
[info]   at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
[info]   at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
[info]   at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
[info]   at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
[info]   at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
[info]   at scala.collection.immutable.List.foreach(List.scala:318)
[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
[info]   at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
[info]   at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runTests(FunSuiteLike.scala:208)
[info]   at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
[info]   at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(Suite.scala:1424)
[info]   at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(FunSuite.scala:1555)
[info]   at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
[info]   at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
[info]   at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(FunSuiteLike.scala:212)
[info]   at org.apache.spark.sql.parquet.ParquetDataSourceOffIOSuite.org$scalatest$BeforeAndAfterAll$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(ParquetIOSuite.scala:346)
[info]   at org.scalatest.BeforeAndAfterAll$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;liftedTree1$1(BeforeAndAfterAll.scala:257)
[info]   at org.scalatest.BeforeAndAfterAll$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(BeforeAndAfterAll.scala:256)
[info]   at org.apache.spark.sql.parquet.ParquetDataSourceOffIOSuite.run(ParquetIOSuite.scala:346)
[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:462)
[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:671)
[info]   at sbt.ForkMain$Run$2.call(ForkMain.java:294)
[info]   at sbt.ForkMain$Run$2.call(ForkMain.java:284)
[info]   at java.util.concurrent.FutureTask.run(FutureTask.java:266)
[info]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
[info]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
[info]   at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is because the default constructor of &lt;tt&gt;Stopwatch&lt;/tt&gt; is no longer public in Guava 17.0.&lt;/p&gt;

&lt;p&gt;Compiling Spark against Hive 0.12.0 also introduces other types of runtime binary incompatibility issue.&lt;/p&gt;

&lt;p&gt;Considering &lt;tt&gt;MySQLIntegration&lt;/tt&gt; and &lt;tt&gt;PostgresIntegration&lt;/tt&gt; are ignored right now, I&apos;d suggest moving them from the Spark project to the &lt;span class=&quot;error&quot;&gt;&amp;#91;Spark integration tests||https://github.com/databricks/spark-integration-tests&amp;#93;&lt;/span&gt; project.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12778987">SPARK-6136</key>
            <summary>Docker client library introduces Guava 17.0, which causes runtime binary incompatibilities</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lian cheng">Cheng Lian</assignee>
                                    <reporter username="lian cheng">Cheng Lian</reporter>
                        <labels>
                    </labels>
                <created>Tue, 3 Mar 2015 09:06:41 +0000</created>
                <updated>Tue, 11 Aug 2015 10:04:08 +0000</updated>
                            <resolved>Wed, 4 Mar 2015 11:41:15 +0000</resolved>
                                    <version>1.3.0</version>
                                    <fixVersion>1.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="14344791" author="apachespark" created="Tue, 3 Mar 2015 09:19:01 +0000"  >&lt;p&gt;User &apos;liancheng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4872&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4872&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14681561" author="apachespark" created="Tue, 11 Aug 2015 10:04:08 +0000"  >&lt;p&gt;User &apos;yjshen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8101&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8101&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 15 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i26a27:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12327642">1.3.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>