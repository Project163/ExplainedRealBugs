<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:50:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16975] Spark-2.0.0 unable to infer schema for parquet data written by Spark-1.6.2</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16975</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Spark-2.0.0 seems to have some problems reading a parquet dataset generated by 1.6.2. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [80]: spark.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&apos;/path/to/data&apos;&lt;/span&gt;)
...
AnalysisException: u&lt;span class=&quot;code-quote&quot;&gt;&apos;Unable to infer schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ParquetFormat at /path/to/data. It must be specified manually;&apos;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The dataset is ~150G and partitioned by _locality_code column. None of the partitions are empty. I have narrowed the failing dataset to the first 32 partitions of the data:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [82]: spark.read.parquet(*subdirs[:32])
...
AnalysisException: u&lt;span class=&quot;code-quote&quot;&gt;&apos;Unable to infer schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ParquetFormat at /path/to/data/_locality_code=AQ,/path/to/data/_locality_code=AI. It must be specified manually;&apos;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Interestingly, it works OK if you remove any of the partitions from the list:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [83]: &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in range(32): spark.read.parquet(*(subdirs[:i] + subdirs[i+1:32]))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Another strange thing is that the schemas for the first and the last 31 partitions of the subset are identical:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [84]: spark.read.parquet(*subdirs[:31]).schema.fields == spark.read.parquet(*subdirs[1:32]).schema.fields
Out[84]: True
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which got me interested and I tried this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [87]: spark.read.parquet(*([subdirs[0]] * 32))
...
AnalysisException: u&lt;span class=&quot;code-quote&quot;&gt;&apos;Unable to infer schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ParquetFormat at /path/to/data/_locality_code=AQ,/path/to/data/_locality_code=AQ. It must be specified manually;&apos;&lt;/span&gt;

In [88]: spark.read.parquet(*([subdirs[15]] * 32))
...
AnalysisException: u&lt;span class=&quot;code-quote&quot;&gt;&apos;Unable to infer schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ParquetFormat at /path/to/data/_locality_code=AX,/path/to/data/_locality_code=AX. It must be specified manually;&apos;&lt;/span&gt;

In [89]: spark.read.parquet(*([subdirs[31]] * 32))
...
AnalysisException: u&lt;span class=&quot;code-quote&quot;&gt;&apos;Unable to infer schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ParquetFormat at /path/to/data/_locality_code=BE,/path/to/data/_locality_code=BE. It must be specified manually;&apos;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If I read the first partition, save it in 2.0 and try to read in the same manner, everything is fine:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [100]: spark.read.parquet(subdirs[0]).write.parquet(&lt;span class=&quot;code-quote&quot;&gt;&apos;spark-2.0-test&apos;&lt;/span&gt;)
16/08/09 11:03:37 WARN ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl

In [101]: df = spark.read.parquet(*([&lt;span class=&quot;code-quote&quot;&gt;&apos;spark-2.0-test&apos;&lt;/span&gt;] * 32))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I have originally posted it to user mailing list, but with the last discoveries this clearly seems like a bug.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Ubuntu Linux 14.04&lt;/p&gt;</environment>
        <key id="12995920">SPARK-16975</key>
            <summary>Spark-2.0.0 unable to infer schema for parquet data written by Spark-1.6.2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dongjoon">Dongjoon Hyun</assignee>
                                    <reporter username="immerrr">immerrr again</reporter>
                        <labels>
                            <label>parquet</label>
                    </labels>
                <created>Tue, 9 Aug 2016 11:04:31 +0000</created>
                <updated>Sat, 13 Aug 2016 01:19:03 +0000</updated>
                            <resolved>Fri, 12 Aug 2016 07:09:52 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>Input/Output</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="15415823" author="rxin" created="Wed, 10 Aug 2016 19:18:12 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; do you have time to look into this?&lt;/p&gt;</comment>
                            <comment id="15415831" author="dongjoon" created="Wed, 10 Aug 2016 19:20:37 +0000"  >&lt;p&gt;Oh, sure. It&apos;s my pleasure. I&apos;ll take a look.&lt;/p&gt;</comment>
                            <comment id="15415833" author="dongjoon" created="Wed, 10 Aug 2016 19:21:51 +0000"  >&lt;p&gt;Thank you for pinging me.&lt;/p&gt;</comment>
                            <comment id="15415903" author="dongjoon" created="Wed, 10 Aug 2016 19:56:25 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=immerrr&quot; class=&quot;user-hover&quot; rel=&quot;immerrr&quot;&gt;immerrr&lt;/a&gt;.&lt;br/&gt;
I can not reproduce your situation, but could you change `_locality_code` into `locality_code`?&lt;br/&gt;
Spark 2.0 ignores the path names starting with underscore or dot; `_` or `.`&lt;/p&gt;</comment>
                            <comment id="15415932" author="dongjoon" created="Wed, 10 Aug 2016 20:11:49 +0000"  >&lt;p&gt;I made a sample case having similar behaviors. I think this is related closed. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt;, how do you think about this?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;spark-1.6.2-bin-hadoop2.6$ ls /tmp/parquet16/
_SUCCESS         _locality_code=1 _locality_code=3 _locality_code=5 _locality_code=7 _locality_code=9
_locality_code=0 _locality_code=2 _locality_code=4 _locality_code=6 _locality_code=8
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; spark.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/parquet16&quot;&lt;/span&gt;).show
org.apache.spark.sql.AnalysisException: Unable to infer schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ParquetFormat at /tmp/parquet16. It must be specified manually;
scala&amp;gt; spark.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/parquet16/_locality_code=0&quot;&lt;/span&gt;).show
+---+
| id|
+---+
|  0|
+---+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15415941" author="dongjoon" created="Wed, 10 Aug 2016 20:17:00 +0000"  >&lt;p&gt;Ah, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt;. &lt;br/&gt;
For this issue, we should add a migration document for 1.6 .&lt;/p&gt;

&lt;p&gt;Spark 2.0 itself has the save problem. We should block the illegal column names. May I make a PR for this?&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; spark.range(10).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;_locality_code&quot;&lt;/span&gt;, $&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).write.partitionBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;_locality_code&quot;&lt;/span&gt;).save(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/parquet20&quot;&lt;/span&gt;)

scala&amp;gt; spark.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/parquet20&quot;&lt;/span&gt;)
org.apache.spark.sql.AnalysisException: Unable to infer schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ParquetFormat at /tmp/parquet20. It must be specified manually;

scala&amp;gt; spark.range(10).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;locality_code&quot;&lt;/span&gt;, $&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).write.partitionBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;locality_code&quot;&lt;/span&gt;).save(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/parquet201&quot;&lt;/span&gt;)

scala&amp;gt; spark.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/parquet201&quot;&lt;/span&gt;)
res6: org.apache.spark.sql.DataFrame = [id: bigint, locality_code: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15415957" author="dongjoon" created="Wed, 10 Aug 2016 20:36:18 +0000"  >&lt;p&gt;Let me dig more. I can find more general solution for this for Spark 1.6 / 2.0.&lt;/p&gt;</comment>
                            <comment id="15415961" author="immerrr" created="Wed, 10 Aug 2016 20:38:27 +0000"  >&lt;p&gt;oh, that&apos;s unfortunate. coming from python world, underscore seems a natural prefix for &quot;internal things&quot;.&lt;/p&gt;

&lt;p&gt;what bugs me, though, is that spark2.0 had no problems reading up to 31 directories starting with underscores and bugged out only when there were 32 of them.&lt;/p&gt;

&lt;p&gt;and i&apos;ll try the rename, give me a sec..&lt;/p&gt;</comment>
                            <comment id="15415966" author="dongjoon" created="Wed, 10 Aug 2016 20:41:14 +0000"  >&lt;p&gt;In the python, could you give the command string to write parquet?&lt;/p&gt;

&lt;p&gt;BTW, I also started to work in order to support `_col=xxx` format.&lt;/p&gt;</comment>
                            <comment id="15415998" author="immerrr" created="Wed, 10 Aug 2016 20:57:18 +0000"  >&lt;p&gt;You mean the one I use to write the data? I don&apos;t have the exact string at hand, but it was a straightforward conversion from JSON inferring schema on the way, smth like&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sqlContext.read.json(&lt;span class=&quot;code-quote&quot;&gt;&apos;/path/to/json-data&apos;&lt;/span&gt;).write.partitionBy(&lt;span class=&quot;code-quote&quot;&gt;&apos;_locality_code&apos;&lt;/span&gt;).parquet(&lt;span class=&quot;code-quote&quot;&gt;&apos;/path/to/parquet-data&apos;&lt;/span&gt;, mode=&lt;span class=&quot;code-quote&quot;&gt;&apos;overwrite&apos;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Oh, another thing was that when I tried reading subdir-by-subdir.  When you read a single subdirectory, the _locality_code column is not present (just like in your example), but for some reason it worked ok when reading just one such subdirectory but failed reading that same directory multiple times.  There were other columns starting with underscore, though. I didn&apos;t use them to partition the data, but maybe they still somehow affected schema inference.&lt;/p&gt;</comment>
                            <comment id="15416001" author="dongjoon" created="Wed, 10 Aug 2016 20:58:38 +0000"  >&lt;p&gt;Okay. Wait a second, please. I&apos;ll make PR for you.&lt;/p&gt;</comment>
                            <comment id="15416003" author="immerrr" created="Wed, 10 Aug 2016 20:59:39 +0000"  >&lt;p&gt;I mean, this line from the original report&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [87]: spark.read.parquet(*([subdirs[0]] * 32))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;means pass subdirs&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; 32 times as parameters to spark.read.parquet, i.e. spark.read.parquet(subdirs&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;, subdirs&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;, ...)&lt;/p&gt;</comment>
                            <comment id="15416009" author="dongjoon" created="Wed, 10 Aug 2016 21:01:58 +0000"  >&lt;p&gt;Yep. And, it raised exceptions, right?&lt;/p&gt;</comment>
                            <comment id="15416013" author="immerrr" created="Wed, 10 Aug 2016 21:03:44 +0000"  >&lt;p&gt;Yes, a seemingly similar one.&lt;/p&gt;</comment>
                            <comment id="15416024" author="apachespark" created="Wed, 10 Aug 2016 21:11:05 +0000"  >&lt;p&gt;User &apos;dongjoon-hyun&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14585&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14585&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15416032" author="dongjoon" created="Wed, 10 Aug 2016 21:15:51 +0000"  >&lt;p&gt;I made a PR, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=immerrr&quot; class=&quot;user-hover&quot; rel=&quot;immerrr&quot;&gt;immerrr&lt;/a&gt;. I tested only `sql` module tests. After passing Jenkins, could you test the PR in your environment if you have some time?&lt;br/&gt;
I think PySpark also will get benefit of this PR.&lt;/p&gt;</comment>
                            <comment id="15416034" author="immerrr" created="Wed, 10 Aug 2016 21:18:44 +0000"  >&lt;p&gt;Great, thank you! That was so fast!&lt;/p&gt;

&lt;p&gt;I&apos;ll try to look at it tomorrow, but cannot promise anything as my experience in Scala and building it is next to none.&lt;/p&gt;</comment>
                            <comment id="15416038" author="dongjoon" created="Wed, 10 Aug 2016 21:20:59 +0000"  >&lt;p&gt;Thank you. See you tomorrow! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15417113" author="immerrr" created="Thu, 11 Aug 2016 12:19:34 +0000"  >&lt;p&gt;I have built the code from the PR and it indeed succeeds reading the data.&lt;/p&gt;

&lt;p&gt;I have tried doing &lt;tt&gt;df.count()&lt;/tt&gt; and now I&apos;m swarmed with warnings like this (they are just keep getting printed endlessly in the terminal): &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;16/08/11 12:18:51 WARN CorruptStatistics: Ignoring statistics because created_by could not be parsed (see PARQUET-251): parquet-mr version 1.6.0
org.apache.parquet.VersionParser$VersionParseException: Could not parse created_by: parquet-mr version 1.6.0 using format: (.+) version ((.*) )?\(build ?(.*)\)
	at org.apache.parquet.VersionParser.parse(VersionParser.java:112)
	at org.apache.parquet.CorruptStatistics.shouldIgnoreStatistics(CorruptStatistics.java:60)
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetStatistics(ParquetMetadataConverter.java:263)
	at org.apache.parquet.format.converter.ParquetMetadataConverter.fromParquetMetadata(ParquetMetadataConverter.java:567)
	at org.apache.parquet.format.converter.ParquetMetadataConverter.readParquetMetadata(ParquetMetadataConverter.java:544)
	at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:431)
	at org.apache.parquet.hadoop.ParquetFileReader.readFooter(ParquetFileReader.java:386)
	at org.apache.spark.sql.execution.datasources.parquet.SpecificParquetRecordReaderBase.initialize(SpecificParquetRecordReaderBase.java:107)
	at org.apache.spark.sql.execution.datasources.parquet.VectorizedParquetRecordReader.initialize(VectorizedParquetRecordReader.java:109)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$buildReader$1.apply(ParquetFileFormat.scala:369)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anonfun$buildReader$1.apply(ParquetFileFormat.scala:343)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:122)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:97)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.scan_nextBatch$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:126)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:86)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;  </comment>
                            <comment id="15417172" author="immerrr" created="Thu, 11 Aug 2016 12:57:48 +0000"  >&lt;p&gt;But it works. I have suppressed WARN logs and &lt;tt&gt;df.count()&lt;/tt&gt; returned the correct value, despite taking 2x time to finish compared to 1.6.2.&lt;/p&gt;</comment>
                            <comment id="15417186" author="immerrr" created="Thu, 11 Aug 2016 13:03:38 +0000"  >&lt;p&gt;The figures were:&lt;br/&gt;
1.6.2: ~6s&lt;br/&gt;
2.0.0: ~12s&lt;/p&gt;

&lt;p&gt;Interestingly enough, after restarting the driver, 2.0 run took far less than that:&lt;br/&gt;
1.6.2: ~5.7s&lt;br/&gt;
2.0.0: ~1.4s&lt;/p&gt;

&lt;p&gt;Maybe, some sort of caching that survives restarts is used internally.&lt;/p&gt;</comment>
                            <comment id="15417240" author="dongjoon" created="Thu, 11 Aug 2016 13:33:12 +0000"  >&lt;p&gt;Great! Thank you for confirming.&lt;/p&gt;</comment>
                            <comment id="15418364" author="dongjoon" created="Fri, 12 Aug 2016 04:51:08 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt;.&lt;br/&gt;
Could you review this PR?&lt;/p&gt;</comment>
                            <comment id="15418451" author="lian cheng" created="Fri, 12 Aug 2016 07:09:52 +0000"  >&lt;p&gt;Issue resolved by pull request 14585&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14585&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14585&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15419755" author="apachespark" created="Sat, 13 Aug 2016 01:19:03 +0000"  >&lt;p&gt;User &apos;HyukjinKwon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14627&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14627&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 14 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32313:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>