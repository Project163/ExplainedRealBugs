<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:40:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-13456] Cannot create encoders for case classes defined in Spark shell after upgrading to Scala 2.11</title>
                <link>https://issues.apache.org/jira/browse/SPARK-13456</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Spark 2.0 started to use Scala 2.11 by default since &lt;a href=&quot;https://github.com/apache/spark/pull/10608&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PR #10608&lt;/a&gt;.  Unfortunately, after this upgrade, Spark fails to create encoders for case classes defined in REPL:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; sqlContext.implicits._
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;T(a: Int, b: &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;)
val ds = Seq(1 -&amp;gt; T(1, 1D), 2 -&amp;gt; T(2, 2D)).toDS()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Exception thrown:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;org.apache.spark.sql.AnalysisException: Unable to generate an encoder for inner class `T` without access to the scope that this class was defined in.
Try moving this class out of its parent class.;
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$resolveDeserializer$1.applyOrElse(Analyzer.scala:565)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$resolveDeserializer$1.applyOrElse(Analyzer.scala:561)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:262)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:262)
  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:261)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:267)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:267)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:304)
  at scala.collection.Iterator$$anon$11.next(Iterator.scala:370)
  at scala.collection.Iterator$class.foreach(Iterator.scala:742)
  at scala.collection.AbstractIterator.foreach(Iterator.scala:1194)
  at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
  at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
  at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
  at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:308)
  at scala.collection.AbstractIterator.to(Iterator.scala:1194)
  at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:300)
  at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1194)
  at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:287)
  at scala.collection.AbstractIterator.toArray(Iterator.scala:1194)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:353)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:267)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:267)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:267)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5$$anonfun$apply$11.apply(TreeNode.scala:333)
  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245)
  at scala.collection.immutable.List.foreach(List.scala:381)
  at scala.collection.TraversableLike$class.map(TraversableLike.scala:245)
  at scala.collection.immutable.List.map(List.scala:285)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:331)
  at scala.collection.Iterator$$anon$11.next(Iterator.scala:370)
  at scala.collection.Iterator$class.foreach(Iterator.scala:742)
  at scala.collection.AbstractIterator.foreach(Iterator.scala:1194)
  at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
  at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
  at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
  at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:308)
  at scala.collection.AbstractIterator.to(Iterator.scala:1194)
  at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:300)
  at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1194)
  at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:287)
  at scala.collection.AbstractIterator.toArray(Iterator.scala:1194)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:353)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:267)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:251)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.resolveDeserializer(Analyzer.scala:561)
  at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.resolve(ExpressionEncoder.scala:315)
  at org.apache.spark.sql.Dataset.&amp;lt;init&amp;gt;(Dataset.scala:81)
  at org.apache.spark.sql.Dataset.&amp;lt;init&amp;gt;(Dataset.scala:92)
  at org.apache.spark.sql.SQLContext.createDataset(SQLContext.scala:482)
  at org.apache.spark.sql.SQLImplicits.localSeqToDatasetHolder(SQLImplicits.scala:140)
  ... 51 elided
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;However, existing Dataset REPL test case does pass:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  test(&lt;span class=&quot;code-quote&quot;&gt;&quot;SPARK-2576 importing SQLContext.implicits._&quot;&lt;/span&gt;) {
    &lt;span class=&quot;code-comment&quot;&gt;// We need to use local-cluster to test &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt;.
&lt;/span&gt;    val output = runInterpreter(&lt;span class=&quot;code-quote&quot;&gt;&quot;local-cluster[1,1,1024]&quot;&lt;/span&gt;,
      &quot;&quot;&quot;
        |val sqlContext = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.apache.spark.sql.SQLContext(sc)
        |&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; sqlContext.implicits._
        |&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;TestCaseClass(value: Int)
        |sc.parallelize(1 to 10).map(x =&amp;gt; TestCaseClass(x)).toDF().collect()
        |
        |&lt;span class=&quot;code-comment&quot;&gt;// Test Dataset Serialization in the REPL
&lt;/span&gt;        |Seq(TestCaseClass(1)).toDS().collect()
      &quot;&quot;&quot;.stripMargin)
    assertDoesNotContain(&lt;span class=&quot;code-quote&quot;&gt;&quot;error:&quot;&lt;/span&gt;, output)
    assertDoesNotContain(&lt;span class=&quot;code-quote&quot;&gt;&quot;Exception&quot;&lt;/span&gt;, output)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;One possible clue is that, &lt;tt&gt;ReplSuite&lt;/tt&gt; calls &lt;tt&gt;SparkILoop&lt;/tt&gt; directly, while Spark shell is started by &lt;tt&gt;o.a.s.repl.Main&lt;/tt&gt;, which also sets option &lt;tt&gt;-Yrepl-class-based&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12941414">SPARK-13456</key>
            <summary>Cannot create encoders for case classes defined in Spark shell after upgrading to Scala 2.11</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cloud_fan">Wenchen Fan</assignee>
                                    <reporter username="lian cheng">Cheng Lian</reporter>
                        <labels>
                    </labels>
                <created>Tue, 23 Feb 2016 14:55:36 +0000</created>
                <updated>Tue, 5 Apr 2016 01:19:40 +0000</updated>
                            <resolved>Tue, 5 Apr 2016 01:19:40 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="15159048" author="cloud_fan" created="Tue, 23 Feb 2016 15:33:49 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15159475" author="marmbrus" created="Tue, 23 Feb 2016 19:19:25 +0000"  >&lt;p&gt;We need to inject OuterScopes registration like we do in 2.10: &lt;a href=&quot;https://github.com/apache/spark/blob/4a46b8859d3314b5b45a67cdc5c81fecb6e9e78c/repl/scala-2.10/src/main/scala/org/apache/spark/repl/SparkIMain.scala#L1209&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/4a46b8859d3314b5b45a67cdc5c81fecb6e9e78c/repl/scala-2.10/src/main/scala/org/apache/spark/repl/SparkIMain.scala#L1209&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15168953" author="cloud_fan" created="Fri, 26 Feb 2016 13:09:11 +0000"  >&lt;p&gt;spark shell of scala 2.11 is very different from the scala 2.10 one, we just use the standard shell instead of rewriting a lof of related stuff.&lt;br/&gt;
The trick we used in the scala 2.10 shell is not easy(or impossible) to port to scala 2.11, because we wanna overwrite something in class `Request`, which is an inner class of `ILoop#ILoopInterpreter`. However, there is no virtual inner class in scala, if we wanna overwrite an inner class, we have to overwrite its factory method too. Unluckily, the factory method of `Request` is private, we can&apos;t overwrite.&lt;/p&gt;

&lt;p&gt;I&apos;m going to try another approach, to make `OutScope` smarter that can detect classes defined in shell and load shell wrapper class automatically.&lt;/p&gt;</comment>
                            <comment id="15170506" author="apachespark" created="Sat, 27 Feb 2016 09:41:03 +0000"  >&lt;p&gt;User &apos;cloud-fan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11410&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11410&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15199774" author="arjenpdevries" created="Thu, 17 Mar 2016 15:59:45 +0000"  >&lt;p&gt;I benefited from learning about this workaround (which is implicitly given in the discussion above, but I only realized afterwards):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; sqlContext.implicits._
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;T(a: Int, b: &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;)
org.apache.spark.sql.catalyst.encoders.OuterScopes.addOuterScope(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;)
val ds = Seq(1 -&amp;gt; T(1, 1D), 2 -&amp;gt; T(2, 2D)).toDS()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15204708" author="yhuai" created="Mon, 21 Mar 2016 17:38:23 +0000"  >&lt;p&gt;Issue resolved by pull request 11410&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11410&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11410&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15209174" author="jlaskowski" created="Wed, 23 Mar 2016 21:06:52 +0000"  >&lt;p&gt;In today&apos;s Spark 2.0.0-SNAPSHOT:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; :pa
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; sqlContext.implicits._

&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Token(name: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, productId: Int, score: &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;)
val data = Token(&lt;span class=&quot;code-quote&quot;&gt;&quot;aaa&quot;&lt;/span&gt;, 100, 0.12) ::
  Token(&lt;span class=&quot;code-quote&quot;&gt;&quot;aaa&quot;&lt;/span&gt;, 200, 0.29) ::
  Token(&lt;span class=&quot;code-quote&quot;&gt;&quot;bbb&quot;&lt;/span&gt;, 200, 0.53) ::
  Token(&lt;span class=&quot;code-quote&quot;&gt;&quot;bbb&quot;&lt;/span&gt;, 300, 0.42) :: Nil

val ds = data.toDS


&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
java.lang.NullPointerException
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
  at java.lang.reflect.Method.invoke(Method.java:498)
  at org.apache.spark.sql.catalyst.encoders.OuterScopes$.getOuterScope(OuterScopes.scala:64)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$resolveDeserializer$1.applyOrElse(Analyzer.scala:588)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$resolveDeserializer$1.applyOrElse(Analyzer.scala:580)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:259)
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:259)
  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:67)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:258)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:248)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.resolveDeserializer(Analyzer.scala:580)
  at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.resolve(ExpressionEncoder.scala:321)
  at org.apache.spark.sql.Dataset.&amp;lt;init&amp;gt;(Dataset.scala:197)
  at org.apache.spark.sql.Dataset.&amp;lt;init&amp;gt;(Dataset.scala:164)
  at org.apache.spark.sql.Dataset$.apply(Dataset.scala:53)
  at org.apache.spark.sql.SQLContext.createDataset(SQLContext.scala:448)
  at org.apache.spark.sql.SQLImplicits.localSeqToDatasetHolder(SQLImplicits.scala:152)
  ... 47 elided
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15209790" author="cloud_fan" created="Thu, 24 Mar 2016 05:23:49 +0000"  >&lt;p&gt;I tried your example locally and everything goes well. How do you build spark?&lt;/p&gt;</comment>
                            <comment id="15209794" author="cloud_fan" created="Thu, 24 Mar 2016 05:25:12 +0000"  >&lt;p&gt;oh i see, the problem is the paste mode, working on it.&lt;/p&gt;</comment>
                            <comment id="15209913" author="apachespark" created="Thu, 24 Mar 2016 07:35:04 +0000"  >&lt;p&gt;User &apos;cloud-fan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11931&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11931&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15211825" author="lian cheng" created="Fri, 25 Mar 2016 14:00:21 +0000"  >&lt;p&gt;Issue resolved by pull request 11931&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11931&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11931&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15211985" author="yhuai" created="Fri, 25 Mar 2016 16:04:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jlaskowski&quot; class=&quot;user-hover&quot; rel=&quot;jlaskowski&quot;&gt;jlaskowski&lt;/a&gt; When you get a chance, can you try again? &lt;a href=&quot;https://github.com/apache/spark/pull/11931&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11931&lt;/a&gt; should fix the problem.&lt;/p&gt;</comment>
                            <comment id="15223574" author="jlaskowski" created="Mon, 4 Apr 2016 00:52:04 +0000"  >&lt;p&gt;I thought it worked fine, but just today ran across the following that looks like the issue has not been resolved.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; :pa
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Token(name: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, productId: Int, score: &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;)
val data = Seq(
  Token(&lt;span class=&quot;code-quote&quot;&gt;&quot;aaa&quot;&lt;/span&gt;, 100, 0.12),
  Token(&lt;span class=&quot;code-quote&quot;&gt;&quot;aaa&quot;&lt;/span&gt;, 200, 0.29),
  Token(&lt;span class=&quot;code-quote&quot;&gt;&quot;bbb&quot;&lt;/span&gt;, 200, 0.53),
  Token(&lt;span class=&quot;code-quote&quot;&gt;&quot;bbb&quot;&lt;/span&gt;, 300, 0.42))

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
defined &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Token
data: Seq[Token] = List(Token(aaa,100,0.12), Token(aaa,200,0.29), Token(bbb,200,0.53), Token(bbb,300,0.42))

scala&amp;gt; val ds = data.toDS
ds: org.apache.spark.sql.Dataset[Token] = [name: string, productId: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; ... 1 more field]

scala&amp;gt; val ds: Dataset[Token] = data.toDS
&amp;lt;console&amp;gt;:27: error: not found: type Dataset
       val ds: Dataset[Token] = data.toDS
               ^

scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql._

scala&amp;gt; val ds: Dataset[Token] = data.toDS
&amp;lt;console&amp;gt;:30: error: type mismatch;
 found   : org.apache.spark.sql.Dataset[Token]
 required: org.apache.spark.sql.Dataset[Token]
       val ds: Dataset[Token] = data.toDS
                                     ^
scala&amp;gt; sc.version
res0: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = 2.0.0-SNAPSHOT
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.0.0-SNAPSHOT
      /_/

Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_77)
Type in expressions to have them evaluated.
Type :help &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15223576" author="jlaskowski" created="Mon, 4 Apr 2016 00:52:33 +0000"  >&lt;p&gt;It appears that the issue has not been resolved properly entirely yet.&lt;/p&gt;</comment>
                            <comment id="15223758" author="cloud_fan" created="Mon, 4 Apr 2016 07:20:34 +0000"  >&lt;p&gt;I found a minimal case to reproduce this issue:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; :pa
&lt;span class=&quot;code-comment&quot;&gt;// Entering paste mode (ctrl-D to finish)
&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Data(i: Int)
val d = Data(1)

&lt;span class=&quot;code-comment&quot;&gt;// Exiting paste mode, now interpreting.
&lt;/span&gt;
defined &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Data
d: Data = Data@1a536164

scala&amp;gt; val d2: Data = d
&amp;lt;console&amp;gt;:28: error: type mismatch;
 found   : Data
 required: Data
       val d2: Data = d
                                  ^
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It&apos;s not related to our encoder framework, but looks like a fundamental problem in the Spark Shell. Looking into it.&lt;/p&gt;</comment>
                            <comment id="15225389" author="yhuai" created="Tue, 5 Apr 2016 00:35:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt; This is the repl issue.&lt;/p&gt;</comment>
                            <comment id="15225390" author="yhuai" created="Tue, 5 Apr 2016 00:36:04 +0000"  >&lt;p&gt;The original jira for this should be &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-1199&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-1199&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15225468" author="cloud_fan" created="Tue, 5 Apr 2016 01:19:23 +0000"  >&lt;p&gt;This is a scala bug: &lt;a href=&quot;https://issues.scala-lang.org/browse/SI-9734&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues.scala-lang.org/browse/SI-9734&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;m going to resolve this JIRA as the issue is not a Spark issue.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 33 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2t7vz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>