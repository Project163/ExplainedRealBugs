<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:25:07 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-6222] [STREAMING] All data may not be recovered from WAL when driver is killed</title>
                <link>https://issues.apache.org/jira/browse/SPARK-6222</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When testing for our next release, our internal tests written by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wypoon&quot; class=&quot;user-hover&quot; rel=&quot;wypoon&quot;&gt;wypoon&lt;/a&gt; caught a regression in Spark Streaming between 1.2.0 and 1.3.0. The test runs FlumePolling stream to read data from Flume, then kills the Application Master. Once YARN restarts it, the test waits until no more data is to be written and verifies the original against the data on HDFS. This was passing in 1.2.0, but is failing now.&lt;/p&gt;

&lt;p&gt;Since the test ties into Cloudera&apos;s internal infrastructure and build process, it cannot be directly run on an Apache build. But I have been working on isolating the commit that may have caused the regression. I have confirmed that it was caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-5147&quot; title=&quot;write ahead logs from streaming receiver are not purged because cleanupOldBlocks in WriteAheadLogBasedBlockHandler is never called&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-5147&quot;&gt;&lt;del&gt;SPARK-5147&lt;/del&gt;&lt;/a&gt; (PR # &lt;a href=&quot;https://github.com/apache/spark/pull/4149&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;4149&lt;/a&gt;). I confirmed this several times using the test and the failure is consistently reproducible. &lt;/p&gt;

&lt;p&gt;To re-confirm, I reverted just this one commit (and Clock consolidation one to avoid conflicts), and the issue was no longer reproducible.&lt;/p&gt;

&lt;p&gt;Since this is a data loss issue, I believe this is a blocker for Spark 1.3.0&lt;br/&gt;
/cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tdas&quot; class=&quot;user-hover&quot; rel=&quot;tdas&quot;&gt;tdas&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pwendell&quot; class=&quot;user-hover&quot; rel=&quot;pwendell&quot;&gt;pwendell&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12780433">SPARK-6222</key>
            <summary>[STREAMING] All data may not be recovered from WAL when driver is killed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hshreedharan">Hari Shreedharan</assignee>
                                    <reporter username="hshreedharan">Hari Shreedharan</reporter>
                        <labels>
                    </labels>
                <created>Mon, 9 Mar 2015 08:46:10 +0000</created>
                <updated>Fri, 24 Apr 2015 00:36:01 +0000</updated>
                            <resolved>Thu, 19 Mar 2015 06:17:19 +0000</resolved>
                                    <version>1.3.0</version>
                                    <fixVersion>1.3.1</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>DStreams</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14353358" author="tdas" created="Mon, 9 Mar 2015 18:39:17 +0000"  >&lt;p&gt;Could you upload the stack traces, and logs that show is error? The PR # 4149 is about automatically deleting old log files. Is it an error that WAL files are deleted automatically too early? &lt;/p&gt;</comment>
                            <comment id="14353773" author="hshreedharan" created="Mon, 9 Mar 2015 22:31:22 +0000"  >&lt;p&gt;This patch fixes the issue &amp;#8211; so the issue is basically that somehow when the checkpoint data is being cleared up, it is still too early.&lt;/p&gt;

&lt;p&gt;I am not sure of what the exact reason is yet. &lt;/p&gt;</comment>
                            <comment id="14353840" author="tdas" created="Mon, 9 Mar 2015 23:10:21 +0000"  >&lt;p&gt;Which patch fixes the issue?&lt;/p&gt;</comment>
                            <comment id="14353842" author="hshreedharan" created="Mon, 9 Mar 2015 23:11:33 +0000"  >&lt;p&gt;The one on the jira. &lt;/p&gt;</comment>
                            <comment id="14353858" author="srowen" created="Mon, 9 Mar 2015 23:20:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hshreedharan&quot; class=&quot;user-hover&quot; rel=&quot;hshreedharan&quot;&gt;hshreedharan&lt;/a&gt; you can make a &lt;span class=&quot;error&quot;&gt;&amp;#91;WIP&amp;#93;&lt;/span&gt; pull request instead of a patch. It&apos;s easier to review that way.&lt;/p&gt;</comment>
                            <comment id="14353867" author="hshreedharan" created="Mon, 9 Mar 2015 23:25:59 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; This patch is actually not intended to fix the issue, since this patch will cause the WAL to not be cleaned up - which is not something we want. This was only intended to help isolate the problem &amp;#8211; from this patch it is clear that we are somehow attempting to clear the WAL data prematurely, causing the regression - when and why I am not yet sure.&lt;/p&gt;</comment>
                            <comment id="14353964" author="hshreedharan" created="Tue, 10 Mar 2015 00:29:51 +0000"  >&lt;p&gt;Here are the logs:&lt;/p&gt;

&lt;p&gt;CleanWithoutPatch &amp;#8211; this is run on an assembly built from a pristine source tree. This is the one where events are missing&lt;br/&gt;
AfterPatch - Here I apply the patch attached to this jira (where there is no periodic cleanup). No events are missing in this run.&lt;/p&gt;

&lt;p&gt;Each file contains the logs of the same application, with a comment in the middle to show where the AM was killed and YARN restarted it.&lt;/p&gt;</comment>
                            <comment id="14354122" author="tdas" created="Tue, 10 Mar 2015 02:06:56 +0000"  >&lt;p&gt;Offline discussion with Hari, these logs dont have the necessary information. He will generate debug/trace level logs.&lt;/p&gt;</comment>
                            <comment id="14355632" author="apachespark" created="Tue, 10 Mar 2015 20:29:52 +0000"  >&lt;p&gt;User &apos;harishreedharan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4964&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4964&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14355652" author="hshreedharan" created="Tue, 10 Mar 2015 20:36:26 +0000"  >&lt;p&gt;I could not generate TRACE level logs because of some weird issues with the cluster, but I was able to figure out what is happening here and was able to fix it with the PR #&lt;a href=&quot;https://github.com/apache/spark/pull/4964&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;4964&lt;/a&gt;. This my analysis:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;We periodically generate a batch to be processed in the `generateJobs` method, which asynchronously starts a job to process the batch, but we checkpoint at the end of this method, without waiting for the job to complete. Therefore the checkpoint at time t has info about jobs started at t, not completed at t.&lt;/li&gt;
	&lt;li&gt;On checkpoint completion, we remove all old checkpoints and any WAL files for time before t - 2 * checkpointDuration. This means that all WAL files for current - minus 2 batches (or 2 checkpoints worth) are deleted. We write a BatchCleared event also into the WAL&lt;/li&gt;
	&lt;li&gt;When we recover, to get back to the same state as we were earlier, we throw out all metadata when we see a BatchCleared event.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;As a result when we recover, we never recover the data between the last checkpoint which was completed and the last checkpoint that was initiated, leading to data loss.&lt;/p&gt;</comment>
                            <comment id="14355731" author="hshreedharan" created="Tue, 10 Mar 2015 21:12:48 +0000"  >&lt;p&gt;In the direct connector for Kafka, we checkpoint the starting and ending offsets for each batch, but at the checkpoint time, the batch has not actually been processed, but just submitted. If the app dies at that time, the checkpoint will contain the offsets of a batch that was not processed - this will result in data loss too. So this bug is relevant event when no WAL is present.&lt;/p&gt;</comment>
                            <comment id="14355965" author="hshreedharan" created="Tue, 10 Mar 2015 23:45:49 +0000"  >&lt;p&gt;Another option is to change the way we delete old block data - we delete the data only for the lastProcessedBatch time. Even that should fix this issue (and does not change much of the checkpoint time logic). I am testing that out now. I, though, prefer the logic currently in the PR because it makes the checkpointing more deterministic - at checkpoint time &quot;t&quot;, the batch generated at time &quot;t&quot; has been processed, while currently at the checkpoint time &quot;t&quot; - the batch may or may not have been processed, which is a bit non-deterministic than I&apos;d like.&lt;/p&gt;</comment>
                            <comment id="14355996" author="hshreedharan" created="Wed, 11 Mar 2015 00:07:56 +0000"  >&lt;p&gt;Thinking about it again - markBatchFullyProcessed(time) in JobGenerator seems to think a batch is processed when the checkpoint is completed, which is not the right thing to do - since the batch may not have been processed. So this actually seems like a real bug - we have an issue with checkpointing vs processing. We assume checkpoint completion means batch completion which simply is not true. I think the proposed method clears that up. For now, I am going to go ahead with that, fixing tests and 1 bug and updating PR.&lt;/p&gt;</comment>
                            <comment id="14359948" author="apachespark" created="Fri, 13 Mar 2015 05:07:49 +0000"  >&lt;p&gt;User &apos;tdas&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5008&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5008&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14359950" author="tdas" created="Fri, 13 Mar 2015 05:09:13 +0000"  >&lt;p&gt;I proposed another way to fix this here&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5008&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5008&lt;/a&gt;&lt;br/&gt;
Basically, dont clear checkpoint data after the pre-batch-start checkpoint. &lt;/p&gt;

&lt;p&gt;BTW, super thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hshreedharan&quot; class=&quot;user-hover&quot; rel=&quot;hshreedharan&quot;&gt;hshreedharan&lt;/a&gt; for painstakingly explaining me offline what the problem was.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12765720">SPARK-5142</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12703551" name="AfterPatch.txt" size="433023" author="hshreedharan" created="Tue, 10 Mar 2015 00:29:50 +0000"/>
                            <attachment id="12703550" name="CleanWithoutPatch.txt" size="520330" author="hshreedharan" created="Tue, 10 Mar 2015 00:29:50 +0000"/>
                            <attachment id="12703519" name="SPARK-6122.patch" size="941" author="hshreedharan" created="Mon, 9 Mar 2015 22:31:21 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 36 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i26ibz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329486">1.3.1</customfieldvalue>
    <customfieldvalue id="12329359">1.4.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>