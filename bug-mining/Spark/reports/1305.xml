<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:22:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4296] Throw &quot;Expression not in GROUP BY&quot; when using same expression in group by clause and  select clause</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4296</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When the input data has a complex structure, using same expression in group by clause and  select clause will throw &quot;Expression not in GROUP BY&quot;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;val sqlContext = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.apache.spark.sql.SQLContext(sc)
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; sqlContext.createSchemaRDD
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Birthday(date: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;)
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Person(name: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, birthday: Birthday)
val people = sc.parallelize(List(Person(&lt;span class=&quot;code-quote&quot;&gt;&quot;John&quot;&lt;/span&gt;, Birthday(&lt;span class=&quot;code-quote&quot;&gt;&quot;1990-01-22&quot;&lt;/span&gt;)), Person(&lt;span class=&quot;code-quote&quot;&gt;&quot;Jim&quot;&lt;/span&gt;, Birthday(&lt;span class=&quot;code-quote&quot;&gt;&quot;1980-02-28&quot;&lt;/span&gt;))))
people.registerTempTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;people&quot;&lt;/span&gt;)
val year = sqlContext.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select count(*), upper(birthday.date) from people group by upper(birthday.date)&quot;&lt;/span&gt;)
year.collect
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the plan of year:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SchemaRDD[3] at RDD at SchemaRDD.scala:105
== Query Plan ==
== Physical Plan ==
org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Expression not in GROUP BY: Upper(birthday#1.date AS date#9) AS c1#3, tree:
Aggregate [Upper(birthday#1.date)], [COUNT(1) AS c0#2L,Upper(birthday#1.date AS date#9) AS c1#3]
 Subquery people
  LogicalRDD [name#0,birthday#1], MapPartitionsRDD[1] at mapPartitions at ExistingRDD.scala:36
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The bug is the equality test for `Upper(birthday#1.date)` and `Upper(birthday#1.date AS date#9)`.&lt;/p&gt;

&lt;p&gt;Maybe Spark SQL needs a mechanism to compare Alias expression and non-Alias expression.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12753672">SPARK-4296</key>
            <summary>Throw &quot;Expression not in GROUP BY&quot; when using same expression in group by clause and  select clause</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lian cheng">Cheng Lian</assignee>
                                    <reporter username="zsxwing">Shixiong Zhu</reporter>
                        <labels>
                    </labels>
                <created>Fri, 7 Nov 2014 11:19:58 +0000</created>
                <updated>Tue, 21 Mar 2017 22:01:34 +0000</updated>
                            <resolved>Tue, 20 Jan 2015 22:01:34 +0000</resolved>
                                    <version>1.1.0</version>
                    <version>1.1.1</version>
                    <version>1.2.0</version>
                                    <fixVersion>1.2.1</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="14201934" author="zsxwing" created="Fri, 7 Nov 2014 11:20:57 +0000"  >&lt;p&gt;Stack trace:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Expression not in GROUP BY: Upper(birthday#11.date AS date#17) AS c1#13, tree:
Aggregate [Upper(birthday#11.date)], [COUNT(1) AS c0#12L,Upper(birthday#11.date AS date#17) AS c1#13]
 Subquery people
  LogicalRDD [name#10,birthday#11], MapPartitionsRDD[5] at mapPartitions at ExistingRDD.scala:36

	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$$anonfun$apply$3$$anonfun$applyOrElse$7.apply(Analyzer.scala:133)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$$anonfun$apply$3$$anonfun$applyOrElse$7.apply(Analyzer.scala:130)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$$anonfun$apply$3.applyOrElse(Analyzer.scala:130)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$$anonfun$apply$3.applyOrElse(Analyzer.scala:115)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:144)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:135)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$.apply(Analyzer.scala:115)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$.apply(Analyzer.scala:113)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1$$anonfun$apply$2.apply(RuleExecutor.scala:61)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1$$anonfun$apply$2.apply(RuleExecutor.scala:59)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldl(IndexedSeqOptimized.scala:51)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(IndexedSeqOptimized.scala:60)
	at scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:34)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1.apply(RuleExecutor.scala:59)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1.apply(RuleExecutor.scala:51)
	at scala.collection.immutable.List.foreach(List.scala:318)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14201937" author="zsxwing" created="Fri, 7 Nov 2014 11:25:01 +0000"  >&lt;p&gt;Original reported by Tridib Samanta at &lt;a href=&quot;http://apache-spark-user-list.1001560.n3.nabble.com/sql-group-by-on-UDF-not-working-td18339.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://apache-spark-user-list.1001560.n3.nabble.com/sql-group-by-on-UDF-not-working-td18339.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14202326" author="tridib" created="Fri, 7 Nov 2014 17:36:33 +0000"  >&lt;p&gt;I wish we can use alias of calculated column in group by clause, which will avoid specifying long calculated fields to be repeated.&lt;/p&gt;</comment>
                            <comment id="14204263" author="gvramana" created="Mon, 10 Nov 2014 02:50:45 +0000"  >&lt;p&gt;Alias are being added implicitly to structure fields in group by for aggregate expressions, so aggregate expression comparison to group by expression is failing.&lt;br/&gt;
So Upper(birthday#11.date AS date#17) is compared against Upper(birthday#11.date)&lt;/p&gt;</comment>
                            <comment id="14218316" author="marmbrus" created="Wed, 19 Nov 2014 19:04:11 +0000"  >&lt;p&gt;I think this was fixed by the linked issue.  Please reopen if I am wrong.&lt;/p&gt;</comment>
                            <comment id="14250611" author="dyross" created="Wed, 17 Dec 2014 21:39:41 +0000"  >&lt;p&gt;I can still reproduce this issue. The test case above does appear to be fixed, but if you use other types of agg functions, it can fail. For example:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;CREATE TABLE test_spark_4296(s STRING);
SELECT UPPER(s) FROM test_spark_4296 GROUP BY UPPER(s);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That works. But this query doesn&apos;t:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;SELECT REGEXP_EXTRACT(s, &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;, 1) FROM test_spark_4296 GROUP BY REGEXP_EXTRACT(s, &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;, 1);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The error is similar to the one above:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;14/12/17 21:39:22 INFO thriftserver.SparkExecuteStatementOperation: Running query &lt;span class=&quot;code-quote&quot;&gt;&apos;SELECT REGEXP_EXTRACT(s, &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;, 1) FROM test_spark_4296 GROUP BY REGEXP_EXTRACT(s, &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;, 1)&apos;&lt;/span&gt;
14/12/17 21:39:22 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on slave0:50816 in memory (size: 5.2 KB, free: 534.4 MB)
14/12/17 21:39:22 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on slave1:45411 in memory (size: 5.2 KB, free: 534.4 MB)
14/12/17 21:39:22 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on slave2:59650 in memory (size: 5.2 KB, free: 534.4 MB)
14/12/17 21:39:22 INFO storage.BlockManager: Removing broadcast 7
14/12/17 21:39:22 INFO storage.BlockManager: Removing block broadcast_7_piece0
14/12/17 21:39:22 INFO storage.MemoryStore: Block broadcast_7_piece0 of size 5308 dropped from memory (free 276233416)
14/12/17 21:39:22 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on master:34621 in memory (size: 5.2 KB, free: 265.0 MB)
14/12/17 21:39:22 INFO storage.BlockManagerMaster: Updated info of block broadcast_7_piece0
14/12/17 21:39:22 INFO storage.BlockManager: Removing block broadcast_7
14/12/17 21:39:22 INFO storage.MemoryStore: Block broadcast_7 of size 9344 dropped from memory (free 276242760)
14/12/17 21:39:22 INFO spark.ContextCleaner: Cleaned broadcast 7
14/12/17 21:39:22 INFO parse.ParseDriver: Parsing command: SELECT REGEXP_EXTRACT(s, &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;, 1) FROM test_spark_4296 GROUP BY REGEXP_EXTRACT(s, &lt;span class=&quot;code-quote&quot;&gt;&quot;.*&quot;&lt;/span&gt;, 1)
14/12/17 21:39:22 INFO parse.ParseDriver: Parse Completed
14/12/17 21:39:22 INFO spark.ContextCleaner: Cleaned shuffle 1
14/12/17 21:39:22 INFO storage.BlockManager: Removing broadcast 6
14/12/17 21:39:22 INFO storage.BlockManager: Removing block broadcast_6_piece0
14/12/17 21:39:22 INFO storage.MemoryStore: Block broadcast_6_piece0 of size 47235 dropped from memory (free 276289995)
14/12/17 21:39:22 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on master:34621 in memory (size: 46.1 KB, free: 265.0 MB)
14/12/17 21:39:22 INFO storage.BlockManagerMaster: Updated info of block broadcast_6_piece0
14/12/17 21:39:22 INFO storage.BlockManager: Removing block broadcast_6
14/12/17 21:39:22 INFO storage.MemoryStore: Block broadcast_6 of size 523775 dropped from memory (free 276813770)
14/12/17 21:39:22 INFO spark.ContextCleaner: Cleaned broadcast 6
14/12/17 21:39:22 INFO storage.BlockManager: Removing broadcast 5
14/12/17 21:39:22 INFO storage.BlockManager: Removing block broadcast_5_piece0
14/12/17 21:39:22 INFO storage.MemoryStore: Block broadcast_5_piece0 of size 7179 dropped from memory (free 276820949)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on master:34621 in memory (size: 7.0 KB, free: 265.0 MB)
14/12/17 21:39:23 INFO storage.BlockManagerMaster: Updated info of block broadcast_5_piece0
14/12/17 21:39:23 INFO storage.BlockManager: Removing block broadcast_5
14/12/17 21:39:23 INFO storage.MemoryStore: Block broadcast_5 of size 12784 dropped from memory (free 276833733)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on slave0:50816 in memory (size: 7.0 KB, free: 534.4 MB)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on slave1:45411 in memory (size: 7.0 KB, free: 534.4 MB)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on slave2:59650 in memory (size: 7.0 KB, free: 534.4 MB)
14/12/17 21:39:23 INFO spark.ContextCleaner: Cleaned broadcast 5
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on slave1:45411 in memory (size: 7.9 KB, free: 534.4 MB)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on slave2:59650 in memory (size: 7.9 KB, free: 534.4 MB)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on slave0:50816 in memory (size: 7.9 KB, free: 534.4 MB)
14/12/17 21:39:23 ERROR thriftserver.SparkExecuteStatementOperation: Error executing query:
org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Expression not in GROUP BY: HiveSimpleUdf#org.apache.hadoop.hive.ql.udf.UDFRegExpExtract(s#609,.*,1) AS _c0#608, tree:
Aggregate [HiveSimpleUdf#org.apache.hadoop.hive.ql.udf.UDFRegExpExtract(s#609,.*,1)], [HiveSimpleUdf#org.apache.hadoop.hive.ql.udf.UDFRegExpExtract(s#609,.*,1) AS _c0#608]
 MetastoreRelation as_adventure, test_spark_4296, None

	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$$anonfun$apply$3$$anonfun$applyOrElse$7.apply(Analyzer.scala:127)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$$anonfun$apply$3$$anonfun$applyOrElse$7.apply(Analyzer.scala:126)
	at scala.Option.foreach(Option.scala:236)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$$anonfun$apply$3.applyOrElse(Analyzer.scala:126)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$$anonfun$apply$3.applyOrElse(Analyzer.scala:109)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:144)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:135)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$.apply(Analyzer.scala:109)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$CheckAggregation$.apply(Analyzer.scala:107)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1$$anonfun$apply$2.apply(RuleExecutor.scala:61)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1$$anonfun$apply$2.apply(RuleExecutor.scala:59)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldl(IndexedSeqOptimized.scala:51)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(IndexedSeqOptimized.scala:60)
	at scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:34)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1.apply(RuleExecutor.scala:59)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1.apply(RuleExecutor.scala:51)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.apply(RuleExecutor.scala:51)
	at org.apache.spark.sql.SQLContext$QueryExecution.analyzed$lzycompute(SQLContext.scala:411)
	at org.apache.spark.sql.SQLContext$QueryExecution.analyzed(SQLContext.scala:411)
	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData$lzycompute(SQLContext.scala:412)
	at org.apache.spark.sql.SQLContext$QueryExecution.withCachedData(SQLContext.scala:412)
	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan$lzycompute(SQLContext.scala:413)
	at org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan(SQLContext.scala:413)
	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:418)
	at org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:416)
	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:422)
	at org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:422)
	at org.apache.spark.sql.SchemaRDD.collect(SchemaRDD.scala:444)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:181)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatement(HiveSessionImpl.java:212)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatement(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatement(CLIService.java:220)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
14/12/17 21:39:23 WARN thrift.ThriftCLIService: Error executing statement:
org.apache.hive.service.cli.HiveSQLException: org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Expression not in GROUP BY: HiveSimpleUdf#org.apache.hadoop.hive.ql.udf.UDFRegExpExtract(s#609,.*,1) AS _c0#608, tree:
Aggregate [HiveSimpleUdf#org.apache.hadoop.hive.ql.udf.UDFRegExpExtract(s#609,.*,1)], [HiveSimpleUdf#org.apache.hadoop.hive.ql.udf.UDFRegExpExtract(s#609,.*,1) AS _c0#608]
 MetastoreRelation as_adventure, test_spark_4296, None

	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:192)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatement(HiveSessionImpl.java:212)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatement(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatement(CLIService.java:220)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
14/12/17 21:39:23 INFO storage.BlockManager: Removing broadcast 4
14/12/17 21:39:23 INFO storage.BlockManager: Removing block broadcast_4_piece0
14/12/17 21:39:23 INFO storage.MemoryStore: Block broadcast_4_piece0 of size 8076 dropped from memory (free 276841809)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on master:34621 in memory (size: 7.9 KB, free: 265.0 MB)
14/12/17 21:39:23 INFO storage.BlockManagerMaster: Updated info of block broadcast_4_piece0
14/12/17 21:39:23 INFO storage.BlockManager: Removing block broadcast_4
14/12/17 21:39:23 INFO storage.MemoryStore: Block broadcast_4 of size 14488 dropped from memory (free 276856297)
14/12/17 21:39:23 INFO spark.ContextCleaner: Cleaned broadcast 4
14/12/17 21:39:23 INFO spark.ContextCleaner: Cleaned shuffle 0
14/12/17 21:39:23 INFO storage.BlockManager: Removing broadcast 3
14/12/17 21:39:23 INFO storage.BlockManager: Removing block broadcast_3_piece0
14/12/17 21:39:23 INFO storage.MemoryStore: Block broadcast_3_piece0 of size 47609 dropped from memory (free 276903906)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on master:34621 in memory (size: 46.5 KB, free: 265.1 MB)
14/12/17 21:39:23 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0
14/12/17 21:39:23 INFO storage.BlockManager: Removing block broadcast_3
14/12/17 21:39:23 INFO storage.MemoryStore: Block broadcast_3 of size 524287 dropped from memory (free 277428193)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on slave0:50816 in memory (size: 46.5 KB, free: 534.5 MB)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on slave2:59650 in memory (size: 46.5 KB, free: 534.5 MB)
14/12/17 21:39:23 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on slave1:45411 in memory (size: 46.5 KB, free: 534.5 MB)
14/12/17 21:39:23 INFO spark.ContextCleaner: Cleaned broadcast 3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14250654" author="marmbrus" created="Wed, 17 Dec 2014 22:05:09 +0000"  >&lt;p&gt;David, is that using Spark 1.2?&lt;/p&gt;</comment>
                            <comment id="14250674" author="dyross" created="Wed, 17 Dec 2014 22:18:47 +0000"  >&lt;p&gt;Hi Michael, We are trunk: &lt;tt&gt;1.3.0-SNAPSHOT&lt;/tt&gt;, as of &lt;a href=&quot;https://github.com/apache/spark/commit/3d0c37b8118f6057a663f959321a79b8061132b6&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/3d0c37b8118f6057a663f959321a79b8061132b6&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14264874" author="lian cheng" created="Mon, 5 Jan 2015 18:36:17 +0000"  >&lt;p&gt;This issue is a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4322&quot; title=&quot;Struct fields can&amp;#39;t be used as sub-expression of grouping fields&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-4322&quot;&gt;&lt;del&gt;SPARK-4322&lt;/del&gt;&lt;/a&gt;, which has already been fixed in 1.2.0.&lt;/p&gt;</comment>
                            <comment id="14264878" author="lian cheng" created="Mon, 5 Jan 2015 18:39:14 +0000"  >&lt;p&gt;Sorry, missed David&apos;s comment below.&lt;/p&gt;</comment>
                            <comment id="14266589" author="apachespark" created="Tue, 6 Jan 2015 19:15:15 +0000"  >&lt;p&gt;User &apos;liancheng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3910&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3910&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14273194" author="yhuai" created="Mon, 12 Jan 2015 03:38:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lian+cheng&quot; class=&quot;user-hover&quot; rel=&quot;lian cheng&quot;&gt;lian cheng&lt;/a&gt; Seems this issues is similar with &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2063?focusedCommentId=14055193&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14055193&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;this one&lt;/a&gt;. The main problem is that we use the last part of a reference of a field in a struct as the alias. Is it possible that we can fix that one as well?&lt;/p&gt;</comment>
                            <comment id="14273196" author="yhuai" created="Mon, 12 Jan 2015 03:44:59 +0000"  >&lt;p&gt;I was wondering if we can also find this issue at other places. Maybe we can resolve this issue thoroughly.&lt;/p&gt;</comment>
                            <comment id="14274227" author="apachespark" created="Mon, 12 Jan 2015 21:49:39 +0000"  >&lt;p&gt;User &apos;yhuai&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4010&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4010&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14276278" author="lian cheng" created="Wed, 14 Jan 2015 00:39:25 +0000"  >&lt;p&gt;Yeah, I think whenever we use expressions that are not &lt;tt&gt;NamedExpression&lt;/tt&gt; in GROUP BY, this issue may be triggered, because an intermediate alias is introduced during analysis phase. That&apos;s why I tried to fix all similar aliases in PR #3910 (but failed).&lt;/p&gt;</comment>
                            <comment id="14285263" author="pwendell" created="Wed, 21 Jan 2015 06:50:33 +0000"  >&lt;p&gt;Note this was fixed in &lt;a href=&quot;https://github.com/apache/spark/pull/3987&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3987&lt;/a&gt; in the 1.2 branch (per discussion with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lian+cheng&quot; class=&quot;user-hover&quot; rel=&quot;lian cheng&quot;&gt;lian cheng&lt;/a&gt;).&lt;/p&gt;</comment>
                            <comment id="15935409" author="irinatruong" created="Tue, 21 Mar 2017 21:58:20 +0000"  >&lt;p&gt;I have the same exception with pyspark when my expression uses a compiled and registered Scala UDF. This is how it&apos;s registered:&lt;/p&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    sqlContext.registerJavaFunction(&quot;round_date&quot;, &apos;my.package.RoundDate&apos;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;And this is how it&apos;s called:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ipdb&amp;gt; sqlContext.sql(&quot;SELECT round_date(t.ts, &apos;1day&apos;) from (select timestamp(&apos;2017-02-02T10:11:12&apos;) as ts union select timestamp(&apos;2017-02-02T10:19:00&apos;) as ts) as t group by round_date(t.ts, &apos;1day&apos;)&quot;).show()
*** AnalysisException: u&quot;expression &apos;t.`ts`&apos; is neither present in the group by, nor is it an aggregate function. Add to group by or wrap in first() (or first_value) if you don&apos;t care which value you get.;;\nAggregate [UDF(ts#80, 1day)], [UDF(ts#80, 1day) AS UDF(ts, 1day)#82]\n+- SubqueryAlias t\n   +- Distinct\n      +- Union\n         :- Project [cast(2017-02-02T10:11:12 as timestamp) AS ts#80]\n         :  +- OneRowRelation$\n         +- Project [cast(2017-02-02T10:19:00 as timestamp) AS ts#81]\n            +- OneRowRelation$\n&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12754227">SPARK-4322</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 34 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i223pj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329029">1.2.1</customfieldvalue>
    <customfieldvalue id="12327642">1.3.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>