<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:55:13 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21782] Repartition creates skews when numPartitions is a power of 2</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21782</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;b&gt;Problem:&lt;/b&gt;&lt;br/&gt;
When an RDD (particularly with a low item-per-partition ratio) is repartitioned to &lt;tt&gt;numPartitions&lt;/tt&gt; = power of 2, the resulting partitions are very uneven-sized. This affects both &lt;tt&gt;repartition()&lt;/tt&gt; and &lt;tt&gt;coalesce(shuffle=true)&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Steps to reproduce:&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ spark-shell

scala&amp;gt; sc.parallelize(0 until 1000, 250).repartition(64).glom().map(_.length).collect()
res0: Array[Int] = Array(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 144, 250, 250, 250, 106, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;Explanation:&lt;/b&gt;&lt;br/&gt;
Currently, the &lt;a href=&quot;https://github.com/apache/spark/blob/v2.2.0/core/src/main/scala/org/apache/spark/rdd/RDD.scala#L450&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;algorithm for repartition&lt;/a&gt; (shuffle-enabled coalesce) is as follows:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for each initial partition &lt;tt&gt;index&lt;/tt&gt;, generate &lt;tt&gt;position&lt;/tt&gt; as &lt;tt&gt;(new Random(index)).nextInt(numPartitions)&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;then, for element number &lt;tt&gt;k&lt;/tt&gt; in initial partition &lt;tt&gt;index&lt;/tt&gt;, put it in the new partition &lt;tt&gt;position + k&lt;/tt&gt; (modulo &lt;tt&gt;numPartitions&lt;/tt&gt;).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;So, essentially elements are smeared roughly equally over &lt;tt&gt;numPartitions&lt;/tt&gt; buckets - starting from the one with number &lt;tt&gt;position+1&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Note that a new instance of &lt;tt&gt;Random&lt;/tt&gt; is created for every initial partition &lt;tt&gt;index&lt;/tt&gt;, with a fixed seed &lt;tt&gt;index&lt;/tt&gt;, and then discarded. So the &lt;tt&gt;position&lt;/tt&gt; is deterministic for every &lt;tt&gt;index&lt;/tt&gt; for any RDD in the world. Also, &lt;a href=&quot;http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/8u40-b25/java/util/Random.java/#393&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;nextInt(bound)&lt;/tt&gt; implementation&lt;/a&gt; has a special case when &lt;tt&gt;bound&lt;/tt&gt; is a power of 2, which is basically taking several highest bits from the initial seed, with only a minimal scrambling.&lt;/p&gt;

&lt;p&gt;Due to deterministic seed, using the generator only once, and lack of scrambling, the &lt;tt&gt;position&lt;/tt&gt; values for power-of-two &lt;tt&gt;numPartitions&lt;/tt&gt; always end up being almost the same regardless of the &lt;tt&gt;index&lt;/tt&gt;, causing some buckets to be much more popular than others. So, &lt;tt&gt;repartition&lt;/tt&gt; will in fact intentionally produce skewed partitions even when before the partition were roughly equal in size.&lt;/p&gt;

&lt;p&gt;The behavior seems to have been introduced in &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-1770&quot; title=&quot;repartition and coalesce(shuffle=true) put objects with the same key in the same bucket&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-1770&quot;&gt;&lt;del&gt;SPARK-1770&lt;/del&gt;&lt;/a&gt; by &lt;a href=&quot;https://github.com/apache/spark/pull/727/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/727/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The load balancing is not perfect: a given output partition&lt;br/&gt;
can have up to N more elements than the average if there are N input&lt;br/&gt;
partitions. However, some randomization is used to minimize the&lt;br/&gt;
probabiliy that this happens.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Another related ticket: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-17817&quot; title=&quot;PySpark RDD Repartitioning Results in Highly Skewed Partition Sizes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-17817&quot;&gt;&lt;del&gt;SPARK-17817&lt;/del&gt;&lt;/a&gt; - &lt;a href=&quot;https://github.com/apache/spark/pull/15445&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15445&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13095558">SPARK-21782</key>
            <summary>Repartition creates skews when numPartitions is a power of 2</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="megaserg">Sergey Serebryakov</assignee>
                                    <reporter username="megaserg">Sergey Serebryakov</reporter>
                        <labels>
                            <label>repartition</label>
                    </labels>
                <created>Fri, 18 Aug 2017 05:47:48 +0000</created>
                <updated>Mon, 13 Mar 2023 23:14:59 +0000</updated>
                            <resolved>Mon, 21 Aug 2017 07:21:39 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16131759" author="megaserg" created="Fri, 18 Aug 2017 05:52:18 +0000"  >&lt;p&gt;Distribution of partition sizes (in bytes) spotted in the wild. Horizontal axis: partition index (&lt;tt&gt;0..1023&lt;/tt&gt;). Vertical axis: partition size in bytes.&lt;/p&gt;</comment>
                            <comment id="16131784" author="srowen" created="Fri, 18 Aug 2017 06:12:46 +0000"  >&lt;p&gt;Is the problem summary just: with a power of 2 bound, similar seeds give similar output?&lt;br/&gt;
Isn&apos;t that solved with a better RNG or just simple scrambling of the seed bits?&lt;br/&gt;
The seed is actually essential.&lt;/p&gt;</comment>
                            <comment id="16131794" author="megaserg" created="Fri, 18 Aug 2017 06:30:14 +0000"  >&lt;p&gt;Your understanding is correct. Either reusing the same &lt;tt&gt;Random&lt;/tt&gt; instance multiple times (not really an option as shuffle is parallel), using a better RNG, or substantially scrambling the seed (hashing?) will help.&lt;br/&gt;
Changing the &quot;smearing&quot; algorithm would also work, e.g. to something like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      val distributePartition = (index: Int, items: Iterator[T]) =&amp;gt; {
         val rng = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Random(index)
         items.map { t =&amp;gt; (rng.nextInt(numPartitions), t) }
       } : Iterator[(Int, T)]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Please let me know which way you&apos;d like to see it.&lt;/p&gt;</comment>
                            <comment id="16131818" author="srowen" created="Fri, 18 Aug 2017 06:59:45 +0000"  >&lt;p&gt;I think scrambling the seed a bit is the smallest change that works, so would favor that.&lt;/p&gt;</comment>
                            <comment id="16131865" author="megaserg" created="Fri, 18 Aug 2017 07:43:19 +0000"  >&lt;p&gt;I played with Scala&apos;s `hashing.byteswap32()` and it seems to be working pretty well. Not perfect, you can still see &quot;patterns&quot; in the size distribution, but it&apos;s much better than before.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ShuffledRDD[Int, Int, Int](sc.parallelize(0 until 1000, 250).mapPartitionsWithIndex(distributePartition), &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashPartitioner(64)).glom().map(_.length).collect()
res50: Array[Int] = Array(26, 25, 18, 15, 14, 11, 13, 16, 17, 19, 21, 19, 18, 18, 14, 13, 12, 8, 14, 15, 16, 17, 13, 13, 17, 22, 22, 20, 18, 14, 14, 15, 12, 14, 13, 14, 13, 10, 10, 10, 11, 12, 11, 10, 9, 13, 16, 19, 21, 19, 17, 14, 14, 13, 14, 16, 16, 15, 16, 16, 16, 20, 24, 25)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16134809" author="srowen" created="Mon, 21 Aug 2017 07:21:39 +0000"  >&lt;p&gt;Issue resolved by pull request 18990&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18990&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18990&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17699874" author="apachespark" created="Mon, 13 Mar 2023 23:14:17 +0000"  >&lt;p&gt;User &apos;megaserg&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18990&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18990&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17699875" author="apachespark" created="Mon, 13 Mar 2023 23:14:59 +0000"  >&lt;p&gt;User &apos;megaserg&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18990&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18990&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12882514" name="Screen Shot 2017-08-16 at 3.40.01 PM.png" size="74530" author="megaserg" created="Fri, 18 Aug 2017 05:50:58 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 35 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3ixyf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>