<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:27:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-7563] OutputCommitCoordinator.stop() should only be executed in driver</title>
                <link>https://issues.apache.org/jira/browse/SPARK-7563</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I am from IBM Platform Symphony team and we are integrating Spark 1.3.1 with EGO (a resource management product).&lt;/p&gt;

&lt;p&gt;In EGO we uses fine-grained dynamic allocation policy, and each Executor will exit after its tasks are all done. When testing &lt;b&gt;spark-shell&lt;/b&gt;, we find that when executor of first job exit, it will stop OutputCommitCoordinator, which result in all future jobs failing. Details are as follows:&lt;/p&gt;

&lt;p&gt;We got the following error in executor when submitting job in &lt;b&gt;spark-shell&lt;/b&gt; the second time (the first job submission is successful):&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;15/05/11 04:02:31 INFO spark.util.AkkaUtils: Connecting to OutputCommitCoordinator: akka.tcp://sparkDriver@whlspark01:50452/user/OutputCommitCoordinator
Exception in thread &quot;main&quot; akka.actor.ActorNotFound: Actor not found for: ActorSelection[Anchor(akka.tcp://sparkDriver@whlspark01:50452/), Path(/user/OutputCommitCoordinator)]
        at akka.actor.ActorSelection$$anonfun$resolveOne$1.apply(ActorSelection.scala:65)
        at akka.actor.ActorSelection$$anonfun$resolveOne$1.apply(ActorSelection.scala:63)
        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32)
        at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.processBatch$1(BatchingExecutor.scala:67)
        at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:82)
        at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:59)
        at akka.dispatch.BatchingExecutor$Batch$$anonfun$run$1.apply(BatchingExecutor.scala:59)
        at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72)
        at akka.dispatch.BatchingExecutor$Batch.run(BatchingExecutor.scala:58)
        at akka.dispatch.ExecutionContexts$sameThreadExecutionContext$.unbatchedExecute(Future.scala:74)
        at akka.dispatch.BatchingExecutor$class.execute(BatchingExecutor.scala:110)
        at akka.dispatch.ExecutionContexts$sameThreadExecutionContext$.execute(Future.scala:73)
        at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40)
        at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248)
        at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:267)
        at akka.remote.DefaultMessageDispatcher.dispatch(Endpoint.scala:89)
        at akka.remote.EndpointReader$$anonfun$receive$2.applyOrElse(Endpoint.scala:937)
        at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
        at akka.remote.EndpointActor.aroundReceive(Endpoint.scala:415)
        at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
        at akka.actor.ActorCell.invoke(ActorCell.scala:487)
        at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
        at akka.dispatch.Mailbox.run(Mailbox.scala:220)
        at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
        at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And in driver side, we see a log message telling that the OutputCommitCoordinator is stopped after the first submission:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;15/05/11 04:01:23 INFO spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorActor: OutputCommitCoordinator stopped!
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We examine the code of OutputCommitCoordinator, and find that executor will reuse the ref of driver&apos;s OutputCommitCoordinatorActor. So when an executor exits, it will eventually call SparkEnv.stop():&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  private[spark] def stop() {
    isStopped = true
    pythonWorkers.foreach { case(key, worker) =&amp;gt; worker.stop() }
    Option(httpFileServer).foreach(_.stop())
    mapOutputTracker.stop()
    shuffleManager.stop()
    broadcastManager.stop()
    blockManager.stop()
    blockManager.master.stop()
    metricsSystem.stop()
    outputCommitCoordinator.stop()      &amp;lt;--------------- 
    actorSystem.shutdown()
    ......
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt; 

&lt;p&gt;and in OutputCommitCoordinator.stop():&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  def stop(): Unit = synchronized {
    coordinatorActor.foreach(_ ! StopCoordinator)
    coordinatorActor = None
    authorizedCommittersByStage.clear()
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We now work this problem around by adding an attribute &quot;isDriver&quot; in OutputCommitCoordinator and judge whether the &quot;stop&quot; command comes from driver or executor:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;diff SparkEnv.scala
360c360
&amp;lt;       new OutputCommitCoordinator(conf, isDriver)
---
&amp;gt;       new OutputCommitCoordinator(conf)


diff OutputCommitCoordinator.scala
43c43
&amp;lt; private[spark] class OutputCommitCoordinator(conf: SparkConf, isDriver: Boolean = false) extends Logging {
---
&amp;gt; private[spark] class OutputCommitCoordinator(conf: SparkConf) extends Logging {
137,141c137,139
&amp;lt;     if (isDriver) {
&amp;lt;       coordinatorActor.foreach(_ ! StopCoordinator)
&amp;lt;       coordinatorActor = None
&amp;lt;       authorizedCommittersByStage.clear()
&amp;lt;     }
---
&amp;gt;     coordinatorActor.foreach(_ ! StopCoordinator)
&amp;gt;     coordinatorActor = None
&amp;gt;     authorizedCommittersByStage.clear()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We propose to apply this fix in future release since it may affects all &lt;b&gt;spark-shell&lt;/b&gt; function of dynamic allocation model.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Red Hat Enterprise Linux Server release 7.0 (Maipo)&lt;br/&gt;
Spark 1.3.1 Release&lt;/p&gt;</environment>
        <key id="12829124">SPARK-7563</key>
            <summary>OutputCommitCoordinator.stop() should only be executed in driver</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="joshrosen">Josh Rosen</assignee>
                                    <reporter username="wenhailong1988">Hailong Wen</reporter>
                        <labels>
                    </labels>
                <created>Tue, 12 May 2015 08:20:20 +0000</created>
                <updated>Mon, 28 Sep 2015 08:13:06 +0000</updated>
                            <resolved>Mon, 28 Sep 2015 08:13:06 +0000</resolved>
                                    <version>1.3.1</version>
                                    <fixVersion>1.3.2</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14544290" author="pwendell" created="Thu, 14 May 2015 20:15:48 +0000"  >&lt;p&gt;/cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt; I think this is caused by the output committer change you worked on. Probably just a corner case here when executors die in the spark shell.&lt;/p&gt;</comment>
                            <comment id="14544300" author="joshrosen" created="Thu, 14 May 2015 20:23:21 +0000"  >&lt;p&gt;Yep, looks like a pretty clear bug.  I think that this messiness was introduced because we decided to use this confusing pattern where the OutputCommitCoordinator component is used both on the master and executors.  My original version of this patch separated the driver and executor componenets more explicitly, but if I recall this was changed in response to some comments during offline code review.  I should have probably fought harder to keep the separation, since having classes with sets of methods that are unsafe to call from certain locations has been a source of multiple types of bugs like this in the past.&lt;/p&gt;

&lt;p&gt;Want me to put together a pull request to apply this patch?&lt;/p&gt;</comment>
                            <comment id="14546006" author="apachespark" created="Fri, 15 May 2015 19:03:02 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/6197&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/6197&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14546468" author="pwendell" created="Sat, 16 May 2015 01:08:09 +0000"  >&lt;p&gt;I pulled the fix into 1.4.0, but not yet 1.3.2 (didn&apos;t feel comfortable doing the backport).&lt;/p&gt;</comment>
                            <comment id="14596449" author="joshrosen" created="Mon, 22 Jun 2015 19:00:11 +0000"  >&lt;p&gt;This still needs a backport.  I&apos;ll do it eventually but it would be nice if someone else could submit a PR; I&apos;ll review.&lt;/p&gt;</comment>
                            <comment id="14650652" author="apachespark" created="Sun, 2 Aug 2015 08:51:06 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7865&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7865&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 16 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2elxz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>