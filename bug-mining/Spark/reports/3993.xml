<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:47:07 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16922] Query with Broadcast Hash join fails due to executor OOM in Spark 2.0</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16922</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;A query which used to work in Spark 1.6 fails with executor OOM in 2.0.&lt;/p&gt;

&lt;p&gt;Stack trace - &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;	at org.apache.spark.unsafe.types.UTF8String.getBytes(UTF8String.java:229)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator$agg_VectorizedHashMap.hash$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator$agg_VectorizedHashMap.findOrInsert(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:161)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Query plan in Spark 1.6&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;== Physical Plan ==
TungstenAggregate(key=[field1#101], functions=[(sum((field2#74 / 100.0)),mode=Final,isDistinct=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)], output=[field1#101,field3#3])
+- TungstenExchange hashpartitioning(field1#101,200), None
   +- TungstenAggregate(key=[field1#101], functions=[(sum((field2#74 / 100.0)),mode=Partial,isDistinct=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)], output=[field1#101,sum#111])
      +- Project [field1#101,field2#74]
         +- BroadcastHashJoin [field5#63L], [&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(field4#97 as decimal(20,0)) as bigint)], BuildRight
            :- ConvertToUnsafe
            :  +- HiveTableScan [field2#74,field5#63L], MetastoreRelation foo, table1, Some(a), [(ds#57 &amp;gt;= 2013-10-01),(ds#57 &amp;lt;= 2013-12-31)]
            +- ConvertToUnsafe
               +- HiveTableScan [field1#101,field4#97], MetastoreRelation foo, table2, Some(b)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Query plan in 2.0&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;== Physical Plan ==
*HashAggregate(keys=[field1#160], functions=[sum((field2#133 / 100.0))])
+- Exchange hashpartitioning(field1#160, 200)
   +- *HashAggregate(keys=[field1#160], functions=[partial_sum((field2#133 / 100.0))])
      +- *Project [field2#133, field1#160]
         +- *BroadcastHashJoin [field5#122L], [&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(field4#156 as decimal(20,0)) as bigint)], Inner, BuildRight
            :- *Filter isnotnull(field5#122L)
            :  +- HiveTableScan [field5#122L, field2#133], MetastoreRelation foo, table1, a, [isnotnull(ds#116), (ds#116 &amp;gt;= 2013-10-01), (ds#116 &amp;lt;= 2013-12-31)]
            +- BroadcastExchange HashedRelationBroadcastMode(List(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(input[0, string, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;] as decimal(20,0)) as bigint)))
               +- *Filter isnotnull(field4#156)
                  +- HiveTableScan [field4#156, field1#160], MetastoreRelation foo, table2, b
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12995292">SPARK-16922</key>
            <summary>Query with Broadcast Hash join fails due to executor OOM in Spark 2.0</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="sitalkedia@gmail.com">Sital Kedia</reporter>
                        <labels>
                    </labels>
                <created>Fri, 5 Aug 2016 17:59:14 +0000</created>
                <updated>Sun, 17 May 2020 18:31:29 +0000</updated>
                            <resolved>Tue, 6 Sep 2016 17:47:06 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>Shuffle</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15409813" author="sitalkedia@gmail.com" created="Fri, 5 Aug 2016 18:00:44 +0000"  >&lt;p&gt;cc - &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="15409878" author="sitalkedia@gmail.com" created="Fri, 5 Aug 2016 18:33:17 +0000"  >&lt;p&gt;PS - Rerunning the query with spark.sql.codegen.aggregate.map.columns.max=0 to disabled vectorized aggregation for columnar map also OOMs, but with a different stack trace. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[Stage 1:&amp;gt;                                                        (0 + 4) / 184]16/08/05 11:26:31 WARN TaskSetManager: Lost task 2.0 in stage 1.0 (TID 4, hadoop4774.prn2.facebook.com): java.lang.OutOfMemoryError: Java heap space
	at org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder.grow(BufferHolder.java:73)
	at org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter.write(UnsafeRowWriter.java:214)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithKeys$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:161)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15410703" author="sitalkedia@gmail.com" created="Sat, 6 Aug 2016 19:31:01 +0000"  >&lt;p&gt;Update - The query works fine when Broadcast hash join in turned off, so the issue might be in broadcast hash join. I put some debug print in UnsafeRowWriter class (&lt;a href=&quot;https://github.com/apache/spark/blob/branch-2.0/sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/codegen/UnsafeRowWriter.java#L214&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/branch-2.0/sql/catalyst/src/main/java/org/apache/spark/sql/catalyst/expressions/codegen/UnsafeRowWriter.java#L214&lt;/a&gt;) and I found that it is receiving a row of size around 800MB and OOMing while trying to grow the buffer holder. It might suggest that there is some data corruption going on probably in the Broadcast hash join. &lt;/p&gt;

&lt;p&gt;cc- &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt; - Any pointer on how to debug this issue further? &lt;/p&gt;</comment>
                            <comment id="15419383" author="sitalkedia@gmail.com" created="Fri, 12 Aug 2016 20:05:59 +0000"  >&lt;p&gt;I found that the regression was introduced in &lt;a href=&quot;https://github.com/apache/spark/pull/12278&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12278&lt;/a&gt;, which introduced a new data structure (LongHashedRelation) for long types. I made a hack to use UnsafeHashedRelation instead of LongHashedRelation in &lt;a href=&quot;https://github.com/apache/spark/blob/branch-2.0/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala#L105&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/branch-2.0/sql/core/src/main/scala/org/apache/spark/sql/execution/joins/HashedRelation.scala#L105&lt;/a&gt; and things started working fine.  This might be due to some data corruption happening in LongHashedRelation. &lt;/p&gt;

&lt;p&gt;cc - &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15419434" author="davies" created="Fri, 12 Aug 2016 20:36:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sitalkedia%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;sitalkedia@gmail.com&quot;&gt;sitalkedia@gmail.com&lt;/a&gt; There are two integer overflow bugs fixed recently in LongHashedRelation, could you test with latest master? How is the range of your joining key?&lt;/p&gt;</comment>
                            <comment id="15419438" author="davies" created="Fri, 12 Aug 2016 20:38:12 +0000"  >&lt;p&gt;I think it&apos;s fixed by &lt;a href=&quot;https://github.com/apache/spark/pull/14464/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14464/files&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15419458" author="sitalkedia@gmail.com" created="Fri, 12 Aug 2016 20:47:27 +0000"  >&lt;p&gt;I am using the fix in &lt;a href=&quot;https://github.com/apache/spark/pull/14464/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14464/files&lt;/a&gt;, still the issue remains. The joining key lies in the range &lt;span class=&quot;error&quot;&gt;&amp;#91;43304915L to 10150946266075397L&amp;#93;&lt;/span&gt;&lt;/p&gt;</comment>
                            <comment id="15421484" author="davies" created="Mon, 15 Aug 2016 18:58:41 +0000"  >&lt;p&gt;Have you also have this one? &lt;a href=&quot;https://github.com/apache/spark/pull/14373&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14373&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15421524" author="sitalkedia@gmail.com" created="Mon, 15 Aug 2016 19:31:36 +0000"  >&lt;p&gt;Yes, I have the above mentioned PR as well. &lt;/p&gt;</comment>
                            <comment id="15427241" author="davies" created="Thu, 18 Aug 2016 21:58:16 +0000"  >&lt;p&gt;Is this failure determistic or not? Happened on every task or some or them? Could you also try to disable the dense mode?&lt;/p&gt;</comment>
                            <comment id="15427250" author="sitalkedia@gmail.com" created="Thu, 18 Aug 2016 22:01:15 +0000"  >&lt;p&gt;The failure is deterministic, we are reproducing the issue for every run of the job (Its not only one job, there are multiple jobs that are failing because of this). For now, we have made a change to not use the  LongHashedRelation to workaround this issue. &lt;/p&gt;</comment>
                            <comment id="15427259" author="sitalkedia@gmail.com" created="Thu, 18 Aug 2016 22:02:41 +0000"  >&lt;p&gt;&amp;gt;&amp;gt; Could you also try to disable the dense mode?&lt;/p&gt;

&lt;p&gt;I tried disabling the dense mode, that did not help either. &lt;/p&gt;</comment>
                            <comment id="15427264" author="davies" created="Thu, 18 Aug 2016 22:05:22 +0000"  >&lt;p&gt;Which serializer are you using? java serializer or Kyro?&lt;/p&gt;</comment>
                            <comment id="15427429" author="sitalkedia@gmail.com" created="Fri, 19 Aug 2016 01:01:31 +0000"  >&lt;p&gt;Kryo &lt;/p&gt;</comment>
                            <comment id="15456597" author="apachespark" created="Thu, 1 Sep 2016 21:00:07 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14927&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14927&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15456605" author="davies" created="Thu, 1 Sep 2016 21:02:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sitalkedia%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;sitalkedia@gmail.com&quot;&gt;sitalkedia@gmail.com&lt;/a&gt; I think I found the cause and fix it, could you help to test it (also check the performance improvement comparing to BytesToBytesMap)?&lt;/p&gt;</comment>
                            <comment id="15456744" author="sitalkedia@gmail.com" created="Thu, 1 Sep 2016 21:57:12 +0000"  >&lt;p&gt;Thanks for the fix &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt;. I will test this change with our job to see if that fixes the issue. &lt;/p&gt;

&lt;p&gt;PS - I am away this week. Will get to it some time next week. &lt;/p&gt;</comment>
                            <comment id="15468027" author="davies" created="Tue, 6 Sep 2016 17:47:08 +0000"  >&lt;p&gt;Issue resolved by pull request 14927&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14927&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14927&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15468339" author="sitalkedia@gmail.com" created="Tue, 6 Sep 2016 19:44:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt; -  Thanks for looking into this. I tested the failing job with the fix and it works fine now. &lt;/p&gt;</comment>
                            <comment id="15468364" author="davies" created="Tue, 6 Sep 2016 19:54:10 +0000"  >&lt;p&gt;Is there any performance difference comparing to BytesToBytesMap?&lt;/p&gt;</comment>
                            <comment id="15469092" author="sitalkedia@gmail.com" created="Wed, 7 Sep 2016 00:36:02 +0000"  >&lt;p&gt;There is no noticable performance gain I observed comparing to BytesToBytesMap. Part of the reason might be due to the fact that BroadcastHashJoin was consuming very less percentage of the total job time. &lt;/p&gt;</comment>
                            <comment id="15549494" author="davies" created="Wed, 5 Oct 2016 17:53:46 +0000"  >&lt;p&gt;Thanks for the feedback, that&apos;s reasonable.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 6 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i31z5j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>