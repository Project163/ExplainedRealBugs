<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:26:30 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-32975] Add config for driver readiness timeout before executors start</title>
                <link>https://issues.apache.org/jira/browse/SPARK-32975</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We are using v1beta2-1.1.2-2.4.5 version of operator with spark-2.4.4&lt;/p&gt;

&lt;p&gt;spark executors keeps getting killed with exit code 1 and we are seeing following exception in the executor which goes to error state. Once this error happens, driver doesn&apos;t restart executor.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;main&quot; java.lang.reflect.UndeclaredThrowableException&lt;br/&gt;
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1713)&lt;br/&gt;
at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:64)&lt;br/&gt;
at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:188)&lt;br/&gt;
at org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:281)&lt;br/&gt;
at org.apache.spark.executor.CoarseGrainedExecutorBackend.main(CoarseGrainedExecutorBackend.scala)&lt;br/&gt;
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:&lt;br/&gt;
at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)&lt;br/&gt;
at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)&lt;br/&gt;
at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)&lt;br/&gt;
at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1.apply$mcV$sp(CoarseGrainedExecutorBackend.scala:201)&lt;br/&gt;
at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:65)&lt;br/&gt;
at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:64)&lt;br/&gt;
at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
at javax.security.auth.Subject.doAs(Subject.java:422)&lt;br/&gt;
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)&lt;br/&gt;
... 4 more&lt;br/&gt;
Caused by: java.io.IOException: Failed to connect to act-pipeline-app-1600187491917-driver-svc.default.svc:7078&lt;br/&gt;
at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:245)&lt;br/&gt;
at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:187)&lt;br/&gt;
at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:198)&lt;br/&gt;
at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:194)&lt;br/&gt;
at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:190)&lt;br/&gt;
at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;br/&gt;
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;br/&gt;
at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
Caused by: java.net.UnknownHostException: act-pipeline-app-1600187491917-driver-svc.default.svc&lt;br/&gt;
at java.net.InetAddress.getAllByName0(InetAddress.java:1281)&lt;br/&gt;
at java.net.InetAddress.getAllByName(InetAddress.java:1193)&lt;br/&gt;
at java.net.InetAddress.getAllByName(InetAddress.java:1127)&lt;br/&gt;
at java.net.InetAddress.getByName(InetAddress.java:1077)&lt;br/&gt;
at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:146)&lt;br/&gt;
at io.netty.util.internal.SocketUtils$8.run(SocketUtils.java:143)&lt;br/&gt;
at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
at io.netty.util.internal.SocketUtils.addressByName(SocketUtils.java:143)&lt;br/&gt;
at io.netty.resolver.DefaultNameResolver.doResolve(DefaultNameResolver.java:43)&lt;br/&gt;
at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:63)&lt;br/&gt;
at io.netty.resolver.SimpleNameResolver.resolve(SimpleNameResolver.java:55)&lt;br/&gt;
at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:57)&lt;br/&gt;
at io.netty.resolver.InetSocketAddressResolver.doResolve(InetSocketAddressResolver.java:32)&lt;br/&gt;
at io.netty.resolver.AbstractAddressResolver.resolve(AbstractAddressResolver.java:108)&lt;br/&gt;
at io.netty.bootstrap.Bootstrap.doResolveAndConnect0(Bootstrap.java:208)&lt;br/&gt;
at io.netty.bootstrap.Bootstrap.access$000(Bootstrap.java:49)&lt;br/&gt;
at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:188)&lt;br/&gt;
at io.netty.bootstrap.Bootstrap$1.operationComplete(Bootstrap.java:174)&lt;br/&gt;
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)&lt;br/&gt;
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:481)&lt;br/&gt;
at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)&lt;br/&gt;
at io.netty.util.concurrent.DefaultPromise.trySuccess(DefaultPromise.java:104)&lt;br/&gt;
at io.netty.channel.DefaultChannelPromise.trySuccess(DefaultChannelPromise.java:82)&lt;br/&gt;
at io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetSuccess(AbstractChannel.java:978)&lt;br/&gt;
at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:512)&lt;br/&gt;
at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:423)&lt;br/&gt;
at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:482)&lt;br/&gt;
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)&lt;br/&gt;
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)&lt;br/&gt;
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)&lt;br/&gt;
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)&lt;br/&gt;
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)&lt;br/&gt;
... 1 more&lt;br/&gt;
CodeCache: size=245760Kb used=4762Kb max_used=4763Kb free=240997Kb&lt;br/&gt;
bounds &lt;span class=&quot;error&quot;&gt;&amp;#91;0x00007f49f5000000, 0x00007f49f54b0000, 0x00007f4a04000000&amp;#93;&lt;/span&gt;&lt;br/&gt;
total_blobs=1764 nmethods=1356 adapters=324&lt;br/&gt;
compilation: enabled&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Additional information:&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;The status of spark application shows it is RUNNING:&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;kubectl describe sparkapplications.sparkoperator.k8s.io act-pipeline-app&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;Status:&lt;/p&gt;

&lt;p&gt;&#160; Application State:&lt;/p&gt;

&lt;p&gt;&#160; &#160; State:&#160; RUNNING&lt;/p&gt;

&lt;p&gt;&#160; Driver Info:&lt;/p&gt;

&lt;p&gt;&#160; &#160; Pod Name: &#160; &#160; &#160; &#160; &#160; &#160; act-pipeline-app-driver&lt;/p&gt;

&lt;p&gt;&#160; &#160; Web UI Address: &#160; &#160; &#160; 10.233.57.201:40550&lt;/p&gt;

&lt;p&gt;&#160; &#160; Web UI Port:&#160; &#160; &#160; &#160; &#160; 40550&lt;/p&gt;

&lt;p&gt;&#160; &#160; Web UI Service Name:&#160; act-pipeline-app-ui-svc&lt;/p&gt;

&lt;p&gt;&#160; Execution Attempts: &#160; &#160; 1&lt;/p&gt;

&lt;p&gt;&#160; Executor State:&lt;/p&gt;

&lt;p&gt;&#160; &#160; act-pipeline-app-1600097064694-exec-1:&#160; RUNNING&lt;/p&gt;

&lt;p&gt;&#160; Last Submission Attempt Time: &#160; &#160; &#160; &#160; &#160; &#160; 2020-09-14T15:24:26Z&lt;/p&gt;

&lt;p&gt;&#160; Spark Application Id: &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; spark-942bb2e500c54f92ac357b818c712558&lt;/p&gt;

&lt;p&gt;&#160; Submission Attempts:&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 1&lt;/p&gt;

&lt;p&gt;&#160; Submission ID:&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 4ecdb6ca-d237-4524-b05e-c42cfcc73dc7&lt;/p&gt;

&lt;p&gt;&#160; Termination Time: &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &amp;lt;nil&amp;gt;&lt;/p&gt;

&lt;p&gt;Events: &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &amp;lt;none&amp;gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;The executor pod is reporting that it is Terminated:&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;kubectl describe pod -l sparkoperator.k8s.io/app-name=act-pipeline-app,spark-role=executor&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;Containers:&lt;/p&gt;

&lt;p&gt;&#160; executor:&lt;/p&gt;

&lt;p&gt;&#160; &#160; Container ID:&#160; docker://9aa5b585e8fb7390b87a4771f3ed1402cae41f0fe55905d0172ed6e90dde34e6&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;&#160; &#160; Ports: &#160; &#160; &#160; &#160; 7079/TCP, 8090/TCP&lt;/p&gt;

&lt;p&gt;&#160; &#160; Host Ports:&#160; &#160; 0/TCP, 0/TCP&lt;/p&gt;

&lt;p&gt;&#160; &#160; Args:&lt;/p&gt;

&lt;p&gt;&#160; &#160; &#160; executor&lt;/p&gt;

&lt;p&gt;&#160; &#160; State:&#160; &#160; &#160; &#160; &#160; Terminated&lt;/p&gt;

&lt;p&gt;&#160; &#160; &#160; Reason: &#160; &#160; &#160; Error&lt;/p&gt;

&lt;p&gt;&#160; &#160; &#160; Exit Code:&#160; &#160; 1&lt;/p&gt;

&lt;p&gt;&#160; &#160; &#160; Started:&#160; &#160; &#160; Mon, 14 Sep 2020 11:25:35 -0400&lt;/p&gt;

&lt;p&gt;&#160; &#160; &#160; Finished: &#160; &#160; Mon, 14 Sep 2020 11:25:39 -0400&lt;/p&gt;

&lt;p&gt;&#160; &#160; Ready:&#160; &#160; &#160; &#160; &#160; False&lt;/p&gt;

&lt;p&gt;&#160; &#160; Restart Count:&#160; 0&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;Conditions:&lt;/p&gt;

&lt;p&gt;&#160; Type&#160; &#160; &#160; &#160; &#160; &#160; &#160; Status&lt;/p&gt;

&lt;p&gt;&#160; Initialized &#160; &#160; &#160; True&lt;/p&gt;

&lt;p&gt;&#160; Ready &#160; &#160; &#160; &#160; &#160; &#160; False&lt;/p&gt;

&lt;p&gt;&#160; ContainersReady &#160; False&lt;/p&gt;

&lt;p&gt;&#160; PodScheduled&#160; &#160; &#160; True&lt;/p&gt;

&lt;p&gt;...&lt;/p&gt;

&lt;p&gt;QoS Class: &#160; &#160; &#160; Burstable&lt;/p&gt;

&lt;p&gt;Node-Selectors:&#160; &amp;lt;none&amp;gt;&lt;/p&gt;

&lt;p&gt;Tolerations: &#160; &#160; node.kubernetes.io/not-ready:NoExecute for 300s&lt;/p&gt;

&lt;p&gt;&#160;&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; node.kubernetes.io/unreachable:NoExecute for 300s&lt;/p&gt;

&lt;p&gt;Events:&#160; &#160; &#160; &#160; &#160; &amp;lt;none&amp;gt;&lt;/p&gt;

&lt;p&gt;In early stage of the driver&#8217;s life the failed executor is not detected (it is assumed to be running) and therefore it will not be restarted.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13328980">SPARK-32975</key>
            <summary>Add config for driver readiness timeout before executors start</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cchriswu">Chris Wu</assignee>
                                    <reporter username="shensonj">Shenson Joseph</reporter>
                        <labels>
                    </labels>
                <created>Wed, 23 Sep 2020 11:48:42 +0000</created>
                <updated>Fri, 18 Feb 2022 06:52:40 +0000</updated>
                            <resolved>Fri, 4 Jun 2021 14:01:00 +0000</resolved>
                                    <version>2.4.4</version>
                    <version>3.0.2</version>
                    <version>3.1.2</version>
                    <version>3.2.0</version>
                                    <fixVersion>3.2.0</fixVersion>
                    <fixVersion>3.1.3</fixVersion>
                                    <component>Kubernetes</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17200771" author="shensonj" created="Wed, 23 Sep 2020 11:51:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anirudh4444&quot; class=&quot;user-hover&quot; rel=&quot;anirudh4444&quot;&gt;anirudh4444&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eje&quot; class=&quot;user-hover&quot; rel=&quot;eje&quot;&gt;eje&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=liyinan926&quot; class=&quot;user-hover&quot; rel=&quot;liyinan926&quot;&gt;liyinan926&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17201207" author="tfasanga" created="Thu, 24 Sep 2020 01:51:20 +0000"  >&lt;p&gt;Note that the main problem is that the executor POD quits with error and Spark driver and Spark operator think it is still running, therefore the executor is never restarted.&lt;/p&gt;

&lt;p&gt;This is intermittent problem. Our testing shows that this happens frequently when the following is true:&#160;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;the driver POD has a sidecar container, and&lt;/li&gt;
	&lt;li&gt;it takes longer to initialize and start the sidecar container (this delay is caused by time required to pull the image of the sidecar container)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;In other words, this problem manifests itself when there is a delay between starting the driver &lt;b&gt;container&lt;/b&gt; and the time the driver &lt;b&gt;POD&lt;/b&gt; is fully started (the POD contains the driver container and the sidecar container).&lt;/p&gt;

&lt;p&gt;In this case we see the following events in the description of the driver POD: (see the &quot;&lt;em&gt;Pulling image &quot;registry.nspos.nokia.local/fluent/fluent-bit:1.5.5&lt;/em&gt;&quot; event that is present in this case)&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Events:
  Type     Reason       Age        From               Message
  ----     ------       ----       ----               -------
  Normal   Scheduled    &amp;lt;unknown&amp;gt;  &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-scheduler  Successfully assigned &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;/act-pipeline-app-driver to node5
  Warning  FailedMount  20m        kubelet, node5     MountVolume.SetUp failed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; volume &lt;span class=&quot;code-quote&quot;&gt;&quot;spark-conf-volume&quot;&lt;/span&gt; : configmap &lt;span class=&quot;code-quote&quot;&gt;&quot;act-pipeline-app-1600699152173-driver-conf-map&quot;&lt;/span&gt; not found
  Normal   Pulled       20m        kubelet, node5     Container image &lt;span class=&quot;code-quote&quot;&gt;&quot;registry.nspos.nokia.local/nspos-pki-container:20.9.0-rel.1&quot;&lt;/span&gt; already present on machine
  Normal   Created      20m        kubelet, node5     Created container nspos-pki
  Normal   Started      20m        kubelet, node5     Started container nspos-pki
  Normal   Pulling      20m        kubelet, node5     Pulling image &lt;span class=&quot;code-quote&quot;&gt;&quot;registry.nspos.nokia.local/analytics-rtanalytics-pipeline-app:20.9.0-rel.48&quot;&lt;/span&gt;
  Normal   Pulled       19m        kubelet, node5     Successfully pulled image &lt;span class=&quot;code-quote&quot;&gt;&quot;registry.nspos.nokia.local/analytics-rtanalytics-pipeline-app:20.9.0-rel.48&quot;&lt;/span&gt;
  Normal   Created      19m        kubelet, node5     Created container spark-kubernetes-driver
  Normal   Started      19m        kubelet, node5     Started container spark-kubernetes-driver
  Normal   Pulling      19m        kubelet, node5     Pulling image &lt;span class=&quot;code-quote&quot;&gt;&quot;registry.nspos.nokia.local/fluent/fluent-bit:1.5.5&quot;&lt;/span&gt;
  Normal   Pulled       18m        kubelet, node5     Successfully pulled image &lt;span class=&quot;code-quote&quot;&gt;&quot;registry.nspos.nokia.local/fluent/fluent-bit:1.5.5&quot;&lt;/span&gt;
  Normal   Created      18m        kubelet, node5     Created container log-sidecar
  Normal   Started      18m        kubelet, node5     Started container log-sidecar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Note: The message &quot;&lt;em&gt;MountVolume.SetUp failed for volume &quot;spark-conf-volume&quot; : configmap &quot;act-pipeline-app-1600699152173-driver-conf-map&quot; not found&lt;/em&gt;&quot; seems to be unrelated and does not seem to cause any problems.&lt;/p&gt;</comment>
                            <comment id="17355513" author="apachespark" created="Wed, 2 Jun 2021 06:43:57 +0000"  >&lt;p&gt;User &apos;cchriswu&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/32739&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/32739&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17355836" author="apachespark" created="Wed, 2 Jun 2021 16:12:59 +0000"  >&lt;p&gt;User &apos;cchriswu&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/32752&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/32752&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17357379" author="dongjoon" created="Fri, 4 Jun 2021 14:01:00 +0000"  >&lt;p&gt;Issue resolved by pull request 32752&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/32752&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/32752&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17359707" author="apachespark" created="Wed, 9 Jun 2021 02:26:03 +0000"  >&lt;p&gt;User &apos;yaooqinn&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/32830&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/32830&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17494396" author="singh-abhijeet" created="Fri, 18 Feb 2022 06:47:40 +0000"  >&lt;p&gt;Though the issue points to driver and the fix is related to a driver config, but I was getting the same error because sidecar injection was happening to executor pod and sidecar container was taking more time to initialize than the exec container.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I resolved it by adding a sleep/wait time in entrypoint.sh for exec, but it would be neat to have a &lt;em&gt;spark.kubernetes.allocation.executor.readinessWait&lt;/em&gt; config which allows to set wait time.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 38 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0iuf4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>