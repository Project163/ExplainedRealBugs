<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:08:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-29574] spark with user provided hadoop doesn&apos;t work on kubernetes</title>
                <link>https://issues.apache.org/jira/browse/SPARK-29574</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When spark-submit is run with image built with &quot;hadoop free&quot; spark and user provided hadoop it fails on kubernetes (hadoop libraries are not on spark&apos;s classpath).&#160;&lt;/p&gt;

&lt;p&gt;I downloaded spark &lt;a href=&quot;https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-without-hadoop.tgz&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Pre-built with user-provided Apache Hadoop&lt;/a&gt;.&#160;&lt;/p&gt;

&lt;p&gt;I created docker image with usage of [docker-image-tool.sh|&lt;a href=&quot;https://github.com/apache/spark/blob/master/bin/docker-image-tool.sh&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/bin/docker-image-tool.sh&lt;/a&gt;].&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Based on this image (2.4.4-without-hadoop)&lt;/p&gt;

&lt;p&gt;I created another one with Dockerfile&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
FROM spark-py:2.4.4-without-hadoop
ENV SPARK_HOME=/opt/spark/
# This is needed &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; newer kubernetes versions
ADD https:&lt;span class=&quot;code-comment&quot;&gt;//repo1.maven.org/maven2/io/fabric8/kubernetes-client/4.6.1/kubernetes-client-4.6.1.jar $SPARK_HOME/jars
&lt;/span&gt;COPY spark-env.sh /opt/spark/conf/spark-env.sh
RUN chmod +x /opt/spark/conf/spark-env.sh
RUN wget -qO- https:&lt;span class=&quot;code-comment&quot;&gt;//www-eu.apache.org/dist/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz | tar xz  -C /opt/
&lt;/span&gt;ENV HADOOP_HOME=/opt/hadoop-3.2.1
ENV PATH=${HADOOP_HOME}/bin:${PATH}

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Contents of spark-env.sh:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
#!/usr/bin/env bash
export SPARK_DIST_CLASSPATH=$(hadoop classpath):$HADOOP_HOME/share/hadoop/tools/lib/*
export LD_LIBRARY_PATH=$HADOOP_HOME/lib/&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;spark-submit run with image crated this way fails since spark-env.sh is overwritten by &lt;a href=&quot;https://github.com/apache/spark/blob/master/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/submit/KubernetesClientApplication.scala#L108&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;volume created when pod starts&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As quick workaround I tried to modify &lt;a href=&quot;https://github.com/apache/spark/blob/ea8b5df47476fe66b63bd7f7bcd15acfb80bde78/resource-managers/kubernetes/docker/src/main/dockerfiles/spark/entrypoint.sh&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;entrypoint script&lt;/a&gt; to run spark-env.sh during startup and moving spark-env.sh to a different directory. &lt;br/&gt;
 Driver starts without issues in this setup however, evethough SPARK_DIST_CLASSPATH is set executor is constantly failing:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
PS C:\Sandbox\projekty\roboticdrive-analytics\components\docker-images\spark-rda&amp;gt; kubectl logs rda-script-1571835692837-exec-12
++ id -u
+ myuid=0
++ id -g
+ mygid=0
+ set +e
++ getent passwd 0
+ uidentry=root:x:0:0:root:/root:/bin/ash
+ set -e
+ &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt; -z root:x:0:0:root:/root:/bin/ash &lt;span class=&quot;code-quote&quot;&gt;&apos;]&apos;&lt;/span&gt;
+ source /opt/spark-env.sh
+++ hadoop classpath
++ export &lt;span class=&quot;code-quote&quot;&gt;&apos;SPARK_DIST_CLASSPATH=/opt/hadoop-3.2.1/etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/hadoop-3.2.1/share/hadoop/common/*:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/hadoop-3.2.1/share/hadoo++ SPARK_DIST_CLASSPATH=&apos;&lt;/span&gt;/opt/hadoop-3.2.1/etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/hadoop-3.2.1/share/hadoop/common/*:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/*:/opt/hadoop-3.2.1/share/hadoop/yarn/*:/opt/hadoop-3.2.1/share/hadoop/tools/lib/*&apos;
++ export LD_LIBRARY_PATH=/opt/hadoop-3.2.1/lib/&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;
++ LD_LIBRARY_PATH=/opt/hadoop-3.2.1/lib/&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;
++ echo &lt;span class=&quot;code-quote&quot;&gt;&apos;SPARK_DIST_CLASSPATH=/opt/hadoop-3.2.1/etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/hadoop-3.2.1/share/hadoop/common/*:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/*:/opt/hadoop-3.2.1/share/hadoop/yarn/*:/opt/hadoop-3.2.1/share/hadoop/tools/lib/*&apos;&lt;/span&gt;
SPARK_DIST_CLASSPATH=/opt/hadoop-3.2.1/etc/hadoop:/opt/hadoop-3.2.1/share/hadoop/common/lib/*:/opt/hadoop-3.2.1/share/hadoop/common/*:/opt/hadoop-3.2.1/share/hadoop/hdfs:/opt/hadoop-3.2.1/share/hadoop/hdfs/lib/*:/opt/hadoop-3.2.1/share/hadoop/hdfs/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/lib/*:/opt/hadoop-3.2.1/share/hadoop/mapreduce/*:/opt/hadoop-3.2.1/share/hadoop/yarn:/opt/hadoop-3.2.1/share/hadoop/yarn/lib/*:/opt/hadoop-3.2.1/share/hadoop/yarn/*:/opt/hadoop-3.2.1/share/hadoop/tools/lib/*
++ echo LD_LIBRARY_PATH=/opt/hadoop-3.2.1/lib/&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;
+ SPARK_K8S_CMD=executor
LD_LIBRARY_PATH=/opt/hadoop-3.2.1/lib/&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;
+ &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;$SPARK_K8S_CMD&quot;&lt;/span&gt; in
+ shift 1
+ SPARK_CLASSPATH=&lt;span class=&quot;code-quote&quot;&gt;&apos;:/opt/spark&lt;span class=&quot;code-comment&quot;&gt;//jars/*&apos;&lt;/span&gt;
&lt;/span&gt;+ env
+ sed &lt;span class=&quot;code-quote&quot;&gt;&apos;s/[^=]*=\(.*\)/\1/g&apos;&lt;/span&gt;
+ sort -t_ -k4 -n
+ grep SPARK_JAVA_OPT_
+ readarray -t SPARK_EXECUTOR_JAVA_OPTS
+ &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt; -n &lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; &apos;&lt;/span&gt;]&apos;
+ &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt; -n &lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; &apos;&lt;/span&gt;]&apos;
+ PYSPARK_ARGS=
+ &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt; -n &lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; &apos;&lt;/span&gt;]&apos;
+ R_ARGS=
+ &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt; -n &lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; &apos;&lt;/span&gt;]&apos;
+ &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; == 2 &apos;&lt;/span&gt;]&apos;
+ &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;&apos; == 3 &apos;&lt;/span&gt;]&apos;
+ &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;$SPARK_K8S_CMD&quot;&lt;/span&gt; in
+ CMD=(${JAVA_HOME}/bin/java &lt;span class=&quot;code-quote&quot;&gt;&quot;${SPARK_EXECUTOR_JAVA_OPTS[@]}&quot;&lt;/span&gt; -Xms$SPARK_EXECUTOR_MEMORY -Xmx$SPARK_EXECUTOR_MEMORY -cp &lt;span class=&quot;code-quote&quot;&gt;&quot;$SPARK_CLASSPATH&quot;&lt;/span&gt; org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url $SPARK_DRIVER_URL --executor-id $SPARK_EXECUTOR_ID --cores $SPARK_EXECUTOR_CORES --app-id $SPARK_APPLICATION_ID --hostname $SPARK_EXECUTOR_POD_IP)
+ exec /sbin/tini -s -- /usr/lib/jvm/java-1.8-openjdk/bin/java -Xms3g -Xmx3g -cp &lt;span class=&quot;code-quote&quot;&gt;&apos;:/opt/spark&lt;span class=&quot;code-comment&quot;&gt;//jars/*&apos;&lt;/span&gt; org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@rda-script-1571835692837-driver-svc.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.svc:7078 --executor-id 12 --cores 1 --app-id spark-33382c27389c4b289d79c06d5f631819 --hostname 10.244.2.24
&lt;/span&gt;Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream
        at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:186)
        at org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:281)
        at org.apache.spark.executor.CoarseGrainedExecutorBackend.main(CoarseGrainedExecutorBackend.scala)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream
        at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:357)
        ... 3 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13264046">SPARK-29574</key>
            <summary>spark with user provided hadoop doesn&apos;t work on kubernetes</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sshakeri">Shahin Shakeri</assignee>
                                    <reporter username="wesolows">Micha&#322; Weso&#322;owski</reporter>
                        <labels>
                    </labels>
                <created>Wed, 23 Oct 2019 15:28:25 +0000</created>
                <updated>Sat, 31 Oct 2020 21:19:21 +0000</updated>
                            <resolved>Mon, 16 Dec 2019 18:12:48 +0000</resolved>
                                    <version>2.4.4</version>
                                    <fixVersion>2.4.8</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Kubernetes</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16959849" author="wesolows" created="Fri, 25 Oct 2019 15:18:39 +0000"  >&lt;p&gt;I investigated the executor issue. It doesn&apos;t handle&#160;SPARK_DIST_CLASSPATH environment variable because in kubernetes it is simply&#160;&#160;&lt;font color=&quot;#172b4d&quot;&gt;org.apache.spark.executor.CoarseGrainedExecutorBackend invoked that does not respect it. For executor to &quot;see&quot; user provided hadoop dependencies I modified entrypoint script so in case of&#160;SPARK_K8S_CMD executor it would specify classpath with $SPARK_DIST_CLASSPATH&lt;/font&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
...
executor)
  CMD=(
    ${JAVA_HOME}/bin/java
    &lt;span class=&quot;code-quote&quot;&gt;&quot;${SPARK_EXECUTOR_JAVA_OPTS[@]}&quot;&lt;/span&gt;
    -Xms$SPARK_EXECUTOR_MEMORY
    -Xmx$SPARK_EXECUTOR_MEMORY
    -cp &lt;span class=&quot;code-quote&quot;&gt;&quot;$SPARK_CLASSPATH:$SPARK_DIST_CLASSPATH&quot;&lt;/span&gt;
    org.apache.spark.executor.CoarseGrainedExecutorBackend
    --driver-url $SPARK_DRIVER_URL
    --executor-id $SPARK_EXECUTOR_ID
    --cores $SPARK_EXECUTOR_CORES
    --app-id $SPARK_APPLICATION_ID
    --hostname $SPARK_EXECUTOR_POD_IP
  ) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So there are two problems:&lt;/p&gt;

&lt;p&gt;Driver doesn&apos;t see environment variables from $SPARK_HOME/conf/spark-env.sh&#160; because this gets hidden by mounted config map, and executor doesn&apos;t take into account $SPARK_DIST_CLASSPATH at all.&#160;&lt;/p&gt;</comment>
                            <comment id="16997512" author="vanzin" created="Mon, 16 Dec 2019 18:12:48 +0000"  >&lt;p&gt;Issue resolved by pull request 26493&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/26493&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/26493&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17073145" author="drboyer" created="Wed, 1 Apr 2020 19:51:49 +0000"  >&lt;p&gt;Will this or can this change be backported to future versions of 2.4? Doing so would mean that I won&apos;t have to manually patch or fork the entrypoint.sh file in my docker images.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;It&apos;s unclear to me if this introduces a backwards-incompatible change or not.&lt;/p&gt;</comment>
                            <comment id="17224165" author="apachespark" created="Sat, 31 Oct 2020 17:21:52 +0000"  >&lt;p&gt;User &apos;dongjoon-hyun&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/30214&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/30214&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13268090">SPARK-29882</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13337686">SPARK-33271</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 2 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z07vps:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>