<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:42:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-48238] Spark fail to start due to class o.a.h.yarn.server.webproxy.amfilter.AmIpFilter is not a jakarta.servlet.Filter</title>
                <link>https://issues.apache.org/jira/browse/SPARK-48238</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I tested the latest master branch, it failed to start on YARN mode&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
dev/make-distribution.sh --tgz -Phive,hive-thriftserver,yarn&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ bin/spark-sql --master yarn
WARNING: Using incubator modules: jdk.incubator.vector
Setting &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; log level to &lt;span class=&quot;code-quote&quot;&gt;&quot;WARN&quot;&lt;/span&gt;.
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
2024-05-10 17:58:17 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
2024-05-10 17:58:18 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive} is set, falling back to uploading libraries under SPARK_HOME.
2024-05-10 17:58:25 ERROR SparkContext: Error initializing SparkContext.
org.sparkproject.jetty.util.MultiException: Multiple exceptions
&#160; &#160; at org.sparkproject.jetty.util.MultiException.ifExceptionThrow(MultiException.java:117) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.initialize(ServletHandler.java:751) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.sparkproject.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:392) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.sparkproject.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:902) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.sparkproject.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:306) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.sparkproject.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.ui.ServerInfo.addHandler(JettyUtils.scala:514) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$2(SparkUI.scala:81) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$2$adapted(SparkUI.scala:81) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619) ~[scala-library-2.13.13.jar:?]
&#160; &#160; at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617) ~[scala-library-2.13.13.jar:?]
&#160; &#160; at scala.collection.AbstractIterable.foreach(Iterable.scala:935) ~[scala-library-2.13.13.jar:?]
&#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$1(SparkUI.scala:81) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$1$adapted(SparkUI.scala:79) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.13.jar:?]
&#160; &#160; at org.apache.spark.ui.SparkUI.attachAllHandlers(SparkUI.scala:79) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.SparkContext.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$31(SparkContext.scala:690) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.SparkContext.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$31$adapted(SparkContext.scala:690) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.13.jar:?]
&#160; &#160; at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:690) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2963) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1118) ~[spark-sql_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at scala.Option.getOrElse(Option.scala:201) [scala-library-2.13.13.jar:?]
&#160; &#160; at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1112) [spark-sql_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.init(SparkSQLEnv.scala:64) [spark-hive-thriftserver_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.&amp;lt;init&amp;gt;(SparkSQLCLIDriver.scala:405) [spark-hive-thriftserver_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:162) [spark-hive-thriftserver_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala) [spark-hive-thriftserver_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
&#160; &#160; at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
&#160; &#160; at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
&#160; &#160; at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]
&#160; &#160; at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1019) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:196) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:219) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1109) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1118) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; Suppressed: java.lang.IllegalStateException: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter is not a jakarta.servlet.Filter
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.servlet.FilterHolder.doStart(FilterHolder.java:99) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.lambda$initialize$2(ServletHandler.java:724) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625) ~[?:?]
&#160; &#160; &#160; &#160; at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734) ~[?:?]
&#160; &#160; &#160; &#160; at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762) ~[?:?]
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.initialize(ServletHandler.java:749) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:392) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:902) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:306) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.ui.ServerInfo.addHandler(JettyUtils.scala:514) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$2(SparkUI.scala:81) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$2$adapted(SparkUI.scala:81) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619) ~[scala-library-2.13.13.jar:?]
&#160; &#160; &#160; &#160; at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617) ~[scala-library-2.13.13.jar:?]
&#160; &#160; &#160; &#160; at scala.collection.AbstractIterable.foreach(Iterable.scala:935) ~[scala-library-2.13.13.jar:?]
&#160; &#160; &#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$1(SparkUI.scala:81) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$1$adapted(SparkUI.scala:79) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.13.jar:?]
&#160; &#160; &#160; &#160; at org.apache.spark.ui.SparkUI.attachAllHandlers(SparkUI.scala:79) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.SparkContext.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$31(SparkContext.scala:690) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.SparkContext.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$31$adapted(SparkContext.scala:690) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at scala.Option.foreach(Option.scala:437) ~[scala-library-2.13.13.jar:?]
&#160; &#160; &#160; &#160; at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:690) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2963) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1118) ~[spark-sql_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at scala.Option.getOrElse(Option.scala:201) [scala-library-2.13.13.jar:?]
&#160; &#160; &#160; &#160; at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1112) [spark-sql_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.init(SparkSQLEnv.scala:64) [spark-hive-thriftserver_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.&amp;lt;init&amp;gt;(SparkSQLCLIDriver.scala:405) [spark-hive-thriftserver_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:162) [spark-hive-thriftserver_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala) [spark-hive-thriftserver_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
&#160; &#160; &#160; &#160; at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
&#160; &#160; &#160; &#160; at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
&#160; &#160; &#160; &#160; at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1019) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:196) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:219) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1109) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1118) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; &#160; &#160; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala) [spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
Caused by: java.lang.IllegalStateException: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter is not a jakarta.servlet.Filter
&#160; &#160; at org.sparkproject.jetty.servlet.FilterHolder.doStart(FilterHolder.java:99) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.sparkproject.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.lambda$initialize$2(ServletHandler.java:724) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625) ~[?:?]
&#160; &#160; at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734) ~[?:?]
&#160; &#160; at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762) ~[?:?]
&#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.initialize(ServletHandler.java:749) ~[spark-core_2.13-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
&#160; &#160; ... 38 more
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; MultiException[java.lang.IllegalStateException: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter is not a jakarta.servlet.Filter, java.lang.IllegalStateException: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter is not a jakarta.servlet.Filter]
&#160; &#160; at org.sparkproject.jetty.util.MultiException.ifExceptionThrow(MultiException.java:117)
&#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.initialize(ServletHandler.java:751)
&#160; &#160; at org.sparkproject.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:392)
&#160; &#160; at org.sparkproject.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:902)
&#160; &#160; at org.sparkproject.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:306)
&#160; &#160; at org.sparkproject.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93)
&#160; &#160; at org.apache.spark.ui.ServerInfo.addHandler(JettyUtils.scala:514)
&#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$2(SparkUI.scala:81)
&#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$2$adapted(SparkUI.scala:81)
&#160; &#160; at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
&#160; &#160; at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
&#160; &#160; at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
&#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$1(SparkUI.scala:81)
&#160; &#160; at org.apache.spark.ui.SparkUI.$anonfun$attachAllHandlers$1$adapted(SparkUI.scala:79)
&#160; &#160; at scala.Option.foreach(Option.scala:437)
&#160; &#160; at org.apache.spark.ui.SparkUI.attachAllHandlers(SparkUI.scala:79)
&#160; &#160; at org.apache.spark.SparkContext.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$31(SparkContext.scala:690)
&#160; &#160; at org.apache.spark.SparkContext.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$31$adapted(SparkContext.scala:690)
&#160; &#160; at scala.Option.foreach(Option.scala:437)
&#160; &#160; at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:690)
&#160; &#160; at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2963)
&#160; &#160; at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:1118)
&#160; &#160; at scala.Option.getOrElse(Option.scala:201)
&#160; &#160; at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:1112)
&#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.init(SparkSQLEnv.scala:64)
&#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.&amp;lt;init&amp;gt;(SparkSQLCLIDriver.scala:405)
&#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:162)
&#160; &#160; at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
&#160; &#160; at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
&#160; &#160; at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
&#160; &#160; at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
&#160; &#160; at java.base/java.lang.reflect.Method.invoke(Method.java:568)
&#160; &#160; at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:1019)
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:196)
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:219)
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:95)
&#160; &#160; at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1109)
&#160; &#160; at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1118)
&#160; &#160; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
&#160; &#160; Suppressed: java.lang.IllegalStateException: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter is not a jakarta.servlet.Filter
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.servlet.FilterHolder.doStart(FilterHolder.java:99)
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93)
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.lambda$initialize$2(ServletHandler.java:724)
&#160; &#160; &#160; &#160; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625)
&#160; &#160; &#160; &#160; at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)
&#160; &#160; &#160; &#160; at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
&#160; &#160; &#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.initialize(ServletHandler.java:749)
&#160; &#160; &#160; &#160; ... 38 more
Caused by: java.lang.IllegalStateException: &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter is not a jakarta.servlet.Filter
&#160; &#160; at org.sparkproject.jetty.servlet.FilterHolder.doStart(FilterHolder.java:99)
&#160; &#160; at org.sparkproject.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93)
&#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.lambda$initialize$2(ServletHandler.java:724)
&#160; &#160; at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1625)
&#160; &#160; at java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)
&#160; &#160; at java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:762)
&#160; &#160; at org.sparkproject.jetty.servlet.ServletHandler.initialize(ServletHandler.java:749)
&#160; &#160; ... 38 more &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Possibly caused by &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-45522&quot; title=&quot;Migrate jetty 9 to jetty 10&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-45522&quot;&gt;&lt;del&gt;SPARK-45522&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-47118&quot; title=&quot;Upgrade Jetty to 11&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-47118&quot;&gt;&lt;del&gt;SPARK-47118&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13578925">SPARK-48238</key>
            <summary>Spark fail to start due to class o.a.h.yarn.server.webproxy.amfilter.AmIpFilter is not a jakarta.servlet.Filter</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="chengpan">Cheng Pan</assignee>
                                    <reporter username="chengpan">Cheng Pan</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Sat, 11 May 2024 04:49:40 +0000</created>
                <updated>Wed, 5 Mar 2025 22:45:12 +0000</updated>
                            <resolved>Mon, 20 May 2024 12:43:25 +0000</resolved>
                                    <version>4.0.0</version>
                                    <fixVersion>4.0.0</fixVersion>
                                    <component>Build</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17845748" author="hf" created="Sun, 12 May 2024 21:56:57 +0000"  >&lt;p&gt;Let me have a look.&lt;/p&gt;</comment>
                            <comment id="17845749" author="hf" created="Sun, 12 May 2024 22:51:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chengpan&quot; class=&quot;user-hover&quot; rel=&quot;chengpan&quot;&gt;chengpan&lt;/a&gt;&#160; It&apos;s sad but you are right, we need to revert to Jetty 10 (The last version of Javax), until Hadoop bump their dep to Jakarta compatible version.&#160;&lt;/p&gt;</comment>
                            <comment id="17845750" author="hf" created="Sun, 12 May 2024 22:54:06 +0000"  >&lt;p&gt;I will open a few tickets on the Hadoop side to follow up on the deps bump, and link those back to this ticket.&#160;&lt;/p&gt;

&lt;p&gt;However, given the proposed timeline of Spark 4, I won&apos;t have the bandwidth to work on it in the coming weeks.&lt;/p&gt;

&lt;p&gt;If anyone takes the lead on this, feel free.&lt;/p&gt;</comment>
                            <comment id="17845781" author="chengpan" created="Mon, 13 May 2024 05:12:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=HF&quot; class=&quot;user-hover&quot; rel=&quot;HF&quot;&gt;HF&lt;/a&gt; javax =&amp;gt; jakarta migration would be complex on the Hadoop side, as Jetty version couples with Jersey, there is a long standing issue of Jersey upgrading tracked in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-15984&quot; title=&quot;Update jersey from 1.19 to 2.x&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-15984&quot;&gt;&lt;del&gt;HADOOP-15984&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For reverting, I would suggest reverting to 9.4 instead of 10, see &lt;a href=&quot;https://github.com/apache/spark/pull/43765#issuecomment-2106600268&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/43765#issuecomment-2106600268&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17846701" author="dongjoon" created="Wed, 15 May 2024 16:14:48 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chengpan&quot; class=&quot;user-hover&quot; rel=&quot;chengpan&quot;&gt;chengpan&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=HF&quot; class=&quot;user-hover&quot; rel=&quot;HF&quot;&gt;HF&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;. Is this true that we need to revert &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-45522&quot; title=&quot;Migrate jetty 9 to jetty 10&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-45522&quot;&gt;&lt;del&gt;SPARK-45522&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-47118&quot; title=&quot;Upgrade Jetty to 11&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-47118&quot;&gt;&lt;del&gt;SPARK-47118&lt;/del&gt;&lt;/a&gt; for only YARN support?&lt;br/&gt;
Do you think there is an alternative like we did for Hadoop 2 and Hadoop 3 support or Hive 1 and Hive 2 support?&lt;br/&gt;
For example, can we isolate Jetty issues to YARN module and JettyUtil via configurations?&lt;/p&gt;</comment>
                            <comment id="17846764" author="hf" created="Wed, 15 May 2024 22:06:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; I&apos;m still new to the codebase, I will need to check in exact how we currently provide backward support for Hadoop and Hive, before commenting further.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17846913" author="chengpan" created="Thu, 16 May 2024 11:15:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=HF&quot; class=&quot;user-hover&quot; rel=&quot;HF&quot;&gt;HF&lt;/a&gt; I opened &lt;a href=&quot;https://github.com/apache/spark/pull/46611&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/46611&lt;/a&gt; to address the YARN incompatible issue by re-implementing a functionally equivalent Filter, please let me know what you think about this approach.&lt;/p&gt;</comment>
                            <comment id="17847867" author="luciferyang" created="Mon, 20 May 2024 12:43:25 +0000"  >&lt;p&gt;Issue resolved by pull request 46611&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/46611&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/46611&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17932777" author="cnauroth" created="Wed, 5 Mar 2025 22:45:12 +0000"  >&lt;p&gt;Linking to &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-51408&quot; title=&quot;AmIpFilterSuite#testProxyUpdate fails in some networks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-51408&quot;&gt;&lt;del&gt;SPARK-51408&lt;/del&gt;&lt;/a&gt;, which has a follow-up to get the tests passing in my network.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13569370">SPARK-47118</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13553872">SPARK-45522</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13610799">SPARK-51408</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            35 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1p5v4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>