<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:52:57 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-20435] More thorough redaction of sensitive information from logs/UI, more unit tests</title>
                <link>https://issues.apache.org/jira/browse/SPARK-20435</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-18535&quot; title=&quot;Redact sensitive information from Spark logs and UI&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-18535&quot;&gt;&lt;del&gt;SPARK-18535&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-19720&quot; title=&quot;Redact sensitive information from SparkSubmit console output&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-19720&quot;&gt;&lt;del&gt;SPARK-19720&lt;/del&gt;&lt;/a&gt; were works to redact sensitive information (e.g. hadoop credential provider password, AWS access/secret keys) from event logs + YARN logs + UI and from the console output, respectively.&lt;/p&gt;

&lt;p&gt;While some unit tests were added along with these changes - they asserted when a sensitive key was found, that redaction took place for that key. They didn&apos;t assert globally that when running a full-fledged Spark app (whether or YARN or locally), that sensitive information was not present in any of the logs or UI. Such a test would also prevent regressions from happening in the future if someone unknowingly adds extra logging that publishes out sensitive information to disk or UI.&lt;/p&gt;

&lt;p&gt;Consequently, it was found that in some Java configurations, sensitive information was still being leaked in the event logs under the &lt;tt&gt;SparkListenerEnvironmentUpdate&lt;/tt&gt; event, like so:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-quote&quot;&gt;&quot;sun.java.command&quot;&lt;/span&gt;:&quot;org.apache.spark.deploy.SparkSubmit ... --conf spark.executorEnv.HADOOP_CREDSTORE_PASSWORD=secret_password ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&quot;secret_password&quot; should have been redacted.&lt;/p&gt;

&lt;p&gt;Moreover, previously redaction logic was only checking if the key matched the secret regex pattern, it&apos;d redact it&apos;s value. That worked for most cases. However, in the above case, the key (sun.java.command) doesn&apos;t tell much, so the value needs to be searched. So the check needs to be expanded to match against values as well.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13066043">SPARK-20435</key>
            <summary>More thorough redaction of sensitive information from logs/UI, more unit tests</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mgrover">Mark Grover</assignee>
                                    <reporter username="mgrover">Mark Grover</reporter>
                        <labels>
                    </labels>
                <created>Sat, 22 Apr 2017 00:34:12 +0000</created>
                <updated>Thu, 27 Apr 2017 05:16:50 +0000</updated>
                            <resolved>Thu, 27 Apr 2017 00:06:58 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15979651" author="vanzin" created="Sat, 22 Apr 2017 00:39:07 +0000"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;sun.java.command&quot;:&quot;org.apache.spark.deploy.SparkSubmit ... --conf spark.executorEnv.HADOOP_CREDSTORE_PASSWORD=
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If someone is typing passwords in the process&apos;s command line, they have bigger problems than the password showing up in the logs... (a.k.a. &quot;ps ax&quot;)&lt;/p&gt;</comment>
                            <comment id="15979653" author="apachespark" created="Sat, 22 Apr 2017 00:41:04 +0000"  >&lt;p&gt;User &apos;markgrover&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17725&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17725&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15979741" author="mgrover" created="Sat, 22 Apr 2017 04:13:27 +0000"  >&lt;blockquote&gt;
&lt;p&gt;If someone is typing passwords in the process&apos;s command line, they have bigger problems than the password showing up in the logs... (a.k.a. &quot;ps ax&quot;)&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thanks for your comment, Marcelo. Providing passwords that way is supported by Spark, terminal sessions finish, and ps ax works for users with appropriate privileges. Log files, on the other hand, touch disks that may not be encrypted, that may be blindly shared over unencrypted channels (say for debugging), so this is still a good thing to do, in my opinion.&lt;/p&gt;</comment>
                            <comment id="15980056" author="vanzin" created="Sat, 22 Apr 2017 17:57:45 +0000"  >&lt;blockquote&gt;&lt;p&gt;Providing passwords that way is supported by Spark&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s not an argument. You can type secrets in any command line and that doesn&apos;t make it OK.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;and ps ax works for users with appropriate privileges&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&quot;ps ax&quot; works for all users. Try it for yourself.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;vanzin@vanzin-t460p:/work/apache/spark-prs$ sudo sleep 100000
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;vanzin@vanzin-t460p:/tmp$ ps axu | grep sleep
root     32583  0.0  0.0  73264  4524 pts/5    S+   10:55   0:00 sudo sleep 100000
root     32584  0.0  0.0   7296   760 pts/5    S+   10:55   0:00 sleep 100000
vanzin   32586  0.0  0.0  14232  1072 pts/2    S+   10:56   0:00 grep --color=auto sleep
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;m not saying redacting from logs is useless, but I&apos;m saying that a user that is providing secrets in the command line is giving up any security, and redaction won&apos;t save him.&lt;/p&gt;</comment>
                            <comment id="15981730" author="mgrover" created="Mon, 24 Apr 2017 19:23:11 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m not saying redacting from logs is useless, but I&apos;m saying that a user that is providing secrets in the command line is giving up any security, and redaction won&apos;t save him.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thanks for the ps ax explanation. I appreciated your input and agree that redacting from logs is not useless.&lt;/p&gt;

&lt;p&gt;The way it is there are 2 ways to supply passwords:&lt;br/&gt;
1. The user copies over the entire conf (say from /etc/spark/conf to $USER/custom-conf). And, then updates the spark-defaults.conf with the appropriate properties containing the password. And, runs Spark jobs with this custom configuration. The benefit is that without any change in Spark today, they can run the jobs and the password won&apos;t be leaked anywhere. However, the disadvantage is it is hard to keep the custom configuration in sync given the lack of an overlay style config today in Spark. Moreover, the password is being written by the user to possibly unencrypted disk in the custom configuration.&lt;br/&gt;
2. Supply the password over command line to spark-submit. The advantage is that there&apos;s no custom configuration to be maintained, there&apos;s no password being persisted to a file by the user. However, during the duration of the job, the password is visible through output of commands like &apos;ps ax&apos; and with the current version of Spark, the password shows up in HDFS, in the event logs and anything derived from them. And, the latter may not be secure. This change is to make this case less worse by redacting passwords from HDFS event logs. Furthermore, as a benefit, we get to add some unit tests that make sure none of the redaction functionality regresses in the future.&lt;/p&gt;

&lt;p&gt;I think both the above methods have their pros and cons and I think it&apos;s best for us to document both ways and let the users choose which method they prefer. This change makes #2 slight less worse and I think it&apos;s worth doing. &lt;br/&gt;
Your points make sense, but it seems still worth making #2 less worse. And, if you agree, I&apos;d really appreciate your review of the PR. Thanks!&lt;/p&gt;</comment>
                            <comment id="15981947" author="vanzin" created="Mon, 24 Apr 2017 21:24:57 +0000"  >&lt;blockquote&gt;&lt;p&gt;The user copies over the entire conf (say from /etc/spark/conf to $USER/custom-conf). And, then updates the spark-defaults.conf with the appropriate properties containing the password.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;While that can be automated with a short script, it&apos;s unnecessarily awkward. I&apos;ve seen the idea around of having a user-specific config file appended to the default configuration automatically by Spark, but haven&apos;t seen anybody actually implement that. It would solve this problem in a cleaner manner.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Supply the password over command line to spark-submit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I hope this is not documented as a recommended way of doing this anywhere, because it&apos;s just not secure. Worst case, the user should be setting passwords via env variables (as is allowed for S3 credentials, for example, using &lt;tt&gt;AWS_ACCESS_KEY_ID&lt;/tt&gt; / &lt;tt&gt;AWS_SECRET_ACCESS_KEY&lt;/tt&gt;).&lt;/p&gt;</comment>
                            <comment id="15985781" author="mgrover" created="Thu, 27 Apr 2017 00:09:40 +0000"  >&lt;p&gt;Thanks Marcelo!&lt;/p&gt;

</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 29 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3dyhz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>