<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:45:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-51451] Regression: [UNSUPPORTED_GENERATOR.NESTED_IN_EXPRESSIONS] The generator is not supported: nested in expressions &quot;unresolvedstarwithcolumns(explode(array(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)))&quot;. SQLSTATE: 42K0E</title>
                <link>https://issues.apache.org/jira/browse/SPARK-51451</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The below code could run on classic spark. but failed to run on connect spark 4.0.0-rc2 and the latest 4.1.0-SNAPSHOT. But it could pass on spark 3.5.5&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
from pyspark.sql &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; SparkSession
from pyspark.sql.functions &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; *

spark = (SparkSession
.builder
.remote(&lt;span class=&quot;code-quote&quot;&gt;&quot;sc:&lt;span class=&quot;code-comment&quot;&gt;//localhost&quot;&lt;/span&gt;)
&lt;/span&gt;.getOrCreate())

df = spark.createDataFrame([(&lt;span class=&quot;code-quote&quot;&gt;&quot;082017&quot;&lt;/span&gt;,)], [&lt;span class=&quot;code-quote&quot;&gt;&apos;dt&apos;&lt;/span&gt;])
df_dt = df.select(date_format(to_date(col(&lt;span class=&quot;code-quote&quot;&gt;&quot;dt&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;MMyyyy&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;MM/dd/yyyy&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;dt&quot;&lt;/span&gt;))

monthArray = [lit(x) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; x in range(0, 12)]
df_month_y = df_dt.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;month_y&quot;&lt;/span&gt;, explode(array(monthArray)))

df_month_y.show()&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Spark connect throws the below exception&lt;/p&gt;

&lt;p&gt;&#160;&lt;br/&gt;
pyspark.errors.exceptions.connect.AnalysisException: &lt;span class=&quot;error&quot;&gt;&amp;#91;UNSUPPORTED_GENERATOR.NESTED_IN_EXPRESSIONS&amp;#93;&lt;/span&gt; The generator is not supported: nested in expressions &quot;unresolvedstarwithcolumns(explode(array(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)))&quot;. SQLSTATE: 42K0E&lt;br/&gt;
&#160;&lt;br/&gt;
JVM stacktrace:&lt;br/&gt;
org.apache.spark.sql.AnalysisException&lt;br/&gt;
at org.apache.spark.sql.errors.QueryCompilationErrors$.nestedGeneratorError(QueryCompilationErrors.scala:315)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$35.applyOrElse(Analyzer.scala:2914)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$$anonfun$apply$35.applyOrElse(Analyzer.scala:2911)&lt;br/&gt;
at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)&lt;br/&gt;
at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)&lt;br/&gt;
at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)&lt;br/&gt;
at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:386)&lt;br/&gt;
at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)&lt;br/&gt;
at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)&lt;br/&gt;
at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:37)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$.apply(Analyzer.scala:2911)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer$ExtractGenerator$.apply(Analyzer.scala:2839)&lt;br/&gt;
at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:242)&lt;br/&gt;
at scala.collection.LinearSeqOps.foldLeft(LinearSeq.scala:183)&lt;br/&gt;
at scala.collection.LinearSeqOps.foldLeft$(LinearSeq.scala:179)&lt;br/&gt;
at scala.collection.immutable.List.foldLeft(List.scala:79)&lt;br/&gt;
at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:239)&lt;br/&gt;
at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:231)&lt;br/&gt;
at scala.collection.immutable.List.foreach(List.scala:334)&lt;br/&gt;
at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:231)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:288)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:284)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:232)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:284)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:247)&lt;br/&gt;
at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:201)&lt;br/&gt;
at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)&lt;br/&gt;
at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:201)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:190)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:76)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:111)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:71)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:278)&lt;br/&gt;
at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:393)&lt;br/&gt;
at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:278)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:99)&lt;br/&gt;
at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:148)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:267)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:643)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:267)&lt;br/&gt;
at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:266)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:99)&lt;br/&gt;
at scala.util.Try$.apply(Try.scala:217)&lt;br/&gt;
at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1378)&lt;br/&gt;
at org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1439)&lt;br/&gt;
at org.apache.spark.util.LazyTry.get(LazyTry.scala:58)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:110)&lt;br/&gt;
at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:79)&lt;br/&gt;
at org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$1(Dataset.scala:115)&lt;br/&gt;
at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)&lt;br/&gt;
at org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:113)&lt;br/&gt;
at org.apache.spark.sql.connect.planner.SparkConnectPlanner.transformShowString(SparkConnectPlanner.scala:306)&lt;br/&gt;
at org.apache.spark.sql.connect.planner.SparkConnectPlanner.$anonfun$transformRelation$1(SparkConnectPlanner.scala:150)&lt;br/&gt;
at org.apache.spark.sql.connect.service.SessionHolder.$anonfun$usePlanCache$3(SessionHolder.scala:477)&lt;br/&gt;
at scala.Option.getOrElse(Option.scala:201)&lt;br/&gt;
at org.apache.spark.sql.connect.service.SessionHolder.usePlanCache(SessionHolder.scala:476)&lt;br/&gt;
at org.apache.spark.sql.connect.planner.SparkConnectPlanner.transformRelation(SparkConnectPlanner.scala:147)&lt;br/&gt;
at org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:74)&lt;br/&gt;
at org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handlePlan(ExecuteThreadRunner.scala:314)&lt;br/&gt;
at org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)&lt;br/&gt;
at org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:196)&lt;br/&gt;
at org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:341)&lt;br/&gt;
at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)&lt;br/&gt;
at org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:341)&lt;br/&gt;
at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)&lt;br/&gt;
at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)&lt;br/&gt;
at org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:186)&lt;br/&gt;
at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)&lt;br/&gt;
at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)&lt;br/&gt;
at org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:340)&lt;br/&gt;
at org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:196)&lt;br/&gt;
at org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:125)&lt;br/&gt;
at org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:347)&lt;/p&gt;</description>
                <environment></environment>
        <key id="13611225">SPARK-51451</key>
            <summary>Regression: [UNSUPPORTED_GENERATOR.NESTED_IN_EXPRESSIONS] The generator is not supported: nested in expressions &quot;unresolvedstarwithcolumns(explode(array(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)))&quot;. SQLSTATE: 42K0E</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ueshin">Takuya Ueshin</assignee>
                                    <reporter username="wbo4958">Bobby Wang</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 10 Mar 2025 08:16:21 +0000</created>
                <updated>Tue, 18 Mar 2025 06:24:10 +0000</updated>
                            <resolved>Tue, 18 Mar 2025 06:22:39 +0000</resolved>
                                    <version>4.1.0</version>
                    <version>4.0.0</version>
                                    <fixVersion>4.0.0</fixVersion>
                                    <component>Connect</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="17936381" author="cloud_fan" created="Tue, 18 Mar 2025 06:22:39 +0000"  >&lt;p&gt;Issue resolved by pull request 50286&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/50286&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/50286&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            34 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1uo6o:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>