<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:55:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21890] ObtainCredentials does not pass creds to addDelegationTokens</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21890</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I observed this while running a oozie job trying to connect to hbase via spark.&lt;br/&gt;
It look like the creds are not being passed in thehttps://github.com/apache/spark/blob/branch-2.2/resource-managers/yarn/src/main/scala/org/apache/spark/deploy/yarn/security/HadoopFSCredentialProvider.scala#L53 for 2.2 release.&lt;/p&gt;

&lt;p&gt;More Info as to why it fails on secure grid:&lt;br/&gt;
Oozie client gets the necessary tokens the application needs before launching.  It passes those tokens along to the oozie launcher job (MR job) which will then actually call the Spark client to launch the spark app and pass the tokens along.&lt;br/&gt;
The oozie launcher job cannot get anymore tokens because all it has is tokens ( you can&apos;t get tokens with tokens, you need tgt or keytab).  &lt;br/&gt;
The error here is because the launcher job runs the Spark Client to submit the spark job but the spark client doesn&apos;t see that it already has the hdfs tokens so it tries to get more, which ends with the exception.&lt;br/&gt;
There was  a change with &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-19021&quot; title=&quot;Generailize HDFSCredentialProvider to support non HDFS security FS&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-19021&quot;&gt;&lt;del&gt;SPARK-19021&lt;/del&gt;&lt;/a&gt; to generalize the hdfs credentials provider that changed it so we don&apos;t pass the existing credentials into the call to get tokens so it doesn&apos;t realize it already has the necessary tokens.&lt;/p&gt;


&lt;p&gt;Stack trace:&lt;br/&gt;
Warning: Skip remote jar hdfs://axonitered-nn1.red.ygrid.yahoo.com:8020/user/schintap/spark_oozie/apps/lib/spark-starter-2.0-SNAPSHOT-jar-with-dependencies.jar.&lt;br/&gt;
Failing Oozie Launcher, Main class &lt;span class=&quot;error&quot;&gt;&amp;#91;org.apache.oozie.action.hadoop.SparkMain&amp;#93;&lt;/span&gt;, main() threw exception, Delegation Token can be issued only with kerberos or web authentication&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:5858)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:687)&lt;br/&gt;
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:1003)&lt;br/&gt;
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)&lt;br/&gt;
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:448)&lt;br/&gt;
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:999)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:881)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:810)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:422)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1936)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2523)&lt;/p&gt;

&lt;p&gt;org.apache.hadoop.ipc.RemoteException(java.io.IOException): Delegation Token can be issued only with kerberos or web authentication&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:5858)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:687)&lt;br/&gt;
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:1003)&lt;br/&gt;
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)&lt;br/&gt;
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:448)&lt;br/&gt;
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:999)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:881)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:810)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at javax.security.auth.Subject.doAs(Subject.java:422)&lt;br/&gt;
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1936)&lt;br/&gt;
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2523)&lt;/p&gt;

&lt;p&gt;	at org.apache.hadoop.ipc.Client.call(Client.java:1471)&lt;br/&gt;
	at org.apache.hadoop.ipc.Client.call(Client.java:1408)&lt;br/&gt;
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)&lt;br/&gt;
	at com.sun.proxy.$Proxy10.getDelegationToken(Unknown Source)&lt;br/&gt;
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getDelegationToken(ClientNamenodeProtocolTranslatorPB.java:933)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)&lt;br/&gt;
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)&lt;br/&gt;
	at com.sun.proxy.$Proxy11.getDelegationToken(Unknown Source)&lt;br/&gt;
	at org.apache.hadoop.hdfs.DFSClient.getDelegationToken(DFSClient.java:1038)&lt;br/&gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken(DistributedFileSystem.java:1543)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.collectDelegationTokens(FileSystem.java:531)&lt;br/&gt;
	at org.apache.hadoop.fs.FileSystem.addDelegationTokens(FileSystem.java:509)&lt;br/&gt;
	at org.apache.hadoop.hdfs.DistributedFileSystem.addDelegationTokens(DistributedFileSystem.java:2228)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.security.HadoopFSCredentialProvider$$anonfun$obtainCredentials$1.apply(HadoopFSCredentialProvider.scala:53)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.security.HadoopFSCredentialProvider$$anonfun$obtainCredentials$1.apply(HadoopFSCredentialProvider.scala:50)&lt;br/&gt;
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:94)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.security.HadoopFSCredentialProvider.obtainCredentials(HadoopFSCredentialProvider.scala:50)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager$$anonfun$obtainCredentials$2.apply(ConfigurableCredentialManager.scala:82)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager$$anonfun$obtainCredentials$2.apply(ConfigurableCredentialManager.scala:80)&lt;br/&gt;
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)&lt;br/&gt;
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)&lt;br/&gt;
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)&lt;br/&gt;
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)&lt;br/&gt;
	at scala.collection.MapLike$DefaultValuesIterable.foreach(MapLike.scala:206)&lt;br/&gt;
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)&lt;br/&gt;
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.security.ConfigurableCredentialManager.obtainCredentials(ConfigurableCredentialManager.scala:80)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:393)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:896)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:173)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.Client.run(Client.scala:1190)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.Client$.main(Client.scala:1249)&lt;br/&gt;
	at org.apache.spark.deploy.yarn.Client.main(Client.scala)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:776)&lt;br/&gt;
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)&lt;br/&gt;
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)&lt;br/&gt;
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:119)&lt;br/&gt;
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)&lt;br/&gt;
	at org.apache.oozie.action.hadoop.SparkMain.runSpark(SparkMain.java:335)&lt;br/&gt;
	at org.apache.oozie.action.hadoop.SparkMain.run(SparkMain.java:265)&lt;br/&gt;
	at org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:59)&lt;br/&gt;
	at org.apache.oozie.action.hadoop.SparkMain.main(SparkMain.java:80)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)&lt;br/&gt;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
	at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
	at org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:235)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)&lt;br/&gt;
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)&lt;br/&gt;
	at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runSubtask(LocalContainerLauncher.java:380)&lt;br/&gt;
	at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runTask(LocalContainerLauncher.java:301)&lt;br/&gt;
	at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.access$200(LocalContainerLauncher.java:187)&lt;br/&gt;
	at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler$1.run(LocalContainerLauncher.java:230)&lt;br/&gt;
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;br/&gt;
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;I have already done the tests will put up a PR shortly with the updates&lt;/p&gt;</description>
                <environment></environment>
        <key id="13099046">SPARK-21890</key>
            <summary>ObtainCredentials does not pass creds to addDelegationTokens</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sanket991">Sanket Reddy</assignee>
                                    <reporter username="sanket991">Sanket Reddy</reporter>
                        <labels>
                    </labels>
                <created>Thu, 31 Aug 2017 20:14:44 +0000</created>
                <updated>Thu, 7 Sep 2017 17:21:21 +0000</updated>
                            <resolved>Thu, 7 Sep 2017 16:26:30 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.2.1</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16150589" author="apachespark" created="Fri, 1 Sep 2017 14:11:04 +0000"  >&lt;p&gt;User &apos;redsanket&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19103&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19103&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16150762" author="sanket991" created="Fri, 1 Sep 2017 15:57:47 +0000"  >&lt;p&gt;Will put up a PR for master too thanks&lt;/p&gt;</comment>
                            <comment id="16154190" author="apachespark" created="Tue, 5 Sep 2017 19:51:05 +0000"  >&lt;p&gt;User &apos;redsanket&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19140&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19140&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 10 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3jirb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>