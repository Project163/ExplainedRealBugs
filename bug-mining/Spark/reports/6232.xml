<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:36 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26339] Behavior of reading files that start with underscore is confusing</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26339</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Behavior of reading files that start with underscore is as follows.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;spark.read (no schema) throws exception which message is confusing.&lt;/li&gt;
	&lt;li&gt;spark.read (userSpecificationSchema) succesfully reads, but content is emtpy.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Example of files are as follows.&lt;br/&gt;
 The same behavior occured when I read json files.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-bash&quot;&gt;
$ cat test.csv
test1,10
test2,20
$ cp test.csv _test.csv
$ ./bin/spark-shell  --master &lt;span class=&quot;code-object&quot;&gt;local&lt;/span&gt;[2]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Spark shell snippet for reproduction:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; val df=spark.read.csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.csv&quot;&lt;/span&gt;)
df: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string]

scala&amp;gt; df.show()
+-----+---+
|  _c0|_c1|
+-----+---+
|test1| 10|
|test2| 20|
+-----+---+

scala&amp;gt; val df = spark.read.schema(&lt;span class=&quot;code-quote&quot;&gt;&quot;test STRING, number INT&quot;&lt;/span&gt;).csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;test.csv&quot;&lt;/span&gt;)
df: org.apache.spark.sql.DataFrame = [test: string, number: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]
scala&amp;gt; df.show()
+-----+------+
| test|number|
+-----+------+
|test1|    10|
|test2|    20|
+-----+------+

scala&amp;gt; val df=spark.read.csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;_test.csv&quot;&lt;/span&gt;)
org.apache.spark.sql.AnalysisException: Unable to infer schema &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; CSV. It must be specified manually.;
  at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$13(DataSource.scala:185)
  at scala.Option.getOrElse(Option.scala:138)
  at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:185)
  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:373)
  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:231)
  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:219)
  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:625)
  at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:478)
  ... 49 elided

scala&amp;gt; val df=spark.read.schema(&lt;span class=&quot;code-quote&quot;&gt;&quot;test STRING, number INT&quot;&lt;/span&gt;).csv(&lt;span class=&quot;code-quote&quot;&gt;&quot;_test.csv&quot;&lt;/span&gt;)
df: org.apache.spark.sql.DataFrame = [test: string, number: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; df.show()
+----+------+
|test|number|
+----+------+
+----+------+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I noticed that spark cannot read files that start with underscore after I read some codes.(I could not find any documents about file name limitation)&lt;/p&gt;

&lt;p&gt;Above behavior is not good especially userSpecificationSchema case, I think.&lt;/p&gt;

&lt;p&gt;I suggest to throw exception which message is &quot;Path does not exist&quot; in both cases.&lt;/p&gt;


</description>
                <environment></environment>
        <key id="13203718">SPARK-26339</key>
            <summary>Behavior of reading files that start with underscore is confusing</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Keiichi Hirobe">Keiichi Hirobe</assignee>
                                    <reporter username="Keiichi Hirobe">Keiichi Hirobe</reporter>
                        <labels>
                    </labels>
                <created>Tue, 11 Dec 2018 13:27:41 +0000</created>
                <updated>Tue, 8 Jan 2019 03:27:14 +0000</updated>
                            <resolved>Sun, 6 Jan 2019 14:52:24 +0000</resolved>
                                    <version>3.0.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="16717168" author="mgaido" created="Tue, 11 Dec 2018 13:37:38 +0000"  >&lt;p&gt;The point is: files starting with underscores are hidden files in Hadoop FS. So what you are doing is the same as reading an empty folder:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if you set the schema, an empty dataframe is returned;&lt;/li&gt;
	&lt;li&gt;if you don&apos;t set it, the schema will be inferred from the data, but since there is no data the exception occurs.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I don&apos;t think this is a bug.&lt;/p&gt;</comment>
                            <comment id="16717196" author="apachespark" created="Tue, 11 Dec 2018 13:51:27 +0000"  >&lt;p&gt;User &apos;KeiichiHirobe&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23288&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23288&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16717961" author="githubbot" created="Tue, 11 Dec 2018 20:34:49 +0000"  >&lt;p&gt;srowen commented on a change in pull request #23288: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26339&quot; title=&quot;Behavior of reading files that start with underscore is confusing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26339&quot;&gt;&lt;del&gt;SPARK-26339&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;SQL&amp;#93;&lt;/span&gt;Throws better exception when reading files that start with underscore&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/spark/pull/23288#discussion_r240781003&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23288#discussion_r240781003&lt;/a&gt;&lt;/p&gt;



&lt;p&gt; ##########&lt;br/&gt;
 File path: sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala&lt;br/&gt;
 ##########&lt;br/&gt;
 @@ -554,7 +554,8 @@ case class DataSource(&lt;/p&gt;

&lt;p&gt;       // Sufficient to check head of the globPath seq for non-glob scenario&lt;br/&gt;
       // Don&apos;t need to check once again if files exist in streaming mode&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (checkFilesExist &amp;amp;&amp;amp; !fs.exists(globPath.head)) {&lt;br/&gt;
+      if (checkFilesExist &amp;amp;&amp;amp;&lt;br/&gt;
+          (!fs.exists(globPath.head) || InMemoryFileIndex.shouldFilterOut(globPath.head.getName))) {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Review comment:&lt;br/&gt;
   I&apos;m probably misunderstanding, but doesn&apos;t this still cause it to throw a &apos;Path does not exist&apos; exception?&lt;/p&gt;

&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16731362" author="srowen" created="Mon, 31 Dec 2018 16:16:19 +0000"  >&lt;p&gt;Issue resolved by pull request 23288&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23288&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23288&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16733844" author="apachespark" created="Fri, 4 Jan 2019 06:03:07 +0000"  >&lt;p&gt;User &apos;KeiichiHirobe&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23446&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23446&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16733846" author="apachespark" created="Fri, 4 Jan 2019 06:03:55 +0000"  >&lt;p&gt;User &apos;KeiichiHirobe&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23446&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23446&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16735205" author="srowen" created="Sun, 6 Jan 2019 14:52:24 +0000"  >&lt;p&gt;Issue resolved by pull request 23446&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23446&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23446&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 45 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s01ec0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>