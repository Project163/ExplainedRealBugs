<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:36:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-12350] VectorAssembler#transform() initially throws an exception</title>
                <link>https://issues.apache.org/jira/browse/SPARK-12350</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Calling VectorAssembler.transform() initially throws an exception, subsequent calls work.&lt;/p&gt;

&lt;h3&gt;&lt;a name=&quot;Stepstoreproduce&quot;&gt;&lt;/a&gt;Steps to reproduce&lt;/h3&gt;
&lt;p&gt;In spark-shell,&lt;br/&gt;
1. Create a dummy dataframe and define an assembler&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.ml.feature.VectorAssembler
val df = sc.parallelize(List((1,2), (3,4))).toDF
val assembler = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; VectorAssembler().setInputCols(Array(&lt;span class=&quot;code-quote&quot;&gt;&quot;_1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;_2&quot;&lt;/span&gt;)).setOutputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;features&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2. Run&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;assembler.transform(df).show
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Initially the following exception is thrown:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/12/15 16:20:19 ERROR TransportRequestHandler: Error opening stream /classes/org/apache/spark/sql/catalyst/expressions/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; request from /9.72.139.102:60610
java.lang.IllegalArgumentException: requirement failed: File not found: /classes/org/apache/spark/sql/catalyst/expressions/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;.class
	at scala.Predef$.require(Predef.scala:233)
	at org.apache.spark.rpc.netty.NettyStreamManager.openStream(NettyStreamManager.scala:60)
	at org.apache.spark.network.server.TransportRequestHandler.processStreamRequest(TransportRequestHandler.java:136)
	at org.apache.spark.network.server.TransportRequestHandler.handle(TransportRequestHandler.java:106)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:104)
	at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:51)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at org.apache.spark.network.util.TransportFrameDecoder.channelRead(TransportFrameDecoder.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:308)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:294)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:846)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Subsequent calls work:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;+---+---+---------+
| _1| _2| features|
+---+---+---------+
|  1|  2|[1.0,2.0]|
|  3|  4|[3.0,4.0]|
+---+---+---------+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems as though there is some internal state that is not initialized.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iyounus&quot; class=&quot;user-hover&quot; rel=&quot;iyounus&quot;&gt;iyounus&lt;/a&gt; originally found this issue.&lt;/p&gt;</description>
                <environment>&lt;p&gt;sparkShell command from sbt&lt;/p&gt;</environment>
        <key id="12922207">SPARK-12350</key>
            <summary>VectorAssembler#transform() initially throws an exception</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vanzin">Marcelo Masiero Vanzin</assignee>
                                    <reporter username="jodersky">Jakob Odersky</reporter>
                        <labels>
                    </labels>
                <created>Wed, 16 Dec 2015 00:34:00 +0000</created>
                <updated>Fri, 18 Dec 2015 17:49:40 +0000</updated>
                            <resolved>Fri, 18 Dec 2015 17:49:40 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>Spark Core</component>
                    <component>Spark Shell</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15059788" author="yanboliang" created="Wed, 16 Dec 2015 10:14:51 +0000"  >&lt;p&gt;I can reproduce this issue, but it not caused by ML because it can output the transformed dataframe at the end of the error log. And if we did not run this program in spark-shell, it works well.&lt;/p&gt;</comment>
                            <comment id="15060500" author="jodersky" created="Wed, 16 Dec 2015 18:39:55 +0000"  >&lt;p&gt;You&apos;re right, somewhere in the huge stack trace output I also see the dataframe displayed as a table&lt;br/&gt;
The error only occurs in the latest upstream&lt;/p&gt;</comment>
                            <comment id="15060650" author="jodersky" created="Wed, 16 Dec 2015 19:40:55 +0000"  >&lt;p&gt;A git-bisect showed that the issue was introduced in 4a46b8859d3314b5b45a67cdc5c81fecb6e9e78c, a commit that fixes &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-11563&quot; title=&quot;Use RpcEnv to transfer generated classes in spark-shell&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-11563&quot;&gt;&lt;del&gt;SPARK-11563&lt;/del&gt;&lt;/a&gt;.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt;, any idea what could have gone wrong?&lt;/p&gt;</comment>
                            <comment id="15060668" author="vanzin" created="Wed, 16 Dec 2015 19:48:17 +0000"  >&lt;p&gt;So, if I understand correctly, the issue is just the scary log message, not because there&apos;s anything wrong with the functionality?&lt;/p&gt;</comment>
                            <comment id="15060705" author="jodersky" created="Wed, 16 Dec 2015 19:58:09 +0000"  >&lt;p&gt;The end result seems to work, the console is however spammed with error messages.&lt;br/&gt;
I think it is due to a `require` that fails in &lt;tt&gt;core/src/main/scala/org/apache/spark/rpc/netty/NettyStreamManager.scala&lt;/tt&gt;, line 60.&lt;br/&gt;
See my comment on &lt;a href=&quot;https://github.com/apache/spark/commit/4a46b8859d3314b5b45a67cdc5c81fecb6e9e78c#commitcomment-15024736&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/4a46b8859d3314b5b45a67cdc5c81fecb6e9e78c#commitcomment-15024736&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15060721" author="vanzin" created="Wed, 16 Dec 2015 20:02:06 +0000"  >&lt;p&gt;I understand where the exception is coming from, I&apos;m asking whether there&apos;s any actual functionality broken by this or is it just about the ugly exception being printed to the terminal.&lt;/p&gt;

&lt;p&gt;It seems there&apos;s not, so it&apos;s just about silencing the exception.&lt;/p&gt;</comment>
                            <comment id="15060732" author="jodersky" created="Wed, 16 Dec 2015 20:06:07 +0000"  >&lt;p&gt;No functionality is broken, so if the exception can be silenced it would be a possible fix.&lt;/p&gt;

&lt;p&gt;However, even if there is no loss of functionality, should the exception not be treated as an error?&lt;/p&gt;</comment>
                            <comment id="15060740" author="vanzin" created="Wed, 16 Dec 2015 20:08:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;should the exception not be treated as an error?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No because the class might exist in other class loaders in the chain, as is the case here.&lt;/p&gt;</comment>
                            <comment id="15060773" author="jodersky" created="Wed, 16 Dec 2015 20:22:50 +0000"  >&lt;p&gt;Ok, but then why throw an exception in the first place?&lt;/p&gt;</comment>
                            <comment id="15060788" author="vanzin" created="Wed, 16 Dec 2015 20:31:26 +0000"  >&lt;p&gt;Well, that&apos;s what the fix will be.&lt;/p&gt;</comment>
                            <comment id="15060819" author="jodersky" created="Wed, 16 Dec 2015 20:44:04 +0000"  >&lt;p&gt;Ok, thanks!&lt;/p&gt;</comment>
                            <comment id="15060873" author="apachespark" created="Wed, 16 Dec 2015 21:10:05 +0000"  >&lt;p&gt;User &apos;vanzin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10337&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10337&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12922354">SPARK-12366</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 48 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2py7z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>