<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:17:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-31923] Event log cannot be generated when some internal accumulators use unexpected types</title>
                <link>https://issues.apache.org/jira/browse/SPARK-31923</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;A user may use internal accumulators by adding the &quot;internal.metrics.&quot; prefix to the accumulator name to hide sensitive information from UI (Accumulators except internal ones will be shown in Spark UI).&lt;/p&gt;

&lt;p&gt;However, &lt;b&gt;org.apache.spark.util.JsonProtocol.accumValueToJson&lt;/b&gt; assumes an internal accumulator has only 3 possible types: int, long, and java.util.List&lt;span class=&quot;error&quot;&gt;&amp;#91;(BlockId, BlockStatus)&amp;#93;&lt;/span&gt;. When an internal accumulator uses an unexpected type, it will crash.&lt;/p&gt;

&lt;p&gt;An event log that contains such accumulator will be dropped because it cannot be converted to JSON, and it will cause weird UI issue when rendering in Spark History Server. For example, if `SparkListenerTaskEnd` is dropped because of this issue, the user will see the task is still running even if it was finished.&lt;/p&gt;

&lt;p&gt;It&apos;s better to make &lt;b&gt;accumValueToJson&lt;/b&gt; more robust.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;How to reproduce it:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Enable Spark event log&lt;/li&gt;
	&lt;li&gt;Run the following command:&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; val accu = sc.doubleAccumulator(&lt;span class=&quot;code-quote&quot;&gt;&quot;internal.metrics.foo&quot;&lt;/span&gt;)
accu: org.apache.spark.util.DoubleAccumulator = DoubleAccumulator(id: 0, name: Some(internal.metrics.foo), value: 0.0)

scala&amp;gt; sc.parallelize(1 to 1, 1).foreach { _ =&amp;gt; accu.add(1.0) }
20/06/06 16:11:27 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception
java.lang.ClassCastException: java.lang.&lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt; cannot be &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; to java.util.List
	at org.apache.spark.util.JsonProtocol$.accumValueToJson(JsonProtocol.scala:330)
	at org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$3.apply(JsonProtocol.scala:306)
	at org.apache.spark.util.JsonProtocol$$anonfun$accumulableInfoToJson$3.apply(JsonProtocol.scala:306)
	at scala.Option.map(Option.scala:146)
	at org.apache.spark.util.JsonProtocol$.accumulableInfoToJson(JsonProtocol.scala:306)
	at org.apache.spark.util.JsonProtocol$$anonfun$accumulablesToJson$2.apply(JsonProtocol.scala:299)
	at org.apache.spark.util.JsonProtocol$$anonfun$accumulablesToJson$2.apply(JsonProtocol.scala:299)
	at scala.collection.immutable.List.map(List.scala:284)
	at org.apache.spark.util.JsonProtocol$.accumulablesToJson(JsonProtocol.scala:299)
	at org.apache.spark.util.JsonProtocol$.taskInfoToJson(JsonProtocol.scala:291)
	at org.apache.spark.util.JsonProtocol$.taskEndToJson(JsonProtocol.scala:145)
	at org.apache.spark.util.JsonProtocol$.sparkEventToJson(JsonProtocol.scala:76)
	at org.apache.spark.scheduler.EventLoggingListener.logEvent(EventLoggingListener.scala:138)
	at org.apache.spark.scheduler.EventLoggingListener.onTaskEnd(EventLoggingListener.scala:158)
	at org.apache.spark.scheduler.SparkListenerBus$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;doPostEvent(SparkListenerBus.scala:45)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1302)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

</description>
                <environment></environment>
        <key id="13309903">SPARK-31923</key>
            <summary>Event log cannot be generated when some internal accumulators use unexpected types</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zsxwing">Shixiong Zhu</assignee>
                                    <reporter username="zsxwing">Shixiong Zhu</reporter>
                        <labels>
                    </labels>
                <created>Sat, 6 Jun 2020 23:12:07 +0000</created>
                <updated>Mon, 12 Apr 2021 18:38:53 +0000</updated>
                            <resolved>Mon, 8 Jun 2020 23:54:08 +0000</resolved>
                                    <version>2.3.0</version>
                    <version>2.3.1</version>
                    <version>2.3.2</version>
                    <version>2.3.3</version>
                    <version>2.3.4</version>
                    <version>2.4.0</version>
                    <version>2.4.1</version>
                    <version>2.4.2</version>
                    <version>2.4.3</version>
                    <version>2.4.4</version>
                    <version>2.4.5</version>
                    <version>2.4.6</version>
                                    <fixVersion>2.4.7</fixVersion>
                    <fixVersion>3.0.1</fixVersion>
                    <fixVersion>3.1.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="17127444" author="apachespark" created="Sat, 6 Jun 2020 23:23:17 +0000"  >&lt;p&gt;User &apos;zsxwing&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28744&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28744&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17128639" author="apachespark" created="Mon, 8 Jun 2020 20:41:57 +0000"  >&lt;p&gt;User &apos;zsxwing&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28758&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28758&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17319622" author="jystephan" created="Mon, 12 Apr 2021 17:44:39 +0000"  >&lt;p&gt;Hi&#160;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zsxwing&quot; class=&quot;user-hover&quot; rel=&quot;zsxwing&quot;&gt;zsxwing&lt;/a&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&#160;&lt;/p&gt;

&lt;p&gt;Despite your patch, we&apos;re running in the same issue while using Spark 3.0.1. The stack trace is informative (for the line numbers we need to refer to this file&#160;&lt;a href=&quot;https://github.com/apache/spark/blob/v3.0.1/core/src/main/scala/org/apache/spark/util/JsonProtocol.scala#L354&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v3.0.1/core/src/main/scala/org/apache/spark/util/JsonProtocol.scala#L354&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The problem is that we&apos;re given a class (java.util.Collections$SynchronizedSet) that enters the branch&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; v: java.util.List[_] =&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but on the next line the cast&#160;v.asScala.toList fails.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;br/&gt;
Question: Is there a workaround available through spark configurations? E.g. a flag to disable the metrics being collected here?&lt;/p&gt;



&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;21/04/12 15:11:40 ERROR AsyncEventQueue: Listener EventLoggingListener threw an exception&lt;/p&gt;

&lt;p&gt;java.lang.ClassCastException: java.util.Collections$SynchronizedSet cannot be cast to java.util.List at org.apache.spark.util.JsonProtocol$.accumValueToJson(JsonProtocol.scala:355) at org.apache.spark.util.JsonProtocol$.$anonfun$accumulableInfoToJson$4(JsonProtocol.scala:331) at scala.Option.map(Option.scala:230) at org.apache.spark.util.JsonProtocol$.accumulableInfoToJson(JsonProtocol.scala:331) at org.apache.spark.util.JsonProtocol$.$anonfun$accumulablesToJson$3(JsonProtocol.scala:324) at scala.collection.immutable.List.map(List.scala:290) at org.apache.spark.util.JsonProtocol$.accumulablesToJson(JsonProtocol.scala:324) at org.apache.spark.util.JsonProtocol$.taskInfoToJson(JsonProtocol.scala:316) at org.apache.spark.util.JsonProtocol$.taskEndToJson(JsonProtocol.scala:151) at org.apache.spark.util.JsonProtocol$.sparkEventToJson(JsonProtocol.scala:79) at org.apache.spark.scheduler.EventLoggingListener.logEvent(EventLoggingListener.scala:97) at org.apache.spark.scheduler.EventLoggingListener.onTaskEnd(EventLoggingListener.scala:119) at org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:45) at org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)&#160;&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17319631" author="zsxwing" created="Mon, 12 Apr 2021 18:02:39 +0000"  >&lt;p&gt;Do you have a reproduction? It&apos;s weird to see `java.util.Collections$SynchronizedSet cannot be cast to java.util.List` since before calling `v.asScala.toList`, the pattern match `case v: java.util.List&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;` should not accept `java.util.Collections$SynchronizedSet`.&lt;/p&gt;</comment>
                            <comment id="17319652" author="jystephan" created="Mon, 12 Apr 2021 18:38:53 +0000"  >&lt;p&gt;After further investigation, I confirmed this is a red herring - our end user was using Spark 3.0.0 after all. Thanks for checking.&#160;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 31 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0fl5s:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>