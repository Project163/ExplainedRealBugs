<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:36:11 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-12155] Execution OOM after a relative large dataset cached in the cluster.</title>
                <link>https://issues.apache.org/jira/browse/SPARK-12155</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I have a cluster with relative 80GB of mem. Then, I cached a 43GB dataframe. When I start to consume the query. I got the following exception (I added more logs to the code).&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/12/05 00:33:43 INFO UnifiedMemoryManager: Creating UnifedMemoryManager &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 4 cores with 16929521664 maxMemory, 8464760832 storageRegionSize.


15/12/05 01:20:50 INFO MemoryStore: Ensuring 1048576 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 3253659951, max: 16798973952)
15/12/05 01:20:50 INFO MemoryStore: Ensuring 5142008 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 3252611375, max: 16798973952)
15/12/05 01:20:50 INFO Executor: Finished task 36.0 in stage 4.0 (TID 109). 3028 bytes result sent to driver
15/12/05 01:20:50 INFO MemoryStore: Ensuring 98948238 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 3314840375, max: 16866344960)
15/12/05 01:20:50 INFO MemoryStore: Ensuring 98675713 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 3215892137, max: 16866344960)
15/12/05 01:20:50 INFO MemoryStore: Ensuring 197347565 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 3117216424, max: 16866344960)
15/12/05 01:20:50 INFO MemoryStore: Ensuring 295995553 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 2919868859, max: 16866344960)
15/12/05 01:20:51 INFO MemoryStore: Ensuring 394728479 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 2687050010, max: 16929521664)
15/12/05 01:20:51 INFO Executor: Finished task 32.0 in stage 4.0 (TID 106). 3028 bytes result sent to driver
15/12/05 01:20:51 INFO MemoryStore: Ensuring 591258816 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 2292321531, max: 16929521664)
15/12/05 01:20:51 INFO MemoryStore: Ensuring 901645182 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 1701062715, max: 16929521664)
15/12/05 01:20:52 INFO MemoryStore: Ensuring 1302179076 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block rdd_94_37(free: 799417533, max: 16929521664)
15/12/05 01:20:52 INFO MemoryStore: Will not store rdd_94_37 as it would require dropping another block from the same RDD
15/12/05 01:20:52 WARN MemoryStore: Not enough space to cache rdd_94_37 in memory! (computed 2.4 GB so far)
15/12/05 01:20:52 INFO MemoryStore: Memory use = 12.6 GB (blocks) + 2.4 GB (scratch space shared across 13 tasks(s)) = 15.0 GB. Storage limit = 15.8 GB.
15/12/05 01:20:52 INFO BlockManager: Found block rdd_94_37 locally
15/12/05 01:20:52 INFO UnifiedMemoryManager: Try to acquire 262144 bytes memory. But, on-heap execution memory poll only has 0 bytes free memory.
15/12/05 01:20:52 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8464760832, storageMemoryPool.poolSize 16929521664, storageRegionSize 8464760832.
15/12/05 01:20:52 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.
15/12/05 01:20:52 INFO StorageMemoryPool: Claiming 262144 bytes free memory space from StorageMemoryPool.
15/12/05 01:20:52 INFO UnifiedMemoryManager: Reclaimed 262144 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.
15/12/05 01:20:52 INFO UnifiedMemoryManager: Try to acquire 67108864 bytes memory. But, on-heap execution memory poll only has 0 bytes free memory.
15/12/05 01:20:52 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8464498688, storageMemoryPool.poolSize 16929259520, storageRegionSize 8464760832.
15/12/05 01:20:52 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.
15/12/05 01:20:52 INFO StorageMemoryPool: Claiming 67108864 bytes free memory space from StorageMemoryPool.
15/12/05 01:20:52 INFO UnifiedMemoryManager: Reclaimed 67108864 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.
15/12/05 01:20:54 INFO Executor: Finished task 37.0 in stage 4.0 (TID 110). 3077 bytes result sent to driver
15/12/05 01:20:56 INFO CoarseGrainedExecutorBackend: Got assigned task 120
15/12/05 01:20:56 INFO Executor: Running task 1.0 in stage 5.0 (TID 120)
15/12/05 01:20:56 INFO CoarseGrainedExecutorBackend: Got assigned task 124
15/12/05 01:20:56 INFO CoarseGrainedExecutorBackend: Got assigned task 128
15/12/05 01:20:56 INFO CoarseGrainedExecutorBackend: Got assigned task 132
15/12/05 01:20:56 INFO Executor: Running task 9.0 in stage 5.0 (TID 128)
15/12/05 01:20:56 INFO Executor: Running task 13.0 in stage 5.0 (TID 132)
15/12/05 01:20:56 INFO Executor: Running task 5.0 in stage 5.0 (TID 124)
15/12/05 01:20:56 INFO MapOutputTrackerWorker: Updating epoch to 2 and clearing cache
15/12/05 01:20:56 INFO TorrentBroadcast: Started reading broadcast variable 6
15/12/05 01:20:56 INFO MemoryStore: Ensuring 9471 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block broadcast_6_piece0(free: 3384207663, max: 16929521664)
15/12/05 01:20:56 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.2 KB, free 12.6 GB)
15/12/05 01:20:56 INFO TorrentBroadcast: Reading broadcast variable 6 took 5 ms
15/12/05 01:20:56 INFO MemoryStore: Ensuring 1048576 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block broadcast_6(free: 3384198192, max: 16929521664)
15/12/05 01:20:56 INFO MemoryStore: Ensuring 22032 bytes of free space &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block broadcast_6(free: 3384198192, max: 16929521664)
15/12/05 01:20:56 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 21.5 KB, free 12.6 GB)
15/12/05 01:20:56 INFO MapOutputTrackerWorker: Don&apos;t have map outputs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; shuffle 1, fetching them
15/12/05 01:20:56 INFO MapOutputTrackerWorker: Don&apos;t have map outputs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; shuffle 1, fetching them
15/12/05 01:20:56 INFO MapOutputTrackerWorker: Don&apos;t have map outputs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; shuffle 1, fetching them
15/12/05 01:20:56 INFO MapOutputTrackerWorker: Don&apos;t have map outputs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; shuffle 1, fetching them
15/12/05 01:20:56 INFO MapOutputTrackerWorker: Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark:&lt;span class=&quot;code-comment&quot;&gt;//MapOutputTracker@10.0.202.130:56969)
&lt;/span&gt;15/12/05 01:20:56 INFO MapOutputTrackerWorker: Got the output locations
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Getting 43 non-empty blocks out of 43 blocks
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Getting 43 non-empty blocks out of 43 blocks
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Getting 43 non-empty blocks out of 43 blocks
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Getting 43 non-empty blocks out of 43 blocks
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Started 3 remote fetches in 41 ms
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Started 3 remote fetches in 41 ms
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Started 3 remote fetches in 40 ms
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Started 3 remote fetches in 41 ms
15/12/05 01:20:56 INFO UnifiedMemoryManager: Try to acquire 67108864 bytes memory. But, on-heap execution memory poll only has 66846720 bytes free memory.
15/12/05 01:20:56 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8397389824, storageMemoryPool.poolSize 16862150656, storageRegionSize 8464760832.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.
15/12/05 01:20:56 INFO StorageMemoryPool: Claiming 262144 bytes free memory space from StorageMemoryPool.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Reclaimed 262144 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Try to acquire 67108864 bytes memory. But, on-heap execution memory poll only has 33554432 bytes free memory.
15/12/05 01:20:56 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8397127680, storageMemoryPool.poolSize 16861888512, storageRegionSize 8464760832.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.
15/12/05 01:20:56 INFO StorageMemoryPool: Claiming 33554432 bytes free memory space from StorageMemoryPool.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Reclaimed 33554432 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.
15/12/05 01:20:56 INFO GenerateMutableProjection: Code generated in 9.602791 ms
15/12/05 01:20:56 INFO GenerateMutableProjection: Code generated in 12.7135 ms
15/12/05 01:20:56 INFO Executor: Finished task 13.0 in stage 5.0 (TID 132). 2271 bytes result sent to driver
15/12/05 01:20:56 INFO Executor: Finished task 9.0 in stage 5.0 (TID 128). 2320 bytes result sent to driver
15/12/05 01:20:56 INFO CoarseGrainedExecutorBackend: Got assigned task 136
15/12/05 01:20:56 INFO CoarseGrainedExecutorBackend: Got assigned task 137
15/12/05 01:20:56 INFO Executor: Running task 17.0 in stage 5.0 (TID 136)
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Getting 43 non-empty blocks out of 43 blocks
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Started 3 remote fetches in 1 ms
15/12/05 01:20:56 INFO UnifiedMemoryManager: Try to acquire 67108864 bytes memory. But, on-heap execution memory poll only has 16515072 bytes free memory.
15/12/05 01:20:56 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8363573248, storageMemoryPool.poolSize 16828334080, storageRegionSize 8464760832.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.
15/12/05 01:20:56 INFO StorageMemoryPool: Claiming 50593792 bytes free memory space from StorageMemoryPool.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Reclaimed 50593792 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.
15/12/05 01:20:56 INFO Executor: Running task 18.0 in stage 5.0 (TID 137)
15/12/05 01:20:56 INFO GenerateUnsafeProjection: Code generated in 30.25836 ms
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Getting 43 non-empty blocks out of 43 blocks
15/12/05 01:20:56 INFO ShuffleBlockFetcherIterator: Started 3 remote fetches in 2 ms
15/12/05 01:20:56 INFO UnifiedMemoryManager: Try to acquire 67108864 bytes memory. But, on-heap execution memory poll only has 16515072 bytes free memory.
15/12/05 01:20:56 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8312979456, storageMemoryPool.poolSize 16777740288, storageRegionSize 8464760832.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.
15/12/05 01:20:56 INFO StorageMemoryPool: Claiming 50593792 bytes free memory space from StorageMemoryPool.
15/12/05 01:20:56 INFO UnifiedMemoryManager: Reclaimed 50593792 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.
15/12/05 01:20:56 INFO GenerateUnsafeRowJoiner: Code generated in 19.615021 ms
15/12/05 01:20:57 INFO GenerateUnsafeProjection: Code generated in 23.149594 ms
15/12/05 01:20:57 INFO TaskMemoryManager: Memory used in task 136
15/12/05 01:20:57 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@5ac6b585: 48.3 MB
15/12/05 01:20:57 INFO TaskMemoryManager: 0 bytes of memory were used by task 136 but are not associated with specific consumers
15/12/05 01:20:57 INFO TaskMemoryManager: 185597952 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; execution and 13545345504 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; storage
15/12/05 01:20:57 INFO TaskMemoryManager: Memory used in task 124
15/12/05 01:20:57 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@30015a6a: 48.3 MB
15/12/05 01:20:57 INFO TaskMemoryManager: 0 bytes of memory were used by task 124 but are not associated with specific consumers
15/12/05 01:20:57 INFO TaskMemoryManager: 185597952 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; execution and 13545345504 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; storage
15/12/05 01:20:57 INFO UnifiedMemoryManager: Try to acquire 67108864 bytes memory. But, on-heap execution memory poll only has 16515072 bytes free memory.
15/12/05 01:20:57 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8262385664, storageMemoryPool.poolSize 16727146496, storageRegionSize 8464760832.
15/12/05 01:20:57 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.
15/12/05 01:20:57 INFO StorageMemoryPool: Claiming 50593792 bytes free memory space from StorageMemoryPool.
15/12/05 01:20:57 INFO UnifiedMemoryManager: Reclaimed 50593792 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.
15/12/05 01:20:57 INFO TaskMemoryManager: Memory used in task 137
15/12/05 01:20:57 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@a9691e0: 48.3 MB
15/12/05 01:20:57 WARN TaskMemoryManager: leak 48.3 MB memory from org.apache.spark.unsafe.map.BytesToBytesMap@5ac6b585
15/12/05 01:20:57 INFO TaskMemoryManager: 0 bytes of memory were used by task 137 but are not associated with specific consumers
15/12/05 01:20:57 INFO TaskMemoryManager: 215023616 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; execution and 13545345504 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; storage
15/12/05 01:20:57 WARN TaskMemoryManager: leak 48.3 MB memory from org.apache.spark.unsafe.map.BytesToBytesMap@a9691e0
15/12/05 01:20:57 ERROR Executor: Managed memory leak detected; size = 50593792 bytes, TID = 136
15/12/05 01:20:57 ERROR Executor: Managed memory leak detected; size = 50593792 bytes, TID = 137
15/12/05 01:20:57 WARN TaskMemoryManager: leak 48.3 MB memory from org.apache.spark.unsafe.map.BytesToBytesMap@30015a6a
15/12/05 01:20:57 ERROR Executor: Managed memory leak detected; size = 50593792 bytes, TID = 124
15/12/05 01:20:57 ERROR Executor: Exception in task 18.0 in stage 5.0 (TID 137)
java.lang.OutOfMemoryError: Unable to acquire 262144 bytes of memory, got 0
	at org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:91)
	at org.apache.spark.unsafe.map.BytesToBytesMap.allocate(BytesToBytesMap.java:735)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:197)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:212)
	at org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap.&amp;lt;init&amp;gt;(UnsafeFixedWidthAggregationMap.java:103)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.&amp;lt;init&amp;gt;(TungstenAggregationIterator.scala:483)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:95)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:86)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
15/12/05 01:20:57 ERROR Executor: Exception in task 17.0 in stage 5.0 (TID 136)
java.lang.OutOfMemoryError: Unable to acquire 262144 bytes of memory, got 0
	at org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:91)
	at org.apache.spark.unsafe.map.BytesToBytesMap.allocate(BytesToBytesMap.java:735)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:197)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:212)
	at org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap.&amp;lt;init&amp;gt;(UnsafeFixedWidthAggregationMap.java:103)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.&amp;lt;init&amp;gt;(TungstenAggregationIterator.scala:483)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:95)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:86)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
15/12/05 01:20:57 ERROR Executor: Exception in task 5.0 in stage 5.0 (TID 124)
java.lang.OutOfMemoryError: Unable to acquire 262144 bytes of memory, got 0
	at org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:91)
	at org.apache.spark.unsafe.map.BytesToBytesMap.allocate(BytesToBytesMap.java:735)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:197)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:212)
	at org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap.&amp;lt;init&amp;gt;(UnsafeFixedWidthAggregationMap.java:103)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.&amp;lt;init&amp;gt;(TungstenAggregationIterator.scala:483)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:95)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:86)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
15/12/05 01:20:57 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[Executor task launch worker-4,5,main]
java.lang.OutOfMemoryError: Unable to acquire 262144 bytes of memory, got 0
	at org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:91)
	at org.apache.spark.unsafe.map.BytesToBytesMap.allocate(BytesToBytesMap.java:735)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:197)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:212)
	at org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap.&amp;lt;init&amp;gt;(UnsafeFixedWidthAggregationMap.java:103)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.&amp;lt;init&amp;gt;(TungstenAggregationIterator.scala:483)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:95)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:86)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
15/12/05 01:20:57 INFO DiskBlockManager: Shutdown hook called
15/12/05 01:20:57 INFO GenerateMutableProjection: Code generated in 21.666344 ms
15/12/05 01:20:57 DEBUG KeepAliveThread: KeepAliveThread received command: Shutdown
15/12/05 01:20:57 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[Executor task launch worker-6,5,main]
java.lang.OutOfMemoryError: Unable to acquire 262144 bytes of memory, got 0
	at org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:91)
	at org.apache.spark.unsafe.map.BytesToBytesMap.allocate(BytesToBytesMap.java:735)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:197)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:212)
	at org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap.&amp;lt;init&amp;gt;(UnsafeFixedWidthAggregationMap.java:103)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.&amp;lt;init&amp;gt;(TungstenAggregationIterator.scala:483)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:95)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:86)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
15/12/05 01:20:57 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[Executor task launch worker-7,5,main]
java.lang.OutOfMemoryError: Unable to acquire 262144 bytes of memory, got 0
	at org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:91)
	at org.apache.spark.unsafe.map.BytesToBytesMap.allocate(BytesToBytesMap.java:735)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:197)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:212)
	at org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap.&amp;lt;init&amp;gt;(UnsafeFixedWidthAggregationMap.java:103)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.&amp;lt;init&amp;gt;(TungstenAggregationIterator.scala:483)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:95)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:86)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
15/12/05 01:20:57 INFO KeepAliveThread: KeepAlive thread has been shutdown successfully
15/12/05 01:20:57 WARN TaskMemoryManager: leak 28.1 MB memory from org.apache.spark.unsafe.map.BytesToBytesMap@6feafdad
15/12/05 01:20:57 ERROR Executor: Managed memory leak detected; size = 29425664 bytes, TID = 120
15/12/05 01:20:57 ERROR Executor: Exception in task 1.0 in stage 5.0 (TID 120)
java.io.FileNotFoundException: /local_disk/spark-1ebb23ad-e3a1-4af2-b3d0-58a70ceed7ec/executor-ca2c389d-8b67-487f-b175-b867282bf0a3/blockmgr-deda3833-d86c-4850-aa4f-64c26ebfbc4f/08/temp_shuffle_8b5df98d-701c-4ef3-98cc-9e4731fe4a68 (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.&amp;lt;init&amp;gt;(FileOutputStream.java:213)
	at org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:88)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
15/12/05 01:20:57 INFO ShutdownHookManager: Shutdown hook called
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The query plan was like &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;TungstenAggregate4
+- TungstenExchange2
   +- TungstenAggregate3
      +- TungstenAggregate2
         +- TungstenExchange1
            +- TungstenAggregate1
               +- Project 
                  +- InMemoryColumnarTableScan
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;OOM happened in the stage having TungstenAggregate2 and TungstenAggregate3.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12919149">SPARK-12155</key>
            <summary>Execution OOM after a relative large dataset cached in the cluster.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="andrewor14">Andrew Or</assignee>
                                    <reporter username="yhuai">Yin Huai</reporter>
                        <labels>
                    </labels>
                <created>Sat, 5 Dec 2015 01:41:06 +0000</created>
                <updated>Thu, 10 Dec 2015 23:30:43 +0000</updated>
                            <resolved>Thu, 10 Dec 2015 23:30:34 +0000</resolved>
                                                    <fixVersion>1.6.0</fixVersion>
                                    <component>Spark Core</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15042582" author="apachespark" created="Sat, 5 Dec 2015 02:11:31 +0000"  >&lt;p&gt;User &apos;yhuai&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10153&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10153&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15042616" author="yhuai" created="Sat, 5 Dec 2015 03:15:06 +0000"  >&lt;p&gt;I have some new logs.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/12/05 02:51:33 INFO MemoryConsumer: allocateArray with size 262144 bytes
15/12/05 02:51:33 INFO MemoryConsumer: allocateArray with size 262144 bytes
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to acquire 262144 bytes memory. But, on-heap execution memory poll only has 0 bytes free memory.269484032 bytes pool size and 269484032 bytes used memory.(taskAttemptId: 131)
15/12/05 02:51:33 INFO MemoryConsumer: allocateArray with size 262144 bytes
15/12/05 02:51:33 INFO MemoryConsumer: allocateArray with size 262144 bytes
15/12/05 02:51:33 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8195276800, storageMemoryPool.poolSize 16660037632, storageRegionSize 8464760832.(taskAttemptId: 131)
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.(taskAttemptId: 131)
15/12/05 02:51:33 INFO StorageMemoryPool: Claiming 262144 bytes free memory space from StorageMemoryPool.
15/12/05 02:51:33 INFO UnifiedMemoryManager: Reclaimed 262144 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.(taskAttemptId: 131)
15/12/05 02:51:33 INFO UnifiedMemoryManager: onHeapExecutionMemoryPool&apos;s size is 269746176 bytes. 262144 bytes are free.(taskAttemptId: 131)
15/12/05 02:51:33 INFO ExecutionMemoryPool: maxToGrant 65536, poolSize 269746176, numActiveTasks 4, curMem 67371008, numBytes 262144, taskAttemptId 131.
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to acquire 262144 bytes memory. But, on-heap execution memory poll only has 196608 bytes free memory.269746176 bytes pool size and 269549568 bytes used memory.(taskAttemptId: 136)
15/12/05 02:51:33 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8195014656, storageMemoryPool.poolSize 16659775488, storageRegionSize 8464760832.(taskAttemptId: 136)
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.(taskAttemptId: 136)
15/12/05 02:51:33 INFO TaskMemoryManager: Task 131 acquire 64.0 KB &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; org.apache.spark.unsafe.map.BytesToBytesMap@118eb11
15/12/05 02:51:33 INFO StorageMemoryPool: Claiming 65536 bytes free memory space from StorageMemoryPool.
15/12/05 02:51:33 INFO UnifiedMemoryManager: Reclaimed 65536 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.(taskAttemptId: 136)
15/12/05 02:51:33 INFO UnifiedMemoryManager: onHeapExecutionMemoryPool&apos;s size is 269811712 bytes. 262144 bytes are free.(taskAttemptId: 136)
15/12/05 02:51:33 INFO ExecutionMemoryPool: maxToGrant 81920, poolSize 269811712, numActiveTasks 4, curMem 67371008, numBytes 262144, taskAttemptId 136.
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to acquire 262144 bytes memory. But, on-heap execution memory poll only has 180224 bytes free memory.269811712 bytes pool size and 269631488 bytes used memory.(taskAttemptId: 135)
15/12/05 02:51:33 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8194949120, storageMemoryPool.poolSize 16659709952, storageRegionSize 8464760832.(taskAttemptId: 135)
15/12/05 02:51:33 INFO TaskMemoryManager: Task 136 acquire 80.0 KB &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; org.apache.spark.unsafe.map.BytesToBytesMap@2a342d48
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.(taskAttemptId: 135)
15/12/05 02:51:33 INFO StorageMemoryPool: Claiming 81920 bytes free memory space from StorageMemoryPool.
15/12/05 02:51:33 INFO UnifiedMemoryManager: Reclaimed 81920 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.(taskAttemptId: 135)
15/12/05 02:51:33 INFO UnifiedMemoryManager: onHeapExecutionMemoryPool&apos;s size is 269893632 bytes. 262144 bytes are free.(taskAttemptId: 135)
15/12/05 02:51:33 INFO ExecutionMemoryPool: maxToGrant 102400, poolSize 269893632, numActiveTasks 4, curMem 67371008, numBytes 262144, taskAttemptId 135.
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to acquire 262144 bytes memory. But, on-heap execution memory poll only has 159744 bytes free memory.269893632 bytes pool size and 269733888 bytes used memory.(taskAttemptId: 119)
15/12/05 02:51:33 INFO TaskMemoryManager: Task 135 acquire 100.0 KB &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; org.apache.spark.unsafe.map.BytesToBytesMap@74e81f25
15/12/05 02:51:33 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8194867200, storageMemoryPool.poolSize 16659628032, storageRegionSize 8464760832.(taskAttemptId: 119)
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.(taskAttemptId: 119)
15/12/05 02:51:33 INFO StorageMemoryPool: Claiming 102400 bytes free memory space from StorageMemoryPool.
15/12/05 02:51:33 INFO UnifiedMemoryManager: Reclaimed 102400 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.(taskAttemptId: 119)
15/12/05 02:51:33 INFO UnifiedMemoryManager: onHeapExecutionMemoryPool&apos;s size is 269996032 bytes. 262144 bytes are free.(taskAttemptId: 119)
15/12/05 02:51:33 INFO ExecutionMemoryPool: maxToGrant 128000, poolSize 269996032, numActiveTasks 4, curMem 67371008, numBytes 262144, taskAttemptId 119.
15/12/05 02:51:33 INFO TaskMemoryManager: Memory used in task 135
15/12/05 02:51:33 INFO TaskMemoryManager: Task 119 acquire 125.0 KB &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; org.apache.spark.unsafe.map.BytesToBytesMap@243b6ff4
15/12/05 02:51:33 INFO TaskMemoryManager: Memory used in task 131
15/12/05 02:51:33 INFO TaskMemoryManager: Memory used in task 136
15/12/05 02:51:33 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@45689186: 64.3 MB
15/12/05 02:51:33 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@51027172: 64.3 MB
15/12/05 02:51:33 INFO TaskMemoryManager: 0 bytes of memory were used by task 131 but are not associated with specific consumers
15/12/05 02:51:33 INFO TaskMemoryManager: Memory used in task 119
15/12/05 02:51:33 INFO TaskMemoryManager: 269484032 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; execution and 13545442975 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; storage
15/12/05 02:51:33 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@79ca871a: 64.3 MB
15/12/05 02:51:33 INFO TaskMemoryManager: 0 bytes of memory were used by task 135 but are not associated with specific consumers
15/12/05 02:51:33 INFO TaskMemoryManager: Acquired by org.apache.spark.unsafe.map.BytesToBytesMap@9b4f050: 64.3 MB
15/12/05 02:51:33 INFO TaskMemoryManager: 0 bytes of memory were used by task 136 but are not associated with specific consumers
15/12/05 02:51:33 INFO TaskMemoryManager: 0 bytes of memory were used by task 119 but are not associated with specific consumers
15/12/05 02:51:33 INFO TaskMemoryManager: 269484032 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; execution and 13545442975 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; storage
15/12/05 02:51:33 INFO TaskMemoryManager: 269484032 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; execution and 13545442975 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; storage
15/12/05 02:51:33 INFO TaskMemoryManager: 269484032 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; execution and 13545442975 bytes of memory are used &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; storage
15/12/05 02:51:33 WARN TaskMemoryManager: leak 64.3 MB memory from org.apache.spark.unsafe.map.BytesToBytesMap@45689186
15/12/05 02:51:33 WARN TaskMemoryManager: leak 64.3 MB memory from org.apache.spark.unsafe.map.BytesToBytesMap@79ca871a
15/12/05 02:51:33 WARN TaskMemoryManager: leak 64.3 MB memory from org.apache.spark.unsafe.map.BytesToBytesMap@9b4f050
15/12/05 02:51:33 WARN TaskMemoryManager: leak 64.3 MB memory from org.apache.spark.unsafe.map.BytesToBytesMap@51027172
15/12/05 02:51:33 ERROR Executor: Managed memory leak detected; size = 67371008 bytes, TID = 136
15/12/05 02:51:33 ERROR Executor: Managed memory leak detected; size = 67371008 bytes, TID = 131
15/12/05 02:51:33 ERROR Executor: Managed memory leak detected; size = 67371008 bytes, TID = 119
15/12/05 02:51:33 ERROR Executor: Managed memory leak detected; size = 67371008 bytes, TID = 135
15/12/05 02:51:33 ERROR Executor: Exception in task 17.0 in stage 5.0 (TID 136)
java.lang.OutOfMemoryError: Unable to acquire 262144 bytes of memory, got 81920
	at org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:97)
	at org.apache.spark.unsafe.map.BytesToBytesMap.allocate(BytesToBytesMap.java:735)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:197)
	at org.apache.spark.unsafe.map.BytesToBytesMap.&amp;lt;init&amp;gt;(BytesToBytesMap.java:212)
	at org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap.&amp;lt;init&amp;gt;(UnsafeFixedWidthAggregationMap.java:103)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregationIterator.&amp;lt;init&amp;gt;(TungstenAggregationIterator.scala:483)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:95)
	at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1$$anonfun$2.apply(TungstenAggregate.scala:86)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think I know the problem.&lt;/p&gt;</comment>
                            <comment id="15042618" author="yhuai" created="Sat, 5 Dec 2015 03:20:32 +0000"  >&lt;p&gt;We can take a look at task &lt;tt&gt;136&lt;/tt&gt;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to acquire 262144 bytes memory. But, on-heap execution memory poll only has 196608 bytes free memory.269746176 bytes pool size and 269549568 bytes used memory.(taskAttemptId: 136)
15/12/05 02:51:33 INFO UnifiedMemoryManager: memoryReclaimableFromStorage 8195014656, storageMemoryPool.poolSize 16659775488, storageRegionSize 8464760832.(taskAttemptId: 136)
15/12/05 02:51:33 INFO UnifiedMemoryManager: Try to reclaim memory space from storage memory pool.(taskAttemptId: 136)
...
15/12/05 02:51:33 INFO UnifiedMemoryManager: Reclaimed 65536 bytes of memory from storage memory pool.Adding them back to onHeapExecutionMemoryPool.(taskAttemptId: 136)
15/12/05 02:51:33 INFO UnifiedMemoryManager: onHeapExecutionMemoryPool&apos;s size is 269811712 bytes. 262144 bytes are free.(taskAttemptId: 136)
15/12/05 02:51:33 INFO ExecutionMemoryPool: maxToGrant 81920, poolSize 269811712, numActiveTasks 4, curMem 67371008, numBytes 262144, taskAttemptId 136.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;task 136 wants to acquire 262144 bytes. However, the execution memory pool only has &lt;tt&gt;196608&lt;/tt&gt; bytes free memory. So, we decide to reclaim memory from storage memory and the amount of memory we want is &lt;tt&gt;65536&lt;/tt&gt; bytes. &lt;/p&gt;

&lt;p&gt;Then, we get &lt;tt&gt;65536&lt;/tt&gt; bytes and put them to execution pool. Now, we have &lt;tt&gt;269811712&lt;/tt&gt; bytes in execution memory pool (it was &lt;tt&gt;269746176&lt;/tt&gt;). However, in &lt;tt&gt;ExecutionMemoryPool.acquireMemory&lt;/tt&gt;, we calculate &lt;tt&gt;maxGrant&lt;/tt&gt; by using &lt;tt&gt;val maxToGrant = math.min(numBytes, math.max(0, (poolSize / numActiveTasks) - curMem))&lt;/tt&gt;. You the memory that can be used by task 136 is actually &lt;tt&gt;269811712 / 4 = 67452928&lt;/tt&gt; (67371008 bytes are actually used). So, the free space for this task ends up be &lt;tt&gt;67452928 - 67371008 = 81920&lt;/tt&gt; bytes.&lt;/p&gt;</comment>
                            <comment id="15044237" author="joshrosen" created="Mon, 7 Dec 2015 01:19:47 +0000"  >&lt;p&gt;I&apos;m working on fixing this issue. I have a regression test for this bug at &lt;a href=&quot;https://github.com/apache/spark/commit/4c8110ddeee990507c9347700dec557fc22a55a5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/4c8110ddeee990507c9347700dec557fc22a55a5&lt;/a&gt;. While investigating this, I found a closely-related bug which impacts eviction of storage memory in cases where you have only a single running task on an executor (this bug, &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-12155&quot; title=&quot;Execution OOM after a relative large dataset cached in the cluster.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-12155&quot;&gt;&lt;del&gt;SPARK-12155&lt;/del&gt;&lt;/a&gt;, is triggered by having multiple running tasks on an executor). I&apos;m going to break down the task of fixing this bug into a series of smaller patches in order to lessen the review burden.&lt;/p&gt;</comment>
                            <comment id="15044348" author="joshrosen" created="Mon, 7 Dec 2015 04:17:41 +0000"  >&lt;p&gt;I think this is blocked by the fix for &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-12165&quot; title=&quot;Execution memory requests may fail to evict storage blocks if storage memory usage is below max memory&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-12165&quot;&gt;&lt;del&gt;SPARK-12165&lt;/del&gt;&lt;/a&gt;, a closely-related bug which impacts the eviction of storage memory in a single-concurrent-task case.&lt;/p&gt;</comment>
                            <comment id="15049274" author="apachespark" created="Wed, 9 Dec 2015 19:47:05 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10230&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10230&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15049909" author="apachespark" created="Thu, 10 Dec 2015 02:50:03 +0000"  >&lt;p&gt;User &apos;andrewor14&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10240&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10240&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="12919551">SPARK-12165</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 49 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2pfwf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12333083">1.6.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>