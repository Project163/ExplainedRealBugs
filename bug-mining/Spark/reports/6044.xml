<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:02:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-25586] toString method of GeneralizedLinearRegressionTrainingSummary runs in infinite loop throwing StackOverflowError</title>
                <link>https://issues.apache.org/jira/browse/SPARK-25586</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;After the change in &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-25118&quot; title=&quot;Need a solution to persist Spark application console outputs when running in shell/yarn client mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-25118&quot;&gt;&lt;del&gt;SPARK-25118&lt;/del&gt;&lt;/a&gt;, which enables spark-shell to run with default log level, test_glr_summary started failing with StackOverflow error.&lt;/p&gt;

&lt;p&gt;Cause: ClosureCleaner calls logDebug on various objects and when it is called for GeneralizedLinearRegressionTrainingSummary, it starts a spark job which runs into infinite loop and fails with the below exception.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
======================================================================
ERROR: test_glr_summary (pyspark.ml.tests.TrainingSummaryTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/jenkins/workspace/SparkPullRequestBuilder/python/pyspark/ml/tests.py&quot;&lt;/span&gt;, line 1809, in test_glr_summary
    self.assertTrue(isinstance(s.aic, &lt;span class=&quot;code-object&quot;&gt;float&lt;/span&gt;))
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/jenkins/workspace/SparkPullRequestBuilder/python/pyspark/ml/regression.py&quot;&lt;/span&gt;, line 1781, in aic
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self._call_java(&lt;span class=&quot;code-quote&quot;&gt;&quot;aic&quot;&lt;/span&gt;)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/jenkins/workspace/SparkPullRequestBuilder/python/pyspark/ml/wrapper.py&quot;&lt;/span&gt;, line 55, in _call_java
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; _java2py(sc, m(*java_args))
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/jenkins/workspace/SparkPullRequestBuilder/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py&quot;&lt;/span&gt;, line 1257, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/jenkins/workspace/SparkPullRequestBuilder/python/pyspark/sql/utils.py&quot;&lt;/span&gt;, line 63, in deco
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; f(*a, **kw)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/jenkins/workspace/SparkPullRequestBuilder/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py&quot;&lt;/span&gt;, line 328, in get_return_value
    format(target_id, &lt;span class=&quot;code-quote&quot;&gt;&quot;.&quot;&lt;/span&gt;, name), value)
Py4JJavaError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling o31639.aic.
: java.lang.StackOverflowError
	at java.io.UnixFileSystem.getBooleanAttributes0(Native Method)
	at java.io.UnixFileSystem.getBooleanAttributes(UnixFileSystem.java:242)
	at java.io.File.exists(File.java:819)
	at sun.misc.URLClassPath$FileLoader.getResource(URLClassPath.java:1245)
	at sun.misc.URLClassPath$FileLoader.findResource(URLClassPath.java:1212)
	at sun.misc.URLClassPath.findResource(URLClassPath.java:188)
	at java.net.URLClassLoader$2.run(URLClassLoader.java:569)
	at java.net.URLClassLoader$2.run(URLClassLoader.java:567)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findResource(URLClassLoader.java:566)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.getResource(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:1093)
	at java.net.URLClassLoader.getResourceAsStream(URLClassLoader.java:232)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.getResourceAsStream(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:2223)
	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:43)
	at org.apache.spark.util.ClosureCleaner$.getInnerClosureClasses(ClosureCleaner.scala:87)
	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:269)
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)
	at org.apache.spark.SparkContext.clean(SparkContext.scala:2342)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:864)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1.apply(RDD.scala:863)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:364)
	at org.apache.spark.rdd.RDD.mapPartitionsWithIndex(RDD.scala:863)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:613)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:89)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)
	at org.apache.spark.sql.Dataset.rdd$lzycompute(Dataset.scala:3038)
	at org.apache.spark.sql.Dataset.rdd(Dataset.scala:3036)
	at org.apache.spark.ml.regression.GeneralizedLinearRegressionSummary.nullDeviance$lzycompute(GeneralizedLinearRegression.scala:1342)
	at org.apache.spark.ml.regression.GeneralizedLinearRegressionSummary.nullDeviance(GeneralizedLinearRegression.scala:1315)
	at org.apache.spark.ml.regression.GeneralizedLinearRegressionTrainingSummary.toString(GeneralizedLinearRegression.scala:1556)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.valueOf(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.java:2994)
	at java.lang.StringBuilder.append(StringBuilder.java:131)
	at scala.StringContext.standardInterpolator(StringContext.scala:125)
	at scala.StringContext.s(StringContext.scala:95)
	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$12$$anonfun$apply$6.apply(ClosureCleaner.scala:289)
	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$12$$anonfun$apply$6.apply(ClosureCleaner.scala:289)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13188703">SPARK-25586</key>
            <summary>toString method of GeneralizedLinearRegressionTrainingSummary runs in infinite loop throwing StackOverflowError</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ankur.gupta">Ankur Gupta</assignee>
                                    <reporter username="ankur.gupta">Ankur Gupta</reporter>
                        <labels>
                    </labels>
                <created>Mon, 1 Oct 2018 21:05:05 +0000</created>
                <updated>Wed, 3 Oct 2018 23:20:36 +0000</updated>
                            <resolved>Wed, 3 Oct 2018 23:19:05 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>MLlib</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16634643" author="apachespark" created="Mon, 1 Oct 2018 21:16:54 +0000"  >&lt;p&gt;User &apos;ankuriitg&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22604&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22604&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16634738" author="srowen" created="Mon, 1 Oct 2018 22:56:20 +0000"  >&lt;p&gt;This is not a bug; &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-25118&quot; title=&quot;Need a solution to persist Spark application console outputs when running in shell/yarn client mode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-25118&quot;&gt;&lt;del&gt;SPARK-25118&lt;/del&gt;&lt;/a&gt; is not committed. This is an improvement that might work around a problem in the proposed implementation of that issue.&lt;/p&gt;</comment>
                            <comment id="16635967" author="apachespark" created="Tue, 2 Oct 2018 18:52:30 +0000"  >&lt;p&gt;User &apos;ankuriitg&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22616&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22616&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16635968" author="apachespark" created="Tue, 2 Oct 2018 18:52:36 +0000"  >&lt;p&gt;User &apos;ankuriitg&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22616&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22616&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16637603" author="vanzin" created="Wed, 3 Oct 2018 23:19:05 +0000"  >&lt;p&gt;Issue resolved by pull request 22616&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22616&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22616&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16637605" author="vanzin" created="Wed, 3 Oct 2018 23:20:15 +0000"  >&lt;blockquote&gt;&lt;p&gt;This is not a bug&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually it&apos;s a bug if you set your log level to DEBUG and happen to be using that class... regardless of the other change.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 6 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3ypgv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>