<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:18:42 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3772] RDD operation on IPython REPL failed with an illegal port number</title>
                <link>https://issues.apache.org/jira/browse/SPARK-3772</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;To reproduce this issue, we should execute following commands on the commit: 6e27cb630de69fa5acb510b4e2f6b980742b1957.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;$ PYSPARK_PYTHON=ipython ./bin/pyspark&lt;br/&gt;
...&lt;br/&gt;
In &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;: file = sc.textFile(&apos;README.md&apos;)&lt;br/&gt;
In &lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt;: file.first()&lt;br/&gt;
...&lt;br/&gt;
14/10/03 08:50:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable&lt;br/&gt;
14/10/03 08:50:13 WARN LoadSnappy: Snappy native library not loaded&lt;br/&gt;
14/10/03 08:50:13 INFO FileInputFormat: Total input paths to process : 1&lt;br/&gt;
14/10/03 08:50:13 INFO SparkContext: Starting job: runJob at PythonRDD.scala:334&lt;br/&gt;
14/10/03 08:50:13 INFO DAGScheduler: Got job 0 (runJob at PythonRDD.scala:334) with 1 output partitions (allowLocal=true)&lt;br/&gt;
14/10/03 08:50:13 INFO DAGScheduler: Final stage: Stage 0(runJob at PythonRDD.scala:334)&lt;br/&gt;
14/10/03 08:50:13 INFO DAGScheduler: Parents of final stage: List()&lt;br/&gt;
14/10/03 08:50:13 INFO DAGScheduler: Missing parents: List()&lt;br/&gt;
14/10/03 08:50:13 INFO DAGScheduler: Submitting Stage 0 (PythonRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; at RDD at PythonRDD.scala:44), which has no missing parents&lt;br/&gt;
14/10/03 08:50:13 INFO MemoryStore: ensureFreeSpace(4456) called with curMem=57388, maxMem=278019440&lt;br/&gt;
14/10/03 08:50:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.4 KB, free 265.1 MB)&lt;br/&gt;
14/10/03 08:50:13 INFO DAGScheduler: Submitting 1 missing tasks from Stage 0 (PythonRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;2&amp;#93;&lt;/span&gt; at RDD at PythonRDD.scala:44)&lt;br/&gt;
14/10/03 08:50:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks&lt;br/&gt;
14/10/03 08:50:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 1207 bytes)&lt;br/&gt;
14/10/03 08:50:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)&lt;br/&gt;
14/10/03 08:50:14 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)&lt;br/&gt;
java.lang.IllegalArgumentException: port out of range:1027423549&lt;br/&gt;
	at java.net.InetSocketAddress.checkPort(InetSocketAddress.java:143)&lt;br/&gt;
	at java.net.InetSocketAddress.&amp;lt;init&amp;gt;(InetSocketAddress.java:188)&lt;br/&gt;
	at java.net.Socket.&amp;lt;init&amp;gt;(Socket.java:244)&lt;br/&gt;
	at org.apache.spark.api.python.PythonWorkerFactory.createSocket$1(PythonWorkerFactory.scala:75)&lt;br/&gt;
	at org.apache.spark.api.python.PythonWorkerFactory.liftedTree1$1(PythonWorkerFactory.scala:90)&lt;br/&gt;
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:89)&lt;br/&gt;
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:62)&lt;br/&gt;
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:100)&lt;br/&gt;
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:71)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)&lt;br/&gt;
	at org.apache.spark.scheduler.Task.run(Task.scala:56)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:182)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:744)&lt;/p&gt;&lt;/blockquote&gt;</description>
                <environment>&lt;p&gt;Mac OS X 10.9.5, Python 2.7.8, IPython 2.2.0&lt;/p&gt;</environment>
        <key id="12745645">SPARK-3772</key>
            <summary>RDD operation on IPython REPL failed with an illegal port number</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="cocoatomo">Tomohiko K.</reporter>
                        <labels>
                            <label>pyspark</label>
                    </labels>
                <created>Fri, 3 Oct 2014 00:03:39 +0000</created>
                <updated>Thu, 9 Oct 2014 23:08:28 +0000</updated>
                            <resolved>Thu, 9 Oct 2014 23:08:28 +0000</resolved>
                                    <version>1.2.0</version>
                                    <fixVersion>1.2.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14157548" author="joshrosen" created="Fri, 3 Oct 2014 01:16:36 +0000"  >&lt;p&gt;Can you post the SHA of the commit that you were using when you saw this?&lt;/p&gt;</comment>
                            <comment id="14157586" author="cocoatomo" created="Fri, 3 Oct 2014 02:01:55 +0000"  >&lt;p&gt;Thank you for the advice.&lt;/p&gt;

&lt;p&gt;I added the commit hash on the description.&lt;/p&gt;</comment>
                            <comment id="14157602" author="joshrosen" created="Fri, 3 Oct 2014 02:28:41 +0000"  >&lt;p&gt;Ah, I see the problem:&lt;/p&gt;

&lt;p&gt;PythonWorkerFactory also passes the &quot;-u&quot; flag when creating Python workers and daemons, which doesn&apos;t work in IPython.  I noticed one of the uses of &quot;-u&quot; when reviewing your PR, but missed these uses:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/42d5077fd3f2c37d1cd23f4c81aa89286a74cb40/core/src/main/scala/org/apache/spark/api/python/PythonWorkerFactory.scala#L111&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/42d5077fd3f2c37d1cd23f4c81aa89286a74cb40/core/src/main/scala/org/apache/spark/api/python/PythonWorkerFactory.scala#L111&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/42d5077fd3f2c37d1cd23f4c81aa89286a74cb40/core/src/main/scala/org/apache/spark/api/python/PythonWorkerFactory.scala#L152&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/42d5077fd3f2c37d1cd23f4c81aa89286a74cb40/core/src/main/scala/org/apache/spark/api/python/PythonWorkerFactory.scala#L152&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I guess we need to apply the same PYTHONUNBUFFERED fix here, too.  Sorry for overlooking this.&lt;/p&gt;

&lt;p&gt;It&apos;s strange that PythonWorkerFactory didn&apos;t report this error in a more graceful way, though.  I think that IPython printed an error message before our code had a chance to run, and in startDaemon() we expected to read an integer from stdout but instead received text.  There are probably less brittle mechanisms for communicating the daemon process&apos;s port to its parent (&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2313&quot; title=&quot;PySpark should accept port via a command line argument rather than STDIN&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2313&quot;&gt;&lt;del&gt;SPARK-2313&lt;/del&gt;&lt;/a&gt; is an issue that partially addresses this).&lt;/p&gt;

&lt;p&gt;I can fix this and open a PR.  If you&apos;d like to do it yourself, just let me know and I&apos;d be glad to review it.&lt;/p&gt;</comment>
                            <comment id="14157604" author="joshrosen" created="Fri, 3 Oct 2014 02:31:15 +0000"  >&lt;p&gt;The reason that we never hit this before is that setting IPYTHON=1 caused Spark to only use IPython on the master; the workers and daemons still launched through regular `python`.  The old behavior might actually be preferable from a performance standpoint, since `ipython` might take longer to start up (this is less of an issue nowadays thanks to the worker re-use patch).&lt;/p&gt;</comment>
                            <comment id="14157617" author="joshrosen" created="Fri, 3 Oct 2014 02:46:23 +0000"  >&lt;p&gt;Actually, I&apos;m surprised that nobody reported this issue in &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-3265&quot; title=&quot;Allow using custom ipython executable with pyspark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-3265&quot;&gt;&lt;del&gt;SPARK-3265&lt;/del&gt;&lt;/a&gt;, since that patch actually allowed you to set PYSPARK_PYTHON in order to use a custom ipython executable.&lt;/p&gt;</comment>
                            <comment id="14158865" author="apachespark" created="Sat, 4 Oct 2014 02:01:35 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2651&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2651&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14165953" author="joshrosen" created="Thu, 9 Oct 2014 23:08:28 +0000"  >&lt;p&gt;Issue resolved by pull request 2651&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2651&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2651&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 6 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i20r8n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12327369">1.2.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>