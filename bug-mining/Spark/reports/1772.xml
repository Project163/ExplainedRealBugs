<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:26:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-7196] decimal precision lost when loading DataFrame from JDBC</title>
                <link>https://issues.apache.org/jira/browse/SPARK-7196</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I have a decimal database field that is defined as 10.2 (i.e. ##########.##). When I load it into Spark via sqlContext.jdbc(..), the type of the corresponding field in the DataFrame is DecimalType, with precisionInfo None. Because of that loss of precision information, &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4176&quot; title=&quot;Support decimals with precision &amp;gt; 18 in Parquet&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-4176&quot;&gt;&lt;del&gt;SPARK-4176&lt;/del&gt;&lt;/a&gt; is triggered when I try to .saveAsTable(..).&lt;/p&gt;</description>
                <environment></environment>
        <key id="12825583">SPARK-7196</key>
            <summary>decimal precision lost when loading DataFrame from JDBC</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="viirya">L. C. Hsieh</assignee>
                                    <reporter username="kgeis">Ken Geis</reporter>
                        <labels>
                    </labels>
                <created>Tue, 28 Apr 2015 16:19:28 +0000</created>
                <updated>Tue, 25 Aug 2015 12:22:26 +0000</updated>
                            <resolved>Thu, 30 Apr 2015 22:15:25 +0000</resolved>
                                    <version>1.3.1</version>
                                    <fixVersion>1.3.2</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="14519158" author="apachespark" created="Wed, 29 Apr 2015 11:33:22 +0000"  >&lt;p&gt;User &apos;viirya&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5777&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5777&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14520715" author="rxin" created="Thu, 30 Apr 2015 02:18:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kgeis&quot; class=&quot;user-hover&quot; rel=&quot;kgeis&quot;&gt;kgeis&lt;/a&gt; can you check if this &lt;a href=&quot;https://github.com/apache/spark/pull/5777&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5777&lt;/a&gt; fixes your issue?&lt;/p&gt;</comment>
                            <comment id="14521067" author="kgeis" created="Thu, 30 Apr 2015 07:35:25 +0000"  >&lt;p&gt;This does not fix my issue.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; val amounts = sqlContext.jdbc(coeusURL, &quot;(SELECT total_direct_cost_total FROM osp$proposal WHERE rownum &amp;lt; 2)&quot;)
amounts: org.apache.spark.sql.DataFrame = [TOTAL_DIRECT_COST_TOTAL: decimal(10,0)]

scala&amp;gt; amounts.schema(0).dataType.asInstanceOf[org.apache.spark.sql.types.DecimalType].precision
res8: Int = -1

scala&amp;gt; amounts.schema(0).dataType.asInstanceOf[org.apache.spark.sql.types.DecimalType].scale
res9: Int = -1

scala&amp;gt; amounts.schema(0).dataType.asInstanceOf[org.apache.spark.sql.types.DecimalType].precisionInfo
res10: Option[org.apache.spark.sql.types.PrecisionInfo] = None

scala&amp;gt; amounts.saveAsTable(&quot;amounts&quot;)
...
java.lang.RuntimeException: Unsupported datatype DecimalType()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14521240" author="viirya" created="Thu, 30 Apr 2015 09:56:31 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kgeis&quot; class=&quot;user-hover&quot; rel=&quot;kgeis&quot;&gt;kgeis&lt;/a&gt; I can&apos;t reproduce your problem. As I test in unit test, after applying the &lt;a href=&quot;https://github.com/apache/spark/pull/5777&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;pr&lt;/a&gt;, the decimal type have precision and scale now through jdbc. Can you check if you apply the pr and your data schema in original database? If both are checked, can you give us a snippet of example data for test? Thanks.&lt;/p&gt;</comment>
                            <comment id="14521590" author="kgeis" created="Thu, 30 Apr 2015 14:44:27 +0000"  >&lt;p&gt;Sorry, I thought I checked out the jdbc_precision branch, but it wasn&apos;t.&lt;/p&gt;

&lt;p&gt;Let&apos;s try again. Downloaded spark-1-jdbc_precision.zip. Retesting... Still not working.&lt;/p&gt;

&lt;p&gt;Sample data (in Oracle):&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;TOTAL_DIRECT_COST_TOTAL
19999
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="14521776" author="viirya" created="Thu, 30 Apr 2015 16:31:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kgeis&quot; class=&quot;user-hover&quot; rel=&quot;kgeis&quot;&gt;kgeis&lt;/a&gt; thanks. I think I know where the problem is. I update the jdbc_precision branch. Please apply it and test again.&lt;/p&gt;</comment>
                            <comment id="14522373" author="kgeis" created="Thu, 30 Apr 2015 22:11:29 +0000"  >&lt;p&gt;This is now correct:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; amounts.schema(0).dataType.asInstanceOf[org.apache.spark.sql.types.DecimalType].precisionInfo
res4: Option[org.apache.spark.sql.types.PrecisionInfo] = Some(PrecisionInfo(12,2))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but now this happens (might be a separate bug):&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; amounts.saveAsTable(&quot;amounts&quot;)
...
15/04/30 15:05:31 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.ClassCastException: java.math.BigDecimal cannot be cast to org.apache.spark.sql.types.Decimal
	at org.apache.spark.sql.parquet.MutableRowWriteSupport.consumeType(ParquetTableSupport.scala:365)
	at org.apache.spark.sql.parquet.MutableRowWriteSupport.write(ParquetTableSupport.scala:335)
	at org.apache.spark.sql.parquet.MutableRowWriteSupport.write(ParquetTableSupport.scala:321)
	at parquet.hadoop.InternalParquetRecordWriter.write(InternalParquetRecordWriter.java:120)
	at parquet.hadoop.ParquetRecordWriter.write(ParquetRecordWriter.java:81)
	at parquet.hadoop.ParquetRecordWriter.write(ParquetRecordWriter.java:37)
	at org.apache.spark.sql.parquet.ParquetRelation2.org$apache$spark$sql$parquet$ParquetRelation2$$writeShard$1(newParquet.scala:699)
	at org.apache.spark.sql.parquet.ParquetRelation2$$anonfun$insert$2.apply(newParquet.scala:717)
	at org.apache.spark.sql.parquet.ParquetRelation2$$anonfun$insert$2.apply(newParquet.scala:717)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14522379" author="rxin" created="Thu, 30 Apr 2015 22:14:54 +0000"  >&lt;p&gt;That&apos;s probably a separate bug. Do you mind filing a separate JIRA and cc me on it? I merged the fix for this one and going to resolve this ticket. Thanks for helping out with the fix.&lt;/p&gt;</comment>
                            <comment id="14522405" author="kgeis" created="Thu, 30 Apr 2015 22:37:23 +0000"  >&lt;p&gt;I get closer when I apply &lt;a href=&quot;https://github.com/apache/spark/pull/5803&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PR5803&lt;/a&gt; from &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-5456&quot; title=&quot;Decimal Type comparison issue&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-5456&quot;&gt;&lt;del&gt;SPARK-5456&lt;/del&gt;&lt;/a&gt;. The field is a DECIMAL(12, 2) in the database. When I save it to Hive and then query off that, the scale is off.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; val amounts = sqlContext.jdbc(coeusURL, &quot;&quot;&quot;(SELECT total_direct_cost_total FROM osp$proposal WHERE rownum &amp;lt; 2)&quot;&quot;&quot;)
scala&amp;gt; amounts.show()
TOTAL_DIRECT_COST_TOTAL
19999                  
scala&amp;gt; amounts.saveAsTable(&quot;amounts&quot;)
scala&amp;gt; sqlContext.sql(&quot;SELECT * FROM amounts&quot;).show()
TOTAL_DIRECT_COST_TOTAL
199.99                 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14522855" author="viirya" created="Fri, 1 May 2015 07:03:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kgeis&quot; class=&quot;user-hover&quot; rel=&quot;kgeis&quot;&gt;kgeis&lt;/a&gt; I can&apos;t reproduce this problem too. Would you mind provide more information, such as the schema of amounts (in returned dataframe)? Are you using &quot;org.apache.spark.sql.parquet&quot; as your defaultDataSourceName?&lt;/p&gt;</comment>
                            <comment id="14522875" author="kgeis" created="Fri, 1 May 2015 07:22:18 +0000"  >&lt;p&gt;My table has&lt;/p&gt;

&lt;p&gt;TOTAL_DIRECT_COST_TOTAL NUMBER(12, 2)&lt;/p&gt;

&lt;p&gt;I don&apos;t understand your question about defaultDataSourceName. I&apos;m not familiar with that. I&apos;ve pasted almost the entire script except for setting the Oracle JDBC URL and putting the Oracle JDBC driver in the SPARK_CLASSPATH variable.&lt;/p&gt;</comment>
                            <comment id="14522878" author="viirya" created="Fri, 1 May 2015 07:25:14 +0000"  >&lt;p&gt;I think NUMBER(12, 2) should be the schema of your Oracle table. Can you do print out amounts.schema to show its schema in dataframe?&lt;/p&gt;</comment>
                            <comment id="14522883" author="kgeis" created="Fri, 1 May 2015 07:30:16 +0000"  >&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; amounts.schema
res1: org.apache.spark.sql.types.StructType = StructType(StructField(TOTAL_DIRECT_COST_TOTAL,DecimalType(12,2),true))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14522901" author="kgeis" created="Fri, 1 May 2015 07:52:18 +0000"  >&lt;p&gt;I think the problem may be specific to Oracle. If I insert 19999 into a NUMBER(12,2) Oracle field and retrieve it, the result is 19999. In H2, I do the same thing, and I get back 19999.00.&lt;/p&gt;

&lt;p&gt;I think that Spark is assuming incorrectly that BigDecimals coming out of result sets have the same scale as the maximum scale allowed for the column.&lt;/p&gt;</comment>
                            <comment id="14522904" author="viirya" created="Fri, 1 May 2015 07:56:06 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kgeis&quot; class=&quot;user-hover&quot; rel=&quot;kgeis&quot;&gt;kgeis&lt;/a&gt; Yes. Looks like the BigDecimal returned from Oracle has different scale compared to the field definition.&lt;/p&gt;</comment>
                            <comment id="14522935" author="kgeis" created="Fri, 1 May 2015 08:25:58 +0000"  >&lt;p&gt;I&apos;m not sure what to do with this. Reopen the issue or file a new one? I&apos;m not sure which project is to blame and how to word it.&lt;/p&gt;</comment>
                            <comment id="14522941" author="viirya" created="Fri, 1 May 2015 08:30:17 +0000"  >&lt;p&gt;I think it is different problem to this JIRA. Please file a new JIRA for it.&lt;/p&gt;</comment>
                            <comment id="14706416" author="fang fang chen" created="Fri, 21 Aug 2015 08:42:06 +0000"  >&lt;p&gt;I also encountered the same issue during saveAsParquetFile, but the patch didn&apos;t resolve my issue.&lt;br/&gt;
Without this patch, the error is:&lt;br/&gt;
Unsupported datatype DecimalType()&lt;br/&gt;
After patching ,the error is:&lt;br/&gt;
Unsupported datatype DecimalType(20,2)&lt;/p&gt;</comment>
                            <comment id="14706418" author="fang fang chen" created="Fri, 21 Aug 2015 08:43:08 +0000"  >&lt;p&gt;Post the error trace here:&lt;br/&gt;
java.lang.RuntimeException: Unsupported datatype DecimalType(20,2)&lt;br/&gt;
        at scala.sys.package$.error(package.scala:27)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetTypesConverter$$anonfun$fromDataType$2.apply(ParquetTypes.scala:368)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetTypesConverter$$anonfun$fromDataType$2.apply(ParquetTypes.scala:312)&lt;br/&gt;
        at scala.Option.getOrElse(Option.scala:120)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetTypesConverter$.fromDataType(ParquetTypes.scala:311)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetTypesConverter$$anonfun$4.apply(ParquetTypes.scala:391)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetTypesConverter$$anonfun$4.apply(ParquetTypes.scala:390)&lt;br/&gt;
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)&lt;br/&gt;
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)&lt;br/&gt;
        at scala.collection.immutable.List.foreach(List.scala:318)&lt;br/&gt;
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)&lt;br/&gt;
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetTypesConverter$.convertFromAttributes(ParquetTypes.scala:389)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetTypesConverter$.writeMetaData(ParquetTypes.scala:436)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache.prepareMetadata(newParquet.scala:240)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.apply(newParquet.scala:256)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache$$anonfun$6.apply(newParquet.scala:251)&lt;br/&gt;
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)&lt;br/&gt;
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)&lt;br/&gt;
        at scala.collection.immutable.List.foreach(List.scala:318)&lt;br/&gt;
        at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)&lt;br/&gt;
        at scala.collection.AbstractTraversable.map(Traversable.scala:105)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetRelation2$MetadataCache.refresh(newParquet.scala:251)&lt;br/&gt;
        at org.apache.spark.sql.parquet.ParquetRelation2.&amp;lt;init&amp;gt;(newParquet.scala:369)&lt;br/&gt;
        at org.apache.spark.sql.parquet.DefaultSource.createRelation(newParquet.scala:96)&lt;br/&gt;
        at org.apache.spark.sql.parquet.DefaultSource.createRelation(newParquet.scala:125)&lt;br/&gt;
        at org.apache.spark.sql.sources.ResolvedDataSource$.apply(ddl.scala:308)&lt;br/&gt;
        at org.apache.spark.sql.DataFrame.save(DataFrame.scala:1123)&lt;br/&gt;
        at org.apache.spark.sql.DataFrame.saveAsParquetFile(DataFrame.scala:922)&lt;br/&gt;
        at org.apache.spark.examples.sql.LoadFromMysql_SqlContext$.main(LoadFromMysql_SqlContext.scala:69)&lt;br/&gt;
        at org.apache.spark.examples.sql.LoadFromMysql_SqlContext.main(LoadFromMysql_SqlContext.scala)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&lt;br/&gt;
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)&lt;br/&gt;
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
        at java.lang.reflect.Method.invoke(Method.java:606)&lt;/p&gt;</comment>
                            <comment id="14711174" author="jmrr" created="Tue, 25 Aug 2015 12:21:39 +0000"  >&lt;p&gt;Same error as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=fang+fang+chen&quot; class=&quot;user-hover&quot; rel=&quot;fang fang chen&quot;&gt;fang fang chen&lt;/a&gt;, using Spark 1.4.1 and pySpark to convert some mysql tables to parquet files.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.sql.AnalysisException: Unsupported datatype DecimalType(20,2);
	at org.apache.spark.sql.parquet.ParquetTypesConverter$$anonfun$fromDataType$2.apply(ParquetTypes.scala:372)
	at org.apache.spark.sql.parquet.ParquetTypesConverter$$anonfun$fromDataType$2.apply(ParquetTypes.scala:316)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.sql.parquet.ParquetTypesConverter$.fromDataType(ParquetTypes.scala:315)
	at org.apache.spark.sql.parquet.ParquetTypesConverter$$anonfun$4.apply(ParquetTypes.scala:396)
	at org.apache.spark.sql.parquet.ParquetTypesConverter$$anonfun$4.apply(ParquetTypes.scala:395)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.parquet.ParquetTypesConverter$.convertFromAttributes(ParquetTypes.scala:394)
	at org.apache.spark.sql.parquet.RowWriteSupport.init(ParquetTableSupport.scala:150)
	at parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:278)
	at parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:252)
	at org.apache.spark.sql.parquet.ParquetOutputWriter.&amp;lt;init&amp;gt;(newParquet.scala:83)
	at org.apache.spark.sql.parquet.ParquetRelation2$$anon$4.newInstance(newParquet.scala:229)
	at org.apache.spark.sql.sources.DefaultWriterContainer.initWriters(commands.scala:470)
	at org.apache.spark.sql.sources.BaseWriterContainer.executorSideSetup(commands.scala:360)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation.org$apache$spark$sql$sources$InsertIntoHadoopFsRelation$$writeRows$1(commands.scala:172)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation$$anonfun$insert$1.apply(commands.scala:160)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation$$anonfun$insert$1.apply(commands.scala:160)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12752097">SPARK-4176</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 13 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2e0qf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>