<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:54:53 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21546] dropDuplicates with watermark yields RuntimeException due to binding failure</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21546</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;With today&apos;s master...&lt;/p&gt;

&lt;p&gt;The following streaming query with watermark and &lt;tt&gt;dropDuplicates&lt;/tt&gt; yields &lt;tt&gt;RuntimeException&lt;/tt&gt; due to failure in binding.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;val topic1 = spark.
  readStream.
  format(&lt;span class=&quot;code-quote&quot;&gt;&quot;kafka&quot;&lt;/span&gt;).
  option(&lt;span class=&quot;code-quote&quot;&gt;&quot;subscribe&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;topic1&quot;&lt;/span&gt;).
  option(&lt;span class=&quot;code-quote&quot;&gt;&quot;kafka.bootstrap.servers&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;localhost:9092&quot;&lt;/span&gt;).
  option(&lt;span class=&quot;code-quote&quot;&gt;&quot;startingoffsets&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;earliest&quot;&lt;/span&gt;).
  load

val records = topic1.
  withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;eventtime&quot;&lt;/span&gt;, &apos;timestamp).  &lt;span class=&quot;code-comment&quot;&gt;// &amp;lt;-- just to put the right name given the purpose
&lt;/span&gt;  withWatermark(eventTime = &lt;span class=&quot;code-quote&quot;&gt;&quot;eventtime&quot;&lt;/span&gt;, delayThreshold = &lt;span class=&quot;code-quote&quot;&gt;&quot;30 seconds&quot;&lt;/span&gt;). &lt;span class=&quot;code-comment&quot;&gt;// &amp;lt;-- use the renamed eventtime column
&lt;/span&gt;  dropDuplicates(&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;).  &lt;span class=&quot;code-comment&quot;&gt;// dropDuplicates will use watermark
&lt;/span&gt;                            &lt;span class=&quot;code-comment&quot;&gt;// only when eventTime column exists
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// include the watermark column =&amp;gt; internal design leak?
&lt;/span&gt;  select(&lt;span class=&quot;code-quote&quot;&gt;&apos;key &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;, &apos;&lt;/span&gt;value &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;string&quot;&lt;/span&gt;, &apos;eventtime).
  as[(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, java.sql.Timestamp)]

scala&amp;gt; records.explain
== Physical Plan ==
*Project [&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(key#0 as string) AS key#169, &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(value#1 as string) AS value#170, eventtime#157-T30000ms]
+- StreamingDeduplicate [value#1], StatefulOperatorStateInfo(&amp;lt;unknown&amp;gt;,93c3de98-3f85-41a4-8aef-d09caf8ea693,0,0), 0
   +- Exchange hashpartitioning(value#1, 200)
      +- EventTimeWatermark eventtime#157: timestamp, interval 30 seconds
         +- *Project [key#0, value#1, timestamp#5 AS eventtime#157]
            +- StreamingRelation kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.streaming.{OutputMode, Trigger}
val sq = records.
  writeStream.
  format(&lt;span class=&quot;code-quote&quot;&gt;&quot;console&quot;&lt;/span&gt;).
  option(&lt;span class=&quot;code-quote&quot;&gt;&quot;truncate&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;).
  trigger(Trigger.ProcessingTime(&lt;span class=&quot;code-quote&quot;&gt;&quot;10 seconds&quot;&lt;/span&gt;)).
  queryName(&lt;span class=&quot;code-quote&quot;&gt;&quot;from-kafka-topic1-to-console&quot;&lt;/span&gt;).
  outputMode(OutputMode.Update).
  start
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;-------------------------------------------
Batch: 0
-------------------------------------------
17/07/27 10:28:58 ERROR Executor: Exception in task 3.0 in stage 13.0 (TID 438)
org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Binding attribute, tree: eventtime#157-T30000ms
	at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:56)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:88)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:87)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:266)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:256)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:87)
	at org.apache.spark.sql.catalyst.expressions.codegen.GeneratePredicate$.bind(GeneratePredicate.scala:45)
	at org.apache.spark.sql.catalyst.expressions.codegen.GeneratePredicate$.bind(GeneratePredicate.scala:40)
	at org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator.generate(CodeGenerator.scala:977)
	at org.apache.spark.sql.execution.SparkPlan.newPredicate(SparkPlan.scala:370)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.org$apache$spark$sql$execution$streaming$WatermarkSupport$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$newPredicate(statefulOperators.scala:350)
	at org.apache.spark.sql.execution.streaming.WatermarkSupport$$anonfun$watermarkPredicateForKeys$1.apply(statefulOperators.scala:160)
	at org.apache.spark.sql.execution.streaming.WatermarkSupport$$anonfun$watermarkPredicateForKeys$1.apply(statefulOperators.scala:160)
	at scala.Option.map(Option.scala:146)
	at org.apache.spark.sql.execution.streaming.WatermarkSupport$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;watermarkPredicateForKeys(statefulOperators.scala:160)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.watermarkPredicateForKeys$lzycompute(statefulOperators.scala:350)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.watermarkPredicateForKeys(statefulOperators.scala:350)
	at org.apache.spark.sql.execution.streaming.WatermarkSupport$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;removeKeysOlderThanWatermark(statefulOperators.scala:167)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.removeKeysOlderThanWatermark(statefulOperators.scala:350)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4$$anonfun$apply$mcV$sp$1.apply$mcV$sp(statefulOperators.scala:403)
	at org.apache.spark.sql.execution.streaming.StateStoreWriter$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;timeTakenMs(statefulOperators.scala:96)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec.timeTakenMs(statefulOperators.scala:350)
	at org.apache.spark.sql.execution.streaming.StreamingDeduplicateExec$$anonfun$doExecute$4$$anonfun$apply$4.apply$mcV$sp(statefulOperators.scala:403)
	at org.apache.spark.util.CompletionIterator$$anon$1.completion(CompletionIterator.scala:46)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:35)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:231)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:225)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:827)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: java.lang.RuntimeException: Couldn&apos;t find eventtime#157-T30000ms in [value#185]
	at scala.sys.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.error(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:27)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:94)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:88)
	at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:52)
	... 49 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;m somehow convinced that watermark support leaks from &lt;tt&gt;StreamingDeduplicate&lt;/tt&gt; and forces a Spark developer to include extra fields for watermark. I think filter pushdown (for the select) should not be executed for this case or should include the extra &lt;tt&gt;eventTime&lt;/tt&gt; column (regardless of whether a developer uses it or not).&lt;/p&gt;</description>
                <environment></environment>
        <key id="13090453">SPARK-21546</key>
            <summary>dropDuplicates with watermark yields RuntimeException due to binding failure</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zsxwing">Shixiong Zhu</assignee>
                                    <reporter username="jlaskowski">Jacek Laskowski</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Jul 2017 08:45:00 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:44 +0000</updated>
                            <resolved>Wed, 2 Aug 2017 21:02:46 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>2.2.1</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16105426" author="zsxwing" created="Fri, 28 Jul 2017 18:16:26 +0000"  >&lt;p&gt;Yeah, good catch. The watermark column should be one of the dropDuplicates columns. Otherwise, it never evicts states.&lt;/p&gt;</comment>
                            <comment id="16111607" author="gurwls223" created="Wed, 2 Aug 2017 19:23:39 +0000"  >&lt;p&gt;User &apos;zsxwing&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18822&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18822&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16112146" author="kevinzwx" created="Thu, 3 Aug 2017 04:08:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zsxwing&quot; class=&quot;user-hover&quot; rel=&quot;zsxwing&quot;&gt;zsxwing&lt;/a&gt; in my case I hope to use a watermark to expire the state but not use the watermark column to filter duplicate elements. i.e. I want to count the unique access of my website for one day, so I should just store the state of dropDuplicates for one day and drop the state the next day, meanwhile I want to use uuid as the key to drop duplicate elements rather than using (uuid, eventTime) together, but dropDuplicates behaves like the latter right? If so how can I get the right results as I expected?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 15 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3i2un:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>