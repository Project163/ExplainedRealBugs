<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:27:55 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-36905] Reading Hive view without explicit column names fails in Spark </title>
                <link>https://issues.apache.org/jira/browse/SPARK-36905</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Consider a Hive view in which some columns are not explicitly named&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-sql&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;VIEW&lt;/span&gt; test_view &lt;span class=&quot;code-keyword&quot;&gt;AS&lt;/span&gt;
&lt;span class=&quot;code-keyword&quot;&gt;SELECT&lt;/span&gt; 1
&lt;span class=&quot;code-keyword&quot;&gt;FROM&lt;/span&gt; some_table
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Reading this view in Spark leads to an &lt;tt&gt;AnalysisException&lt;/tt&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.spark.sql.AnalysisException: cannot resolve &lt;span class=&quot;code-quote&quot;&gt;&apos;`_c0`&apos;&lt;/span&gt; given input columns: [1]
  at org.apache.spark.sql.catalyst.analysis.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$AnalysisErrorAt.failAnalysis(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:42)
  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:188)
  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:185)
  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:340)
  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:340)
  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:337)
  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:406)
  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:242)
  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:404)
  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:357)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:337)
  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:337)
  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:406)
  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:242)
  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:404)
  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:357)
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:337)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:104)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:116)
  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:116)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:127)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:132)
  at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)
  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
  at scala.collection.TraversableLike.map(TraversableLike.scala:238)
  at scala.collection.TraversableLike.map$(TraversableLike.scala:231)
  at scala.collection.AbstractTraversable.map(Traversable.scala:108)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:132)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:137)
  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:242)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:137)
  at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:104)
  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:185)
  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:94)
  at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:182)
  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:94)
  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:91)
  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:155)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveViews(Analyzer.scala:1147)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveViews(Analyzer.scala:1151)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$10.$anonfun$applyOrElse$82(Analyzer.scala:1207)
  at scala.Option.map(Option.scala:230)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$10.applyOrElse(Analyzer.scala:1207)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$10.applyOrElse(Analyzer.scala:1155)
  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$3(AnalysisHelper.scala:90)
  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUp$1(AnalysisHelper.scala:90)
  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:221)
  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp(AnalysisHelper.scala:86)
  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUp$(AnalysisHelper.scala:84)
  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1155)
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1116)
  at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:215)
  at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)
  at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)
  at scala.collection.immutable.List.foldLeft(List.scala:89)
  at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:212)
  at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:204)
  at scala.collection.immutable.List.foreach(List.scala:392)
  at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:204)
  at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:196)
  at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:190)
  at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:155)
  at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)
  at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)
  at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)
  at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:174)
  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:228)
  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:173)
  at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:74)
  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
  at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:144)
  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:771)
  at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:144)
  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:74)
  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:72)
  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:64)
  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$1(Dataset.scala:90)
  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:771)
  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:88)
  at org.apache.spark.sql.DataFrameReader.table(DataFrameReader.scala:918)
  at org.apache.spark.sql.SparkSession.table(SparkSession.scala:592)
  ... 47 elided
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;TRACE level log showing the query plan&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
21/09/30 10:17:17 TRACE PlanChangeLogger:
=== Result of Batch Cleanup ===
 &lt;span class=&quot;code-quote&quot;&gt;&apos;Project [upcast(&apos;&lt;/span&gt;_c0, IntegerType) AS _c0#3]          &lt;span class=&quot;code-quote&quot;&gt;&apos;Project [upcast(&apos;&lt;/span&gt;_c0, IntegerType) AS _c0#3]
 +- Project [1 AS 1#4]                                  +- Project [1 AS 1#4]
    +- SubqueryAlias spark_catalog.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.some_table      +- SubqueryAlias spark_catalog.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.some_table
       +- Relation &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.some_table[id#1L] orc              +- Relation &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.some_table[id#1L] orc
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13404343">SPARK-36905</key>
            <summary>Reading Hive view without explicit column names fails in Spark </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="linhongliu-db">Linhong Liu</assignee>
                                    <reporter username="shardulm">Shardul Mahadik</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Sep 2021 17:15:46 +0000</created>
                <updated>Thu, 14 Oct 2021 14:24:41 +0000</updated>
                            <resolved>Thu, 14 Oct 2021 14:24:23 +0000</resolved>
                                    <version>3.2.0</version>
                                    <fixVersion>3.2.1</fixVersion>
                    <fixVersion>3.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="17422958" author="shardulm" created="Thu, 30 Sep 2021 18:17:59 +0000"  >&lt;p&gt;This worked fine prior to &lt;a href=&quot;https://github.com/apache/spark/pull/31368&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/31368&lt;/a&gt; cc:&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Previous output&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; spark.table(&lt;span class=&quot;code-quote&quot;&gt;&quot;test_view&quot;&lt;/span&gt;).explain(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)
== Parsed Logical Plan ==
&apos;UnresolvedRelation [test_view], [], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;

== Analyzed Logical Plan ==
_c0: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;
SubqueryAlias spark_catalog.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.test_view
+- View (`&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;`.`test_view`, [_c0#4])
   +- Project [1 AS 1#5]
      +- SubqueryAlias spark_catalog.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.some_table
         +- Relation[id#1L] orc

== Optimized Logical Plan ==
Project [1 AS _c0#4]
+- Relation[id#1L] orc

== Physical Plan ==
*(1) Project [1 AS _c0#4]
+- *(1) ColumnarToRow
   +- FileScan orc &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;. some_table[] Batched: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, DataFilters: [], Format: ORC, Location: InMemoryFileIndex[file:/...], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&amp;lt;&amp;gt;
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17422962" author="xkrogen" created="Thu, 30 Sep 2021 18:23:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shardulm&quot; class=&quot;user-hover&quot; rel=&quot;shardulm&quot;&gt;shardulm&lt;/a&gt; is important here that the view is from Hive? Can this be replicated in Spark w/o Hive?&lt;/p&gt;</comment>
                            <comment id="17422966" author="shardulm" created="Thu, 30 Sep 2021 18:28:50 +0000"  >&lt;p&gt;This cannot be reproduced with a view created from Spark. This only happens on views created from Hive and then read in Spark.&lt;/p&gt;</comment>
                            <comment id="17424183" author="xkrogen" created="Mon, 4 Oct 2021 21:07:24 +0000"  >&lt;p&gt;cc also &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maropu&quot; class=&quot;user-hover&quot; rel=&quot;maropu&quot;&gt;maropu&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=viirya&quot; class=&quot;user-hover&quot; rel=&quot;viirya&quot;&gt;viirya&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=csun&quot; class=&quot;user-hover&quot; rel=&quot;csun&quot;&gt;csun&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17425072" author="gengliang.wang" created="Wed, 6 Oct 2021 16:24:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shardulm&quot; class=&quot;user-hover&quot; rel=&quot;shardulm&quot;&gt;shardulm&lt;/a&gt; Thanks for reporting the issue. &lt;br/&gt;
I don&apos;t think this is a release blocker. I will mention this one as a known issue in the release note if it is not resolved by then.&lt;/p&gt;</comment>
                            <comment id="17427450" author="apachespark" created="Tue, 12 Oct 2021 05:29:16 +0000"  >&lt;p&gt;User &apos;linhongliu-db&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34254&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34254&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17427451" author="apachespark" created="Tue, 12 Oct 2021 05:30:44 +0000"  >&lt;p&gt;User &apos;linhongliu-db&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34254&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34254&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 5 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0vgs8:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>