<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:55:29 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18608] Spark ML algorithms that check RDD cache level for internal caching double-cache data</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18608</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Some algorithms in Spark ML (e.g. &lt;tt&gt;LogisticRegression&lt;/tt&gt;, &lt;tt&gt;LinearRegression&lt;/tt&gt;, and I believe now &lt;tt&gt;KMeans&lt;/tt&gt;) handle persistence internally. They check whether the input dataset is cached, and if not they cache it for performance.&lt;/p&gt;

&lt;p&gt;However, the check is done using &lt;tt&gt;dataset.rdd.getStorageLevel == NONE&lt;/tt&gt;. This will actually always be true, since even if the dataset itself is cached, the RDD returned by &lt;tt&gt;dataset.rdd&lt;/tt&gt; will not be cached.&lt;/p&gt;

&lt;p&gt;Hence if the input dataset is cached, the data will end up being cached twice, which is wasteful.&lt;/p&gt;

&lt;p&gt;To see this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.storage.StorageLevel
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.storage.StorageLevel

scala&amp;gt; val df = spark.range(10).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;num&quot;&lt;/span&gt;)
df: org.apache.spark.sql.DataFrame = [num: bigint]

scala&amp;gt; df.storageLevel == StorageLevel.NONE
res0: &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;

scala&amp;gt; df.persist
res1: df.type = [num: bigint]

scala&amp;gt; df.storageLevel == StorageLevel.MEMORY_AND_DISK
res2: &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;

scala&amp;gt; df.rdd.getStorageLevel == StorageLevel.MEMORY_AND_DISK
res3: &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;

scala&amp;gt; df.rdd.getStorageLevel == StorageLevel.NONE
res4: &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Before &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16063&quot; title=&quot;Add storageLevel to Dataset&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-16063&quot;&gt;&lt;del&gt;SPARK-16063&lt;/del&gt;&lt;/a&gt;, there was no way to check the storage level of the input &lt;tt&gt;DataSet&lt;/tt&gt;, but now we can, so the checks should be migrated to use &lt;tt&gt;dataset.storageLevel&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13023677">SPARK-18608</key>
            <summary>Spark ML algorithms that check RDD cache level for internal caching double-cache data</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="podongfeng">Ruifeng Zheng</assignee>
                                    <reporter username="mlnick">Nicholas Pentreath</reporter>
                        <labels>
                    </labels>
                <created>Mon, 28 Nov 2016 09:28:36 +0000</created>
                <updated>Thu, 20 Jun 2019 05:26:07 +0000</updated>
                            <resolved>Tue, 12 Sep 2017 18:37:41 +0000</resolved>
                                                    <fixVersion>2.2.1</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>ML</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="15701447" author="srowen" created="Mon, 28 Nov 2016 09:31:07 +0000"  >&lt;p&gt;Agree, I had long since meant to note this. This would be great to fix.&lt;/p&gt;</comment>
                            <comment id="15701839" author="mlnick" created="Mon, 28 Nov 2016 12:21:50 +0000"  >&lt;p&gt;I&apos;ve also been meaning to log this for a little while now. &lt;/p&gt;

&lt;p&gt;It&apos;s actually not a simple fix - there is now some automated label casting to Double in &lt;tt&gt;predictor.fit&lt;/tt&gt; that will throw away the dataset storage level info. We could perhaps centralize the handle persistence logic in &lt;tt&gt;fit&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="15707663" author="yuhaoyan" created="Wed, 30 Nov 2016 06:05:40 +0000"  >&lt;p&gt;Agree. we can just add an extra parameter handlePersistence: Boolean to the train method in Predictor. &lt;/p&gt;</comment>
                            <comment id="15761233" author="zahili" created="Mon, 19 Dec 2016 13:59:28 +0000"  >&lt;p&gt;Hi, &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mlnick&quot; class=&quot;user-hover&quot; rel=&quot;mlnick&quot;&gt;mlnick&lt;/a&gt;, can I join this discussion?&lt;br/&gt;
Could you please explain to me why do you believe that the generated rdd is cached ?&lt;br/&gt;
As you can see in &lt;a href=&quot;https://github.com/apache/spark/blob/master/python/pyspark/sql/dataframe.py&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/python/pyspark/sql/dataframe.py&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;we generate a new rdd, so it&apos;s normal that this rdd is not cached&lt;/p&gt;

&lt;p&gt;    def rdd(self):&lt;br/&gt;
        &quot;&quot;&quot;Returns the content as an :class:`pyspark.RDD` of :class:`Row`.&lt;br/&gt;
        &quot;&quot;&quot;&lt;br/&gt;
        if self._lazy_rdd is None:&lt;br/&gt;
            jrdd = self._jdf.javaToPython()&lt;br/&gt;
            self._lazy_rdd = RDD(jrdd, self.sql_ctx._sc, BatchedSerializer(PickleSerializer()))&lt;br/&gt;
        return self._lazy_rdd&lt;/p&gt;</comment>
                            <comment id="15769648" author="srowen" created="Thu, 22 Dec 2016 09:56:05 +0000"  >&lt;p&gt;I don&apos;t think this has to do with Pyspark. The situation is different: input is cached, but the intermediate RDD created internally is not, and so is cached again.&lt;/p&gt;</comment>
                            <comment id="15769718" author="zahili" created="Thu, 22 Dec 2016 10:31:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt;, Now , I understand what you mean, your purpose is to optimize the memory,however, I think that all we need is to add an extra check,&lt;br/&gt;
if the dataframe is cached, we call the mllib algo directly,&lt;br/&gt;
if not, we have to cache the internal rdd&lt;/p&gt;

&lt;p&gt;But the problem of this solution is: if we do not cache the internal rdd, we will get a lot of warnings from mllib package (RDD is not cached)&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala#L216&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/clustering/KMeans.scala#L216&lt;/a&gt;&lt;br/&gt;
because df.rdd.getStorageLevel == StorageLevel.NONE is true.&lt;/p&gt;

&lt;p&gt;So maybe we will need to create a new public class in mllib methods which can take the handlePersistence as parameter : if it has true there no need to recheck the input RDD&lt;/p&gt;</comment>
                            <comment id="15849830" author="podongfeng" created="Thu, 2 Feb 2017 11:52:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuhaoyan&quot; class=&quot;user-hover&quot; rel=&quot;yuhaoyan&quot;&gt;yuhaoyan&lt;/a&gt; Agree that it&apos;s nice to add an extra parameter:&lt;/p&gt;

&lt;p&gt;in &lt;tt&gt;Predictor&lt;/tt&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  override def fit(dataset: Dataset[_]): M = {
    val handlePersistence = dataset.storageLevel == StorageLevel.NONE
  ...
    copyValues(train(casted, handlePersistence).setParent(&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;))
  }

&lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; def train(dataset: Dataset[_], handlePersistence: &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;): M

~~&lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; def train(dataset: Dataset[_]): M~~  &lt;span class=&quot;code-comment&quot;&gt;//delete &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In each classification and regression algorithms, override the new &lt;tt&gt;train&lt;/tt&gt; api instead of old one.&lt;/p&gt;

&lt;p&gt;For clustering algorithms, directly modify the &lt;tt&gt;fit&lt;/tt&gt; method.&lt;/p&gt;

&lt;p&gt;Since &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16063&quot; title=&quot;Add storageLevel to Dataset&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-16063&quot;&gt;&lt;del&gt;SPARK-16063&lt;/del&gt;&lt;/a&gt; was already resolved, is there someone working on this?&lt;/p&gt;</comment>
                            <comment id="15875465" author="mlnick" created="Tue, 21 Feb 2017 06:55:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=podongfeng&quot; class=&quot;user-hover&quot; rel=&quot;podongfeng&quot;&gt;podongfeng&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuhaoyan&quot; class=&quot;user-hover&quot; rel=&quot;yuhaoyan&quot;&gt;yuhaoyan&lt;/a&gt; I&apos;m not aware of anyone working on this now, either of you want to take it?&lt;/p&gt;</comment>
                            <comment id="15875468" author="podongfeng" created="Tue, 21 Feb 2017 06:59:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mlnick&quot; class=&quot;user-hover&quot; rel=&quot;mlnick&quot;&gt;mlnick&lt;/a&gt; I will send a PR for this according to the above discussion:  use &lt;tt&gt;train(dataset: Dataset&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;, handlePersistence: Boolean)&lt;/tt&gt; instead of &lt;tt&gt;train(dataset: Dataset&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;)&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="15875482" author="yuhaoyan" created="Tue, 21 Feb 2017 07:10:13 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=podongfeng&quot; class=&quot;user-hover&quot; rel=&quot;podongfeng&quot;&gt;podongfeng&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="15875669" author="apachespark" created="Tue, 21 Feb 2017 09:30:04 +0000"  >&lt;p&gt;User &apos;zhengruifeng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17014&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17014&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15893596" author="podongfeng" created="Fri, 3 Mar 2017 02:24:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mlnick&quot; class=&quot;user-hover&quot; rel=&quot;mlnick&quot;&gt;mlnick&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuhaoyan&quot; class=&quot;user-hover&quot; rel=&quot;yuhaoyan&quot;&gt;yuhaoyan&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; I think if we use &lt;tt&gt;train(dataset: Dataset&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;, handlePersistence: Boolean)&lt;/tt&gt; instead of &lt;tt&gt;train(dataset: Dataset&lt;span class=&quot;error&quot;&gt;&amp;#91;_&amp;#93;&lt;/span&gt;)&lt;/tt&gt; may result in extra problems for external implementers, because the existing external algorithms overriding &lt;tt&gt;Predictor.train&lt;/tt&gt; will not work. &lt;/p&gt;

&lt;p&gt;I think we can do it in another way:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Predictor[
    FeaturesType,
    Learner &amp;lt;: Predictor[FeaturesType, Learner, M],
    M &amp;lt;: PredictionModel[FeaturesType, M]]
  &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Estimator[M] with PredictorParams {

  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; storageLevel = StorageLevel.NONE &lt;span class=&quot;code-comment&quot;&gt;// 
&lt;/span&gt;
  override def fit(dataset: Dataset[_]): M = {
    storageLevel = dataset.storageLevel
...
  }

  &lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; def train(dataset: Dataset[_]): M
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;so in algorithm implementations we can use the orignial storageLevel of the input dataset.&lt;/p&gt;</comment>
                            <comment id="15906822" author="podongfeng" created="Mon, 13 Mar 2017 03:33:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mlnick&quot; class=&quot;user-hover&quot; rel=&quot;mlnick&quot;&gt;mlnick&lt;/a&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yuhaoyan&quot; class=&quot;user-hover&quot; rel=&quot;yuhaoyan&quot;&gt;yuhaoyan&lt;/a&gt; What&apos;s your opinions about what I commented above?&lt;/p&gt;</comment>
                            <comment id="15907038" author="srowen" created="Mon, 13 Mar 2017 09:01:51 +0000"  >&lt;p&gt;Is the point here that the .ml implementation can check the storage level of its input, and pass that information in some way, internally, to the .mllib implementation that it delegates to? Yes I think that&apos;s the most feasible answer to this particular problem, as long as it doesn&apos;t change a public API. The .mllib implementations would have to have some internal mechanism for getting this information about parents&apos; storage level, if applicable.&lt;/p&gt;

&lt;p&gt;It does raise the more general question of whether these implementation can meaningfully decide about caching anyway, and whether they should try, rather than just warn. More generally it&apos;s hard for any library function to reason about whether to persist its input or not, or even, to reason about when a data structure can be unpersisted. Those are much bigger and separate questions, but it&apos;s why this type of question keeps popping up and is hard to solve.&lt;/p&gt;</comment>
                            <comment id="15923158" author="yuhaoyan" created="Mon, 13 Mar 2017 23:14:31 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=podongfeng&quot; class=&quot;user-hover&quot; rel=&quot;podongfeng&quot;&gt;podongfeng&lt;/a&gt; I&apos;d say it&apos;s a better solution as it avoids API change. In the long term, this should be a temporary workaround until we migrate all the implementations from RDD to DataFrame. &lt;/p&gt;

&lt;p&gt;Also FYI, Nick mentioned something related &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-19071?focusedCommentId=15834232&amp;amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15834232&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;. I think the new solution can adapt to it with a setter method. Right now, we can just focus on resolving the double-caching issue.&lt;/p&gt;</comment>
                            <comment id="16162004" author="josephkb" created="Mon, 11 Sep 2017 21:11:28 +0000"  >&lt;p&gt;Hi all, it looks like there has been confusion about what has been agreed on.  This is my current understanding:&lt;/p&gt;

&lt;p&gt;There are 2 issues:&lt;br/&gt;
1. This JIRA &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-18608&quot; title=&quot;Spark ML algorithms that check RDD cache level for internal caching double-cache data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-18608&quot;&gt;&lt;del&gt;SPARK-18608&lt;/del&gt;&lt;/a&gt;, which discusses the bug of double-caching because of misuse of &lt;tt&gt;dataset.rdd.getStorageLevel&lt;/tt&gt;.  Note that &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-21799&quot; title=&quot;KMeans performance regression (5-6x slowdown) in Spark 2.2&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-21799&quot;&gt;&lt;del&gt;SPARK-21799&lt;/del&gt;&lt;/a&gt; is just a special case of this bug.&lt;br/&gt;
2. &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-21972&quot; title=&quot;Allow users to control input data persistence in ML Estimators via a handlePersistence ml.Param&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-21972&quot;&gt;&lt;del&gt;SPARK-21972&lt;/del&gt;&lt;/a&gt;, which discusses adding a parameter handlePersistence to allow user control over whether to cache the input data.&lt;/p&gt;

&lt;p&gt;I recommend:&lt;br/&gt;
1. We should fix the current double-caching bug in master and branch-2.2.  Going from Spark 2.1 to 2.2, I&apos;ve only seen a performance regression with K-Means, but I recommend we fix the bug for all cases.  This fix would be like &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=podongfeng&quot; class=&quot;user-hover&quot; rel=&quot;podongfeng&quot;&gt;podongfeng&lt;/a&gt;&apos;s original PR for &lt;a href=&quot;https://github.com/apache/spark/pull/17014&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17014&lt;/a&gt; (before adding in handlePersistence).&lt;br/&gt;
2. We can work on adding handlePersistence to master.  No backporting there of course.  Note that &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-19422&quot; title=&quot;Cache input data in algorithms&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-19422&quot;&gt;&lt;del&gt;SPARK-19422&lt;/del&gt;&lt;/a&gt; is also related, and it may be blocked by decisions on &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-21972&quot; title=&quot;Allow users to control input data persistence in ML Estimators via a handlePersistence ml.Param&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-21972&quot;&gt;&lt;del&gt;SPARK-21972&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="16162496" author="apachespark" created="Tue, 12 Sep 2017 04:59:04 +0000"  >&lt;p&gt;User &apos;zhengruifeng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19197&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19197&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16163446" author="josephkb" created="Tue, 12 Sep 2017 18:37:42 +0000"  >&lt;p&gt;Issue resolved by pull request 19197&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19197&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19197&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16164519" author="apachespark" created="Wed, 13 Sep 2017 11:33:04 +0000"  >&lt;p&gt;User &apos;yanboliang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19220&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19220&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10032">
                    <name>Blocker</name>
                                            <outwardlinks description="blocks">
                                        <issuelink>
            <issuekey id="13039405">SPARK-19422</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13096504">SPARK-21799</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 9 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i36u1z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12340470">2.2.1</customfieldvalue>
    <customfieldvalue id="12339551">2.3.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>