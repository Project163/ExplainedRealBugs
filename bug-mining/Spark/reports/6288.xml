<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26734] StackOverflowError on WAL serialization caused by large receivedBlockQueue</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26734</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We encountered an intermittent StackOverflowError with a stack trace similar to:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;JobGenerator&quot; java.lang.StackOverflowError
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The name of the thread has been seen to be either &quot;JobGenerator&quot; or &quot;streaming-start&quot;, depending on when in the lifecycle of the job the problem occurs.&#160; It appears to only occur in streaming jobs with checkpointing and WAL enabled; this has prevented us from upgrading to v2.4.0.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Via debugging, we tracked this down to allocateBlocksToBatch in ReceivedBlockTracker:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
 * Allocate all unallocated blocks to the given batch.
 * This event will get written to the write ahead log (&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; enabled).
 */
def allocateBlocksToBatch(batchTime: Time): Unit = &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; {
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (lastAllocatedBatchTime == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; || batchTime &amp;gt; lastAllocatedBatchTime) {
    val streamIdToBlocks = streamIds.map { streamId =&amp;gt;
      (streamId, getReceivedBlockQueue(streamId).clone())
    }.toMap
    val allocatedBlocks = AllocatedBlocks(streamIdToBlocks)
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (writeToLog(BatchAllocationEvent(batchTime, allocatedBlocks))) {
      streamIds.foreach(getReceivedBlockQueue(_).clear())
      timeToAllocatedBlocks.put(batchTime, allocatedBlocks)
      lastAllocatedBatchTime = batchTime
    } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
      logInfo(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Possibly processed batch $batchTime needs to be processed again in WAL recovery&quot;&lt;/span&gt;)
    }
  } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
    &lt;span class=&quot;code-comment&quot;&gt;// This situation occurs when:
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// 1. WAL is ended with BatchAllocationEvent, but without BatchCleanupEvent,
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// possibly processed batch job or half-processed batch job need to be processed again,
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// so the batchTime will be equal to lastAllocatedBatchTime.
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// 2. Slow checkpointing makes recovered batch time older than WAL recovered
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// lastAllocatedBatchTime.
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// This situation will only occurs in recovery time.
&lt;/span&gt;    logInfo(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Possibly processed batch $batchTime needs to be processed again in WAL recovery&quot;&lt;/span&gt;)
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Prior to 2.3.1, this code did&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
getReceivedBlockQueue(streamId).dequeueAll(x =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but it was changed as part of&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-23991&quot; title=&quot;data loss when allocateBlocksToBatch&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-23991&quot;&gt;&lt;del&gt;SPARK-23991&lt;/del&gt;&lt;/a&gt;&#160;to&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
getReceivedBlockQueue(streamId).clone()&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We&apos;ve not been able to reproduce this in a test of the actual above method, but we&apos;ve been able to produce a test that reproduces it by putting a lot of values into the queue:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;SerializationFailureTest &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; FunSpec {

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; val logger = LoggerFactory.getLogger(getClass)

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; type ReceivedBlockQueue = mutable.Queue[ReceivedBlockInfo]

  describe(&lt;span class=&quot;code-quote&quot;&gt;&quot;Queue&quot;&lt;/span&gt;) {
    it(&lt;span class=&quot;code-quote&quot;&gt;&quot;should be serializable&quot;&lt;/span&gt;) {
      runTest(1062)
    }
    it(&lt;span class=&quot;code-quote&quot;&gt;&quot;should not be serializable&quot;&lt;/span&gt;) {
      runTest(1063)
    }
    it(&lt;span class=&quot;code-quote&quot;&gt;&quot;should DEFINITELY not be serializable&quot;&lt;/span&gt;) {
      runTest(199952)
    }
  }

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def runTest(mx: Int): Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;] = {
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
      val random = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; scala.util.Random()
      val queue = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ReceivedBlockQueue()
      &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (_ &amp;lt;- 0 until mx) {
        queue += ReceivedBlockInfo(
          streamId = 0,
          numRecords = Some(random.nextInt(5)),
          metadataOption = None,
          blockStoreResult = WriteAheadLogBasedStoreResult(
            blockId = StreamBlockId(0, random.nextInt()),
            numRecords = Some(random.nextInt(5)),
            walRecordHandle = FileBasedWriteAheadLogSegment(
              path = s&lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//foo.bar.com:8080/spark/streaming/BAZ/00007/receivedData/0/log-${random.nextInt()}-${random.nextInt()}&quot;&lt;/span&gt;&quot;&quot;,
&lt;/span&gt;              offset = random.nextLong(),
              length = random.nextInt()
            )
          )
        )
      }
      val record = BatchAllocationEvent(
        Time(1548320400000L), AllocatedBlocks(
          Map(
            0 -&amp;gt; queue
          )
        )
      )
      Utils.serialize(record)
    } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; {
      &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; t: Throwable =&amp;gt;
        fail(t)
    }
  }
}

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In my tests it seemed like the serialization would fail if there were ~1064 elements in the queue.&#160; I&apos;m&#160;&lt;em&gt;assuming&lt;/em&gt; that this is actually a scala bug, though I haven&apos;t tried reproducing it without the involvement of the spark objects.&lt;/p&gt;

&lt;p&gt;I expect this could be solved by transforming the cloned queue into a different type of Seq.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment>&lt;p&gt;spark 2.4.0 streaming job&lt;/p&gt;

&lt;p&gt;java 1.8&lt;/p&gt;

&lt;p&gt;scala 2.11.12&lt;/p&gt;</environment>
        <key id="13211966">SPARK-26734</key>
            <summary>StackOverflowError on WAL serialization caused by large receivedBlockQueue</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="eddardstark">Ross M. Lodge</assignee>
                                    <reporter username="eddardstark">Ross M. Lodge</reporter>
                        <labels>
                    </labels>
                <created>Sat, 26 Jan 2019 00:19:05 +0000</created>
                <updated>Sun, 17 May 2020 18:21:34 +0000</updated>
                            <resolved>Wed, 6 Feb 2019 16:45:40 +0000</resolved>
                                    <version>2.3.1</version>
                    <version>2.3.2</version>
                    <version>2.4.0</version>
                                    <fixVersion>2.3.4</fixVersion>
                    <fixVersion>2.4.1</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Block Manager</component>
                    <component>DStreams</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16761921" author="srowen" created="Wed, 6 Feb 2019 16:45:40 +0000"  >&lt;p&gt;Issue resolved by pull request 23716&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23716&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23716&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17006211" author="spearsberg" created="Tue, 31 Dec 2019 18:33:45 +0000"  >&lt;p&gt;Is this bug fixed? I still see the same error at Spark 2.4.3&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 46 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|yi0c6w:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>