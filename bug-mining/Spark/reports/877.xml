<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:18:56 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3855] Binding Exception when running PythonUDFs</title>
                <link>https://issues.apache.org/jira/browse/SPARK-3855</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;from pyspark &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; *
from pyspark.sql &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; *
sc = SparkContext()
sqlContext = SQLContext(sc)
sqlContext.registerFunction(&lt;span class=&quot;code-quote&quot;&gt;&quot;strlen&quot;&lt;/span&gt;, lambda string: len(string))
sqlContext.inferSchema(sc.parallelize([Row(a=&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;)])).registerTempTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;)
srdd = sqlContext.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT strlen(a) FROM test WHERE strlen(a) &amp;gt; 1&quot;&lt;/span&gt;)
print srdd._jschema_rdd.baseSchemaRDD().queryExecution().toString()
print srdd.collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;output:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;== Parsed Logical Plan ==
Project [&lt;span class=&quot;code-quote&quot;&gt;&apos;strlen(&apos;&lt;/span&gt;a) AS c0#1]
 Filter (&lt;span class=&quot;code-quote&quot;&gt;&apos;strlen(&apos;&lt;/span&gt;a) &amp;gt; 1)
  UnresolvedRelation None, test, None

== Analyzed Logical Plan ==
Project [c0#1]
 Project [pythonUDF#2 AS c0#1]
  EvaluatePython PythonUDF#strlen(a#0)
   Project [a#0]
    Filter (CAST(pythonUDF#3, DoubleType) &amp;gt; CAST(1, DoubleType))
     EvaluatePython PythonUDF#strlen(a#0)
      SparkLogicalPlan (ExistingRdd [a#0], MapPartitionsRDD[7] at mapPartitions at SQLContext.scala:525)

== Optimized Logical Plan ==
Project [pythonUDF#2 AS c0#1]
 EvaluatePython PythonUDF#strlen(a#0)
  Project [a#0]
   Filter (CAST(pythonUDF#3, DoubleType) &amp;gt; 1.0)
    EvaluatePython PythonUDF#strlen(a#0)
     SparkLogicalPlan (ExistingRdd [a#0], MapPartitionsRDD[7] at mapPartitions at SQLContext.scala:525)

== Physical Plan ==
Project [pythonUDF#2 AS c0#1]
 BatchPythonEvaluation PythonUDF#strlen(a#0), [a#0,pythonUDF#5]
  Project [a#0]
   Filter (CAST(pythonUDF#3, DoubleType) &amp;gt; 1.0)
    BatchPythonEvaluation PythonUDF#strlen(a#0), [a#0,pythonUDF#3]
     ExistingRdd [a#0], MapPartitionsRDD[7] at mapPartitions at SQLContext.scala:525

Code Generation: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
== RDD ==
14/10/08 15:03:00 ERROR Executor: Exception in task 1.0 in stage 4.0 (TID 9)
org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Binding attribute, tree: pythonUDF#2
	at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:47)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:47)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:46)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:144)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:162)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenDown(TreeNode.scala:191)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:147)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:135)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:46)
	at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection$$anonfun$$init$$2.apply(Projection.scala:52)
	at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection$$anonfun$$init$$2.apply(Projection.scala:52)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.&amp;lt;init&amp;gt;(Projection.scala:52)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$newMutableProjection$1.apply(SparkPlan.scala:106)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$newMutableProjection$1.apply(SparkPlan.scala:106)
	at org.apache.spark.sql.execution.Project$$anonfun$1.apply(basicOperators.scala:43)
	at org.apache.spark.sql.execution.Project$$anonfun$1.apply(basicOperators.scala:42)
	at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:599)
	at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:599)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
	at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:182)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.RuntimeException: Couldn&apos;t find pythonUDF#2 in [a#0,pythonUDF#5]
	at scala.sys.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.error(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:27)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:53)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:47)
	at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:46)
	... 46 more
14/10/08 15:03:00 ERROR Executor: Exception in task 0.0 in stage 4.0 (TID 8)
org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$TreeNodeException: Binding attribute, tree: pythonUDF#2
	at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:47)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:47)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:46)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:144)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:162)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:273)
	at scala.collection.AbstractIterator.to(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:265)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:252)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenDown(TreeNode.scala:191)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:147)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:135)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:46)
	at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection$$anonfun$$init$$2.apply(Projection.scala:52)
	at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection$$anonfun$$init$$2.apply(Projection.scala:52)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.catalyst.expressions.InterpretedMutableProjection.&amp;lt;init&amp;gt;(Projection.scala:52)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$newMutableProjection$1.apply(SparkPlan.scala:106)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$newMutableProjection$1.apply(SparkPlan.scala:106)
	at org.apache.spark.sql.execution.Project$$anonfun$1.apply(basicOperators.scala:43)
	at org.apache.spark.sql.execution.Project$$anonfun$1.apply(basicOperators.scala:42)
	at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:599)
	at org.apache.spark.rdd.RDD$$anonfun$13.apply(RDD.scala:599)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
	at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:182)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.RuntimeException: Couldn&apos;t find pythonUDF#2 in [a#0,pythonUDF#5]
	at scala.sys.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.error(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:27)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:53)
	at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1$$anonfun$applyOrElse$1.apply(BoundAttribute.scala:47)
	at org.apache.spark.sql.catalyst.errors.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$.attachTree(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:46)
	... 46 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12746831">SPARK-3855</key>
            <summary>Binding Exception when running PythonUDFs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="marmbrus">Michael Armbrust</assignee>
                                    <reporter username="marmbrus">Michael Armbrust</reporter>
                        <labels>
                    </labels>
                <created>Wed, 8 Oct 2014 21:29:16 +0000</created>
                <updated>Fri, 17 Oct 2014 21:12:55 +0000</updated>
                            <resolved>Fri, 17 Oct 2014 21:12:55 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.2.0</fixVersion>
                                    <component>PySpark</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14164210" author="apachespark" created="Wed, 8 Oct 2014 21:35:45 +0000"  >&lt;p&gt;User &apos;marmbrus&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2717&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2717&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 6 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i20ydr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>