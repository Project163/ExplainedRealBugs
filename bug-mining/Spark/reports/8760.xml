<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:31:37 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-41193] Ignore `collect data with single partition larger than 2GB bytes array limit` in `DatasetLargeResultCollectingSuite` as default</title>
                <link>https://issues.apache.org/jira/browse/SPARK-41193</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Test this suite with *&lt;b&gt;Java 8/11/17&lt;/b&gt;* on Linux/MacOS On Apple Silicon with following commands:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Maven:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;```&lt;br/&gt;
build/mvn clean install -DskipTests -pl sql/core -am&lt;br/&gt;
build/mvn clean test -pl sql/core -Dtest=none -DwildcardSuites=org.apache.spark.sql.DatasetLargeResultCollectingSuite&lt;br/&gt;
```&lt;/p&gt;

&lt;p&gt;and&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;```&lt;br/&gt;
dev/change-scala-version.sh 2.13&#160;&lt;br/&gt;
build/mvn clean install -DskipTests -pl sql/core -am -Pscala-2.13&lt;br/&gt;
build/mvn clean test -pl sql/core -Pscala-2.13 -Dtest=none -DwildcardSuites=org.apache.spark.sql.DatasetLargeResultCollectingSuite&lt;br/&gt;
```&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;SBT:&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;```&lt;br/&gt;
build/sbt clean &quot;sql/testOnly org.apache.spark.sql.DatasetLargeResultCollectingSuite&quot;&lt;br/&gt;
```&lt;/p&gt;


&lt;p&gt;```&lt;br/&gt;
dev/change-scala-version.sh 2.13&#160;&lt;br/&gt;
build/sbt clean &quot;sql/testOnly org.apache.spark.sql.DatasetLargeResultCollectingSuite&quot; -Pscala-2.13&lt;br/&gt;
```&lt;/p&gt;


&lt;p&gt;All test failed with `java.lang.OutOfMemoryError: Java heap space` as follows:&lt;/p&gt;

&lt;p&gt;```&lt;br/&gt;
10:19:56.910 ERROR org.apache.spark.executor.Executor: Exception in task 0.0 in stage 0.0 (TID 0)&lt;br/&gt;
java.lang.OutOfMemoryError: Java heap space&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.nio.HeapByteBuffer.&amp;lt;init&amp;gt;(HeapByteBuffer.java:57)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.nio.ByteBuffer.allocate(ByteBuffer.java:335)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.serializer.SerializerHelper$$$Lambda$2321/1995130077.apply(Unknown Source)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1(Utils.scala:271)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.Utils$.$anonfun$writeByteBuffer$1$adapted(Utils.scala:271)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.Utils$$$Lambda$2324/69671223.apply(Unknown Source)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.Utils$.writeByteBufferImpl(Utils.scala:249)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:271)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2(ChunkedByteBuffer.scala:103)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.io.ChunkedByteBuffer.$anonfun$writeExternal$2$adapted(ChunkedByteBuffer.scala:103)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.io.ChunkedByteBuffer$$Lambda$2323/1073743200.apply(Unknown Source)&lt;br/&gt;
&#160; &#160; &#160; &#160; at scala.collection.ArrayOps$.foreach$extension(ArrayOps.scala:1328)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.util.io.ChunkedByteBuffer.writeExternal(ChunkedByteBuffer.scala:103)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeArray(ObjectOutputStream.java:1378)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)&lt;br/&gt;
&#160; &#160; &#160; &#160; at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:46)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.serializer.SerializerHelper$.serializeToChunkedBuffer(SerializerHelper.scala:42)&lt;br/&gt;
&#160; &#160; &#160; &#160; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:599)&lt;br/&gt;
```&lt;/p&gt;</description>
                <environment></environment>
        <key id="13503352">SPARK-41193</key>
            <summary>Ignore `collect data with single partition larger than 2GB bytes array limit` in `DatasetLargeResultCollectingSuite` as default</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="LuciferYang">Yang Jie</assignee>
                                    <reporter username="LuciferYang">Yang Jie</reporter>
                        <labels>
                    </labels>
                <created>Fri, 18 Nov 2022 04:27:19 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:50 +0000</updated>
                            <resolved>Tue, 22 Nov 2022 06:51:12 +0000</resolved>
                                    <version>3.4.0</version>
                                    <fixVersion>3.4.0</fixVersion>
                                    <component>Tests</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="17635658" author="apachespark" created="Fri, 18 Nov 2022 04:44:41 +0000"  >&lt;p&gt;User &apos;LuciferYang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/38704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/38704&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17637026" author="gurwls223" created="Tue, 22 Nov 2022 06:51:12 +0000"  >&lt;p&gt;Issue resolved by pull request 38704&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/38704&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/38704&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 51 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1cac0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>