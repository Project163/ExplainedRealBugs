<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:33:17 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-43342] Revert SPARK-39006 Show a directional error message for executor PVC dynamic allocation failure</title>
                <link>https://issues.apache.org/jira/browse/SPARK-43342</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When using static PVC with Spark 3.4, spark PI example fails with the error below. Previous versions of Spark worked well.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
23/04/26 13:22:02 INFO ExecutorPodsAllocator: Going to request 5 executors from Kubernetes &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ResourceProfile Id: 0, target: 5, known: 0, sharedSlotFromPendingPods: 2147483647. 23/04/26 13:22:02 INFO BasicExecutorFeatureStep: Decommissioning not enabled, skipping shutdown script 23/04/26 13:22:02 ERROR ExecutorPodsSnapshotsStoreImpl: Going to stop due to IllegalArgumentException java.lang.IllegalArgumentException: PVC ClaimName: a1pvc should contain OnDemand or SPARK_EXECUTOR_ID when requiring multiple executors &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.deploy.k8s.features.MountVolumesFeatureStep.checkPVCClaimName(MountVolumesFeatureStep.scala:135) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.deploy.k8s.features.MountVolumesFeatureStep.$anonfun$constructVolumes$4(MountVolumesFeatureStep.scala:75) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.Iterator.foreach(Iterator.scala:943) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.Iterator.foreach$(Iterator.scala:943) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.AbstractIterator.foreach(Iterator.scala:1431) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.IterableLike.foreach(IterableLike.scala:74) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.IterableLike.foreach$(IterableLike.scala:73) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.AbstractIterable.foreach(Iterable.scala:56) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.TraversableLike.map(TraversableLike.scala:286) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.TraversableLike.map$(TraversableLike.scala:279) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.AbstractTraversable.map(Traversable.scala:108) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.deploy.k8s.features.MountVolumesFeatureStep.constructVolumes(MountVolumesFeatureStep.scala:58) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.deploy.k8s.features.MountVolumesFeatureStep.configurePod(MountVolumesFeatureStep.scala:35) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.KubernetesExecutorBuilder.$anonfun$buildFromFeatures$5(KubernetesExecutorBuilder.scala:83) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.immutable.List.foldLeft(List.scala:91) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.KubernetesExecutorBuilder.buildFromFeatures(KubernetesExecutorBuilder.scala:82) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$requestNewExecutors$1(ExecutorPodsAllocator.scala:430) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.requestNewExecutors(ExecutorPodsAllocator.scala:417) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36(ExecutorPodsAllocator.scala:370) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$onNewSnapshots$36$adapted(ExecutorPodsAllocator.scala:363) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.onNewSnapshots(ExecutorPodsAllocator.scala:363) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3(ExecutorPodsAllocator.scala:134) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsAllocator.$anonfun$start$3$adapted(ExecutorPodsAllocator.scala:134) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.org$apache$spark$scheduler$cluster$k8s$ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber$$processSnapshotsInternal(ExecutorPodsSnapshotsStoreImpl.scala:143) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl$SnapshotsSubscriber.processSnapshots(ExecutorPodsSnapshotsStoreImpl.scala:131) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at org.apache.spark.scheduler.cluster.k8s.ExecutorPodsSnapshotsStoreImpl.$anonfun$addSubscriber$1(ExecutorPodsSnapshotsStoreImpl.scala:85) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;at java.base/java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:833) &#160; &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;How to reproduce:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Create statically provisioned PV, for example nfs PV: &lt;a href=&quot;https://kubernetes.io/docs/concepts/storage/volumes/#nfs&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://kubernetes.io/docs/concepts/storage/volumes/#nfs&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;Create PVC that binds to PV above.&lt;/li&gt;
	&lt;li&gt;Run Spark PI example: $SPARK_HOME/bin/spark-submit --master k8s://kubernetes.default.svc --properties-file spark.properties $SPARK_HOME/examples/src/main/python/pi.py 10&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;spark.properties contents:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
spark.executor.instances=5
spark.kubernetes.executor.volumes.persistentVolumeClaim.nfs1.mount.path=/isilon/mnts
spark.kubernetes.executor.volumes.persistentVolumeClaim.nfs1.mount.readOnly=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
spark.kubernetes.executor.volumes.persistentVolumeClaim.nfs1.options.claimName=a1pvc
spark.kubernetes.driver.volumes.persistentVolumeClaim.nfs1.options.claimName=a1pvc
spark.kubernetes.driver.volumes.persistentVolumeClaim.nfs1.mount.readOnly=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
spark.kubernetes.driver.volumes.persistentVolumeClaim.nfs1.mount.path=/isilon/mnts &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13534704">SPARK-43342</key>
            <summary>Revert SPARK-39006 Show a directional error message for executor PVC dynamic allocation failure</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="dcoliversun">Qian Sun</assignee>
                                    <reporter username="ofrenkel">Oleg Frenkel</reporter>
                        <labels>
                    </labels>
                <created>Tue, 2 May 2023 15:24:22 +0000</created>
                <updated>Sun, 7 May 2023 01:27:33 +0000</updated>
                            <resolved>Sun, 7 May 2023 01:27:11 +0000</resolved>
                                    <version>3.4.0</version>
                                    <fixVersion>3.4.1</fixVersion>
                                    <component>Kubernetes</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17719121" author="dcoliversun" created="Thu, 4 May 2023 02:17:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;&#160;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yikunkero&quot; class=&quot;user-hover&quot; rel=&quot;yikunkero&quot;&gt;yikunkero&lt;/a&gt; It seems like a regression caused by&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-39006&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;SPARK-39006&lt;/a&gt;, please assign to me&lt;/p&gt;</comment>
                            <comment id="17719136" author="dongjoon" created="Thu, 4 May 2023 03:41:31 +0000"  >&lt;p&gt;Thank you for pinging me, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dcoliversun&quot; class=&quot;user-hover&quot; rel=&quot;dcoliversun&quot;&gt;dcoliversun&lt;/a&gt; . BTW, Apache Spark community has a community rule to set the `Assignee` when committers merge a proper PR.&lt;/p&gt;

&lt;p&gt;Please make a PR first.&lt;/p&gt;</comment>
                            <comment id="17719137" author="dongjoon" created="Thu, 4 May 2023 03:42:39 +0000"  >&lt;p&gt;BTW, thank you for reporting, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ofrenkel&quot; class=&quot;user-hover&quot; rel=&quot;ofrenkel&quot;&gt;ofrenkel&lt;/a&gt; .&lt;/p&gt;</comment>
                            <comment id="17719620" author="snoot" created="Fri, 5 May 2023 04:17:49 +0000"  >&lt;p&gt;User &apos;dcoliversun&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/41057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/41057&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17719621" author="snoot" created="Fri, 5 May 2023 04:18:03 +0000"  >&lt;p&gt;User &apos;dcoliversun&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/41057&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/41057&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17720265" author="dongjoon" created="Sun, 7 May 2023 01:27:11 +0000"  >&lt;p&gt;Issue resolved by pull request 41069&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/41069&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/41069&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13441339">SPARK-39006</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 27 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1hn3c:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>