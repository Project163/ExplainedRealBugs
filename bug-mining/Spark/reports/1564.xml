<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:25:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-6299] ClassNotFoundException in standalone mode when running groupByKey with class defined in REPL.</title>
                <link>https://issues.apache.org/jira/browse/SPARK-6299</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Anyone can reproduce this issue by the code below&lt;br/&gt;
(runs well in local mode, got exception with clusters)&lt;br/&gt;
(it runs well in Spark 1.1.1)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;ClassA(value: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;)
val rdd = sc.parallelize(List((&lt;span class=&quot;code-quote&quot;&gt;&quot;k1&quot;&lt;/span&gt;, ClassA(&lt;span class=&quot;code-quote&quot;&gt;&quot;v1&quot;&lt;/span&gt;)), (&lt;span class=&quot;code-quote&quot;&gt;&quot;k1&quot;&lt;/span&gt;, ClassA(&lt;span class=&quot;code-quote&quot;&gt;&quot;v2&quot;&lt;/span&gt;)) ))
rdd.groupByKey.collect
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;org.apache.spark.SparkException: Job aborted due to stage failure: Task 162 in stage 1.0 failed 4 times, most recent failure: Lost task 162.3 in stage 1.0 (TID 1027, ip-172-16-182-27.ap-northeast-1.compute.internal): java.lang.ClassNotFoundException: $iwC$$iwC$$iwC$$iwC$UserRelationshipRow
at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:425)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:358)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName0(Native Method)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.java:274)
at org.apache.spark.serializer.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:59)
at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1612)
at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1517)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1771)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
at org.apache.spark.serializer.DeserializationStream$$anon$1.getNext(Serializer.scala:133)
at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:71)
at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:91)
at org.apache.spark.shuffle.hash.HashShuffleReader.read(HashShuffleReader.scala:44)
at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:92)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:280)
at org.apache.spark.rdd.RDD.iterator(RDD.scala:247)
at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:68)
at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
at org.apache.spark.scheduler.Task.run(Task.scala:56)
at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

Driver stacktrace:
at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1214)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1203)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1202)
at scala.collection.mutable.ResizableArray$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(ResizableArray.scala:59)
at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1202)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:696)
at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:696)
at scala.Option.foreach(Option.scala:236)
at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:696)
at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1420)
at akka.actor.Actor$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;aroundReceive(Actor.scala:465)
at org.apache.spark.scheduler.DAGSchedulerEventProcessActor.aroundReceive(DAGScheduler.scala:1375)
at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
at akka.actor.ActorCell.invoke(ActorCell.scala:487)
at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
at akka.dispatch.Mailbox.run(Mailbox.scala:220)
at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12781406">SPARK-6299</key>
            <summary>ClassNotFoundException in standalone mode when running groupByKey with class defined in REPL.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="swkimme">Kevin (Sangwoo) Kim</assignee>
                                    <reporter username="swkimme">Kevin (Sangwoo) Kim</reporter>
                        <labels>
                    </labels>
                <created>Thu, 12 Mar 2015 04:59:01 +0000</created>
                <updated>Fri, 8 Jan 2016 13:13:49 +0000</updated>
                            <resolved>Tue, 17 Mar 2015 06:49:49 +0000</resolved>
                                    <version>1.2.1</version>
                    <version>1.3.0</version>
                                    <fixVersion>1.3.1</fixVersion>
                    <fixVersion>1.4.0</fixVersion>
                                    <component>Spark Shell</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14358816" author="srowen" created="Thu, 12 Mar 2015 15:22:42 +0000"  >&lt;p&gt;Hm, is this supposed to work? the class is not defined outside your driver process, and isn&apos;t found on the executors as a result.&lt;/p&gt;</comment>
                            <comment id="14359789" author="swkimme" created="Fri, 13 Mar 2015 02:05:05 +0000"  >&lt;p&gt;Hi Sean, &lt;br/&gt;
Surely it should work, I guess this is quite common pattern while working with spark shell. &lt;br/&gt;
(This code works in Spark 1.1.1) &lt;/p&gt;</comment>
                            <comment id="14360352" author="srowen" created="Fri, 13 Mar 2015 13:42:11 +0000"  >&lt;p&gt;OK, could definitely be wrong about that. I tried it on 1.2.1 (YARN) and it worked fine:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;res0: Array[(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, Iterable[ClassA])] = Array((k1,CompactBuffer(ClassA(v1), ClassA(v2))))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On master, which is roughly 1.3.0 (local), it also works:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;res0: Array[(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, Iterable[ClassA])] = Array((k1,CompactBuffer(ClassA(v1), ClassA(v2))))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;How are you running this? I can&apos;t reproduce it.&lt;/p&gt;</comment>
                            <comment id="14360391" author="kevin@between.us" created="Fri, 13 Mar 2015 14:11:41 +0000"  >&lt;p&gt;I&apos;m running standalone cluster,&lt;br/&gt;
And I confirmed another guy in community can reproduce the error.&lt;br/&gt;
For local mode, it works fine on my side too.&lt;/p&gt;

</comment>
                            <comment id="14360405" author="srowen" created="Fri, 13 Mar 2015 14:20:25 +0000"  >&lt;p&gt;Yes, I see it happens in standalone mode, so must somehow be specific to this mode. IIRC there are odd problems with case classes in particular, so you might try working around by defining a non-case class instead.&lt;/p&gt;</comment>
                            <comment id="14362782" author="swkimme" created="Mon, 16 Mar 2015 05:59:42 +0000"  >&lt;p&gt;I&apos;ve digging onto this issue, found some clues and workarounds. &lt;/p&gt;

&lt;p&gt;1. The problem came from &apos;JavaSerializer&apos;  in &apos;NettyBlockTransferService&apos;&lt;br/&gt;
it needs to be initialized with &apos;replClassLoader&apos; in Executor, but it&apos;s just using &apos;Thread.currentThread.getContextClassLoader&apos;.&lt;br/&gt;
I&apos;m thinking about how can we set classloader properly in NettyBlockTransferService.&lt;/p&gt;

&lt;p&gt;2. (EDIT) I&apos;m finding workaround. (Tried setting spark.shuffle.blockTransferService to nio but failed) &lt;/p&gt;</comment>
                            <comment id="14363239" author="apachespark" created="Mon, 16 Mar 2015 14:18:06 +0000"  >&lt;p&gt;User &apos;swkimme&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5046&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5046&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14385516" author="senkwich" created="Sat, 28 Mar 2015 20:34:12 +0000"  >&lt;p&gt;FYI, we had the same issue on Mesos for 1.2.1 when the class was defined through the REPL. So, it was not just limited to standalone mode.&lt;/p&gt;</comment>
                            <comment id="14699600" author="dreyco676" created="Mon, 17 Aug 2015 14:40:04 +0000"  >&lt;p&gt;In case anyone else is stuck on 1.3.0 for a while I was able to get around this by setting SPARK_CLASSPATH before starting spark-shell. The jar was not actually used in the REPL but by including it seemed to resolve the issue of distributing Classes in my script.&lt;/p&gt;

&lt;p&gt;SPARK_CLASSPATH=/path/ojdbc6.jar spark-shell --master yarn --deploy-mode client --num-executors 100 --driver-memory 7500m --executor-memory 7500m&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12736522">SPARK-3203</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12823179">SPARK-7061</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12843196">ZEPPELIN-158</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 14 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i26o7z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>