<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:30:40 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-9141] DataFrame recomputed instead of using cached parent.</title>
                <link>https://issues.apache.org/jira/browse/SPARK-9141</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;As I understand, DataFrame.cache() is supposed to work the same as RDD.cache(), so that repeated operations on it will use the cached results and not recompute the entire lineage. However, it seems that some DataFrame operations (e.g. withColumn) change the underlying RDD lineage so that cache doesn&apos;t work as expected.&lt;/p&gt;

&lt;p&gt;Below is a Scala example that demonstrates this. First, I define two UDF&apos;s that  use println so that it is easy to see when they are being called. Next, I create a simple data frame with one row and two columns. Next, I add a column, cache it, and call count() to force the computation. Lastly, I add another column, cache it, and call count().&lt;/p&gt;

&lt;p&gt;I would have expected the last statement to only compute the last column, since everything else was cached. However, because withColumn() changes the lineage, the whole data frame is recomputed.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-comment&quot;&gt;// Examples udf&apos;s that println when called 
&lt;/span&gt;    val twice = udf { (x: Int) =&amp;gt; println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Computed: twice($x)&quot;&lt;/span&gt;); x * 2 } 
    val triple = udf { (x: Int) =&amp;gt; println(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Computed: triple($x)&quot;&lt;/span&gt;); x * 3 } 

    &lt;span class=&quot;code-comment&quot;&gt;// Initial dataset 
&lt;/span&gt;    val df1 = sc.parallelize(Seq((&lt;span class=&quot;code-quote&quot;&gt;&quot;a&quot;&lt;/span&gt;, 1))).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;name&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;) 

    &lt;span class=&quot;code-comment&quot;&gt;// Add column by applying twice udf 
&lt;/span&gt;    val df2 = df1.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;twice&quot;&lt;/span&gt;, twice($&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;)) 
    df2.cache() 
    df2.count() &lt;span class=&quot;code-comment&quot;&gt;//prints Computed: twice(1) 
&lt;/span&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// Add column by applying triple udf 
&lt;/span&gt;    val df3 = df2.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;triple&quot;&lt;/span&gt;, triple($&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;)) 
    df3.cache() 
    df3.count() &lt;span class=&quot;code-comment&quot;&gt;//prints Computed: twice(1)\nComputed: triple(1) &lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I found a workaround, which helped me understand what was going on behind the scenes, but doesn&apos;t seem like an ideal solution. Basically, I convert to RDD then back DataFrame, which seems to freeze the lineage. The code below shows the workaround for creating the second data frame so cache will work as expected.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    val df2 = {
      val tmp = df1.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;twice&quot;&lt;/span&gt;, twice($&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;))
      sqlContext.createDataFrame(tmp.rdd, tmp.schema)
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12845974">SPARK-9141</key>
            <summary>DataFrame recomputed instead of using cached parent.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="marmbrus">Michael Armbrust</assignee>
                                    <reporter username="pnpritchard">Nick Pritchard</reporter>
                        <labels>
                            <label>cache</label>
                            <label>dataframe</label>
                    </labels>
                <created>Fri, 17 Jul 2015 20:18:30 +0000</created>
                <updated>Tue, 2 Feb 2016 01:23:05 +0000</updated>
                            <resolved>Wed, 5 Aug 2015 16:02:12 +0000</resolved>
                                    <version>1.4.0</version>
                    <version>1.4.1</version>
                                    <fixVersion>1.5.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="14649437" author="justin.uang" created="Fri, 31 Jul 2015 16:30:12 +0000"  >&lt;p&gt;(Taken from spark dev email: &lt;a href=&quot;http://apache-spark-developers-list.1001551.n3.nabble.com/DataFrame-rdd-doesn-t-respect-DataFrame-cache-slowing-down-CrossValidator-td13466.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://apache-spark-developers-list.1001551.n3.nabble.com/DataFrame-rdd-doesn-t-respect-DataFrame-cache-slowing-down-CrossValidator-td13466.html&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;If I call DataFrame#cache and DataFrame#count, and then get an rdd from DataFrame#rdd, then the resulting RDD computes the entire lineage chain, not using&lt;br/&gt;
cached DataFrame results.&lt;/p&gt;

&lt;p&gt;Likewise, for the CrossValidation and LogisticRegression use case to work, we would need this and the original of this bug to be fixed as well, such that if I cached DataFrame A, then derive DataFrame B with DataFrame#withColumn, then B.rdd() should return an RDD that uses the cached DataFrame A.&lt;/p&gt;</comment>
                            <comment id="14653013" author="apachespark" created="Tue, 4 Aug 2015 03:19:03 +0000"  >&lt;p&gt;User &apos;marmbrus&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7920&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7920&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14658438" author="yhuai" created="Wed, 5 Aug 2015 16:02:13 +0000"  >&lt;p&gt;Issue resolved by pull request 7920&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7920&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7920&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14658449" author="apachespark" created="Wed, 5 Aug 2015 16:09:03 +0000"  >&lt;p&gt;User &apos;yhuai&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7964&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7964&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15024314" author="tianyi" created="Tue, 24 Nov 2015 11:37:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt; It seems that your patch did not fix this problem. I found the same problem in spark 1.5.1.&lt;/p&gt;</comment>
                            <comment id="15024927" author="marmbrus" created="Tue, 24 Nov 2015 17:35:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tianyi&quot; class=&quot;user-hover&quot; rel=&quot;tianyi&quot;&gt;tianyi&lt;/a&gt; please provide a reproduction of the issue you are hitting.  The example from the description works for me.  In particular please include explain for the cache and failing dataframe.&lt;/p&gt;</comment>
                            <comment id="15026105" author="tianyi" created="Wed, 25 Nov 2015 03:34:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt; Sorry, it&apos;s our fault.&lt;/p&gt;</comment>
                            <comment id="15125491" author="zephod" created="Sun, 31 Jan 2016 20:43:11 +0000"  >&lt;p&gt;Can it be that this problem still persists in spark 1.6? I have a program where I do a transitive closure and it visibly slows with every iteration. Also filtered.explain() suggests that everything is recomputed. The slow down occurs even if the input is define in such a way, that no rows get computer, i.e., filtered is always empty (after few initial iterations). (The code assumes that Edge is a simple case class with start and end)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    val e = Seq((1, 2), (1, 3), (2, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (23, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13))
    &lt;span class=&quot;code-comment&quot;&gt;//val e = Seq((1, 2), (1, 3), (2, 4), (4, 5), (5, 6), (6, 7))
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; edges = sc
      .parallelize(e, N)
      .map(p =&amp;gt; Edge(p._1, p._2))
      .toDF()
      .cache()
    &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; filtered = edges
      .filter(&lt;span class=&quot;code-quote&quot;&gt;&quot;start = 1&quot;&lt;/span&gt;)
      .distinct()
      .withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;start&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;fStart&quot;&lt;/span&gt;)
      .withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;end&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;fEnd&quot;&lt;/span&gt;)
      .cache()

    &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; i = 0
    &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (i &amp;lt; 300) {
      i = i + 1
      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;\n i = &quot;&lt;/span&gt; + i)
      filtered = filtered
        .join(edges, filtered(&lt;span class=&quot;code-quote&quot;&gt;&quot;fEnd&quot;&lt;/span&gt;) === edges(&lt;span class=&quot;code-quote&quot;&gt;&quot;start&quot;&lt;/span&gt;))
        .select(filtered(&lt;span class=&quot;code-quote&quot;&gt;&quot;fStart&quot;&lt;/span&gt;), edges(&lt;span class=&quot;code-quote&quot;&gt;&quot;end&quot;&lt;/span&gt;))
        .withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;start&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;fStart&quot;&lt;/span&gt;)
        .withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;end&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;fEnd&quot;&lt;/span&gt;)
        .distinct
        .cache()
      
      filtered.show
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Also I sometimes get the following error, which I don&apos;t understand (and it is non-deterministic - I only get the error sometimes):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;16/01/31 21:33:52 ERROR Utils: Uncaught exception in thread driver-heartbeater
java.io.IOException: java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.HashMap$SerializationProxy to field org.apache.spark.executor.TaskMetrics._accumulatorUpdates of type scala.collection.immutable.Map in instance of org.apache.spark.executor.TaskMetrics
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1207)
	at org.apache.spark.executor.TaskMetrics.readObject(TaskMetrics.scala:219)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1058)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1900)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1801)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1351)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:371)
	at org.apache.spark.util.Utils$.deserialize(Utils.scala:92)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15125498" author="justin.uang" created="Sun, 31 Jan 2016 20:50:08 +0000"  >&lt;p&gt;Does your explain() string grow exponentially w.r.t. to the number of the iterations? I tried doing an algorithm that did self joins as well that used caching to get around iterating over the parent twice, and while the caching worked, the strings that the DataFrame generates grows exponentially to the point of crashing the driver.&lt;/p&gt;</comment>
                            <comment id="15125517" author="zephod" created="Sun, 31 Jan 2016 21:19:29 +0000"  >&lt;p&gt;It grows linearly. I got the errors when the string wasn&apos;t printed out. I did not see any of those problems when working with RDDs.&lt;/p&gt;

&lt;p&gt;PS. Would having exponential lineage (while not printing it out as a string) cause errors in Spark SQL?&lt;/p&gt;</comment>
                            <comment id="15127395" author="zephod" created="Tue, 2 Feb 2016 01:23:05 +0000"  >&lt;p&gt;Should I create a new issue with my case?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 42 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2fqzb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310921" key="com.pyxis.greenhopper.jira:gh-sprint">
                        <customfieldname>Sprint</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="165">Spark 1.5 release</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12332078">1.5.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>