<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:40:52 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-14488] &quot;CREATE TEMPORARY TABLE ... USING ... AS SELECT ...&quot; creates persisted table</title>
                <link>https://issues.apache.org/jira/browse/SPARK-14488</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following Spark shell snippet reproduces this bug:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sqlContext range 10 registerTempTable &lt;span class=&quot;code-quote&quot;&gt;&quot;x&quot;&lt;/span&gt;

&lt;span class=&quot;code-comment&quot;&gt;// The problematic DDL statement:
&lt;/span&gt;sqlContext sql &lt;span class=&quot;code-quote&quot;&gt;&quot;CREATE TEMPORARY TABLE y USING PARQUET AS SELECT * FROM x&quot;&lt;/span&gt;

sqlContext.tables().show()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It shows the following result:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+---------+-----------+
|tableName|isTemporary|
+---------+-----------+
|        y|      false|
|        x|       true|
+---------+-----------+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that &lt;tt&gt;y&lt;/tt&gt; is NOT temporary although it&apos;s created using &lt;tt&gt;CREATE TEMPORARY TABLE ...&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Explain shows that the physical plan node is &lt;tt&gt;CreateTableUsingAsSelect&lt;/tt&gt; rather than &lt;tt&gt;CreateTempTableUsingAsSelect&lt;/tt&gt;.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;== Parsed Logical Plan ==
&apos;CreateTableUsingAsSelect `y`, PARQUET, true, [Ljava.lang.String;@4d001a14, None, Overwrite, Map()
+- &apos;Project [*]
   +- &apos;UnresolvedRelation `x`, None

== Analyzed Logical Plan ==

CreateTableUsingAsSelect `y`, PARQUET, true, [Ljava.lang.String;@4d001a14, None, Overwrite, Map()
+- Project [id#0L]
   +- SubqueryAlias x
      +- Range 0, 10, 1, 1, [id#0L]

== Optimized Logical Plan ==
CreateTableUsingAsSelect `y`, PARQUET, true, [Ljava.lang.String;@4d001a14, None, Overwrite, Map()
+- Range 0, 10, 1, 1, [id#0L]

== Physical Plan ==
ExecutedCommand CreateMetastoreDataSourceAsSelect `y`, PARQUET, [Ljava.lang.String;@4d001a14, None, Overwrite, Map(), Range 0, 10, 1, 1, [id#0L]|
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12957182">SPARK-14488</key>
            <summary>&quot;CREATE TEMPORARY TABLE ... USING ... AS SELECT ...&quot; creates persisted table</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lian cheng">Cheng Lian</assignee>
                                    <reporter username="lian cheng">Cheng Lian</reporter>
                        <labels>
                    </labels>
                <created>Fri, 8 Apr 2016 10:58:58 +0000</created>
                <updated>Tue, 12 Apr 2016 14:32:35 +0000</updated>
                            <resolved>Tue, 12 Apr 2016 14:32:35 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15232030" author="lian cheng" created="Fri, 8 Apr 2016 11:09:54 +0000"  >&lt;p&gt;Oh, wait... Since there&apos;s a &lt;tt&gt;USING&lt;/tt&gt; in the DDL statement, are we supposed to write the query result using given data source format on disk, and use written files to create a temporary table? So basically this DDL is used to save a query result using a specific data source format to disk? I find this one quite confusing...&lt;/p&gt;

&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;yhuai&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15232078" author="lian cheng" created="Fri, 8 Apr 2016 11:58:46 +0000"  >&lt;p&gt;Updated title and description of this ticket.&lt;/p&gt;</comment>
                            <comment id="15232092" author="lian cheng" created="Fri, 8 Apr 2016 12:05:34 +0000"  >&lt;p&gt;Tried the same snippet using Spark 1.6, and got the following exception, which makes sense. I tend to believe that the combination described in the ticket is invalid and should be rejected by either parser or analyzer.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; sqlContext sql &quot;CREATE TEMPORARY TABLE y USING PARQUET AS SELECT * FROM x&quot;
java.util.NoSuchElementException: key not found: path
        at scala.collection.MapLike$class.default(MapLike.scala:228)
        at org.apache.spark.sql.execution.datasources.CaseInsensitiveMap.default(ddl.scala:150)
        at scala.collection.MapLike$class.apply(MapLike.scala:141)
        at org.apache.spark.sql.execution.datasources.CaseInsensitiveMap.apply(ddl.scala:150)
        at org.apache.spark.sql.execution.datasources.ResolvedDataSource$.apply(ResolvedDataSource.scala:230)
        at org.apache.spark.sql.execution.datasources.CreateTempTableUsingAsSelect.run(ddl.scala:112)
        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult$lzycompute(commands.scala:58)
        at org.apache.spark.sql.execution.ExecutedCommand.sideEffectResult(commands.scala:56)
        at org.apache.spark.sql.execution.ExecutedCommand.doExecute(commands.scala:70)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:132)
        at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:130)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
        at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:130)
        at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:55)
        at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:55)
        at org.apache.spark.sql.DataFrame.&amp;lt;init&amp;gt;(DataFrame.scala:145)
        at org.apache.spark.sql.DataFrame.&amp;lt;init&amp;gt;(DataFrame.scala:130)
        at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:52)
        at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:817)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:26)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:31)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:33)
        at $iwC$$iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:35)
        at $iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:37)
        at $iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:39)
        at $iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:41)
        at $iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:43)
        at &amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:45)
        at .&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:49)
        at .&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)
        at .&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:7)
        at .&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)
        at $print(&amp;lt;console&amp;gt;)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:483)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
        at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
        at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
        at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:483)
        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15232107" author="cloud_fan" created="Fri, 8 Apr 2016 12:17:26 +0000"  >&lt;p&gt;This command looks very weird to me, does it make sense? Should we remove it?&lt;/p&gt;</comment>
                            <comment id="15232111" author="lian cheng" created="Fri, 8 Apr 2016 12:21:27 +0000"  >&lt;p&gt;However, if &lt;tt&gt;TEMPORARY + USING + AS SELECT&lt;/tt&gt; is an invalid combination, why do we have a &lt;a href=&quot;https://github.com/apache/spark/blob/583b5e05309adb73cdffd974a810d6bfb5f2ff95/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/ddl.scala#L116&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;&lt;tt&gt;CreateTempTableUsingAsSelect&lt;/tt&gt; command&lt;/a&gt;, which exactly maps to this combination?&lt;/p&gt;</comment>
                            <comment id="15232118" author="lian cheng" created="Fri, 8 Apr 2016 12:24:40 +0000"  >&lt;p&gt;Result of &lt;tt&gt;EXPLAIN EXTENDED CREATE TEMPORARY TABLE y USING PARQUET AS SELECT * FROM x&lt;/tt&gt;:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;== Parsed Logical Plan ==
&apos;CreateTableUsingAsSelect `y`, PARQUET, true, [Ljava.lang.String;@4d001a14, None, Overwrite, Map()
+- &apos;Project [*]
   +- &apos;UnresolvedRelation `x`, None

== Analyzed Logical Plan ==

CreateTableUsingAsSelect `y`, PARQUET, true, [Ljava.lang.String;@4d001a14, None, Overwrite, Map()
+- Project [id#0L]
   +- SubqueryAlias x
      +- Range 0, 10, 1, 1, [id#0L]

== Optimized Logical Plan ==
CreateTableUsingAsSelect `y`, PARQUET, true, [Ljava.lang.String;@4d001a14, None, Overwrite, Map()
+- Range 0, 10, 1, 1, [id#0L]

== Physical Plan ==
ExecutedCommand CreateMetastoreDataSourceAsSelect `y`, PARQUET, [Ljava.lang.String;@4d001a14, None, Overwrite, Map(), Range 0, 10, 1, 1, [id#0L]|
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So it seems that the parser drops &lt;tt&gt;TEMPORARY&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="15232277" author="hvanhovell" created="Fri, 8 Apr 2016 14:46:27 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lian+cheng&quot; class=&quot;user-hover&quot; rel=&quot;lian cheng&quot;&gt;lian cheng&lt;/a&gt; I just did the following:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; import org.apache.spark.sql.execution.SparkSqlParser._

scala&amp;gt; parsePlan(&quot;CREATE TEMPORARY TABLE y USING PARQUET AS SELECT * FROM x&quot;)
res0: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
&apos;CreateTableUsingAsSelect `y`, PARQUET, true, [Ljava.lang.String;@2f98859a, None, Overwrite, Map()
+- &apos;Project [*]
   +- &apos;UnresolvedRelation `x`, None

scala&amp;gt; res0.asInstanceOf[org.apache.spark.sql.execution.datasources.CreateTableUsingAsSelect].temporary
res1: Boolean = true
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The temporary variabele seems to be set.&lt;/p&gt;</comment>
                            <comment id="15232401" author="lian cheng" created="Fri, 8 Apr 2016 16:06:59 +0000"  >&lt;p&gt;Ah, sorry, the logical plan class &lt;tt&gt;CreateTableUsingAsSelect&lt;/tt&gt; uses a boolean flag to indicate whether the table is temporary or not, while physical plan uses two different classes &lt;tt&gt;CreateTempTableUsingAsSelect&lt;/tt&gt; and &lt;tt&gt;CreateTableUsingAsSelect&lt;/tt&gt;. Then something is probably wrong in the planner.&lt;/p&gt;</comment>
                            <comment id="15232402" author="hvanhovell" created="Fri, 8 Apr 2016 16:08:31 +0000"  >&lt;p&gt;&lt;tt&gt;CreateTempTableUsingAsSelect&lt;/tt&gt; should be planned by &lt;tt&gt;SparkStrategies DDLStrategy&lt;/tt&gt;, see: &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala#L428-L431&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala#L428-L431&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15232414" author="lian cheng" created="Fri, 8 Apr 2016 16:17:05 +0000"  >&lt;p&gt;Discussed with &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;yhuai&lt;/a&gt; offline, and here&apos;s the summary:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;CreateTempTableUsingAsSelect&lt;/tt&gt; existed since 1.3 (I&apos;m surprised that I never noticed it!). Its semantics is:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Execute the &lt;tt&gt;SELECT&lt;/tt&gt; query.&lt;/li&gt;
	&lt;li&gt;Store query result to a user specified position in filesystem. Note that this means the &lt;tt&gt;PATH&lt;/tt&gt; data source option should always be set when using this DDL command.&lt;/li&gt;
	&lt;li&gt;Create a temporary table using written files.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Basically, it can be used to dump query results to the filesystem without creating persisted tables. It&apos;s indeed a confusing command and is kinda equivalent to the following DDL sequence:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;tt&gt;INSERT OVERWRITE DIRECTORY ... STORE AS ... SELECT ...&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;CREATE TEMPORARY TABLE ... USING ... OPTION (PATH ...)&lt;/tt&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;However, Spark hasn&apos;t implemented &lt;tt&gt;INSERT OVERWRITE DIRECTORY&lt;/tt&gt; yet. In the long run, we should implement it and deprecate this confusing DDL command.&lt;/p&gt;

&lt;p&gt;Ticket title and description were updated accordingly.&lt;/p&gt;</comment>
                            <comment id="15232422" author="lian cheng" created="Fri, 8 Apr 2016 16:19:42 +0000"  >&lt;p&gt;Yea, that&apos;s why I came to this DDL command, because this command seems to be the only way to trigger &lt;tt&gt;CreateTempTableUsingAsSelect&lt;/tt&gt;. However, the physical plan doesn&apos;t use it. Will look into this. Thanks!&lt;/p&gt;</comment>
                            <comment id="15233739" author="yhuai" created="Sat, 9 Apr 2016 21:27:14 +0000"  >&lt;p&gt;btw, a useful language feature to add is &lt;tt&gt;CREATE TEMPORARY TABLE t AS SELECT&lt;/tt&gt;, which is the SQL equivalent of &lt;tt&gt;sql(&quot;...&quot;).registerTempTable()&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="15235593" author="apachespark" created="Mon, 11 Apr 2016 17:54:04 +0000"  >&lt;p&gt;User &apos;liancheng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12303&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12303&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15237269" author="lian cheng" created="Tue, 12 Apr 2016 14:32:35 +0000"  >&lt;p&gt;Issue resolved by pull request 12303&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12303&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12303&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12957257">SPARK-14493</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 32 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2vu73:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>