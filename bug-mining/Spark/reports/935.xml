<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:19:29 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4133] PARSING_ERROR(2) when upgrading issues from 1.0.2 to 1.1.0</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4133</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Snappy related problems found when trying to upgrade existing Spark Streaming App from 1.0.2 to 1.1.0.&lt;/p&gt;

&lt;p&gt;We can not run an existing 1.0.2 spark app if upgraded to 1.1.0&lt;/p&gt;

&lt;p&gt;&amp;gt; IOException is thrown by snappy (parsing_error(2))&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Executor task launch worker-0 DEBUG storage.BlockManager - Getting local block broadcast_0
Executor task launch worker-0 DEBUG storage.BlockManager - Level &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block broadcast_0 is StorageLevel(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 1)
Executor task launch worker-0 DEBUG storage.BlockManager - Getting block broadcast_0 from memory
Executor task launch worker-0 DEBUG storage.BlockManager - Getting local block broadcast_0
Executor task launch worker-0 DEBUG executor.Executor - Task 0&apos;s epoch is 0
Executor task launch worker-0 DEBUG storage.BlockManager - Block broadcast_0 not registered locally
Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Started reading broadcast variable 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 INFO  receiver.ReceiverSupervisorImpl - Registered receiver 0
Executor task launch worker-0 INFO  util.RecurringTimer - Started timer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; BlockGenerator at time 1414656492400
Executor task launch worker-0 INFO  receiver.BlockGenerator - Started BlockGenerator
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-87 INFO  receiver.BlockGenerator - Started block pushing thread
Executor task launch worker-0 INFO  receiver.ReceiverSupervisorImpl - Starting receiver
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 INFO  scheduler.ReceiverTracker - Registered receiver &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; stream 0 from akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver
&lt;/span&gt;Executor task launch worker-0 INFO  kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: stratioStreaming
Executor task launch worker-0 INFO  kafka.KafkaReceiver - Connecting to Zookeeper: node.stratio.com:2181
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-6 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG local.LocalActor - [actor] handled message (8.442354 ms) StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG local.LocalActor - [actor] handled message (8.412421 ms) StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-6 DEBUG local.LocalActor - [actor] handled message (8.385471 ms) StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;Executor task launch worker-0 INFO  utils.VerifiableProperties - Verifying properties
Executor task launch worker-0 INFO  utils.VerifiableProperties - Property group.id is overridden to stratioStreaming
Executor task launch worker-0 INFO  utils.VerifiableProperties - Property zookeeper.connect is overridden to node.stratio.com:2181
Executor task launch worker-0 INFO  utils.VerifiableProperties - Property zookeeper.connection.timeout.ms is overridden to 10000
Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Reading broadcast variable 0 took 0.033998997 s
Executor task launch worker-0 INFO  consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414656492293-8ecb3e3a], Connecting to zookeeper instance at node.stratio.com:2181
Executor task launch worker-0 DEBUG zkclient.ZkConnection - Creating &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ZookKeeper instance to connect to node.stratio.com:2181.
ZkClient-EventThread-169-node.stratio.com:2181 INFO  zkclient.ZkEventThread - Starting ZkClient event thread.
Executor task launch worker-0 INFO  zookeeper.ZooKeeper - Initiating client connection, connectString=node.stratio.com:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@5b4bdc81
Executor task launch worker-0 DEBUG zkclient.ZkClient - Awaiting connection to Zookeeper server
Executor task launch worker-0 DEBUG zkclient.ZkClient - Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; keeper state SyncConnected
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Opening socket connection to server node.stratio.com/172.19.0.96:2181. Will not attempt to authenticate using SASL (unknown error)
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Socket connection established to node.stratio.com/172.19.0.96:2181, initiating session
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Session establishment request sent on node.stratio.com/172.19.0.96:2181
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Session establishment complete on server node.stratio.com/172.19.0.96:2181, sessionid = 0x1496007e6710002, negotiated timeout = 6000
Executor task launch worker-0-EventThread DEBUG zkclient.ZkClient - Received event: WatchedEvent state:SyncConnected type:None path:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Executor task launch worker-0-EventThread INFO  zkclient.ZkClient - zookeeper state changed (SyncConnected)
Executor task launch worker-0-EventThread DEBUG zkclient.ZkClient - Leaving process event
Executor task launch worker-0 DEBUG zkclient.ZkClient - State is SyncConnected
RecurringTimer - BlockGenerator DEBUG util.RecurringTimer - Callback &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; BlockGenerator called at time 1414656492400
Executor task launch worker-0 DEBUG utils.KafkaScheduler - Initializing task scheduler.
Executor task launch worker-0 INFO  consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414656492293-8ecb3e3a], starting auto committer every 60000 ms
Executor task launch worker-0 DEBUG utils.KafkaScheduler - Scheduling task kafka-consumer-autocommit with initial delay 60000 ms and period 60000 ms.
Executor task launch worker-0 INFO  kafka.KafkaReceiver - Connected to node.stratio.com:2181
Executor task launch worker-0 DEBUG consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414656492293-8ecb3e3a], entering consume 
Executor task launch worker-0 INFO  consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414656492293-8ecb3e3a], begin registering consumer stratioStreaming_ajn-stratio-1414656492293-8ecb3e3a in ZK
Executor task launch worker-0 DEBUG storage.BlockManager - Getting local block broadcast_0
Executor task launch worker-0 DEBUG storage.BlockManager - Block broadcast_0 not registered locally
Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Started reading broadcast variable 0
Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Reading broadcast variable 0 took 5.5676E-5 s
Executor task launch worker-0 ERROR executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
java.io.IOException: PARSING_ERROR(2)
	at org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:78)
	at org.xerial.snappy.SnappyNative.uncompressedLength(Native Method)
	at org.xerial.snappy.Snappy.uncompressedLength(Snappy.java:545)
	at org.xerial.snappy.SnappyInputStream.readFully(SnappyInputStream.java:125)
	at org.xerial.snappy.SnappyInputStream.readHeader(SnappyInputStream.java:88)
	at org.xerial.snappy.SnappyInputStream.&amp;lt;init&amp;gt;(SnappyInputStream.java:58)
	at org.apache.spark.io.SnappyCompressionCodec.compressedInputStream(CompressionCodec.scala:128)
	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:232)
	at org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Executor task launch worker-0 ERROR executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
java.io.IOException: PARSING_ERROR(2)
	at org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:78)
	at org.xerial.snappy.SnappyNative.uncompressedLength(Native Method)
	at org.xerial.snappy.Snappy.uncompressedLength(Snappy.java:545)
	at org.xerial.snappy.SnappyInputStream.readFully(SnappyInputStream.java:125)
	at org.xerial.snappy.SnappyInputStream.readHeader(SnappyInputStream.java:88)
	at org.xerial.snappy.SnappyInputStream.&amp;lt;init&amp;gt;(SnappyInputStream.java:58)
	at org.apache.spark.io.SnappyCompressionCodec.compressedInputStream(CompressionCodec.scala:128)
	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:232)
	at org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2144 cap=2144]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2144 cap=2144]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0, runningTasks: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0, runningTasks: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG local.LocalActor - [actor] handled message (1.213476 ms) StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2144 cap=2144]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG local.LocalActor - [actor] handled message (1.543991 ms) StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2144 cap=2144]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;Result resolver thread-0 WARN  scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.io.IOException: PARSING_ERROR(2)
        org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:78)
        org.xerial.snappy.SnappyNative.uncompressedLength(Native Method)
        org.xerial.snappy.Snappy.uncompressedLength(Snappy.java:545)
        org.xerial.snappy.SnappyInputStream.readFully(SnappyInputStream.java:125)
        org.xerial.snappy.SnappyInputStream.readHeader(SnappyInputStream.java:88)
        org.xerial.snappy.SnappyInputStream.&amp;lt;init&amp;gt;(SnappyInputStream.java:58)
        org.apache.spark.io.SnappyCompressionCodec.compressedInputStream(CompressionCodec.scala:128)
        org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:232)
        org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
        sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        java.lang.reflect.Method.invoke(Method.java:606)
        java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Result resolver thread-0 WARN  scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.io.IOException: PARSING_ERROR(2)
        org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:78)
        org.xerial.snappy.SnappyNative.uncompressedLength(Native Method)
        org.xerial.snappy.Snappy.uncompressedLength(Snappy.java:545)
        org.xerial.snappy.SnappyInputStream.readFully(SnappyInputStream.java:125)
        org.xerial.snappy.SnappyInputStream.readHeader(SnappyInputStream.java:88)
        org.xerial.snappy.SnappyInputStream.&amp;lt;init&amp;gt;(SnappyInputStream.java:58)
        org.apache.spark.io.SnappyCompressionCodec.compressedInputStream(CompressionCodec.scala:128)
        org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:232)
        org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
        sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        java.lang.reflect.Method.invoke(Method.java:606)
        java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Result resolver thread-0 ERROR scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
Result resolver thread-0 ERROR scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
Result resolver thread-0 INFO  scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
Result resolver thread-0 INFO  scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  scheduler.TaskSchedulerImpl - Cancelling stage 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  scheduler.TaskSchedulerImpl - Cancelling stage 0
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-84 INFO  scheduler.DAGScheduler - Failed to run runJob at ReceiverTracker.scala:275
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-85 INFO  scheduler.DAGScheduler - Failed to run runJob at ReceiverTracker.scala:275
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.DAGScheduler - Removing running stage 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.DAGScheduler - Removing running stage 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.DAGScheduler - After removal of stage 0, remaining stages = 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.DAGScheduler - After removal of stage 0, remaining stages = 0
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Reading reply sessionid:0x1496007e6710002, packet:: clientPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; serverPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; finished:&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; header:: 1,1  replyHeader:: 1,25,-101  request:: &lt;span class=&quot;code-quote&quot;&gt;&apos;/consumers/stratioStreaming/ids/stratioStreaming_ajn-stratio-1414656492293-8ecb3e3a,#7b2276657273696f6e223a312c22737562736372697074696f6e223a7b227374726174696f5f73747265616d696e675f616374696f6e223a317d2c227061747465726e223a22737461746963222c2274696d657374616d70223a2231343134363536343932343737227d,v{s{31,s{&apos;&lt;/span&gt;world,&apos;anyone}}},1  response::  
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&amp;gt; Only spark version changed&lt;/p&gt;

&lt;p&gt;As far as we have checked, snappy will throw this error when dealing with zero bytes length arrays.&lt;/p&gt;

&lt;p&gt;We have tried:&lt;/p&gt;

&lt;p&gt;&amp;gt; Changing from snappy to LZF&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Executor task launch worker-0 DEBUG zkclient.ZkConnection - Creating &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ZookKeeper instance to connect to node.stratio.com:2181.
ZkClient-EventThread-166-node.stratio.com:2181 INFO  zkclient.ZkEventThread - Starting ZkClient event thread.
Executor task launch worker-0 INFO  zookeeper.ZooKeeper - Initiating client connection, connectString=node.stratio.com:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@5a4f889
Executor task launch worker-0 DEBUG zkclient.ZkClient - Awaiting connection to Zookeeper server
Executor task launch worker-0 DEBUG zkclient.ZkClient - Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; keeper state SyncConnected
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Opening socket connection to server node.stratio.com/172.19.0.96:2181. Will not attempt to authenticate using SASL (unknown error)
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Socket connection established to node.stratio.com/172.19.0.96:2181, initiating session
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Session establishment request sent on node.stratio.com/172.19.0.96:2181
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Session establishment complete on server node.stratio.com/172.19.0.96:2181, sessionid = 0x1496007e6710009, negotiated timeout = 6000
Executor task launch worker-0-EventThread DEBUG zkclient.ZkClient - Received event: WatchedEvent state:SyncConnected type:None path:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Executor task launch worker-0-EventThread INFO  zkclient.ZkClient - zookeeper state changed (SyncConnected)
Executor task launch worker-0-EventThread DEBUG zkclient.ZkClient - Leaving process event
Executor task launch worker-0 DEBUG zkclient.ZkClient - State is SyncConnected
ProducerSendThread- DEBUG async.ProducerSendThread - 5000 ms elapsed. Queue time reached. Sending..
ProducerSendThread- DEBUG async.ProducerSendThread - Handling 0 events
Executor task launch worker-0 DEBUG storage.BlockManager - Getting local block broadcast_0
Executor task launch worker-0 DEBUG storage.BlockManager - Block broadcast_0 not registered locally
Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Started reading broadcast variable 0
Executor task launch worker-0 ERROR executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
java.io.EOFException
	at java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2325)
	at java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
	at java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
	at java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
	at org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
	at org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
	at org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:235)
	at org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Reading broadcast variable 0 took 1.002E-4 s
Executor task launch worker-0 ERROR executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
java.io.EOFException
	at java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2325)
	at java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
	at java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
	at java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
	at org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
	at org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
	at org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:235)
	at org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Executor task launch worker-0 DEBUG utils.KafkaScheduler - Initializing task scheduler.
Executor task launch worker-0 INFO  consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414658065894-94786a0e], starting auto committer every 60000 ms
Executor task launch worker-0 DEBUG utils.KafkaScheduler - Scheduling task kafka-consumer-autocommit with initial delay 60000 ms and period 60000 ms.
Executor task launch worker-0 INFO  kafka.KafkaReceiver - Connected to node.stratio.com:2181
Executor task launch worker-0 DEBUG consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414658065894-94786a0e], entering consume 
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2066 cap=2066]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0, runningTasks: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG local.LocalActor - [actor] handled message (1.674221 ms) StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=179 lim=2066 cap=2066]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2066 cap=2066]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0, runningTasks: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG local.LocalActor - [actor] handled message (0.994221 ms) StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2066 cap=2066]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;Result resolver thread-0 WARN  scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.io.EOFException: 
        java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2325)
        java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
        java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
        java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
        org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
        org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
        org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
        org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:235)
        org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
        sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        java.lang.reflect.Method.invoke(Method.java:606)
        java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG scheduler.JobGenerator - Got event GenerateJobs(1414658066000 ms)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG streaming.DStreamGraph - Generating jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414658066000 ms
RecurringTimer - BlockGenerator DEBUG util.RecurringTimer - Callback &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; BlockGenerator called at time 1414658066000
Result resolver thread-0 WARN  scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.io.EOFException: 
        java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2325)
        java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
        java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
        java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
        org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
        org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
        org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
        org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:235)
        org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
        sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        java.lang.reflect.Method.invoke(Method.java:606)
        java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.MappedDStream - Time 1414658066000 ms is valid
RecurringTimer - JobGenerator DEBUG util.RecurringTimer - Callback &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; JobGenerator called at time 1414658066000
Result resolver thread-0 ERROR scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
Result resolver thread-0 ERROR scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
RecurringTimer - JobGenerator DEBUG util.RecurringTimer - Callback &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; JobGenerator called at time 1414658066000
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG scheduler.JobGenerator - Got event GenerateJobs(1414658066000 ms)
RecurringTimer - JobGenerator DEBUG util.RecurringTimer - Callback &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; JobGenerator called at time 1414658066000
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.JobGenerator - Got event GenerateJobs(1414658066000 ms)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG streaming.DStreamGraph - Generating jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414658066000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG streaming.DStreamGraph - Generating jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414658066000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.FilteredDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG kafka.KafkaInputDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 INFO  scheduler.ReceiverTracker - Stream 0 received 0 blocks
Result resolver thread-0 INFO  scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
Result resolver thread-0 INFO  scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG dstream.MappedDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.FilteredDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG dstream.FilteredDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.MapValuedDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.ShuffledDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.MapPartitionedDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.MappedDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG kafka.KafkaInputDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  scheduler.ReceiverTracker - Stream 0 received 0 blocks
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG kafka.KafkaInputDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 INFO  scheduler.ReceiverTracker - Stream 0 received 0 blocks
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 INFO  scheduler.TaskSchedulerImpl - Cancelling stage 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  scheduler.TaskSchedulerImpl - Cancelling stage 0
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-85 INFO  scheduler.DAGScheduler - Failed to run runJob at ReceiverTracker.scala:275
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  kafka.KafkaInputDStream - Persisting RDD 1 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414658066000 ms to StorageLevel(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 1) at time 1414658066000 ms
Executor task launch worker-0 INFO  consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414658065894-94786a0e], begin registering consumer stratioStreaming_ajn-stratio-1414658065894-94786a0e in ZK
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-84 INFO  scheduler.DAGScheduler - Failed to run runJob at ReceiverTracker.scala:275
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 INFO  kafka.KafkaInputDStream - Persisting RDD 1 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414658066000 ms to StorageLevel(&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 1) at time 1414658066000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG scheduler.DAGScheduler - Removing running stage 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.DAGScheduler - Removing running stage 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG scheduler.DAGScheduler - After removal of stage 0, remaining stages = 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.DAGScheduler - After removal of stage 0, remaining stages = 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.MappedDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.FilteredDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG streaming.DStreamGraph - Generated 1 jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414658066000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.MappedDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.FilteredDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  scheduler.JobScheduler - Added jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414658066000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.JobGenerator - Got event DoCheckpoint(1414658066000 ms)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 INFO  scheduler.JobScheduler - Starting job streaming job 1414658066000 ms.0 from job set of time 1414658066000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.MappedDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.FilteredDStream - Time 1414658066000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG dstream.MappedDStream - Time 1414658066000 ms is valid
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Reading reply sessionid:0x1496007e6710009, packet:: clientPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; serverPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; finished:&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; header:: 1,1  replyHeader:: 1,50,0  request:: &lt;span class=&quot;code-quote&quot;&gt;&apos;/consumers/stratioStreaming/ids/stratioStreaming_ajn-stratio-1414658065894-94786a0e,#7b2276657273696f6e223a312c22737562736372697074696f6e223a7b227374726174696f5f73747265616d696e675f616374696f6e223a317d2c227061747465726e223a22737461746963222c2274696d657374616d70223a2231343134363538303636303136227d,v{s{31,s{&apos;&lt;/span&gt;world,&lt;span class=&quot;code-quote&quot;&gt;&apos;anyone}}},1  response:: &apos;&lt;/span&gt;/consumers/stratioStreaming/ids/stratioStreaming_ajn-stratio-1414658065894-94786a0e 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&amp;gt; Changing spark.broadcast.compress false&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Reading broadcast variable 0 took 0.240869283 s
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG kafka.KafkaInputDStream - Cleared 1 RDDs that were older than 1414657342000 ms: 1414657342000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG kafka.KafkaInputDStream - Cleared 1 RDDs that were older than 1414657342000 ms: 1414657342000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG streaming.DStreamGraph - Cleared old metadata &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414657344000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-13 DEBUG storage.BlockManagerSlaveActor - removing RDD 3
Executor task launch worker-1 DEBUG storage.BlockManager - Getting local block broadcast_1
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.MappedDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG dstream.FilteredDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.FilteredDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-13 INFO  storage.BlockManager - Removing RDD 3
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManagerSlaveActor - [actor] handled message (134.08408 ms) RemoveRdd(3) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$f]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManagerSlaveActor - [actor] received message RemoveRdd(2) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$i]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG storage.BlockManagerSlaveActor - removing RDD 2
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 INFO  storage.BlockManager - Removing RDD 2
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManagerSlaveActor - [actor] handled message (0.050955 ms) RemoveRdd(2) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$i]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManagerSlaveActor - [actor] received message RemoveRdd(1) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$j]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG storage.BlockManagerSlaveActor - removing RDD 1
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 INFO  storage.BlockManager - Removing RDD 1
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManagerSlaveActor - [actor] handled message (0.037738 ms) RemoveRdd(1) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$j]
&lt;/span&gt;Executor task launch worker-0 ERROR executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
java.io.EOFException
	at java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2325)
	at java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
	at java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
	at java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
	at org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
	at org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
	at org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:235)
	at org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG storage.BlockManagerSlaveActor - Done removing RDD 1, response is 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManagerSlaveActor - Done removing RDD 2, response is 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG storage.BlockManagerSlaveActor - Done removing RDD 3, response is 0
Executor task launch worker-1 DEBUG storage.BlockManager - Level &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block broadcast_1 is StorageLevel(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 1)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG dstream.FilteredDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.MappedDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.FilteredDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG streaming.DStreamGraph - Generated 4 jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414657344000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  scheduler.JobScheduler - Added jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414657344000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.JobGenerator - Got event DoCheckpoint(1414657344000 ms)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG storage.BlockManagerSlaveActor - Sent response: 0 to Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$j]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManagerSlaveActor - Sent response: 0 to Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$i]
&lt;/span&gt;Executor task launch worker-1 DEBUG storage.BlockManager - Getting block broadcast_1 from memory
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG storage.BlockManagerSlaveActor - Sent response: 0 to Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$f]
&lt;/span&gt;Executor task launch worker-0 DEBUG storage.BlockManager - Getting local block broadcast_0
Executor task launch worker-0 DEBUG storage.BlockManager - Level &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block broadcast_0 is StorageLevel(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 1)
Executor task launch worker-0 DEBUG storage.BlockManager - Getting block broadcast_0 from memory
Executor task launch worker-0 DEBUG executor.Executor - Task 0&apos;s epoch is 0
Executor task launch worker-1 DEBUG executor.Executor - Task 1&apos;s epoch is 0
Executor task launch worker-0 DEBUG storage.BlockManager - Getting local block broadcast_0
Executor task launch worker-0 DEBUG storage.BlockManager - Block broadcast_0 not registered locally
Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Started reading broadcast variable 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.MappedDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.FilteredDStream - Time 1414657344000 ms is valid
Executor task launch worker-0 INFO  broadcast.TorrentBroadcast - Reading broadcast variable 0 took 7.0321E-5 s
Executor task launch worker-0 ERROR executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
java.io.EOFException
	at java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2325)
	at java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
	at java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
	at java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
	at org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
	at org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
	at org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
	at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:235)
	at org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2066 cap=2066]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2066 cap=2066]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0, runningTasks: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0, runningTasks: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG local.LocalActor - [actor] handled message (1.681797 ms) StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2066 cap=2066]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG local.LocalActor - [actor] handled message (0.688875 ms) StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=2066 cap=2066]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.MappedDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.FilteredDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG spark.HeartbeatReceiver - [actor] received message Heartbeat(localhost,[Lscala.Tuple2;@1a94802,BlockManagerId(&amp;lt;driver&amp;gt;, ajn-stratio.local, 53377, 0)) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$c]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  receiver.ReceiverSupervisorImpl - Registered receiver 0
Executor task launch worker-0 INFO  util.RecurringTimer - Started timer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; BlockGenerator at time 1414657344800
Executor task launch worker-0 INFO  receiver.BlockGenerator - Started BlockGenerator
Executor task launch worker-0 INFO  receiver.ReceiverSupervisorImpl - Starting receiver
&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-87 INFO  receiver.BlockGenerator - Started block pushing thread
Result resolver thread-0 WARN  scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.io.EOFException: 
        java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2325)
        java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
        java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
        java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
        org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
        org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
        org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
        org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:235)
        org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
        sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        java.lang.reflect.Method.invoke(Method.java:606)
        java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Result resolver thread-0 WARN  scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.io.EOFException: 
        java.io.ObjectInputStream$PeekInputStream.readFully(ObjectInputStream.java:2325)
        java.io.ObjectInputStream$BlockDataInputStream.readShort(ObjectInputStream.java:2794)
        java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:801)
        java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
        org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
        org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
        org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
        org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:235)
        org.apache.spark.broadcast.TorrentBroadcast.readObject(TorrentBroadcast.scala:169)
        sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        java.lang.reflect.Method.invoke(Method.java:606)
        java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Executor task launch worker-0 INFO  kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: stratioStreaming
Executor task launch worker-0 INFO  kafka.KafkaReceiver - Connecting to Zookeeper: node.stratio.com:2181
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.MappedDStream - Time 1414657344000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 DEBUG dstream.FilteredDStream - Time 1414657344000 ms is valid
Result resolver thread-0 ERROR scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
Result resolver thread-0 ERROR scheduler.TaskSetManager - Task 0 in stage 0.0 failed 1 times; aborting job
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  scheduler.ReceiverTracker - Registered receiver &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; stream 0 from akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver
&lt;/span&gt;Result resolver thread-0 INFO  scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
Result resolver thread-0 INFO  scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG storage.BlockManagerMasterActor - [actor] received message BlockManagerHeartbeat(BlockManagerId(&amp;lt;driver&amp;gt;, ajn-stratio.local, 53377, 0)) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$d]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG storage.BlockManagerMasterActor - [actor] handled message (0.197908 ms) BlockManagerHeartbeat(BlockManagerId(&amp;lt;driver&amp;gt;, ajn-stratio.local, 53377, 0)) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$d]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG spark.HeartbeatReceiver - [actor] handled message (169.804965 ms) Heartbeat(localhost,[Lscala.Tuple2;@1a94802,BlockManagerId(&amp;lt;driver&amp;gt;, ajn-stratio.local, 53377, 0)) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/temp/$c]&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&amp;gt; Changing from TorrentBroadcast to HTTPBroadcast (&quot;spark.broadcast.factory&quot;, &quot;org.apache.spark.broadcast.HttpBroadcastFactory&quot;).&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  scheduler.DAGScheduler - Missing parents: List()
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.DAGScheduler - submitStage(Stage 1)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.DAGScheduler - missing: List()
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  scheduler.DAGScheduler - Submitting Stage 1 (FilteredRDD[6] at filter at FilteredDStream.scala:35), which has no missing parents
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.DAGScheduler - submitMissingTasks(Stage 1)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.MappedDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.FilteredDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.MappedDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.FilteredDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.MappedDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.FilteredDStream - Time 1414657758000 ms is valid
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Reading reply sessionid:0x1496007e6710006, packet:: clientPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; serverPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; finished:&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; header:: 7,4  replyHeader:: 7,41,0  request:: &apos;/consumers/stratioStreaming/ids/stratioStreaming_ajn-stratio-1414657757842-d7a2ca15,F  response:: #7b2276657273696f6e223a312c22737562736372697074696f6e223a7b227374726174696f5f73747265616d696e675f7265717565737473223a317d2c227061747465726e223a22737461746963222c2274696d657374616d70223a2231343134363537373538303535227d,s{41,41,1414657758409,1414657758409,0,0,0,92710854385008646,108,0,41} 
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.MappedDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.FilteredDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.MappedDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.FilteredDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.MappedDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.FilteredDStream - Time 1414657758000 ms is valid
qtp1571833412-35 DEBUG http.HttpParser - filled 167/167
RecurringTimer - BlockGenerator DEBUG util.RecurringTimer - Callback &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; BlockGenerator called at time 1414657758400
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.MappedDStream - Time 1414657758000 ms is valid
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG dstream.FilteredDStream - Time 1414657758000 ms is valid
qtp1571833412-35 - /broadcast_0 DEBUG server.Server - REQUEST /broadcast_0 on BlockingHttpConnection@7cbd5b8f,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=1
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG streaming.DStreamGraph - Generated 14 jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414657758000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 INFO  scheduler.JobScheduler - Added jobs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; time 1414657758000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  scheduler.JobScheduler - Starting job streaming job 1414657758000 ms.0 from job set of time 1414657758000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 DEBUG scheduler.JobGenerator - Got event DoCheckpoint(1414657758000 ms)
qtp1571833412-35 - /broadcast_0 DEBUG server.Server - RESPONSE /broadcast_0  404 handled=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
pool-7-thread-1 INFO  spark.SparkContext - Starting job: collect at ActionBaseFunction.java:65
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Reading reply sessionid:0x1496007e6710006, packet:: clientPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; serverPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; finished:&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; header:: 8,8  replyHeader:: 8,41,0  request:: &lt;span class=&quot;code-quote&quot;&gt;&apos;/consumers/stratioStreaming/ids,T  response:: v{&apos;&lt;/span&gt;stratioStreaming_ajn-stratio-1414657757842-d7a2ca15} 
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Reading reply sessionid:0x1496007e6710006, packet:: clientPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; serverPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; finished:&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; header:: 9,4  replyHeader:: 9,41,0  request:: &apos;/consumers/stratioStreaming/ids/stratioStreaming_ajn-stratio-1414657757842-d7a2ca15,F  response:: #7b2276657273696f6e223a312c22737562736372697074696f6e223a7b227374726174696f5f73747265616d696e675f7265717565737473223a317d2c227061747465726e223a22737461746963222c2274696d657374616d70223a2231343134363537373538303535227d,s{41,41,1414657758409,1414657758409,0,0,0,92710854385008646,108,0,41} 
pool-7-thread-1 INFO  spark.SparkContext - Job finished: collect at ActionBaseFunction.java:65, took 3.9409E-5 s
Executor task launch worker-0 DEBUG storage.BlockManager - Getting local block broadcast_0
Executor task launch worker-0 DEBUG storage.BlockManager - Level &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block broadcast_0 is StorageLevel(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 1)
Executor task launch worker-0 DEBUG storage.BlockManager - Getting block broadcast_0 from memory
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 INFO  scheduler.JobScheduler - Finished job streaming job 1414657758000 ms.0 from job set of time 1414657758000 ms
Executor task launch worker-0 INFO  storage.BlockManager - Found block broadcast_0 locally
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 INFO  scheduler.JobScheduler - Starting job streaming job 1414657758000 ms.1 from job set of time 1414657758000 ms
Executor task launch worker-0 DEBUG executor.Executor - Task 0&apos;s epoch is 0
Executor task launch worker-0 ERROR executor.Executor - Exception in task 0.0 in stage 0.0 (TID 0)
java.io.FileNotFoundException: http:&lt;span class=&quot;code-comment&quot;&gt;//172.17.42.1:34477/broadcast_0
&lt;/span&gt;	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1624)
	at org.apache.spark.broadcast.HttpBroadcast$.org$apache$spark$broadcast$HttpBroadcast$$read(HttpBroadcast.scala:197)
	at org.apache.spark.broadcast.HttpBroadcast.readObject(HttpBroadcast.scala:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
pool-7-thread-1 INFO  spark.SparkContext - Starting job: collect at ActionBaseFunction.java:65
pool-7-thread-1 INFO  spark.SparkContext - Job finished: collect at ActionBaseFunction.java:65, took 3.1765E-5 s
Executor task launch worker-0 INFO  util.RecurringTimer - Started timer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; BlockGenerator at time 1414657758600
Executor task launch worker-0 INFO  receiver.BlockGenerator - Started BlockGenerator
Executor task launch worker-0 INFO  receiver.ReceiverSupervisorImpl - Starting receiver
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  storage.MemoryStore - ensureFreeSpace(3136) called with curMem=1216, maxMem=991470551
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 INFO  scheduler.JobScheduler - Finished job streaming job 1414657758000 ms.1 from job set of time 1414657758000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 INFO  scheduler.JobScheduler - Starting job streaming job 1414657758000 ms.2 from job set of time 1414657758000 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG local.LocalActor - [actor] received message StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=1868 cap=1868]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  storage.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.1 KB, free 945.5 MB)
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Reading reply sessionid:0x1496007e6710006, packet:: clientPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; serverPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; finished:&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; header:: 10,8  replyHeader:: 10,41,0  request:: &lt;span class=&quot;code-quote&quot;&gt;&apos;/brokers/ids,F  response:: v{&apos;&lt;/span&gt;7} 
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManager - Put block broadcast_1 locally took  7 ms
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG storage.BlockManager - Putting block broadcast_1 without replication took  7 ms
pool-7-thread-1 INFO  spark.SparkContext - Starting job: collect at ActionBaseFunction.java:65
Executor task launch worker-0 INFO  kafka.KafkaReceiver - Starting Kafka Consumer Stream with group: stratioStreaming
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  receiver.ReceiverSupervisorImpl - Registered receiver 0
Executor task launch worker-0 INFO  kafka.KafkaReceiver - Connecting to Zookeeper: node.stratio.com:2181
Executor task launch worker-0 INFO  utils.VerifiableProperties - Verifying properties
Executor task launch worker-0 INFO  utils.VerifiableProperties - Property group.id is overridden to stratioStreaming
Executor task launch worker-0 INFO  utils.VerifiableProperties - Property zookeeper.connect is overridden to node.stratio.com:2181
Executor task launch worker-0 INFO  utils.VerifiableProperties - Property zookeeper.connection.timeout.ms is overridden to 10000
Executor task launch worker-0 INFO  consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414657758445-7b49bb3b], Connecting to zookeeper instance at node.stratio.com:2181
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-4 INFO  scheduler.ReceiverTracker - Registered receiver &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; stream 0 from akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver
&lt;/span&gt;&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-99 INFO  receiver.BlockGenerator - Started block pushing thread
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  scheduler.DAGScheduler - Submitting 2 missing tasks from Stage 1 (FilteredRDD[6] at filter at FilteredDStream.scala:35)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.DAGScheduler - New pending tasks: Set(ResultTask(1, 1), ResultTask(1, 0))
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 INFO  scheduler.TaskSchedulerImpl - Adding task set 1.0 with 2 tasks
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.TaskSetManager - Epoch &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; TaskSet 1.0: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-2 DEBUG scheduler.TaskSetManager - Valid locality levels &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; TaskSet 1.0: NO_PREF, ANY
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Reading reply sessionid:0x1496007e6710006, packet:: clientPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; serverPath:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; finished:&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; header:: 11,4  replyHeader:: 11,41,0  request:: &apos;/brokers/ids/7,F  response:: #7b226a6d785f706f7274223a393939392c2274696d657374616d70223a2231343134363535333735373234222c22686f7374223a226e6f64652e7374726174696f2e636f6d222c2276657273696f6e223a312c22706f7274223a393039327d,s{18,18,1414655375792,1414655375792,0,0,0,92710854385008640,95,0,18} 
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG local.LocalActor - [actor] received message ReviveOffers from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;pool-7-thread-1 INFO  spark.SparkContext - Job finished: collect at ActionBaseFunction.java:65, took 3.0385E-5 s
Executor task launch worker-0 DEBUG zkclient.ZkConnection - Creating &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ZookKeeper instance to connect to node.stratio.com:2181.
Executor task launch worker-0 INFO  zookeeper.ZooKeeper - Initiating client connection, connectString=node.stratio.com:2181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@2fdc4517
ZkClient-EventThread-189-node.stratio.com:2181 INFO  zkclient.ZkEventThread - Starting ZkClient event thread.
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0, runningTasks: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0, runningTasks: 1
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-5 DEBUG local.LocalActor - [actor] handled message (4.883443 ms) StatusUpdate(0,FAILED,java.nio.HeapByteBuffer[pos=0 lim=1868 cap=1868]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_1, runningTasks: 0
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 INFO  scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, PROCESS_LOCAL, 880 bytes)
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Opening socket connection to server node.stratio.com/172.19.0.96:2181. Will not attempt to authenticate using SASL (unknown error)
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Socket connection established to node.stratio.com/172.19.0.96:2181, initiating session
Executor task launch worker-0-SendThread(node.stratio.com:2181) DEBUG zookeeper.ClientCnxn - Session establishment request sent on node.stratio.com/172.19.0.96:2181
Executor task launch worker-0-SendThread(node.stratio.com:2181) INFO  zookeeper.ClientCnxn - Session establishment complete on server node.stratio.com/172.19.0.96:2181, sessionid = 0x1496007e6710007, negotiated timeout = 6000
Executor task launch worker-0 DEBUG zkclient.ZkClient - Awaiting connection to Zookeeper server
Executor task launch worker-0 DEBUG zkclient.ZkClient - Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; keeper state SyncConnected
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 INFO  scheduler.JobScheduler - Finished job streaming job 1414657758000 ms.2 from job set of time 1414657758000 ms
Executor task launch worker-0-EventThread DEBUG zkclient.ZkClient - Received event: WatchedEvent state:SyncConnected type:None path:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Executor task launch worker-0-EventThread INFO  zkclient.ZkClient - zookeeper state changed (SyncConnected)
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-12 INFO  scheduler.JobScheduler - Starting job streaming job 1414657758000 ms.3 from job set of time 1414657758000 ms
Executor task launch worker-0 DEBUG zkclient.ZkClient - State is SyncConnected
Result resolver thread-0 WARN  scheduler.TaskSetManager - Lost task 0.0 in stage 0.0 (TID 0, localhost): java.io.FileNotFoundException: http:&lt;span class=&quot;code-comment&quot;&gt;//172.17.42.1:34477/broadcast_0
&lt;/span&gt;        sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1624)
        org.apache.spark.broadcast.HttpBroadcast$.org$apache$spark$broadcast$HttpBroadcast$$read(HttpBroadcast.scala:197)
        org.apache.spark.broadcast.HttpBroadcast.readObject(HttpBroadcast.scala:89)
        sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        java.lang.reflect.Method.invoke(Method.java:606)
        java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1017)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1893)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1990)
        java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1915)
        java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1798)
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1350)
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)
        org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:87)
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:159)
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Executor task launch worker-0-EventThread DEBUG zkclient.ZkClient - Leaving process event
Executor task launch worker-0 DEBUG utils.KafkaScheduler - Initializing task scheduler.
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG local.LocalActor - [actor] handled message (7.610459 ms) ReviveOffers from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;Executor task launch worker-0 INFO  consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414657758445-7b49bb3b], starting auto committer every 60000 ms
Executor task launch worker-1 INFO  executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
Executor task launch worker-0 DEBUG utils.KafkaScheduler - Scheduling task kafka-consumer-autocommit with initial delay 60000 ms and period 60000 ms.
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG local.LocalActor - [actor] received message StatusUpdate(1,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]
&lt;/span&gt;Executor task launch worker-0 INFO  kafka.KafkaReceiver - Connected to node.stratio.com:2181
Executor task launch worker-0 DEBUG consumer.ZookeeperConsumerConnector - [stratioStreaming_ajn-stratio-1414657758445-7b49bb3b], entering consume 
sparkDriver-akka.actor.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-dispatcher-3 DEBUG local.LocalActor - [actor] handled message (0.07141 ms) StatusUpdate(1,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]) from Actor[akka:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver/deadLetters]&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but with no luck for the moment.&lt;/p&gt;
</description>
                <environment></environment>
        <key id="12751361">SPARK-4133</key>
            <summary>PARSING_ERROR(2) when upgrading issues from 1.0.2 to 1.1.0</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ajnavarro">Antonio Jesus Navarro</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Oct 2014 11:53:31 +0000</created>
                <updated>Thu, 5 Feb 2015 18:56:42 +0000</updated>
                            <resolved>Thu, 5 Feb 2015 18:56:42 +0000</resolved>
                                    <version>1.1.0</version>
                                                    <component>DStreams</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="14188284" author="ajnavarro" created="Wed, 29 Oct 2014 11:58:36 +0000"  >&lt;p&gt;Existing Spark Streaming app can not be upgraded from 1.0.2 to 1.1.0&lt;/p&gt;</comment>
                            <comment id="14188665" author="joshrosen" created="Wed, 29 Oct 2014 17:48:35 +0000"  >&lt;p&gt;Since you mentioned that you see a similar issue when using HTTPBroadcast, could you post the stacktrace from that case, too?  Similarly, can you post the stacktrace when broadcast compression is disabled?&lt;/p&gt;</comment>
                            <comment id="14188815" author="joshrosen" created="Wed, 29 Oct 2014 19:15:10 +0000"  >&lt;p&gt;Also, can you paste more of the log leading up to the error?  It would be helpful to see any other log messages from broadcast, such as messages about it fetching pieces / blocks.&lt;/p&gt;</comment>
                            <comment id="14189014" author="joshrosen" created="Wed, 29 Oct 2014 21:20:29 +0000"  >&lt;p&gt;Also, could you enable debug logging and share the executor logs?  If you&apos;re able to reliably reproduce this bug, please email me at joshrosen@databricks.com and I&apos;d be glad to hop on Skype to help you configure logging, etc.&lt;/p&gt;</comment>
                            <comment id="14189821" author="ajnavarro" created="Thu, 30 Oct 2014 09:01:30 +0000"  >&lt;p&gt;Hi Josh,&lt;br/&gt;
I edited the issue to add more logs.&lt;br/&gt;
Thanks.&lt;/p&gt;</comment>
                            <comment id="14195294" author="joshrosen" created="Mon, 3 Nov 2014 22:56:52 +0000"  >&lt;p&gt;Do you happen to be creating multiple running SparkContexts in the same JVM by any chance?&lt;/p&gt;</comment>
                            <comment id="14195859" author="ajnavarro" created="Tue, 4 Nov 2014 08:09:44 +0000"  >&lt;p&gt;Yes, We are creating one local SparkContext for each SparkStreamingContext.&lt;/p&gt;</comment>
                            <comment id="14196283" author="vitalii.migov@gmail.com" created="Tue, 4 Nov 2014 16:04:18 +0000"  >&lt;p&gt;The same issue observed in the similar spark streaming application.&lt;br/&gt;
Note: Broadcast factory changed to the HttpBroadcastFactory as suggested, so there is &lt;br/&gt;
 &quot;java.io.FileNotFoundException: &lt;a href=&quot;http://10.8.0.22:44907/broadcast_0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://10.8.0.22:44907/broadcast_0&lt;/a&gt;&quot; exception instead of the &quot;Snappy java.io.IOException: PARSING_ERROR(2)&quot;&lt;/p&gt;

&lt;p&gt;Full logs attached to the issue: spark_ex.logs&lt;/p&gt;

&lt;p&gt;I think that something wrong with the handing of the &quot;broadcast_0&quot; in the BlockManager:&lt;br/&gt;
14/11/04 17:20:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1216.0 B, free 983.1 MB)&lt;br/&gt;
14/11/04 17:20:39 DEBUG BlockManager: Put block broadcast_0 locally took  84 ms&lt;br/&gt;
14/11/04 17:20:39 DEBUG BlockManager: Putting block broadcast_0 without replication took  86 ms&lt;br/&gt;
14/11/04 17:20:39 DEBUG BlockManager: Getting local block broadcast_0&lt;br/&gt;
14/11/04 17:20:39 DEBUG BlockManager: Level for block broadcast_0 is StorageLevel(true, true, false, true, 1)&lt;br/&gt;
14/11/04 17:20:39 DEBUG BlockManager: Getting block broadcast_0 from memory&lt;br/&gt;
14/11/04 17:20:39 INFO BlockManager: Found block broadcast_0 locally&lt;br/&gt;
14/11/04 17:20:57 WARN BlockManager: Block broadcast_0 already exists on this machine; not re-adding it&lt;br/&gt;
14/11/04 17:20:57 DEBUG BlockManager: Getting local block broadcast_0&lt;br/&gt;
14/11/04 17:20:57 DEBUG BlockManager: Block broadcast_0 not registered locally&lt;br/&gt;
14/11/04 17:20:57 DEBUG BlockManager: Getting remote block broadcast_0&lt;br/&gt;
14/11/04 17:20:57 DEBUG BlockManagerMasterActor: &lt;span class=&quot;error&quot;&gt;&amp;#91;actor&amp;#93;&lt;/span&gt; received message GetLocations(broadcast_0) from Actor&lt;span class=&quot;error&quot;&gt;&amp;#91;akka://sparkDriver/temp/$l&amp;#93;&lt;/span&gt;&lt;br/&gt;
14/11/04 17:20:57 DEBUG BlockManager: Block broadcast_0 not found&lt;br/&gt;
14/11/04 17:20:57 DEBUG BlockManagerMasterActor: &lt;span class=&quot;error&quot;&gt;&amp;#91;actor&amp;#93;&lt;/span&gt; handled message (0.117676 ms) GetLocations(broadcast_0) from Actor&lt;span class=&quot;error&quot;&gt;&amp;#91;akka://sparkDriver/temp/$l&amp;#93;&lt;/span&gt;&lt;br/&gt;
14/11/04 17:20:57 INFO HttpBroadcast: Started reading broadcast variable 0&lt;br/&gt;
14/11/04 17:20:57 DEBUG HttpBroadcast: broadcast read server: &lt;a href=&quot;http://10.8.0.22:44907&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://10.8.0.22:44907&lt;/a&gt; id: broadcast-0&lt;br/&gt;
14/11/04 17:20:57 DEBUG HttpBroadcast: broadcast not using security&lt;br/&gt;
14/11/04 17:20:57 DEBUG RecurringTimer: Callback for BlockGenerator called at time 1415114457200&lt;br/&gt;
14/11/04 17:20:57 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)&lt;br/&gt;
java.io.FileNotFoundException: &lt;a href=&quot;http://10.8.0.22:44907/broadcast_0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://10.8.0.22:44907/broadcast_0&lt;/a&gt;&lt;/p&gt;

</comment>
                            <comment id="14196386" author="vitalii.migov@gmail.com" created="Tue, 4 Nov 2014 17:22:33 +0000"  >&lt;p&gt;After additional investigation of this issue i have found that SparkContext mistakenly created by twice.&lt;/p&gt;

&lt;p&gt; This code will lead to the double creation of the SparkContext and as are result of this - lead to the described error.&lt;br/&gt;
  val sparkConf = sparkCtxBuilder.createSparkConf()&lt;br/&gt;
  val sparkContext = new SparkContext(sparkConf)&lt;br/&gt;
  val ssc =  new StreamingContext(sparkConf, Seconds(5))  &amp;lt;!---  sparkConf passed&lt;/p&gt;

&lt;p&gt; This is corrected initialization sequence. After changing initial code to this - error is gone:&lt;br/&gt;
  val sparkConf = sparkCtxBuilder.createSparkConf()&lt;br/&gt;
  val sparkContext = new SparkContext(sparkConf)&lt;br/&gt;
  val ssc =  new StreamingContext(sparkContext, Seconds(5)) &amp;lt;!-- sparkContext passed&lt;/p&gt;</comment>
                            <comment id="14196455" author="joshrosen" created="Tue, 4 Nov 2014 17:56:33 +0000"  >&lt;p&gt;Spark doesn&apos;t support multiple active SparkContexts in the same JVM, although this isn&apos;t well-documented and there&apos;s no error-checking for this (PySpark has checks for this, though).  This isn&apos;t to say that we can&apos;t / won&apos;t eventually support multiple contexts per JVM (see &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2243&quot; title=&quot;Support multiple SparkContexts in the same JVM&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2243&quot;&gt;&lt;del&gt;SPARK-2243&lt;/del&gt;&lt;/a&gt;), but that could be somewhat difficult in the very short term because there may be several baked-in assumptions that we&apos;ll have to address (the (effectively) global SparkEnv, for example).  In both this issue and the issue reported in a comment on &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4080&quot; title=&quot;&amp;quot;IOException: unexpected exception type&amp;quot; while deserializing tasks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-4080&quot;&gt;&lt;del&gt;SPARK-4080&lt;/del&gt;&lt;/a&gt;, I think the symptoms are being caused by the two SparkContexts&apos; block / broadcast managers becoming mixed up so that executors belonging to one SparkContext are somehow fetching blocks added by another SparkContext (or are deleting each others&apos; blocks; see &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-3148&quot; title=&quot;Update global variables of HttpBroadcast so that multiple SparkContexts can coexist&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-3148&quot;&gt;&lt;del&gt;SPARK-3148&lt;/del&gt;&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4180&quot; title=&quot;SparkContext constructor should throw exception if another SparkContext is already running&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-4180&quot;&gt;&lt;del&gt;SPARK-4180&lt;/del&gt;&lt;/a&gt; will add proper error-detection to detect when multiple contexts have been created and to help debug where this is happening (e.g. by printing the callsite that created the currently active context).&lt;/p&gt;</comment>
                            <comment id="14197655" author="vitalii.migov@gmail.com" created="Wed, 5 Nov 2014 06:06:08 +0000"  >&lt;p&gt;The problem is that if we mistakenly pass SparkConf to the  StreamingContext instead of the previously created SparkContext then StreamingContext  will silently create new ( second ) SparkContext . This error is hard to find and it can lead to the spontaneous errors related to the block / broadcast managers which in turn can manifest itself by cryptic exceptions like : &quot;java.io.IOException: PARSING_ERROR(2)&quot;.&lt;br/&gt;
This can be easily prevented if StreamingContext will require to pass SparkContext as argument to constructor and will not try to create new SparkContext if SparkConf   passed.&lt;/p&gt;</comment>
                            <comment id="14200762" author="joshrosen" created="Thu, 6 Nov 2014 19:45:05 +0000"  >&lt;p&gt;We can&apos;t remove that StreamingContext constructor since we don&apos;t want to break binary compatibility, but we can add a warning / raise an error.  I&apos;m working on a patch for this now.&lt;/p&gt;</comment>
                            <comment id="14224539" author="tdas" created="Tue, 25 Nov 2014 13:39:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt; Any more comments regarding this error based on patches that have gone in?&lt;/p&gt;</comment>
                            <comment id="14254967" author="derrickburns" created="Sat, 20 Dec 2014 22:04:59 +0000"  >&lt;p&gt;I am getting a similar error with Spark 1.1.1. I am not creating a second SparkContext.&lt;/p&gt;

&lt;p&gt;2014-12-20 20:04:16,233 WARN  &lt;span class=&quot;error&quot;&gt;&amp;#91;task-result-getter-2&amp;#93;&lt;/span&gt; scheduler.TaskSetManager (Logging.scala:logWarning(71)) - Lost task 30.0 in stage 242.0 (TID 65228, ip-10-215-133-219.us-west-2.compute.internal): java.io.IOException: failed to uncompress the chunk: PARSING_ERROR(2)&lt;br/&gt;
        org.xerial.snappy.SnappyInputStream.hasNextChunk(SnappyInputStream.java:361)&lt;br/&gt;
        org.xerial.snappy.SnappyInputStream.read(SnappyInputStream.java:383)&lt;br/&gt;
        java.io.ObjectInputStream$PeekInputStream.peek(ObjectInputStream.java:2293)&lt;br/&gt;
        java.io.ObjectInputStream$BlockDataInputStream.peek(ObjectInputStream.java:2586)&lt;br/&gt;
        java.io.ObjectInputStream$BlockDataInputStream.peekByte(ObjectInputStream.java:2596)&lt;br/&gt;
        java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1318)&lt;br/&gt;
        java.io.ObjectInputStream.readObject(ObjectInputStream.java:370)&lt;br/&gt;
        org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:62)&lt;br/&gt;
        org.apache.spark.serializer.DeserializationStream$$anon$1.getNext(Serializer.scala:133)&lt;br/&gt;
        org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:71)&lt;br/&gt;
        org.apache.spark.storage.BlockManager$LazyProxyIterator$1.hasNext(BlockManager.scala:1171)&lt;br/&gt;
        scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)&lt;br/&gt;
        org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)&lt;br/&gt;
        org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)&lt;br/&gt;
        org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:89)&lt;br/&gt;
        org.apache.spark.shuffle.hash.HashShuffleReader.read(HashShuffleReader.scala:46)&lt;br/&gt;
        org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:92)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:229)&lt;br/&gt;
        org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)&lt;br/&gt;
        org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)&lt;br/&gt;
        org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:61)&lt;br/&gt;
        org.apache.spark.rdd.RDD.iterator(RDD.scala:227)&lt;br/&gt;
        org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)&lt;br/&gt;
        org.apache.spark.scheduler.Task.run(Task.scala:54)&lt;br/&gt;
        org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)&lt;br/&gt;
        java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
        java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
        java.lang.Thread.run(Thread.java:745)&lt;/p&gt;</comment>
                            <comment id="14258545" author="tdas" created="Wed, 24 Dec 2014 21:34:41 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=derrickburns&quot; class=&quot;user-hover&quot; rel=&quot;derrickburns&quot;&gt;derrickburns&lt;/a&gt; Are you sure you are not creating multiple Spark Contexts? See previous posts on this JIRA to find how you might be accidentally creating to SparkContexts.&lt;/p&gt;</comment>
                            <comment id="14297404" author="tdas" created="Thu, 29 Jan 2015 19:27:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=derrickburns&quot; class=&quot;user-hover&quot; rel=&quot;derrickburns&quot;&gt;derrickburns&lt;/a&gt; Any thoughts? If there arent any more thoughts, I am going to close this JIRA. As of now, I am going to remove the blocker priority. &lt;/p&gt;
</comment>
                            <comment id="14297919" author="derrickburns" created="Thu, 29 Jan 2015 23:47:41 +0000"  >&lt;p&gt;I worked around it, so feel free....&lt;/p&gt;

&lt;p&gt;On Thu, Jan 29, 2015 at 11:28 AM, Tathagata Das (JIRA) &amp;lt;jira@apache.org&amp;gt;&lt;/p&gt;
</comment>
                            <comment id="14307766" author="joshrosen" created="Thu, 5 Feb 2015 18:56:42 +0000"  >&lt;p&gt;I&apos;m going to close this issue for now, since I think this was caused by multiple SparkContexts and not a Spark bug, per-se.  Please comment here or open a new issue if you see &lt;tt&gt;PARSING_ERROR(2)&lt;/tt&gt; on newer versions of Spark without creating multiple active SparkContexts.&lt;/p&gt;

&lt;p&gt;Note that &lt;tt&gt;FAILED_TO_UNCOMPRESS(5)&lt;/tt&gt; is a distinct issue, which is being addressed at &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4105&quot; title=&quot;FAILED_TO_UNCOMPRESS(5) errors when fetching shuffle data with sort-based shuffle&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-4105&quot;&gt;&lt;del&gt;SPARK-4105&lt;/del&gt;&lt;/a&gt;.  That issue is still open because we&apos;ve seen reports of it in newer versions.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12758293">SPARK-4641</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12748414">SPARK-3958</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12743065">SPARK-3630</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12679241" name="spark_ex.logs" size="79487" author="vitalii.migov@gmail.com" created="Tue, 4 Nov 2014 16:03:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 41 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i21pr3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>