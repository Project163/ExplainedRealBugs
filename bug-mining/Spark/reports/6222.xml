<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:32 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26403] DataFrame pivot using array column fails with &quot;Unsupported literal type class&quot;</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26403</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Doing a pivot (using the &lt;tt&gt;pivot(pivotColumn: Column)&lt;/tt&gt; overload) on a column containing arrays results in a runtime error:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt;
scala&amp;gt; val df = Seq((1, Seq(&quot;a&quot;, &quot;x&quot;), 2), (1, Seq(&quot;b&quot;), 3), (2, Seq(&quot;a&quot;, &quot;x&quot;), 10), (3, Seq(), 100)).toDF(&quot;x&quot;, &quot;s&quot;, &quot;y&quot;)
df: org.apache.spark.sql.DataFrame = [x: int, s: array&amp;lt;string&amp;gt; ... 1 more field]

scala&amp;gt; df.show
+---+------+---+
|  x|     s|  y|
+---+------+---+
|  1|[a, x]|  2|
|  1|   [b]|  3|
|  2|[a, x]| 10|
|  3|    []|100|
+---+------+---+


scala&amp;gt; df.groupBy(&quot;x&quot;).pivot(&quot;s&quot;).agg(collect_list($&quot;y&quot;)).show
java.lang.RuntimeException: Unsupported literal type class scala.collection.mutable.WrappedArray$ofRef WrappedArray()
  at org.apache.spark.sql.catalyst.expressions.Literal$.apply(literals.scala:78)
  at org.apache.spark.sql.RelationalGroupedDataset$$anonfun$pivot$1.apply(RelationalGroupedDataset.scala:419)
  at org.apache.spark.sql.RelationalGroupedDataset$$anonfun$pivot$1.apply(RelationalGroupedDataset.scala:419)
  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
  at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
  at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35)
  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
  at scala.collection.AbstractTraversable.map(Traversable.scala:104)
  at org.apache.spark.sql.RelationalGroupedDataset.pivot(RelationalGroupedDataset.scala:419)
  at org.apache.spark.sql.RelationalGroupedDataset.pivot(RelationalGroupedDataset.scala:397)
  at org.apache.spark.sql.RelationalGroupedDataset.pivot(RelationalGroupedDataset.scala:317)
  ... 49 elided
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, this doesn&apos;t seem to be a fundamental limitation with &lt;tt&gt;pivot&lt;/tt&gt;, as it works fine using the &lt;tt&gt;pivot(pivotColumn: Column, values: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Any&amp;#93;&lt;/span&gt;)&lt;/tt&gt; overload, as long as the arrays are mapped to the &lt;tt&gt;Array&lt;/tt&gt; type:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt;
scala&amp;gt; val rawValues = df.select(&quot;s&quot;).distinct.sort(&quot;s&quot;).collect
rawValues: Array[org.apache.spark.sql.Row] = Array([WrappedArray()], [WrappedArray(a, x)], [WrappedArray(b)])

scala&amp;gt; val values = rawValues.map(_.getSeq[String](0).to[Array])
values: Array[Array[String]] = Array(Array(), Array(a, x), Array(b))

scala&amp;gt; df.groupBy(&quot;x&quot;).pivot(&quot;s&quot;, values).agg(collect_list($&quot;y&quot;)).show
+---+-----+------+---+
|  x|   []|[a, x]|[b]|
+---+-----+------+---+
|  1|   []|   [2]|[3]|
|  3|[100]|    []| []|
|  2|   []|  [10]| []|
+---+-----+------+---+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It would be nice if &lt;tt&gt;pivot&lt;/tt&gt; was more resilient to Spark&apos;s own representation of array columns, and so the first version worked.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13205285">SPARK-26403</key>
            <summary>DataFrame pivot using array column fails with &quot;Unsupported literal type class&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gurwls223">Hyukjin Kwon</assignee>
                                    <reporter username="huonw">Huon Wilson</reporter>
                        <labels>
                    </labels>
                <created>Wed, 19 Dec 2018 05:39:00 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:41 +0000</updated>
                            <resolved>Thu, 3 Jan 2019 03:02:58 +0000</resolved>
                                    <version>2.4.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16724839" author="githubbot" created="Wed, 19 Dec 2018 09:43:26 +0000"  >&lt;p&gt;HyukjinKwon opened a new pull request #23349: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26403&quot; title=&quot;DataFrame pivot using array column fails with &amp;quot;Unsupported literal type class&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26403&quot;&gt;&lt;del&gt;SPARK-26403&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;SQL&amp;#93;&lt;/span&gt; Support pivoting using array column for `pivot(column)` API&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/spark/pull/23349&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23349&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What changes were proposed in this pull request?&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   This PR fixes `Literal(..: Any)` can accepts `collection.mutable.WrappedArray` in order to `pivot(Column)` can accepts array column as well.&lt;/p&gt;

&lt;p&gt;   We can unwrap the array and use it for type dispatch.&lt;/p&gt;

&lt;p&gt;   ```scala&lt;br/&gt;
   val df = Seq(&lt;br/&gt;
     (2, Seq.empty&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;),&lt;br/&gt;
     (2, Seq(&quot;a&quot;, &quot;x&quot;)),&lt;br/&gt;
     (3, Seq.empty&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;),&lt;br/&gt;
     (3, Seq(&quot;a&quot;, &quot;x&quot;))).toDF(&quot;x&quot;, &quot;s&quot;)&lt;br/&gt;
   df.groupBy(&quot;x&quot;).pivot(&quot;s&quot;).count().show()&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;   Before:&lt;/p&gt;

&lt;p&gt;   ```&lt;br/&gt;
   Unsupported literal type class scala.collection.mutable.WrappedArray$ofRef WrappedArray()&lt;br/&gt;
   java.lang.RuntimeException: Unsupported literal type class scala.collection.mutable.WrappedArray$ofRef WrappedArray()&lt;br/&gt;
   	at org.apache.spark.sql.catalyst.expressions.Literal$.apply(literals.scala:80)&lt;br/&gt;
   	at org.apache.spark.sql.RelationalGroupedDataset.$anonfun$pivot$2(RelationalGroupedDataset.scala:427)&lt;br/&gt;
   	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:237)&lt;br/&gt;
   	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)&lt;br/&gt;
   	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)&lt;br/&gt;
   	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:39)&lt;br/&gt;
   	at scala.collection.TraversableLike.map(TraversableLike.scala:237)&lt;br/&gt;
   	at scala.collection.TraversableLike.map$(TraversableLike.scala:230)&lt;br/&gt;
   	at scala.collection.AbstractTraversable.map(Traversable.scala:108)&lt;br/&gt;
   	at org.apache.spark.sql.RelationalGroupedDataset.pivot(RelationalGroupedDataset.scala:425)&lt;br/&gt;
   	at org.apache.spark.sql.RelationalGroupedDataset.pivot(RelationalGroupedDataset.scala:406)&lt;br/&gt;
   	at org.apache.spark.sql.RelationalGroupedDataset.pivot(RelationalGroupedDataset.scala:317)&lt;br/&gt;
   	at org.apache.spark.sql.DataFramePivotSuite.$anonfun$new$1(DataFramePivotSuite.scala:341)&lt;br/&gt;
   	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;   After:&lt;/p&gt;

&lt;p&gt;   ```&lt;br/&gt;
   &lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;-&lt;del&gt;&lt;ins&gt;&lt;/del&gt;-----&lt;/ins&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  x&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; []&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;a, x&amp;#93;&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;   &lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;-&lt;del&gt;&lt;ins&gt;&lt;/del&gt;-----&lt;/ins&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  3&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  2&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;     1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;   &lt;ins&gt;--&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;-&lt;del&gt;&lt;ins&gt;&lt;/del&gt;-----&lt;/ins&gt;&lt;br/&gt;
   ```&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;How was this patch tested?&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Manually tested and unittests were added.&lt;/p&gt;


&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16732608" author="gurwls223" created="Thu, 3 Jan 2019 03:02:58 +0000"  >&lt;p&gt;Issue resolved by pull request 23349&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23349&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23349&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 45 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|u0046o:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>