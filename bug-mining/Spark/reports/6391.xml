<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:04:45 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-27267] Snappy 1.1.7.1 fails when decompressing empty serialized data</title>
                <link>https://issues.apache.org/jira/browse/SPARK-27267</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I use pyspark&#160; like that&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;from pyspark.storagelevel import StorageLevel&lt;br/&gt;
df=spark.sql(&quot;select * from xzn.person&quot;)&lt;br/&gt;
df.persist(StorageLevel(False, True, False, False))&lt;br/&gt;
df.count()&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;table person is a simple table stored as orc files and some orc files is empty. When I run the query, it throw the error :&#160;&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;19/03/22 21:46:31 INFO MemoryStore:54 - Block rdd_2_1 stored as values in memory (estimated size 0.0 B, free 1662.6 MB)&lt;br/&gt;
19/03/22 21:46:31 INFO FileScanRDD:54 - Reading File path: viewfs://name/xzn.db/person/part-00011, range: 0-49, partition values: &lt;span class=&quot;error&quot;&gt;&amp;#91;empty row&amp;#93;&lt;/span&gt;&lt;br/&gt;
19/03/22 21:46:31 INFO FileScanRDD:54 - Reading File path: viewfs://name/xzn.db/person/part-00011_copy_1, range: 0-49, partition values: &lt;span class=&quot;error&quot;&gt;&amp;#91;empty row&amp;#93;&lt;/span&gt;&lt;br/&gt;
19/03/22 21:46:31 INFO FileScanRDD:54 - Reading File path: viewfs://name/xzn.db/person/part-00012, range: 0-49, partition values: &lt;span class=&quot;error&quot;&gt;&amp;#91;empty row&amp;#93;&lt;/span&gt;&lt;br/&gt;
19/03/22 21:46:31 INFO FileScanRDD:54 - Reading File path: viewfs://name/xzn.db/person/part-00012_copy_1, range: 0-49, partition values: &lt;span class=&quot;error&quot;&gt;&amp;#91;empty row&amp;#93;&lt;/span&gt;&lt;br/&gt;
19/03/22 21:46:31 INFO FileScanRDD:54 - Reading File path: viewfs://name/xzn.db/person/part-00013, range: 0-49, partition values: &lt;span class=&quot;error&quot;&gt;&amp;#91;empty row&amp;#93;&lt;/span&gt;&lt;br/&gt;
19/03/22 21:46:31 ERROR Executor:91 - Exception in task 1.0 in stage 0.0 (TID 1)&lt;br/&gt;
org.xerial.snappy.SnappyIOException: &lt;span class=&quot;error&quot;&gt;&amp;#91;EMPTY_INPUT&amp;#93;&lt;/span&gt; Cannot decompress empty stream&lt;br/&gt;
 at org.xerial.snappy.SnappyInputStream.readHeader(SnappyInputStream.java:94)&lt;br/&gt;
 at org.xerial.snappy.SnappyInputStream.&amp;lt;init&amp;gt;(SnappyInputStream.java:59)&lt;br/&gt;
 at org.apache.spark.io.SnappyCompressionCodec.compressedInputStream(CompressionCodec.scala:164)&lt;br/&gt;
 at org.apache.spark.serializer.SerializerManager.wrapForCompression(SerializerManager.scala:163)&lt;br/&gt;
 at org.apache.spark.serializer.SerializerManager.dataDeserializeStream(SerializerManager.scala:209)&lt;br/&gt;
 at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:596)&lt;br/&gt;
 at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:886)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)&lt;br/&gt;
 at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)&lt;br/&gt;
 at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)&lt;br/&gt;
 at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)&lt;br/&gt;
 at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)&lt;br/&gt;
 at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)&lt;br/&gt;
 at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)&lt;br/&gt;
 at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)&lt;br/&gt;
 at org.apache.spark.scheduler.Task.run(Task.scala:121)&lt;br/&gt;
 at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)&lt;br/&gt;
 at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)&lt;br/&gt;
 at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)&lt;br/&gt;
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;br/&gt;
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;br/&gt;
 at java.lang.Thread.run(Thread.java:748)&lt;br/&gt;
```&lt;/p&gt;

&lt;p&gt;After I search it, I find that&#160;1.1.7.x&#160; snappy-java &apos;s behavior is different from 1.1.2.x (that&#160; spark 2.0.2 use this version).&#160;SnappyOutputStream in 1.1.2.x version always writes a snappy header whether or not to write a value,&#160; but&#160;&#160;SnappyOutputStream in 1.1.7.x don&apos;t generate header if u don&apos;t write value into it, so in spark 2.4 if RDD cache a empty value, memoryStore will not cache any bytes ( no snappy header ),&#160; then it will throw the empty error.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Maybe we can change SnappyOutputStream to fix it&#160;in 1.1.7.x snappy-java, there is my&#160;SnappyOutputStream method&#160;compressInput code&#160;&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;protected void compressInput()&lt;br/&gt;
 throws IOException&lt;br/&gt;
 {&lt;br/&gt;
 // generate header &lt;br/&gt;
 if (!headerWritten) &lt;/p&gt;
{
 outputCursor = writeHeader();
 headerWritten = true;
 }

&lt;p&gt; if (inputCursor &amp;lt;= 0) &lt;/p&gt;
{
 return; // no need to dump
 }

&lt;p&gt;// if (!headerWritten) &lt;/p&gt;
{
// outputCursor = writeHeader();
// headerWritten = true;
// }

&lt;p&gt; // Compress and dump the buffer content&lt;br/&gt;
 if (!hasSufficientOutputBufferFor(inputCursor)) &lt;/p&gt;
{
 dumpOutput();
 }

&lt;p&gt; writeBlockPreemble();&lt;/p&gt;

&lt;p&gt; int compressedSize = Snappy.compress(inputBuffer, 0, inputCursor, outputBuffer, outputCursor + 4);&lt;br/&gt;
 // Write compressed data size&lt;br/&gt;
 writeInt(outputBuffer, outputCursor, compressedSize);&lt;br/&gt;
 outputCursor += 4 + compressedSize;&lt;br/&gt;
 inputCursor = 0;&lt;br/&gt;
 }&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment>&lt;p&gt;spark.rdd.compress=true&lt;/p&gt;

&lt;p&gt;spark.io.compression.codec =snappy&lt;/p&gt;

&lt;p&gt;spark 2.4 in hadoop 2.6 with hive&lt;/p&gt;</environment>
        <key id="13223720">SPARK-27267</key>
            <summary>Snappy 1.1.7.1 fails when decompressing empty serialized data</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="max2049">Max  Xie</assignee>
                                    <reporter username="max2049">Max  Xie</reporter>
                        <labels>
                    </labels>
                <created>Mon, 25 Mar 2019 09:57:59 +0000</created>
                <updated>Sun, 31 Mar 2019 02:30:06 +0000</updated>
                            <resolved>Sat, 30 Mar 2019 05:01:29 +0000</resolved>
                                    <version>2.4.0</version>
                                    <fixVersion>2.4.2</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Block Manager</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16801311" author="max2049" created="Tue, 26 Mar 2019 01:54:13 +0000"  >&lt;p&gt;I has committed this fix to snappy-java (&lt;a href=&quot;https://github.com/xerial/snappy-java)&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/xerial/snappy-java)&lt;/a&gt;&#160;.After merge the commit, maybe spark should update its snappy-java. This is the commit &lt;a href=&quot;https://github.com/xerial/snappy-java/pull/229&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/xerial/snappy-java/pull/229&lt;/a&gt;&#160;&#160;&lt;/p&gt;</comment>
                            <comment id="16801316" author="q79969786" created="Tue, 26 Mar 2019 02:21:11 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=max2049&quot; class=&quot;user-hover&quot; rel=&quot;max2049&quot;&gt;max2049&lt;/a&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/thumbs_up.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16801366" author="taroleo" created="Tue, 26 Mar 2019 04:39:51 +0000"  >&lt;p&gt;Just released snappy-java 1.1.7.3 with this hot fix.&#160;&lt;a href=&quot;https://github.com/xerial/snappy-java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/xerial/snappy-java&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16801396" author="q79969786" created="Tue, 26 Mar 2019 05:34:20 +0000"  >&lt;p&gt;Thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=taroleo&quot; class=&quot;user-hover&quot; rel=&quot;taroleo&quot;&gt;taroleo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;@&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=max2049&quot; class=&quot;user-hover&quot; rel=&quot;max2049&quot;&gt;max2049&lt;/a&gt; Could you&#160;create a PR to upgrade&#160;snappy-java to&#160;1.1.7.3?&lt;/p&gt;</comment>
                            <comment id="16805274" author="srowen" created="Fri, 29 Mar 2019 18:08:13 +0000"  >&lt;p&gt;Good call, looks like it has a Java 9+ fix too, which we may need eventually. There are no other changes that would even affect Spark, so seems safe.&lt;/p&gt;</comment>
                            <comment id="16805319" author="taroleo" created="Fri, 29 Mar 2019 18:33:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; Actually this java9 support is for SnappyFramedStream, which is not used in Spark. I&apos;m now testing snappy-java&#160;using jdk11&#160;&lt;a href=&quot;https://github.com/xerial/snappy-java/pull/230&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/xerial/snappy-java/pull/230&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16805338" author="srowen" created="Fri, 29 Mar 2019 18:52:02 +0000"  >&lt;p&gt;That&apos;s fine, can&apos;t hurt, but won&apos;t do anything now.&lt;/p&gt;</comment>
                            <comment id="16805618" author="max2049" created="Sat, 30 Mar 2019 04:55:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt;&#160;Sorry for this late reply. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; has create a PR (&#160;&lt;a href=&quot;https://github.com/apache/spark/pull/24242&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24242&lt;/a&gt;&#160; ) to fix it.&#160;&#160;Thank you.&#160;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 33 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0122w:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12339177">3.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>