<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:46:45 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17061] Incorrect results returned following a join of two datasets and a map step where total number of columns &gt;100</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17061</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We have hit a consistent bug where we have a dataset with more than 100 columns. I am raising as a blocker because spark is returning the WRONG results rather than erroring, leading to data integrity issues&lt;/p&gt;

&lt;p&gt;I have put together the following test case which will show the issue (it will run in spark-shell). In this example i am joining a dataset with lots of fields onto another dataset. &lt;/p&gt;

&lt;p&gt;The join works fine and if you show the dataset you will get the expected result. However if you run a map step over the dataset you end up with a strange error where the sequence that is in the right dataset now only contains the last value.&lt;/p&gt;

&lt;p&gt;Whilst this test may seem a rather contrived example, what we are doing here is a very standard analtical pattern. My original code was designed to:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;take a dataset of child records&lt;/li&gt;
	&lt;li&gt;groupByKey up to the parent: giving a Dataset of (ParentID, Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Children&amp;#93;&lt;/span&gt;)&lt;/li&gt;
	&lt;li&gt;join the children onto the parent by parentID: giving ((Parent),(ParentID,Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Children&amp;#93;&lt;/span&gt;)&lt;/li&gt;
	&lt;li&gt;map over the result to give a tuple of (Parent,Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Children&amp;#93;&lt;/span&gt;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Notes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;The issue is resolved by having less fields - as soon as we go &amp;lt;= 100 the integrity issue goes away. Try removing one of the fields from BigCaseClass below&lt;/li&gt;
	&lt;li&gt;The issue will arise based on the total number of fields in the resulting dataset. Below i have a small case class and a big case class, but two case classes of 50 variable would give the same issue&lt;/li&gt;
	&lt;li&gt;the issue occurs where the case class being joined on (on the right) has a case class type. It doesnt occur if you have a Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;If i go back to an RDD for the map step after the join i can workaround the issue, but i lose all the benefits of datasets&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Scala code test case:&lt;/p&gt;

&lt;p&gt;  case class Name(name: String)&lt;br/&gt;
  case class SmallCaseClass (joinkey: Integer, names: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;Name&amp;#93;&lt;/span&gt;)    &lt;br/&gt;
  case class BigCaseClass  (field1: Integer,field2: Integer,field3: Integer,field4: Integer,field5: Integer,field6: Integer,field7: Integer,field8: Integer,field9: Integer,field10: Integer,field11: Integer,field12: Integer,field13: Integer,field14: Integer,field15: Integer,field16: Integer,field17: Integer,field18: Integer,field19: Integer,field20: Integer,field21: Integer,field22: Integer,field23: Integer,field24: Integer,field25: Integer,field26: Integer,field27: Integer,field28: Integer,field29: Integer,field30: Integer,field31: Integer,field32: Integer,field33: Integer,field34: Integer,field35: Integer,field36: Integer,field37: Integer,field38: Integer,field39: Integer,field40: Integer,field41: Integer,field42: Integer,field43: Integer,field44: Integer,field45: Integer,field46: Integer,field47: Integer,field48: Integer,field49: Integer,field50: Integer,field51: Integer,field52: Integer,field53: Integer,field54: Integer,field55: Integer,field56: Integer,field57: Integer,field58: Integer,field59: Integer,field60: Integer,field61: Integer,field62: Integer,field63: Integer,field64: Integer,field65: Integer,field66: Integer,field67: Integer,field68: Integer,field69: Integer,field70: Integer,field71: Integer,field72: Integer,field73: Integer,field74: Integer,field75: Integer,field76: Integer,field77: Integer,field78: Integer,field79: Integer,field80: Integer,field81: Integer,field82: Integer,field83: Integer,field84: Integer,field85: Integer,field86: Integer,field87: Integer,field88: Integer,field89: Integer,field90: Integer,field91: Integer,field92: Integer,field93: Integer,field94: Integer,field95: Integer,field96: Integer,field97: Integer,field98: Integer,field99: Integer)&lt;/p&gt;

&lt;p&gt;    val bigCC=Seq(BigCaseClass(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99))&lt;/p&gt;

&lt;p&gt;    val smallCC=Seq(SmallCaseClass(1,Seq(&lt;br/&gt;
        Name(&quot;Jamie&quot;), &lt;br/&gt;
        Name(&quot;Ian&quot;),&lt;br/&gt;
        Name(&quot;Dave&quot;),&lt;br/&gt;
        Name(&quot;Will&quot;)&lt;br/&gt;
        )))&lt;/p&gt;


&lt;p&gt;    val bigCCDS = spark.createDataset(spark.sparkContext.parallelize(bigCC))&lt;br/&gt;
    val smallCCDS = spark.createDataset(spark.sparkContext.parallelize(smallCC))&lt;/p&gt;

&lt;p&gt;    val joined_test=bigCCDS.as(&quot;A&quot;).joinWith(smallCCDS.as(&quot;B&quot;),  $&quot;A.field1&quot;===$&quot;B.joinkey&quot;, &quot;LEFT&quot;)&lt;/p&gt;

&lt;p&gt;    /*This next step is fine - it shows all 4 names:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;[1,WrappedArray(&lt;span class=&quot;error&quot;&gt;&amp;#91;Jamie&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Ian&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Dave&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Will&amp;#93;&lt;/span&gt;)]&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
    joined_test.show(false)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    /*This one ends up repeating will - I did the most simple map step possible here&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;[1,WrappedArray(&lt;span class=&quot;error&quot;&gt;&amp;#91;Will&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Will&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Will&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Will&amp;#93;&lt;/span&gt;)]&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
    joined_test.map(identity).show(false)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;    /*This one works because we have less than 100 fields:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;Jamie&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Ian&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Dave&amp;#93;&lt;/span&gt;, &lt;span class=&quot;error&quot;&gt;&amp;#91;Will&amp;#93;&lt;/span&gt;*/&lt;br/&gt;
    joined_test.map(_._2).show(false)&lt;/li&gt;
&lt;/ul&gt;

</description>
                <environment></environment>
        <key id="12997311">SPARK-17061</key>
            <summary>Incorrect results returned following a join of two datasets and a map step where total number of columns &gt;100</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="proflin">Liwei Lin(Inactive)</assignee>
                                    <reporter username="jamiehutton">Jamie Hutton</reporter>
                        <labels>
                            <label>correctness</label>
                    </labels>
                <created>Mon, 15 Aug 2016 15:20:06 +0000</created>
                <updated>Wed, 31 Aug 2016 21:42:24 +0000</updated>
                            <resolved>Thu, 25 Aug 2016 12:21:18 +0000</resolved>
                                    <version>2.0.0</version>
                    <version>2.0.1</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15421148" author="srowen" created="Mon, 15 Aug 2016 15:37:59 +0000"  >&lt;p&gt;Search JIRA please, and don&apos;t set blocker&lt;/p&gt;</comment>
                            <comment id="15421169" author="jamiehutton" created="Mon, 15 Aug 2016 15:51:34 +0000"  >&lt;p&gt;Apologies for setting blocker. I wont use that again.&lt;/p&gt;

&lt;p&gt;Is the above definitely the same issue as the one you marked as a duplicate? That does seem to be slightly different as it relates to persist and 200 columns. Did you manage to run the above test case on a 2.0.1 codebase and did it work?&lt;/p&gt;</comment>
                            <comment id="15421178" author="srowen" created="Mon, 15 Aug 2016 15:56:52 +0000"  >&lt;p&gt;It is likely to be &amp;#8211; see also &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-17043&quot; title=&quot;Cannot call zipWithIndex on RDD with more than 200 columns (get wrong result)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-17043&quot;&gt;&lt;del&gt;SPARK-17043&lt;/del&gt;&lt;/a&gt;. At least, I&apos;d try a version with this fix before reopening this one.&lt;/p&gt;</comment>
                            <comment id="15421277" author="jamiehutton" created="Mon, 15 Aug 2016 17:06:05 +0000"  >&lt;p&gt;I have just downloaded 2.0.1 nightly build from here:&lt;br/&gt;
&lt;a href=&quot;http://people.apache.org/~pwendell/spark-nightly/spark-branch-2.0-bin/spark-2.0.1-SNAPSHOT-2016_08_15_00_23-e02d0d0-bin/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://people.apache.org/~pwendell/spark-nightly/spark-branch-2.0-bin/spark-2.0.1-SNAPSHOT-2016_08_15_00_23-e02d0d0-bin/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately the issue is still present. I am going to down-grade the issue to critical as you suggested and re-open if thats ok. Please can you guys take a look at it?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;</comment>
                            <comment id="15421280" author="jamiehutton" created="Mon, 15 Aug 2016 17:07:22 +0000"  >&lt;p&gt;Tested in 2.0.1 nightly snapshot and still not resolved so this appears not to be a dupe&lt;/p&gt;</comment>
                            <comment id="15422051" author="proflin" created="Tue, 16 Aug 2016 02:14:27 +0000"  >&lt;p&gt;This can be reproduced against the master branch; let me look into this. Thanks.&lt;/p&gt;</comment>
                            <comment id="15426025" author="apachespark" created="Thu, 18 Aug 2016 07:32:09 +0000"  >&lt;p&gt;User &apos;lw-lin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14698&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14698&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15436626" author="apachespark" created="Thu, 25 Aug 2016 10:19:06 +0000"  >&lt;p&gt;User &apos;hvanhovell&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14806&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14806&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15438917" author="jamiehutton" created="Fri, 26 Aug 2016 13:19:37 +0000"  >&lt;p&gt;Just wanted to say we have pulled the latest nightly with this fix and it solves our original issue. Thank you so much for getting this one fixed &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15444614" author="proflin" created="Mon, 29 Aug 2016 02:52:17 +0000"  >&lt;p&gt;Oh cool! Thank you for the well-formed reproducer!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12991445">SPARK-16664</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12997715">SPARK-17093</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 12 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32blr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>