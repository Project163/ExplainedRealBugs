<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:32:11 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-42168] CoGroup with window function returns incorrect result when partition keys differ in order</title>
                <link>https://issues.apache.org/jira/browse/SPARK-42168</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following example returns an incorrect result:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pandas as pd

from pyspark.sql &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; SparkSession, Window
from pyspark.sql.functions &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; col, lit, sum

spark = SparkSession \
    .builder \
    .getOrCreate()

ids = 1000
days = 1000
parts = 10

id_df = spark.range(ids)
day_df = spark.range(days).withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;)
id_day_df = id_df.join(day_df)
left_df = id_day_df.select(col(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;), col(&lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;), lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;left&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;side&quot;&lt;/span&gt;)).repartition(parts).cache()
right_df = id_day_df.select(col(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;), col(&lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;), lit(&lt;span class=&quot;code-quote&quot;&gt;&quot;right&quot;&lt;/span&gt;).alias(&lt;span class=&quot;code-quote&quot;&gt;&quot;side&quot;&lt;/span&gt;)).repartition(parts).cache()  #.withColumnRenamed(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;id2&quot;&lt;/span&gt;)

# note the column order is different to the groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;) column order below
window = Window.partitionBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;)

left_grouped_df = left_df.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;)
right_grouped_df = right_df.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;day_sum&quot;&lt;/span&gt;, sum(col(&lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;)).over(window)).groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;)

def cogroup(left: pd.DataFrame, right: pd.DataFrame) -&amp;gt; pd.DataFrame:
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; pd.DataFrame([{
        &lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;: left[&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;][0] &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not left.empty &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; (right[&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;][0] &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not right.empty &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; None),
        &lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;: left[&lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;][0] &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not left.empty &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; (right[&lt;span class=&quot;code-quote&quot;&gt;&quot;day&quot;&lt;/span&gt;][0] &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; not right.empty &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; None),
        &lt;span class=&quot;code-quote&quot;&gt;&quot;lefts&quot;&lt;/span&gt;: len(left.index),
        &lt;span class=&quot;code-quote&quot;&gt;&quot;rights&quot;&lt;/span&gt;: len(right.index)
    }])

df = left_grouped_df.cogroup(right_grouped_df) \
         .applyInPandas(cogroup, schema=&lt;span class=&quot;code-quote&quot;&gt;&quot;id &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, day &lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;, lefts integer, rights integer&quot;&lt;/span&gt;)

df.explain()
df.show(5)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Output is&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
+- FlatMapCoGroupsInPandas [id#8L, day#9L], [id#29L, day#30L], cogroup(id#8L, day#9L, side#10, id#29L, day#30L, side#31, day_sum#54L), [id#64L, day#65L, lefts#66, rights#67]
   :- Sort [id#8L ASC NULLS FIRST, day#9L ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
   :  +- Exchange hashpartitioning(id#8L, day#9L, 200), ENSURE_REQUIREMENTS, [plan_id=117]
   :     +- ...
   +- Sort [id#29L ASC NULLS FIRST, day#30L ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
      +- Project [id#29L, day#30L, id#29L, day#30L, side#31, day_sum#54L]
         +- Window [sum(day#30L) windowspecdefinition(day#30L, id#29L, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS day_sum#54L], [day#30L, id#29L]
            +- Sort [day#30L ASC NULLS FIRST, id#29L ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
               +- Exchange hashpartitioning(day#30L, id#29L, 200), ENSURE_REQUIREMENTS, [plan_id=112]
                  +- ...


+---+---+-----+------+
| id|day|lefts|rights|
+---+---+-----+------+
|  0|  3|    0|     1|
|  0|  4|    0|     1|
|  0| 13|    1|     0|
|  0| 27|    0|     1|
|  0| 31|    0|     1|
+---+---+-----+------+
only showing top 5 rows
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The first child is hash-partitioned by &lt;tt&gt;id&lt;/tt&gt; and &lt;tt&gt;day&lt;/tt&gt;, while the second child is hash-partitioned by &lt;tt&gt;day&lt;/tt&gt; and &lt;tt&gt;id&lt;/tt&gt; (required by the window function). Therefore, rows end up in different partitions.&lt;/p&gt;

&lt;p&gt;This has been fixed in Spark 3.3 by &lt;a href=&quot;https://github.com/apache/spark/pull/32875/files#diff-e938569a4ca4eba8f7e10fe473d4f9c306ea253df151405bcaba880a601f075fR75-R76&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;#32875&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
== Physical Plan ==
AdaptiveSparkPlan isFinalPlan=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
+- FlatMapCoGroupsInPandas [id#8L, day#9L], [id#29L, day#30L], cogroup(id#8L, day#9L, side#10, id#29L, day#30L, side#31, day_sum#54L)#63, [id#64L, day#65L, lefts#66, rights#67]
   :- Sort [id#8L ASC NULLS FIRST, day#9L ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
   :  +- Exchange hashpartitioning(id#8L, day#9L, 200), ENSURE_REQUIREMENTS, [plan_id=117]
   :     +- ...
   +- Sort [id#29L ASC NULLS FIRST, day#30L ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
      +- Exchange hashpartitioning(id#29L, day#30L, 200), ENSURE_REQUIREMENTS, [plan_id=118]
         +- Project [id#29L, day#30L, id#29L, day#30L, side#31, day_sum#54L]
            +- Window [sum(day#30L) windowspecdefinition(day#30L, id#29L, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS day_sum#54L], [day#30L, id#29L]
               +- Sort [day#30L ASC NULLS FIRST, id#29L ASC NULLS FIRST], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
                  +- Exchange hashpartitioning(day#30L, id#29L, 200), ENSURE_REQUIREMENTS, [plan_id=112]
                     +- ...

+---+---+-----+------+
| id|day|lefts|rights|
+---+---+-----+------+
|  0| 13|    1|     1|
|  0| 63|    1|     1|
|  0| 89|    1|     1|
|  0| 95|    1|     1|
|  0| 96|    1|     1|
+---+---+-----+------+
only showing top 5 rows
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Only PySpark is to be affected (&lt;tt&gt;FlatMapCoGroupsInPandas }}), as Scala API uses {{CoGroup&lt;/tt&gt;. &lt;tt&gt;FlatMapCoGroupsInPandas&lt;/tt&gt; reports required child distribution &lt;tt&gt;ClusteredDistribution&lt;/tt&gt;, while &lt;tt&gt;CoGroup&lt;/tt&gt; reports &lt;tt&gt;HashClusteredDistribution&lt;/tt&gt;. The &lt;tt&gt;EnsureRequirements&lt;/tt&gt; rule correctly recognizes a &lt;tt&gt;HashClusteredDistribution(id, day)&lt;/tt&gt; as not compatible with &lt;tt&gt;hashpartitioning(day, id)&lt;/tt&gt;, while &lt;tt&gt;ClusteredDistribution(id, day)&lt;/tt&gt; is compatible with &lt;tt&gt;hashpartitioning(day, id)&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13521114">SPARK-42168</key>
            <summary>CoGroup with window function returns incorrect result when partition keys differ in order</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="enricomi">Enrico Minack</assignee>
                                    <reporter username="enricomi">Enrico Minack</reporter>
                        <labels>
                            <label>correctness</label>
                    </labels>
                <created>Tue, 24 Jan 2023 12:12:40 +0000</created>
                <updated>Mon, 30 Jan 2023 10:55:11 +0000</updated>
                            <resolved>Thu, 26 Jan 2023 01:43:43 +0000</resolved>
                                    <version>3.0.3</version>
                    <version>3.1.3</version>
                    <version>3.2.3</version>
                                    <fixVersion>3.2.4</fixVersion>
                                    <component>PySpark</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="17680229" author="apachespark" created="Tue, 24 Jan 2023 14:06:27 +0000"  >&lt;p&gt;User &apos;EnricoMi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39717&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39717&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17680853" author="gurwls223" created="Thu, 26 Jan 2023 01:43:43 +0000"  >&lt;p&gt;Issue resolved by pull request 39717&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39717&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39717&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17680909" author="apachespark" created="Thu, 26 Jan 2023 07:24:45 +0000"  >&lt;p&gt;User &apos;EnricoMi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39752&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39752&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17681560" author="apachespark" created="Sat, 28 Jan 2023 10:49:27 +0000"  >&lt;p&gt;User &apos;EnricoMi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39781&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39781&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17682009" author="apachespark" created="Mon, 30 Jan 2023 10:55:11 +0000"  >&lt;p&gt;User &apos;EnricoMi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39803&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39803&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 41 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1fbig:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>