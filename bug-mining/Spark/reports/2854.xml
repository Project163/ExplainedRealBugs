<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:35:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-12089] java.lang.NegativeArraySizeException when growing BufferHolder</title>
                <link>https://issues.apache.org/jira/browse/SPARK-12089</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When running a large spark sql query including multiple joins I see tasks failing with the following trace:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.lang.NegativeArraySizeException
        at org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder.grow(BufferHolder.java:36)
        at org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter.write(UnsafeRowWriter.java:188)
        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
        at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
        at org.apache.spark.sql.execution.joins.OneSideOuterIterator.getRow(SortMergeOuterJoin.scala:288)
        at org.apache.spark.sql.execution.RowIteratorToScala.next(RowIterator.scala:76)
        at org.apache.spark.sql.execution.RowIteratorToScala.next(RowIterator.scala:62)
        at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
        at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:164)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
        at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
        at org.apache.spark.scheduler.Task.run(Task.scala:88)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From the spark code it looks like this is due to a integer overflow when growing a buffer length. The offending line &lt;tt&gt;BufferHolder.java:36&lt;/tt&gt; is the following in the version I&apos;m running:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] tmp = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[length * 2];
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This seems to indicate to me that this buffer will never be able to hold more then 2G worth of data. And likely will hold even less since any length &amp;gt; 1073741824 will cause a integer overflow and turn the new buffer size negative.&lt;/p&gt;

&lt;p&gt;I hope I&apos;m simply missing some critical config setting but it still seems weird that we have a (rather low) upper limit on these buffers. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12917473">SPARK-12089</key>
            <summary>java.lang.NegativeArraySizeException when growing BufferHolder</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="nongli">Nong Li</assignee>
                                    <reporter username="tyro89">Erik Selin</reporter>
                        <labels>
                    </labels>
                <created>Wed, 2 Dec 2015 05:49:36 +0000</created>
                <updated>Fri, 4 Dec 2015 18:18:44 +0000</updated>
                            <resolved>Fri, 4 Dec 2015 18:01:38 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>1.6.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="15036004" author="cloud_fan" created="Wed, 2 Dec 2015 15:53:48 +0000"  >&lt;p&gt;yea, I think we should be more conservative to grow the buffer array, maybe we can check the `length`, if `length &amp;gt; Integer.Max / 2`, we should just use `Integer.Max` as new array size, instead of `length * 2`.  cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15036015" author="tyro89" created="Wed, 2 Dec 2015 15:58:30 +0000"  >&lt;p&gt;I can make that change if it is that easy. I&apos;m just wondering if that&apos;s really enough? What would happen when we need a buffer to hold more then Integer.Max?&lt;/p&gt;</comment>
                            <comment id="15036194" author="davies" created="Wed, 2 Dec 2015 17:28:07 +0000"  >&lt;p&gt;Is it possible that you have a record larger than 1G? I don&apos;t think so, or there are many places will break.&lt;/p&gt;

&lt;p&gt;Does this task always fail or not? If not, it means the length get corrupt somewhere, that&apos;s the root cause.&lt;/p&gt;

&lt;p&gt;Can you reproduce this?&lt;/p&gt;</comment>
                            <comment id="15036247" author="tyro89" created="Wed, 2 Dec 2015 17:50:42 +0000"  >&lt;p&gt;There shouldn&apos;t be a single record larger than 1G no. But I&apos;m doing a group by month so I was guessing that a large amount of pre-aggregated data might end up in the same buffer?&lt;/p&gt;

&lt;p&gt;I have tasks failing and later succeeding and then there&apos;s others that seems to just kill the job. I&apos;m not deeply familiar with this area of spark but I guess that does mean that we might be failing to reclaim parts of the buffer for later use? I can reproduce but it takes me ~ 4 hours to get to the failing stage &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15036280" author="davies" created="Wed, 2 Dec 2015 18:09:35 +0000"  >&lt;p&gt;Could you turn on debug log, and paste the java source code of the SpecificUnsafeProjection (generated unsafe projection) here?&lt;/p&gt;</comment>
                            <comment id="15036295" author="davies" created="Wed, 2 Dec 2015 18:16:07 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tyro89&quot; class=&quot;user-hover&quot; rel=&quot;tyro89&quot;&gt;tyro89&lt;/a&gt; Are you build a large Array using group by? How is the query looks like?&lt;/p&gt;</comment>
                            <comment id="15036327" author="tyro89" created="Wed, 2 Dec 2015 18:32:37 +0000"  >&lt;p&gt;It&apos;s a bunch of table joins followed by a group by on multiple fields. One of the fields being a month window. Example:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;select x.a, x.b, x.c, x.month from (
  select a, b, c, concat(year(from_unixtime(t)), &lt;span class=&quot;code-quote&quot;&gt;&quot;-&quot;&lt;/span&gt;, month(from_unixtime(t))) AS month
  from foo
  left join bar on foo.bar_id = bar.id
  left join biz on foo.biz_id = biz.id
) as x
group by x.a, x.b, x.c, x.month
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;My hypothesis, but I need your expertise to confirm/deny since I&apos;m really not familiar with this area of sparks codebase. Is that the monthly group by is indeed creating something huge, perhaps by bucketing a lot of data together into the same buffer? I have similar jobs running very similar queries but grouped by day and they are not running into this issue.&lt;/p&gt;

&lt;p&gt;I&apos;ll do a debug log run once I have some spare cycles on my end! &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15036807" author="davies" created="Wed, 2 Dec 2015 22:44:37 +0000"  >&lt;p&gt;This query will not generate huge record, each record should be less than 100B.&lt;/p&gt;</comment>
                            <comment id="15037018" author="yhuai" created="Thu, 3 Dec 2015 01:21:51 +0000"  >&lt;p&gt;The stacktrace I have is&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/12/02 01:10:43 ERROR DynamicPartitionWriterContainer: Task attempt attempt_201512020110_0005_m_000038_0 aborted.
15/12/02 01:10:43 WARN TaskMemoryManager: leak 64.0 MB memory from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7f646f40
15/12/02 01:10:43 ERROR Executor: Managed memory leak detected; size = 67108864 bytes, TID = 51040
15/12/02 01:10:43 ERROR Executor: Exception in task 38.0 in stage 5.0 (TID 51040)
org.apache.spark.SparkException: Task failed &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; writing rows.
    at org.apache.spark.sql.execution.datasources.DynamicPartitionWriterContainer.writeRows(WriterContainer.scala:396)
    at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelation$$anonfun$run$1$$anonfun$apply$mcV$sp$3.apply(InsertIntoHadoopFsRelation.scala:150)
    at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelation$$anonfun$run$1$$anonfun$apply$mcV$sp$3.apply(InsertIntoHadoopFsRelation.scala:150)
    at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
    at org.apache.spark.scheduler.Task.run(Task.scala:88)
    at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:209)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.NegativeArraySizeException
    at org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder.grow(BufferHolder.java:45)
    at org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter.write(UnsafeRowWriter.java:196)
    at org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)
    at org.apache.spark.sql.execution.datasources.DynamicPartitionWriterContainer.writeRows(WriterContainer.scala:360)
    ... 8 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It was yesterday&apos;s branch 1.6 (around noon PST).&lt;/p&gt;</comment>
                            <comment id="15037275" author="apachespark" created="Thu, 3 Dec 2015 05:18:04 +0000"  >&lt;p&gt;User &apos;yhuai&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10120&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10120&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15037276" author="yhuai" created="Thu, 3 Dec 2015 05:19:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tyro89&quot; class=&quot;user-hover&quot; rel=&quot;tyro89&quot;&gt;tyro89&lt;/a&gt; Can you reproduce it? I am trying to add some logs and see if we can understand the problem better. I put my changes in &lt;a href=&quot;https://github.com/apache/spark/pull/10120&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10120&lt;/a&gt;. If you can reproduce the problem, can you give it a try? We will also try it.&lt;/p&gt;</comment>
                            <comment id="15040771" author="apachespark" created="Fri, 4 Dec 2015 06:11:04 +0000"  >&lt;p&gt;User &apos;nongli&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10142&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15041874" author="davies" created="Fri, 4 Dec 2015 18:01:38 +0000"  >&lt;p&gt;Issue resolved by pull request 10142&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10142&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15041899" author="yhuai" created="Fri, 4 Dec 2015 18:18:44 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tyro89&quot; class=&quot;user-hover&quot; rel=&quot;tyro89&quot;&gt;tyro89&lt;/a&gt; &lt;a href=&quot;https://github.com/apache/spark/pull/10142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10142&lt;/a&gt; has been merged. Can you try the latest 1.6 branch?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 50 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2p5kf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12333083">1.6.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>