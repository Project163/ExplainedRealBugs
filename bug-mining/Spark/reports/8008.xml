<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:26:38 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-35700] spark.sql.orc.filterPushdown not working with Spark 3.1.1 for tables with varchar data type</title>
                <link>https://issues.apache.org/jira/browse/SPARK-35700</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We are not able to upgrade to Spark 3.1.1 from Spark 2.4.x as the join on varchar column is failing which is unexpected and works on Spark 3.0.0.&#160; We are trying to run it on Spark 3.1.1 (MR 3.2) on K8s&#160;&lt;/p&gt;

&lt;p&gt;Below is my use case:&lt;/p&gt;

&lt;p&gt;Tables are external hive table and files are stored as ORC. We do have varchar column and when we are trying to perform join on varchar column we are getting the exception.&lt;/p&gt;

&lt;p&gt;As I understand Spark 3.1.1 have introduced varchar data type but seems its not well tested with ORC and does not have backward compatibility. I have even tried with below config without luck&lt;/p&gt;

&lt;p&gt;&lt;b&gt;spark.sql.legacy.charVarcharAsString: &quot;true&quot;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;We are not getting the error when&#160;&lt;b&gt;spark.sql.orc.filterPushdown=false&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Below is the code: Here col1 is of type varchar(32) in hive&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
df = spark.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select col1, col2 from table1 a &lt;span class=&quot;code-keyword&quot;&gt;inner&lt;/span&gt; join table2 on b (a.col1=b.col1 and a.col2 &amp;gt; b.col2 )&quot;&lt;/span&gt;) 
df.write.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;orc&quot;&lt;/span&gt;).option(&lt;span class=&quot;code-quote&quot;&gt;&quot;compression&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;zlib&quot;&lt;/span&gt;).mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;Append&quot;&lt;/span&gt;).save(&lt;span class=&quot;code-quote&quot;&gt;&quot;&amp;lt;s3_path&amp;gt;&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Below is the error:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Job aborted due to stage failure: Task 43 in stage 5.0 failed 4 times, most recent failure: Lost task 43.3 in stage 5.0 (TID 524) (10.219.36.64 executor 5): java.lang.UnsupportedOperationException: DataType: varchar(32)
	at org.apache.spark.sql.execution.datasources.orc.OrcFilters$.getPredicateLeafType(OrcFilters.scala:150)
	at org.apache.spark.sql.execution.datasources.orc.OrcFilters$.getType$1(OrcFilters.scala:222)
	at org.apache.spark.sql.execution.datasources.orc.OrcFilters$.buildLeafSearchArgument(OrcFilters.scala:266)
	at org.apache.spark.sql.execution.datasources.orc.OrcFilters$.convertibleFiltersHelper$1(OrcFilters.scala:132)
	at org.apache.spark.sql.execution.datasources.orc.OrcFilters$.$anonfun$convertibleFilters$4(OrcFilters.scala:135)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)
	at scala.collection.immutable.List.flatMap(List.scala:355)
	at org.apache.spark.sql.execution.datasources.orc.OrcFilters$.convertibleFilters(OrcFilters.scala:134)
	at org.apache.spark.sql.execution.datasources.orc.OrcFilters$.createFilter(OrcFilters.scala:73)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat.$anonfun$buildReaderWithPartitionValues$4(OrcFileFormat.scala:189)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat.$anonfun$buildReaderWithPartitionValues$4$adapted(OrcFileFormat.scala:188)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.sql.execution.datasources.orc.OrcFileFormat.$anonfun$buildReaderWithPartitionValues$1(OrcFileFormat.scala:188)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:116)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:169)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:93)
	at org.apache.spark.sql.execution.FileSourceScanExec$$anon$1.hasNext(DataSourceScanExec.scala:503)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.columnartorow_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)
	at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:177)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(Unknown Source)

Driver stacktrace:3
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I can see there is no mapping of varchar in OrcFilters.scala:150&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/v3.1.1/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/orc/OrcFilters.scala#L142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v3.1.1/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/orc/OrcFilters.scala#L142&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment>&lt;p&gt;Spark&#160;3.1.1 on K8S&lt;/p&gt;</environment>
        <key id="13382956">SPARK-35700</key>
            <summary>spark.sql.orc.filterPushdown not working with Spark 3.1.1 for tables with varchar data type</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Qin Yao">Kent Yao 2</assignee>
                                    <reporter username="arghya18">Arghya Saha</reporter>
                        <labels>
                    </labels>
                <created>Wed, 9 Jun 2021 13:39:01 +0000</created>
                <updated>Mon, 12 Dec 2022 18:11:10 +0000</updated>
                            <resolved>Tue, 22 Jun 2021 02:23:33 +0000</resolved>
                                    <version>3.1.1</version>
                                    <fixVersion>3.2.0</fixVersion>
                    <fixVersion>3.1.3</fixVersion>
                                    <component>Kubernetes</component>
                    <component>PySpark</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="17362698" author="gurwls223" created="Mon, 14 Jun 2021 05:04:51 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Qin+Yao&quot; class=&quot;user-hover&quot; rel=&quot;Qin Yao&quot;&gt;Qin Yao&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; FYI&lt;/p&gt;</comment>
                            <comment id="17364371" author="arghya18" created="Wed, 16 Jun 2021 16:31:00 +0000"  >&lt;p&gt;Any update on this please? This is very common use case.&lt;/p&gt;</comment>
                            <comment id="17365492" author="saurabhc100" created="Fri, 18 Jun 2021 13:05:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arghya18&quot; class=&quot;user-hover&quot; rel=&quot;arghya18&quot;&gt;arghya18&lt;/a&gt; - I tried to reproduce this scenario, but its not failing for me&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;CREATE external TABLE tblvarchorc1 (x INTEGER, y VARCHAR(8)) stored as orc;&lt;/p&gt;

&lt;p&gt;CREATE external TABLE tblvarchorc2 (x INTEGER, y VARCHAR(8)) stored as orc;&lt;/p&gt;

&lt;p&gt;spark.sql(&quot;select * from tblvarchorc1&quot;).show&lt;br/&gt;
 &lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;x&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;y&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;test&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+&lt;/p&gt;

&lt;p&gt;spark.sql(&quot;select * from tblvarchorc2&quot;).show&lt;br/&gt;
 &lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;x&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;y&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;test&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;--+&lt;/p&gt;

&lt;p&gt;spark.sql(&quot;select * from tblvarchorc1 a inner join tblvarchorc2 b on (a.y = b.y and a.x &amp;gt;= b.x ) &quot;).show&lt;br/&gt;
 &lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;-&lt;del&gt;+&lt;ins&gt;&lt;/del&gt;------&lt;/ins&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;x&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;y&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;x&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;y&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;-&lt;del&gt;+&lt;ins&gt;&lt;/del&gt;------&lt;/ins&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;test&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;1&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;test&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;&lt;ins&gt;---&lt;del&gt;&lt;/ins&gt;&lt;/del&gt;-&lt;del&gt;+&lt;ins&gt;&lt;/del&gt;------&lt;/ins&gt;&lt;/p&gt;

&lt;p&gt;This method converts the schema to the string type&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def replaceCharVarcharWithString(dt: DataType): DataType = dt match {
 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; ArrayType(et, nullable) =&amp;gt;
 ArrayType(replaceCharVarcharWithString(et), nullable)
 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; MapType(kt, vt, nullable) =&amp;gt;
 MapType(replaceCharVarcharWithString(kt), replaceCharVarcharWithString(vt), nullable)
 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; StructType(fields) =&amp;gt;
 StructType(fields.map { field =&amp;gt;
 field.copy(dataType = replaceCharVarcharWithString(field.dataType))
 })
 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _: CharType =&amp;gt; StringType
 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _: VarcharType =&amp;gt; StringType
 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; dt
}&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;also i have validated we are getting the&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
spark.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select * from&#160; tblvarchorc1&quot;&lt;/span&gt;).schema
res1: org.apache.spark.sql.types.StructType = StructType(StructField(x,IntegerType,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;), StructField(y,StringType,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Can you share the reproducible scenario to debug this further.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17366097" author="gurwls223" created="Sun, 20 Jun 2021 03:50:30 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Qin+Yao&quot; class=&quot;user-hover&quot; rel=&quot;Qin Yao&quot;&gt;Qin Yao&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;, there was a same JIRA reported in &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-35762&quot; title=&quot;Errors while using spark-sql read hive 3.1 orc table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-35762&quot;&gt;&lt;del&gt;SPARK-35762&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It would be great if the issue persists with the reproducible step as &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-35762&quot; title=&quot;Errors while using spark-sql read hive 3.1 orc table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-35762&quot;&gt;&lt;del&gt;SPARK-35762&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17366123" author="saurabhc100" created="Sun, 20 Jun 2021 09:03:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt;/ &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Qin+Yao&quot; class=&quot;user-hover&quot; rel=&quot;Qin Yao&quot;&gt;Qin Yao&lt;/a&gt;&#160;/ &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;&#160;- I was able to reproduce this issue in the master branch for the steps given in the&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-35762&quot; title=&quot;Errors while using spark-sql read hive 3.1 orc table&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-35762&quot;&gt;&lt;del&gt;SPARK-35762&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&#160;Below are some of the scenario found while debugging this issue.&lt;/p&gt;

&lt;p&gt;1) This is issue is reproducible for all the orc data created using the Hive, but when the insertion is done using the SPARK, we are not getting this exception.&lt;/p&gt;

&lt;p&gt;2) We are getting the exception due this, when the file is created using hive&#160; and while calling the&#160;readSchema the &lt;a href=&quot;http://example.com/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/orc/OrcUtils.scala#L63&#160;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the&#160;reader.getSchema we get the varchar datatype.&lt;/p&gt;

&lt;p&gt;But on reading the orc file created by the Spark we are getting the string datatype.&lt;/p&gt;

&lt;p&gt;3) I tried adding the validation for converting varchar to String&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
readSchema(file, conf, ignoreCorruptFiles) match {
 &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; Some(schema) =&amp;gt;
 val orcSchema = CatalystSqlParser.parseDataType(
 schema.toString).asInstanceOf[StructType]
 val varCharExist = orcSchema.fields.exists(
 x =&amp;gt; CharVarcharUtils.hasCharVarchar(x.dataType))
 &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (varCharExist) {
 Some(CharVarcharUtils.replaceCharVarcharWithStringInSchema(orcSchema))
 } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
 Some(orcSchema)
 }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;After adding this fix , we are converting the varchar to string and query is working fine.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;4) Similar conversion of data type change is needed on the&#160;&lt;/p&gt;

&lt;p&gt;`def readSchema(file: Path, conf: Configuration, ignoreCorruptFiles: Boolean) `, this called by inferSchema ,&lt;/p&gt;

&lt;p&gt;readOrcSchemasInParallel.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;If this approach is fine. Than I can go head and create the PR for the same, otherwise if we want to see some other approach we can discuss on this&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17366564" author="apachespark" created="Mon, 21 Jun 2021 12:12:55 +0000"  >&lt;p&gt;User &apos;yaooqinn&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/33001&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/33001&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17366944" author="dongjoon" created="Tue, 22 Jun 2021 02:23:33 +0000"  >&lt;p&gt;Issue resolved by pull request 33001&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/33001&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/33001&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17367580" author="apachespark" created="Tue, 22 Jun 2021 18:16:42 +0000"  >&lt;p&gt;User &apos;cloud-fan&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/33030&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/33030&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310361">
                    <name>Blocked</name>
                                            <outwardlinks description="Blocked">
                                        <issuelink>
            <issuekey id="13436602">SPARK-38695</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13383839">SPARK-35762</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13407897">SPARK-37096</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 21 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0rsx4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>