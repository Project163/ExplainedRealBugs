<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:32:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-10542] The  PySpark 1.5 closure serializer can&apos;t serialize a namedtuple instance.</title>
                <link>https://issues.apache.org/jira/browse/SPARK-10542</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Code to Reproduce Bug:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;from collections &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; namedtuple
PowerPlantRow=namedtuple(&lt;span class=&quot;code-quote&quot;&gt;&quot;PowerPlantRow&quot;&lt;/span&gt;, [&lt;span class=&quot;code-quote&quot;&gt;&quot;AT&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;V&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;AP&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;RH&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;PE&quot;&lt;/span&gt;])
rdd=sc.parallelize([1]).map(lambda x: PowerPlantRow(1.0, 2.0, 3.0, 4.0, 5.0))
rdd.count()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Error message on Spark 1.5:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;AttributeError: &lt;span class=&quot;code-quote&quot;&gt;&apos;builtin_function_or_method&apos;&lt;/span&gt; object has no attribute &lt;span class=&quot;code-quote&quot;&gt;&apos;__code__&apos;&lt;/span&gt;
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&amp;lt;ipython-input-5-59448e31019f&amp;gt; in &amp;lt;module&amp;gt;()
      2 PowerPlantRow=namedtuple(&lt;span class=&quot;code-quote&quot;&gt;&quot;PowerPlantRow&quot;&lt;/span&gt;, [&lt;span class=&quot;code-quote&quot;&gt;&quot;AT&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;V&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;AP&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;RH&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;PE&quot;&lt;/span&gt;])
      3 rdd=sc.parallelize([1]).map(lambda x: PowerPlantRow(1.0, 2.0, 3.0, 4.0, 5.0))
----&amp;gt; 4 rdd.count()

/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc in count(self)
   1004         3
   1005         &quot;&quot;&quot;
-&amp;gt; 1006         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.mapPartitions(lambda i: [sum(1 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; _ in i)]).sum()
   1007 
   1008     def stats(self):

/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc in sum(self)
    995         6.0
    996         &quot;&quot;&quot;
--&amp;gt; 997         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.mapPartitions(lambda x: [sum(x)]).fold(0, &lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;.add)
    998 
    999     def count(self):

/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc in fold(self, zeroValue, op)
    869         # zeroValue provided to each partition is unique from the one provided
    870         # to the &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; reduce call
--&amp;gt; 871         vals = self.mapPartitions(func).collect()
    872         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; reduce(op, vals, zeroValue)
    873 

/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc in collect(self)
    771         &quot;&quot;&quot;
    772         with SCCallSiteSync(self.context) as css:
--&amp;gt; 773             port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
    774         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; list(_load_from_socket(port, self._jrdd_deserializer))
    775 

/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc in _jrdd(self)
   2383         command = (self.func, profiler, self._prev_jrdd_deserializer,
   2384                    self._jrdd_deserializer)
-&amp;gt; 2385         pickled_cmd, bvars, env, includes = _prepare_for_python_RDD(self.ctx, command, self)
   2386         python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(),
   2387                                              bytearray(pickled_cmd),

/home/ubuntu/databricks/spark/python/pyspark/rdd.pyc in _prepare_for_python_RDD(sc, command, obj)
   2303     # the serialized command will be compressed by broadcast
   2304     ser = CloudPickleSerializer()
-&amp;gt; 2305     pickled_command = ser.dumps(command)
   2306     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; len(pickled_command) &amp;gt; (1 &amp;lt;&amp;lt; 20):  # 1M
   2307         # The broadcast will have same life cycle as created PythonRDD

/home/ubuntu/databricks/spark/python/pyspark/serializers.pyc in dumps(self, obj)
    425 
    426     def dumps(self, obj):
--&amp;gt; 427         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; cloudpickle.dumps(obj, 2)
    428 
    429 

/home/ubuntu/databricks/spark/python/pyspark/cloudpickle.pyc in dumps(obj, protocol)
    639 
    640     cp = CloudPickler(file,protocol)
--&amp;gt; 641     cp.dump(obj)
    642 
    643     &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; file.getvalue()

/home/ubuntu/databricks/spark/python/pyspark/cloudpickle.pyc in dump(self, obj)
    105         self.inject_addons()
    106         &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;:
--&amp;gt; 107             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Pickler.dump(self, obj)
    108         except RuntimeError as e:
    109             &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;recursion&apos;&lt;/span&gt; in e.args[0]:

/usr/lib/python2.7/pickle.pyc in dump(self, obj)
    222         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; self.proto &amp;gt;= 2:
    223             self.write(PROTO + chr(self.proto))
--&amp;gt; 224         self.save(obj)
    225         self.write(STOP)
    226 

/usr/lib/python2.7/pickle.pyc in save(self, obj)
    284         f = self.dispatch.get(t)
    285         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; f:
--&amp;gt; 286             f(self, obj) # Call unbound method with explicit self
    287             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
    288 

/usr/lib/python2.7/pickle.pyc in save_tuple(self, obj)
    560         write(MARK)
    561         &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; element in obj:
--&amp;gt; 562             save(element)
    563 
    564         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; id(obj) in memo:

/usr/lib/python2.7/pickle.pyc in save(self, obj)
    284         f = self.dispatch.get(t)
    285         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; f:
--&amp;gt; 286             f(self, obj) # Call unbound method with explicit self
    287             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
    288 
... skipped 23125 bytes ...
    650 
    651     dispatch[DictionaryType] = save_dict

/usr/lib/python2.7/pickle.pyc in _batch_setitems(self, items)
    684                 k, v = tmp[0]
    685                 save(k)
--&amp;gt; 686                 save(v)
    687                 write(SETITEM)
    688             # &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; tmp is empty, and we&apos;re done

/usr/lib/python2.7/pickle.pyc in save(self, obj)
    284         f = self.dispatch.get(t)
    285         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; f:
--&amp;gt; 286             f(self, obj) # Call unbound method with explicit self
    287             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
    288 

/home/ubuntu/databricks/spark/python/pyspark/cloudpickle.pyc in save_global(self, obj, name, pack)
    367                     v = v.__func__
    368                 dd[k] = v
--&amp;gt; 369             self.save(dd)
    370             self.write(pickle.TUPLE2)
    371             self.write(pickle.REDUCE)

/usr/lib/python2.7/pickle.pyc in save(self, obj)
    284         f = self.dispatch.get(t)
    285         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; f:
--&amp;gt; 286             f(self, obj) # Call unbound method with explicit self
    287             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
    288 

/usr/lib/python2.7/pickle.pyc in save_dict(self, obj)
    647 
    648         self.memoize(obj)
--&amp;gt; 649         self._batch_setitems(obj.iteritems())
    650 
    651     dispatch[DictionaryType] = save_dict

/usr/lib/python2.7/pickle.pyc in _batch_setitems(self, items)
    679                 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; k, v in tmp:
    680                     save(k)
--&amp;gt; 681                     save(v)
    682                 write(SETITEMS)
    683             elif n:

/usr/lib/python2.7/pickle.pyc in save(self, obj)
    284         f = self.dispatch.get(t)
    285         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; f:
--&amp;gt; 286             f(self, obj) # Call unbound method with explicit self
    287             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
    288 

/home/ubuntu/databricks/spark/python/pyspark/cloudpickle.pyc in save_function(self, obj, name)
    191         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; islambda(obj) or obj.__code__.co_filename == &lt;span class=&quot;code-quote&quot;&gt;&apos;&amp;lt;stdin&amp;gt;&apos;&lt;/span&gt; or themodule is None:
    192             #print(&lt;span class=&quot;code-quote&quot;&gt;&quot;save global&quot;&lt;/span&gt;, islambda(obj), obj.__code__.co_filename, modname, themodule)
--&amp;gt; 193             self.save_function_tuple(obj)
    194             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
    195         &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:

/home/ubuntu/databricks/spark/python/pyspark/cloudpickle.pyc in save_function_tuple(self, func)
    240         # save the &lt;span class=&quot;code-keyword&quot;&gt;rest&lt;/span&gt; of the func data needed by _fill_function
    241         save(f_globals)
--&amp;gt; 242         save(defaults)
    243         save(dct)
    244         write(pickle.TUPLE)

/usr/lib/python2.7/pickle.pyc in save(self, obj)
    284         f = self.dispatch.get(t)
    285         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; f:
--&amp;gt; 286             f(self, obj) # Call unbound method with explicit self
    287             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
    288 

/usr/lib/python2.7/pickle.pyc in save_tuple(self, obj)
    546         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; n &amp;lt;= 3 and proto &amp;gt;= 2:
    547             &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; element in obj:
--&amp;gt; 548                 save(element)
    549             # Subtle.  Same as in the big comment below.
    550             &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; id(obj) in memo:

/usr/lib/python2.7/pickle.pyc in save(self, obj)
    284         f = self.dispatch.get(t)
    285         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; f:
--&amp;gt; 286             f(self, obj) # Call unbound method with explicit self
    287             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;
    288 

/home/ubuntu/databricks/spark/python/pyspark/cloudpickle.pyc in save_builtin_function(self, obj)
    313         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; obj.__module__ is &lt;span class=&quot;code-quote&quot;&gt;&quot;__builtin__&quot;&lt;/span&gt;:
    314             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.save_global(obj)
--&amp;gt; 315         &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.save_function(obj)
    316     dispatch[types.BuiltinFunctionType] = save_builtin_function
    317 

/home/ubuntu/databricks/spark/python/pyspark/cloudpickle.pyc in save_function(self, obj, name)
    189         # we&apos;ll pickle the actual function object rather than simply saving a
    190         # reference (as is done in &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; pickler), via save_function_tuple.
--&amp;gt; 191         &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; islambda(obj) or obj.__code__.co_filename == &lt;span class=&quot;code-quote&quot;&gt;&apos;&amp;lt;stdin&amp;gt;&apos;&lt;/span&gt; or themodule is None:
    192             #print(&lt;span class=&quot;code-quote&quot;&gt;&quot;save global&quot;&lt;/span&gt;, islambda(obj), obj.__code__.co_filename, modname, themodule)
    193             self.save_function_tuple(obj)

AttributeError: &lt;span class=&quot;code-quote&quot;&gt;&apos;builtin_function_or_method&apos;&lt;/span&gt; object has no attribute &lt;span class=&quot;code-quote&quot;&gt;&apos;__code__&apos;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12863155">SPARK-10542</key>
            <summary>The  PySpark 1.5 closure serializer can&apos;t serialize a namedtuple instance.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="davies">Davies Liu</reporter>
                        <labels>
                    </labels>
                <created>Thu, 10 Sep 2015 18:48:41 +0000</created>
                <updated>Tue, 15 Sep 2015 02:49:50 +0000</updated>
                            <resolved>Tue, 15 Sep 2015 02:49:50 +0000</resolved>
                                    <version>1.5.0</version>
                                    <fixVersion>1.5.1</fixVersion>
                    <fixVersion>1.6.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14739468" author="apachespark" created="Thu, 10 Sep 2015 19:52:02 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8707&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8707&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12863163">SPARK-10544</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 10 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2k0in:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12333108">1.5.1</customfieldvalue>
    <customfieldvalue id="12333083">1.6.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>