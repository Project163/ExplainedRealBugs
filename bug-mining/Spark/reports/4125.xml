<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:48:11 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17368] Scala value classes create encoder problems and break at runtime</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17368</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Using Scala value classes as the inner type for Datasets breaks in Spark 2.0 and 1.6.X.&lt;/p&gt;

&lt;p&gt;This simple Spark 2 application demonstrates that the code will compile, but will break at runtime with the error. The value class is of course &lt;b&gt;FeatureId&lt;/b&gt;, as it extends AnyVal.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;main&quot; java.lang.RuntimeException: Error while encoding: java.lang.RuntimeException: Couldn&apos;t find v on int
assertnotnull(input[0, int, true], top level non-flat input object).v AS v#0
+- assertnotnull(input[0, int, true], top level non-flat input object).v
   +- assertnotnull(input[0, int, true], top level non-flat input object)
      +- input[0, int, true]&quot;.
        at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder.toRow(ExpressionEncoder.scala:279)
        at org.apache.spark.sql.SparkSession$$anonfun$3.apply(SparkSession.scala:421)
        at org.apache.spark.sql.SparkSession$$anonfun$3.apply(SparkSession.scala:421)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test code for Spark 2.0.0:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;import org.apache.spark.sql.{Dataset, SparkSession}

object BreakSpark {
  case class FeatureId(v: Int) extends AnyVal

  def main(args: Array[String]): Unit = {
    val seq = Seq(FeatureId(1), FeatureId(2), FeatureId(3))
    val spark = SparkSession.builder.getOrCreate()
    import spark.implicits._
    spark.sparkContext.setLogLevel(&quot;warn&quot;)
    val ds: Dataset[FeatureId] = spark.createDataset(seq)
    println(s&quot;BREAK HERE: ${ds.count}&quot;)
  }
}

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;JDK 8 on MacOS&lt;br/&gt;
Scala 2.11.8&lt;br/&gt;
Spark 2.0.0&lt;/p&gt;</environment>
        <key id="13002196">SPARK-17368</key>
            <summary>Scala value classes create encoder problems and break at runtime</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jodersky">Jakob Odersky</assignee>
                                    <reporter username="arisofalaska@gmail.com">Aris Vlasakakis</reporter>
                        <labels>
                    </labels>
                <created>Thu, 1 Sep 2016 23:12:09 +0000</created>
                <updated>Sat, 25 Aug 2018 09:09:11 +0000</updated>
                            <resolved>Fri, 14 Oct 2016 00:48:34 +0000</resolved>
                                    <version>1.6.2</version>
                    <version>2.0.0</version>
                                    <fixVersion>2.1.0</fixVersion>
                                    <component>Spark Core</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15456966" author="jodersky" created="Thu, 1 Sep 2016 23:45:21 +0000"  >&lt;p&gt;FYI the issue also occurs for top-level value classes (i.e. &lt;tt&gt;FeatureId&lt;/tt&gt; defined outside of &lt;tt&gt;object BreakSpark&lt;/tt&gt;)&lt;/p&gt;

&lt;p&gt;Please also be aware that the given example will &lt;b&gt;not compile&lt;/b&gt; in a spark shell. See this related issue &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-17367&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-17367&lt;/a&gt; regarding the definition of value classes in the REPL.&lt;/p&gt;</comment>
                            <comment id="15456979" author="arisofalaska@gmail.com" created="Thu, 1 Sep 2016 23:52:24 +0000"  >&lt;p&gt;Yes, agreed that this code cannot be pasted into &lt;tt&gt;spark-shell&lt;/tt&gt;. My assumption was that this would be a compiled JAR and then passed into &lt;tt&gt;spark-submit&lt;/tt&gt; &amp;#8211; a normal Spark application. When you do so, the code compiles but Spark breaks at runtime.&lt;/p&gt;</comment>
                            <comment id="15459587" author="jodersky" created="Fri, 2 Sep 2016 21:04:33 +0000"  >&lt;p&gt;I&apos;m currently taking a look at this but my first analysis is not very positive: considering that value classes are pure compile-time constructs I think it isn&apos;t possible to do anything with them through reflection, which Catalyst assumes.&lt;br/&gt;
Here&apos;s a relevant blog post &lt;a href=&quot;http://tech.kinja.com/scala-value-classes-and-reflection-here-be-dragons-1527846740&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://tech.kinja.com/scala-value-classes-and-reflection-here-be-dragons-1527846740&lt;/a&gt;&lt;br/&gt;
I&apos;ll check it out in a bit more detail but I fear that we&apos;ll have to resolve this as a won&apos;t fix and not support value classes in Datasets &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="15459649" author="arisofalaska@gmail.com" created="Fri, 2 Sep 2016 21:30:50 +0000"  >&lt;p&gt;I actually had an identical first thought from my experience of value classes and how they disappear in the JVM byte code. It would be very helpful if in the documentation somewhere that it was said that Scala value classes were explicitly not supported by spark datasets. The error messages are extremely cryptic and very confusing. Even better would be some kind of macro support or whatever else by Spark that would find and call it out of your code, but that&apos;s wishful thinking.&lt;/p&gt;</comment>
                            <comment id="15459707" author="jodersky" created="Fri, 2 Sep 2016 22:00:09 +0000"  >&lt;p&gt;Yeah macros would be awesome, something with Scala.meta would be neat &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; In the mean time it occurred to me that Catalyst uses ClassTags to do reflection in lots of places. These are generated during compile-time, so it might just yet be possible to support value classes.&lt;br/&gt;
A quick test showed me that value classes can be detected and their parameters accessed. Getting a Schema for such a case is trivial, I&apos;ll see about adding encoders next!&lt;/p&gt;</comment>
                            <comment id="15468833" author="jodersky" created="Tue, 6 Sep 2016 22:35:40 +0000"  >&lt;p&gt;So I thought about this a bit more and although it is possible to support value classes, I currently see two main issues that make it cumbersome:&lt;/p&gt;

&lt;p&gt;1. Catalyst (the engine behind Datasets) generates and compiles code during runtime, that will represent the actual computation. This code being Java, together with the fact that value classes don&apos;t have runtime representations, will require changes in the implementation of Encoders (see my experimental branch &lt;a href=&quot;https://github.com/apache/spark/compare/master...jodersky:value-classes&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;2. The largest problem of both is how will encoders for value classes be accessible? Currently, encoders are exposed as type classes and there is unfortunately no way to create type classes for classes extending AnyVal (you could create an encoder for AnyVals, however that would also apply to any primitive type and you would get implicit resolution conflicts). Requiring explicit encoders for value classes may work, however you would still have no compile-time safety, as accessing of a value class&apos; inner val will occur during runtime and may hence fail if it is not encodable.&lt;/p&gt;

&lt;p&gt;The cleanest solution would be to use meta programming: it would guarantee &quot;encodability&quot; during compile-time and could easily complement the current API. Unfortunately however, I don&apos;t think it could be included in Spark in the near future as the current meta programming solutions in Scala are either too new (scala.meta) or on their way to being deprecated (the current experimental scala macros). (I have been wanting to experiment with meta encoders for a while though, so maybe I&apos;ll try putting together an external library for that)&lt;/p&gt;

&lt;p&gt;How inconvenient is it to extract the wrapped value before creating a dataset and re-wrapping your final results?&lt;/p&gt;</comment>
                            <comment id="15469564" author="arisofalaska@gmail.com" created="Wed, 7 Sep 2016 05:04:01 +0000"  >&lt;p&gt;It goes from inconvenient to actually prohibitive in a practical sense. I have a Dataset&lt;span class=&quot;error&quot;&gt;&amp;#91;Something&amp;#93;&lt;/span&gt;, and inside case class Something I have various other case classes, and somewhere inside there there is a particular value class. It is so crazy to do manual unwrapping and rewrapping that at this point I just decided to eat the performance cost and use a regular class, not value class (I removed the &apos;extends AnyVal&apos;).&lt;/p&gt;

&lt;p&gt;More generally, specially accommodating for value classes is &lt;b&gt;really hard&lt;/b&gt; in a practical setting because if I have a whole bunch of ADTs and other case classes I&apos;m working with, how do I know if anywhere in my domain I used a &lt;b&gt;value class&lt;/b&gt; and I suddenly have to jump through a bunch of hoops just so Spark doesn&apos;t blow up? If I just had a Dataset&lt;span class=&quot;error&quot;&gt;&amp;#91;ThisIsAValueClass&amp;#93;&lt;/span&gt; with the top-level class being a value class, what you&apos;re saying is easy, but in practice the value class is one of many things somewhere deeper.&lt;/p&gt;</comment>
                            <comment id="15469933" author="srowen" created="Wed, 7 Sep 2016 07:58:51 +0000"  >&lt;p&gt;I get the problem, but is there actually any solution? this is a compile-time construct.&lt;/p&gt;</comment>
                            <comment id="15471428" author="jodersky" created="Wed, 7 Sep 2016 18:27:19 +0000"  >&lt;p&gt;Hmm, you&apos;re right my assumption was of using only value classes in the beginning and at the end was too naive.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt;, how likely do you think it is that we can include a meta-encoder in Spark? It could be included in the form of an optional import. Since the existing encoders/ScalaReflection framework already use runtime-reflection, my guess is that adding compile-time reflection will not be too difficult.&lt;/p&gt;</comment>
                            <comment id="15471450" author="srowen" created="Wed, 7 Sep 2016 18:35:42 +0000"  >&lt;p&gt;This is beyond my knowledge I&apos;m afraid. I&apos;d help take a look if I can but not sure I&apos;d know where to start on it myself!&lt;/p&gt;</comment>
                            <comment id="15530989" author="apachespark" created="Wed, 28 Sep 2016 21:52:04 +0000"  >&lt;p&gt;User &apos;jodersky&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15284&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15284&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15573700" author="marmbrus" created="Fri, 14 Oct 2016 00:48:34 +0000"  >&lt;p&gt;Issue resolved by pull request 15284&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15284&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15284&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15582882" author="jodersky" created="Mon, 17 Oct 2016 17:39:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=arisofalaska%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;arisofalaska@gmail.com&quot;&gt;arisofalaska@gmail.com&lt;/a&gt; Let me explain the fix to what I thought was initially impossible.&lt;br/&gt;
Value classes do have a class-representation for compatibility with Java, and although this will have a slight overhead compared to the primitive counterpart, catalyst will mostly negate that overhead by proving its own encoders and operators on serialized objects. This means that any operations on datasets that allow user defined functions (e.g. `map`, `filter` etc) will work with the class representation instead of the wrapped value.&lt;br/&gt;
Regarding the availability of encoders: while we cannot create type-classes that apply only to value classes (an implicit for `AnyVal` will also be applied to primitive types), without resorting to macros, this fix adds value class support to existing encoders. E.g. you can define your value class as a case class and have a working encoder out-of-the-box.&lt;br/&gt;
Unfortunately there is no way to statically verify that the wrapped value is also encodable, but encoders in general will perform &quot;deep inspection&quot; during runtime.&lt;/p&gt;</comment>
                            <comment id="15583873" author="arisofalaska@gmail.com" created="Mon, 17 Oct 2016 23:48:06 +0000"  >&lt;p&gt;That is great, thank you for the help with this.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13002180">SPARK-17367</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13065016">SPARK-20384</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 5 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i335pz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>