<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:26:17 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-35287] RemoveRedundantProjects removes non-redundant projects</title>
                <link>https://issues.apache.org/jira/browse/SPARK-35287</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;RemoveRedundantProjects erroneously removes non-redundant projects which are required to convert rows coming from DataSourceV2ScanExec to UnsafeRow. There is a code for this case, but it only looks at the child. The bug occurs when DataSourceV2ScanExec is not a child of the project, but a descendant. The method &lt;tt&gt;isRedundant&lt;/tt&gt; in &lt;tt&gt;RemoveRedundantProjects&lt;/tt&gt;&#160;should be updated to account for descendants too.&lt;/p&gt;

&lt;p&gt;The original scenario requires Iceberg to reproduce the issue. In theory, it should be able to reproduce the bug with Spark SQL only, and someone more knowledgeable with Spark SQL should be able to make such a scenario. The following is my reproduction scenario (Spark 3.1.1, Iceberg 0.11.1):&#160;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.collection.JavaConverters._

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.iceberg.{PartitionSpec, TableProperties}
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.iceberg.hadoop.HadoopTables
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.iceberg.spark.SparkSchemaUtil
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.{DataFrame, QueryTest, SparkSession}
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.internal.SQLConf

&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;RemoveRedundantProjectsTest &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; QueryTest {
  override val spark: SparkSession = SparkSession
    .builder()
    .master(&lt;span class=&quot;code-quote&quot;&gt;&quot;local[4]&quot;&lt;/span&gt;)
    .config(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.driver.bindAddress&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;127.0.0.1&quot;&lt;/span&gt;)
    .appName(suiteName)
    .getOrCreate()
  test(&lt;span class=&quot;code-quote&quot;&gt;&quot;RemoveRedundantProjects removes non-redundant projects&quot;&lt;/span&gt;) {
    withSQLConf(
      SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key -&amp;gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-1&quot;&lt;/span&gt;,
      SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -&amp;gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;,
      SQLConf.REMOVE_REDUNDANT_PROJECTS_ENABLED.key -&amp;gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;) {
      withTempDir { dir =&amp;gt;
        val path = dir.getCanonicalPath
        val data = spark.range(3).toDF
        val table = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HadoopTables().create(
          SparkSchemaUtil.convert(data.schema),
          PartitionSpec.unpartitioned(),
          Map(TableProperties.WRITE_NEW_DATA_LOCATION -&amp;gt; path).asJava,
          path)
        data.write.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;iceberg&quot;&lt;/span&gt;).mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).save(path)
        table.refresh()

        val df = spark.read.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;iceberg&quot;&lt;/span&gt;).load(path)
        val dfX = df.as(&lt;span class=&quot;code-quote&quot;&gt;&quot;x&quot;&lt;/span&gt;)
        val dfY = df.as(&lt;span class=&quot;code-quote&quot;&gt;&quot;y&quot;&lt;/span&gt;)
        val join = dfX.filter(dfX(&lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;) &amp;gt; 0).join(dfY, &lt;span class=&quot;code-quote&quot;&gt;&quot;id&quot;&lt;/span&gt;)
        join.explain(&lt;span class=&quot;code-quote&quot;&gt;&quot;extended&quot;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;assert&lt;/span&gt;(join.count() == 2)
      }
    }
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Stack trace:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[info] - RemoveRedundantProjects removes non-redundant projects *** FAILED ***
[info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 4) (xeroxms100.northamerica.corp.microsoft.com executor driver): java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericInternalRow cannot be cast to org.apache.spark.sql.catalyst.expressions.UnsafeRow
[info]  at org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:226)
[info]  at org.apache.spark.sql.execution.SortExec.$anonfun$doExecute$1(SortExec.scala:119)
[info]  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
[info]  at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
[info]  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[info]  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[info]  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[info]  at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[info]  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[info]  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[info]  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[info]  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[info]  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[info]  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[info]  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[info]  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[info]  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[info]  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[info]  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[info]  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[info]  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[info]  at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[info]  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
[info]  at org.apache.spark.scheduler.Task.run(Task.scala:131)
[info]  at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
[info]  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
[info]  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
[info]  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[info]  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[info]  at java.lang.Thread.run(Thread.java:748)
[info]
[info] Driver stacktrace:
[info]   at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)
[info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)
[info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)
[info]   at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
[info]   at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
[info]   at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
[info]   at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)
[info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)
[info]   at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)
[info]   at scala.Option.foreach(Option.scala:407)
[info]   ...
[info]   Cause: java.lang.ClassCastException: org.apache.spark.sql.catalyst.expressions.GenericInternalRow cannot be cast to org.apache.spark.sql.catalyst.expressions.UnsafeRow
[info]   at org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:226)
[info]   at org.apache.spark.sql.execution.SortExec.$anonfun$doExecute$1(SortExec.scala:119)
[info]   at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)
[info]   at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)
[info]   at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
[info]   at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[info]   at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[info]   at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)
[info]   at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)
[info]   at org.apache.spark.rdd.RDD.iterator(RDD.scala:337)
[info]   ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13376217">SPARK-35287</key>
            <summary>RemoveRedundantProjects removes non-redundant projects</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sarutak">Kousuke Saruta</assignee>
                                    <reporter username="chungmin">Chungmin</reporter>
                        <labels>
                    </labels>
                <created>Sat, 1 May 2021 15:24:33 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:39 +0000</updated>
                            <resolved>Mon, 24 May 2021 16:27:00 +0000</resolved>
                                    <version>3.1.1</version>
                                    <fixVersion>3.2.0</fixVersion>
                    <fixVersion>3.1.3</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17338291" author="gurwls223" created="Mon, 3 May 2021 10:19:21 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aokolnychyi&quot; class=&quot;user-hover&quot; rel=&quot;aokolnychyi&quot;&gt;aokolnychyi&lt;/a&gt;&#160;FYI&lt;/p&gt;</comment>
                            <comment id="17348184" author="apachespark" created="Thu, 20 May 2021 09:34:56 +0000"  >&lt;p&gt;User &apos;sarutak&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/32606&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/32606&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17350511" author="cloud_fan" created="Mon, 24 May 2021 16:27:00 +0000"  >&lt;p&gt;Issue resolved by pull request 32606&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/32606&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/32606&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 25 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0qnfs:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>