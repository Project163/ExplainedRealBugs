<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:40:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-11327] spark-dispatcher doesn&apos;t pass along some spark properties</title>
                <link>https://issues.apache.org/jira/browse/SPARK-11327</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I haven&apos;t figured out exactly what&apos;s going on yet, but there&apos;s something in the spark-dispatcher which is failing to pass along properties to the spark-driver when using spark-submit in a clustered mesos docker environment.&lt;/p&gt;

&lt;p&gt;Most importantly, it&apos;s not passing along spark.mesos.executor.docker.image.&lt;/p&gt;

&lt;p&gt;cli:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;docker run -t -i --rm --net=host --entrypoint=/usr/local/spark/bin/spark-submit docker.example.com/spark:2015.10.2 --conf spark.driver.memory=8G --conf spark.mesos.executor.docker.image=docker.example.com/spark:2015.10.2 --master mesos:&lt;span class=&quot;code-comment&quot;&gt;//spark-dispatcher.example.com:31262 --deploy-mode cluster --properties-file /usr/local/spark/conf/spark-defaults.conf --&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;com.example.spark.streaming.MyApp http://jarserver.example.com:8000/sparkapp.jar zk1.example.com:2181 spark-testing my-stream 40&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;submit output:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/10/26 22:03:53 INFO RestSubmissionClient: Submitting a request to launch an application in mesos:&lt;span class=&quot;code-comment&quot;&gt;//compute1.example.com:31262.
&lt;/span&gt;15/10/26 22:03:53 DEBUG RestSubmissionClient: Sending POST request to server at http:&lt;span class=&quot;code-comment&quot;&gt;//compute1.example.com:31262/v1/submissions/create:
&lt;/span&gt;{
  &lt;span class=&quot;code-quote&quot;&gt;&quot;action&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;CreateSubmissionRequest&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;appArgs&quot;&lt;/span&gt; : [ &lt;span class=&quot;code-quote&quot;&gt;&quot;zk1.example.com:2181&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;spark-testing&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;requests&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;40&quot;&lt;/span&gt; ],
  &lt;span class=&quot;code-quote&quot;&gt;&quot;appResource&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;http:&lt;span class=&quot;code-comment&quot;&gt;//jarserver.example.com:8000/sparkapp.jar&quot;&lt;/span&gt;,
&lt;/span&gt;  &lt;span class=&quot;code-quote&quot;&gt;&quot;clientSparkVersion&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;1.5.0&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;environmentVariables&quot;&lt;/span&gt; : {
    &lt;span class=&quot;code-quote&quot;&gt;&quot;SPARK_SCALA_VERSION&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;2.10&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;SPARK_CONF_DIR&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;/usr/local/spark/conf&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;SPARK_HOME&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;/usr/local/spark&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;SPARK_ENV_LOADED&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;1&quot;&lt;/span&gt;
  },
  &lt;span class=&quot;code-quote&quot;&gt;&quot;mainClass&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;com.example.spark.streaming.MyApp&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;sparkProperties&quot;&lt;/span&gt; : {
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.serializer&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.spark.serializer.KryoSerializer&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.executorEnv.MESOS_NATIVE_JAVA_LIBRARY&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;/usr/local/lib/libmesos.so&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.history.fs.logDirectory&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hdfsha.example.com/spark/logs&quot;&lt;/span&gt;,
&lt;/span&gt;    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.eventLog.enabled&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.driver.maxResultSize&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;0&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.mesos.deploy.recoveryMode&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;ZOOKEEPER&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.mesos.deploy.zookeeper.url&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;zk1.example.com:2181,zk2.example.com:2181,zk3.example.com:2181,zk4.example.com:2181,zk5.example.com:2181&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.jars&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;http:&lt;span class=&quot;code-comment&quot;&gt;//jarserver.example.com:8000/sparkapp.jar&quot;&lt;/span&gt;,
&lt;/span&gt;    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.driver.supervise&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.app.name&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;com.example.spark.streaming.MyApp&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.driver.memory&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;8G&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.logConf&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.deploy.zookeeper.dir&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;/spark_mesos_dispatcher&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.mesos.executor.docker.image&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;docker.example.com/spark-prod:2015.10.2&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.submit.deployMode&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;cluster&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.master&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;mesos:&lt;span class=&quot;code-comment&quot;&gt;//compute1.example.com:31262&quot;&lt;/span&gt;,
&lt;/span&gt;    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.executor.memory&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;8G&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.eventLog.dir&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hdfsha.example.com/spark/logs&quot;&lt;/span&gt;,
&lt;/span&gt;    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.mesos.docker.executor.network&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;HOST&quot;&lt;/span&gt;,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.mesos.executor.home&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;/usr/local/spark&quot;&lt;/span&gt;
  }
}
15/10/26 22:03:53 DEBUG RestSubmissionClient: Response from the server:
{
  &lt;span class=&quot;code-quote&quot;&gt;&quot;action&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;CreateSubmissionResponse&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;serverSparkVersion&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;1.5.0&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;submissionId&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;driver-20151026220353-0011&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;success&quot;&lt;/span&gt; : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
}
15/10/26 22:03:53 INFO RestSubmissionClient: Submission successfully created as driver-20151026220353-0011. Polling submission state...
15/10/26 22:03:53 INFO RestSubmissionClient: Submitting a request &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the status of submission driver-20151026220353-0011 in mesos:&lt;span class=&quot;code-comment&quot;&gt;//compute1.example.com:31262.
&lt;/span&gt;15/10/26 22:03:53 DEBUG RestSubmissionClient: Sending GET request to server at http:&lt;span class=&quot;code-comment&quot;&gt;//compute1.example.com:31262/v1/submissions/status/driver-20151026220353-0011.
&lt;/span&gt;15/10/26 22:03:53 DEBUG RestSubmissionClient: Response from the server:
{
  &lt;span class=&quot;code-quote&quot;&gt;&quot;action&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;SubmissionStatusResponse&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;driverState&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;QUEUED&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;serverSparkVersion&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;1.5.0&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;submissionId&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;driver-20151026220353-0011&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;success&quot;&lt;/span&gt; : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
}
15/10/26 22:03:53 INFO RestSubmissionClient: State of driver driver-20151026220353-0011 is now QUEUED.
15/10/26 22:03:53 INFO RestSubmissionClient: Server responded with CreateSubmissionResponse:
{
  &lt;span class=&quot;code-quote&quot;&gt;&quot;action&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;CreateSubmissionResponse&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;serverSparkVersion&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;1.5.0&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;submissionId&quot;&lt;/span&gt; : &lt;span class=&quot;code-quote&quot;&gt;&quot;driver-20151026220353-0011&quot;&lt;/span&gt;,
  &lt;span class=&quot;code-quote&quot;&gt;&quot;success&quot;&lt;/span&gt; : &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;driver log:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/10/26 22:08:08 INFO SparkContext: Running Spark version 1.5.0
15/10/26 22:08:08 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
15/10/26 22:08:08 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
15/10/26 22:08:08 DEBUG MutableMetricsFactory: field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, type=DEFAULT, valueName=Time, value=[GetGroups])
15/10/26 22:08:08 DEBUG MetricsSystemImpl: UgiMetrics, User and group related metrics
15/10/26 22:08:08 DEBUG KerberosName: Kerberos krb5 configuration not found, setting &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; realm to empty
15/10/26 22:08:08 DEBUG Groups:  Creating &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Groups object
15/10/26 22:08:08 DEBUG NativeCodeLoader: Trying to load the custom-built &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library...
15/10/26 22:08:08 DEBUG NativeCodeLoader: Failed to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
15/10/26 22:08:08 DEBUG NativeCodeLoader: java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
15/10/26 22:08:08 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
15/10/26 22:08:08 DEBUG PerformanceAdvisory: Falling back to shell based
15/10/26 22:08:08 DEBUG JniBasedUnixGroupsMappingWithFallback: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
15/10/26 22:08:08 DEBUG Shell: Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.&amp;lt;clinit&amp;gt;(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.&amp;lt;clinit&amp;gt;(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:130)
	at org.apache.hadoop.security.Groups.&amp;lt;init&amp;gt;(Groups.java:94)
	at org.apache.hadoop.security.Groups.&amp;lt;init&amp;gt;(Groups.java:74)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:303)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:804)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2084)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2084)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2084)
	at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:310)
	at org.apache.spark.streaming.StreamingContext$.createNewSparkContext(StreamingContext.scala:847)
	at org.apache.spark.streaming.StreamingContext.&amp;lt;init&amp;gt;(StreamingContext.scala:81)
	at org.apache.spark.streaming.api.java.JavaStreamingContext.&amp;lt;init&amp;gt;(JavaStreamingContext.scala:134)
	at com.example.spark.streaming.MyApp.main(MyApp.java:63)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
15/10/26 22:08:08 DEBUG Shell: setsid exited with exit code 0
15/10/26 22:08:08 DEBUG Groups: Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
15/10/26 22:08:08 DEBUG UserGroupInformation: hadoop login
15/10/26 22:08:08 DEBUG UserGroupInformation: hadoop login commit
15/10/26 22:08:08 DEBUG UserGroupInformation: using local user:UnixPrincipal: root
15/10/26 22:08:08 DEBUG UserGroupInformation: Using user: &lt;span class=&quot;code-quote&quot;&gt;&quot;UnixPrincipal: root&quot;&lt;/span&gt; with name root
15/10/26 22:08:08 DEBUG UserGroupInformation: User entry: &lt;span class=&quot;code-quote&quot;&gt;&quot;root&quot;&lt;/span&gt;
15/10/26 22:08:08 DEBUG UserGroupInformation: UGI loginUser:root (auth:SIMPLE)
15/10/26 22:08:08 INFO SparkContext: Spark configuration:
spark.app.name=MyApp
spark.deploy.zookeeper.dir=/spark_mesos_dispatcher
spark.driver.maxResultSize=0
spark.driver.memory=8192M
spark.eventLog.dir=hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hdfsha.example.com/spark/logs
&lt;/span&gt;spark.eventLog.enabled=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
spark.executor.memory=8G
spark.executorEnv.MESOS_NATIVE_JAVA_LIBRARY=/usr/local/lib/libmesos.so
spark.history.fs.logDirectory=hdfs:&lt;span class=&quot;code-comment&quot;&gt;//hdfsha.example.com/spark/logs
&lt;/span&gt;spark.jars=file:/&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;/lib/mesos/sandbox/sparkapp.jar
spark.logConf=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
spark.master=mesos:&lt;span class=&quot;code-comment&quot;&gt;//zk://zk1.example.com:2181/mesos
&lt;/span&gt;spark.mesos.deploy.recoveryMode=ZOOKEEPER
spark.mesos.deploy.zookeeper.url=zk1.example.com:2181,zk2.example.com:2181,zk3.example.com:2181,zk4.example.com:2181,zk5.example.com:2181
spark.mesos.docker.executor.network=HOST
spark.mesos.executor.home=/usr/local/spark
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.submit.deployMode=client
15/10/26 22:08:08 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: root
15/10/26 22:08:08 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: root
15/10/26 22:08:08 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)
15/10/26 22:08:08 DEBUG SSLOptions: No SSL protocol specified
15/10/26 22:08:08 DEBUG SSLOptions: No SSL protocol specified
15/10/26 22:08:08 DEBUG SSLOptions: No SSL protocol specified
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The timestamps are different because I don&apos;t know which machine the driver is going to be scheduled on, so after I know I did a docker start -ai &amp;lt;id&amp;gt; and got the logs that way.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12908048">SPARK-11327</key>
            <summary>spark-dispatcher doesn&apos;t pass along some spark properties</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jayv">Jo Voordeckers</assignee>
                                    <reporter username="abraithwaite">Alan Braithwaite</reporter>
                        <labels>
                    </labels>
                <created>Mon, 26 Oct 2015 22:40:13 +0000</created>
                <updated>Mon, 4 Apr 2016 20:30:55 +0000</updated>
                            <resolved>Thu, 31 Mar 2016 19:08:24 +0000</resolved>
                                                    <fixVersion>1.6.2</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>Mesos</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="14975280" author="abraithwaite" created="Mon, 26 Oct 2015 22:51:16 +0000"  >&lt;p&gt;This may warrant opening a separate issue, but perhaps how properties are passed through to the end application from submit could be better documented.  Right now, afaict, there are a number of ways that properties get defined in a job which it isn&apos;t clear which override which.&lt;/p&gt;

&lt;p&gt;Please let me know if you need any more information for this ticket.  (Getting spark-defaults.conf cleaned up now)&lt;/p&gt;</comment>
                            <comment id="14975844" author="srowen" created="Tue, 27 Oct 2015 07:00:50 +0000"  >&lt;p&gt;I may be being dense but what is spark-dispatcher? is this about code in Spark?&lt;/p&gt;</comment>
                            <comment id="14976530" author="abraithwaite" created="Tue, 27 Oct 2015 15:07:54 +0000"  >&lt;p&gt;It&apos;s the cluster mode manager for mesos.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/running-on-mesos.html#cluster-mode&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://spark.apache.org/docs/latest/running-on-mesos.html#cluster-mode&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14976559" author="srowen" created="Tue, 27 Oct 2015 15:29:27 +0000"  >&lt;p&gt;Does this entail a change for sbin/start-mesos-dispatcher.sh you mean? could be indeed. Can you open a PR to make the suggested change?&lt;/p&gt;</comment>
                            <comment id="14976561" author="srowen" created="Tue, 27 Oct 2015 15:29:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abraithwaite&quot; class=&quot;user-hover&quot; rel=&quot;abraithwaite&quot;&gt;abraithwaite&lt;/a&gt; setting the component would help here (&lt;a href=&quot;https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="14976587" author="abraithwaite" created="Tue, 27 Oct 2015 15:44:23 +0000"  >&lt;p&gt;Ah, sorry about that.  Thanks for the pointer.&lt;/p&gt;</comment>
                            <comment id="14976595" author="abraithwaite" created="Tue, 27 Oct 2015 15:47:08 +0000"  >&lt;p&gt;I don&apos;t think it&apos;s in the startup script.  We&apos;re running the java command directly using marathon/mesos.  (java -cp .. etc).  It&apos;s worked fine on my laptop before, but I suspect that&apos;s because it&apos;s pulling spark.mesos.executor.docker.image from spark-defaults.conf instead of the CLI.&lt;/p&gt;</comment>
                            <comment id="14989280" author="dragos" created="Wed, 4 Nov 2015 10:32:25 +0000"  >&lt;p&gt;I think this is related to (possibly a duplicate of) &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-11280&quot; title=&quot;Mesos cluster deployment using only one node&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-11280&quot;&gt;&lt;del&gt;SPARK-11280&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15009189" author="jayv" created="Tue, 17 Nov 2015 18:27:01 +0000"  >&lt;p&gt;I&apos;ve seen similar issues, when running on mesos (no docker tho). &lt;br/&gt;
The Mesos Dispatcher only sets the class, jar and cpu/mem resources when spinning up a new executor, all the spark properties (UI port, classpath order, system properties, jvm opts, etc...) passed to the dispatcher via spark-submit are not passed along in the commandline. &lt;/p&gt;

&lt;p&gt;I&apos;ve made a quick patch that solves this for me:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/9752/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/9752/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I need to debug some more, because &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dragos&quot; class=&quot;user-hover&quot; rel=&quot;dragos&quot;&gt;dragos&lt;/a&gt; found this, which suggests it does &quot;something&quot; with those args:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/jayv/spark/blob/mesos_cluster_params/core/src/main/scala/org/apache/spark/scheduler/cluster/mesos/MesosClusterScheduler.scala#L375-L377&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/jayv/spark/blob/mesos_cluster_params/core/src/main/scala/org/apache/spark/scheduler/cluster/mesos/MesosClusterScheduler.scala#L375-L377&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15009212" author="apachespark" created="Tue, 17 Nov 2015 18:38:03 +0000"  >&lt;p&gt;User &apos;jayv&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/9752&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/9752&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15009843" author="jayv" created="Tue, 17 Nov 2015 23:36:52 +0000"  >&lt;p&gt;I&apos;ve done more forensics on this:&lt;/p&gt;

&lt;p&gt;SPARK_EXECUTOR_OPTS gets populated with all the args in MesosClusterDispatcher.&lt;br/&gt;
The driver loaunched via SparkSubmit (executed from the dispatcher) doesn&apos;t care about SPARK_EXECUTOR_OPTS.&lt;br/&gt;
As a result, the driver doesn&apos;t see those properties, nor any of the jobs spawned from that driver.&lt;/p&gt;

&lt;p&gt;By appending the args onto the SparkSubmit call in the MesosClusterDispatcher as in my fix, makes sure that the driver gets the right properties and makes sure all properties are propagated all the way down to jobs spawned from the driver.&lt;/p&gt;

&lt;p&gt;I see 2 solutions here, either something along the lines of my patch or to make SparkSubmit aware of SPARK_EXECUTOR_OPTS. The latter involves parsing all variations of -Dfoo=bar and setting these system properties from inside the driver process, which I think is somewhat nasty and error prone.&lt;/p&gt;</comment>
                            <comment id="15009899" author="abraithwaite" created="Wed, 18 Nov 2015 00:14:11 +0000"  >&lt;p&gt;If you&apos;ve already got marathon deployed in your mesos cluster, what&apos;s the benefit to running jobs with spark-dispatcher instead of just making marathon configs to run spark jobs in client mode?&lt;/p&gt;</comment>
                            <comment id="15011339" author="dragos" created="Wed, 18 Nov 2015 16:36:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=abraithwaite&quot; class=&quot;user-hover&quot; rel=&quot;abraithwaite&quot;&gt;abraithwaite&lt;/a&gt; it&apos;s a valid question, but it&apos;s nevertheless a bug in Mesos cluster-mode..&lt;/p&gt;</comment>
                            <comment id="15064744" author="jayv" created="Fri, 18 Dec 2015 20:53:41 +0000"  >&lt;p&gt;This PR is now superseded by this one against master:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/10370&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10370&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15220508" author="jayv" created="Thu, 31 Mar 2016 19:19:23 +0000"  >&lt;p&gt;So who should I nudge to get it backported into 1.x ?&lt;/p&gt;</comment>
                            <comment id="15220762" author="apachespark" created="Thu, 31 Mar 2016 22:19:04 +0000"  >&lt;p&gt;User &apos;jayv&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12101&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12101&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12938052">SPARK-13258</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 33 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2njnj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12334910">1.6.2</customfieldvalue>
    <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>