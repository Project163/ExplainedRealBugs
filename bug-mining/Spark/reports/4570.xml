<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:51:23 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-19666] Exception when calling createDataFrame with typed RDD</title>
                <link>https://issues.apache.org/jira/browse/SPARK-19666</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; tmp = sc.parallelize(Seq(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; __Message()))
    val spark = SparkSession.builder().getOrCreate()
    &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; df = spark.createDataFrame(tmp, classOf[__Message])
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Produces this error message.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.NullPointerException
	at org.spark_project.guava.reflect.TypeToken.method(TypeToken.java:465)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:126)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:125)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.sql.catalyst.JavaTypeInference$.org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(JavaTypeInference.scala:125)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:127)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:125)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.sql.catalyst.JavaTypeInference$.org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(JavaTypeInference.scala:125)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:127)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:125)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.sql.catalyst.JavaTypeInference$.org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(JavaTypeInference.scala:125)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:127)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:125)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.sql.catalyst.JavaTypeInference$.org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(JavaTypeInference.scala:125)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:127)
	at org.apache.spark.sql.catalyst.JavaTypeInference$$anonfun$2.apply(JavaTypeInference.scala:125)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.IndexedSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186)
	at org.apache.spark.sql.catalyst.JavaTypeInference$.org$apache$spark$sql$catalyst$JavaTypeInference$$inferDataType(JavaTypeInference.scala:125)
	at org.apache.spark.sql.catalyst.JavaTypeInference$.inferDataType(JavaTypeInference.scala:55)
	at org.apache.spark.sql.SparkSession.getSchema(SparkSession.scala:708)
	at org.apache.spark.sql.SparkSession.createDataFrame(SparkSession.scala:347)
	at uk.co.gresearch.aggregator.Main$.main(Main.scala:46)
	at uk.co.gresearch.aggregator.Main.main(Main.scala)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13044537">SPARK-19666</key>
            <summary>Exception when calling createDataFrame with typed RDD</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gurwls223">Hyukjin Kwon</assignee>
                                    <reporter username="colinbreame">Colin Breame</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Feb 2017 12:13:53 +0000</created>
                <updated>Mon, 12 Dec 2022 18:11:11 +0000</updated>
                            <resolved>Wed, 22 Feb 2017 20:42:44 +0000</resolved>
                                    <version>2.1.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="15874798" author="maropu" created="Mon, 20 Feb 2017 16:49:05 +0000"  >&lt;p&gt;It&apos;d be better to put at least a simple query to reproduce the issue you&apos;ld like to report.&lt;br/&gt;
What&apos;s &quot;__Message&quot;?&lt;br/&gt;
A query below works well, so what&apos;s a different between this query and yours?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; :paste
&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;BeanClass &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Serializable {
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt;[&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;] &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; data: Int = 0
  def getData(): Int = data
  def setData(i: Int): Unit = { data = i }
}
scala&amp;gt; val rdd = sc.parallelize((0 until 10)).map { i =&amp;gt; val data = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BeanClass(); data.setData(i); data }
scala&amp;gt; val df = spark.createDataFrame(rdd, classOf[BeanClass])
scala&amp;gt; df.show
+----+
|data|
+----+
|   0|
|   1|
|   2|
|   3|
|   4|
|   5|
|   6|
|   7|
|   8|
|   9|
+----+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15875604" author="gurwls223" created="Tue, 21 Feb 2017 08:43:13 +0000"  >&lt;p&gt;Hm, probably the &lt;tt&gt;__Message&lt;/tt&gt; is an invalid java bean. Maybe, at least we could improve the error message.&lt;/p&gt;</comment>
                            <comment id="15875645" author="maropu" created="Tue, 21 Feb 2017 09:09:43 +0000"  >&lt;p&gt;In my case, when I passed a invalid bean, I got a empty DF;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; :paste
&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;BeanClass &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; Serializable {
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt;[&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;] &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; data: Int = 0
  def get(): Int = data
  def set(i: Int): Unit = { data = i }
}
scala&amp;gt; val rdd = sc.parallelize((0 until 10)).map { i =&amp;gt; val data = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BeanClass(); data.set(i); data }
rdd: org.apache.spark.rdd.RDD[BeanClass] = MapPartitionsRDD[1] at map at &amp;lt;console&amp;gt;:25
scala&amp;gt; val df = spark.createDataFrame(rdd, classOf[BeanClass])
df: org.apache.spark.sql.DataFrame = []
scala&amp;gt; df.show
++
||
++
||
||
||
||
||
||
||
||
||
||
++
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Even in this case, I want better error messages.&lt;br/&gt;
Probably, it seems okay to add error handling around here: &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/JavaTypeInference.scala#L124&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/JavaTypeInference.scala#L124&lt;/a&gt;&lt;br/&gt;
i.e.) If we get a empty `properties`, it just throws an AnalysisException, or something.&lt;/p&gt;</comment>
                            <comment id="15875670" author="apachespark" created="Tue, 21 Feb 2017 09:30:04 +0000"  >&lt;p&gt;User &apos;HyukjinKwon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17013&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17013&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15875672" author="gurwls223" created="Tue, 21 Feb 2017 09:30:22 +0000"  >&lt;p&gt;Ah, yes. I just tested some cases too. I could reproduce the (I assume) same case and proposed a PR.&lt;/p&gt;</comment>
                            <comment id="15875674" author="maropu" created="Tue, 21 Feb 2017 09:31:44 +0000"  >&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="15879191" author="cloud_fan" created="Wed, 22 Feb 2017 20:42:45 +0000"  >&lt;p&gt;Issue resolved by pull request 17013&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17013&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17013&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                            <outwardlinks description="contains">
                                        <issuelink>
            <issuekey id="13088410">SPARK-21473</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 38 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3abrr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>