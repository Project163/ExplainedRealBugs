<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:40:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-14103] Python DataFrame CSV load on large file is writing to console in Ipython</title>
                <link>https://issues.apache.org/jira/browse/SPARK-14103</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I am using the spark from the master branch and when I run the following command on a large tab separated file then I get the contents of the file being written to the stderr&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;, delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is a sample of output:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;^M[Stage 1:&amp;gt;                                                          (0 + 2) / 2]16/03/23 14:01:02 ERROR Executor: Exception in task 1.0 in stage 1.0 (TID 2)
com.univocity.parsers.common.TextParsingException: Error processing input: Length of parsed input (1000001) exceeds the maximum number of characters defined in your parser settings (1000000). Identified line separator characters in the parsed content. This may be the cause of the error. The line separator in your parser settings is set to &lt;span class=&quot;code-quote&quot;&gt;&apos;\n&apos;&lt;/span&gt;. Parsed content:
        Privacy-shake&quot;,: a haptic &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; managing privacy settings in mobile location sharing applications       privacy shake a haptic &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; managing privacy settings in mobile location sharing applications  2010    2010/09/07              international conference on human computer interaction  interact                43331058        19371[\n]        3D4F6CA1        Between the Profiles: Another such Bias. Technology Acceptance Studies on Social Network Services       between the profiles another such bias technology acceptance studies on social network services 2015    2015/08/02      10.1007/978-3-319-21383-5_12    international conference on human-computer interaction  interact                43331058        19502[\n]

.......

.........

web snippets    2008    2008/05/04      10.1007/978-3-642-01344-7_13    international conference on web information systems and technologies    webist          44F29802        19489
06FA3FFA        Interactive 3D User Interfaces &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Neuroanatomy Exploration     interactive 3d user interfaces &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; neuroanatomy exploration     2009                    internationa]
        at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:241)
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:356)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:137)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:120)
        at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:742)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foreach(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(TraversableOnce.scala:155)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foldLeft(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;aggregate(TraversableOnce.scala:212)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.aggregate(CSVParser.scala:120)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:69)
        at org.apache.spark.scheduler.Task.run(Task.scala:82)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException
16/03/23 14:01:03 ERROR TaskSetManager: Task 0 in stage 1.0 failed 1 times; aborting job
^M[Stage 1:&amp;gt;                                                          (0 + 1) / 2]


&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;For a small sample (&amp;lt;10,000 lines) of the data, I am not getting any error. But as soon as I go above more than 100,000 samples, I start getting the error. &lt;/p&gt;

&lt;p&gt;I don&apos;t think the spark platform should output the actual data to stderr ever as it decreases the readability. &lt;/p&gt;</description>
                <environment>&lt;p&gt;Ubuntu, Python 2.7.11, Anaconda 2.5.0, Spark from Master branch&lt;/p&gt;</environment>
        <key id="12952965">SPARK-14103</key>
            <summary>Python DataFrame CSV load on large file is writing to console in Ipython</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gurwls223">Hyukjin Kwon</assignee>
                                    <reporter username="shubhanshumishra@gmail.com">Shubhanshu Mishra</reporter>
                        <labels>
                            <label>csv</label>
                            <label>csvparser</label>
                            <label>dataframe</label>
                            <label>pyspark</label>
                    </labels>
                <created>Wed, 23 Mar 2016 20:22:38 +0000</created>
                <updated>Mon, 12 Dec 2022 18:11:05 +0000</updated>
                            <resolved>Fri, 8 Apr 2016 07:28:56 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15209096" author="srowen" created="Wed, 23 Mar 2016 20:25:40 +0000"  >&lt;p&gt;Isn&apos;t this saying that one &lt;em&gt;line&lt;/em&gt; is extremely long? The error pretty much tells you that.&lt;/p&gt;</comment>
                            <comment id="15214086" author="srowen" created="Mon, 28 Mar 2016 10:59:30 +0000"  >&lt;p&gt;I think you just have a line separator problem or similar... it&apos;s complaining that it can&apos;t parse it because the whole thing is one big line.&lt;/p&gt;</comment>
                            <comment id="15215027" author="shubhanshumishra@gmail.com" created="Mon, 28 Mar 2016 22:40:39 +0000"  >&lt;p&gt;Yes, the error does say so. However, I have checked the file. It has `\r\n` style line endings and otherwise looks perfectly file. &lt;/p&gt;

&lt;p&gt;I am able to process the file correctly using cut but am not able to do it using the CSV format reader. The maximum number of characters in a given line in my file are 697 with 97 as the minimum. &lt;/p&gt;

&lt;p&gt;It looks like the line ending characters are causing an issue and spark is normalizing the line ending character to be just &quot;\n&quot; instead of &quot;\r\n&quot;. &lt;/p&gt;

&lt;p&gt;I tried to run my command with the following settings and was able to prove this intuition:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [2]: df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;, delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;, rowSeparator=&lt;span class=&quot;code-quote&quot;&gt;&quot;\r\n&quot;&lt;/span&gt;, inputBufferSize=500, maxColumns=20, maxCharsPerColumn=1000)
16/03/28 17:17:39 ERROR Executor: Exception in task 1.0 in stage 3.0 (TID 5)    
com.univocity.parsers.common.TextParsingException: Error processing input: Length of parsed input (1001) exceeds the maximum number of characters defined in your parser settings (1000). 
Identified line separator characters in the parsed content. This may be the cause of the error. The line separator in your parser settings is set to &lt;span class=&quot;code-quote&quot;&gt;&apos;\n&apos;&lt;/span&gt;. Parsed content:
        I did it my way&quot;: moving away from the tyranny of turn-by-turn pedestrian navigation    i did it my way moving away from the tyranny of turn by turn pedestrian navigation      2010  2010/09/07       10.1145/1851600.1851660 international conference on human computer interaction  interact                43331058        18871[\n]
        770CA612        Fixed in time and &lt;span class=&quot;code-quote&quot;&gt;&quot;time in motion&quot;&lt;/span&gt;: mobility of vision through a SenseCam lens  fixed in time and time in motion mobility of vision through a sensecam lens     2009  2009/09/15       10.1145/1613858.1613861 international conference on human computer interaction  interact                43331058        19370[\n]
        7B5DE5DE        Assistive Wearable Technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Visually Impaired     assistive wearable technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; visually impaired     2015    2015/08/24              international conference on human computer interaction interact                43331058        19555[\n]
        085BEC09        HOUDINI: Introducing &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; Tracking and Pen Recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; LLP Tabletops      houdini introducing object tracking and pen recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; llp tabletops       2014  2014/06/22       10.1007/978-3-319-07230-2_23    international c
Parser Configuration: CsvParserSettings:
        Column reordering enabled=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Empty value=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        Header extraction enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Headers=[C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10]
        Ignore leading whitespaces=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Ignore trailing whitespaces=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Input buffer size=128
        Input reading on separate thread=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Line separator detection enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Maximum number of characters per column=1000
        Maximum number of columns=20
        Null value=
        &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of records to read=all
        Parse unescaped quotes=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Row processor=none
        Selected fields=none
        Skip empty lines=trueFormat configuration:
        CsvFormat:
                Comment character=\0
                Field delimiter=\t
                Line separator (normalized)=\n
                Line separator sequence=\n
                Quote character=&quot;
                Quote escape character=quote escape
                Quote escape escape character=\0, line=36, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;=9828. Content parsed: [I did it my way&quot;: moving away from the tyranny of turn-by-turn pedestrian navigation     i did it my way moving away from the tyranny of turn by turn pedestrian navigation     2010    2010/09/07      10.1145/1851600.1851660 international conference on human computer interaction  interact      43331058 18871
770CA612        Fixed in time and &lt;span class=&quot;code-quote&quot;&gt;&quot;time in motion&quot;&lt;/span&gt;: mobility of vision through a SenseCam lens  fixed in time and time in motion mobility of vision through a sensecam lens     2009    2009/09/15     10.1145/1613858.1613861 international conference on human computer interaction  interact                43331058        19370
7B5DE5DE        Assistive Wearable Technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Visually Impaired     assistive wearable technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; visually impaired     2015    2015/08/24              international conference on human computer interaction interact                43331058        19555
085BEC09        HOUDINI: Introducing &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; Tracking and Pen Recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; LLP Tabletops      houdini introducing object tracking and pen recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; llp tabletops       2014    2014/06/22     10.1007/978-3-319-07230-2_23    international c]
        at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:241)
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:356)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:137)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:120)
        at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:742)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foreach(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(TraversableOnce.scala:155)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foldLeft(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;aggregate(TraversableOnce.scala:212)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.aggregate(CSVParser.scala:120)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:69)
        at org.apache.spark.scheduler.Task.run(Task.scala:82)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException
16/03/28 17:17:39 ERROR TaskSetManager: Task 1 in stage 3.0 failed 1 times; aborting job
16/03/28 17:17:39 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 4)
com.univocity.parsers.common.TextParsingException: Error processing input: org.apache.spark.TaskKilledException - &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
Parser Configuration: CsvParserSettings:
        Column reordering enabled=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Empty value=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        Header extraction enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Headers=[C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10]
        Ignore leading whitespaces=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Ignore trailing whitespaces=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Input buffer size=128
        Input reading on separate thread=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Line separator detection enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Maximum number of characters per column=1000
        Maximum number of columns=20
        Null value=
        &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of records to read=all
        Parse unescaped quotes=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Row processor=none
        Selected fields=none
        Skip empty lines=trueFormat configuration:
        CsvFormat:
                Comment character=\0
                Field delimiter=\t
                Line separator (normalized)=\n
                Line separator sequence=\n
                Quote character=&quot;
                Quote escape character=quote escape
                Quote escape escape character=\0, line=706, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;=197760. Content parsed: [mexic]
        at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:241)
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:356)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:137)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:120)
        at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:742)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foreach(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(TraversableOnce.scala:155)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foldLeft(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;aggregate(TraversableOnce.scala:212)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.aggregate(CSVParser.scala:120)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:69)
        at org.apache.spark.scheduler.Task.run(Task.scala:82)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: org.apache.spark.TaskKilledException
        at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
        at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:369)
        at org.apache.spark.sql.execution.datasources.csv.StringIteratorReader.refill(CSVParser.scala:167)
        at org.apache.spark.sql.execution.datasources.csv.StringIteratorReader.read(CSVParser.scala:195)
        at org.apache.spark.sql.execution.datasources.csv.StringIteratorReader.read(CSVParser.scala:215)
        at com.univocity.parsers.common.input.DefaultCharInputReader.reloadBuffer(DefaultCharInputReader.java:81)
        at com.univocity.parsers.common.input.AbstractCharInputReader.updateBuffer(AbstractCharInputReader.java:118)
        at com.univocity.parsers.common.input.AbstractCharInputReader.nextChar(AbstractCharInputReader.java:180)
        at com.univocity.parsers.csv.CsvParser.parseValue(CsvParser.java:94)
        at com.univocity.parsers.csv.CsvParser.parseField(CsvParser.java:179)
        at com.univocity.parsers.csv.CsvParser.parseRecord(CsvParser.java:75)
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:328)
        ... 18 more
---------------------------------------------------------------------------
Py4JJavaError                             Traceback (most recent call last)
&amp;lt;ipython-input-2-cdfcc501837a&amp;gt; in &amp;lt;module&amp;gt;()
----&amp;gt; 1 df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;, delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;, rowSeparator=&lt;span class=&quot;code-quote&quot;&gt;&quot;\r\n&quot;&lt;/span&gt;, inputBufferSize=500, maxColumns=20, maxCharsPerColumn=1000)

/spark/python/pyspark/sql/readwriter.pyc in load(self, path, format, schema, **options)
    133             &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; type(path) != list:
    134                 path = [path]
--&amp;gt; 135             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self._df(self._jreader.load(self._sqlContext._sc._jvm.PythonUtils.toSeq(path)))
    136         &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
    137             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self._df(self._jreader.load())

/spark/python/lib/py4j-0.9.2-src.zip/py4j/java_gateway.py in __call__(self, *args)
    834         answer = self.gateway_client.send_command(command)
    835         return_value = get_return_value(
--&amp;gt; 836             answer, self.gateway_client, self.target_id, self.name)
    837 
    838         &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; temp_arg in temp_args:

/spark/python/pyspark/sql/utils.pyc in deco(*a, **kw)
     43     def deco(*a, **kw):
     44         &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;:
---&amp;gt; 45             &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; f(*a, **kw)
     46         except py4j.protocol.Py4JJavaError as e:
     47             s = e.java_exception.toString()

/spark/python/lib/py4j-0.9.2-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
    308                 raise Py4JJavaError(
    309                     &lt;span class=&quot;code-quote&quot;&gt;&quot;An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling {0}{1}{2}.\n&quot;&lt;/span&gt;.
--&amp;gt; 310                     format(target_id, &lt;span class=&quot;code-quote&quot;&gt;&quot;.&quot;&lt;/span&gt;, name), value)
    311             &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt;:
    312                 raise Py4JError(

Py4JJavaError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling o44.load.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3.0 (TID 5, localhost): com.univocity.parsers.common.TextParsingException: Error processing input: Length of parsed input (1001) exceeds the maximum number of characters defined in your parser settings (1000). 
Identified line separator characters in the parsed content. This may be the cause of the error. The line separator in your parser settings is set to &lt;span class=&quot;code-quote&quot;&gt;&apos;\n&apos;&lt;/span&gt;. Parsed content:
        I did it my way&quot;: moving away from the tyranny of turn-by-turn pedestrian navigation    i did it my way moving away from the tyranny of turn by turn pedestrian navigation      2010  2010/09/07       10.1145/1851600.1851660 international conference on human computer interaction  interact                43331058        18871[\n]
        770CA612        Fixed in time and &lt;span class=&quot;code-quote&quot;&gt;&quot;time in motion&quot;&lt;/span&gt;: mobility of vision through a SenseCam lens  fixed in time and time in motion mobility of vision through a sensecam lens     2009  2009/09/15       10.1145/1613858.1613861 international conference on human computer interaction  interact                43331058        19370[\n]
        7B5DE5DE        Assistive Wearable Technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Visually Impaired     assistive wearable technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; visually impaired     2015    2015/08/24              international conference on human computer interaction interact                43331058        19555[\n]
        085BEC09        HOUDINI: Introducing &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; Tracking and Pen Recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; LLP Tabletops      houdini introducing object tracking and pen recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; llp tabletops       2014  2014/06/22       10.1007/978-3-319-07230-2_23    international c
Parser Configuration: CsvParserSettings:
        Column reordering enabled=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Empty value=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        Header extraction enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Headers=[C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10]
        Ignore leading whitespaces=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Ignore trailing whitespaces=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Input buffer size=128
        Input reading on separate thread=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Line separator detection enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Maximum number of characters per column=1000
        Maximum number of columns=20
        Null value=
        &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of records to read=all
        Parse unescaped quotes=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Row processor=none
        Selected fields=none
        Skip empty lines=trueFormat configuration:
        CsvFormat:
                Comment character=\0
                Field delimiter=\t
                Line separator (normalized)=\n
                Line separator sequence=\n
                Quote character=&quot;
                Quote escape character=quote escape
                Quote escape escape character=\0, line=36, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;=9828. Content parsed: [I did it my way&quot;: moving away from the tyranny of turn-by-turn pedestrian navigation     i did it my way moving away from the tyranny of turn by turn pedestrian navigation     2010    2010/09/07      10.1145/1851600.1851660 international conference on human computer interaction  interact      43331058 18871
770CA612        Fixed in time and &lt;span class=&quot;code-quote&quot;&gt;&quot;time in motion&quot;&lt;/span&gt;: mobility of vision through a SenseCam lens  fixed in time and time in motion mobility of vision through a sensecam lens     2009    2009/09/15     10.1145/1613858.1613861 international conference on human computer interaction  interact                43331058        19370
7B5DE5DE        Assistive Wearable Technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Visually Impaired     assistive wearable technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; visually impaired     2015    2015/08/24              international conference on human computer interaction interact                43331058        19555
085BEC09        HOUDINI: Introducing &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; Tracking and Pen Recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; LLP Tabletops      houdini introducing object tracking and pen recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; llp tabletops       2014    2014/06/22     10.1007/978-3-319-07230-2_23    international c]
        at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:241)
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:356)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:137)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:120)
        at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:742)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foreach(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(TraversableOnce.scala:155)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foldLeft(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;aggregate(TraversableOnce.scala:212)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.aggregate(CSVParser.scala:120)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:69)
        at org.apache.spark.scheduler.Task.run(Task.scala:82)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException

Driver stacktrace:
        at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1457)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1445)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1444)
        at scala.collection.mutable.ResizableArray$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
        at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1444)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:809)
        at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:809)
        at scala.Option.foreach(Option.scala:257)
        at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:809)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1666)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1625)
        at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1614)
        at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
        at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1765)
        at org.apache.spark.SparkContext.runJob(SparkContext.scala:1828)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1.apply(RDD.scala:1060)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
        at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
        at org.apache.spark.rdd.RDD.withScope(RDD.scala:357)
        at org.apache.spark.rdd.RDD.aggregate(RDD.scala:1053)
        at org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$.infer(CSVInferSchema.scala:48)
        at org.apache.spark.sql.execution.datasources.csv.DefaultSource.inferSchema(DefaultSource.scala:69)
        at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$17.apply(DataSource.scala:292)
        at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$17.apply(DataSource.scala:292)
        at scala.Option.orElse(Option.scala:289)
        at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:291)
        at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:162)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)
        at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)
        at py4j.Gateway.invoke(Gateway.java:290)
        at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)
        at py4j.commands.CallCommand.execute(CallCommand.java:79)
        at py4j.GatewayConnection.run(GatewayConnection.java:209)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: com.univocity.parsers.common.TextParsingException: Error processing input: Length of parsed input (1001) exceeds the maximum number of characters defined in your parser settings (1000). 
Identified line separator characters in the parsed content. This may be the cause of the error. The line separator in your parser settings is set to &lt;span class=&quot;code-quote&quot;&gt;&apos;\n&apos;&lt;/span&gt;. Parsed content:
        I did it my way&quot;: moving away from the tyranny of turn-by-turn pedestrian navigation    i did it my way moving away from the tyranny of turn by turn pedestrian navigation      2010  2010/09/07       10.1145/1851600.1851660 international conference on human computer interaction  interact                43331058        18871[\n]
        770CA612        Fixed in time and &lt;span class=&quot;code-quote&quot;&gt;&quot;time in motion&quot;&lt;/span&gt;: mobility of vision through a SenseCam lens  fixed in time and time in motion mobility of vision through a sensecam lens     2009  2009/09/15       10.1145/1613858.1613861 international conference on human computer interaction  interact                43331058        19370[\n]
        7B5DE5DE        Assistive Wearable Technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Visually Impaired     assistive wearable technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; visually impaired     2015    2015/08/24              international conference on human computer interaction interact                43331058        19555[\n]
        085BEC09        HOUDINI: Introducing &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; Tracking and Pen Recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; LLP Tabletops      houdini introducing object tracking and pen recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; llp tabletops       2014  2014/06/22       10.1007/978-3-319-07230-2_23    international c
Parser Configuration: CsvParserSettings:
        Column reordering enabled=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Empty value=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
        Header extraction enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Headers=[C0, C1, C2, C3, C4, C5, C6, C7, C8, C9, C10]
        Ignore leading whitespaces=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Ignore trailing whitespaces=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Input buffer size=128
        Input reading on separate thread=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Line separator detection enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
        Maximum number of characters per column=1000
        Maximum number of columns=20
        Null value=
        &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of records to read=all
        Parse unescaped quotes=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Row processor=none
        Selected fields=none
        Skip empty lines=trueFormat configuration:
        CsvFormat:
                Comment character=\0
                Field delimiter=\t
                Line separator (normalized)=\n
                Line separator sequence=\n
                Quote character=&quot;
                Quote escape character=quote escape
                Quote escape escape character=\0, line=36, &lt;span class=&quot;code-object&quot;&gt;char&lt;/span&gt;=9828. Content parsed: [I did it my way&quot;: moving away from the tyranny of turn-by-turn pedestrian navigation     i did it my way moving away from the tyranny of turn by turn pedestrian navigation     2010    2010/09/07      10.1145/1851600.1851660 international conference on human computer interaction  interact      43331058 18871
770CA612        Fixed in time and &lt;span class=&quot;code-quote&quot;&gt;&quot;time in motion&quot;&lt;/span&gt;: mobility of vision through a SenseCam lens  fixed in time and time in motion mobility of vision through a sensecam lens     2009    2009/09/15     10.1145/1613858.1613861 international conference on human computer interaction  interact                43331058        19370
7B5DE5DE        Assistive Wearable Technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; Visually Impaired     assistive wearable technology &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; visually impaired     2015    2015/08/24              international conference on human computer interaction interact                43331058        19555
085BEC09        HOUDINI: Introducing &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt; Tracking and Pen Recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; LLP Tabletops      houdini introducing object tracking and pen recognition &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; llp tabletops       2014    2014/06/22     10.1007/978-3-319-07230-2_23    international c]
        at com.univocity.parsers.common.AbstractParser.handleException(AbstractParser.java:241)
        at com.univocity.parsers.common.AbstractParser.parseNext(AbstractParser.java:356)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:137)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.next(CSVParser.scala:120)
        at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:742)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foreach(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(TraversableOnce.scala:155)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.foldLeft(CSVParser.scala:120)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;aggregate(TraversableOnce.scala:212)
        at org.apache.spark.sql.execution.datasources.csv.BulkCsvReader.aggregate(CSVParser.scala:120)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1058)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.SparkContext$$anonfun$35.apply(SparkContext.scala:1827)
        at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:69)
        at org.apache.spark.scheduler.Task.run(Task.scala:82)
        at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:231)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        ... 1 more
Caused by: java.lang.ArrayIndexOutOfBoundsException

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Can we file this as a relevant issue of the CSV reader?&lt;/p&gt;
</comment>
                            <comment id="15215064" author="shubhanshumishra@gmail.com" created="Mon, 28 Mar 2016 23:07:17 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt;thanks for the reply. As I have mentioned above, I tried setting the rowSeparator above as &quot;\r\n&quot; but couldn&apos;t get it to work. &lt;/p&gt;

&lt;p&gt;When I process the same file using &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;).map(lambda x: len(x))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I am able to get the correct result of 697. &lt;/p&gt;

&lt;p&gt;Even using &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;).map(lambda x: x.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;)).collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;is working. &lt;/p&gt;

&lt;p&gt;I further tested to see if the number of columns are inconsistent in the rows and found the number is the same for all rows:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [1]: data = sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;).map(lambda x: len(x.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;))).collect()
                                                                                
In [2]: max(data)
Out[2]: 11

In [3]: min(data)
Out[3]: 11
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;So the issue is in the parsing function of the dataframe csv reader. If I don&apos;t use the inferSchema option, then error happens if I run any operation on the DataFrame which tries to read the full DataFrame. &lt;/p&gt;

&lt;p&gt;Even after using the `dos2unix` command to convert the text file to the format which converts each `\r\n` to `\n`.&lt;/p&gt;


&lt;p&gt;` &lt;/p&gt;</comment>
                            <comment id="15215067" author="shubhanshumishra@gmail.com" created="Mon, 28 Mar 2016 23:09:23 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; I am reopening the issue as it is not yet resolved. I have added more details and test cases in the comments. &lt;/p&gt;</comment>
                            <comment id="15215076" author="shubhanshumishra@gmail.com" created="Mon, 28 Mar 2016 23:19:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; I just checked the Spark Code on github and found that the line separator &lt;span class=&quot;error&quot;&gt;&amp;#91;mentioned as rowSeparator&amp;#93;&lt;/span&gt; is hard coded as &quot;\n&quot; in the code. &lt;a href=&quot;https://github.com/apache/spark/blob/e474088144cdd2632cf2fef6b2cf10b3cd191c23/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVOptions.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/e474088144cdd2632cf2fef6b2cf10b3cd191c23/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVOptions.scala&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Ideally, the line separator should be fetched from the platform dependent settings CRLF for Windows and LF for Unix based systems. Also, when users define a custom RowSeparator it should override the default settings. &lt;/p&gt;

&lt;p&gt;This might be causing issues. I can send a PR for accepting the line separators and setting the defaults to the System specific setting. &lt;/p&gt;</comment>
                            <comment id="15216228" author="srowen" created="Tue, 29 Mar 2016 16:01:11 +0000"  >&lt;p&gt;It shouldn&apos;t be platform dependent; configurable maybe. I actually suspect this field does nothing, since it is operating on lines as parsed by Hadoop&apos;s &lt;tt&gt;TextInputFormat&lt;/tt&gt; already, and that will actually read CR, LF or CRLF as a delimiter. But that means my explanation is wrong.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://github.com/databricks/spark-csv/pull/307&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/databricks/spark-csv/pull/307&lt;/a&gt; which is the same issue. But this suggests it happens because of one very large field. In that case it sounds like the idea is to increase &quot;maxCharsPerColumn&quot; to work for your data.&lt;/p&gt;</comment>
                            <comment id="15216350" author="shubhanshumishra@gmail.com" created="Tue, 29 Mar 2016 17:12:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; As I have mentioned above the maximum characters in each line is 697 which is well within the limits of the default maxCharsPerColumn. Also, as I have mentioned above, when I read the file the spark context it works correctly:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;data = sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;).map(lambda x: x.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;)).collect()

In [1]: data = sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;).map(lambda x: len(x.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;))).collect()
                                                                                
In [2]: max(data)
Out[2]: 11

In [3]: min(data)
Out[3]: 11
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15216378" author="srowen" created="Tue, 29 Mar 2016 17:19:42 +0000"  >&lt;p&gt;Did you compute the maximum line length? that&apos;s not quite what you show earlier, and not what you show in this snippet. Assuming you did, it still doesn&apos;t explain why the parser thinks there is a run of text far too long to process.  Your example does not exercise the CSV parser here. You should try raising the limit just to confirm it fixes it (and, then you have your workaround) and then do a little more debugging to understand why it&apos;s seeing a very long line.&lt;/p&gt;</comment>
                            <comment id="15216394" author="shubhanshumishra@gmail.com" created="Tue, 29 Mar 2016 17:26:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; In &lt;a href=&quot;#comment-15215064&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;comment-15215064&lt;/a&gt; comment I did mention how I extracted the length of each line and what the maximum line length was. I will try with raising the limit as well.  &lt;/p&gt;</comment>
                            <comment id="15216400" author="srowen" created="Tue, 29 Mar 2016 17:28:59 +0000"  >&lt;p&gt;You show the length of one line there, not the max. Just double-check. In any event, the question is why the parser sees something different.&lt;/p&gt;</comment>
                            <comment id="15216437" author="shubhanshumishra@gmail.com" created="Tue, 29 Mar 2016 17:42:19 +0000"  >&lt;p&gt;I just double checked using the following code and this is the output I found:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;In [8]:
data = sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;).map(lambda x: len(x)).collect()
max(data), min(data)
Out[8]:
(696, 96)
In [11]:
data = sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;).map(lambda x: len(x.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;))).collect()
max(data), min(data)
Out[11]:
(11, 11)
In [12]:
data = sc.textFile(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;).map(lambda x: max([len(k) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; k in x.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;)])).collect()
max(data), min(data)
Out[12]:
(286, 20)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15216541" author="shubhanshumishra@gmail.com" created="Tue, 29 Mar 2016 18:17:04 +0000"  >&lt;p&gt;Ok I tried your suggestion of increasing maxCharsPerColumn to an insanely high value and that has made the code load my file into the dataframe&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
wc -l temp.txt 
# Output is 100000  3181726 25693963 temp.txt

# Any number larger than 3181726 works
df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,  delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;, maxCharsPerColumn=3181726) # Works
df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,  delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;, maxCharsPerColumn=10000000) # Works
df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,  delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;, maxCharsPerColumn=2679360) # Works

# However, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; one fails
df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,  delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;, maxCharsPerColumn=2679350) # Gives error
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I check the file at that point using the following bash commands:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ head -c2679360 temp1.txt | tail -n3

5F59257A        Performance of multicarrier CDMA technique combined with space-time block coding over Rayleigh channel  performance of multicarrier cdma technique combined with space time block coding over rayleigh channel 2002    2002    10.1109/ISSSTA.2002.1048562     international symposium on information theory and its applications      isita           44B587D1        17005
6C9A7181        Compressive receiver sidelobes suppression based on mismatching algorithms      compressive receiver sidelobes suppression based on mismatching algorithms      1998    1998  10.1109/ISSSTA.1998.722528       international symposium on information theory and its applications      isita           44B587D1        17166
777FD068        UE Counting Mechanism &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; MBMS Considering PtM Macro Diversity Combining Support in UMTS Networks       ue counting mechanism &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; mbms considering ptm macro diversity combining support in umts networks      2006    2006/08 10.1109/ISSSTA.2006.311795      internation
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;I don&apos;t see any issues with the data in these lines. Especially between the following characters:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ head -c2679360 temp1.txt | tail -c20

6.311795\tinternation
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15216547" author="shubhanshumishra@gmail.com" created="Tue, 29 Mar 2016 18:19:46 +0000"  >&lt;p&gt;Another issue with your &lt;a href=&quot;#comment-15216228&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;comment-15216228&lt;/a&gt; is that I am actually reading a file, which was generated on a windows system, on a linux system. So the direct conversion of CRLF to LF will not take place and hence a proper assignment of rowSeperator is needed. &lt;/p&gt;</comment>
                            <comment id="15216639" author="srowen" created="Tue, 29 Mar 2016 18:56:52 +0000"  >&lt;p&gt;I&apos;m saying that this is already done by &lt;tt&gt;TextInputFormat&lt;/tt&gt;... or should be. Certainly that&apos;s what you&apos;re already using in your examples because they call textFile(), or they wouldn&apos;t work right? &lt;/p&gt;

&lt;p&gt;And it looks like the CSV parser consumes the already-parsed lines, meaning, I don&apos;t see how the parser&apos;s notion of record separator matters. But this could be where some problem lies. It is suspicious that you have this problem with Windows-formatted newlines. However breaking on \n should cause it to break on \r\n but just leave the \r in. So I also don&apos;t immediately see how this leads to a line-too-long problem.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt; is any of this ringing a bell?&lt;/p&gt;</comment>
                            <comment id="15216660" author="shubhanshumishra@gmail.com" created="Tue, 29 Mar 2016 19:08:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; yes, you are right. The issue is not with &quot;\r\n&quot; but something else. I convered the &quot;\r\n&quot; in the file to &quot;\n&quot; and the error continues to exist. &lt;/p&gt;

&lt;p&gt;Another issue which should be addressed is the long debug message which is printed to the console with the whole content of the file. This is annoying. It should just print the stack trace and the error message and not the whole string of file contents which were read by the parser. &lt;/p&gt;</comment>
                            <comment id="15216705" author="srowen" created="Tue, 29 Mar 2016 19:24:54 +0000"  >&lt;p&gt;Printing the bad line is helpful but would be great if the length were capped. I don&apos;t know if we can control this much if it&apos;s from the library.&lt;/p&gt;</comment>
                            <comment id="15217198" author="gurwls223" created="Wed, 30 Mar 2016 01:28:33 +0000"  >&lt;p&gt;As &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sowen&quot; class=&quot;user-hover&quot; rel=&quot;sowen&quot;&gt;sowen&lt;/a&gt; said, CRLF is dealt with in &lt;tt&gt;TextInputFormat&lt;/tt&gt; which calls &lt;a href=&quot;https://github.com/apache/hadoop/blob/7fd00b3db4b7d73afd41276ba9a06ec06a0e1762/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LineReader.java#L186&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;LineReader.readDefaultLine(...)&lt;/a&gt; at the end, meaning it would not be a problem.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shubhanshumishra%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;shubhanshumishra@gmail.com&quot;&gt;shubhanshumishra@gmail.com&lt;/a&gt; So, the codes below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,  delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;, maxCharsPerColumn=2679350) # Gives error
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;throw an exception, right?&lt;/p&gt;

&lt;p&gt;Could you maybe share the error message? I (or my blind eyes) cannot find the exception message about this.&lt;/p&gt;</comment>
                            <comment id="15217212" author="gurwls223" created="Wed, 30 Mar 2016 01:44:14 +0000"  >&lt;p&gt;For long messages, there is a JIRA opened already here, &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-13792&quot; title=&quot;Limit logging of bad records&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-13792&quot;&gt;&lt;del&gt;SPARK-13792&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="15217821" author="srowen" created="Wed, 30 Mar 2016 11:36:35 +0000"  >&lt;p&gt;The exception is in the description:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;com.univocity.parsers.common.TextParsingException: Error processing input: Length of parsed input (1000001) exceeds the maximum number of characters defined in your parser settings (1000000). Identified line separator characters in the parsed content. This may be the cause of the error. The line separator in your parser settings is set to &lt;span class=&quot;code-quote&quot;&gt;&apos;\n&apos;&lt;/span&gt;. Parsed content:
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It does really sound like a very long line but the tests above do seem to argue that the lines are quite normal and short.&lt;/p&gt;</comment>
                            <comment id="15217850" author="gurwls223" created="Wed, 30 Mar 2016 11:59:30 +0000"  >&lt;p&gt;Thank you so much for cutting it short. Currenrly Im not too sure. Let me investigate this.&lt;/p&gt;</comment>
                            <comment id="15217853" author="gurwls223" created="Wed, 30 Mar 2016 12:02:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shubhanshumishra%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;shubhanshumishra@gmail.com&quot;&gt;shubhanshumishra@gmail.com&lt;/a&gt; I just wonder if I could have that &lt;tt&gt;temp.txt&lt;/tt&gt; file if you are okay although I will try to reproduce this with a dummy file.&lt;/p&gt;</comment>
                            <comment id="15217981" author="shubhanshumishra@gmail.com" created="Wed, 30 Mar 2016 13:45:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt; the temp.txt file is actually just the first 100,000 lines of the Papers.txt file from this URL &lt;a href=&quot;https://academicgraph.blob.core.windows.net/graph-2016-02-05/Papers.zip&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://academicgraph.blob.core.windows.net/graph-2016-02-05/Papers.zip&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This file is part of the Microsoft Academic Graph which is free to download but you need to accept the license. &lt;/p&gt;

&lt;p&gt;The license can be found at: &lt;a href=&quot;http://research.microsoft.com/en-us/projects/mag/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://research.microsoft.com/en-us/projects/mag/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Steps for downloading are as follows:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Go to &lt;a href=&quot;http://research.microsoft.com/en-us/projects/mag/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://research.microsoft.com/en-us/projects/mag/&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;Accept the terms and click on &quot;get the data&quot;&lt;/li&gt;
	&lt;li&gt;Click the link 2016-02-05 under West United States&lt;/li&gt;
	&lt;li&gt;Under individual files download Papers (9.05GB), it is a zip file.&lt;/li&gt;
	&lt;li&gt;Unzip the Papers.zip&lt;/li&gt;
	&lt;li&gt;Run the command 
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;head -n 100000 Papers.txt &amp;gt; temp.txt&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;Try to load the temp.txt in spark dataframe
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, inferSchema=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;,  delimiter=&lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;, maxCharsPerColumn=2679350) # Gives error
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;I am using the master branch of Spark from github, it was updated yesterday. &lt;br/&gt;
Ubuntu, Python 2.7.11, Anaconda 2.5.0&lt;/p&gt;</comment>
                            <comment id="15218001" author="gurwls223" created="Wed, 30 Mar 2016 14:02:21 +0000"  >&lt;p&gt;Thanks for detailed directions. Fortunately, I think i found some clues. Let me provide some examples and explanation in a PR if I&apos;m getting right.&lt;/p&gt;</comment>
                            <comment id="15222792" author="gurwls223" created="Sat, 2 Apr 2016 08:32:55 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shubhanshumishra%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;shubhanshumishra@gmail.com&quot;&gt;shubhanshumishra@gmail.com&lt;/a&gt; Right, it looks like an issue in Univocity Parser.&lt;/p&gt;

&lt;p&gt;I could reproduce this error with the data below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-quote&quot;&gt;&quot;a&quot;&lt;/span&gt;b	ccc	ddd
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and code below:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;val path = &lt;span class=&quot;code-quote&quot;&gt;&quot;temp.tsv&quot;&lt;/span&gt;
sqlContext.read
  .format(&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;)
  .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;maxCharsPerColumn&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;4&quot;&lt;/span&gt;)
  .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;delimiter&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;\t&quot;&lt;/span&gt;)
  .load(path)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It looks Univocity parser gets confused when it meets &lt;tt&gt;quote&lt;/tt&gt; character during parsing a value and the value does not end with the character. It just treats the entire rows and values as a quoted value  as a value afterward when this happens.&lt;/p&gt;

&lt;p&gt;So, it looks your data has such rows, for example below:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;7C0E15CD	&lt;span class=&quot;code-quote&quot;&gt;&quot;I did it my way&quot;&lt;/span&gt;: moving away from the tyranny of turn-by-turn pedestrian navigation	i did it my way moving away from the tyranny of turn by turn pedestrian navigation	2010	2010/09/07	10.1145/1851600.1851660	international conference on human computer interaction	interact		43331058	18871
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All the data after &lt;tt&gt;&quot;I did it my way&lt;/tt&gt; was being treated as a quoted value.&lt;/p&gt;


&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sowen&quot; class=&quot;user-hover&quot; rel=&quot;sowen&quot;&gt;sowen&lt;/a&gt; Actually, for me it has been a bit questionable for the use of Univocity parser. It looks it is generally true that this library itself is faster then Apache CSV parser but it brought complexity of codes and there are pretty messy additional logics to use Univocity for now. Also, it became pretty difficult to figure out such issues.&lt;/p&gt;

&lt;p&gt;I am thinking about changing Univocity to Apahce CSV parser after performance tests. Do you think this makes sense?&lt;/p&gt;</comment>
                            <comment id="15222879" author="gurwls223" created="Sat, 2 Apr 2016 12:54:17 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=falaki&quot; class=&quot;user-hover&quot; rel=&quot;falaki&quot;&gt;falaki&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin%40databricks.com&quot; class=&quot;user-hover&quot; rel=&quot;rxin@databricks.com&quot;&gt;rxin@databricks.com&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15222912" author="srowen" created="Sat, 2 Apr 2016 15:06:57 +0000"  >&lt;p&gt;I&apos;ve used the Apache parser in the past and it has been fine. I have never used this one. That&apos;s a funny bug here. Any idea if it&apos;s known or easily fixable? that&apos;s the ideal way forward.&lt;/p&gt;</comment>
                            <comment id="15222931" author="gurwls223" created="Sat, 2 Apr 2016 16:18:43 +0000"  >&lt;p&gt;After thinking further, I realised that this might be a right behaviour in a way. I just checked the &lt;a href=&quot;http://docs.univocity.com/parsers/1.5.0/com/univocity/parsers/csv/CsvFormat.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Univocity parser API&lt;/a&gt; and this mentions a case similar with this at quote option, although for me it still looks a bit weird because  I think it is sensible to parse &lt;tt&gt;&quot;a&quot;b&lt;/tt&gt; to &lt;tt&gt;ab&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;I think they intended to work like this as the value in the above case is anyway started with a &lt;tt&gt;quote&lt;/tt&gt; character and this might imply that it is a value up to another ending &lt;tt&gt;quote&lt;/tt&gt; character right before a delimiter.&lt;/p&gt;

&lt;p&gt;Maybe those quotes might have to be followed by escape characters or set &lt;tt&gt;quote&lt;/tt&gt; to another character or &lt;tt&gt;null&lt;/tt&gt; (not sure if &lt;tt&gt;null&lt;/tt&gt; works though).&lt;/p&gt;

&lt;p&gt;I haven&apos;t checked how Apache CSV works with this. Let me test this soon and will update if there is something else I should inform.&lt;/p&gt;</comment>
                            <comment id="15222938" author="srowen" created="Sat, 2 Apr 2016 16:40:18 +0000"  >&lt;p&gt;I don&apos;t think this case is ambiguous. The second &quot; appears alone without preceding \ or following &quot;. However I don&apos;t know if it&apos;s valid to quote only part of a field in CSV. And it doesn&apos;t seem to match the intent; the content should escape those quotes. I think you could argue it&apos;s a bad input problem but the error is odd.&lt;/p&gt;</comment>
                            <comment id="15223006" author="shubhanshumishra@gmail.com" created="Sat, 2 Apr 2016 18:50:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt; thanks for pointing this out. I used the &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;quote=&quot;&quot;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; as a value and the dataframe reader was able to correctly parse the file. &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;df = sqlContext.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp.txt&quot;&lt;/span&gt;, format=&lt;span class=&quot;code-quote&quot;&gt;&quot;csv&quot;&lt;/span&gt;, header=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;, quote=&lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;, inferSchema=&quot;&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;code-quote&quot;&gt;&quot;, delimiter=&quot;&lt;/span&gt;\t&quot;) # WORKS
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After your comment, I looked at the &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVOptions.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVOptions.scala&lt;/a&gt; file which sets the default quote character to &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&quot;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;, however, in the &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;getChar&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; function, it is mentioned if the length of the option is 0 then the value will be set to the null unicode char &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;\u000&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;. &lt;/p&gt;

&lt;p&gt;I think this fixes up this issue. However, the long error message should be taken care of. &lt;/p&gt;
</comment>
                            <comment id="15223650" author="gurwls223" created="Mon, 4 Apr 2016 04:29:46 +0000"  >&lt;p&gt;This issue in Univocity is fixed and they will release &lt;tt&gt;2.0.2&lt;/tt&gt; (See &lt;a href=&quot;https://github.com/uniVocity/univocity-parsers/issues/60&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/uniVocity/univocity-parsers/issues/60&lt;/a&gt;). Could I bump up this version to solve this issue?&lt;/p&gt;</comment>
                            <comment id="15224386" author="srowen" created="Mon, 4 Apr 2016 15:59:41 +0000"  >&lt;p&gt;Go for it. There aren&apos;t actually long lines in the file though, so I&apos;m sort of confused how this might resolve it. It wouldn&apos;t look past the end of the line for a quote would it? there seems to be a line separator issue in here somewhere.&lt;/p&gt;</comment>
                            <comment id="15225263" author="gurwls223" created="Mon, 4 Apr 2016 23:30:17 +0000"  >&lt;p&gt;Oh, sorry I should have mentioned that it reads all the data (including line separators) regardless of a line separator once it meets a quote character which does not end.&lt;/p&gt;

&lt;p&gt;In &lt;tt&gt;BulkCsvReader&lt;/tt&gt;, it sort of uses a &lt;tt&gt;Reader&lt;/tt&gt; converted from &lt;tt&gt;Iterator&lt;/tt&gt;, meaning it processes data not line by line in the point of Univocity parser.&lt;/p&gt;

&lt;p&gt;If this were processed with &lt;tt&gt;Iterator&lt;/tt&gt; with each line as a input, then it would be just like you said but it is processed with &lt;tt&gt;Reader&lt;/tt&gt; with whole data as input. So, this even ignores line separators as well as delimiters which ends up reading whole data after a quote as a value.&lt;/p&gt;

&lt;p&gt;&lt;del&gt;(Actually this is one of the reasons why I am thinkng changing this library to Apache&apos;s. It seems Univocity only takes input as &lt;tt&gt;Reader&lt;/tt&gt; whereas Apache&apos;s takes &lt;tt&gt;String&lt;/tt&gt;, which can be easily produced from &lt;tt&gt;Iterator&lt;/tt&gt; (as far as I remember).&lt;/del&gt;&lt;/p&gt;</comment>
                            <comment id="15225305" author="gurwls223" created="Mon, 4 Apr 2016 23:50:01 +0000"  >&lt;p&gt;Just to cut it short, the input is being read as a byte stream, bytes by bytes across every line produced by &lt;tt&gt;Iterator&lt;/tt&gt; with manually inserted line separators.&lt;/p&gt;</comment>
                            <comment id="15229485" author="apachespark" created="Thu, 7 Apr 2016 01:28:04 +0000"  >&lt;p&gt;User &apos;HyukjinKwon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/12226&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/12226&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 32 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2v47b:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>