<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:48:42 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-49872] Spark History UI -- StreamConstraintsException: String length (20054016) exceeds the maximum length (20000000)</title>
                <link>https://issues.apache.org/jira/browse/SPARK-49872</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;There is an issue with the Spark History UI with large amounts of event logs.&lt;/p&gt;

&lt;p&gt;The root of this problem is the breaking change in jackson that (in the name of &quot;safety&quot;) introduced some JSON size limits, see: &lt;a href=&quot;https://github.com/FasterXML/jackson-core/issues/1014&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/FasterXML/jackson-core/issues/1014&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Looks like &lt;tt&gt;JSONOptions&lt;/tt&gt; in Spark already &lt;a href=&quot;https://github.com/apache/spark/blob/c2dbb6d04bc9c781fb4a7673e5acf2c67b99c203/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/json/JSONOptions.scala#L55-L58&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;support configuring this limit&lt;/a&gt;, but there seems to be no way to set it globally.&lt;/p&gt;

&lt;p&gt;Spark should be able to handle strings of arbitrary length. I have tried configuring rolling event logs, pruning event logs, etc. but this issue is not fixed or causes so much data loss that the spark history ui is completely useless.&lt;/p&gt;

&lt;p&gt;Perhaps a solution could be to add a config like:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
spark.history.server.jsonStreamReadConstraints.maxStringLength=&amp;lt;new_value&amp;gt; &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This has a workaround for reading JSON during your application:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
spark.read.option(&lt;span class=&quot;code-quote&quot;&gt;&quot;maxStringLen&quot;&lt;/span&gt;, 100000000).json(path) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;But this is not an option for accessing the Spark History UI. Here is the full stack trace&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
HTTP ERROR 500 
com.fasterxml.jackson.core.exc.StreamConstraintsException: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; length
 (20054016) exceeds the maximum length (20000000)

URI:/history/application_1728009195451_0002/1/jobs/
STATUS:500
MESSAGE:com.fasterxml.jackson.core.exc.StreamConstraintsException: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; length (20054016) exceeds the maximum length (20000000)
SERVLET:org.apache.spark.deploy.history.HistoryServer$$anon$1-582a764a
CAUSED BY:com.fasterxml.jackson.core.exc.StreamConstraintsException: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; length (20054016) exceeds the maximum length (20000000) 

com.fasterxml.jackson.core.exc.StreamConstraintsException: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; length (20054016) exceeds the maximum length (20000000)
	at com.fasterxml.jackson.core.StreamReadConstraints.validateStringLength(StreamReadConstraints.java:324)
	at com.fasterxml.jackson.core.util.ReadConstrainedTextBuffer.validateStringLength(ReadConstrainedTextBuffer.java:27)
	at com.fasterxml.jackson.core.util.TextBuffer.finishCurrentSegment(TextBuffer.java:939)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._finishString2(ReaderBasedJsonParser.java:2240)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._finishString(ReaderBasedJsonParser.java:2206)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.getText(ReaderBasedJsonParser.java:323)
	at com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer._deserializeContainerNoRecursion(JsonNodeDeserializer.java:572)
	at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:100)
	at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserialize(JsonNodeDeserializer.java:25)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323)
	at com.fasterxml.jackson.databind.ObjectMapper._readTreeAndClose(ObjectMapper.java:4867)
	at com.fasterxml.jackson.databind.ObjectMapper.readTree(ObjectMapper.java:3219)
	at org.apache.spark.util.JsonProtocol$.sparkEventFromJson(JsonProtocol.scala:927)
	at org.apache.spark.scheduler.ReplayListenerBus.replay(ReplayListenerBus.scala:88)
	at org.apache.spark.scheduler.ReplayListenerBus.replay(ReplayListenerBus.scala:59)
	at org.apache.spark.deploy.history.FsHistoryProvider.$anonfun$parseAppEventLogs$3(FsHistoryProvider.scala:1143)
	at org.apache.spark.deploy.history.FsHistoryProvider.$anonfun$parseAppEventLogs$3$adapted(FsHistoryProvider.scala:1141)
	at org.apache.spark.util.SparkErrorUtils.tryWithResource(SparkErrorUtils.scala:48)
	at org.apache.spark.util.SparkErrorUtils.tryWithResource$(SparkErrorUtils.scala:46)
	at org.apache.spark.util.Utils$.tryWithResource(Utils.scala:95)
	at org.apache.spark.deploy.history.FsHistoryProvider.$anonfun$parseAppEventLogs$1(FsHistoryProvider.scala:1141)
	at org.apache.spark.deploy.history.FsHistoryProvider.$anonfun$parseAppEventLogs$1$adapted(FsHistoryProvider.scala:1139)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at org.apache.spark.deploy.history.FsHistoryProvider.parseAppEventLogs(FsHistoryProvider.scala:1139)
	at org.apache.spark.deploy.history.FsHistoryProvider.rebuildAppStore(FsHistoryProvider.scala:1120)
	at org.apache.spark.deploy.history.FsHistoryProvider.createInMemoryStore(FsHistoryProvider.scala:1358)
	at org.apache.spark.deploy.history.FsHistoryProvider.getAppUI(FsHistoryProvider.scala:347)
	at org.apache.spark.deploy.history.HistoryServer.getAppUI(HistoryServer.scala:199)
	at org.apache.spark.deploy.history.ApplicationCache.$anonfun$loadApplicationEntry$2(ApplicationCache.scala:163)
	at org.apache.spark.deploy.history.ApplicationCache.time(ApplicationCache.scala:134)
	at org.apache.spark.deploy.history.ApplicationCache.org$apache$spark$deploy$history$ApplicationCache$$loadApplicationEntry(ApplicationCache.scala:161)
	at org.apache.spark.deploy.history.ApplicationCache$$anon$1.load(ApplicationCache.scala:55)
	at org.apache.spark.deploy.history.ApplicationCache$$anon$1.load(ApplicationCache.scala:51)
	at org.sparkproject.guava.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3599)
	at org.sparkproject.guava.cache.LocalCache$Segment.loadSync(LocalCache.java:2379)
	at org.sparkproject.guava.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2342)
	at org.sparkproject.guava.cache.LocalCache$Segment.get(LocalCache.java:2257)
	at org.sparkproject.guava.cache.LocalCache.get(LocalCache.java:4000)
	at org.sparkproject.guava.cache.LocalCache.getOrLoad(LocalCache.java:4004)
	at org.sparkproject.guava.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4874)
	at org.apache.spark.deploy.history.ApplicationCache.get(ApplicationCache.scala:88)
	at org.apache.spark.deploy.history.ApplicationCache.withSparkUI(ApplicationCache.scala:100)
	at org.apache.spark.deploy.history.HistoryServer.org$apache$spark$deploy$history$HistoryServer$$loadAppUi(HistoryServer.scala:256)
	at org.apache.spark.deploy.history.HistoryServer$$anon$1.doGet(HistoryServer.scala:104)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:503)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:590)
	at org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.sparkproject.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1656)
	at org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)
	at org.sparkproject.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.sparkproject.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1626)
	at org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:552)
	at org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)
	at org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:234)
	at org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.apache.spark.ui.ProxyRedirectHandler.handle(JettyUtils.scala:582)
	at org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.sparkproject.jetty.server.Server.handle(Server.java:516)
	at org.sparkproject.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.sparkproject.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.sparkproject.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.sparkproject.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:750)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13594251">SPARK-49872</key>
            <summary>Spark History UI -- StreamConstraintsException: String length (20054016) exceeds the maximum length (20000000)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cloud_fan">Wenchen Fan</assignee>
                                    <reporter username="anthonysgro">Anthony Sgro</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 4 Oct 2024 03:12:52 +0000</created>
                <updated>Tue, 19 Aug 2025 00:08:09 +0000</updated>
                            <resolved>Tue, 19 Aug 2025 00:07:33 +0000</resolved>
                                    <version>3.5.3</version>
                    <version>3.5.4</version>
                                    <fixVersion>4.1.0</fixVersion>
                    <fixVersion>4.0.1</fixVersion>
                    <fixVersion>3.5.7</fixVersion>
                                    <component>UI</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="17889214" author="roczei" created="Mon, 14 Oct 2024 12:59:28 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anthonysgro&quot; class=&quot;user-hover&quot; rel=&quot;anthonysgro&quot;&gt;anthonysgro&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;I have started to work on this.&lt;/p&gt;</comment>
                            <comment id="17898012" author="JIRAUSER306061" created="Wed, 13 Nov 2024 17:51:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=roczei&quot; class=&quot;user-hover&quot; rel=&quot;roczei&quot;&gt;roczei&lt;/a&gt; thanks, any progress on this?&lt;/p&gt;</comment>
                            <comment id="17898378" author="roczei" created="Thu, 14 Nov 2024 18:27:10 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anthonysgro&quot; class=&quot;user-hover&quot; rel=&quot;anthonysgro&quot;&gt;anthonysgro&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;&amp;gt; thanks, any progress on this?&lt;/p&gt;

&lt;p&gt;Actul state: &lt;a href=&quot;https://github.com/roczei/spark/pull/7&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/roczei/spark/pull/7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have not finished yet because it is not so easy to set the related jackson parameter in case of Spark History Server. I need a few weeks to finish with the testing. &lt;/p&gt;</comment>
                            <comment id="17905053" author="steven.aerts" created="Thu, 12 Dec 2024 08:12:47 +0000"  >&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I created a competing &lt;a href=&quot;https://github.com/apache/spark/pull/49163&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;pull request&lt;/a&gt; with a workaround for this issue, which removes stringlength check from Jackson.&lt;/p&gt;

&lt;p&gt;I propose to remove the check instead of making it configurable, to make sure that JsonProtocol does not lose its strong backwards- and forwards-compatibility guarantees: any version of Spark should be able to read JSON output written by any other version, including newer versions.&#160; &lt;br/&gt;
I think that this limit prevented this guarantee.&lt;/p&gt;

&lt;p&gt;If you still prefer a configurable version, let me know I do not mind to extend my PR.&#160; &lt;/p&gt;

&lt;p&gt;Best regards,&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&#160; Steven&lt;/p&gt;</comment>
                            <comment id="17905197" author="JIRAUSER307916" created="Thu, 12 Dec 2024 14:16:49 +0000"  >&lt;p&gt;I&apos;d +1 the approach in &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steven.aerts&quot; class=&quot;user-hover&quot; rel=&quot;steven.aerts&quot;&gt;steven.aerts&lt;/a&gt; PR here. We&apos;re running a single SHS cluster in HA on Spark 3.5.3 reading from a very large Spark event log distribution (~75-80k log files). We allow our clients any version of Spark to run on our cluster from 2.3 &amp;gt; 3.5.3, and so this bug has hit us particularly on some of the more current versions of Spark logs where AQE and physical plans seem to generate some pretty large json blobs within the logs. Having the ability to be backwards and forwards-compatible by disabling the check, as opposed to coming up with some sort of larger and larger integer to configure this check with seems more accommodating.&lt;/p&gt;</comment>
                            <comment id="17905239" author="JIRAUSER306061" created="Thu, 12 Dec 2024 16:19:03 +0000"  >&lt;p&gt;love the approach, thank you &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steven.aerts&quot; class=&quot;user-hover&quot; rel=&quot;steven.aerts&quot;&gt;steven.aerts&lt;/a&gt; for addressing this!&lt;/p&gt;</comment>
                            <comment id="17905536" author="roczei" created="Fri, 13 Dec 2024 16:07:24 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steven.aerts&quot; class=&quot;user-hover&quot; rel=&quot;steven.aerts&quot;&gt;steven.aerts&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;&amp;gt;&#160;I propose to remove the check instead of making it configurable, to make sure that JsonProtocol does not lose its strong backwards- and forwards-compatibility &lt;br/&gt;
&amp;gt; guarantees: any version of Spark should be able to read JSON output written by any other version, including newer versions.&#160;&lt;br/&gt;
&amp;gt; I think that this limit prevented this guarantee.&lt;/p&gt;

&lt;p&gt;+1&lt;/p&gt;

&lt;p&gt;I agree with you&lt;/p&gt;</comment>
                            <comment id="17949834" author="JIRAUSER309636" created="Tue, 6 May 2025 20:48:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steven.aerts&quot; class=&quot;user-hover&quot; rel=&quot;steven.aerts&quot;&gt;steven.aerts&lt;/a&gt;, thanks for the fix!&lt;/p&gt;

&lt;p&gt;Do we plan to merge &lt;a href=&quot;https://github.com/apache/spark/pull/49163&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/49163&lt;/a&gt; soon and will it be available in spark 3.5 as well? &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-47150&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-47150&lt;/a&gt; for spark 3.5&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17951713" author="luciferyang" created="Thu, 15 May 2025 12:00:10 +0000"  >&lt;p&gt;Issue resolved by pull request 49163&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/49163&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/49163&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="18014154" author="dongjoon" created="Fri, 15 Aug 2025 15:44:11 +0000"  >&lt;p&gt;This is reverted via &lt;a href=&quot;https://github.com/apache/spark/pull/52036&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/52036&lt;/a&gt; to deliver a surgical patch to all live branches.&lt;/p&gt;</comment>
                            <comment id="18014754" author="cloud_fan" created="Tue, 19 Aug 2025 00:07:33 +0000"  >&lt;p&gt;Issue resolved by pull request 52049&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/52049&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/52049&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="13569689">SPARK-47150</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1rsaw:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>