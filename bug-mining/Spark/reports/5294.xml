<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:56:57 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-22403] StructuredKafkaWordCount example fails in YARN cluster mode</title>
                <link>https://issues.apache.org/jira/browse/SPARK-22403</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When I run the StructuredKafkaWordCount example in YARN client mode, it runs fine. However, when I run it in YARN cluster mode, the application errors during initialization, and dies after the default number of YARN application attempts. In the AM log, I see&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;17/10/30 11:34:52 INFO execution.SparkSqlParser: Parsing command: CAST(value AS STRING)
17/10/30 11:34:53 ERROR streaming.StreamMetadata: Error writing stream metadata StreamMetadata(b71ca714-a7a1-467f-96aa-023375964429) to /data/yarn/nm/usercache/systest/appcache/application_1508800814252_0047/container_1508800814252_0047_01_000001/tmp/temporary-b5ced4ae-32e0-4725-b905-aad679aec9b5/metadata
org.apache.hadoop.security.AccessControlException: Permission denied: user=systest, access=WRITE, inode=&quot;/&quot;:hdfs:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:397)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:256)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:194)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1842)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1826)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1785)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.resolvePathForStartFile(FSDirWriteFileOp.java:315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2313)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2257)
...
        at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1235)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1214)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1152)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:458)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:455)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:469)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:396)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1103)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1083)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:972)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:960)
	at org.apache.spark.sql.execution.streaming.StreamMetadata$.write(StreamMetadata.scala:76)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$6.apply(StreamExecution.scala:116)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$6.apply(StreamExecution.scala:114)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.execution.streaming.StreamExecution.&amp;lt;init&amp;gt;(StreamExecution.scala:114)
	at org.apache.spark.sql.streaming.StreamingQueryManager.createQuery(StreamingQueryManager.scala:240)
	at org.apache.spark.sql.streaming.StreamingQueryManager.startQuery(StreamingQueryManager.scala:278)
	at org.apache.spark.sql.streaming.DataStreamWriter.start(DataStreamWriter.scala:282)
	at org.apache.spark.examples.sql.streaming.StructuredKafkaWordCount$.main(StructuredKafkaWordCount.scala:79)
	at org.apache.spark.examples.sql.streaming.StructuredKafkaWordCount.main(StructuredKafkaWordCount.scala)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Looking at StreamingQueryManager#createQuery, we have&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/streaming/StreamingQueryManager.scala#L198&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/streaming/StreamingQueryManager.scala#L198&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    val checkpointLocation = userSpecifiedCheckpointLocation.map { ...
      ...
    }.orElse {
      ...
    }.getOrElse {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (useTempCheckpointLocation) {
        &lt;span class=&quot;code-comment&quot;&gt;// Delete the temp checkpoint when a query is being stopped without errors.
&lt;/span&gt;        deleteCheckpointOnStop = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
        Utils.createTempDir(namePrefix = s&lt;span class=&quot;code-quote&quot;&gt;&quot;temporary&quot;&lt;/span&gt;).getCanonicalPath
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        ...
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And Utils.createTempDir has&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
  def createTempDir(
      root: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.getProperty(&lt;span class=&quot;code-quote&quot;&gt;&quot;java.io.tmpdir&quot;&lt;/span&gt;),
      namePrefix: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &lt;span class=&quot;code-quote&quot;&gt;&quot;spark&quot;&lt;/span&gt;): File = {
    val dir = createDirectory(root, namePrefix)
    ShutdownHookManager.registerShutdownDeleteDir(dir)
    dir
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In client mode, java.io.tmpdir is set to &quot;/tmp&quot;, which also exists in HDFS and has permissions 1777. In cluster mode, java.io.tmpdir is set in the YARN AM to &quot;$PWD/tmp&quot;, where PWD is &quot;${yarn.nodemanager.local-dirs}/usercache/${user}/appcache/application_${appid}/container_${contid}&quot;.&lt;br/&gt;
The problem is that Spark is using java.io.tmpdir, which is a path in the local filesystem, as a path in HDFS. When that path is &quot;/tmp&quot;, which happens to exist in HDFS, no problem arises, but that is just by coincidence.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13113180">SPARK-22403</key>
            <summary>StructuredKafkaWordCount example fails in YARN cluster mode</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wypoon">Wing Yew Poon</assignee>
                                    <reporter username="wypoon">Wing Yew Poon</reporter>
                        <labels>
                    </labels>
                <created>Mon, 30 Oct 2017 22:55:28 +0000</created>
                <updated>Fri, 10 Nov 2017 00:22:45 +0000</updated>
                            <resolved>Fri, 10 Nov 2017 00:21:57 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.2.1</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16225913" author="wypoon" created="Mon, 30 Oct 2017 23:01:55 +0000"  >&lt;p&gt;The simplest change that will solve the problem in this particular scenario, is to change the Utils.createTempDir(namePrefix = s&quot;temporary&quot;) call in &lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/streaming/StreamingQueryManager.scala#L208&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/streaming/StreamingQueryManager.scala#L208&lt;/a&gt; to Utils.createTempDir(root = &quot;/tmp&quot;, namePrefix = &quot;temporary&quot;).&lt;br/&gt;
In my view, using &quot;/tmp&quot; is not worse, in fact is better, than using System.getProperty(&quot;java.io.tmpdir&quot;).&lt;br/&gt;
However, others may know of better solutions.&lt;/p&gt;</comment>
                            <comment id="16227266" author="zsxwing" created="Tue, 31 Oct 2017 18:23:00 +0000"  >&lt;p&gt;Yeah, Spark creates a temp directory for you. You can set &quot;checkpointLocation&quot; by yourself to avoid this issue. I don&apos;t know if there is an API to create a temp directory for all types of file systems.&lt;/p&gt;</comment>
                            <comment id="16227298" author="wypoon" created="Tue, 31 Oct 2017 18:38:42 +0000"  >&lt;p&gt;I realize that in a production application, one would set checkpointLocation and avoid this issue. However, there is evidently a problem in the code that handles the case when checkpointLocation is not set and a temporary checkpoint location is created. Also, the StructuredKafkaWordCount example does not accept a parameter for setting the checkpointLocation.&lt;/p&gt;</comment>
                            <comment id="16227321" author="zsxwing" created="Tue, 31 Oct 2017 18:52:58 +0000"  >&lt;p&gt;Yeah, feel free to submit a PR to improve the example.&lt;/p&gt;</comment>
                            <comment id="16245191" author="apachespark" created="Thu, 9 Nov 2017 04:33:03 +0000"  >&lt;p&gt;User &apos;wypoon&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19703&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19703&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 1 week, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3lw5r:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>