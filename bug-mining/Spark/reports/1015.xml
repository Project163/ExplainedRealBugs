<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:20:14 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4326] unidoc is broken on master</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4326</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;On master, `jekyll build` throws the following error:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[error] /Users/meng/src/spark/core/src/main/scala/org/apache/spark/util/collection/AppendOnlyMap.scala:205: value hashInt is not a member of com.google.common.hash.HashFunction
[error]   &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def rehash(h: Int): Int = Hashing.murmur3_32().hashInt(h).asInt()
[error]                                                          ^
[error] /Users/meng/src/spark/core/src/main/scala/org/apache/spark/util/collection/ExternalAppendOnlyMap.scala:426: value limit is not a member of object com.google.common.io.ByteStreams
[error]         val bufferedStream = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BufferedInputStream(ByteStreams.limit(fileStream, end - start))
[error]                                                                  ^
[error] /Users/meng/src/spark/core/src/main/scala/org/apache/spark/util/collection/ExternalSorter.scala:558: value limit is not a member of object com.google.common.io.ByteStreams
[error]         val bufferedStream = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; BufferedInputStream(ByteStreams.limit(fileStream, end - start))
[error]                                                                  ^
[error] /Users/meng/src/spark/core/src/main/scala/org/apache/spark/util/collection/OpenHashSet.scala:261: value hashInt is not a member of com.google.common.hash.HashFunction
[error]   &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def hashcode(h: Int): Int = Hashing.murmur3_32().hashInt(h).asInt()
[error]                                                            ^
[error] /Users/meng/src/spark/core/src/main/scala/org/apache/spark/util/collection/Utils.scala:37: type mismatch;
[error]  found   : java.util.Iterator[T]
[error]  required: Iterable[?]
[error]     collectionAsScalaIterable(ordering.leastOf(asJavaIterator(input), num)).iterator
[error]                                                              ^
[error] /Users/meng/src/spark/sql/core/src/main/scala/org/apache/spark/sql/parquet/ParquetTableOperations.scala:421: value putAll is not a member of com.google.common.cache.Cache[org.apache.hadoop.fs.FileStatus,parquet.hadoop.Footer]
[error]           footerCache.putAll(newFooters)
[error]                       ^
[warn] /Users/meng/src/spark/sql/hive/src/main/scala/org/apache/spark/sql/hive/parquet/FakeParquetSerDe.scala:34: @deprecated now takes two arguments; see the scaladoc.
[warn] @deprecated(&lt;span class=&quot;code-quote&quot;&gt;&quot;No code should depend on FakeParquetHiveSerDe as it is only intended as a &quot;&lt;/span&gt; +
[warn]  ^
[info] No documentation generated with unsucessful compiler run
[warn] two warnings found
[error] 6 errors found
[error] (spark/scalaunidoc:doc) Scaladoc generation failed
[error] Total time: 48 s, completed Nov 10, 2014 1:31:01 PM
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It doesn&apos;t happen on branch-1.2.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12754257">SPARK-4326</key>
            <summary>unidoc is broken on master</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mengxr">Xiangrui Meng</assignee>
                                    <reporter username="mengxr">Xiangrui Meng</reporter>
                        <labels>
                    </labels>
                <created>Mon, 10 Nov 2014 21:45:08 +0000</created>
                <updated>Thu, 13 Nov 2014 21:18:44 +0000</updated>
                            <resolved>Thu, 13 Nov 2014 21:18:44 +0000</resolved>
                                    <version>1.3.0</version>
                                    <fixVersion>1.2.0</fixVersion>
                                    <component>Build</component>
                    <component>Documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14206265" author="srowen" created="Tue, 11 Nov 2014 10:50:23 +0000"  >&lt;p&gt;Hm. &lt;tt&gt;hashInt&lt;/tt&gt; isn&apos;t in Guava 11, but is in 12. This leads me to believe that unidoc is picking up Guava 11 from Hadoop, and not Guava 14 from Spark since it&apos;s shaded. I would like to phone a friend: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14207156" author="vanzin" created="Tue, 11 Nov 2014 21:58:37 +0000"  >&lt;p&gt;Funny that it doesn&apos;t happen on 1.2 since the dependency mess should be the same in both. I&apos;ll try this out when I&apos;m done with some other tests, to see if I can figure it out.&lt;/p&gt;</comment>
                            <comment id="14207177" author="nchammas" created="Tue, 11 Nov 2014 22:11:47 +0000"  >&lt;p&gt;Side question: Should we be (or are we already) regularly building the docs to catch these problems at PR/review time?&lt;/p&gt;</comment>
                            <comment id="14207767" author="mengxr" created="Wed, 12 Nov 2014 07:30:53 +0000"  >&lt;p&gt;I was wondering why it worked on 1.2, and then I found unidoc on branch-1.2 was also broken (same error). Maybe I didn&apos;t update my local branch-1.2 when I created this JIRA.&lt;/p&gt;

&lt;p&gt;I think we are adding unidoc to nightly Jenkins builds &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="14208998" author="vanzin" created="Thu, 13 Nov 2014 00:46:34 +0000"  >&lt;p&gt;So, this is really weird. Unidoc is run by the sbt build, where none of the shading shenanigans from the maven build should apply. The root pom.xml adds guava as a dependency for everybody with compile scope when the sbt profile is enabled.&lt;/p&gt;

&lt;p&gt;That being said, if you look at the output of &lt;tt&gt;show allDependencies&lt;/tt&gt; from within an sbt shell, it will show some components with a &quot;guava 11.0.2 provided&quot; dependency. So the profile isn&apos;t taking?&lt;/p&gt;

&lt;p&gt;Another fun fact is that the dependencies for the core project, where the errors above come from, are correct in the output of &lt;tt&gt;show allDependencies&lt;/tt&gt;; it shows &quot;guava 14.0.1 compile&quot; as it should.&lt;/p&gt;

&lt;p&gt;I was able to workaround this by adding guava explicitly in SparkBuild.scala, in the &lt;tt&gt;sharedSettings&lt;/tt&gt; variable:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    libraryDependencies += &lt;span class=&quot;code-quote&quot;&gt;&quot;com.google.guava&quot;&lt;/span&gt; % &lt;span class=&quot;code-quote&quot;&gt;&quot;guava&quot;&lt;/span&gt; % &lt;span class=&quot;code-quote&quot;&gt;&quot;14.0.1&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That got rid of the above errors, but it didn&apos;t fix the overall build. Anyone more familiar with sbt/unidoc knows what&apos;s going on here?&lt;/p&gt;

&lt;p&gt;Here are the errors with that hack applied:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[error] /work/apache/spark/network/shuffle/src/main/java/org/apache/spark/network/shuffle/protocol/UploadBlock.java:55: not found: type Type
[error]   protected Type type() { return Type.UPLOAD_BLOCK; }
[error]             ^
[error] /work/apache/spark/network/shuffle/src/main/java/org/apache/spark/network/shuffle/protocol/RegisterExecutor.java:44: not found: type Type
[error]   protected Type type() { return Type.REGISTER_EXECUTOR; }
[error]             ^
[error] /work/apache/spark/network/shuffle/src/main/java/org/apache/spark/network/shuffle/protocol/OpenBlocks.java:40: not found: type Type
[error]   protected Type type() { return Type.OPEN_BLOCKS; }
[error]             ^
[error] /work/apache/spark/network/shuffle/src/main/java/org/apache/spark/network/shuffle/protocol/StreamHandle.java:39: not found: type Type
[error]   protected Type type() { return Type.STREAM_HANDLE; }
[error]             ^
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14209058" author="mengxr" created="Thu, 13 Nov 2014 01:25:29 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt; Thanks for looking into this issue! This is the commit that caused the problem:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-3796&quot; title=&quot;Create shuffle service for external block storage&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-3796&quot;&gt;&lt;del&gt;SPARK-3796&lt;/del&gt;&lt;/a&gt;: &lt;a href=&quot;https://github.com/apache/spark/commit/f55218aeb1e9d638df6229b36a59a15ce5363482&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/f55218aeb1e9d638df6229b36a59a15ce5363482&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It adds Guava 11.0.1 in the pom, which is perhaps not the correct way to specify Guava version. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=adav&quot; class=&quot;user-hover&quot; rel=&quot;adav&quot;&gt;adav&lt;/a&gt; Could you explain which Guava version you need per Hadoop profile?&lt;/p&gt;</comment>
                            <comment id="14209170" author="vanzin" created="Thu, 13 Nov 2014 03:11:50 +0000"  >&lt;p&gt;Hmm, but core/pom.xml defines an explicit dependency on guava 14, so it should override the 11.0.2 dependency from the shuffle module (which is correct, btw). And maven&apos;s / sbt&apos;s dependency resolution seems to indicate that&apos;s happening, although unidoc doesn&apos;t. That&apos;s the weird part. Maybe some bug in the unidoc plugin?&lt;/p&gt;</comment>
                            <comment id="14209242" author="ilikerps" created="Thu, 13 Nov 2014 04:23:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mengxr&quot; class=&quot;user-hover&quot; rel=&quot;mengxr&quot;&gt;mengxr&lt;/a&gt; perhaps you pointed to the wrong commit, here I added guava 11.0.2 specifically:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/commit/4c42986cc070d9c5c55c7bf8a2a67585967b1082#diff-e1e0dc857976f8b64c5f3a99435ff947R53&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/4c42986cc070d9c5c55c7bf8a2a67585967b1082#diff-e1e0dc857976f8b64c5f3a99435ff947R53&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I can&apos;t explain why this would be causing this issue, as the dependency should be overridden as Marcelo said. However, this dependency is actually not necessary, it&apos;s only to avoid people writing code that won&apos;t compile in YARN or other Hadoop versions. We could just remove it and find some other way to deal with people possibly writing invalid code.&lt;/p&gt;

&lt;p&gt;The second issue regarding compile errors in the shuffle protocol is even weirder, as that shouldn&apos;t require any dependencies and is simply a java compiler thing. Maybe it doesn&apos;t compile on a sufficiently old JDK? Perhaps an incorrect version of SBT?&lt;/p&gt;</comment>
                            <comment id="14211237" author="apachespark" created="Thu, 13 Nov 2014 20:21:06 +0000"  >&lt;p&gt;User &apos;mengxr&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3253&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3253&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14211241" author="mengxr" created="Thu, 13 Nov 2014 20:22:12 +0000"  >&lt;p&gt;Sorry, I pointed to the wrong commit ... I just sent a PR to fix this. Please help review and see whether it causes other problems. Thanks!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 1 week, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2278n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12327369">1.2.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>