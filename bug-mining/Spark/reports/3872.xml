<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:46:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16802] joins.LongToUnsafeRowMap crashes with ArrayIndexOutOfBoundsException</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16802</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Hello!&lt;/p&gt;

&lt;p&gt;This is a little similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16740&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;SPARK-16740&lt;/a&gt; (should I have reopened it?).&lt;/p&gt;

&lt;p&gt;I would recommend to give another full review to &lt;tt&gt;HashedRelation.scala&lt;/tt&gt;, particularly the new &lt;tt&gt;LongToUnsafeRowMap&lt;/tt&gt;&#160;code. I&apos;ve had a few other errors that I haven&apos;t managed to reproduce so far, as well as what I suspect could be memory leaks (I have a query in a loop OOMing after a few iterations despite not caching its results).&lt;/p&gt;

&lt;p&gt;Here is the script to reproduce the ArrayIndexOutOfBoundsException on the current 2.0 branch:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; os
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; random

from pyspark &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; SparkContext
from pyspark.sql &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; types as SparkTypes
from pyspark.sql &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; SQLContext

sc = SparkContext()
sqlc = SQLContext(sc)

schema1 = SparkTypes.StructType([
    SparkTypes.StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;id1&quot;&lt;/span&gt;, SparkTypes.LongType(), nullable=True)
])
schema2 = SparkTypes.StructType([
    SparkTypes.StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;id2&quot;&lt;/span&gt;, SparkTypes.LongType(), nullable=True)
])


def randlong():
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; random.randint(-9223372036854775808, 9223372036854775807)

&lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; True:
    l1, l2 = randlong(), randlong()

    # Sample values that crash:
    # l1, l2 = 4661454128115150227, -5543241376386463808

    print &lt;span class=&quot;code-quote&quot;&gt;&quot;Testing with %s, %s&quot;&lt;/span&gt; % (l1, l2)
    data1 = [(l1, ), (l2, )]
    data2 = [(l1, )]

    df1 = sqlc.createDataFrame(sc.parallelize(data1), schema1)
    df2 = sqlc.createDataFrame(sc.parallelize(data2), schema2)

    crash = True
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; crash:
        os.system(&lt;span class=&quot;code-quote&quot;&gt;&quot;rm -rf /tmp/sparkbug&quot;&lt;/span&gt;)
        df1.write.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/sparkbug/vertex&quot;&lt;/span&gt;)
        df2.write.parquet(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/sparkbug/edge&quot;&lt;/span&gt;)

        df1 = sqlc.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/sparkbug/vertex&quot;&lt;/span&gt;)
        df2 = sqlc.read.load(&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/sparkbug/edge&quot;&lt;/span&gt;)

    sqlc.registerDataFrameAsTable(df1, &lt;span class=&quot;code-quote&quot;&gt;&quot;df1&quot;&lt;/span&gt;)
    sqlc.registerDataFrameAsTable(df2, &lt;span class=&quot;code-quote&quot;&gt;&quot;df2&quot;&lt;/span&gt;)

    result_df = sqlc.sql(&quot;&quot;&quot;
        SELECT
            df1.id1
        FROM df1
        LEFT OUTER JOIN df2 ON df1.id1 = df2.id2
    &quot;&quot;&quot;)

    print result_df.collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.lang.ArrayIndexOutOfBoundsException: 1728150825
	at org.apache.spark.sql.execution.joins.LongToUnsafeRowMap.getValue(HashedRelation.scala:463)
	at org.apache.spark.sql.execution.joins.LongHashedRelation.getValue(HashedRelation.scala:762)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.hasNext(SerDeUtil.scala:117)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:310)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.to(SerDeUtil.scala:112)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:302)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.toBuffer(SerDeUtil.scala:112)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:289)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.toArray(SerDeUtil.scala:112)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:899)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:899)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1898)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1898)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
16/07/29 20:19:00 WARN TaskSetManager: Lost task 0.0 in stage 17.0 (TID 50, localhost): java.lang.ArrayIndexOutOfBoundsException: 1728150825
	at org.apache.spark.sql.execution.joins.LongToUnsafeRowMap.getValue(HashedRelation.scala:463)
	at org.apache.spark.sql.execution.joins.LongHashedRelation.getValue(HashedRelation.scala:762)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:370)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.hasNext(SerDeUtil.scala:117)
	at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at scala.collection.&lt;span class=&quot;code-keyword&quot;&gt;generic&lt;/span&gt;.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;to(TraversableOnce.scala:310)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.to(SerDeUtil.scala:112)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toBuffer(TraversableOnce.scala:302)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.toBuffer(SerDeUtil.scala:112)
	at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;toArray(TraversableOnce.scala:289)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.toArray(SerDeUtil.scala:112)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:899)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:899)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1898)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1898)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12993633">SPARK-16802</key>
            <summary>joins.LongToUnsafeRowMap crashes with ArrayIndexOutOfBoundsException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="davies">Davies Liu</assignee>
                                    <reporter username="sylvinus">Sylvain Zimmer</reporter>
                        <labels>
                    </labels>
                <created>Fri, 29 Jul 2016 20:30:43 +0000</created>
                <updated>Mon, 19 Sep 2016 18:14:13 +0000</updated>
                            <resolved>Thu, 4 Aug 2016 18:21:07 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15400045" author="wm624" created="Fri, 29 Jul 2016 21:43:05 +0000"  >&lt;p&gt;Very easy to reproduce. I am learning SQL code now.&lt;/p&gt;</comment>
                            <comment id="15400260" author="sylvinus" created="Fri, 29 Jul 2016 23:51:25 +0000"  >&lt;p&gt;Maybe useful for others: an ugly workaround to avoid this code path is to cast the join as string and do something like this instead:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        SELECT
            df1.id1
        FROM df1
        LEFT OUTER JOIN df2 ON &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(df1.id1 as string) = &lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(df2.id2 as string)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15403110" author="wm624" created="Tue, 2 Aug 2016 00:41:14 +0000"  >&lt;p&gt;With latest code, it should have been fixed. I re-run the test code for 10+ mintues. &lt;/p&gt;</comment>
                            <comment id="15404009" author="srowen" created="Tue, 2 Aug 2016 13:59:07 +0000"  >&lt;p&gt;Do you have a particular fix that addressed it &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wm624&quot; class=&quot;user-hover&quot; rel=&quot;wm624&quot;&gt;wm624&lt;/a&gt;? which version did you reproduce it on, and where is it working?&lt;/p&gt;</comment>
                            <comment id="15404611" author="apachespark" created="Tue, 2 Aug 2016 19:06:06 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14464&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14464&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15408262" author="davies" created="Thu, 4 Aug 2016 18:21:07 +0000"  >&lt;p&gt;Issue resolved by pull request 14464&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14464&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14464&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15415698" author="wm624" created="Wed, 10 Aug 2016 18:11:59 +0000"  >&lt;p&gt;Sorry for missing your comments. My email box doesn&apos;t show up the message. I will check the settings on JIRA.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 14 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i31ox3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12336857">2.0.1</customfieldvalue>
    <customfieldvalue id="12335644">2.1.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>