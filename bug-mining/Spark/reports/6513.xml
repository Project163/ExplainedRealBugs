<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:05:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-27100] Use `Array` instead of `Seq` in `FilePartition` to prevent StackOverflowError</title>
                <link>https://issues.apache.org/jira/browse/SPARK-27100</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;ALS in Spark MLlib causes StackOverflow:&lt;/p&gt;

&lt;p&gt;&#160;/opt/sparkml/spark213/bin/spark-submit&#160; --properties-file /opt/HiBench/report/als/spark/conf/sparkbench/spark.conf --class com.intel.hibench.sparkbench.ml.ALSExample --master yarn-client --num-executors 3 --executor-memory 322g /opt/HiBench/sparkbench/assembly/target/sparkbench-assembly-7.1-SNAPSHOT-dist.jar --numUsers 40000 --numProducts 60000 --rank 100 --numRecommends 20 --numIterations 100 --kryo false --implicitPrefs true --numProductBlocks -1 --numUserBlocks -1 --lambda 1.0 hdfs://bdw-slave20:8020/HiBench/ALS/Input&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;dag-scheduler-event-loop&quot; java.lang.StackOverflowError&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1534)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)&lt;br/&gt;
 at scala.collection.immutable.List$SerializationProxy.writeObject(List.scala:468)&lt;br/&gt;
 at sun.reflect.GeneratedMethodAccessor27.invoke(Unknown Source)&lt;br/&gt;
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
 at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
 at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1028)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)&lt;br/&gt;
 at scala.collection.immutable.List$SerializationProxy.writeObject(List.scala:468)&lt;br/&gt;
 at sun.reflect.GeneratedMethodAccessor27.invoke(Unknown Source)&lt;br/&gt;
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
 at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
 at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1028)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;/p&gt;</description>
                <environment></environment>
        <key id="13220370">SPARK-27100</key>
            <summary>Use `Array` instead of `Seq` in `FilePartition` to prevent StackOverflowError</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="parthc">Parth Chandra</assignee>
                                    <reporter username="KaiXu">KaiXu</reporter>
                        <labels>
                    </labels>
                <created>Fri, 8 Mar 2019 03:21:34 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:56 +0000</updated>
                            <resolved>Wed, 26 Jun 2019 07:49:09 +0000</resolved>
                                    <version>2.1.3</version>
                    <version>2.3.3</version>
                                    <fixVersion>2.4.4</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16787530" author="q79969786" created="Fri, 8 Mar 2019 04:47:21 +0000"  >&lt;p&gt;Could you try the latest Spark version please?&lt;/p&gt;</comment>
                            <comment id="16787565" author="kaixu" created="Fri, 8 Mar 2019 06:02:59 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yumwang&quot; class=&quot;user-hover&quot; rel=&quot;yumwang&quot;&gt;yumwang&lt;/a&gt;, I tried Spark2.3.3, it also has the similar issue.&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;main&quot; org.apache.spark.SparkException: Job aborted due to stage failure: Task serialization failed: java.lang.StackOverflowError&lt;br/&gt;
java.lang.StackOverflowError&lt;br/&gt;
 at java.lang.Exception.&amp;lt;init&amp;gt;(Exception.java:102)&lt;br/&gt;
 at java.lang.ReflectiveOperationException.&amp;lt;init&amp;gt;(ReflectiveOperationException.java:89)&lt;br/&gt;
 at java.lang.reflect.InvocationTargetException.&amp;lt;init&amp;gt;(InvocationTargetException.java:72)&lt;br/&gt;
 at sun.reflect.GeneratedMethodAccessor25.invoke(Unknown Source)&lt;br/&gt;
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
 at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
 at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1028)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)&lt;br/&gt;
 at scala.collection.immutable.List$SerializationProxy.writeObject(List.scala:468)&lt;br/&gt;
 at sun.reflect.GeneratedMethodAccessor25.invoke(Unknown Source)&lt;br/&gt;
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&lt;br/&gt;
 at java.lang.reflect.Method.invoke(Method.java:498)&lt;br/&gt;
 at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1028)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)&lt;br/&gt;
 at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)&lt;br/&gt;
 at scala.collection.immutable.List$SerializationProxy.writeObject(List.scala:468)&lt;br/&gt;
 at sun.reflect.GeneratedMethodAccessor25.invoke(Unknown Source)&lt;/p&gt;</comment>
                            <comment id="16787620" author="kaixu" created="Fri, 8 Mar 2019 07:27:53 +0000"  >&lt;p&gt;I have checked stderr log file(50M&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;) of the task,&#160; the stack trace is repeated as above but does not show any stack information about Spark, the issue seems exists since Spark1.1&#160;&lt;/p&gt;</comment>
                            <comment id="16787749" author="gurwls223" created="Fri, 8 Mar 2019 10:10:20 +0000"  >&lt;p&gt;Hm, can you show reproducible steps including codes? I think it should be checked if there&apos;s the same issue in the current master branch or not.&lt;/p&gt;</comment>
                            <comment id="16793233" author="kaixu" created="Fri, 15 Mar 2019 01:40:30 +0000"  >&lt;p&gt;hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt;, the workload I&apos;m running is ALS from Hibench, the code can be obtained from &lt;a href=&quot;https://github.com/intel-hadoop/HiBench/blob/master/sparkbench/ml/src/main/scala/com/intel/sparkbench/ml/ALSExample.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;here&lt;/a&gt;, and here is the &lt;a href=&quot;https://github.com/intel-hadoop/HiBench/blob/master/docs/run-sparkbench.md&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;doc &lt;/a&gt; on how to build and run.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Follow above doc to config the Hibench based on your cluster.&lt;/li&gt;
	&lt;li&gt;Edit {HIBENCH_HOME}/conf/benchmarks.lst, keep ml.als in this file to run ALS only.&lt;/li&gt;
	&lt;li&gt;Edit {HIBENCH_HOME}/conf/hibench.conf, change the value of hibench.scale.profile to gigantic.&lt;/li&gt;
	&lt;li&gt;Edit {HIBENCH_HOME}/conf/workloads/ml/al.conf, change the value of hibench.als.rank to 200, hibench.als.numIterations to 100&lt;/li&gt;
	&lt;li&gt;{HIBENCH_HOME}/conf/run_all.sh, to start the test.&lt;/li&gt;
	&lt;li&gt;Wait to about 30 iterations, it will fail with StackOverflowError&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="16797079" author="gurwls223" created="Wed, 20 Mar 2019 11:43:00 +0000"  >&lt;p&gt;Would you be interested in narrowing down the problem, so that people can test it against the master branch?&lt;/p&gt;</comment>
                            <comment id="16863375" author="parthc" created="Thu, 13 Jun 2019 18:47:27 +0000"  >&lt;p&gt;The stack overflow is due to serialization of a ShuffleMapTask (see attached file with complete stack) &lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12971716/12971716_SPARK-27100-Overflow.txt&quot; title=&quot;SPARK-27100-Overflow.txt attached to SPARK-27100&quot;&gt;SPARK-27100-Overflow.txt&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt; .&#160;&lt;/p&gt;

&lt;p&gt;ShuffleMapTask.partition is a FilePartition and FilePartition.files is a Stream which is essentially a linked list. It is therefore serialized recursively.&lt;br/&gt;
If the number of files in each partition is, say, 10000 files, recursing into a linked list of length 10000 causes a stack overflow. This is a general problem with serialization of Scala streams (and other collections that are lazily initialized) that is fixed in 2.13 (&lt;a href=&quot;https://github.com/scala/scala/pull/6676&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/scala/scala/pull/6676&lt;/a&gt;). &lt;/p&gt;

&lt;p&gt;The problem is only in Bucketed partitions. The corresponding implementation for non Bucketed partitions uses a StreamBuffer. &lt;br/&gt;
&#160;&lt;br/&gt;
Partial expansion of ShuffleMapTask just before the stack overflow -&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
obj = \{ShuffleMapTask@16639} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.scheduler.ShuffleMapTask.toString()
 taskBinary = \{TorrentBroadcast@17216} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.broadcast.TorrentBroadcast.toString()
 partition = \{FilePartition@17217} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.execution.datasources.FilePartition.toString()
 index = 0
 files = \{Stream$Cons@17244} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate scala.collection.immutable.Stream$Cons.toString()
 hd = \{PartitionedFile@17246} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.execution.datasources.PartitionedFile.toString()
 partitionValues = \{GenericInternalRow@17259} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.catalyst.expressions.GenericInternalRow.toString()
 filePath = &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//path/a.db/master/version=1/rangeid=000/part-00039-295e3ac1-760c-482e-8640-5e5d1539c2c9_00000.c000.gz.parquet&quot;&lt;/span&gt;
&lt;/span&gt; start = 0
 length = 225781388
 locations = \{&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[3]@17261} 
 tlVal = \{Stream$Cons@16687} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate scala.collection.immutable.Stream$Cons.toString()
 hd = \{PartitionedFile@17249} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.execution.datasources.PartitionedFile.toString()
 partitionValues = \{GenericInternalRow@17255} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.catalyst.expressions.GenericInternalRow.toString()
 filePath = &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//path/a.db/master/version=1/rangeid=001/part-00061-0346437e-7f8f-44ac-8739-94d1ee285c0b_00000.c000.gz.parquet&quot;&lt;/span&gt;
&lt;/span&gt; start = 0
 length = 431239612
 locations = \{&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[3]@17257} 
 tlVal = \{Stream$Cons@16812} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate scala.collection.immutable.Stream$Cons.toString()
 hd = \{PartitionedFile@17264} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.execution.datasources.PartitionedFile.toString()
 partitionValues = \{GenericInternalRow@17268} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.catalyst.expressions.GenericInternalRow.toString()
 filePath = &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//path/a.db/master/version=1/rangeid=002/part-00058-b3a99b18-140e-43ed-838e-276eaa45a5f3_00000.c000.gz.parquet&quot;&lt;/span&gt;
&lt;/span&gt; start = 0
 length = 219930113
 locations = \{&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[3]@17270} 
 tlVal = \{Stream$Cons@17265} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate scala.collection.immutable.Stream$Cons.toString()
 hd = \{PartitionedFile@17273} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.execution.datasources.PartitionedFile.toString()
 partitionValues = \{GenericInternalRow@17277} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate org.apache.spark.sql.catalyst.expressions.GenericInternalRow.toString()
 filePath = &lt;span class=&quot;code-quote&quot;&gt;&quot;hdfs:&lt;span class=&quot;code-comment&quot;&gt;//path/a.db/master/version=1/rangeid=003/part-00051-58be3faa-0611-49de-8546-1656b6086934_00000.c000.gz.parquet&quot;&lt;/span&gt;
&lt;/span&gt; start = 0
 length = 219503110
 locations = \{&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[3]@17279} 
 tlVal = \{Stream$Cons@17274} Method threw &lt;span class=&quot;code-quote&quot;&gt;&apos;java.lang.StackOverflowError&apos;&lt;/span&gt; exception. Cannot evaluate scala.collection.immutable.Stream$Cons.toString()
 tlGen = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
 tlGen = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
 tlGen = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
 tlGen = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16863381" author="parthc" created="Thu, 13 Jun 2019 18:59:07 +0000"  >&lt;p&gt;Opened a PR with a fix and a test to reproduce the issue.&#160;&lt;a href=&quot;https://github.com/apache/spark/pull/24865&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24865&lt;/a&gt;.&lt;br/&gt;
Thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dbtsai&quot; class=&quot;user-hover&quot; rel=&quot;dbtsai&quot;&gt;dbtsai&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; for offline help with this one. &lt;/p&gt;</comment>
                            <comment id="16871976" author="apachespark" created="Tue, 25 Jun 2019 04:05:02 +0000"  >&lt;p&gt;User &apos;parthchandra&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24957&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24957&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16873033" author="dbtsai" created="Wed, 26 Jun 2019 07:49:09 +0000"  >&lt;p&gt;Issue resolved by pull request 24957&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24957&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24957&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16891610" author="dongjoon" created="Wed, 24 Jul 2019 05:09:26 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=parthc&quot; class=&quot;user-hover&quot; rel=&quot;parthc&quot;&gt;parthc&lt;/a&gt;. I added you to the Apache Spark contributor group and assigned this issue to you.&lt;br/&gt;
Thank you for your contribution.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12761542">SPARK-4838</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12971716" name="SPARK-27100-Overflow.txt" size="365347" author="parthc" created="Thu, 13 Jun 2019 18:47:09 +0000"/>
                            <attachment id="12961681" name="stderr" size="52336331" author="KaiXu" created="Fri, 8 Mar 2019 07:34:43 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 16 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z00hfs:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>