<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:07:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-22340] pyspark setJobGroup doesn&apos;t match java threads</title>
                <link>https://issues.apache.org/jira/browse/SPARK-22340</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;With pyspark, &lt;tt&gt;sc.setJobGroup&lt;/tt&gt;&apos;s documentation says&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Assigns a group ID to all the jobs started by this thread until the group ID is set to a different value or cleared.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;However, this doesn&apos;t appear to be associated with Python threads, only with Java threads.  As such, a Python thread which calls this and then submits multiple jobs doesn&apos;t necessarily get its jobs associated with any particular spark job group.  For example:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
def run_jobs():
    sc.setJobGroup(&lt;span class=&quot;code-quote&quot;&gt;&apos;hello&apos;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&apos;hello jobs&apos;&lt;/span&gt;)
    x = sc.range(100).sum()
    y = sc.range(1000).sum()
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; x, y

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; concurrent.futures
with concurrent.futures.ThreadPoolExecutor() as executor:
    &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; = executor.submit(run_jobs)
    sc.cancelJobGroup(&lt;span class=&quot;code-quote&quot;&gt;&apos;hello&apos;&lt;/span&gt;)
    &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt;.result()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this example, depending how the action calls on the Python side are allocated to Java threads, the jobs for &lt;tt&gt;x&lt;/tt&gt; and &lt;tt&gt;y&lt;/tt&gt; won&apos;t necessarily be assigned the job group &lt;tt&gt;hello&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;First, we should clarify the docs if this truly is the case.&lt;/p&gt;

&lt;p&gt;Second, it would be really helpful if we could make the job group assignment reliable for a Python thread, though I&#8217;m not sure the best way to do this.  As it stands, job groups are pretty useless from the pyspark side, if we can&apos;t rely on this fact.&lt;/p&gt;

&lt;p&gt;My only idea so far is to mimic the TLS behavior on the Python side and then patch every point where job submission may take place to pass that in, but this feels pretty brittle. In my experience with py4j, controlling threading there is a challenge. &lt;/p&gt;</description>
                <environment></environment>
        <key id="13111578">SPARK-22340</key>
            <summary>pyspark setJobGroup doesn&apos;t match java threads</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gurwls223">Hyukjin Kwon</assignee>
                                    <reporter username="leif">Leif Mortenson</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Oct 2017 00:23:20 +0000</created>
                <updated>Mon, 12 Dec 2022 18:11:00 +0000</updated>
                            <resolved>Thu, 7 Nov 2019 21:47:42 +0000</resolved>
                                    <version>2.0.2</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16217535" author="leif" created="Tue, 24 Oct 2017 19:37:52 +0000"  >&lt;p&gt;This is less spooky than I initially thought, I will explain later tonight.&lt;/p&gt;</comment>
                            <comment id="16217835" author="leif" created="Tue, 24 Oct 2017 22:46:01 +0000"  >&lt;p&gt;Ok, this is fairly straightforward.  The problem is that from the Python side, &lt;tt&gt;setJobGroup&lt;/tt&gt; isn&apos;t thread-local, it&apos;s global.  Here is a tight reproducer:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;import concurrent.futures
import threading
import time
executor = concurrent.futures.ThreadPoolExecutor()

latch_1 = threading.Event()
latch_2 = threading.Event()

def wait(x):
    time.sleep(x)
    return x

def multiple_job_groups():
    sc.setJobGroup(&apos;imajobgroup&apos;, &apos;helloitme&apos;)
    groups = []
    groups.append(get_job_group())
    sc.parallelize([1, 1]).map(wait).collect()
    latch_2.set()
    latch_1.wait()
    groups.append(get_job_group())
    sc.parallelize([1, 1]).map(wait).collect()
    groups.append(get_job_group())
    return groups

def another_job_group():
    latch_2.wait()
    sc.setJobGroup(&apos;another&apos;, &apos;itnotme&apos;)
    sc.parallelize([1, 1]).map(wait).collect()
    latch_1.set()

future_1 = executor.submit(multiple_job_groups)
future_2 = executor.submit(another_job_group)
future_1.result()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The result is that &lt;tt&gt;another_job_group&lt;/tt&gt; modifies the local property in between the first and second executions of &lt;tt&gt;multiple_job_groups&lt;/tt&gt;&apos;s jobs, and we get this result:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;[&apos;imajobgroup&apos;, &apos;another&apos;, &apos;another&apos;]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think I can &quot;solve&quot; this by wrapping &lt;tt&gt;SparkContext&lt;/tt&gt; with a lock (to sequence the execution of &lt;tt&gt;setJobGroup&lt;/tt&gt; and something in py4j that will release the lock during JVM execution, which feels Very Dangerous.&lt;/p&gt;

&lt;p&gt;Would greatly appreciate it if we could do something to really solve this inside pyspark, but will attempt the Dangerous on my side for now.&lt;/p&gt;</comment>
                            <comment id="16219825" author="leif" created="Thu, 26 Oct 2017 01:28:39 +0000"  >&lt;p&gt;By monkey-patching &lt;tt&gt;SCCallSiteSync&lt;/tt&gt;, I&apos;m able to inject a call to &lt;tt&gt;setJobGroup&lt;/tt&gt; based on a python thread-local variable.  This is vulnerable to a race condition where another thread can call &lt;tt&gt;setJobGroup&lt;/tt&gt; in between my call to &lt;tt&gt;setJobGroup&lt;/tt&gt; and the subsequent action, which is not great, but I think low-ish risk and probably lower risk than trying to introduce sufficient locking around this.&lt;/p&gt;</comment>
                            <comment id="16872852" author="viirya" created="Wed, 26 Jun 2019 01:26:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt; Should we reopen this as you are open a PR for it now?&lt;/p&gt;</comment>
                            <comment id="16969583" author="gurwls223" created="Thu, 7 Nov 2019 21:47:42 +0000"  >&lt;p&gt;Issue resolved by pull request 24898&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24898&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24898&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16971723" author="tagar" created="Mon, 11 Nov 2019 16:46:02 +0000"  >&lt;p&gt;Glad to see this is solved.&#160;&lt;/p&gt;

&lt;p&gt;A nice side-effect should be somewhat better performance on some cases involving heavy python-java communication&lt;br/&gt;
on multi-numa/ multi-socket configurations. With static threads, Linux kernel will actually have a chance to &lt;br/&gt;
schedule threads on processors/cores that are more local to data&apos;s numa placement.&#160;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13255453">SPARK-29017</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 1 week, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3lmbj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>