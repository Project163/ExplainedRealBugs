<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:54:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21565] aggregate query fails with watermark on eventTime but works with watermark on timestamp column generated by current_timestamp</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21565</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;*Short Description: *&lt;/p&gt;

&lt;p&gt;Aggregation query fails with eventTime as watermark column while works with newTimeStamp column generated by running SQL with current_timestamp,&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Exception:&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Caused by: java.util.NoSuchElementException: None.get
	at scala.None$.get(Option.scala:347)
	at scala.None$.get(Option.scala:345)
	at org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anonfun$doExecute$3.apply(statefulOperators.scala:204)
	at org.apache.spark.sql.execution.streaming.StateStoreSaveExec$$anonfun$doExecute$3.apply(statefulOperators.scala:172)
	at org.apache.spark.sql.execution.streaming.state.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$StateStoreOps$$anonfun$1.apply(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:70)
	at org.apache.spark.sql.execution.streaming.state.&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;$StateStoreOps$$anonfun$1.apply(&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;.scala:65)
	at org.apache.spark.sql.execution.streaming.state.StateStoreRDD.compute(StateStoreRDD.scala:64)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;b&gt;Code to replicate:&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt; test

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.nio.file.{Files, Path, Paths}
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.text.SimpleDateFormat

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.types._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.{SparkSession}

&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.collection.JavaConverters._

object Test1 {

  def main(args: Array[&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;]) {

    val sparkSession = SparkSession
      .builder()
      .master(&lt;span class=&quot;code-quote&quot;&gt;&quot;local[*]&quot;&lt;/span&gt;)
      .appName(&lt;span class=&quot;code-quote&quot;&gt;&quot;Spark SQL basic example&quot;&lt;/span&gt;)
      .config(&lt;span class=&quot;code-quote&quot;&gt;&quot;spark.some.config.option&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;some-value&quot;&lt;/span&gt;)
      .getOrCreate()

    val sdf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SimpleDateFormat(&lt;span class=&quot;code-quote&quot;&gt;&quot;yyyy-MM-dd HH:mm:ss&quot;&lt;/span&gt;)
    val checkpointPath = &lt;span class=&quot;code-quote&quot;&gt;&quot;target/cp1&quot;&lt;/span&gt;
    val newEventsPath = Paths.get(&lt;span class=&quot;code-quote&quot;&gt;&quot;target/newEvents/&quot;&lt;/span&gt;).toAbsolutePath
    delete(newEventsPath)
    delete(Paths.get(checkpointPath).toAbsolutePath)
    Files.createDirectories(newEventsPath)


    val dfNewEvents= newEvents(sparkSession)
    dfNewEvents.createOrReplaceTempView(&lt;span class=&quot;code-quote&quot;&gt;&quot;dfNewEvents&quot;&lt;/span&gt;)

    &lt;span class=&quot;code-comment&quot;&gt;//The below works - Start
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;//    val dfNewEvents2 = sparkSession.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select *,current_timestamp as newTimeStamp from dfNewEvents &quot;&lt;/span&gt;).withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;newTimeStamp&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;2 seconds&quot;&lt;/span&gt;)
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;//    dfNewEvents2.createOrReplaceTempView(&lt;span class=&quot;code-quote&quot;&gt;&quot;dfNewEvents2&quot;&lt;/span&gt;)
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;//    val groupEvents = sparkSession.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select symbol,newTimeStamp, count(price) as count1 from dfNewEvents2 group by symbol,newTimeStamp&quot;&lt;/span&gt;)
&lt;/span&gt;    &lt;span class=&quot;code-comment&quot;&gt;// End
&lt;/span&gt;    
    
    &lt;span class=&quot;code-comment&quot;&gt;//The below doesn&apos;t work - Start
&lt;/span&gt;    val dfNewEvents2 = sparkSession.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select * from dfNewEvents &quot;&lt;/span&gt;).withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;eventTime&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;2 seconds&quot;&lt;/span&gt;)
     dfNewEvents2.createOrReplaceTempView(&lt;span class=&quot;code-quote&quot;&gt;&quot;dfNewEvents2&quot;&lt;/span&gt;)
      val groupEvents = sparkSession.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select symbol,eventTime, count(price) as count1 from dfNewEvents2 group by symbol,eventTime&quot;&lt;/span&gt;)
    &lt;span class=&quot;code-comment&quot;&gt;// - End
&lt;/span&gt;    
    
    val query1 = groupEvents.writeStream
      .outputMode(&lt;span class=&quot;code-quote&quot;&gt;&quot;append&quot;&lt;/span&gt;)
        .format(&lt;span class=&quot;code-quote&quot;&gt;&quot;console&quot;&lt;/span&gt;)
      .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;checkpointLocation&quot;&lt;/span&gt;, checkpointPath)
      .start(&lt;span class=&quot;code-quote&quot;&gt;&quot;./myop&quot;&lt;/span&gt;)

    val newEventFile1=newEventsPath.resolve(&lt;span class=&quot;code-quote&quot;&gt;&quot;eventNew1.json&quot;&lt;/span&gt;)
    Files.write(newEventFile1, List(
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;{&quot;&lt;/span&gt;symbol&lt;span class=&quot;code-quote&quot;&gt;&quot;: &quot;&lt;/span&gt;GOOG&lt;span class=&quot;code-quote&quot;&gt;&quot;,&quot;&lt;/span&gt;price&lt;span class=&quot;code-quote&quot;&gt;&quot;:100,&quot;&lt;/span&gt;eventTime&lt;span class=&quot;code-quote&quot;&gt;&quot;:&quot;&lt;/span&gt;2017-07-25T16:00:00.000-04:00&lt;span class=&quot;code-quote&quot;&gt;&quot;}&quot;&lt;/span&gt;&quot;&quot;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;&quot;&quot;{&quot;&lt;/span&gt;symbol&lt;span class=&quot;code-quote&quot;&gt;&quot;: &quot;&lt;/span&gt;GOOG&lt;span class=&quot;code-quote&quot;&gt;&quot;,&quot;&lt;/span&gt;price&lt;span class=&quot;code-quote&quot;&gt;&quot;:200,&quot;&lt;/span&gt;eventTime&lt;span class=&quot;code-quote&quot;&gt;&quot;:&quot;&lt;/span&gt;2017-07-25T16:00:00.000-04:00&lt;span class=&quot;code-quote&quot;&gt;&quot;}&quot;&lt;/span&gt;&quot;&quot;
    ).toIterable.asJava)
    query1.processAllAvailable()

    sparkSession.streams.awaitAnyTermination(10000)

  }

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def newEvents(sparkSession: SparkSession) = {
    val newEvents = Paths.get(&lt;span class=&quot;code-quote&quot;&gt;&quot;target/newEvents/&quot;&lt;/span&gt;).toAbsolutePath
    delete(newEvents)
    Files.createDirectories(newEvents)

    val dfNewEvents = sparkSession.readStream.schema(eventsSchema).json(newEvents.toString)&lt;span class=&quot;code-comment&quot;&gt;//.withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;eventTime&quot;&lt;/span&gt;,&lt;span class=&quot;code-quote&quot;&gt;&quot;2 seconds&quot;&lt;/span&gt;)
&lt;/span&gt;    dfNewEvents
  }

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; val eventsSchema = StructType(List(
    StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;symbol&quot;&lt;/span&gt;, StringType, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;),
    StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;price&quot;&lt;/span&gt;, DoubleType, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;),
    StructField(&lt;span class=&quot;code-quote&quot;&gt;&quot;eventTime&quot;&lt;/span&gt;, TimestampType, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)
  ))

  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def delete(dir: Path) = {
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(Files.exists(dir)) {
      Files.walk(dir).iterator().asScala.toList
        .map(p =&amp;gt; p.toFile)
        .sortWith((o1, o2) =&amp;gt; o1.compareTo(o2) &amp;gt; 0)
        .foreach(_.delete)
    }
  }

}


&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13090886">SPARK-21565</key>
            <summary>aggregate query fails with watermark on eventTime but works with watermark on timestamp column generated by current_timestamp</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="joseph.torres">Jose Torres</assignee>
                                    <reporter username="amit.assudani@gmail.com">Amit Assudani</reporter>
                        <labels>
                    </labels>
                <created>Fri, 28 Jul 2017 20:26:44 +0000</created>
                <updated>Mon, 7 Aug 2017 20:06:35 +0000</updated>
                            <resolved>Mon, 7 Aug 2017 20:02:33 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.2.1</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="16107933" author="a1ray" created="Mon, 31 Jul 2017 20:47:43 +0000"  >&lt;p&gt;I believe you need to use a window to group by your event time.&lt;/p&gt;</comment>
                            <comment id="16107968" author="amit.assudani@gmail.com" created="Mon, 31 Jul 2017 21:14:08 +0000"  >&lt;p&gt;I am not sure, does it mean we can not use watermark without windows - kind of on a microbatch level ? &lt;/p&gt;

&lt;p&gt;If that is the case, it should not work with current_timestamp and should have validation not to allow without windows.&lt;/p&gt;</comment>
                            <comment id="16108006" author="a1ray" created="Mon, 31 Jul 2017 21:36:56 +0000"  >&lt;p&gt;No nothing like the limitations of microbatches. The window can be made trivially small if you want only one timestamp per group, for example &lt;tt&gt;window(eventTime, &quot;1 microsecond&quot;)&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;And yes this should probably be checked in analysis if this is the intended limitation.&lt;/p&gt;</comment>
                            <comment id="16111451" author="zsxwing" created="Wed, 2 Aug 2017 18:12:35 +0000"  >&lt;p&gt;Thanks for reporting it. I can reproduce the error in a unit test. Still investigating it.&lt;/p&gt;</comment>
                            <comment id="16117173" author="zsxwing" created="Mon, 7 Aug 2017 20:06:05 +0000"  >&lt;p&gt;Resolved by &lt;a href=&quot;https://github.com/apache/spark/pull/18840&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18840&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 15 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3i5hr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>