<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:56:56 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-22446] Optimizer causing StringIndexerModel&apos;s indexer UDF to throw &quot;Unseen label&quot; exception incorrectly for filtered data.</title>
                <link>https://issues.apache.org/jira/browse/SPARK-22446</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;In the following, the `indexer` UDF defined inside the `org.apache.spark.ml.feature.StringIndexerModel.transform` method throws an &quot;Unseen label&quot; error, despite the label not being present in the transformed DataFrame.&lt;/p&gt;

&lt;p&gt;Here is the definition of the indexer UDF in the transform method:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    val indexer = udf { label: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; =&amp;gt;
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (labelToIndex.contains(label)) {
        labelToIndex(label)
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkException(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Unseen label: $label.&quot;&lt;/span&gt;)
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can demonstrate the error with a very simple example DataFrame.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.ml.feature.StringIndexer
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.ml.feature.StringIndexer

scala&amp;gt; &lt;span class=&quot;code-comment&quot;&gt;// first we create a DataFrame with three cities
&lt;/span&gt;
scala&amp;gt; val df = List(
     | (&lt;span class=&quot;code-quote&quot;&gt;&quot;A&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;London&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;StrA&quot;&lt;/span&gt;),
     | (&lt;span class=&quot;code-quote&quot;&gt;&quot;B&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;Bristol&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;),
     | (&lt;span class=&quot;code-quote&quot;&gt;&quot;C&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;New York&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;StrC&quot;&lt;/span&gt;)
     | ).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;ID&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;CITY&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;CONTENT&quot;&lt;/span&gt;)
df: org.apache.spark.sql.DataFrame = [ID: string, CITY: string ... 1 more field]

scala&amp;gt; df.show
+---+--------+-------+
| ID|    CITY|CONTENT|
+---+--------+-------+
|  A|  London|   StrA|
|  B| Bristol|   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|
|  C|New York|   StrC|
+---+--------+-------+


scala&amp;gt; &lt;span class=&quot;code-comment&quot;&gt;// then we remove the row with &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; in CONTENT column, which removes Bristol
&lt;/span&gt;
scala&amp;gt; val dfNoBristol = finalStatic.filter($&lt;span class=&quot;code-quote&quot;&gt;&quot;CONTENT&quot;&lt;/span&gt;.isNotNull)
dfNoBristol: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [ID: string, CITY: string ... 1 more field]

scala&amp;gt; dfNoBristol.show
+---+--------+-------+
| ID|    CITY|CONTENT|
+---+--------+-------+
|  A|  London|   StrA|
|  C|New York|   StrC|
+---+--------+-------+


scala&amp;gt; &lt;span class=&quot;code-comment&quot;&gt;// now create a StringIndexer &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the CITY column and fit to dfNoBristol
&lt;/span&gt;
scala&amp;gt; val model = {
     | &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringIndexer()
     | .setInputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;CITY&quot;&lt;/span&gt;)
     | .setOutputCol(&lt;span class=&quot;code-quote&quot;&gt;&quot;CITYIndexed&quot;&lt;/span&gt;)
     | .fit(dfNoBristol)
     | }
model: org.apache.spark.ml.feature.StringIndexerModel = strIdx_f5afa23333fb

scala&amp;gt; &lt;span class=&quot;code-comment&quot;&gt;// the StringIndexerModel has only two labels: &lt;span class=&quot;code-quote&quot;&gt;&quot;London&quot;&lt;/span&gt; and &lt;span class=&quot;code-quote&quot;&gt;&quot;New York&quot;&lt;/span&gt;
&lt;/span&gt;
scala&amp;gt; str.labels foreach println
London
New York

scala&amp;gt; &lt;span class=&quot;code-comment&quot;&gt;// transform our DataFrame to add an index column
&lt;/span&gt;
scala&amp;gt; val dfWithIndex = model.transform(dfNoBristol)
dfWithIndex: org.apache.spark.sql.DataFrame = [ID: string, CITY: string ... 2 more fields]

scala&amp;gt; dfWithIndex.show
+---+--------+-------+-----------+
| ID|    CITY|CONTENT|CITYIndexed|
+---+--------+-------+-----------+
|  A|  London|   StrA|        0.0|
|  C|New York|   StrC|        1.0|
+---+--------+-------+-----------+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The unexpected behaviour comes when we filter `dfWithIndex` for `CITYIndexed` equal to 1.0 and perform an action. The `indexer` UDF in `transform` method throws an exception reporting unseen label &quot;Bristol&quot;. This is irrational behaviour as far as the user of the API is concerned, because there is no such value as &quot;Bristol&quot; when do show all rows of `dfWithIndex`:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; dfWithIndex.filter($&lt;span class=&quot;code-quote&quot;&gt;&quot;CITYIndexed&quot;&lt;/span&gt; === 1.0).count
17/11/04 00:33:41 ERROR Executor: Exception in task 1.0 in stage 20.0 (TID 40)
org.apache.spark.SparkException: Failed to execute user defined function($anonfun$5: (string) =&amp;gt; &lt;span class=&quot;code-object&quot;&gt;double&lt;/span&gt;)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.agg_doAggregateWithoutKey$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:125)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:108)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: org.apache.spark.SparkException: Unseen label: Bristol.  To handle unseen labels, set Param handleInvalid to keep.
	at org.apache.spark.ml.feature.StringIndexerModel$$anonfun$5.apply(StringIndexer.scala:222)
	at org.apache.spark.ml.feature.StringIndexerModel$$anonfun$5.apply(StringIndexer.scala:208)
	... 13 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To understand what is happening here, note that an action is triggered when we call `StringIndexer.fit()`, before the `CITYIndexed === 1` filter is applied, so the StringIndexerModel sees only London and New York, as expected. Now compare the query plans for `dfWithIndex` and `dfWithIndex.filter($&quot;CITYIndexed&quot; === 1.0)`:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; dfWithIndex.explain
== Physical Plan ==
*Project [_1#3 AS ID#7, _2#4 AS CITY#8, _3#5 AS CONTENT#9, UDF(_2#4) AS CITYIndexed#159]
+- *Filter isnotnull(_3#5)
   +- LocalTableScan [_1#3, _2#4, _3#5]

scala&amp;gt; dfWithIndex.filter($&quot;CITYIndexed&quot; === 1.0).explain
== Physical Plan ==
*Project [_1#3 AS ID#7, _2#4 AS CITY#8, _3#5 AS CONTENT#9, UDF(_2#4) AS CITYIndexed#159]
+- *Filter (isnotnull(_3#5) &amp;amp;&amp;amp; (UDF(_2#4) = 1.0))
   +- LocalTableScan [_1#3, _2#4, _3#5]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that in the latter, the query plan has pushed the filter `$&quot;CITYIndexed&quot; === 1.0` back to be performed at the same stage as our null filter (`Filter (isnotnull(_3#5) &amp;amp;&amp;amp; (UDF(_2#4) = 1.0))`).&lt;/p&gt;

&lt;p&gt;With a debugger I have seen that both operands of `&amp;amp;&amp;amp;` are executed on each row of `df`: `isnotnull(_3#5)` and `UDF(_2#4) = 1.0`. Therefore, the UDF is passed the label `Bristol` despite isnotnull returning false for that row.&lt;/p&gt;

&lt;p&gt;If we cache the DataFrame `dfNoBristol` immediately after creating it, then there is no longer an error because the optimizer does not attempt to call the UDF on unseen data. The fact that we get different results depending on whether or not we call cache is a cause for concern.&lt;/p&gt;

&lt;p&gt;I have seen similar issues with pure SparkSql DataFrame operations when the DAG gets complicated (many joins, and aggregations). These are harder to isolate to such a simple example, but I plan to report them in the near future.&lt;/p&gt;</description>
                <environment>&lt;p&gt;spark-shell, local mode, macOS Sierra 10.12.6&lt;/p&gt;</environment>
        <key id="13116111">SPARK-22446</key>
            <summary>Optimizer causing StringIndexerModel&apos;s indexer UDF to throw &quot;Unseen label&quot; exception incorrectly for filtered data.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="viirya">L. C. Hsieh</assignee>
                                    <reporter username="IdRatherBeCoding">Greg Bellchambers</reporter>
                        <labels>
                    </labels>
                <created>Sat, 4 Nov 2017 00:57:05 +0000</created>
                <updated>Tue, 6 Mar 2018 03:01:26 +0000</updated>
                            <resolved>Wed, 8 Nov 2017 11:18:15 +0000</resolved>
                                    <version>2.0.2</version>
                    <version>2.1.2</version>
                    <version>2.2.1</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>ML</component>
                    <component>Optimizer</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="16239897" author="viirya" created="Mon, 6 Nov 2017 04:36:14 +0000"  >&lt;p&gt;For this special case, the simplest workaround is to set &lt;tt&gt;handleInvalid&lt;/tt&gt; as keep. Actually the another predicate &lt;tt&gt;isnotnull(_3#5)&lt;/tt&gt; can filter the row out if the UDF doesn&apos;t cause error with &lt;tt&gt;handleInvalid&lt;/tt&gt; as keep.&lt;/p&gt;

&lt;p&gt;The problem is happened at the optimizer when pushing predicates down through projection. For the catalyst expressions, applying on the supposedly filtered out data is not a problem because other predicates should filter it out.&lt;/p&gt;

&lt;p&gt;UDFs are special case because they can possibly cause runtime exception when applying on unexcepted data. It is not always safe to push down such predicates.&lt;/p&gt;

&lt;p&gt;However, because not all UDFs are not safe to push down, we may not want to disable all pushdown UDF predicates. Currently I think we should let such UDFs as non-deterministic and disable pushdown for it.&lt;/p&gt;
</comment>
                            <comment id="16239905" author="apachespark" created="Mon, 6 Nov 2017 04:49:03 +0000"  >&lt;p&gt;User &apos;viirya&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19662&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19662&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16243752" author="cloud_fan" created="Wed, 8 Nov 2017 11:18:15 +0000"  >&lt;p&gt;Issue resolved by pull request 19662&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19662&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19662&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16356340" author="josephkb" created="Thu, 8 Feb 2018 01:27:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=viirya&quot; class=&quot;user-hover&quot; rel=&quot;viirya&quot;&gt;viirya&lt;/a&gt; Did you confirm this is an issue in Spark 2.2 or earlier?&lt;/p&gt;</comment>
                            <comment id="16356506" author="viirya" created="Thu, 8 Feb 2018 05:19:53 +0000"  >&lt;p&gt;Yes, this is an issue in Spark 2.2. For earlier version, let me check it.&lt;/p&gt;</comment>
                            <comment id="16356525" author="viirya" created="Thu, 8 Feb 2018 06:06:54 +0000"  >&lt;p&gt;2.0 and 2.1 also have this issue.&lt;/p&gt;</comment>
                            <comment id="16384078" author="josephkb" created="Fri, 2 Mar 2018 19:54:00 +0000"  >&lt;p&gt;I see.  Do you have a sense of how hard it would be to backport this fix (definitely to 2.2 and maybe to 2.1 if it&apos;s easy)?&lt;/p&gt;</comment>
                            <comment id="16384618" author="viirya" created="Sat, 3 Mar 2018 11:14:24 +0000"  >&lt;p&gt;This fix uses an new API&#160;&#160;&lt;tt&gt;asNondeterministic&lt;/tt&gt; of &lt;tt&gt;UserDefinedFunction.&#160;&lt;/tt&gt;&lt;tt&gt;asNondeterministic&lt;/tt&gt; is added since 2.3.0. If we want to backport this fix, we need to backport the API too. It is not hard but it involves SQL codes. Should we backport it because of this fix?&lt;/p&gt;</comment>
                            <comment id="16386520" author="josephkb" created="Mon, 5 Mar 2018 18:44:15 +0000"  >&lt;p&gt;Maybe not then unless someone complains?&lt;/p&gt;</comment>
                            <comment id="16387191" author="viirya" created="Tue, 6 Mar 2018 03:01:26 +0000"  >&lt;p&gt;Yeah, sounds good.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 37 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3me8n:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>