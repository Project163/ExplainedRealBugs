<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:54:52 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-12717] pyspark broadcast fails when using multiple threads</title>
                <link>https://issues.apache.org/jira/browse/SPARK-12717</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following multi-threaded program that uses broadcast variables consistently throws exceptions like:  &lt;b&gt;Exception(&quot;Broadcast variable &apos;18&apos; not loaded!&quot;,)&lt;/b&gt; &amp;#8212; even when run with &quot;--master local&lt;span class=&quot;error&quot;&gt;&amp;#91;10&amp;#93;&lt;/span&gt;&quot;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;bug_spark.py&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;:                                                                                                           
    &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; pyspark                                                                                             
except:                                                                                                        
    pass                                                                                                       
from optparse &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; OptionParser                                                                              
                                                                                                               
def my_option_parser():                                                                                        
    op = OptionParser()                                                                                        
    op.add_option(&lt;span class=&quot;code-quote&quot;&gt;&quot;--parallelism&quot;&lt;/span&gt;, dest=&lt;span class=&quot;code-quote&quot;&gt;&quot;parallelism&quot;&lt;/span&gt;, type=&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;&quot;&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;=20)                                  
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; op                                                                                                  
                                                                                                               
def do_process(x, w):                                                                                          
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; x * w.value                                                                                         
                                                                                                               
def func(name, rdd, conf):                                                                                     
    new_rdd = rdd.map(lambda x :   do_process(x, conf))                                                        
    total = new_rdd.reduce(lambda x, y : x + y)                                                                
    count = rdd.count()                                                                                        
    print name, 1.0 * total / count                                                                            
                                                                                                               
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; __name__ == &lt;span class=&quot;code-quote&quot;&gt;&quot;__main__&quot;&lt;/span&gt;:                                                                                     
    &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; threading                                                                                           
    op = my_option_parser()                                                                                    
    options, args = op.parse_args()                                                                            
    sc = pyspark.SparkContext(appName=&lt;span class=&quot;code-quote&quot;&gt;&quot;Buggy&quot;&lt;/span&gt;)                                                                 
    data_rdd = sc.parallelize(range(0,1000), 1)                                                                
    confs = [ sc.broadcast(i) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in xrange(options.parallelism) ]                                           
    threads = [ threading.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;(target=func, args=[&lt;span class=&quot;code-quote&quot;&gt;&quot;thread_&quot;&lt;/span&gt; + str(i), data_rdd, confs[i]]) &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i in xrange(options.parallelism) ]                                                                                          
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; t in threads:                                                                                          
        t.start()                                                                                              
    &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; t in threads:                                                                                          
        t.join() 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Abridged run output:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;abridge_run.txt&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;% spark-submit --master local[10] bug_spark.py --parallelism 20
[snip]
16/01/08 17:10:20 ERROR Executor: Exception in task 0.0 in stage 9.0 (TID 9)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Network/Servers/mother.adverplex.com/Volumes/homeland/Users/walker/.spark/spark-1.6.0-bin-hadoop2.6/python/lib/pyspark.zip/pyspark/worker.py&quot;&lt;/span&gt;, line 98, in main
    command = pickleSer._read_with_length(infile)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Network/Servers/mother.adverplex.com/Volumes/homeland/Users/walker/.spark/spark-1.6.0-bin-hadoop2.6/python/lib/pyspark.zip/pyspark/serializers.py&quot;&lt;/span&gt;, line 164, in _read_with_length
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.loads(obj)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Network/Servers/mother.adverplex.com/Volumes/homeland/Users/walker/.spark/spark-1.6.0-bin-hadoop2.6/python/lib/pyspark.zip/pyspark/serializers.py&quot;&lt;/span&gt;, line 422, in loads
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; pickle.loads(obj)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Network/Servers/mother.adverplex.com/Volumes/homeland/Users/walker/.spark/spark-1.6.0-bin-hadoop2.6/python/lib/pyspark.zip/pyspark/broadcast.py&quot;&lt;/span&gt;, line 39, in _from_id
    raise Exception(&lt;span class=&quot;code-quote&quot;&gt;&quot;Broadcast variable &lt;span class=&quot;code-quote&quot;&gt;&apos;%s&apos;&lt;/span&gt; not loaded!&quot;&lt;/span&gt; % bid)
Exception: (Exception(&lt;span class=&quot;code-quote&quot;&gt;&quot;Broadcast variable &lt;span class=&quot;code-quote&quot;&gt;&apos;6&apos;&lt;/span&gt; not loaded!&quot;&lt;/span&gt;,), &amp;lt;function _from_id at 0xce7a28&amp;gt;, (6L,))

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.&amp;lt;init&amp;gt;(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
[snip]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;Linux, python 2.6 or python 2.7.&lt;/p&gt;</environment>
        <key id="12928758">SPARK-12717</key>
            <summary>pyspark broadcast fails when using multiple threads</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bryanc">Bryan Cutler</assignee>
                                    <reporter username="efwalkermit">Edward Walker</reporter>
                        <labels>
                    </labels>
                <created>Fri, 8 Jan 2016 22:18:19 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:54 +0000</updated>
                            <resolved>Tue, 1 Aug 2017 22:40:29 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>2.1.2</fixVersion>
                    <fixVersion>2.2.1</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>4</votes>
                                    <watches>17</watches>
                                                                                                                <comments>
                            <comment id="15716576" author="agritsenko" created="Fri, 2 Dec 2016 21:30:10 +0000"  >&lt;p&gt;I&apos;m having the same problem when trying to optimize a production environment.&lt;br/&gt;
Is there any update on this issue? Is it being picked up?&lt;/p&gt;

&lt;p&gt;EDIT: It&apos;s still an issue in pyspark 2.0.2&lt;/p&gt;

&lt;p&gt;Alexey&lt;/p&gt;</comment>
                            <comment id="15819883" author="gurwls223" created="Thu, 12 Jan 2017 02:02:07 +0000"  >&lt;p&gt;It still happens in the current master.&lt;/p&gt;</comment>
                            <comment id="15958336" author="garfieldog" created="Thu, 6 Apr 2017 05:57:22 +0000"  >&lt;p&gt;I met the same problem with pyspark 2.1.0. Any progress?&lt;/p&gt;</comment>
                            <comment id="15968945" author="maver1ck" created="Fri, 14 Apr 2017 12:08:28 +0000"  >&lt;p&gt;Same problem with Python3.&lt;/p&gt;

&lt;p&gt;CC: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15975910" author="apachespark" created="Thu, 20 Apr 2017 01:47:03 +0000"  >&lt;p&gt;User &apos;vundela&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17694&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17694&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15977182" author="vsr" created="Thu, 20 Apr 2017 18:15:22 +0000"  >&lt;p&gt;Please find the attached log with fix for the following command &lt;br/&gt;
spark2-submit  --master local&lt;span class=&quot;error&quot;&gt;&amp;#91;20&amp;#93;&lt;/span&gt; bug_spark.py --parallelism 1000 &amp;gt;&amp;amp; run.log&lt;/p&gt;</comment>
                            <comment id="15979210" author="apachespark" created="Fri, 21 Apr 2017 18:46:05 +0000"  >&lt;p&gt;User &apos;vundela&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17722&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17722&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16092756" author="maver1ck" created="Wed, 19 Jul 2017 08:05:45 +0000"  >&lt;p&gt;Any progress with this error ?&lt;br/&gt;
I have patched from this thread merged and it&apos;s working fine.&lt;br/&gt;
Maybe we can merge this to master? (and other branches)&lt;/p&gt;</comment>
                            <comment id="16095432" author="apachespark" created="Thu, 20 Jul 2017 21:53:02 +0000"  >&lt;p&gt;User &apos;BryanCutler&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18695&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18695&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16109911" author="gurwls223" created="Tue, 1 Aug 2017 22:34:17 +0000"  >&lt;p&gt;Issue resolved by pull request 18695&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18695&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18695&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;but it looks I can&apos;t set &lt;tt&gt;Assignee&lt;/tt&gt;. Could anyone help me set this and resolve this?&lt;/p&gt;</comment>
                            <comment id="16109917" author="srowen" created="Tue, 1 Aug 2017 22:37:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt; I added you to the Committers group in JIRA, maybe that lets you. But I also just assigned this one.&lt;/p&gt;</comment>
                            <comment id="16109923" author="gurwls223" created="Tue, 1 Aug 2017 22:38:33 +0000"  >&lt;p&gt;I see. Thank you. Yes, I am seeing now.&lt;/p&gt;</comment>
                            <comment id="16110007" author="bryanc" created="Tue, 1 Aug 2017 23:55:15 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hyukjin.kwon&quot; class=&quot;user-hover&quot; rel=&quot;hyukjin.kwon&quot;&gt;hyukjin.kwon&lt;/a&gt;!  What are your thoughts on backporting this for 2.2?  &lt;/p&gt;</comment>
                            <comment id="16110014" author="gurwls223" created="Wed, 2 Aug 2017 00:04:40 +0000"  >&lt;p&gt;Would you mind if I ask open a backport? Just want to check if it passes the test for sure.&lt;/p&gt;</comment>
                            <comment id="16111304" author="bryanc" created="Wed, 2 Aug 2017 16:59:04 +0000"  >&lt;p&gt;Sure, I&apos;ll open a PR for 2.2 and ping you.&lt;/p&gt;</comment>
                            <comment id="16179421" author="avloss" created="Mon, 25 Sep 2017 17:43:53 +0000"  >&lt;p&gt;This looks closed, but I still had this same issue again:&lt;br/&gt;
python 3.6.1&lt;br/&gt;
spark 2.2.0&lt;/p&gt;</comment>
                            <comment id="16179440" author="bryanc" created="Mon, 25 Sep 2017 17:57:14 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=avloss&quot; class=&quot;user-hover&quot; rel=&quot;avloss&quot;&gt;avloss&lt;/a&gt;, the fix will be in Spark 2.1.2 which will be released soon, Spark 2.2.1 which is still pending, and Spark 2.3 when that is released.&lt;/p&gt;</comment>
                            <comment id="16326006" author="codlife" created="Mon, 15 Jan 2018 08:47:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bryanc&quot; class=&quot;user-hover&quot; rel=&quot;bryanc&quot;&gt;bryanc&lt;/a&gt; I use pyspark 2.2.0, got the same error. which pyspark version is ok ? thankyou!&lt;/p&gt;</comment>
                            <comment id="16326459" author="bryanc" created="Mon, 15 Jan 2018 17:42:22 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=codlife&quot; class=&quot;user-hover&quot; rel=&quot;codlife&quot;&gt;codlife&lt;/a&gt;, you can use Spark 2.2.1 which was released in December or the upcoming release of 2.3.0, both have this fix.&lt;/p&gt;</comment>
                            <comment id="16691281" author="apachespark" created="Mon, 19 Nov 2018 05:48:37 +0000"  >&lt;p&gt;User &apos;BryanCutler&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18825&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18825&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16691282" author="apachespark" created="Mon, 19 Nov 2018 05:49:48 +0000"  >&lt;p&gt;User &apos;BryanCutler&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18825&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18825&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12864333" name="run.log" size="5408118" author="vsr" created="Thu, 20 Apr 2017 18:15:22 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2r25j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>