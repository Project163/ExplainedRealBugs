<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:36:48 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-12625] SparkR is using deprecated APIs</title>
                <link>https://issues.apache.org/jira/browse/SPARK-12625</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;See the test failure for the following pull request:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/10559&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10559&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/48642/consoleFull&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/48642/consoleFull&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SparkR is using a lot of deprecated APIs.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;========================================================================
Running SparkR tests
========================================================================
Loading required &lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;: methods

Attaching &lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;SparkR&apos;&lt;/span&gt;

The following object is masked from &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;:testthat&apos;&lt;/span&gt;:

    describe

The following objects are masked from &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;:stats&apos;&lt;/span&gt;:

    cov, filter, lag, na.omit, predict, sd, &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;

The following objects are masked from &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;:base&apos;&lt;/span&gt;:

    colnames, colnames&amp;lt;-, intersect, rank, rbind, sample, subset,
    summary, table, transform

SerDe functionality : ...................
functions on binary files : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
....
binary functions : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
...........
broadcast variables : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
..
functions in client.R : .....
test functions in sparkR.R : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
........Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
..........
include an external JAR in SparkContext : ..
include R packages : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context

MLlib functions : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
............
parallelize() and collect() : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
.............................
basic RDD functions : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
...........................................................................................................................................................................................................................................................................................................................................................................................................................................
partitionBy, groupByKey, reduceByKey etc. : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
....................
SparkSQL functions : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
.......................................................1...................................................................................2.3....4......................................................................................................................5............6.....................................................................................................................................7............................................................................8........................................................................
tests RDD function take() : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
................
the textFile() function : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
.............
functions in utils.R : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
.......................

1. Error: create DataFrame from RDD --------------------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: insertInto(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;people&quot;&lt;/span&gt;) at test_sparkSQL.R:174
5: insertInto(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;people&quot;&lt;/span&gt;)
6: .local(x, tableName, ...)
7: callJMethod(x@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;insertInto&quot;&lt;/span&gt;, tableName, overwrite)
8: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
9: stop(readString(conn))

2. Error: read/write json files ------------------------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: write.df(df, jsonPath2, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;, mode = &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;) at test_sparkSQL.R:404
5: write.df(df, jsonPath2, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;, mode = &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;)
6: .local(df, path, ...)
7: callJMethod(df@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;save&quot;&lt;/span&gt;, source, jmode, options)
8: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
9: stop(readString(conn))

3. Error: jsonRDD() on a RDD with json string ----------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: jsonRDD(sqlContext, rdd) at test_sparkSQL.R:426
5: callJMethod(sqlContext, &lt;span class=&quot;code-quote&quot;&gt;&quot;jsonRDD&quot;&lt;/span&gt;, callJMethod(getJRDD(rdd), &lt;span class=&quot;code-quote&quot;&gt;&quot;rdd&quot;&lt;/span&gt;), samplingRatio)
6: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
7: stop(readString(conn))

4. Error: insertInto() on a registered table -----------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: write.df(df, parquetPath, &lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;) at test_sparkSQL.R:465
5: write.df(df, parquetPath, &lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;)
6: .local(df, path, ...)
7: callJMethod(df@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;save&quot;&lt;/span&gt;, source, jmode, options)
8: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
9: stop(readString(conn))

5. Error: subsetting -----------------------------------------------------------
error in evaluating the argument &lt;span class=&quot;code-quote&quot;&gt;&apos;i&apos;&lt;/span&gt; in selecting a method &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; function &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt;: 
Calls: %in% -&amp;gt; %in% -&amp;gt; callJMethod -&amp;gt; invokeJava

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: df[df$age %in% c(19, 30), 1:2] at test_sparkSQL.R:844

6. Error: test HiveContext -----------------------------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: saveAsTable(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;json2&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;append&quot;&lt;/span&gt;, path = jsonPath2) at test_sparkSQL.R:905
5: saveAsTable(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;json2&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;append&quot;&lt;/span&gt;, path = jsonPath2)
6: callJMethod(df@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;saveAsTable&quot;&lt;/span&gt;, tableName, source, jmode, options)
7: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
8: stop(readString(conn))

7. Error: filter() on a DataFrame ----------------------------------------------
error in evaluating the argument &lt;span class=&quot;code-quote&quot;&gt;&apos;condition&apos;&lt;/span&gt; in selecting a method &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; function &lt;span class=&quot;code-quote&quot;&gt;&apos;where&apos;&lt;/span&gt;: 
Calls: %in% -&amp;gt; %in% -&amp;gt; callJMethod -&amp;gt; invokeJava

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: where(df, df$age %in% c(19)) at test_sparkSQL.R:1260

8. Error: read/write Parquet files ---------------------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: write.df(df, parquetPath, &lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;, mode = &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;) at test_sparkSQL.R:1472
5: write.df(df, parquetPath, &lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;, mode = &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;)
6: .local(df, path, ...)
7: callJMethod(df@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;save&quot;&lt;/span&gt;, source, jmode, options)
8: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
9: stop(readString(conn))
Error: Test failures
Execution halted
Loading required &lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;: methods

Attaching &lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;: &lt;span class=&quot;code-quote&quot;&gt;&apos;SparkR&apos;&lt;/span&gt;

The following object is masked from &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;:testthat&apos;&lt;/span&gt;:

    describe

The following objects are masked from &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;:stats&apos;&lt;/span&gt;:

    cov, filter, lag, na.omit, predict, sd, &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;

The following objects are masked from &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-keyword&quot;&gt;package&lt;/span&gt;:base&apos;&lt;/span&gt;:

    colnames, colnames&amp;lt;-, intersect, rank, rbind, sample, subset,
    summary, table, transform

SerDe functionality : ...................
functions on binary files : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
....
binary functions : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
...........
broadcast variables : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
..
functions in client.R : .....
test functions in sparkR.R : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
........Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
..........
include an external JAR in SparkContext : ..
include R packages : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context

MLlib functions : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
............
parallelize() and collect() : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
.............................
basic RDD functions : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
...........................................................................................................................................................................................................................................................................................................................................................................................................................................
partitionBy, groupByKey, reduceByKey etc. : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
....................
SparkSQL functions : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
.......................................................1...................................................................................2.3....4......................................................................................................................5............6.....................................................................................................................................7............................................................................8........................................................................
tests RDD function take() : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
................
the textFile() function : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
.............
functions in utils.R : Re-using existing Spark Context. Please stop SparkR with sparkR.stop() or restart R to create a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Spark Context
.......................

1. Error: create DataFrame from RDD --------------------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: insertInto(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;people&quot;&lt;/span&gt;) at test_sparkSQL.R:174
5: insertInto(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;people&quot;&lt;/span&gt;)
6: .local(x, tableName, ...)
7: callJMethod(x@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;insertInto&quot;&lt;/span&gt;, tableName, overwrite)
8: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
9: stop(readString(conn))

2. Error: read/write json files ------------------------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: write.df(df, jsonPath2, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;, mode = &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;) at test_sparkSQL.R:404
5: write.df(df, jsonPath2, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;, mode = &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;)
6: .local(df, path, ...)
7: callJMethod(df@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;save&quot;&lt;/span&gt;, source, jmode, options)
8: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
9: stop(readString(conn))

3. Error: jsonRDD() on a RDD with json string ----------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: jsonRDD(sqlContext, rdd) at test_sparkSQL.R:426
5: callJMethod(sqlContext, &lt;span class=&quot;code-quote&quot;&gt;&quot;jsonRDD&quot;&lt;/span&gt;, callJMethod(getJRDD(rdd), &lt;span class=&quot;code-quote&quot;&gt;&quot;rdd&quot;&lt;/span&gt;), samplingRatio)
6: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
7: stop(readString(conn))

4. Error: insertInto() on a registered table -----------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: write.df(df, parquetPath, &lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;) at test_sparkSQL.R:465
5: write.df(df, parquetPath, &lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;)
6: .local(df, path, ...)
7: callJMethod(df@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;save&quot;&lt;/span&gt;, source, jmode, options)
8: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
9: stop(readString(conn))

5. Error: subsetting -----------------------------------------------------------
error in evaluating the argument &lt;span class=&quot;code-quote&quot;&gt;&apos;i&apos;&lt;/span&gt; in selecting a method &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; function &lt;span class=&quot;code-quote&quot;&gt;&apos;[&apos;&lt;/span&gt;: 
Calls: %in% -&amp;gt; %in% -&amp;gt; callJMethod -&amp;gt; invokeJava

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: df[df$age %in% c(19, 30), 1:2] at test_sparkSQL.R:844

6. Error: test HiveContext -----------------------------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: saveAsTable(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;json2&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;append&quot;&lt;/span&gt;, path = jsonPath2) at test_sparkSQL.R:905
5: saveAsTable(df, &lt;span class=&quot;code-quote&quot;&gt;&quot;json2&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;append&quot;&lt;/span&gt;, path = jsonPath2)
6: callJMethod(df@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;saveAsTable&quot;&lt;/span&gt;, tableName, source, jmode, options)
7: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
8: stop(readString(conn))

7. Error: filter() on a DataFrame ----------------------------------------------
error in evaluating the argument &lt;span class=&quot;code-quote&quot;&gt;&apos;condition&apos;&lt;/span&gt; in selecting a method &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; function &lt;span class=&quot;code-quote&quot;&gt;&apos;where&apos;&lt;/span&gt;: 
Calls: %in% -&amp;gt; %in% -&amp;gt; callJMethod -&amp;gt; invokeJava

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: where(df, df$age %in% c(19)) at test_sparkSQL.R:1260

8. Error: read/write Parquet files ---------------------------------------------

1: withCallingHandlers(eval(code, new_test_environment), error = capture_calls, message = function(c) invokeRestart(&lt;span class=&quot;code-quote&quot;&gt;&quot;muffleMessage&quot;&lt;/span&gt;))
2: eval(code, new_test_environment)
3: eval(expr, envir, enclos)
4: write.df(df, parquetPath, &lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;, mode = &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;) at test_sparkSQL.R:1472
5: write.df(df, parquetPath, &lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;, mode = &lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;)
6: .local(df, path, ...)
7: callJMethod(df@sdf, &lt;span class=&quot;code-quote&quot;&gt;&quot;save&quot;&lt;/span&gt;, source, jmode, options)
8: invokeJava(isStatic = FALSE, objId$id, methodName, ...)
9: stop(readString(conn))
Error: Test failures
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12927066">SPARK-12625</key>
            <summary>SparkR is using deprecated APIs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="felixcheung">Felix Cheung</assignee>
                                    <reporter username="rxin">Reynold Xin</reporter>
                        <labels>
                    </labels>
                <created>Mon, 4 Jan 2016 20:07:51 +0000</created>
                <updated>Tue, 5 Jan 2016 06:32:06 +0000</updated>
                            <resolved>Tue, 5 Jan 2016 06:32:06 +0000</resolved>
                                                    <fixVersion>2.0.0</fixVersion>
                                    <component>SparkR</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15081702" author="rxin" created="Mon, 4 Jan 2016 20:08:15 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shivaram&quot; class=&quot;user-hover&quot; rel=&quot;shivaram&quot;&gt;shivaram&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=felixcheung&quot; class=&quot;user-hover&quot; rel=&quot;felixcheung&quot;&gt;felixcheung&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Can one of you fix the above? I might just disable the R test first in order to get that in.&lt;/p&gt;</comment>
                            <comment id="15081903" author="felixcheung" created="Mon, 4 Jan 2016 22:10:27 +0000"  >&lt;p&gt;Is this the complete set of API to be removed? I took a look and think we should be able to address this quickly.&lt;br/&gt;
I will start this afternoon. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15081905" author="rxin" created="Mon, 4 Jan 2016 22:11:15 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=felixcheung&quot; class=&quot;user-hover&quot; rel=&quot;felixcheung&quot;&gt;felixcheung&lt;/a&gt; that should be it. Thanks!&lt;/p&gt;</comment>
                            <comment id="15082188" author="apachespark" created="Tue, 5 Jan 2016 01:38:03 +0000"  >&lt;p&gt;User &apos;felixcheung&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/10584&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/10584&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 46 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2qrq7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329449">2.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>