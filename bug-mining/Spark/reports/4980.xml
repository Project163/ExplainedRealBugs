<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:54:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18004] DataFrame filter Predicate push-down fails for Oracle Timestamp type columns</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18004</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;DataFrame filter Predicate push-down fails for Oracle Timestamp type columns with Exception java.sql.SQLDataException: ORA-01861: literal does not match format string:&lt;/p&gt;

&lt;p&gt;Java source code (this code works fine for mysql &amp;amp; mssql databases) :&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;//DataFrame df = create a DataFrame over an Oracle table
df = df.filter(df.col(&quot;TS&quot;).lt(new java.sql.Timestamp(System.currentTimeMillis())));
		df.explain();
		df.show();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Log statements with the Exception:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Schema: root
 |-- ID: string (nullable = false)
 |-- TS: timestamp (nullable = true)
 |-- DEVICE_ID: string (nullable = true)
 |-- REPLACEMENT: string (nullable = true)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;== Physical Plan ==
Filter (TS#1 &amp;lt; 1476861841934000)
+- Scan JDBCRelation(jdbc:oracle:thin:@10.0.0.111:1521:orcl,ORATABLE,[Lorg.apache.spark.Partition;@78c74647,{user=user, password=pwd, url=jdbc:oracle:thin:@10.0.0.111:1521:orcl, dbtable=ORATABLE, driver=oracle.jdbc.driver.OracleDriver})[ID#0,TS#1,DEVICE_ID#2,REPLACEMENT#3] PushedFilters: [LessThan(TS,2016-10-19 12:54:01.934)]
2016-10-19 12:54:04,268 ERROR [Executor task launch worker-0] org.apache.spark.executor.Executor
Exception in task 0.0 in stage 0.0 (TID 0)

java.sql.SQLDataException: ORA-01861: literal does not match format string

	at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:461)
	at oracle.jdbc.driver.T4CTTIoer.processError(T4CTTIoer.java:402)
	at oracle.jdbc.driver.T4C8Oall.processError(T4C8Oall.java:1065)
	at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:681)
	at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:256)
	at oracle.jdbc.driver.T4C8Oall.doOALL(T4C8Oall.java:577)
	at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:239)
	at oracle.jdbc.driver.T4CPreparedStatement.doOall8(T4CPreparedStatement.java:75)
	at oracle.jdbc.driver.T4CPreparedStatement.executeForDescribe(T4CPreparedStatement.java:1043)
	at oracle.jdbc.driver.OracleStatement.executeMaybeDescribe(OracleStatement.java:1111)
	at oracle.jdbc.driver.OracleStatement.doExecuteWithTimeout(OracleStatement.java:1353)
	at oracle.jdbc.driver.OraclePreparedStatement.executeInternal(OraclePreparedStatement.java:4485)
	at oracle.jdbc.driver.OraclePreparedStatement.executeQuery(OraclePreparedStatement.java:4566)
	at oracle.jdbc.driver.OraclePreparedStatementWrapper.executeQuery(OraclePreparedStatementWrapper.java:5251)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$$anon$1.&amp;lt;init&amp;gt;(JDBCRDD.scala:383)
	at org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:359)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13013426">SPARK-18004</key>
            <summary>DataFrame filter Predicate push-down fails for Oracle Timestamp type columns</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Rui Zha">Rui Zha</assignee>
                                    <reporter username="snalapure@dataken.net">Suhas Nalapure</reporter>
                        <labels>
                    </labels>
                <created>Wed, 19 Oct 2016 07:43:08 +0000</created>
                <updated>Mon, 3 Jul 2017 00:41:41 +0000</updated>
                            <resolved>Mon, 3 Jul 2017 00:41:41 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="15670571" author="hvanhovell" created="Wed, 16 Nov 2016 14:41:28 +0000"  >&lt;p&gt;So there seems to something going on with the date format here. Could you check what query Spark SQL is sending to Oracle?&lt;/p&gt;</comment>
                            <comment id="15673885" author="snalapure@dataken.net" created="Thu, 17 Nov 2016 14:40:23 +0000"  >&lt;p&gt;Date format as per the physical plan logged by Spark Dataframe:   PushedFilters: &lt;span class=&quot;error&quot;&gt;&amp;#91;LessThan(TS,2016-11-17 19:42:01.057)&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Confirmed the same from Oracle query logs as well: WHERE TS &amp;lt; &apos;2016-11-17 19:42:01.057&apos;&lt;/p&gt;</comment>
                            <comment id="15673904" author="hvanhovell" created="Thu, 17 Nov 2016 14:50:21 +0000"  >&lt;p&gt;which format should be passed to oracle?&lt;/p&gt;</comment>
                            <comment id="15676091" author="snalapure@dataken.net" created="Fri, 18 Nov 2016 08:01:32 +0000"  >&lt;p&gt;The date/timestamp format Oracle expects may vary from instance to instance based on the configuration of parameters NLS_TIMESTAMP_FORMAT and NLS_DATE_FORMAT . So ideal solution would be to use the to_timestamp and to_date Oracle functions. E.g. to_timestamp(&apos;12-01-2012 21:24:00&apos;, &apos;dd-mm-yyyy hh24:mi:ss&apos;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/8855378/oracle-sql-timestamps-in-where-clause&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://stackoverflow.com/questions/8855378/oracle-sql-timestamps-in-where-clause&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://docs.oracle.com/cd/B19306_01/server.102/b14225/ch4datetime.htm#i1006312&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.oracle.com/cd/B19306_01/server.102/b14225/ch4datetime.htm#i1006312&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15682989" author="maropu" created="Mon, 21 Nov 2016 09:30:28 +0000"  >&lt;p&gt;The current spark Jdbc interface (JdbcDialect) cannot handle formats for database-dependent timestamps and just puts `Timestamp#toString` in where clauses (&lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JDBCRDD.scala#L95&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JDBCRDD.scala#L95&lt;/a&gt;). One solution is to transform this `Timestamp` into a database-specific timestamp format like &lt;a href=&quot;https://github.com/apache/spark/compare/master...maropu:SPARK-18004#diff-5a29ce8f760092fb4a9c1f190cc2f61cR96&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/compare/master...maropu:SPARK-18004#diff-5a29ce8f760092fb4a9c1f190cc2f61cR96&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16002282" author="tenggyut" created="Tue, 9 May 2017 08:31:09 +0000"  >&lt;p&gt;a silly but doable workaround: cast TimestampType row to LongType and compare the inner representation...&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;src.filter(col(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp_col&quot;&lt;/span&gt;).&lt;span class=&quot;code-keyword&quot;&gt;cast&lt;/span&gt;(LongType).*(1000l) &amp;gt; condition.asInstanceOf[Timestamp].getTime)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16008856" author="grahn" created="Fri, 12 May 2017 22:51:10 +0000"  >&lt;p&gt;The right solution here is to make an explicit cast on the string representation of the timestamp value and not rely on implicit casting by the database&lt;br/&gt;
ANSI casting should work in nearly every RDBMS out there if the string is ISO 8601 format.  Eg.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;select timestamp &apos;2016-10-19 12:54:01.934&apos;;
        timestamp
-------------------------
 2016-10-19 12:54:01.934

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16010621" author="phalverson" created="Mon, 15 May 2017 14:36:57 +0000"  >&lt;p&gt;Here&apos;s the culprit, a private function that converts a scala value to a SQL literal. Note use of &lt;tt&gt;toString&lt;/tt&gt; to format dates and timestamps. Seems like there should be some hook to a &lt;tt&gt;JDBCDialect&lt;/tt&gt; that can handle vendor-specific syntax etc.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  /**
   * Converts value to SQL expression.
   */
  &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; def compileValue(value: Any): Any = value match {
    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; stringValue: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; =&amp;gt; s&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-quote&quot;&gt;&apos;${escapeSql(stringValue)}&apos;&lt;/span&gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; timestampValue: Timestamp =&amp;gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-quote&quot;&gt;&apos;&quot;&lt;/span&gt; + timestampValue + &lt;span class=&quot;code-quote&quot;&gt;&quot;&apos;&lt;/span&gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; dateValue: Date =&amp;gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-quote&quot;&gt;&apos;&quot;&lt;/span&gt; + dateValue + &lt;span class=&quot;code-quote&quot;&gt;&quot;&apos;&lt;/span&gt;&quot;&lt;/span&gt;
    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; arrayValue: Array[Any] =&amp;gt; arrayValue.map(compileValue).mkString(&lt;span class=&quot;code-quote&quot;&gt;&quot;, &quot;&lt;/span&gt;)
    &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; value
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16060795" author="apachespark" created="Fri, 23 Jun 2017 12:13:04 +0000"  >&lt;p&gt;User &apos;SharpRay&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18404&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18404&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16060963" author="rui zha" created="Fri, 23 Jun 2017 14:18:10 +0000"  >&lt;p&gt;The PR 18404 is closed. I will resend the PR later.&lt;/p&gt;</comment>
                            <comment id="16061770" author="apachespark" created="Sat, 24 Jun 2017 03:11:03 +0000"  >&lt;p&gt;User &apos;SharpRay&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18411&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18411&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16066162" author="apachespark" created="Wed, 28 Jun 2017 08:56:03 +0000"  >&lt;p&gt;User &apos;SharpRay&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18451&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18451&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13074865">SPARK-20885</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 20 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i352tb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>