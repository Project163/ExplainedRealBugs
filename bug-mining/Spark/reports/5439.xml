<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:57:56 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-22967] VersionSuite failed on Windows caused by Windows format path</title>
                <link>https://issues.apache.org/jira/browse/SPARK-22967</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;On Windows system, two unit test case would fail while running VersionSuite (&quot;A simple set of tests that call the methods of a `HiveClient`, loading different version of hive from maven central.&quot;)&lt;/p&gt;

&lt;p&gt;Failed A : test(s&quot;$version: read avro file containing decimal&quot;) &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:java.lang.IllegalArgumentException: Can not create a Path from an empty string);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Failed B: test(s&quot;$version: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-17920&quot; title=&quot;HiveWriterContainer passes null configuration to serde.initialize, causing NullPointerException in AvroSerde when using avro.schema.url&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-17920&quot;&gt;&lt;del&gt;SPARK-17920&lt;/del&gt;&lt;/a&gt;: Insert into/overwrite avro table&quot;)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Unable to infer the schema. The schema specification is required to create the table `&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;`.`tab2`.;
org.apache.spark.sql.AnalysisException: Unable to infer the schema. The schema specification is required to create the table `&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;`.`tab2`.;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As I deep into this problem, I found it is related to ParserUtils#unescapeSQLString().&lt;/p&gt;

&lt;p&gt;These are two lines at the beginning of Failed A:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val url = &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().getContextClassLoader.getResource(&lt;span class=&quot;code-quote&quot;&gt;&quot;avroDecimal&quot;&lt;/span&gt;)
val location = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; File(url.getFile)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And in my environment&#65292;`location` (path value) is&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
D:\workspace\IdeaProjects\spark\sql\hive\target\scala-2.11\test-classes\avroDecimal
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then, in SparkSqlParser#visitCreateHiveTable()#L1128:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val location = Option(ctx.locationSpec).map(visitLocationSpec)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This line want to get LocationSepcContext&apos;s content first, which is equal to `location` above.&lt;br/&gt;
Then, the content is passed to visitLocationSpec(), and passed to unescapeSQLString()&lt;br/&gt;
finally.&lt;/p&gt;

&lt;p&gt;Lets&apos; have a look at unescapeSQLString():&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;/** Unescape baskslash-escaped string enclosed by quotes. */&lt;/span&gt;
  def unescapeSQLString(b: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;): &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = {
    &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; enclosure: &lt;span class=&quot;code-object&quot;&gt;Character&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
    val sb = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; StringBuilder(b.length())

    def appendEscapedChar(n: Char) {
      n match {
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&apos;\u0000&apos;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;\&apos;&lt;/span&gt;&lt;span class=&quot;code-quote&quot;&gt;&apos; =&amp;gt; sb.append(&apos;&lt;/span&gt;\&apos;&apos;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;&lt;span class=&quot;code-quote&quot;&gt;&quot;&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&apos;\&quot;&lt;/span&gt;&apos;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;b&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&apos;\b&apos;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;n&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&apos;\n&apos;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;r&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&apos;\r&apos;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;t&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&apos;\t&apos;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;Z&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&apos;\u001A&apos;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;\\&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&apos;\\&apos;&lt;/span&gt;)
        &lt;span class=&quot;code-comment&quot;&gt;// The following 2 lines are exactly what MySQL does TODO: why &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; we &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;?
&lt;/span&gt;        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;%&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&quot;\\%&quot;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&apos;_&apos;&lt;/span&gt; =&amp;gt; sb.append(&lt;span class=&quot;code-quote&quot;&gt;&quot;\\_&quot;&lt;/span&gt;)
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; _ =&amp;gt; sb.append(n)
      }
    }

    &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; i = 0
    val strLength = b.length
    &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (i &amp;lt; strLength) {
      val currentChar = b.charAt(i)
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (enclosure == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (currentChar == &lt;span class=&quot;code-quote&quot;&gt;&apos;\&apos;&lt;/span&gt;&lt;span class=&quot;code-quote&quot;&gt;&apos; || currentChar == &apos;&lt;/span&gt;\&quot;&apos;) {
          enclosure = currentChar
        }
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (enclosure == currentChar) {
        enclosure = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (currentChar == &lt;span class=&quot;code-quote&quot;&gt;&apos;\\&apos;&lt;/span&gt;) {

        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((i + 6 &amp;lt; strLength) &amp;amp;&amp;amp; b.charAt(i + 1) == &lt;span class=&quot;code-quote&quot;&gt;&apos;u&apos;&lt;/span&gt;) {
          &lt;span class=&quot;code-comment&quot;&gt;// \u0000 style character literals.
&lt;/span&gt;
          val base = i + 2
          val code = (0 until 4).foldLeft(0) { (mid, j) =&amp;gt;
            val digit = &lt;span class=&quot;code-object&quot;&gt;Character&lt;/span&gt;.digit(b.charAt(j + base), 16)
            (mid &amp;lt;&amp;lt; 4) + digit
          }
          sb.append(code.asInstanceOf[Char])
          i += 5
        } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (i + 4 &amp;lt; strLength) {
          &lt;span class=&quot;code-comment&quot;&gt;// \000 style character literals.
&lt;/span&gt;
          val i1 = b.charAt(i + 1)
          val i2 = b.charAt(i + 2)
          val i3 = b.charAt(i + 3)

          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((i1 &amp;gt;= &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt; &amp;amp;&amp;amp; i1 &amp;lt;= &lt;span class=&quot;code-quote&quot;&gt;&apos;1&apos;&lt;/span&gt;) &amp;amp;&amp;amp; (i2 &amp;gt;= &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt; &amp;amp;&amp;amp; i2 &amp;lt;= &lt;span class=&quot;code-quote&quot;&gt;&apos;7&apos;&lt;/span&gt;) &amp;amp;&amp;amp; (i3 &amp;gt;= &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt; &amp;amp;&amp;amp; i3 &amp;lt;= &lt;span class=&quot;code-quote&quot;&gt;&apos;7&apos;&lt;/span&gt;)) {
            val tmp = ((i3 - &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt;) + ((i2 - &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt;) &amp;lt;&amp;lt; 3) + ((i1 - &lt;span class=&quot;code-quote&quot;&gt;&apos;0&apos;&lt;/span&gt;) &amp;lt;&amp;lt; 6)).asInstanceOf[Char]
            sb.append(tmp)
            i += 3
          } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
            appendEscapedChar(i1)
            i += 1
          }
        } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (i + 2 &amp;lt; strLength) {
          &lt;span class=&quot;code-comment&quot;&gt;// escaped character literals.
&lt;/span&gt;          val n = b.charAt(i + 1)
          appendEscapedChar(n)
          i += 1
        }
      } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
        &lt;span class=&quot;code-comment&quot;&gt;// non-escaped character literals.
&lt;/span&gt;        sb.append(currentChar)
      }
      i += 1
    }
    sb.toString()
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; Again, here, variable `b` is equal to content and `location`, is valued of &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
D:\workspace\IdeaProjects\spark\sql\hive\target\scala-2.11\test-classes\avroDecimal
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And we can make sense from the unescapeSQLString()&apos; strategies that it transform  the String &quot;\t&quot; into a escape character &apos;\t&apos; and remove all backslashes.&lt;br/&gt;
So, our original correct location resulted in:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
D:workspaceIdeaProjectssparksqlhive\targetscala-2.11\test-classesavroDecimal
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; after unescapeSQLString() completed.&lt;br/&gt;
Note that, here, [ \t ] is no longer a string, but a escape character. &lt;/p&gt;

&lt;p&gt;Then, return into SparkSqlParser#visitCreateHiveTable(), and move to L1134:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val locUri = location.map(CatalogUtils.stringToURI(_))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;`location` is passed to stringToURI(), and resulted in:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
file:/D:workspaceIdeaProjectssparksqlhive%09argetscala-2.11%09est-classesavroDecimal
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;finally, as  escape character &apos;\t&apos;  is transformed into URI code &apos;%09&apos;.&lt;/p&gt;

&lt;p&gt;Although, I&apos;m not clearly about how this wrong path directly caused that exception, as I almostly know nothing about Hive, I can verify that this wrong path is the real factor to cause this exception.&lt;/p&gt;

&lt;p&gt;When I append these lines(in order to fix the wrong path) after HiveExternalCatalog#doCreateTable()Line236-240:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (tableLocation.get.getPath.startsWith(&lt;span class=&quot;code-quote&quot;&gt;&quot;/D&quot;&lt;/span&gt;)) {
     tableLocation = Some(CatalogUtils.stringToURI(
        &lt;span class=&quot;code-quote&quot;&gt;&quot;file:/D:/workspace/IdeaProjects/spark/sql/hive/target/scala-2.11/test-classes/avroDecimal&quot;&lt;/span&gt;))
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;then, failed unit test A will pass, excluding test B.&lt;/p&gt;

&lt;p&gt;And below is the stack trace of the Exception:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
org.apache.hadoop.hive.ql.metadata.HiveException: MetaException(message:java.lang.IllegalArgumentException: Can not create a Path from an empty string)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:602)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$createTable$1.apply$mcV$sp(HiveClientImpl.scala:469)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$createTable$1.apply(HiveClientImpl.scala:467)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$createTable$1.apply(HiveClientImpl.scala:467)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$withHiveState$1.apply(HiveClientImpl.scala:273)
	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:210)
	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:209)
	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:256)
	at org.apache.spark.sql.hive.client.HiveClientImpl.createTable(HiveClientImpl.scala:467)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$doCreateTable$1.apply$mcV$sp(HiveExternalCatalog.scala:263)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$doCreateTable$1.apply(HiveExternalCatalog.scala:216)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$doCreateTable$1.apply(HiveExternalCatalog.scala:216)
	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)
	at org.apache.spark.sql.hive.HiveExternalCatalog.doCreateTable(HiveExternalCatalog.scala:216)
	at org.apache.spark.sql.catalyst.catalog.ExternalCatalog.createTable(ExternalCatalog.scala:119)
	at org.apache.spark.sql.catalyst.catalog.SessionCatalog.createTable(SessionCatalog.scala:304)
	at org.apache.spark.sql.execution.command.CreateTableCommand.run(tables.scala:128)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)
	at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:186)
	at org.apache.spark.sql.Dataset$$anonfun$6.apply(Dataset.scala:186)
	at org.apache.spark.sql.Dataset$$anonfun$51.apply(Dataset.scala:3196)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3195)
	at org.apache.spark.sql.Dataset.&amp;lt;init&amp;gt;(Dataset.scala:186)
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:71)
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:638)
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:694)
	at org.apache.spark.sql.hive.client.VersionsSuite$$anonfun$6$$anonfun$apply$24$$anonfun$apply$mcV$sp$3.apply$mcV$sp(VersionsSuite.scala:829)
	at org.apache.spark.sql.hive.client.VersionsSuite.withTable(VersionsSuite.scala:70)
	at org.apache.spark.sql.hive.client.VersionsSuite$$anonfun$6$$anonfun$apply$24.apply$mcV$sp(VersionsSuite.scala:828)
	at org.apache.spark.sql.hive.client.VersionsSuite$$anonfun$6$$anonfun$apply$24.apply(VersionsSuite.scala:805)
	at org.apache.spark.sql.hive.client.VersionsSuite$$anonfun$6$$anonfun$apply$24.apply(VersionsSuite.scala:805)
	at org.scalatest.OutcomeOf$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:68)
	at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runTest(FunSuiteLike.scala:196)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(FunSuiteLike.scala:233)
	at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(SparkFunSuite.scala:31)
	at org.scalatest.BeforeAndAfterAll$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;liftedTree1$1(BeforeAndAfterAll.scala:213)
	at org.scalatest.BeforeAndAfterAll$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;run(BeforeAndAfterAll.scala:210)
	at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:31)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:45)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1340)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$1.apply(Runner.scala:1334)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1334)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1011)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1010)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1500)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1010)
	at org.scalatest.tools.Runner$.run(Runner.scala:850)
	at org.scalatest.tools.Runner.run(Runner.scala)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2(ScalaTestRunner.java:138)
	at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:28)
Caused by: MetaException(message:java.lang.IllegalArgumentException: Can not create a Path from an empty string)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_with_environment_context(HiveMetaStore.java:1121)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:103)
	at com.sun.proxy.$Proxy31.create_table_with_environment_context(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:482)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:471)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:89)
	at com.sun.proxy.$Proxy32.createTable(Unknown Source)
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:596)
	... 78 more
Caused by: java.lang.IllegalArgumentException: Can not create a Path from an empty string
	at org.apache.hadoop.fs.Path.checkPathArg(Path.java:127)
	at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:184)
	at org.apache.hadoop.fs.Path.getParent(Path.java:357)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:427)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:690)
	at org.apache.hadoop.hive.metastore.Warehouse.mkdirs(Warehouse.java:194)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_core(HiveMetaStore.java:1059)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_table_with_environment_context(HiveMetaStore.java:1107)
	... 93 more

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As for test B, I did&apos;n do a careful inspection, but I find a same wrong path as test A. So, I guess exceptions were  caused by the same factor.&lt;/p&gt;





</description>
                <environment>&lt;p&gt;Windos7&lt;/p&gt;</environment>
        <key id="13128687">SPARK-22967</key>
            <summary>VersionSuite failed on Windows caused by Windows format path</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="Ngone51">wuyi</assignee>
                                    <reporter username="Ngone51">wuyi</reporter>
                        <labels>
                            <label>build</label>
                            <label>test</label>
                            <label>windows</label>
                    </labels>
                <created>Fri, 5 Jan 2018 03:16:30 +0000</created>
                <updated>Mon, 12 Dec 2022 18:11:07 +0000</updated>
                            <resolved>Thu, 11 Jan 2018 13:18:43 +0000</resolved>
                                    <version>2.2.1</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>SQL</component>
                        <due>Fri, 5 Jan 2018 00:00:00 +0000</due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16312579" author="ngone51" created="Fri, 5 Jan 2018 06:50:44 +0000"  >&lt;p&gt;@&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16313254" author="gurwls223" created="Fri, 5 Jan 2018 15:02:14 +0000"  >&lt;p&gt;Yup, it&apos;s a known issue. I have been fixing the tests in batch so far and usually the fix is about replacing the path to URI form. Would you like to open a PR? I can review.&lt;/p&gt;</comment>
                            <comment id="16314380" author="ngone51" created="Sat, 6 Jan 2018 05:16:54 +0000"  >&lt;p&gt;I&apos;d like to open a PR, but I&apos;m not 100% sure how to fix this bug yet. As you say:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
fix is about replacing the path to URI form
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But this Windows&apos; path goes wrong before the stringToURI() called (as I mentioned above). So, should we fix it before URI transform happen ?&lt;/p&gt;</comment>
                            <comment id="16315547" author="gurwls223" created="Mon, 8 Jan 2018 01:24:53 +0000"  >&lt;p&gt;Ah, I meant to fix the tests to use URI forms instead of Windows file path if they are not specific to test the path forms themselves.&lt;/p&gt;</comment>
                            <comment id="16316161" author="ngone51" created="Mon, 8 Jan 2018 11:48:54 +0000"  >&lt;p&gt;I understand what you mean now, and things with Hive go well after I tried this. But, another wired problem arise.&lt;/p&gt;

&lt;p&gt;Tmp dir was created at the beginning of test B(mentioned above):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;protected&lt;/span&gt; def withTempDir(f: File =&amp;gt; Unit): Unit = {
   val dir = Utils.createTempDir().getCanonicalFile
   &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; f(dir) &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; Utils.deleteRecursively(dir)
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And, it would be deleted in finally clause.&lt;/p&gt;

&lt;p&gt;And test B will run with below Hive visions sequently:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; val versions = Seq(&lt;span class=&quot;code-quote&quot;&gt;&quot;0.12&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;0.13&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;0.14&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;1.0&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;1.1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;1.2&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;2.0&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;2.1&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And each version will delete the tmp dir successfully except the version 0.12. And when I try to delete this tmp file manualy, then, Windows warning me that this file may open in another program. It seems that an open stream is occupying this file.&lt;/p&gt;

&lt;p&gt;But, this tmp file could be deleted after another version test start running.&lt;/p&gt;

&lt;p&gt;And, I tried to exchange the order between 0.12 and 0.13, but the result remains the same.&lt;/p&gt;

&lt;p&gt;That&apos;s really make me confused. Maybe, there&apos;s something incompatible with version 0.12.&lt;/p&gt;


</comment>
                            <comment id="16316185" author="gurwls223" created="Mon, 8 Jan 2018 12:07:09 +0000"  >&lt;p&gt;There&apos;s a annoying problem on Windows. Every file &lt;em&gt;must&lt;/em&gt; be closed before being removed as it holds an exclusive lock. In theory, those temp directories are guaranteed to be removed at JVM&apos;s shutdown hook. I think we can ignore that stuff for now. Does that make the tests fail?&lt;/p&gt;</comment>
                            <comment id="16316262" author="ngone51" created="Mon, 8 Jan 2018 13:00:30 +0000"  >&lt;p&gt;Yeah, it fails the test.&lt;/p&gt;</comment>
                            <comment id="16316278" author="gurwls223" created="Mon, 8 Jan 2018 13:13:32 +0000"  >&lt;p&gt;Hm .. I haven&apos;t taken a look for it closely yet but can we ignore it in that case in anyway? If it&apos;s difficult or impossible, I think we can just skip on Windows as it&apos;s going to fail anyway. I did this several times. For example, I think you can refer &lt;a href=&quot;https://github.com/apache/spark/pull/16999&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16999&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I know it take a while to investigate to check if other tests are failed on Windows but it should be really nicer if we can identify some more test cases failed on Windows fix them in a batch.&lt;/p&gt;</comment>
                            <comment id="16316368" author="ngone51" created="Mon, 8 Jan 2018 14:04:29 +0000"  >&lt;p&gt;Maybe, we can give a warning rather than an exception, since the main goal of the tests have been achieved.&lt;/p&gt;

&lt;p&gt;I will check it again tomorrow...&lt;/p&gt;

&lt;p&gt;And I know another case(ChildProcAppHanlderSuite) may related to Windows, also. I can post it once I have time.&lt;/p&gt;</comment>
                            <comment id="16316524" author="gurwls223" created="Mon, 8 Jan 2018 15:54:56 +0000"  >&lt;p&gt;Yea, that sounds good roughly. Will check the PR once you opened.&lt;/p&gt;</comment>
                            <comment id="16317998" author="apachespark" created="Tue, 9 Jan 2018 08:21:04 +0000"  >&lt;p&gt;User &apos;Ngone51&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/20199&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/20199&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16322188" author="gurwls223" created="Thu, 11 Jan 2018 13:18:43 +0000"  >&lt;p&gt;Fixed in &lt;a href=&quot;https://github.com/apache/spark/pull/20199&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/20199&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10430"><![CDATA[Patch]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 44 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|hzzy7p:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>