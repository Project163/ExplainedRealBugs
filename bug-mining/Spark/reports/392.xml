<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:14:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-1749] DAGScheduler supervisor strategy broken with Mesos</title>
                <link>https://issues.apache.org/jira/browse/SPARK-1749</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Any bad Python code will trigger this bug, for example `sc.parallelize(range(100)).map(lambda n: undefined_variable * 2).collect()` will cause a `undefined_variable isn&apos;t defined`, which will cause spark to try to kill the task, resulting in the following stacktrace:&lt;/p&gt;

&lt;p&gt;java.lang.UnsupportedOperationException&lt;br/&gt;
	at org.apache.spark.scheduler.SchedulerBackend$class.killTask(SchedulerBackend.scala:32)&lt;br/&gt;
	at org.apache.spark.scheduler.cluster.mesos.MesosSchedulerBackend.killTask(MesosSchedulerBackend.scala:41)&lt;br/&gt;
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:184)&lt;br/&gt;
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:182)&lt;br/&gt;
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:182)&lt;br/&gt;
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)&lt;br/&gt;
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$3.apply(TaskSchedulerImpl.scala:182)&lt;br/&gt;
	at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$3.apply(TaskSchedulerImpl.scala:175)&lt;br/&gt;
	at scala.Option.foreach(Option.scala:236)&lt;br/&gt;
	at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:175)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1058)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1045)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1045)&lt;br/&gt;
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1045)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:998)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:499)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:499)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:499)&lt;br/&gt;
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:499)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGSchedulerActorSupervisor$$anonfun$2.applyOrElse(DAGScheduler.scala:1151)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGSchedulerActorSupervisor$$anonfun$2.applyOrElse(DAGScheduler.scala:1147)&lt;br/&gt;
	at akka.actor.SupervisorStrategy.handleFailure(FaultHandling.scala:295)&lt;br/&gt;
	at akka.actor.dungeon.FaultHandling$class.handleFailure(FaultHandling.scala:253)&lt;br/&gt;
	at akka.actor.ActorCell.handleFailure(ActorCell.scala:338)&lt;br/&gt;
	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:423)&lt;br/&gt;
	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:447)&lt;br/&gt;
	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:262)&lt;br/&gt;
	at akka.dispatch.Mailbox.run(Mailbox.scala:218)&lt;br/&gt;
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)&lt;br/&gt;
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)&lt;br/&gt;
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)&lt;br/&gt;
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)&lt;br/&gt;
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)&lt;/p&gt;

&lt;p&gt;This is because killTask isn&apos;t implemented for the MesosSchedulerBackend. I assume this isn&apos;t pyspark-specific, as there will be other instances where you might want to kill the task &lt;/p&gt;</description>
                <environment></environment>
        <key id="12712920">SPARK-1749</key>
            <summary>DAGScheduler supervisor strategy broken with Mesos</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="markhamstra">Mark Hamstra</assignee>
                                    <reporter username="bouk">Bouke van der Bijl</reporter>
                        <labels>
                            <label>mesos</label>
                            <label>scheduler</label>
                            <label>scheduling</label>
                    </labels>
                <created>Wed, 7 May 2014 19:19:17 +0000</created>
                <updated>Thu, 26 Jun 2014 03:58:15 +0000</updated>
                            <resolved>Thu, 26 Jun 2014 03:58:15 +0000</resolved>
                                    <version>1.0.0</version>
                                    <fixVersion>1.0.1</fixVersion>
                    <fixVersion>1.1.0</fixVersion>
                                    <component>Mesos</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="13992215" author="markhamstra" created="Wed, 7 May 2014 20:54:27 +0000"  >&lt;p&gt;The failure is bad, but not all that bad, since it occurs when the Supervisor actor in the DAGScheduler is already trying to cancel running jobs and shut down the system after having caught an exception thrown during the processing of DAGScheduler event.&lt;/p&gt;

&lt;p&gt;I&apos;m not going to try to fix anything in PySpark in the PR addressing this issue &amp;#8211; in part because it isn&apos;t clear to me from the stack trace just what PySpark is doing to cause the failure in the DAGScheduler; but once the DAGScheduler does catch the exception thrown by the eventProcessActor, it should handle it better when Mesos is doing the task scheduling, and I can fix that.&lt;/p&gt;

&lt;p&gt;Another issue specific to Python may need to be filed as a follow up.  &lt;/p&gt;</comment>
                            <comment id="13993602" author="bouk" created="Fri, 9 May 2014 14:40:50 +0000"  >&lt;p&gt;This isn&apos;t really PySpark specific, this works fine on other backends which will mark the task as failed and just keep the SparkContext running.&lt;/p&gt;

&lt;p&gt;It shouldn&apos;t be shutting down the whole SparkContext just because a single job failed&lt;/p&gt;</comment>
                            <comment id="14044323" author="pwendell" created="Thu, 26 Jun 2014 03:58:15 +0000"  >&lt;p&gt;Issue resolved by pull request 1219&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/1219&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/1219&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>391236</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 21 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1vdtb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>391457</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12326744">1.0.1</customfieldvalue>
    <customfieldvalue id="12326686">1.1.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>