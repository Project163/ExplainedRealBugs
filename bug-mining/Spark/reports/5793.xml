<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:00:21 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-24578] Reading remote cache block behavior changes and causes timeout issue</title>
                <link>https://issues.apache.org/jira/browse/SPARK-24578</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;After&#160;Spark 2.3, we observed lots of errors like the following in some of our production job&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
18/06/15 20:59:42 ERROR TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=91672904003, chunkIndex=0}, buffer=org.apache.spark.storage.BlockManagerManagedBuffer@783a9324} to /172.22.18.7:60865; closing connection
java.io.IOException: Broken pipe
at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)
at sun.nio.ch.IOUtil.write(IOUtil.java:65)
at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)
at org.apache.spark.network.protocol.MessageWithHeader.writeNioBuffer(MessageWithHeader.java:156)
at org.apache.spark.network.protocol.MessageWithHeader.copyByteBuf(MessageWithHeader.java:142)
at org.apache.spark.network.protocol.MessageWithHeader.transferTo(MessageWithHeader.java:123)
at io.netty.channel.socket.nio.NioSocketChannel.doWriteFileRegion(NioSocketChannel.java:355)
at io.netty.channel.nio.AbstractNioByteChannel.doWrite(AbstractNioByteChannel.java:224)
at io.netty.channel.socket.nio.NioSocketChannel.doWrite(NioSocketChannel.java:382)
at io.netty.channel.AbstractChannel$AbstractUnsafe.flush0(AbstractChannel.java:934)
at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.flush0(AbstractNioChannel.java:362)
at io.netty.channel.AbstractChannel$AbstractUnsafe.flush(AbstractChannel.java:901)
at io.netty.channel.DefaultChannelPipeline$HeadContext.flush(DefaultChannelPipeline.java:1321)
at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776)
at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768)
at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749)
at io.netty.channel.ChannelOutboundHandlerAdapter.flush(ChannelOutboundHandlerAdapter.java:115)
at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776)
at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768)
at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749)
at io.netty.channel.ChannelDuplexHandler.flush(ChannelDuplexHandler.java:117)
at io.netty.channel.AbstractChannelHandlerContext.invokeFlush0(AbstractChannelHandlerContext.java:776)
at io.netty.channel.AbstractChannelHandlerContext.invokeFlush(AbstractChannelHandlerContext.java:768)
at io.netty.channel.AbstractChannelHandlerContext.flush(AbstractChannelHandlerContext.java:749)
at io.netty.channel.DefaultChannelPipeline.flush(DefaultChannelPipeline.java:983)
at io.netty.channel.AbstractChannel.flush(AbstractChannel.java:248)
at io.netty.channel.nio.AbstractNioByteChannel$1.run(AbstractNioByteChannel.java:284)
at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Here is a small reproducible for a small cluster of 2 executors (say host-1 and host-2) each with 8 cores. Here, the memory of driver and executors are not an import factor here as long as it is big enough, say 20G.&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val n = 100000000
val df0 = sc.parallelize(1 to n).toDF
val df = df0.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x0&quot;&lt;/span&gt;, rand()).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x0&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x1&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x2&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x3&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x4&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x5&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x6&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x7&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x8&quot;&lt;/span&gt;, rand()
).withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;x9&quot;&lt;/span&gt;, rand())

df.cache; df.count

(1 to 10).toArray.par.map { i =&amp;gt; println(i); df.groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;x1&quot;&lt;/span&gt;).agg(count(&lt;span class=&quot;code-quote&quot;&gt;&quot;value&quot;&lt;/span&gt;)).show() }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;In the above example, we generate a random DataFrame of size around 7G; cache it and then perform a parallel DataFrame operations by using `array.par.map`. Because of the parallel computation, with high possibility, some task&#160;could be scheduled to a host-2 where it needs to read the cache block data from host-1. This follows the code path of &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/storage/BlockManager.scala#L691&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/storage/BlockManager.scala#L691&lt;/a&gt;&#160;and then tries to transfer a big block (~ 500MB) of cache block from host-1 to host-2. Often, this big transfer makes&#160;the cluster suffer time out issue (it will retry 3 times, each with 120s timeout, and then do recompute to put the cache block into the local MemoryStore).&lt;/p&gt;

&lt;p&gt;We&#160;couldn&apos;t&#160;to reproduce the same issue in Spark 2.2.1. From the log of Spark 2.2.1, we found that&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
18/06/16 17:23:47 DEBUG BlockManager: Getting local block rdd_3_0 
18/06/16 17:23:47 TRACE BlockInfoManager: Task 0 trying to acquire read lock &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; rdd_3_0 
18/06/16 17:23:47 DEBUG BlockManager: Block rdd_3_0 was not found 
18/06/16 17:23:47 DEBUG BlockManager: Getting remote block rdd_3_0 
18/06/16 17:23:47 DEBUG BlockManager: Block rdd_3_0 not found 
18/06/16 17:23:47 TRACE BlockInfoManager: Task 0 trying to put rdd_3_0 
18/06/16 17:23:47 TRACE BlockInfoManager: Task 0 trying to acquire read lock &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; rdd_3_0 
18/06/16 17:23:47 TRACE BlockInfoManager: Task 0 trying to acquire write lock &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; rdd_3_0 
18/06/16 17:23:47 TRACE BlockInfoManager: Task 0 acquired write lock &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; rdd_3_0 
18/06/16 17:23:58 INFO MemoryStore: Block rdd_3_0 stored as values in memory (estimated size 538.2 MB, free 11.1 GB)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;That is,&#160;when a&#160;task is&#160;scheduled to a host-2&#160;where it&#160;needs to read the cache block rdd_3_0 data from host-1, the endpoint of `master.getLocations(..)` ( see&#160;&lt;a href=&quot;https://github.com/apache/spark/blob/v2.2.1/core/src/main/scala/org/apache/spark/storage/BlockManager.scala#L622&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v2.2.1/core/src/main/scala/org/apache/spark/storage/BlockManager.scala#L622&lt;/a&gt;)&#160;reports a remote cache block is not found and triggered the recompute.&#160;&#160;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;I believe this behavior change is introduced by this change set&#160;&#160;&lt;a href=&quot;https://github.com/apache/spark/commit/e1960c3d6f380b0dfbba6ee5d8ac6da4bc29a698#diff-2b643ea78c1add0381754b1f47eec132&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/e1960c3d6f380b0dfbba6ee5d8ac6da4bc29a698#diff-2b643ea78c1add0381754b1f47eec132&lt;/a&gt;&lt;/del&gt;&#160;&lt;/p&gt;

&lt;p&gt;We have two questions here&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;what is the right behavior, should we re-compute or should we transfer block from remote?&lt;/li&gt;
	&lt;li&gt;if we should transfer from remote, why the performance is so bad for cache block?&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13166723">SPARK-24578</key>
            <summary>Reading remote cache block behavior changes and causes timeout issue</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wbzhao">Wenbo Zhao</assignee>
                                    <reporter username="wbzhao">Wenbo Zhao</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Mon, 18 Jun 2018 14:55:02 +0000</created>
                <updated>Mon, 19 Feb 2024 12:10:34 +0000</updated>
                            <resolved>Wed, 20 Jun 2018 21:27:15 +0000</resolved>
                                    <version>2.3.0</version>
                    <version>2.3.1</version>
                                    <fixVersion>2.3.2</fixVersion>
                    <fixVersion>2.4.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>13</watches>
                                                                                                                <comments>
                            <comment id="16515858" author="wbzhao" created="Mon, 18 Jun 2018 15:14:11 +0000"  >&lt;p&gt;An easier reproduciable cluster setting is 10 executors each with 2 cores and 15G memory.&lt;/p&gt;</comment>
                            <comment id="16515879" author="icexelloss" created="Mon, 18 Jun 2018 15:23:19 +0000"  >&lt;p&gt;cc @gatorsmile &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We found this when switching from 2.2.1 to 2.3.0 in one of our applications. The implication is pretty bad - the time outs significantly hurt the performance (20s to several minutes for some jobs). This could affect other Spark 2.3 users too because it&apos;s&#160;pretty easy to reproduce.&lt;/p&gt;</comment>
                            <comment id="16516527" author="irashid" created="Tue, 19 Jun 2018 01:37:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wbzhao&quot; class=&quot;user-hover&quot; rel=&quot;wbzhao&quot;&gt;wbzhao&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=icexelloss&quot; class=&quot;user-hover&quot; rel=&quot;icexelloss&quot;&gt;icexelloss&lt;/a&gt; you&apos;re saying this is &lt;b&gt;without&lt;/b&gt; touching the value of &quot;spark.maxRemoteBlockSizeFetchToMem&quot;, right?  If you aren&apos;t turning on fetch-to-disk, then the behavior shouldn&apos;t change in 2.3.0 (though of course there may be bugs)&lt;/p&gt;


&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jerryshao&quot; class=&quot;user-hover&quot; rel=&quot;jerryshao&quot;&gt;jerryshao&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=attilapiros&quot; class=&quot;user-hover&quot; rel=&quot;attilapiros&quot;&gt;attilapiros&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16516602" author="wbzhao" created="Tue, 19 Jun 2018 03:03:53 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=irashid&quot; class=&quot;user-hover&quot; rel=&quot;irashid&quot;&gt;irashid&lt;/a&gt; We didn&apos;t touch&#160;&quot;spark.maxRemoteBlockSizeFetchToMem&quot;. You are right. After digging more details, I don&apos;t think that commit is relevant,&lt;/p&gt;</comment>
                            <comment id="16516609" author="wbzhao" created="Tue, 19 Jun 2018 03:12:13 +0000"  >&lt;p&gt;For now, we could reproduce this issue in completely different env and different distribution of Spark 2.3.0. We also observed that by setting spark.locality.wait to be a big number, e.g. 60s could help but this reduces the our system throughput significantly.&lt;/p&gt;</comment>
                            <comment id="16516611" author="irashid" created="Tue, 19 Jun 2018 03:24:25 +0000"  >&lt;p&gt;btw to answer your initial questions:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;1. what is the right behavior, should we re-compute or should we transfer block from remote?&lt;br/&gt;
2. if we should transfer from remote, why the performance is so bad for cache block?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Spark should try to fetch from the remote, and if that fails for some reason, it should fall back to recomputing.  so you should actually see a similar sequence of events in the logs in spark 2.3.0 as you do in your spark 2.2.1 snippet &amp;#8211; the difference being the remote fetch fails in 2.3.0, and so instead it does the recomputation.  The real issue here is why the remote fetches are failing.  Unfortunately there isn&apos;t a ton of info in that stack trace &amp;#8211; are there any other warning messages before that in the logs?&lt;/p&gt;

&lt;p&gt;I can see how setting spark.locality.wait lets you workaround this, but its definitely not an ideal solution.&lt;/p&gt;

&lt;p&gt;I wouldn&apos;t rule out that commit you mentioned as the issue &amp;#8211; its certainly possible.&lt;/p&gt;</comment>
                            <comment id="16516621" author="wbzhao" created="Tue, 19 Jun 2018 03:49:11 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=irashid&quot; class=&quot;user-hover&quot; rel=&quot;irashid&quot;&gt;irashid&lt;/a&gt;, many thanks for clarifying my questions. I tried to compare the logs between Spark 2.2.1 and 2.3.0 to see if there something interesting but out of luck so far. I added a few logging to benchmark how much time we need to transfer ~500MB data in the &lt;a href=&quot;https://github.com/apache/spark/blob/v2.3.0/common/network-common/src/main/java/org/apache/spark/network/protocol/MessageWithHeader.java#L142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v2.3.0/common/network-common/src/main/java/org/apache/spark/network/protocol/MessageWithHeader.java#L142&lt;/a&gt;. In Spark 2.2.1, it only took &amp;lt;= 2s, but in Spark 2.3.0, it is very slow and never got finish with 120s and thus timeout.&#160;&lt;/p&gt;

&lt;p&gt;Are you able to reproduce the issue?&lt;/p&gt;</comment>
                            <comment id="16517180" author="wbzhao" created="Tue, 19 Jun 2018 14:41:34 +0000"  >&lt;p&gt;After digging more details, this commit&#160; &lt;a href=&quot;https://github.com/apache/spark/commit/16612638f0539f197eb7deb1be2ec53fed60d707#diff-a1f697fbd4610dff4eb8ff848e8cea2a&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/16612638f0539f197eb7deb1be2ec53fed60d707#diff-a1f697fbd4610dff4eb8ff848e8cea2a&lt;/a&gt;&#160;came to my attention. I reverted this commit in our Spark distribution and found out the issue went away.&lt;/p&gt;

&lt;p&gt;I also examined the log to verify that performance of&#160;&lt;a href=&quot;https://github.com/apache/spark/blob/v2.3.0/common/network-common/src/main/java/org/apache/spark/network/protocol/MessageWithHeader.java#L142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v2.3.0/common/network-common/src/main/java/org/apache/spark/network/protocol/MessageWithHeader.java#L142&lt;/a&gt;&#160;is back to normal. It is able to transfer the 500MB data in 2s~3s.&#160;&lt;/p&gt;

&lt;p&gt;However, it is still not quite clear why that commit is causing the issue.&lt;/p&gt;</comment>
                            <comment id="16517287" author="attilapiros" created="Tue, 19 Jun 2018 16:41:05 +0000"  >&lt;p&gt;The copyByteBuf() along with transferTo() is called several times on a huge byteBuf.&#160;If we have a really huge chunk from small chunks we are re-merging the small chunks again and again by&#160;&lt;a href=&quot;https://github.com/apache/spark/blob/v2.3.0/common/network-common/src/main/java/org/apache/spark/network/protocol/MessageWithHeader.java#L140.&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/v2.3.0/common/network-common/src/main/java/org/apache/spark/network/protocol/MessageWithHeader.java#L140&lt;/a&gt;&#160;although we need only a very small part of it.&lt;/p&gt;

&lt;p&gt;Is it possible the following line would help?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ByteBuffer buffer = buf.nioBuffer(0, &lt;span class=&quot;code-object&quot;&gt;Math&lt;/span&gt;.min(buf.readableBytes(), NIO_BUFFER_LIMIT));&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16517416" author="attilapiros" created="Tue, 19 Jun 2018 18:41:24 +0000"  >&lt;p&gt;I have written a small test I know it is a bit&#160;naive but I still thing it shows us something:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/attilapiros/730d67b62317d14f5fd0f6779adea245&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/attilapiros/730d67b62317d14f5fd0f6779adea245&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And the result is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;n = 500 
duration221 = 2 
duration221.new = 0 
duration230 = 5242 
duration230.new = 7
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;My guess the receiver timeouts and the sender is writing into a closed socket.&lt;/p&gt;</comment>
                            <comment id="16517439" author="irashid" created="Tue, 19 Jun 2018 19:18:58 +0000"  >&lt;p&gt;I think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=attilapiros&quot; class=&quot;user-hover&quot; rel=&quot;attilapiros&quot;&gt;attilapiros&lt;/a&gt; may be right &amp;#8211; can you send a PR to fix?&lt;/p&gt;

&lt;p&gt;We were able to reproduce the issue with the code you gave, and noticed that the errors occur exactly at the two minute timeout.  The receiver closes the connection because of the timeout, so then the sender just has a generic failure that the connection was closed.&lt;/p&gt;

&lt;p&gt;Sender:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;18/06/18 10:12:08 ERROR server.TransportRequestHandler: Error sending result ChunkFetchSuccess{streamChunkId=StreamChunkId{streamId=879251518000, chunkIndex=0}, buffer=org.apache.spark.storage.BlockManagerManagedBuffer@19b0a640} to /xxxxxx:38710; closing connection
java.io.IOException: Connection reset by peer
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Receiver:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;18/06/18 10:12:08 ERROR server.TransportChannelHandler: Connection to xxx.com/xxxx:38765 has been quiet for 120000 ms while there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout if this is wrong.
18/06/18 10:12:08 ERROR client.TransportResponseHandler: Still have 1 requests outstanding when connection from xxxxx.com/xxxxxxxx:38765 is closed
18/06/18 10:12:08 INFO shuffle.RetryingBlockFetcher: Retrying fetch (1/3) for 1 outstanding blocks after 5000 ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At first I found it hard to believe this slow down would lead to the connection appearing totally quiet &amp;#8211; but i realized that there is actually a lot of concurrent activity going on, as all the executors are also sending and receiving many more blocks from each other. So if you&apos;re simultaneously dealing with a bunch of large blocks, and we put this big slow down inside the netty threads, this could lead to things appearing idle.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wbzhao&quot; class=&quot;user-hover&quot; rel=&quot;wbzhao&quot;&gt;wbzhao&lt;/a&gt; does this match the cases you see as well?&lt;/p&gt;</comment>
                            <comment id="16517440" author="wbzhao" created="Tue, 19 Jun 2018 19:21:41 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=attilapiros&quot; class=&quot;user-hover&quot; rel=&quot;attilapiros&quot;&gt;attilapiros&lt;/a&gt;, I guess what you suggest is&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ByteBuffer buffer = buf.nioBuffer(buf.readerIndex(), &lt;span class=&quot;code-object&quot;&gt;Math&lt;/span&gt;.min(buf.readableBytes(), NIO_BUFFER_LIMIT));&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Will report back how my test goes.&lt;/p&gt;</comment>
                            <comment id="16517441" author="wbzhao" created="Tue, 19 Jun 2018 19:23:42 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=irashid&quot; class=&quot;user-hover&quot; rel=&quot;irashid&quot;&gt;irashid&lt;/a&gt; Yes, that is exactly what I saw in our side.&lt;/p&gt;</comment>
                            <comment id="16517449" author="vanzin" created="Tue, 19 Jun 2018 19:43:53 +0000"  >&lt;p&gt;Attila&apos;s suggestion looks good, but I wonder what caused this to show up in 2.3... the code he&apos;s changing has been there since 2.0, so my guess would be something changed in Netty (which was upgraded in 2.3). Anyway, just curious about the underlying cause of the change.&lt;/p&gt;</comment>
                            <comment id="16517452" author="attilapiros" created="Tue, 19 Jun 2018 19:54:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wbzhao&quot; class=&quot;user-hover&quot; rel=&quot;wbzhao&quot;&gt;wbzhao&lt;/a&gt; Yes, you are right, readerIndex is the first (I just checked skipBytes), thanks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=irashid&quot; class=&quot;user-hover&quot; rel=&quot;irashid&quot;&gt;irashid&lt;/a&gt; Yes, I can create a PR soon.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt; Netty was upgraded between 2.2.1 and 2.3.0: from 4.0.43.Final to 4.1.17.Final. Could it be?&lt;/p&gt;</comment>
                            <comment id="16517458" author="wbzhao" created="Tue, 19 Jun 2018 19:58:31 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vanzin&quot; class=&quot;user-hover&quot; rel=&quot;vanzin&quot;&gt;vanzin&lt;/a&gt;.&#160; the commit&#160;&lt;a href=&quot;https://github.com/apache/spark/commit/16612638f0539f197eb7deb1be2ec53fed60d707#diff-a1f697fbd4610dff4eb8ff848e8cea2a&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/16612638f0539f197eb7deb1be2ec53fed60d707#diff-a1f697fbd4610dff4eb8ff848e8cea2a&lt;/a&gt;&#160;is only included&#160; since 2.3.0.&#160; If I understand right, the root cause is that we don&apos;t&#160;do&#160;`consolidateIfNeeded` anymore for many small chunks which causes the buf.notBuffer() has bad performance in the case that we have to call `copyByteBuf()` many times. In my example, the many times = 500MB / 256 KB.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=attilapiros&quot; class=&quot;user-hover&quot; rel=&quot;attilapiros&quot;&gt;attilapiros&lt;/a&gt; I applied&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ByteBuffer buffer = buf.nioBuffer(buf.readerIndex(), &lt;span class=&quot;code-object&quot;&gt;Math&lt;/span&gt;.min(buf.readableBytes(), NIO_BUFFER_LIMIT));&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;in our spark distribution and ran through the test code in this jira. This works fine.&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16517461" author="vanzin" created="Tue, 19 Jun 2018 20:03:20 +0000"  >&lt;p&gt;Ah, I see. That makes sense. (I actually took at look at netty changes and didn&apos;t find anything in this area, so was starting to wonder.)&lt;/p&gt;</comment>
                            <comment id="16517465" author="wbzhao" created="Tue, 19 Jun 2018 20:05:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=attilapiros&quot; class=&quot;user-hover&quot; rel=&quot;attilapiros&quot;&gt;attilapiros&lt;/a&gt; if don&apos;t mind, I could create a PR for it &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16517505" author="apachespark" created="Tue, 19 Jun 2018 20:25:05 +0000"  >&lt;p&gt;User &apos;attilapiros&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21592&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21592&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16517515" author="attilapiros" created="Tue, 19 Jun 2018 20:36:22 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wbzhao&quot; class=&quot;user-hover&quot; rel=&quot;wbzhao&quot;&gt;wbzhao&lt;/a&gt; oh sorry I read your comment late, definitely without your help (pointing to the right commit caused the problem) it would took much much longer. If you like please create another PR, it is fine for me.&lt;/p&gt;</comment>
                            <comment id="16517529" author="apachespark" created="Tue, 19 Jun 2018 20:44:07 +0000"  >&lt;p&gt;User &apos;WenboZhao&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21593&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21593&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16517532" author="wbzhao" created="Tue, 19 Jun 2018 20:46:11 +0000"  >&lt;p&gt;woop, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=attilapiros&quot; class=&quot;user-hover&quot; rel=&quot;attilapiros&quot;&gt;attilapiros&lt;/a&gt;, sorry, I didn&apos;t know you have created a PR.&#160;&lt;/p&gt;</comment>
                            <comment id="16518300" author="irashid" created="Wed, 20 Jun 2018 15:45:18 +0000"  >&lt;p&gt;Given the severity of the issue and that its a regression in 2.3, I&apos;ve set the target version and made it a blocker&lt;/p&gt;</comment>
                            <comment id="16518618" author="zsxwing" created="Wed, 20 Jun 2018 21:27:15 +0000"  >&lt;p&gt;Issue resolved by pull request 21593&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/21593&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/21593&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17753038" author="JIRAUSER301722" created="Fri, 11 Aug 2023 03:45:02 +0000"  >&lt;p&gt;I still have this problem in Amazon EMR spark 3.1.2, any idea?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 13 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3uz53:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12343289">2.3.2</customfieldvalue>
    <customfieldvalue id="12342385">2.4.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>