<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:31:49 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-39601] AllocationFailure should not be treated as exitCausedByApp when driver is shutting down</title>
                <link>https://issues.apache.org/jira/browse/SPARK-39601</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I observed some Spark Applications successfully completed all jobs but failed during the shutting down phase w/ reason: Max number of executor failures (16) reached, the timeline is&lt;/p&gt;

&lt;p&gt;Driver - Job success, Spark starts shutting down procedure.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2022-06-23 19:50:55 CST AbstractConnector INFO - Stopped Spark@74e9431b{HTTP/1.1, (http/1.1)}
{0.0.0.0:0}
2022-06-23 19:50:55 CST SparkUI INFO - Stopped Spark web UI at http:&lt;span class=&quot;code-comment&quot;&gt;//hadoop2627.xxx.org:28446
&lt;/span&gt;2022-06-23 19:50:55 CST YarnClusterSchedulerBackend INFO - Shutting down all executors
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Driver - A container allocate successful during shutting down phase.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2022-06-23 19:52:21 CST YarnAllocator INFO - Launching container container_e94_1649986670278_7743380_02_000025 on host hadoop4388.xxx.org &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; executor with ID 24 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; ResourceProfile Id 0&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Executor - The executor can not connect to driver endpoint because driver already stopped the endpoint.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Exception in thread &lt;span class=&quot;code-quote&quot;&gt;&quot;main&quot;&lt;/span&gt; java.lang.reflect.UndeclaredThrowableException
&#160; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1911)
&#160; at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:61)
&#160; at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:393)
&#160; at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend$.main(YarnCoarseGrainedExecutorBackend.scala:81)
&#160; at org.apache.spark.executor.YarnCoarseGrainedExecutorBackend.main(YarnCoarseGrainedExecutorBackend.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:&#160;
&#160; at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)
&#160; at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
&#160; at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
&#160; at org.apache.spark.executor.CoarseGrainedExecutorBackend$.$anonfun$run$9(CoarseGrainedExecutorBackend.scala:413)
&#160; at scala.runtime.java8.JFunction1$mcVI$sp.apply(JFunction1$mcVI$sp.java:23)
&#160; at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:877)
&#160; at scala.collection.immutable.Range.foreach(Range.scala:158)
&#160; at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:876)
&#160; at org.apache.spark.executor.CoarseGrainedExecutorBackend$.$anonfun$run$7(CoarseGrainedExecutorBackend.scala:411)
&#160; at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:62)
&#160; at org.apache.spark.deploy.SparkHadoopUtil$$anon$1.run(SparkHadoopUtil.scala:61)
&#160; at java.security.AccessController.doPrivileged(Native Method)
&#160; at javax.security.auth.Subject.doAs(Subject.java:422)
&#160; at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
&#160; ... 4 more
Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark:&lt;span class=&quot;code-comment&quot;&gt;//CoarseGrainedScheduler@hadoop2627.xxx.org:21956
&lt;/span&gt;&#160; at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
&#160; at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
&#160; at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
&#160; at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
&#160; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
&#160; at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
&#160; at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
&#160; at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
&#160; at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
&#160; at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
  at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Driver - YarnAllocator received container launch error message and treat it as `exitCausedByApp`&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2022-06-23 19:52:27 CST YarnAllocator INFO - Completed container container_e94_1649986670278_7743380_02_000025 on host: hadoop4388.xxx.org (state: COMPLETE, exit status: 1)
2022-06-23 19:52:27 CST YarnAllocator WARN - Container from a bad node: container_e94_1649986670278_7743380_02_000025 on host: hadoop4388.xxx.org. Exit status: 1. Diagnostics: [2022-06-23 19:52:24.932]Exception from container-launch.
Container id: container_e94_1649986670278_7743380_02_000025
Exit code: 1
Shell output: main : command provided 1
main : run as user is bdms_pm
main : requested yarn user is bdms_pm
Getting exit code file...
Creating script paths...
Writing pid file...
Writing to tmp file /mnt/dfs/2/yarn/local/nmPrivate/application_1649986670278_7743380/container_e94_1649986670278_7743380_02_000025/container_e94_1649986670278_7743380_02_000025.pid.tmp
Writing to cgroup task files...
Creating local dirs...
Launching container...
Getting exit code file...
Creating script paths...
[2022-06-23 19:52:24.938]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
&#160; at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
&#160; at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
&#160; at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
&#160; at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
&#160; at scala.concurrent.Promise.trySuccess(Promise.scala:94)
&#160; at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
&#160; at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
&#160; at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
&#160; at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$7(NettyRpcEnv.scala:246)
&#160; at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$7$adapted(NettyRpcEnv.scala:246)
&#160; at org.apache.spark.rpc.netty.RpcOutboxMessage.onSuccess(Outbox.scala:90)
&#160; at org.apache.spark.network.client.TransportResponseHandler.handle(TransportResponseHandler.java:195)
&#160; at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:142)
&#160; at org.apache.spark.network.server.TransportChannelHandler.channelRead0(TransportChannelHandler.java:53)
&#160; at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99)
&#160; at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
&#160; at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Driver - Eventually application failed because &#8221;failed&#8220; executor reached threshold&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
2022-06-23 19:52:30 CST ApplicationMaster INFO - Final app status: FAILED, exitCode: 11, (reason: Max number of executor failures (16) reached)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13468408">SPARK-39601</key>
            <summary>AllocationFailure should not be treated as exitCausedByApp when driver is shutting down</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="chengpan">Cheng Pan</assignee>
                                    <reporter username="chengpan">Cheng Pan</reporter>
                        <labels>
                    </labels>
                <created>Sat, 25 Jun 2022 14:28:35 +0000</created>
                <updated>Tue, 13 Dec 2022 14:52:33 +0000</updated>
                            <resolved>Tue, 13 Dec 2022 14:19:57 +0000</resolved>
                                    <version>3.3.0</version>
                                    <fixVersion>3.4.0</fixVersion>
                                    <component>YARN</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17558787" author="apachespark" created="Sat, 25 Jun 2022 15:07:22 +0000"  >&lt;p&gt;User &apos;pan3793&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/36991&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/36991&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17558788" author="apachespark" created="Sat, 25 Jun 2022 15:08:00 +0000"  >&lt;p&gt;User &apos;pan3793&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/36991&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/36991&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17632163" author="apachespark" created="Fri, 11 Nov 2022 08:31:59 +0000"  >&lt;p&gt;User &apos;pan3793&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/38622&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/38622&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17646682" author="apachespark" created="Tue, 13 Dec 2022 14:52:33 +0000"  >&lt;p&gt;User &apos;pan3793&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/39053&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/39053&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 48 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z16cvs:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>