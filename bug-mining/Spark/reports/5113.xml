<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:55:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21501] Spark shuffle index cache size should be memory based</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21501</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Right now the spark shuffle service has a cache for index files. It is based on a # of files cached (spark.shuffle.service.index.cache.entries). This can cause issues if people have a lot of reducers because the size of each entry can fluctuate based on the # of reducers. &lt;/p&gt;

&lt;p&gt;We saw an issues with a job that had 170000 reducers and it caused NM with spark shuffle service to use 700-800MB or memory in NM by itself.&lt;/p&gt;

&lt;p&gt;We should change this cache to be memory based and only allow a certain memory size used. When I say memory based I mean the cache should have a limit of say 100MB.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13089089">SPARK-21501</key>
            <summary>Spark shuffle index cache size should be memory based</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sanket991">Sanket Reddy</assignee>
                                    <reporter username="tgraves">Thomas Graves</reporter>
                        <labels>
                    </labels>
                <created>Fri, 21 Jul 2017 16:21:17 +0000</created>
                <updated>Wed, 21 Oct 2020 13:11:42 +0000</updated>
                            <resolved>Wed, 23 Aug 2017 16:51:42 +0000</resolved>
                                    <version>2.1.0</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>Shuffle</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="16098531" author="kiszk" created="Mon, 24 Jul 2017 14:56:47 +0000"  >&lt;p&gt;I guess that to use Spark 2.1 or later version alleviates this issue by &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-15074&quot; title=&quot;Spark shuffle service bottlenecked while fetching large amount of intermediate data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-15074&quot;&gt;&lt;del&gt;SPARK-15074&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16098907" author="tgraves" created="Mon, 24 Jul 2017 18:01:10 +0000"  >&lt;p&gt;The issue was actually introduced with &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-15074&quot; title=&quot;Spark shuffle service bottlenecked while fetching large amount of intermediate data&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-15074&quot;&gt;&lt;del&gt;SPARK-15074&lt;/del&gt;&lt;/a&gt;.  Updated the affects version. I was thinking that was added earlier so thanks for pointing out.&lt;/p&gt;

&lt;p&gt;That cache should be memory based not # of entries based.&lt;/p&gt;</comment>
                            <comment id="16099351" author="kiszk" created="Tue, 25 Jul 2017 01:08:48 +0000"  >&lt;p&gt;I see. I misunderstood the description.&lt;br/&gt;
You expect that memory cache would be enabled even when # of entries is larger than &lt;tt&gt;spark.shuffle.service.index.cache.entries&lt;/tt&gt; if the total cache size is not large.&lt;/p&gt;</comment>
                            <comment id="16100006" author="tgraves" created="Tue, 25 Jul 2017 13:10:08 +0000"  >&lt;p&gt;We want to change it from a # of entries to a size of memory.  So the cache is enabled but has a max size of 200MB for instance. This way you can size that based on the memory size of the YARN NM where the spark shuffle service runs.  If I have a 1GB heap on my NM this ensures it only uses 200MB.  With the # of entries you can&apos;t guarantee it won&apos;t use all 1GB of your heap because the size of each entry is dependent upon the # of reducers in that job.&lt;/p&gt;</comment>
                            <comment id="16100658" author="sanket991" created="Tue, 25 Jul 2017 19:57:09 +0000"  >&lt;p&gt;Hi I am working on this issue just to avoid any redundancies if any thanks&lt;/p&gt;</comment>
                            <comment id="16362424" author="renxunsaky" created="Tue, 13 Feb 2018 14:45:17 +0000"  >&lt;p&gt;Hi guys,&lt;/p&gt;

&lt;p&gt;Could you tell me how to figure out how many memory the&#160;NM with spark shuffle service has used ? And how to know a spark job has used how many reducers ?&lt;/p&gt;

&lt;p&gt;Because I have the same problem recently and I want to get a list of spark jobs by sorting by number of reducers.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;

&lt;p&gt;Regards,&lt;/p&gt;

&lt;p&gt;Xun REN.&lt;/p&gt;</comment>
                            <comment id="17218285" author="lars_francke" created="Wed, 21 Oct 2020 13:11:42 +0000"  >&lt;p&gt;Just FYI for others stumbling across this: This has a bug in how the memory is calculated and might use way more than the 100MB it intends to.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-33206&quot; title=&quot;Spark Shuffle Index Cache calculates memory usage wrong&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-33206&quot;&gt;&lt;del&gt;SPARK-33206&lt;/del&gt;&lt;/a&gt; for details.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 3 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3huu7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>