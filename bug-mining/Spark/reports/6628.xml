<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:06:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-28025] HDFSBackedStateStoreProvider should not leak .crc files </title>
                <link>https://issues.apache.org/jira/browse/SPARK-28025</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The HDFSBackedStateStoreProvider when using the default CheckpointFileManager is leaving &apos;.crc&apos; files behind. There&apos;s a .crc file created for each `atomicFile` operation of the CheckpointFileManager.&lt;/p&gt;

&lt;p&gt;Over time, the number of files becomes very large. It makes the state store file system constantly increase in size and, in our case, deteriorates the file system performance.&lt;/p&gt;

&lt;p&gt;Here&apos;s a sample of one of our spark storage volumes after 2 days of execution (4 stateful streaming jobs, each on a different sub-dir):&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Total files in PVC (used for checkpoints and state store)
$find . | wc -l
431796

# .crc files
$find . -name &quot;*.crc&quot; | wc -l
418053&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;With each .crc file taking one storage block, the used storage runs into the GBs of data.&lt;/p&gt;

&lt;p&gt;These jobs are running on Kubernetes. Our shared storage provider, GlusterFS,&#160;shows serious performance deterioration with this large number of files:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;DEBUG HDFSBackedStateStoreProvider: fetchFiles() took 29164ms&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment>&lt;p&gt;Spark 2.4.3&lt;/p&gt;

&lt;p&gt;Kubernetes 1.11&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/help_16.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; (OpenShift)&lt;/p&gt;

&lt;p&gt;StateStore storage on a mounted PVC. Viewed as a local filesystem by the `FileContextBasedCheckpointFileManager` :&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; glusterfm.isLocal
res17: Boolean = true&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</environment>
        <key id="13239002">SPARK-28025</key>
            <summary>HDFSBackedStateStoreProvider should not leak .crc files </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kabhwan">Jungtaek Lim</assignee>
                                    <reporter username="gmaas">Gerard Maas</reporter>
                        <labels>
                    </labels>
                <created>Wed, 12 Jun 2019 10:39:08 +0000</created>
                <updated>Thu, 8 Oct 2020 08:12:33 +0000</updated>
                            <resolved>Fri, 23 Aug 2019 06:12:22 +0000</resolved>
                                    <version>2.4.3</version>
                                    <fixVersion>2.4.4</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="16861983" author="gmaas" created="Wed, 12 Jun 2019 10:40:10 +0000"  >&lt;p&gt;Same problem. A different part of the code.&lt;/p&gt;</comment>
                            <comment id="16861991" author="gmaas" created="Wed, 12 Jun 2019 10:50:08 +0000"  >&lt;p&gt;I reproduced&#160; the issue&#160;in a&#160;&#160;spark-shell session:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
____ __
/ __/__ ___ _____/ /__
_\ \/ _ \/ _ `/ __/ &apos;_/
/___/ .__/\_,_/_/ /_/\_\ version 2.4.3
/_/

scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.execution.streaming._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.execution.streaming._

scala&amp;gt; val hadoopConf = spark.sparkContext.hadoopConfiguration

scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.internal.SQLConf
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.internal.SQLConf

scala&amp;gt; SQLConf.STREAMING_CHECKPOINT_FILE_MANAGER_CLASS.parent.key
res1: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = spark.sql.streaming.checkpointFileManagerClass

scala&amp;gt; hadoopConf.getSQLConf.STREAMING_CHECKPOINT_FILE_MANAGER_CLASS.parent.key)
res2: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;

&lt;span class=&quot;code-comment&quot;&gt;// mount point &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the shared PVC: /storage
&lt;/span&gt;scala&amp;gt; val glusterCpfm = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.apache.hadoop.fs.Path(&lt;span class=&quot;code-quote&quot;&gt;&quot;/storage/crc-store&quot;&lt;/span&gt;)
glusterCpfm: org.apache.hadoop.fs.Path = /storage/crc-store

scala&amp;gt; val glusterfm = CheckpointFileManager.create(glusterCpfm, hadoopConf)
glusterfm: org.apache.spark.sql.execution.streaming.CheckpointFileManager = org.apache.spark.sql.execution.streaming.FileContextBasedCheckpointFileManager@28d00f54

scala&amp;gt; glusterfm.isLocal
res17: &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;

scala&amp;gt; glusterfm.mkdirs(glusterCpfm)

scala&amp;gt; val atomicFile = glusterfm.createAtomic(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.apache.hadoop.fs.Path(&lt;span class=&quot;code-quote&quot;&gt;&quot;/storage/crc-store/file.log&quot;&lt;/span&gt;), &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)
atomicFile: org.apache.spark.sql.execution.streaming.CheckpointFileManager.CancellableFSDataOutputStream = org.apache.spark.sql.execution.streaming.CheckpointFileManager$RenameBasedFSDataOutputStream@1c6e065

scala&amp;gt; atomicFile.writeChars(&lt;span class=&quot;code-quote&quot;&gt;&quot;Hello, World&quot;&lt;/span&gt;)

scala&amp;gt; atomicFile.close

/**
* Inspect the file system
*
* $ cat file.log
* Hello, World
* $ ls -al
* total 5
* drwxr-sr-x. 2 jboss 2000 85 Jun 12 09:44 .
* drwxrwsr-x. 8 root 2000 4096 Jun 12 09:42 ..
* -rw-r--r--. 1 jboss 2000 12 Jun 12 09:44 ..file.log.c6f90863-77d2-494e-b1cc-0d0ed1344f74.tmp.crc
* -rw-r--r--. 1 jboss 2000 24 Jun 12 09:44 file.log
**/

&lt;span class=&quot;code-comment&quot;&gt;// Delete the file -- simulate the operation done by the HDFSBackedStateStoreProvider#cleanup
&lt;/span&gt;
scala&amp;gt; glusterfm.delete(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.apache.hadoop.fs.Path(&lt;span class=&quot;code-quote&quot;&gt;&quot;/storage/crc-store/file.log&quot;&lt;/span&gt;))

/**
* Inspect the file system -&amp;gt; .crc file left behind
* $ ls -al
* total 9
* drwxr-sr-x. 2 jboss 2000 4096 Jun 12 09:46 .
* drwxrwsr-x. 8 root 2000 4096 Jun 12 09:42 ..
* -rw-r--r--. 1 jboss 2000 12 Jun 12 09:44 ..file.log.c6f90863-77d2-494e-b1cc-0d0ed1344f74.tmp.crc
**/
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16862065" author="kabhwan" created="Wed, 12 Jun 2019 12:36:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gmaas&quot; class=&quot;user-hover&quot; rel=&quot;gmaas&quot;&gt;gmaas&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Nice finding. Would you like to submit a PR for this? Thanks!&lt;/p&gt;

&lt;p&gt;(If you would want to defer to someone, please ping me so that I could take this up.)&lt;/p&gt;</comment>
                            <comment id="16862227" author="stevel@apache.org" created="Wed, 12 Jun 2019 15:45:46 +0000"  >&lt;p&gt;looking at the previous patch, you don&apos;t need to call exists() Before the delete as delete is required to be a no-op if the source isnt&apos; there. Saves the cost of a HEAD if you are using an object store as a destination.&lt;/p&gt;</comment>
                            <comment id="16862339" author="skonto" created="Wed, 12 Jun 2019 18:17:12 +0000"  >&lt;p&gt;There is a workaround (avoid creating crc files if you dont want, in certain envs it is the default &lt;a href=&quot;https://cloud.google.com/blog/products/storage-data-transfer/new-file-checksum-feature-lets-you-validate-data-transfers-between-hdfs-and-cloud-storage&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cloud.google.com/blog/products/storage-data-transfer/new-file-checksum-feature-lets-you-validate-data-transfers-between-hdfs-and-cloud-storage&lt;/a&gt;) by setting `--conf spark.hadoop.spark.sql.streaming.checkpointFileManagerClass=org.apache.spark.sql.execution.streaming.FileSystemBasedCheckpointFileManager` when using local fs&lt;/p&gt;

&lt;p&gt;and modifying the&#160;FileSystemBasedCheckpointFileManager to run `fs.setWriteChecksum(false)` after fs is created.&lt;/p&gt;

&lt;p&gt;Reason is the&#160;FileContextBasedCheckpointFileManager will use ChecksumFS (&lt;a href=&quot;https://github.com/apache/hadoop/blob/73746c5da76d5e39df131534a1ec35dfc5d2529b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ChecksumFs.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/73746c5da76d5e39df131534a1ec35dfc5d2529b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ChecksumFs.java&lt;/a&gt;) under the hoods which will ignore &quot;&lt;/p&gt;

&lt;p&gt;CreateOpts.checksumParam(ChecksumOpt.createDisabled())&quot; passed. These settings will only avoid creating checksums for the checksums themshelves and only if the underlying fs supports it. However, it will create the checksum file in any case.&lt;/p&gt;

&lt;p&gt;FileSystemBasedCheckpointFileManager uses&#160;&lt;a href=&quot;https://github.com/apache/hadoop/blob/73746c5da76d5e39df131534a1ec35dfc5d2529b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ChecksumFileSystem.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/73746c5da76d5e39df131534a1ec35dfc5d2529b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/ChecksumFileSystem.java&lt;/a&gt;&#160;which allows to avoid checksums when creating files if you set that flag.&lt;/p&gt;

&lt;p&gt;Note that the crc is created when the tmp file is created not during rename or mv.&lt;/p&gt;

&lt;p&gt;I will create a PR shortly.&#160;&lt;/p&gt;</comment>
                            <comment id="16862449" author="kabhwan" created="Wed, 12 Jun 2019 20:47:55 +0000"  >&lt;p&gt;Personally I would respect the reporter and encourage to submit a patch by theirselves so that we could have broader contributors, but I&#160;assume you two are colleague (same employer) and discussed&#160;to decide who to submit a PR.&lt;/p&gt;</comment>
                            <comment id="16862548" author="skonto" created="Wed, 12 Jun 2019 23:27:38 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan&quot; class=&quot;user-hover&quot; rel=&quot;kabhwan&quot;&gt;kabhwan&lt;/a&gt; yes we discussed this internally when trying to solve the issue, otherwise I would not intervene. I fully respect people colleagues or not &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16862908" author="skonto" created="Thu, 13 Jun 2019 10:26:05 +0000"  >&lt;p&gt;I just found out that the following config options would suffice to avoid creating crcs for the given case:&lt;/p&gt;

&lt;p&gt;--conf spark.hadoop.spark.sql.streaming.checkpointFileManagerClass=org.apache.spark.sql.execution.streaming.FileSystemBasedCheckpointFileManager --conf spark.hadoop.fs.file.impl=org.apache.hadoop.fs.RawLocalFileSystem&lt;/p&gt;

&lt;p&gt;So no need to make a PR to disable crc emission if user wants to for this case. I could make one to cover all cases to be able to enable/disable crcs if needed.&#160;However, the filesystem hierarchy in hadoop is a bit inconsistent. So the LocalFileSystem will use a a FilterFileSystem that has the flag&#160;setWriteChecksum but the&#160;DistributedFileSystem does not have it and it is controlled by property &lt;a href=&quot;https://github.com/apache/hadoop/blob/533138718cc05b78e0afe583d7a9bd30e8a48fdc/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java#L620&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/533138718cc05b78e0afe583d7a9bd30e8a48fdc/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java#L620&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;`dfs.checksum.type`&lt;/p&gt;

&lt;p&gt;Btw there is a nice summary on the topic in chapter 5 of the book: hadoop the definitive guide.&#160;&lt;/p&gt;

&lt;p&gt;Looking at the old PR, I am not sure it would work with the LocalFs as it seems that the crc file will be renamed by default as the underlying system supports checksums by default.&#160;&#160;&lt;/p&gt;</comment>
                            <comment id="16892875" author="bartalos" created="Thu, 25 Jul 2019 15:21:21 +0000"  >&lt;p&gt;I&apos;m also affected by performance issue&#160;caused by .crc files leak in checkpoint directory. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=skonto&quot; class=&quot;user-hover&quot; rel=&quot;skonto&quot;&gt;skonto&lt;/a&gt;&#160;thank you for the workaround, it works.&lt;/p&gt;

&lt;p&gt;Would it be possible to implement&#160;cleaning of crc files, when one needs the&#160;checksum&#160;?&lt;/p&gt;</comment>
                            <comment id="16909912" author="kabhwan" created="Sun, 18 Aug 2019 08:01:25 +0000"  >&lt;p&gt;I still think it should rename crc file as well (so that it can be removed altogether if we purge batches) or just remove the crc file when it renames tmp file.&#160;If we want to stick with workaround,&#160;at least the workaround should be added to the guide doc. It doesn&apos;t look like being resolved.&lt;/p&gt;</comment>
                            <comment id="16919471" author="skonto" created="Fri, 30 Aug 2019 11:52:49 +0000"  >&lt;p&gt;@&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zsxwing&quot; class=&quot;user-hover&quot; rel=&quot;zsxwing&quot;&gt;zsxwing&lt;/a&gt;&#160;this needs to be re-opened. When using the workaround we recently hit this issue:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/broadinstitute/gatk/issues/1389&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/broadinstitute/gatk/issues/1389&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;which can be fixed easily with a derived class like in this PR:&#160;&lt;a href=&quot;https://github.com/broadinstitute/gatk/pull/1421/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/broadinstitute/gatk/pull/1421/files&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;but this is a bit of inconvenient.&#160;&lt;/p&gt;

&lt;p&gt;However, I believe as well that this should be fixed in Spark (less surprises) otherwise we need to document it as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan&quot; class=&quot;user-hover&quot; rel=&quot;kabhwan&quot;&gt;kabhwan&lt;/a&gt;&#160;said above.&lt;/p&gt;</comment>
                            <comment id="16919507" author="kabhwan" created="Fri, 30 Aug 2019 12:48:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=skonto&quot; class=&quot;user-hover&quot; rel=&quot;skonto&quot;&gt;skonto&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Please take a look at my PR as my PR didn&apos;t follow your workaround. We identified which Hadoop issue we are facing, and took a workaround as deleting crc file manually.&lt;/p&gt;</comment>
                            <comment id="16919514" author="stevel@apache.org" created="Fri, 30 Aug 2019 12:53:26 +0000"  >&lt;p&gt;Has anyone considered enhancing org.apache.hadoop.fs.ChecksumFileSystem to say &quot;if &quot;file.bytes-per-checksum&quot; == 0 then checksums are disabled?&lt;/p&gt;

&lt;p&gt;Currently it fails if bytes per CRC  &amp;lt;= 0, but you could make the 0 value a switch to say &quot;none&quot;.&lt;/p&gt;</comment>
                            <comment id="16919577" author="skonto" created="Fri, 30 Aug 2019 14:06:51 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan&quot; class=&quot;user-hover&quot; rel=&quot;kabhwan&quot;&gt;kabhwan&lt;/a&gt;&#160;cool I have a look.&lt;/p&gt;</comment>
                            <comment id="16919580" author="gsomogyi" created="Fri, 30 Aug 2019 14:09:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=skonto&quot; class=&quot;user-hover&quot; rel=&quot;skonto&quot;&gt;skonto&lt;/a&gt;, this one:&#160;&lt;a href=&quot;https://github.com/apache/spark/pull/25488&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/25488&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16919583" author="skonto" created="Fri, 30 Aug 2019 14:16:13 +0000"  >&lt;p&gt;Thanks I will have a look &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16920018" author="kabhwan" created="Sat, 31 Aug 2019 04:29:59 +0000"  >&lt;p&gt;FYI, I just submitted a patch for &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-16255&quot; title=&quot;ChecksumFS.Make FileSystem.rename(path, path, options) doesn&amp;#39;t rename checksum&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-16255&quot;&gt;&lt;del&gt;HADOOP-16255&lt;/del&gt;&lt;/a&gt;. Hope we can get rid of workaround sooner.&lt;/p&gt;</comment>
                            <comment id="16920706" author="gsomogyi" created="Mon, 2 Sep 2019 08:53:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt;&#160;I think adding&#160;&quot;file.bytes-per-checksum = 0&quot; possibility would be a workaround (at least here). The whole point why one choose&#160;ChecksumFileSystem is to have checksum.&lt;/p&gt;</comment>
                            <comment id="17210072" author="kabhwan" created="Thu, 8 Oct 2020 08:12:33 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Sorry to ping you on the old issue. According to the line we create a temp file, I guess we intend to &quot;disable&quot; creating CRC file, so actually it should never&#160;be an issue if thing works as intended, whereas it isn&apos;t.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/5effa8ea261ba59214afedc2853d1b248b330ca6/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/CheckpointFileManager.scala#L306-L311&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/5effa8ea261ba59214afedc2853d1b248b330ca6/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/CheckpointFileManager.scala#L306-L311&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// fc = FileContext.getFileContext(...)
&lt;/span&gt;
 fc.create(
  path, EnumSet.of(CREATE, OVERWRITE), CreateOpts.checksumParam(ChecksumOpt.createDisabled()))&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Is this something we should fix in Hadoop side, or the option is incorrect and we should apply other option?&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                            <outwardlinks description="causes">
                                        <issuelink>
            <issuekey id="13250558">SPARK-28712</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13003924">SPARK-17475</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 5 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z03nr4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>