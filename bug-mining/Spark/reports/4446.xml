<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:50:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18687] Backward compatibility - creating a Dataframe on a new SQLContext object fails with a Derby error</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18687</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;With a local spark instance built with hive support, (-Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0 -Phive -Phive-thriftserver)&lt;/p&gt;

&lt;p&gt;The following script/sequence works in Pyspark without any error in 1.6.x, but fails in 2.x.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;people = sc.parallelize([&lt;span class=&quot;code-quote&quot;&gt;&quot;Michael,30&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;Andy,12&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;Justin,19&quot;&lt;/span&gt;])
peoplePartsRDD = people.map(lambda p: p.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;,&quot;&lt;/span&gt;))
peopleRDD = peoplePartsRDD.map(lambda p: pyspark.sql.Row(name=p[0], age=&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;(p[1])))
peopleDF= sqlContext.createDataFrame(peopleRDD)
peopleDF.first()

sqlContext2 = SQLContext(sc)
people2 = sc.parallelize([&lt;span class=&quot;code-quote&quot;&gt;&quot;Abcd,40&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;Efgh,14&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;Ijkl,16&quot;&lt;/span&gt;])
peoplePartsRDD2 = people2.map(lambda l: l.split(&lt;span class=&quot;code-quote&quot;&gt;&quot;,&quot;&lt;/span&gt;))
peopleRDD2 = peoplePartsRDD2.map(lambda p: pyspark.sql.Row(fname=p[0], age=&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;(p[1])))
peopleDF2 = sqlContext2.createDataFrame(peopleRDD2) # &amp;lt;==== error here
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The error produced is:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;16/12/01 22:35:36 ERROR Schema: Failed initialising database.
Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
java.sql.SQLException: Failed to start database &apos;metastore_db&apos; with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@4494053, see the next exception for details.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
.
.
------

org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
java.sql.SQLException: Failed to start database &apos;metastore_db&apos; with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@519dabfd, see the next exception for details.
        at org.apache.derby.impl.jdb
.
.
.
NestedThrowables:
java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
java.sql.SQLException: Failed to start database &apos;metastore_db&apos; with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@519dabfd, see the next exception for details.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
.
.
.
Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
java.sql.SQLException: Failed to start database &apos;metastore_db&apos; with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@519dabfd, see the next exception for details.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedConnection.&amp;lt;init&amp;gt;(Unknown Source)
.
.
.
16/12/01 22:48:09 ERROR Schema: Failed initialising database.
Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=true, username = APP. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------
java.sql.SQLException: Failed to start database &apos;metastore_db&apos; with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@519dabfd, see the next exception for details.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedConnection.&amp;lt;init&amp;gt;(Unknown Source)
.
.
.
Caused by: java.sql.SQLException: Failed to start database &apos;metastore_db&apos; with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@519dabfd, see the next exception for details.
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
        at org.apache.derby.impl.jdbc.Util.seeNextException(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedConnection.bootDatabase(Unknown Source)
        at org.apache.derby.impl.jdbc.EmbedConnection.&amp;lt;init&amp;gt;(Unknown Source)
.
.
.

Caused by: ERROR XJ040: Failed to start database &apos;metastore_db&apos; with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@519dabfd, see the next exception for details.
        at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
        at org.apache.derby.impl.jdbc.SQLExceptionFactory.wrapArgsForTransportAcrossDRDA(Unknown Source)
        ... 111 more
Caused by: ERROR XSDB6: Another instance of Derby may have already booted the database /Users/vinayak/devel/spark-stc/git_repo/spark-master-x/spark/metastore_db.
        at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
        at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
        at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockOnDB(Unknown Source)
        at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown Source)
        at java.security.AccessController.doPrivileged(Native Method)
        at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.getJBMSLockOnDB(Unknown Source)
        at org.apache.derby.impl.store.raw.data.BaseDataFileFactory.boot(Unknown Source)
        at org.apache.derby.impl.services.monitor.BaseMonitor.boot(Unknown Source)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The error goes away if sqlContext2 is replaced with sqlContext in the last (error) line. Since the SQLContext class is preserved for backward compatibility, the changes in 2.x break scripts/notebooks that follow the above pattern of calls and used to run fine with 1.6.x.&lt;/p&gt;
</description>
                <environment>&lt;p&gt;Spark built with hive support&lt;/p&gt;</environment>
        <key id="13025020">SPARK-18687</key>
            <summary>Backward compatibility - creating a Dataframe on a new SQLContext object fails with a Derby error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="vijoshi">Vinayak Joshi</assignee>
                                    <reporter username="vijoshi">Vinayak Joshi</reporter>
                        <labels>
                    </labels>
                <created>Fri, 2 Dec 2016 09:01:33 +0000</created>
                <updated>Fri, 13 Jan 2017 17:21:25 +0000</updated>
                            <resolved>Fri, 13 Jan 2017 17:21:25 +0000</resolved>
                                    <version>2.0.0</version>
                    <version>2.0.1</version>
                    <version>2.0.2</version>
                                    <fixVersion>2.0.3</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>PySpark</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="15714546" author="srowen" created="Fri, 2 Dec 2016 09:09:58 +0000"  >&lt;p&gt;Spark 2 isn&apos;t necessarily compatible with Spark 1, and you shouldn&apos;t be making multiple SQLContexts right? why do the second one?&lt;/p&gt;</comment>
                            <comment id="15714630" author="vijoshi" created="Fri, 2 Dec 2016 09:44:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=srowen&quot; class=&quot;user-hover&quot; rel=&quot;srowen&quot;&gt;srowen&lt;/a&gt; Understand - however, it appears we have users who have code written that way and it used to work with 1.6 but breaks with 2.0. Since SQLContext has been preserved for backward compatibility, we&apos;re looking to see if this can problem can be plugged. &lt;/p&gt;

&lt;p&gt;A similar sequence of calls using Scala in spark-shell remains fine and looking into the code I figure it&apos;s because of the way the scala impl of SQLContext reuses the existing SparkSession internally. I am going to submit a PR on the same lines for the python impl of SQLContext that appears to fix the problem. However, I am not an expert in this particular part of the code so hopefully my change can be reviewed and considered for this issue.&lt;/p&gt;</comment>
                            <comment id="15714664" author="vijoshi" created="Fri, 2 Dec 2016 09:58:40 +0000"  >&lt;p&gt;Created pull request &lt;a href=&quot;https://github.com/apache/spark/pull/16119&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16119&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15714666" author="apachespark" created="Fri, 2 Dec 2016 09:59:06 +0000"  >&lt;p&gt;User &apos;vijoshi&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16119&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16119&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13029620">SPARK-18956</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 50 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i372cf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>