<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:41:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-47146] Possible thread leak when doing sort merge join</title>
                <link>https://issues.apache.org/jira/browse/SPARK-47146</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I have a long-running spark job. stumbled upon executor taking up a lot of threads, resulting in no threads available on the server. Querying thread details via jstack, there are tons of threads named read-ahead. Checking the code confirms that these threads are created by ReadAheadInputStream. This class is initialized to create a single-threaded thread pool&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; ExecutorService executorService =
    ThreadUtils.newDaemonSingleThreadExecutor(&lt;span class=&quot;code-quote&quot;&gt;&quot;read-ahead&quot;&lt;/span&gt;); &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This thread pool is closed by ReadAheadInputStream#close().&#160;&lt;/p&gt;

&lt;p&gt;The call stack for the normal case close() method is&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
ts=2024-02-21 17:36:18;thread_name=Executor task launch worker &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; task 60.0 in stage 71.0 (TID 258);id=330;is_daemon=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;;priority=5;TCCL=org.apache.spark.util.MutableURLClassLoader@17233230
&#160; &#160; @org.apache.spark.io.ReadAheadInputStream.close()
&#160; &#160; &#160; &#160; at org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.close(UnsafeSorterSpillReader.java:149)
&#160; &#160; &#160; &#160; at org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.loadNext(UnsafeSorterSpillReader.java:121)
&#160; &#160; &#160; &#160; at org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillMerger$1.loadNext(UnsafeSorterSpillMerger.java:87)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.advanceNext(UnsafeExternalRowSorter.java:187)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:67)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage27.processNext(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;:-1)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage29.smj_findNextJoinRows_0$(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;:-1)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage29.hashAgg_doAggregateWithKeys_1$(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;:-1)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage29.hashAgg_doAggregateWithKeys_0$(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;:-1)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage29.processNext(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;:-1)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
&#160; &#160; &#160; &#160; at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:779)
&#160; &#160; &#160; &#160; at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
&#160; &#160; &#160; &#160; at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)
&#160; &#160; &#160; &#160; at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
&#160; &#160; &#160; &#160; at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)
&#160; &#160; &#160; &#160; at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
&#160; &#160; &#160; &#160; at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
&#160; &#160; &#160; &#160; at org.apache.spark.scheduler.Task.run(Task.scala:139)
&#160; &#160; &#160; &#160; at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)
&#160; &#160; &#160; &#160; at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)
&#160; &#160; &#160; &#160; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)
&#160; &#160; &#160; &#160; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
&#160; &#160; &#160; &#160; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
&#160; &#160; &#160; &#160; at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:829) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;As shown in UnsafeSorterSpillReader#close, the stream is only closed when the data in the stream is read through.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
@Override
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void loadNext() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
  &lt;span class=&quot;code-comment&quot;&gt;// Kill the task in &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; it has been marked as killed. This logic is from
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// InterruptibleIterator, but we inline it here instead of wrapping the iterator in order
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// to avoid performance overhead. This check is added here in `loadNext()` instead of in
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// `hasNext()` because it&apos;s technically possible &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the caller to be relying on
&lt;/span&gt;  &lt;span class=&quot;code-comment&quot;&gt;// `getNumRecords()` instead of `hasNext()` to know when to stop.
&lt;/span&gt;  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (taskContext != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
    taskContext.killTaskIfInterrupted();
  }
  recordLength = din.readInt();
  keyPrefix = din.readLong();
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (recordLength &amp;gt; arr.length) {
    arr = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[recordLength];
    baseObject = arr;
  }
  ByteStreams.readFully(in, arr, 0, recordLength);
  numRecordsRemaining--;
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (numRecordsRemaining == 0) {
    close();
  }
} &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In sort merge join+inner join, if any StreamSide or BufferSide iterator touches the end, the unread iterator at the other end will not continue to read. A similar situation exists for left and right outer joins.&lt;/p&gt;

&lt;p&gt;In short, in several specific sort merge join types, a memory leak can occur when the amount of data is so large that a spill is triggered and there are iterators that are not read through.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13569656">SPARK-47146</key>
            <summary>Possible thread leak when doing sort merge join</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="JacobZheng">JacobZheng</assignee>
                                    <reporter username="JacobZheng">JacobZheng</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 23 Feb 2024 15:05:16 +0000</created>
                <updated>Wed, 6 Mar 2024 12:59:59 +0000</updated>
                            <resolved>Tue, 5 Mar 2024 05:17:49 +0000</resolved>
                                    <version>3.2.0</version>
                    <version>3.3.0</version>
                    <version>3.4.0</version>
                                    <fixVersion>3.5.2</fixVersion>
                    <fixVersion>3.4.3</fixVersion>
                    <fixVersion>4.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="17823420" author="mridulm80" created="Tue, 5 Mar 2024 05:17:49 +0000"  >&lt;p&gt;Issue resolved by pull request 45327&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/45327&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/45327&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17823832" author="mridulm80" created="Wed, 6 Mar 2024 02:37:47 +0000"  >&lt;p&gt;Backported to 3.5 and 3.4 in PR: &lt;a href=&quot;https://github.com/apache/spark/pull/45390&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/45390&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            1 year, 35 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1nl60:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>