<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26308] Large BigDecimal value is converted to null when passed into a UDF</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26308</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We are loading a Hive table into a Spark DataFrame. The Hive table has a decimal(30, 0) column with values greater than Long.MAX_VALUE. The DataFrame loads correctly.&lt;/p&gt;

&lt;p&gt;We then use a UDF to convert the decimal type to a String value. For decimal values &amp;lt; Long.MAX_VALUE, this works fine, but when the decimal value &amp;gt; Long.MAX_VALUE, the input to the UDF is a &lt;b&gt;null&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;Hive table schema and data:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
create table decimal_test (col1 decimal(30, 0), col2 decimal(10, 0), col3 &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;, col4 string);
insert into decimal_test values(2011000000000002456556, 123456789, 10, &lt;span class=&quot;code-quote&quot;&gt;&apos;test1&apos;&lt;/span&gt;);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Execution in spark-shell:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;(Note that the first column in the final output is null, it should have been &quot;2011000000000002456556&quot;)&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; val df1 = spark.sqlContext.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select * from decimal_test&quot;&lt;/span&gt;)
df1: org.apache.spark.sql.DataFrame = [col1: decimal(30,0), col2: decimal(10,0) ... 2 more fields]

scala&amp;gt; df1.show
+--------------------+---------+----+-----+
| col1| col2|col3| col4|
+--------------------+---------+----+-----+
|20110000000000024...|123456789| 10|test1|
+--------------------+---------+----+-----+


scala&amp;gt; val decimalToString = (value: java.math.BigDecimal) =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (value == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; { value.toBigInteger().toString }
decimalToString: java.math.BigDecimal =&amp;gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &amp;lt;function1&amp;gt;

scala&amp;gt; val udf1 = org.apache.spark.sql.functions.udf(decimalToString)
udf1: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&amp;lt;function1&amp;gt;,StringType,Some(List(DecimalType(38,18))))

scala&amp;gt; val df2 = df1.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;, udf1(df1.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;)))
df2: org.apache.spark.sql.DataFrame = [col1: string, col2: decimal(10,0) ... 2 more fields]

scala&amp;gt; df2.show
+----+---------+----+-----+
|col1| col2|col3| col4|
+----+---------+----+-----+
|&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|123456789| 10|test1|
+----+---------+----+-----+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Oddly this works if we change the &quot;decimalToString&quot; udf to take an &quot;Any&quot; instead of a &quot;java.math.BigDecimal&quot;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; val decimalToString = (value: Any) =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (value == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; { &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (value.isInstanceOf[java.math.BigDecimal]) value.asInstanceOf[java.math.BigDecimal].toBigInteger().toString &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; }
decimalToString: Any =&amp;gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = &amp;lt;function1&amp;gt;

scala&amp;gt; val udf1 = org.apache.spark.sql.functions.udf(decimalToString)
udf1: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(&amp;lt;function1&amp;gt;,StringType,None)

scala&amp;gt; val df2 = df1.withColumn(&lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;, udf1(df1.col(&lt;span class=&quot;code-quote&quot;&gt;&quot;col1&quot;&lt;/span&gt;)))
df2: org.apache.spark.sql.DataFrame = [col1: string, col2: decimal(10,0) ... 2 more fields]

scala&amp;gt; df2.show
+--------------------+---------+----+-----+
| col1| col2|col3| col4|
+--------------------+---------+----+-----+
|20110000000000024...|123456789| 10|test1|
+--------------------+---------+----+-----+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13203122">SPARK-26308</key>
            <summary>Large BigDecimal value is converted to null when passed into a UDF</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mgaido">Marco Gaido</assignee>
                                    <reporter username="jay.pranavamurthi">Jay Pranavamurthi</reporter>
                        <labels>
                    </labels>
                <created>Fri, 7 Dec 2018 18:49:10 +0000</created>
                <updated>Mon, 12 Dec 2022 18:10:50 +0000</updated>
                            <resolved>Thu, 20 Dec 2018 06:20:04 +0000</resolved>
                                    <version>2.3.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="16713761" author="dongjoon" created="Sat, 8 Dec 2018 19:44:13 +0000"  >&lt;p&gt;cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mgaido&quot; class=&quot;user-hover&quot; rel=&quot;mgaido&quot;&gt;mgaido&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16714483" author="mgaido" created="Mon, 10 Dec 2018 09:32:08 +0000"  >&lt;p&gt;Thanks for pinging me &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;, I&apos;ll take a look at this asap.&lt;/p&gt;</comment>
                            <comment id="16714557" author="mgaido" created="Mon, 10 Dec 2018 10:46:57 +0000"  >&lt;p&gt;So the problem here is that the type inferred for decimal types in UDF is &lt;tt&gt;decimal(38, 18)&lt;/tt&gt;. Since the value doesn&apos;t fit in this range, it is converted to &lt;tt&gt;null&lt;/tt&gt;. In your &quot;workaround&quot;, you&apos;re basically turning off automatic inference for the input types, hence the problem is &quot;solved&quot;. Since the UDF are not related to a column/schema, I don&apos;t have a better suggestion how to deal with this case. Another &quot;workaround&quot; is to use the overloaded &lt;tt&gt;udf&lt;/tt&gt; method which gets the output data type too as parameter (in this method there is no input inference either).&lt;/p&gt;

&lt;p&gt;The only &quot;solution&quot; I can think of is to disable type inference for decimal types. If we agree on this I can submit a PR for it. What do you think &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smilegator&quot; class=&quot;user-hover&quot; rel=&quot;smilegator&quot;&gt;smilegator&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ueshin&quot; class=&quot;user-hover&quot; rel=&quot;ueshin&quot;&gt;ueshin&lt;/a&gt;?&lt;/p&gt;</comment>
                            <comment id="16714589" author="cloud_fan" created="Mon, 10 Dec 2018 11:16:24 +0000"  >&lt;p&gt;`ScalaUDF.inputTypes` is only used to check input types, I think we should put a general `DecimalType` there, instead of a specific one like `DecimalType(38, 18)`.&lt;/p&gt;</comment>
                            <comment id="16714597" author="mgaido" created="Mon, 10 Dec 2018 11:24:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt; what do you mean by a general &lt;tt&gt;DecimalType&lt;/tt&gt;? A &lt;tt&gt;DecimalType&lt;/tt&gt; can be instantiated only with a related precision and scale. And whatever we choose cannot fit all the cases. Are you suggesting making optional the precision and scale in &lt;tt&gt;DecimalType&lt;/tt&gt;?&lt;/p&gt;</comment>
                            <comment id="16714608" author="cloud_fan" created="Mon, 10 Dec 2018 11:40:45 +0000"  >&lt;p&gt;there is a `object DecimalType extends AbstractDataType`.&lt;/p&gt;</comment>
                            <comment id="16714702" author="mgaido" created="Mon, 10 Dec 2018 13:18:49 +0000"  >&lt;p&gt;Yes, but it is an &lt;tt&gt;AbstractDataType&lt;/tt&gt;, not a &lt;tt&gt;DataType&lt;/tt&gt;. This can be done (it may require binaries breaking changes, but may be fine for 3.0), but alleviates only the issue: let&apos;s think to the case of an array of decimals: the array type can&apos;t be an abstract datatype, so the problem would still be there.&lt;/p&gt;</comment>
                            <comment id="16714769" author="cloud_fan" created="Mon, 10 Dec 2018 14:13:55 +0000"  >&lt;p&gt;How about we override `ScalaUDF.checkInputTypes` and special-case decimal type?&lt;/p&gt;</comment>
                            <comment id="16714782" author="mgaido" created="Mon, 10 Dec 2018 14:25:43 +0000"  >&lt;p&gt;I think that works. Maybe it is not a &quot;perfect&quot; solution but for Scala UDF it should be safe to do that. I&apos;ll work on it, thanks.&lt;/p&gt;</comment>
                            <comment id="16714879" author="mgaido" created="Mon, 10 Dec 2018 15:12:41 +0000"  >&lt;p&gt;I checked but it doesn&apos;t work because the cast is added anyway in &lt;tt&gt;ImplicitTypeCasts&lt;/tt&gt;. So I don&apos;t have a good solution which works for any scenario. An idea may be to create an abstract version of Array, Strict and Map types which allow abstract types, but I am not sure this is acceptable just to fix this issue... We may start here tackling the case of decimals only and leave a TODO for decimals in complex types. How does this sound?&lt;/p&gt;</comment>
                            <comment id="16719753" author="gurwls223" created="Thu, 13 Dec 2018 05:00:20 +0000"  >&lt;p&gt;^ I think that sounds okay.&lt;/p&gt;</comment>
                            <comment id="16720070" author="githubbot" created="Thu, 13 Dec 2018 11:43:16 +0000"  >&lt;p&gt;mgaido91 opened a new pull request #23308: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26308&quot; title=&quot;Large BigDecimal value is converted to null when passed into a UDF&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26308&quot;&gt;&lt;del&gt;SPARK-26308&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;SQL&amp;#93;&lt;/span&gt; Infer abstract decimal type for java/scala BigDecimal&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/spark/pull/23308&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23308&lt;/a&gt;&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;What changes were proposed in this pull request?&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Currently, when we infer the schema for scala/java decimals, we return as data type the `SYSTEM_DEFAULT` implementation, ie. the decimal type with precision 38 and scale 18. But this is not right, as we know nothing about the right precision and scale and these values can be not enough to store the data. This problem arises in particular with UDF, where we cast all the input of type `DecimalType` to a `DecimalType(38, 18)`: in case this is not enough, null is returned as input for the UDF.&lt;/p&gt;

&lt;p&gt;   The PR changes the resolution of `BigDecimal`/`Decimal` to the abstract `DecimalType`. Please notice that the same problem is still present for Decimals in arrays, structs and maps, because the related types don&apos;t accept an `AbstractDataType`. In a followup work, we can introduce abstract types for them accepting abstract types in order to fix the issue for them too.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;How was this patch tested?&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   added UT&lt;/p&gt;


&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16725612" author="cloud_fan" created="Thu, 20 Dec 2018 06:20:04 +0000"  >&lt;p&gt;Issue resolved by pull request 23308&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23308&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23308&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16725614" author="githubbot" created="Thu, 20 Dec 2018 06:22:25 +0000"  >&lt;p&gt;asfgit closed pull request #23308: &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26308&quot; title=&quot;Large BigDecimal value is converted to null when passed into a UDF&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26308&quot;&gt;&lt;del&gt;SPARK-26308&lt;/del&gt;&lt;/a&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;SQL&amp;#93;&lt;/span&gt; Avoid cast of decimals for ScalaUDF&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/spark/pull/23308&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23308&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/TypeCoercion.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/TypeCoercion.scala&lt;br/&gt;
index 133fa119b7aa6..1706b3eece6d7 100644&lt;br/&gt;
&amp;#8212; a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/TypeCoercion.scala&lt;br/&gt;
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/TypeCoercion.scala&lt;br/&gt;
@@ -879,6 +879,37 @@ object TypeCoercion {&lt;br/&gt;
           }&lt;br/&gt;
         }&lt;br/&gt;
         e.withNewChildren(children)&lt;br/&gt;
+&lt;br/&gt;
+      case udf: ScalaUDF if udf.inputTypes.nonEmpty =&amp;gt;&lt;br/&gt;
+        val children = udf.children.zip(udf.inputTypes).map &lt;/p&gt;
{ case (in, expected) =&amp;gt;
+          implicitCast(in, udfInputToCastType(in.dataType, expected)).getOrElse(in)
+        }
&lt;p&gt;+        udf.withNewChildren(children)&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private def udfInputToCastType(input: DataType, expectedType: DataType): DataType = {&lt;br/&gt;
+      (input, expectedType) match {&lt;br/&gt;
+        // &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26308&quot; title=&quot;Large BigDecimal value is converted to null when passed into a UDF&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26308&quot;&gt;&lt;del&gt;SPARK-26308&lt;/del&gt;&lt;/a&gt;: avoid casting to an arbitrary precision and scale for decimals. Please note&lt;br/&gt;
+        // that precision and scale cannot be inferred properly for a ScalaUDF because, when it is&lt;br/&gt;
+        // created, it is not bound to any column. So here the precision and scale of the input&lt;br/&gt;
+        // column is used.&lt;br/&gt;
+        case (in: DecimalType, _: DecimalType) =&amp;gt; in&lt;br/&gt;
+        case (ArrayType(dtIn, _), ArrayType(dtExp, nullableExp)) =&amp;gt;&lt;br/&gt;
+          ArrayType(udfInputToCastType(dtIn, dtExp), nullableExp)&lt;br/&gt;
+        case (MapType(keyDtIn, valueDtIn, _), MapType(keyDtExp, valueDtExp, nullableExp)) =&amp;gt;&lt;br/&gt;
+          MapType(udfInputToCastType(keyDtIn, keyDtExp),&lt;br/&gt;
+            udfInputToCastType(valueDtIn, valueDtExp),&lt;br/&gt;
+            nullableExp)&lt;br/&gt;
+        case (StructType(fieldsIn), StructType(fieldsExp)) =&amp;gt;&lt;br/&gt;
+          val fieldTypes =&lt;br/&gt;
+            fieldsIn.map(&lt;em&gt;.dataType).zip(fieldsExp.map(&lt;/em&gt;.dataType)).map &lt;/p&gt;
{ case (dtIn, dtExp) =&amp;gt;
+              udfInputToCastType(dtIn, dtExp)
+            }
&lt;p&gt;+          StructType(fieldsExp.zip(fieldTypes).map &lt;/p&gt;
{ case (field, newDt) =&amp;gt;
+            field.copy(dataType = newDt)
+          }
&lt;p&gt;)&lt;br/&gt;
+        case (_, other) =&amp;gt; other&lt;br/&gt;
+      }&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     /**&lt;br/&gt;
diff --git a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ScalaUDF.scala b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ScalaUDF.scala&lt;br/&gt;
index fae90caebf96c..a23aaa3a0b3ef 100644&lt;br/&gt;
&amp;#8212; a/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ScalaUDF.scala&lt;br/&gt;
+++ b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ScalaUDF.scala&lt;br/&gt;
@@ -52,7 +52,7 @@ case class ScalaUDF(&lt;br/&gt;
     udfName: Option&lt;span class=&quot;error&quot;&gt;&amp;#91;String&amp;#93;&lt;/span&gt; = None,&lt;br/&gt;
     nullable: Boolean = true,&lt;br/&gt;
     udfDeterministic: Boolean = true)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;extends Expression with ImplicitCastInputTypes with NonSQLExpression with UserDefinedExpression {&lt;br/&gt;
+  extends Expression with NonSQLExpression with UserDefinedExpression {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   // The constructor for SPARK 2.1 and 2.2&lt;br/&gt;
   def this(&lt;br/&gt;
diff --git a/sql/core/src/test/scala/org/apache/spark/sql/UDFSuite.scala b/sql/core/src/test/scala/org/apache/spark/sql/UDFSuite.scala&lt;br/&gt;
index 20dcefa7e3cad..a26d306cff6b5 100644&lt;br/&gt;
&amp;#8212; a/sql/core/src/test/scala/org/apache/spark/sql/UDFSuite.scala&lt;br/&gt;
+++ b/sql/core/src/test/scala/org/apache/spark/sql/UDFSuite.scala&lt;br/&gt;
@@ -17,6 +17,8 @@&lt;/p&gt;

&lt;p&gt; package org.apache.spark.sql&lt;/p&gt;

&lt;p&gt;+import java.math.BigDecimal&lt;br/&gt;
+&lt;br/&gt;
 import org.apache.spark.sql.api.java._&lt;br/&gt;
 import org.apache.spark.sql.catalyst.plans.logical.Project&lt;br/&gt;
 import org.apache.spark.sql.execution.QueryExecution&lt;br/&gt;
@@ -26,7 +28,7 @@ import org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationComm&lt;br/&gt;
 import org.apache.spark.sql.functions.&lt;/p&gt;
{lit, udf}
&lt;p&gt; import org.apache.spark.sql.test.SharedSQLContext&lt;br/&gt;
 import org.apache.spark.sql.test.SQLTestData._&lt;br/&gt;
-import org.apache.spark.sql.types.&lt;/p&gt;
{DataTypes, DoubleType}
&lt;p&gt;+import org.apache.spark.sql.types._&lt;br/&gt;
 import org.apache.spark.sql.util.QueryExecutionListener&lt;/p&gt;


&lt;p&gt;@@ -420,4 +422,32 @@ class UDFSuite extends QueryTest with SharedSQLContext &lt;/p&gt;
{
       checkAnswer(df, Seq(Row(&quot;null1x&quot;), Row(null), Row(&quot;N3null&quot;)))
     }
&lt;p&gt;   }&lt;br/&gt;
+&lt;br/&gt;
+  test(&quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26308&quot; title=&quot;Large BigDecimal value is converted to null when passed into a UDF&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26308&quot;&gt;&lt;del&gt;SPARK-26308&lt;/del&gt;&lt;/a&gt;: udf with decimal&quot;) {&lt;br/&gt;
+    val df1 = spark.createDataFrame(&lt;br/&gt;
+      sparkContext.parallelize(Seq(Row(new BigDecimal(&quot;2011000000000002456556&quot;)))),&lt;br/&gt;
+      StructType(Seq(StructField(&quot;col1&quot;, DecimalType(30, 0)))))&lt;br/&gt;
+    val udf1 = org.apache.spark.sql.functions.udf((value: BigDecimal) =&amp;gt; &lt;/p&gt;
{
+      if (value == null) null else value.toBigInteger.toString
+    }
&lt;p&gt;)&lt;br/&gt;
+    checkAnswer(df1.select(udf1(df1.col(&quot;col1&quot;))), Seq(Row(&quot;2011000000000002456556&quot;)))&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  test(&quot;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-26308&quot; title=&quot;Large BigDecimal value is converted to null when passed into a UDF&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-26308&quot;&gt;&lt;del&gt;SPARK-26308&lt;/del&gt;&lt;/a&gt;: udf with complex types of decimal&quot;) {&lt;br/&gt;
+    val df1 = spark.createDataFrame(&lt;br/&gt;
+      sparkContext.parallelize(Seq(Row(Array(new BigDecimal(&quot;2011000000000002456556&quot;))))),&lt;br/&gt;
+      StructType(Seq(StructField(&quot;col1&quot;, ArrayType(DecimalType(30, 0))))))&lt;br/&gt;
+    val udf1 = org.apache.spark.sql.functions.udf((arr: Seq&lt;span class=&quot;error&quot;&gt;&amp;#91;BigDecimal&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+      arr.map(value =&amp;gt; if (value == null) null else value.toBigInteger.toString)
+    }
&lt;p&gt;)&lt;br/&gt;
+    checkAnswer(df1.select(udf1($&quot;col1&quot;)), Seq(Row(Array(&quot;2011000000000002456556&quot;))))&lt;br/&gt;
+&lt;br/&gt;
+    val df2 = spark.createDataFrame(&lt;br/&gt;
+      sparkContext.parallelize(Seq(Row(Map(&quot;a&quot; -&amp;gt; new BigDecimal(&quot;2011000000000002456556&quot;))))),&lt;br/&gt;
+      StructType(Seq(StructField(&quot;col1&quot;, MapType(StringType, DecimalType(30, 0))))))&lt;br/&gt;
+    val udf2 = org.apache.spark.sql.functions.udf((map: Map&lt;span class=&quot;error&quot;&gt;&amp;#91;String, BigDecimal&amp;#93;&lt;/span&gt;) =&amp;gt; &lt;/p&gt;
{
+      map.mapValues(value =&amp;gt; if (value == null) null else value.toBigInteger.toString)
+    }
&lt;p&gt;)&lt;br/&gt;
+    checkAnswer(df2.select(udf2($&quot;col1&quot;)), Seq(Row(Map(&quot;a&quot; -&amp;gt; &quot;2011000000000002456556&quot;))))&lt;br/&gt;
+  }&lt;br/&gt;
 }&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 47 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|s01aoo:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>