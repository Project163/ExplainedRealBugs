<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:29:13 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-8437] Using directory path without wildcard for filename slow for large number of files with wholeTextFiles and binaryFiles</title>
                <link>https://issues.apache.org/jira/browse/SPARK-8437</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When calling wholeTextFiles or binaryFiles with a directory path with 10,000s of files in it, Spark hangs for a few minutes before processing the files.&lt;/p&gt;

&lt;p&gt;If you add a * to the end of the path, there is no delay.&lt;/p&gt;

&lt;p&gt;This happens for me on Spark 1.3.1 and 1.4 on the local filesystem, HDFS, and on S3.&lt;/p&gt;

&lt;p&gt;To reproduce, create a directory with 50,000 files in it, then run:&lt;/p&gt;


&lt;p&gt;val a = sc.binaryFiles(&quot;file:/path/to/files/&quot;)&lt;br/&gt;
a.count()&lt;/p&gt;

&lt;p&gt;val b = sc.binaryFiles(&quot;file:/path/to/files/*&quot;)&lt;br/&gt;
b.count()&lt;/p&gt;

&lt;p&gt;and monitor the different startup times.&lt;/p&gt;

&lt;p&gt;For example, in the spark-shell these commands are pasted in together, so the delay at f.count() is from 10:11:08 t- 10:13:29 to output &quot;Total input paths to process : 49999&quot;, then until 10:15:42 to being processing files:&lt;/p&gt;

&lt;p&gt;scala&amp;gt; val f = sc.binaryFiles(&quot;file:/home/ewan/large/&quot;)&lt;br/&gt;
15/06/18 10:11:07 INFO MemoryStore: ensureFreeSpace(160616) called with curMem=0, maxMem=278019440&lt;br/&gt;
15/06/18 10:11:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 156.9 KB, free 265.0 MB)&lt;br/&gt;
15/06/18 10:11:08 INFO MemoryStore: ensureFreeSpace(17282) called with curMem=160616, maxMem=278019440&lt;br/&gt;
15/06/18 10:11:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.9 KB, free 265.0 MB)&lt;br/&gt;
15/06/18 10:11:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:40430 (size: 16.9 KB, free: 265.1 MB)&lt;br/&gt;
15/06/18 10:11:08 INFO SparkContext: Created broadcast 0 from binaryFiles at &amp;lt;console&amp;gt;:21&lt;br/&gt;
f: org.apache.spark.rdd.RDD&lt;span class=&quot;error&quot;&gt;&amp;#91;(String, org.apache.spark.input.PortableDataStream)&amp;#93;&lt;/span&gt; = &lt;a href=&quot;file:/home/ewan/large/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/home/ewan/large/&lt;/a&gt; BinaryFileRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; at binaryFiles at &amp;lt;console&amp;gt;:21&lt;/p&gt;

&lt;p&gt;scala&amp;gt; f.count()&lt;br/&gt;
15/06/18 10:13:29 INFO FileInputFormat: Total input paths to process : 49999&lt;br/&gt;
15/06/18 10:15:42 INFO FileInputFormat: Total input paths to process : 49999&lt;br/&gt;
15/06/18 10:15:42 INFO CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0&lt;br/&gt;
15/06/18 10:15:42 INFO SparkContext: Starting job: count at &amp;lt;console&amp;gt;:24&lt;br/&gt;
15/06/18 10:15:42 INFO DAGScheduler: Got job 0 (count at &amp;lt;console&amp;gt;:24) with 49999 output partitions (allowLocal=false)&lt;br/&gt;
15/06/18 10:15:42 INFO DAGScheduler: Final stage: ResultStage 0(count at &amp;lt;console&amp;gt;:24)&lt;br/&gt;
15/06/18 10:15:42 INFO DAGScheduler: Parents of final stage: List()&lt;/p&gt;

&lt;p&gt;Adding a * to the end of the path removes the delay:&lt;/p&gt;


&lt;p&gt;scala&amp;gt; val f = sc.binaryFiles(&quot;file:/home/ewan/large/*&quot;)&lt;br/&gt;
15/06/18 10:08:29 INFO MemoryStore: ensureFreeSpace(160616) called with curMem=0, maxMem=278019440&lt;br/&gt;
15/06/18 10:08:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 156.9 KB, free 265.0 MB)&lt;br/&gt;
15/06/18 10:08:29 INFO MemoryStore: ensureFreeSpace(17309) called with curMem=160616, maxMem=278019440&lt;br/&gt;
15/06/18 10:08:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.9 KB, free 265.0 MB)&lt;br/&gt;
15/06/18 10:08:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42825 (size: 16.9 KB, free: 265.1 MB)&lt;br/&gt;
15/06/18 10:08:29 INFO SparkContext: Created broadcast 0 from binaryFiles at &amp;lt;console&amp;gt;:21&lt;br/&gt;
f: org.apache.spark.rdd.RDD&lt;span class=&quot;error&quot;&gt;&amp;#91;(String, org.apache.spark.input.PortableDataStream)&amp;#93;&lt;/span&gt; = &lt;a href=&quot;file:/home/ewan/large/*&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/home/ewan/large/*&lt;/a&gt; BinaryFileRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; at binaryFiles at &amp;lt;console&amp;gt;:21&lt;/p&gt;

&lt;p&gt;scala&amp;gt; f.count()&lt;br/&gt;
15/06/18 10:08:32 INFO FileInputFormat: Total input paths to process : 49999&lt;br/&gt;
15/06/18 10:08:33 INFO FileInputFormat: Total input paths to process : 49999&lt;br/&gt;
15/06/18 10:08:35 INFO CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0&lt;br/&gt;
15/06/18 10:08:35 INFO SparkContext: Starting job: count at &amp;lt;console&amp;gt;:24&lt;br/&gt;
15/06/18 10:08:35 INFO DAGScheduler: Got job 0 (count at &amp;lt;console&amp;gt;:24) with 49999 output partitions &lt;/p&gt;
</description>
                <environment>&lt;p&gt;Ubuntu 15.04 + local filesystem&lt;br/&gt;
Amazon EMR + S3 + HDFS&lt;/p&gt;</environment>
        <key id="12838740">SPARK-8437</key>
            <summary>Using directory path without wildcard for filename slow for large number of files with wholeTextFiles and binaryFiles</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="ewanleith">Ewan Leith</reporter>
                        <labels>
                    </labels>
                <created>Thu, 18 Jun 2015 09:48:44 +0000</created>
                <updated>Thu, 13 Oct 2016 16:47:35 +0000</updated>
                            <resolved>Tue, 30 Jun 2015 17:07:48 +0000</resolved>
                                    <version>1.3.1</version>
                    <version>1.4.0</version>
                                    <fixVersion>1.4.1</fixVersion>
                    <fixVersion>1.5.0</fixVersion>
                                    <component>Input/Output</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14591608" author="srowen" created="Thu, 18 Jun 2015 10:24:09 +0000"  >&lt;p&gt;Yeah that&apos;s a weird one, but I&apos;m pretty sure this is a Hadoop API phenomenon rather than Spark-related. I assume that the glob can be pushed down further rather than go manually list and expand directories remotely or something. It might not be something Spark can do anything about, but have a look. At least you could propose a doc change to suggest that the glob expression is more desirable.&lt;/p&gt;</comment>
                            <comment id="14591615" author="ewanleith" created="Thu, 18 Jun 2015 10:30:30 +0000"  >&lt;p&gt;Thanks, I wasn&apos;t sure if it was Hadoop or Spark specific, initially I thought it was S3 related but it happens all over.&lt;/p&gt;

&lt;p&gt;If it is Hadoop, I don&apos;t know if it would be feasible for Spark to check if a directory has been given and add a wildcard in the background, that might not give the desired effect, but otherwise there&apos;s various doc changes to make.&lt;/p&gt;

&lt;p&gt;I&apos;ve just tried this with textFile(&quot;/path/to/files/&quot;) and got the same issue, so I assume it is a hadoop thing, and documentation changes might be the best option&lt;/p&gt;</comment>
                            <comment id="14602600" author="apachespark" created="Fri, 26 Jun 2015 09:11:55 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7036&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7036&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14606721" author="andrewor14" created="Tue, 30 Jun 2015 00:23:15 +0000"  >&lt;p&gt;The merged PR involves only documentation changes. I don&apos;t think there is another Spark fix that can change this, as this issue is fundamental to the underlying file system. I am closing this.&lt;/p&gt;</comment>
                            <comment id="14606807" author="andrewor14" created="Tue, 30 Jun 2015 01:33:36 +0000"  >&lt;p&gt;Re-opening because the patch was reverted.&lt;/p&gt;</comment>
                            <comment id="14608174" author="apachespark" created="Tue, 30 Jun 2015 11:57:04 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7126&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7126&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15572468" author="stevel@apache.org" created="Thu, 13 Oct 2016 16:47:35 +0000"  >&lt;p&gt;Just came across by way of comments in the source. This &lt;b&gt;shouldn&apos;t&lt;/b&gt; happen; the glob code ought to recognise when there is no wildcard and exit early &#8212;faster than if there was a wildcard. If its taking longer, then the full list process is making a mess of things, or somehow the result generation is playing up. If it was S3 only I&apos;d blame the S3 APIs, but this sounds like S3 just amplifies a problem which may exist already&lt;/p&gt;

&lt;p&gt;How big was the directory where this surfaced? Was it deep, wide or deep &amp;amp; wide?&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 5 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2g77j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12332833">1.4.2</customfieldvalue>
    <customfieldvalue id="12332078">1.5.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>