<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:35:06 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-45227] Fix a subtle thread-safety issue with CoarseGrainedExecutorBackend where an executor process randomly gets stuck</title>
                <link>https://issues.apache.org/jira/browse/SPARK-45227</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;h2&gt;&lt;a name=&quot;Symptom&quot;&gt;&lt;/a&gt;Symptom&lt;/h2&gt;

&lt;p&gt;Our Spark 3 app running on EMR 6.10.0 with Spark 3.3.1 got stuck in the very last step of writing a data frame to S3 by calling &lt;tt&gt;df.write&lt;/tt&gt;. Looking at Spark UI, we saw that an executor process hung over 1 hour. After we manually killed the executor process, the app succeeded. Note that the same EMR cluster with two worker nodes was able to run the same app without any issue before and after the incident.&lt;/p&gt;
&lt;h2&gt;&lt;a name=&quot;Observations&quot;&gt;&lt;/a&gt;Observations&lt;/h2&gt;

&lt;p&gt;Below is what&apos;s observed from relevant container logs and thread dump.&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;A regular task that&apos;s sent to the executor, which also reported back to the driver upon the task completion.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;$zgrep &apos;task 150&apos; container_1694029806204_12865_01_000001/stderr.gz&lt;br/&gt;
23/09/12 18:13:55 INFO TaskSetManager: Starting task 150.0 in stage 23.0 (TID 923) (ip-10-0-185-107.ec2.internal, executor 3, partition 150, NODE_LOCAL, 4432 bytes) taskResourceAssignments Map()&lt;br/&gt;
23/09/12 18:13:55 INFO TaskSetManager: Finished task 150.0 in stage 23.0 (TID 923) in 126 ms on ip-10-0-185-107.ec2.internal (executor 3) (16/200)&lt;/p&gt;

&lt;p&gt;$zgrep &apos;task 923&apos; container_1694029806204_12865_01_000004/stderr.gz&lt;br/&gt;
23/09/12 18:13:55 INFO YarnCoarseGrainedExecutorBackend: Got assigned task 923&lt;/p&gt;

&lt;p&gt;$zgrep &apos;task 150&apos; container_1694029806204_12865_01_000004/stderr.gz&lt;br/&gt;
23/09/12 18:13:55 INFO Executor: Running task 150.0 in stage 23.0 (TID 923)&lt;br/&gt;
23/09/12 18:13:55 INFO Executor: Finished task 150.0 in stage 23.0 (TID 923). 4495 bytes result sent to driver}}&lt;/p&gt;&lt;/blockquote&gt; * Another task that&apos;s sent to the executor but didn&apos;t get launched since the single-threaded dispatcher was stuck (presumably in an &quot;infinite loop&quot; as explained later).&lt;/p&gt;

&lt;p&gt;&lt;blockquote&gt;&lt;p&gt;$zgrep &apos;task 153&apos; container_1694029806204_12865_01_000001/stderr.gz&lt;br/&gt;
23/09/12 18:13:55 INFO TaskSetManager: Starting task 153.0 in stage 23.0 (TID 924) (ip-10-0-185-107.ec2.internal, executor 3, partition 153, NODE_LOCAL, 4432 bytes) taskResourceAssignments Map()&lt;/p&gt;

&lt;p&gt;$zgrep &apos; 924&apos; container_1694029806204_12865_01_000004/stderr.gz&lt;br/&gt;
23/09/12 18:13:55 INFO YarnCoarseGrainedExecutorBackend: Got assigned task 924&lt;/p&gt;

&lt;p&gt;$zgrep &apos;task 153&apos; container_1694029806204_12865_01_000004/stderr.gz&lt;br/&gt;
&amp;gt;&amp;gt; note that the above command has no matching result, indicating that task 153.0 in stage 23.0 (TID 924) was never launched}}&lt;/p&gt;&lt;/blockquote&gt;* Thread dump shows that the dispatcher-Executor thread has the following stack trace.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;&quot;dispatcher-Executor&quot; #40 daemon prio=5 os_prio=0 tid=0x0000ffff98e37800 nid=0x1aff runnable &lt;span class=&quot;error&quot;&gt;&amp;#91;0x0000ffff73bba000&amp;#93;&lt;/span&gt;&lt;br/&gt;
java.lang.Thread.State: RUNNABLE&lt;br/&gt;
at scala.runtime.BoxesRunTime.equalsNumObject(BoxesRunTime.java:142)&lt;br/&gt;
at scala.runtime.BoxesRunTime.equals2(BoxesRunTime.java:131)&lt;br/&gt;
at scala.runtime.BoxesRunTime.equals(BoxesRunTime.java:123)&lt;br/&gt;
at scala.collection.mutable.HashTable.elemEquals(HashTable.scala:365)&lt;br/&gt;
at scala.collection.mutable.HashTable.elemEquals$(HashTable.scala:365)&lt;br/&gt;
at scala.collection.mutable.HashMap.elemEquals(HashMap.scala:44)&lt;br/&gt;
at scala.collection.mutable.HashTable.findEntry0(HashTable.scala:140)&lt;br/&gt;
at scala.collection.mutable.HashTable.findOrAddEntry(HashTable.scala:169)&lt;br/&gt;
at scala.collection.mutable.HashTable.findOrAddEntry$(HashTable.scala:167)&lt;br/&gt;
at scala.collection.mutable.HashMap.findOrAddEntry(HashMap.scala:44)&lt;br/&gt;
at scala.collection.mutable.HashMap.put(HashMap.scala:126)&lt;br/&gt;
at scala.collection.mutable.HashMap.update(HashMap.scala:131)&lt;br/&gt;
at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$receive$1.applyOrElse(CoarseGrainedExecutorBackend.scala:200)&lt;br/&gt;
at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)&lt;br/&gt;
at org.apache.spark.rpc.netty.Inbox$$Lambda$323/1930826709.apply$mcV$sp(Unknown Source)&lt;br/&gt;
at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)&lt;br/&gt;
at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)&lt;br/&gt;
at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)&lt;br/&gt;
at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)&lt;br/&gt;
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;br/&gt;
at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;br/&gt;
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)&lt;br/&gt;
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)&lt;br/&gt;
at java.lang.Thread.run(Thread.java:750)}}&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;&lt;a name=&quot;Relevantcodepaths&quot;&gt;&lt;/a&gt;Relevant code paths&lt;/h2&gt;

&lt;p&gt;Within an executor process, there&apos;s a &lt;a href=&quot;https://github.com/apache/spark/blob/1fdd46f173f7bc90e0523eb0a2d5e8e27e990102/core/src/main/scala/org/apache/spark/rpc/netty/MessageLoop.scala#L170&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;dispatcher thread&lt;/a&gt; dedicated to CoarseGrainedExecutorBackend (a single RPC endpoint) that launches tasks scheduled by the driver. Each task is run on a TaskRunner thread backed by a thread pool created for the executor. The TaskRunner thread and the dispatcher thread are different. However, they read and write a common object (i.e., taskResources) that&apos;s a mutable hashmap without thread-safety, in &lt;a href=&quot;https://github.com/apache/spark/blob/1fdd46f173f7bc90e0523eb0a2d5e8e27e990102/core/src/main/scala/org/apache/spark/executor/Executor.scala#L561&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Executor&lt;/a&gt; and &lt;a href=&quot;https://github.com/apache/spark/blob/1fdd46f173f7bc90e0523eb0a2d5e8e27e990102/core/src/main/scala/org/apache/spark/executor/CoarseGrainedExecutorBackend.scala#L189&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;CoarseGrainedExecutorBackend&lt;/a&gt;, respectively.&lt;/p&gt;
&lt;h2&gt;&lt;a name=&quot;What%27sgoingon%3F&quot;&gt;&lt;/a&gt;What&apos;s going on?&lt;/h2&gt;

&lt;p&gt;Based on the above observations, our hypothesis is that the dispatcher thread runs into an &quot;infinite loop&quot; due to a race condition when two threads access the same hashmap object.&#160; For illustration purpose, let&apos;s consider the following scenario where two threads (Thread 1 and Thread 2) access a hash table without thread-safety&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Thread 1 sees A.next = B, but then yields execution to Thread 2&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13063040/13063040_hashtable1.png&quot; height=&quot;182&quot; width=&quot;357&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;br/&gt;
&#160;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Thread 2 triggers a resize operation resulting in B.next = A (Note that hashmap doesn&apos;t care about ordering), and then yields execution to Thread 1.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/13063041/13063041_hashtable2.png&quot; height=&quot;329&quot; width=&quot;383&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;After taking over CPU, Thread 1 would run into an &quot;infinite loop&quot; when traversing the list in the last bucket, given A.next = B and B.next = A in its view.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;&lt;a name=&quot;Proposedfix&quot;&gt;&lt;/a&gt;Proposed fix&lt;/h2&gt;
&lt;ul&gt;
	&lt;li&gt;Replace &lt;tt&gt;scala.collection.mutable.HashMap&lt;/tt&gt; in CoarseGrainedExecutorBackend with &lt;tt&gt;java.util.concurrent.&lt;/tt&gt;&lt;tt&gt;ConcurrentHashMap&lt;/tt&gt; for thread safety.&lt;/li&gt;
	&lt;li&gt;As a mitigation before the fix is released, consider to use fewer threads per executor process (i.e., fewer spark.executor.cores)to reduce the likelihood of such a race condition.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="13551311">SPARK-45227</key>
            <summary>Fix a subtle thread-safety issue with CoarseGrainedExecutorBackend where an executor process randomly gets stuck</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="xiongbo">Bo Xiong</assignee>
                                    <reporter username="xiongbo">Bo Xiong</reporter>
                        <labels>
                            <label>hang</label>
                            <label>infinite-loop</label>
                            <label>pull-request-available</label>
                            <label>race-condition</label>
                            <label>stuck</label>
                            <label>threadsafe</label>
                    </labels>
                <created>Wed, 20 Sep 2023 02:45:25 +0000</created>
                <updated>Mon, 8 Apr 2024 06:08:02 +0000</updated>
                            <resolved>Fri, 29 Sep 2023 03:58:20 +0000</resolved>
                                    <version>3.3.1</version>
                    <version>3.5.0</version>
                    <version>4.0.0</version>
                                    <fixVersion>3.4.2</fixVersion>
                    <fixVersion>3.5.1</fixVersion>
                    <fixVersion>3.3.4</fixVersion>
                    <fixVersion>4.0.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                    <workratio workratioPercent="0"/>
                                    <progress percentage="0">
                                    <originalProgress>
                                                    <row percentage="100" backgroundColor="#89afd7"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="0" backgroundColor="#51a825"/>
                                                    <row percentage="100" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="0">
                                    <originalProgress>
                                                    <row percentage="100" backgroundColor="#89afd7"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="0" backgroundColor="#51a825"/>
                                                    <row percentage="100" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                    <timeoriginalestimate seconds="14400">4h</timeoriginalestimate>
                            <timeestimate seconds="14400">4h</timeestimate>
                                        <comments>
                            <comment id="17767843" author="JIRAUSER302302" created="Fri, 22 Sep 2023 06:11:22 +0000"  >&lt;p&gt;I&apos;ve submitted &lt;a href=&quot;https://github.com/apache/spark/pull/43021&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;a fix&lt;/a&gt;. &#160;Please help get it merged.&lt;/p&gt;

&lt;p&gt;If possible, please also help patch v3.3.1 and above.&#160; Thanks!&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="13063040" name="hashtable1.png" size="23512" author="xiongbo" created="Wed, 20 Sep 2023 02:58:20 +0000"/>
                            <attachment id="13063041" name="hashtable2.png" size="34718" author="xiongbo" created="Wed, 20 Sep 2023 02:58:23 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10430"><![CDATA[Patch]]></customfieldvalue>
    <customfieldvalue key="10431"><![CDATA[Important]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 7 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1kgug:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>