<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:07:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-29604] SessionState is initialized with isolated classloader for Hive if spark.sql.hive.metastore.jars is being set</title>
                <link>https://issues.apache.org/jira/browse/SPARK-29604</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I&apos;ve observed the issue that external listeners cannot be loaded properly when we run spark-sql with &quot;spark.sql.hive.metastore.jars&quot; configuration being used.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: Error while instantiating &apos;org.apache.spark.sql.hive.HiveSessionStateBuilder&apos;:
	at org.apache.spark.sql.SparkSession$.org$apache$spark$sql$SparkSession$$instantiateSessionState(SparkSession.scala:1102)
	at org.apache.spark.sql.SparkSession$$anonfun$sessionState$2.apply(SparkSession.scala:154)
	at org.apache.spark.sql.SparkSession$$anonfun$sessionState$2.apply(SparkSession.scala:153)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession.sessionState$lzycompute(SparkSession.scala:153)
	at org.apache.spark.sql.SparkSession.sessionState(SparkSession.scala:150)
	at org.apache.spark.sql.SparkSession$$anonfun$1$$anonfun$apply$2.apply(SparkSession.scala:104)
	at org.apache.spark.sql.SparkSession$$anonfun$1$$anonfun$apply$2.apply(SparkSession.scala:104)
	at scala.Option.map(Option.scala:146)
	at org.apache.spark.sql.SparkSession$$anonfun$1.apply(SparkSession.scala:104)
	at org.apache.spark.sql.SparkSession$$anonfun$1.apply(SparkSession.scala:103)
	at org.apache.spark.sql.internal.SQLConf$.get(SQLConf.scala:149)
	at org.apache.spark.sql.hive.client.HiveClientImpl.org$apache$spark$sql$hive$client$HiveClientImpl$$client(HiveClientImpl.scala:282)
	at org.apache.spark.sql.hive.client.HiveClientImpl$$anonfun$withHiveState$1.apply(HiveClientImpl.scala:306)
	at org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:247)
	at org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:246)
	at org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:296)
	at org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:386)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply$mcZ$sp(HiveExternalCatalog.scala:215)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:215)
	at org.apache.spark.sql.hive.HiveExternalCatalog$$anonfun$databaseExists$1.apply(HiveExternalCatalog.scala:215)
	at org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:97)
	at org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:214)
	at org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:114)
	at org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:102)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLEnv$.init(SparkSQLEnv.scala:53)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.&amp;lt;init&amp;gt;(SparkSQLCLIDriver.scala:315)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver$.main(SparkSQLCLIDriver.scala:166)
	at org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver.main(SparkSQLCLIDriver.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:847)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:922)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:931)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: org.apache.spark.SparkException: Exception when registering StreamingQueryListener
	at org.apache.spark.sql.streaming.StreamingQueryManager.&amp;lt;init&amp;gt;(StreamingQueryManager.scala:70)
	at org.apache.spark.sql.internal.BaseSessionStateBuilder.streamingQueryManager(BaseSessionStateBuilder.scala:260)
	at org.apache.spark.sql.internal.BaseSessionStateBuilder.build(BaseSessionStateBuilder.scala:296)
	at org.apache.spark.sql.SparkSession$.org$apache$spark$sql$SparkSession$$instantiateSessionState(SparkSession.scala:1099)
	... 40 more
Caused by: java.lang.ClassNotFoundException: com.hortonworks.spark.atlas.SparkAtlasStreamingQueryEventTracker
	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.spark.util.Utils$.classForName(Utils.scala:193)
	at org.apache.spark.util.Utils$$anonfun$loadExtensions$1.apply(Utils.scala:2640)
	at org.apache.spark.util.Utils$$anonfun$loadExtensions$1.apply(Utils.scala:2638)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.util.Utils$.loadExtensions(Utils.scala:2638)
	at org.apache.spark.sql.streaming.StreamingQueryManager$$anonfun$1.apply(StreamingQueryManager.scala:62)
	at org.apache.spark.sql.streaming.StreamingQueryManager$$anonfun$1.apply(StreamingQueryManager.scala:61)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.sql.streaming.StreamingQueryManager.&amp;lt;init&amp;gt;(StreamingQueryManager.scala:61)
	... 43 more
 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <environment></environment>
        <key id="13264478">SPARK-29604</key>
            <summary>SessionState is initialized with isolated classloader for Hive if spark.sql.hive.metastore.jars is being set</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kabhwan">Jungtaek Lim</assignee>
                                    <reporter username="kabhwan">Jungtaek Lim</reporter>
                        <labels>
                    </labels>
                <created>Fri, 25 Oct 2019 12:24:26 +0000</created>
                <updated>Tue, 3 Dec 2019 23:53:47 +0000</updated>
                            <resolved>Wed, 30 Oct 2019 08:10:11 +0000</resolved>
                                    <version>2.4.4</version>
                    <version>3.0.0</version>
                                    <fixVersion>2.4.5</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="16959711" author="kabhwan" created="Fri, 25 Oct 2019 12:25:24 +0000"  >&lt;p&gt;I&apos;ve figured out the root cause and have a patch. Will submit a patch soon. I may need some more time to craft a relevant test.&lt;/p&gt;</comment>
                            <comment id="16962802" author="dongjoon" created="Wed, 30 Oct 2019 08:10:11 +0000"  >&lt;p&gt;This is resolved via &lt;a href=&quot;https://github.com/apache/spark/pull/26258&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/26258&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16962851" author="dongjoon" created="Wed, 30 Oct 2019 09:39:49 +0000"  >&lt;p&gt;This lands at `branch-2.4` via &lt;a href=&quot;https://github.com/apache/spark/pull/26316&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/26316&lt;/a&gt; .&lt;/p&gt;</comment>
                            <comment id="16962859" author="dongjoon" created="Wed, 30 Oct 2019 09:44:45 +0000"  >&lt;p&gt;BTW, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan&quot; class=&quot;user-hover&quot; rel=&quot;kabhwan&quot;&gt;kabhwan&lt;/a&gt;. Could you check the old version (at least `2.3.x`) and update `Affects Version/s:`, too?&lt;/p&gt;</comment>
                            <comment id="16963000" author="kabhwan" created="Wed, 30 Oct 2019 12:57:45 +0000"  >&lt;p&gt;I think it doesn&apos;t apply to branch-2.3 as the root issue is more alike lazy initialization of streaming query listeners and there&apos;s no configuration for registering streaming query listeners in Spark 2.3. (only API)&lt;/p&gt;</comment>
                            <comment id="16963264" author="dongjoon" created="Wed, 30 Oct 2019 17:35:31 +0000"  >&lt;p&gt;Thank you so much for confirming, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan&quot; class=&quot;user-hover&quot; rel=&quot;kabhwan&quot;&gt;kabhwan&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;The newly added test case seems to be flaky in `SBT Hadoop 3.2` build. Could you check that?&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;a href=&quot;https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Test%20(Dashboard)/job/spark-master-test-sbt-hadoop-3.2/676/testReport/org.apache.spark.sql.hive.thriftserver/SparkSQLEnvSuite/SPARK_29604_external_listeners_should_be_initialized_with_Spark_classloader/history/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Test%20(Dashboard)/job/spark-master-test-sbt-hadoop-3.2/676/testReport/org.apache.spark.sql.hive.thriftserver/SparkSQLEnvSuite/SPARK_29604_external_listeners_should_be_initialized_with_Spark_classloader/history/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="16963476" author="kabhwan" created="Wed, 30 Oct 2019 22:20:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt;&lt;br/&gt;
Do we have any annotation/trait to &quot;isolate&quot; running test suite? I&apos;m suspecting session, or listeners in session is being modified from other tests running concurrently.&lt;/p&gt;</comment>
                            <comment id="16963693" author="dongjoon" created="Thu, 31 Oct 2019 06:37:04 +0000"  >&lt;p&gt;Unfortunately, I don&apos;t know~ &lt;/p&gt;

&lt;p&gt;The session theory makes sense to me.&lt;/p&gt;

&lt;p&gt;In addition to that, according to the log, if some test fails, this test suite seems to fail together.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;a href=&quot;https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Test%20(Dashboard)/job/spark-master-test-sbt-hadoop-3.2/682/testReport/junit/org.apache.spark.sql.hive.thriftserver/SparkSQLEnvSuite/SPARK_29604_external_listeners_should_be_initialized_with_Spark_classloader/history/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Test%20(Dashboard)/job/spark-master-test-sbt-hadoop-3.2/682/testReport/junit/org.apache.spark.sql.hive.thriftserver/SparkSQLEnvSuite/SPARK_29604_external_listeners_should_be_initialized_with_Spark_classloader/history/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;please see `SBT Hadoop-3.2` Jenkins job.&lt;/p&gt;</comment>
                            <comment id="16963737" author="kabhwan" created="Thu, 31 Oct 2019 07:45:33 +0000"  >&lt;p&gt;I&apos;ve manually ran the test suite locally (single run) and it passed 3 times sequentially.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ java -version
openjdk version &lt;span class=&quot;code-quote&quot;&gt;&quot;11.0.2&quot;&lt;/span&gt; 2019-01-15
OpenJDK &lt;span class=&quot;code-object&quot;&gt;Runtime&lt;/span&gt; Environment 18.9 (build 11.0.2+9)
OpenJDK 64-Bit Server VM 18.9 (build 11.0.2+9, mixed mode)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ build/sbt &lt;span class=&quot;code-quote&quot;&gt;&quot;hive-thriftserver/testOnly *.SparkSQLEnvSuite&quot;&lt;/span&gt; -Phadoop-3.2 -Phive-thriftserver
...
[info] SparkSQLEnvSuite:
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/jlim/WorkArea/ScalaProjects/spark/common/unsafe/target/scala-2.12/spark-unsafe_2.12-3.0.0-SNAPSHOT.jar) to constructor java.nio.DirectByteBuffer(&lt;span class=&quot;code-object&quot;&gt;long&lt;/span&gt;,&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)
WARNING: Please consider reporting &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; release
[info] - SPARK-29604 external listeners should be initialized with Spark classloader (2 minutes, 26 seconds)
[info] ScalaTest
[info] Run completed in 2 minutes, 30 seconds.
[info] Total number of tests run: 1
[info] Suites: completed 1, aborted 0
[info] Tests: succeeded 1, failed 0, canceled 0, ignored 0, pending 0
[info] All tests passed.
[info] Passed: Total 1, Failed 0, Errors 0, Passed 1
[success] Total time: 319 s, completed Oct 31, 2019, 4:30:34 PM
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Maybe I should add this suite to `testsWhichShouldRunInTheirOwnDedicatedJvm` - I cannot find any other way to isolate the test suite.&lt;/p&gt;</comment>
                            <comment id="16964137" author="dongjoon" created="Thu, 31 Oct 2019 15:30:09 +0000"  >&lt;p&gt;Thank you for keeping working on this.&lt;br/&gt;
Yes. It passed locally. That&apos;s the reason why I didn&apos;t revert this patch until now.&lt;br/&gt;
But, we are on 3.0.0-preview voting. In the worst case, we need to revert this.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 2 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z07yds:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>