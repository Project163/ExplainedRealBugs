<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:13:55 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-1712] ParallelCollectionRDD operations hanging forever without any error messages </title>
                <link>https://issues.apache.org/jira/browse/SPARK-1712</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt; conf/spark-defaults.conf&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;spark.akka.frameSize         5
spark.&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;.parallelism    1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; val collection = (1 to 1000000).map(i =&amp;gt; (&quot;foo&quot; + i, i)).toVector
collection: Vector[(String, Int)] = Vector((foo1,1), (foo2,2), (foo3,3), (foo4,4), (foo5,5), (foo6,6), (foo7,7), (foo8,8), (foo9,9), (foo10,10), (foo11,11), (foo12,12), (foo13,13), (foo14,14), (foo15,15), (foo16,16), (foo17,17), (foo18,18), (foo19,19), (foo20,20), (foo21,21), (foo22,22), (foo23,23), (foo24,24), (foo25,25), (foo26,26), (foo27,27), (foo28,28), (foo29,29), (foo30,30), (foo31,31), (foo32,32), (foo33,33), (foo34,34), (foo35,35), (foo36,36), (foo37,37), (foo38,38), (foo39,39), (foo40,40), (foo41,41), (foo42,42), (foo43,43), (foo44,44), (foo45,45), (foo46,46), (foo47,47), (foo48,48), (foo49,49), (foo50,50), (foo51,51), (foo52,52), (foo53,53), (foo54,54), (foo55,55), (foo56,56), (foo57,57), (foo58,58), (foo59,59), (foo60,60), (foo61,61), (foo62,62), (foo63,63), (foo64,64), (foo...

scala&amp;gt; val rdd = sc.parallelize(collection)
rdd: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[0] at parallelize at &amp;lt;console&amp;gt;:24

scala&amp;gt; rdd.first
res4: (String, Int) = (foo1,1)

scala&amp;gt; rdd.map(_._2).sum
// nothing happens

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;CPU and I/O idle. &lt;br/&gt;
Memory usage reported by JVM, after manually triggered GC:&lt;br/&gt;
repl: 216 MB / 2 GB&lt;br/&gt;
executor: 67 MB / 2 GB&lt;br/&gt;
worker: 6 MB / 128 MB&lt;br/&gt;
master: 6 MB / 128 MB&lt;/p&gt;

&lt;p&gt;No errors found in worker&apos;s stderr/stdout. &lt;/p&gt;

&lt;p&gt;It works fine with 700,000 elements and then it takes about 1 second to process the request and calculate the sum. With 700,000 items the spark executor memory doesn&apos;t even exceed 300 MB out of 2GB available. It fails with 800,000 items.&lt;/p&gt;

&lt;p&gt;Multiple parralelized collections of size 700,000 items at the same time in the same session work fine.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Linux Ubuntu 14.04, a single spark node; standalone mode.&lt;/p&gt;</environment>
        <key id="12712205">SPARK-1712</key>
            <summary>ParallelCollectionRDD operations hanging forever without any error messages </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="gq">Guoqiang Li</assignee>
                                    <reporter username="pkolaczk">Piotr Kolaczkowski</reporter>
                        <labels>
                    </labels>
                <created>Sun, 4 May 2014 19:14:52 +0000</created>
                <updated>Wed, 18 Jun 2014 14:41:21 +0000</updated>
                            <resolved>Wed, 28 May 2014 22:58:03 +0000</resolved>
                                    <version>0.9.0</version>
                                    <fixVersion>0.9.2</fixVersion>
                    <fixVersion>1.0.1</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13989324" author="pkolaczk" created="Mon, 5 May 2014 07:20:46 +0000"  >&lt;p&gt;The problem goes away if I increase parallelismLevel. &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;val rdd = sc.parallelize(collection, 64)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So I guess this is something related to partition size.&lt;/p&gt;</comment>
                            <comment id="13989696" author="gq" created="Mon, 5 May 2014 16:58:05 +0000"  >&lt;p&gt;Unable to reproduce the bug.Can you upload the log?&lt;/p&gt;</comment>
                            <comment id="13989876" author="pkolaczk" created="Mon, 5 May 2014 19:30:23 +0000"  >&lt;p&gt;This is log from shell:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; val rdd = sc.parallelize(collection)
14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter: parse(&quot;       val rdd = sc.parallelize(collection)
&quot;) Some(List(val rdd = sc.parallelize(collection)))
14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter:   11: ValDef
  11: TypeTree
  31: Apply
  20: Select
  17: Ident
  32: Ident

14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter: parse(&quot;
class $read extends Serializable {
  class $iwC extends Serializable {
val $VAL2 = $line3.$read.INSTANCE;
import $VAL2.$iw.$iw.`sc`;
class $iwC extends Serializable {
import org.apache.spark.SparkContext._
class $iwC extends Serializable {
class $iwC extends Serializable {
import com.datastax.bdp.spark.CassandraFunctions._
class $iwC extends Serializable {
import com.datastax.bdp.spark.context.CassandraContext
class $iwC extends Serializable {
import com.tuplejump.calliope.Implicits._
class $iwC extends Serializable {
val $VAL3 = $line17.$read.INSTANCE;
import $VAL3.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.`collection`;
class $iwC extends Serializable {
       val rdd = sc.parallelize(collection)

      

}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;

}
object $read {
  val INSTANCE = new $read();
}

&quot;) Some(List(class $read extends Serializable {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;();
    ()
  };
  class $iwC extends Serializable {
    def &amp;lt;init&amp;gt;() = {
      super.&amp;lt;init&amp;gt;();
      ()
    };
    val $VAL2 = $line3.$read.INSTANCE;
    import $VAL2.$iw.$iw.sc;
    class $iwC extends Serializable {
      def &amp;lt;init&amp;gt;() = {
        super.&amp;lt;init&amp;gt;();
        ()
      };
      import org.apache.spark.SparkContext._;
      class $iwC extends Serializable {
        def &amp;lt;init&amp;gt;() = {
          super.&amp;lt;init&amp;gt;();
          ()
        };
        class $iwC extends Serializable {
          def &amp;lt;init&amp;gt;() = {
            super.&amp;lt;init&amp;gt;();
            ()
          };
          import com.datastax.bdp.spark.CassandraFunctions._;
          class $iwC extends Serializable {
            def &amp;lt;init&amp;gt;() = {
              super.&amp;lt;init&amp;gt;();
              ()
            };
            import com.datastax.bdp.spark.context.CassandraContext;
            class $iwC extends Serializable {
              def &amp;lt;init&amp;gt;() = {
                super.&amp;lt;init&amp;gt;();
                ()
              };
              import com.tuplejump.calliope.Implicits._;
              class $iwC extends Serializable {
                def &amp;lt;init&amp;gt;() = {
                  super.&amp;lt;init&amp;gt;();
                  ()
                };
                val $VAL3 = $line17.$read.INSTANCE;
                import $VAL3.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.collection;
                class $iwC extends Serializable {
                  def &amp;lt;init&amp;gt;() = {
                    super.&amp;lt;init&amp;gt;();
                    ()
                  };
                  val rdd = sc.parallelize(collection)
                };
                val $iw = new $iwC()
              };
              val $iw = new $iwC()
            };
            val $iw = new $iwC()
          };
          val $iw = new $iwC()
        };
        val $iw = new $iwC()
      };
      val $iw = new $iwC()
    };
    val $iw = new $iwC()
  };
  val $iw = new $iwC()
}, object $read extends scala.AnyRef {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;();
    ()
  };
  val INSTANCE = new $read()
}))
14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter: class $read extends Serializable {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;;
    ()
  };
  class $iwC extends Serializable {
    def &amp;lt;init&amp;gt;() = {
      super.&amp;lt;init&amp;gt;;
      ()
    };
    val $VAL2 = $line3.$read.INSTANCE;
    import $VAL2.$iw.$iw.sc;
    class $iwC extends Serializable {
      def &amp;lt;init&amp;gt;() = {
        super.&amp;lt;init&amp;gt;;
        ()
      };
      import org.apache.spark.SparkContext._;
      class $iwC extends Serializable {
        def &amp;lt;init&amp;gt;() = {
          super.&amp;lt;init&amp;gt;;
          ()
        };
        class $iwC extends Serializable {
          def &amp;lt;init&amp;gt;() = {
            super.&amp;lt;init&amp;gt;;
            ()
          };
          import com.datastax.bdp.spark.CassandraFunctions._;
          class $iwC extends Serializable {
            def &amp;lt;init&amp;gt;() = {
              super.&amp;lt;init&amp;gt;;
              ()
            };
            import com.datastax.bdp.spark.context.CassandraContext;
            class $iwC extends Serializable {
              def &amp;lt;init&amp;gt;() = {
                super.&amp;lt;init&amp;gt;;
                ()
              };
              import com.tuplejump.calliope.Implicits._;
              class $iwC extends Serializable {
                def &amp;lt;init&amp;gt;() = {
                  super.&amp;lt;init&amp;gt;;
                  ()
                };
                val $VAL3 = $line17.$read.INSTANCE;
                import $VAL3.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.collection;
                class $iwC extends Serializable {
                  def &amp;lt;init&amp;gt;() = {
                    super.&amp;lt;init&amp;gt;;
                    ()
                  };
                  val rdd = sc parallelize collection
                };
                val $iw = new $iwC.&amp;lt;init&amp;gt;
              };
              val $iw = new $iwC.&amp;lt;init&amp;gt;
            };
            val $iw = new $iwC.&amp;lt;init&amp;gt;
          };
          val $iw = new $iwC.&amp;lt;init&amp;gt;
        };
        val $iw = new $iwC.&amp;lt;init&amp;gt;
      };
      val $iw = new $iwC.&amp;lt;init&amp;gt;
    };
    val $iw = new $iwC.&amp;lt;init&amp;gt;
  };
  val $iw = new $iwC.&amp;lt;init&amp;gt;
}
14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter: object $read extends scala.AnyRef {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;;
    ()
  };
  val INSTANCE = new $read.&amp;lt;init&amp;gt;
}
14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter: Set symbol of rdd to val rdd(): org.apache.spark.rdd.RDD
14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter: parse(&quot;
object $eval {
  lazy val $result = $line18.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.`rdd`
  val $print: String =  {
    $read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw
    (&quot;&quot;
      
 + &quot;rdd: org.apache.spark.rdd.RDD[(String, Int)] = &quot; + scala.runtime.ScalaRunTime.replStringOf($line18.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.`rdd`, 1000)

    )
  }
}
      
&quot;) Some(List(object $eval extends scala.AnyRef {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;();
    ()
  };
  lazy val $result = $line18.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.rdd;
  val $print: String = {
    $read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw;
    &quot;&quot;.$plus(&quot;rdd: org.apache.spark.rdd.RDD[(String, Int)] = &quot;).$plus(scala.runtime.ScalaRunTime.replStringOf($line18.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.rdd, 1000))
  }
}))
14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter: object $eval extends scala.AnyRef {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;;
    ()
  };
  lazy val $result = $line18.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.rdd;
  val $print: String = {
    $read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw;
    &quot;&quot;.+(&quot;rdd: org.apache.spark.rdd.RDD[(String, Int)] = &quot;).+(scala.runtime.ScalaRunTime.replStringOf($line18.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.rdd, 1000))
  }
}
14/05/05 21:23:16 DEBUG SparkILoop$SparkILoopInterpreter: Invoking: public static java.lang.String $line18.$eval.$print()
rdd: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[0] at parallelize at &amp;lt;console&amp;gt;:21

scala&amp;gt; rdd.map(_._2).sum
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: parse(&quot;       rdd.map(_._2).sum
&quot;) Some(List(rdd.map(((x$1) =&amp;gt; x$1._2)).sum))
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter:   21: Select
  14: Apply
  11: Select
  7: Ident
  17: Function
  15: ValDef
  15: TypeTree
  -1: EmptyTree
  17: Select
  15: Ident

14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: parse(&quot;       val res3 =
              rdd.map(_._2).sum
&quot;) Some(List(val res3 = rdd.map(((x$1) =&amp;gt; x$1._2)).sum))
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter:   11: ValDef
  11: TypeTree
  46: Select
  39: Apply
  36: Select
  32: Ident
  42: Function
  40: ValDef
  40: TypeTree
  -1: EmptyTree
  42: Select
  40: Ident

14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: parse(&quot;
class $read extends Serializable {
  class $iwC extends Serializable {
val $VAL4 = $line3.$read.INSTANCE;
import $VAL4.$iw.$iw.`sc`;
class $iwC extends Serializable {
import org.apache.spark.SparkContext._
class $iwC extends Serializable {
class $iwC extends Serializable {
import com.datastax.bdp.spark.CassandraFunctions._
class $iwC extends Serializable {
import com.datastax.bdp.spark.context.CassandraContext
class $iwC extends Serializable {
import com.tuplejump.calliope.Implicits._
class $iwC extends Serializable {
val $VAL5 = $line17.$read.INSTANCE;
import $VAL5.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.`collection`;
val $VAL6 = $line18.$read.INSTANCE;
import $VAL6.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.`rdd`;
class $iwC extends Serializable {
       val res3 =
              rdd.map(_._2).sum

      

}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;
}
val $iw = new $iwC;

}
object $read {
  val INSTANCE = new $read();
}

&quot;) Some(List(class $read extends Serializable {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;();
    ()
  };
  class $iwC extends Serializable {
    def &amp;lt;init&amp;gt;() = {
      super.&amp;lt;init&amp;gt;();
      ()
    };
    val $VAL4 = $line3.$read.INSTANCE;
    import $VAL4.$iw.$iw.sc;
    class $iwC extends Serializable {
      def &amp;lt;init&amp;gt;() = {
        super.&amp;lt;init&amp;gt;();
        ()
      };
      import org.apache.spark.SparkContext._;
      class $iwC extends Serializable {
        def &amp;lt;init&amp;gt;() = {
          super.&amp;lt;init&amp;gt;();
          ()
        };
        class $iwC extends Serializable {
          def &amp;lt;init&amp;gt;() = {
            super.&amp;lt;init&amp;gt;();
            ()
          };
          import com.datastax.bdp.spark.CassandraFunctions._;
          class $iwC extends Serializable {
            def &amp;lt;init&amp;gt;() = {
              super.&amp;lt;init&amp;gt;();
              ()
            };
            import com.datastax.bdp.spark.context.CassandraContext;
            class $iwC extends Serializable {
              def &amp;lt;init&amp;gt;() = {
                super.&amp;lt;init&amp;gt;();
                ()
              };
              import com.tuplejump.calliope.Implicits._;
              class $iwC extends Serializable {
                def &amp;lt;init&amp;gt;() = {
                  super.&amp;lt;init&amp;gt;();
                  ()
                };
                val $VAL5 = $line17.$read.INSTANCE;
                import $VAL5.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.collection;
                val $VAL6 = $line18.$read.INSTANCE;
                import $VAL6.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.rdd;
                class $iwC extends Serializable {
                  def &amp;lt;init&amp;gt;() = {
                    super.&amp;lt;init&amp;gt;();
                    ()
                  };
                  val res3 = rdd.map(((x$1) =&amp;gt; x$1._2)).sum
                };
                val $iw = new $iwC()
              };
              val $iw = new $iwC()
            };
            val $iw = new $iwC()
          };
          val $iw = new $iwC()
        };
        val $iw = new $iwC()
      };
      val $iw = new $iwC()
    };
    val $iw = new $iwC()
  };
  val $iw = new $iwC()
}, object $read extends scala.AnyRef {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;();
    ()
  };
  val INSTANCE = new $read()
}))
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: class $read extends Serializable {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;;
    ()
  };
  class $iwC extends Serializable {
    def &amp;lt;init&amp;gt;() = {
      super.&amp;lt;init&amp;gt;;
      ()
    };
    val $VAL4 = $line3.$read.INSTANCE;
    import $VAL4.$iw.$iw.sc;
    class $iwC extends Serializable {
      def &amp;lt;init&amp;gt;() = {
        super.&amp;lt;init&amp;gt;;
        ()
      };
      import org.apache.spark.SparkContext._;
      class $iwC extends Serializable {
        def &amp;lt;init&amp;gt;() = {
          super.&amp;lt;init&amp;gt;;
          ()
        };
        class $iwC extends Serializable {
          def &amp;lt;init&amp;gt;() = {
            super.&amp;lt;init&amp;gt;;
            ()
          };
          import com.datastax.bdp.spark.CassandraFunctions._;
          class $iwC extends Serializable {
            def &amp;lt;init&amp;gt;() = {
              super.&amp;lt;init&amp;gt;;
              ()
            };
            import com.datastax.bdp.spark.context.CassandraContext;
            class $iwC extends Serializable {
              def &amp;lt;init&amp;gt;() = {
                super.&amp;lt;init&amp;gt;;
                ()
              };
              import com.tuplejump.calliope.Implicits._;
              class $iwC extends Serializable {
                def &amp;lt;init&amp;gt;() = {
                  super.&amp;lt;init&amp;gt;;
                  ()
                };
                val $VAL5 = $line17.$read.INSTANCE;
                import $VAL5.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.collection;
                val $VAL6 = $line18.$read.INSTANCE;
                import $VAL6.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.rdd;
                class $iwC extends Serializable {
                  def &amp;lt;init&amp;gt;() = {
                    super.&amp;lt;init&amp;gt;;
                    ()
                  };
                  val res3 = rdd.map(((x$1) =&amp;gt; x$1._2)).sum
                };
                val $iw = new $iwC.&amp;lt;init&amp;gt;
              };
              val $iw = new $iwC.&amp;lt;init&amp;gt;
            };
            val $iw = new $iwC.&amp;lt;init&amp;gt;
          };
          val $iw = new $iwC.&amp;lt;init&amp;gt;
        };
        val $iw = new $iwC.&amp;lt;init&amp;gt;
      };
      val $iw = new $iwC.&amp;lt;init&amp;gt;
    };
    val $iw = new $iwC.&amp;lt;init&amp;gt;
  };
  val $iw = new $iwC.&amp;lt;init&amp;gt;
}
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: object $read extends scala.AnyRef {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;;
    ()
  };
  val INSTANCE = new $read.&amp;lt;init&amp;gt;
}
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: Set symbol of res3 to val res3(): Double
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: parse(&quot;
object $eval {
  lazy val $result = $line19.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.`res3`
  val $print: String =  {
    $read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw
    (&quot;&quot;
      
 + &quot;res3: Double = &quot; + scala.runtime.ScalaRunTime.replStringOf($line19.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.`res3`, 1000)

    )
  }
}
      
&quot;) Some(List(object $eval extends scala.AnyRef {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;();
    ()
  };
  lazy val $result = $line19.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.res3;
  val $print: String = {
    $read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw;
    &quot;&quot;.$plus(&quot;res3: Double = &quot;).$plus(scala.runtime.ScalaRunTime.replStringOf($line19.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.res3, 1000))
  }
}))
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: object $eval extends scala.AnyRef {
  def &amp;lt;init&amp;gt;() = {
    super.&amp;lt;init&amp;gt;;
    ()
  };
  lazy val $result = $line19.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.res3;
  val $print: String = {
    $read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw;
    &quot;&quot;.+(&quot;res3: Double = &quot;).+(scala.runtime.ScalaRunTime.replStringOf($line19.$read.INSTANCE.$iw.$iw.$iw.$iw.$iw.$iw.$iw.$iw.res3, 1000))
  }
}
14/05/05 21:23:45 DEBUG SparkILoop$SparkILoopInterpreter: Invoking: public static java.lang.String $line19.$eval.$print()
14/05/05 21:23:46 INFO SharkContext: Starting job: sum at &amp;lt;console&amp;gt;:24
14/05/05 21:23:46 INFO DAGScheduler: Got job 0 (sum at &amp;lt;console&amp;gt;:24) with 2 output partitions (allowLocal=false)
14/05/05 21:23:46 INFO DAGScheduler: Final stage: Stage 0 (sum at &amp;lt;console&amp;gt;:24)
14/05/05 21:23:46 INFO DAGScheduler: Parents of final stage: List()
14/05/05 21:23:46 INFO DAGScheduler: Missing parents: List()
14/05/05 21:23:46 DEBUG DAGScheduler: submitStage(Stage 0)
14/05/05 21:23:46 DEBUG DAGScheduler: missing: List()
14/05/05 21:23:46 INFO DAGScheduler: Submitting Stage 0 (MappedRDD[2] at numericRDDToDoubleRDDFunctions at &amp;lt;console&amp;gt;:24), which has no missing parents
14/05/05 21:23:46 DEBUG DAGScheduler: submitMissingTasks(Stage 0)
14/05/05 21:23:46 INFO DAGScheduler: Submitting 2 missing tasks from Stage 0 (MappedRDD[2] at numericRDDToDoubleRDDFunctions at &amp;lt;console&amp;gt;:24)
14/05/05 21:23:46 DEBUG DAGScheduler: New pending tasks: Set(ResultTask(0, 0), ResultTask(0, 1))
14/05/05 21:23:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
14/05/05 21:23:46 DEBUG TaskSetManager: Epoch for TaskSet 0.0: 0
14/05/05 21:23:46 DEBUG TaskSetManager: Valid locality levels for TaskSet 0.0: ANY
14/05/05 21:23:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 0
14/05/05 21:23:46 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 0
14/05/05 21:23:46 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor 0: 127.0.0.1 (PROCESS_LOCAL)
14/05/05 21:23:47 INFO TaskSetManager: Serialized task 0.0:0 as 13890654 bytes in 617 ms
14/05/05 21:23:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:47 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:48 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:49 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:50 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
14/05/05 21:23:51 DEBUG TaskSchedulerImpl: parentName: , name: TaskSet_0, runningTasks: 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;How to enable logging from Executor? It doesn&apos;t seem to log anything anywhere, but maybe something is misconfigured.&lt;/p&gt;</comment>
                            <comment id="13989882" author="pkolaczk" created="Mon, 5 May 2014 19:36:17 +0000"  >&lt;p&gt;There are some logs from SparkWorker and SparkMaster:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;INFO 21:32:45,654 SparkMaster: 14/05/05 21:32:45 INFO Slf4jLogger: Slf4jLogger started
 INFO 21:32:45,698 SparkMaster: 14/05/05 21:32:45 INFO Remoting: Starting remoting
 INFO 21:32:45,849 SparkMaster: 14/05/05 21:32:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkMaster@127.0.0.1:7077]
 INFO 21:32:46,112 SparkMaster: 14/05/05 21:32:46 INFO Master: Starting Spark master at spark://127.0.0.1:7077
 INFO 21:32:46,136 SparkMaster: 14/05/05 21:32:46 INFO Server: jetty-7.6.8.v20121106
 INFO 21:32:46,142 SparkMaster: 14/05/05 21:32:46 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/metrics/master/json,null}
 INFO 21:32:46,142 SparkMaster: 14/05/05 21:32:46 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/metrics/applications/json,null}
 INFO 21:32:46,143 SparkMaster: 14/05/05 21:32:46 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
 INFO 21:32:46,143 SparkMaster: 14/05/05 21:32:46 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/app/json,null}
 INFO 21:32:46,143 SparkMaster: 14/05/05 21:32:46 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/app,null}
 INFO 21:32:46,143 SparkMaster: 14/05/05 21:32:46 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/json,null}
 INFO 21:32:46,143 SparkMaster: 14/05/05 21:32:46 INFO ContextHandler: started o.e.j.s.h.ContextHandler{*,null}
 INFO 21:32:46,152 SparkMaster: 14/05/05 21:32:46 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:7080
 INFO 21:32:46,153 SparkMaster: 14/05/05 21:32:46 INFO MasterWebUI: Started Master web UI at http://m4600.local:7080
 INFO 21:32:46,169 SparkMaster: 14/05/05 21:32:46 INFO Master: I have been elected leader! New state: ALIVE
 INFO 21:32:46,474 Started SparkWork connected to 127.0.0.1:7077
 INFO 21:32:46,994 SparkWorker: 14/05/05 21:32:46 WARN Utils: Your hostname, m4600 resolves to a loopback address: 127.0.0.2; using 192.168.122.1 instead (on interface virbr0)
 INFO 21:32:46,994 SparkWorker: 14/05/05 21:32:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
 INFO 21:32:47,473 SparkWorker: 14/05/05 21:32:47 INFO Slf4jLogger: Slf4jLogger started
 INFO 21:32:47,519 SparkWorker: 14/05/05 21:32:47 INFO Remoting: Starting remoting
 INFO 21:32:47,661 SparkWorker: 14/05/05 21:32:47 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkWorker@127.0.0.1:45858]
 INFO 21:32:47,827 SparkWorker: 14/05/05 21:32:47 INFO Worker: Starting Spark worker 127.0.0.1:45858 with 8 cores, 4.0 GB RAM
 INFO 21:32:47,828 SparkWorker: 14/05/05 21:32:47 INFO Worker: Spark home: /home/pkolaczk/Projekty/datastax/bdp/resources/spark
 INFO 21:32:47,945 SparkWorker: 14/05/05 21:32:47 INFO Server: jetty-7.6.8.v20121106
 INFO 21:32:47,951 SparkWorker: 14/05/05 21:32:47 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/metrics/json,null}
 INFO 21:32:47,951 SparkWorker: 14/05/05 21:32:47 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/static,null}
 INFO 21:32:47,952 SparkWorker: 14/05/05 21:32:47 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/log,null}
 INFO 21:32:47,952 SparkWorker: 14/05/05 21:32:47 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/logPage,null}
 INFO 21:32:47,952 SparkWorker: 14/05/05 21:32:47 INFO ContextHandler: started o.e.j.s.h.ContextHandler{/json,null}
 INFO 21:32:47,952 SparkWorker: 14/05/05 21:32:47 INFO ContextHandler: started o.e.j.s.h.ContextHandler{*,null}
 INFO 21:32:47,961 SparkWorker: 14/05/05 21:32:47 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0:7081
 INFO 21:32:47,962 SparkWorker: 14/05/05 21:32:47 INFO WorkerWebUI: Started Worker web UI at http://m4600.local:7081
 INFO 21:32:47,963 SparkWorker: 14/05/05 21:32:47 INFO Worker: Connecting to master spark://127.0.0.1:7077...
 INFO 21:32:48,199 SparkMaster: 14/05/05 21:32:48 INFO Master: Registering worker 127.0.0.1:45858 with 8 cores, 4.0 GB RAM
 INFO 21:32:48,225 SparkWorker: 14/05/05 21:32:48 INFO Worker: Successfully registered with master spark://127.0.0.1:7077
 INFO 21:33:00,119 SparkMaster: 14/05/05 21:33:00 INFO Master: Registering app Spark shell
 INFO 21:33:00,124 SparkMaster: 14/05/05 21:33:00 INFO Master: Registered app Spark shell with ID app-20140505213300-0000
 INFO 21:33:00,145 SparkMaster: 14/05/05 21:33:00 INFO Master: Launching executor app-20140505213300-0000/0 on worker worker-20140505213247-127.0.0.1-45858
 INFO 21:33:00,185 SparkWorker: 14/05/05 21:33:00 INFO Worker: Asked to launch executor app-20140505213300-0000/0 for Spark shell
 INFO 21:33:00,812 SparkWorker: 14/05/05 21:33:00 INFO ExecutorRunner: Launch command: &quot;/opt/jdk/bin/java&quot; &quot;-cp&quot; &quot;:/home/pkolaczk/Projekty/datastax/bdp/build/dse-4.5.0-SNAPSHOT.jar:/home/pkolaczk/Projekty/datastax/bdp/build/maven-ant-tasks-2.1.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/cassandra-driver-core-2.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/commons-codec-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/commons-io-2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/guava-15.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/HdrHistogram-1.0.9.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/java-uuid-generator-3.1.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/jbcrypt-0.3m.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/jline-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/jna-3.4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/journalio-1.4.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/log4j-1.2.17.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/metrics-core-3.0.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/netty-3.9.0.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/netty-all-4.0.13.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/slf4j-api-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/slf4j-log4j12-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/tools/lib/stress.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-2.7.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-runtime-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/cassandra-all-2.0.7.31.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/cassandra-clientutil-2.0.7.31.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/cassandra-thrift-2.0.7.31.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-cli-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-codec-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-lang-2.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-lang3-3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-logging-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/compress-lzf-0.8.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/concurrentlinkedhashmap-lru-1.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/disruptor-3.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/elephant-bird-hadoop-compat-4.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/guava-15.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/hibernate-validator-4.3.0.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/high-scale-lib-1.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/httpclient-4.2.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/httpcore-4.2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/jackson-core-asl-1.9.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/jackson-mapper-asl-1.9.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/jamm-0.2.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/jbcrypt-0.3m.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/joda-time-1.6.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/json-simple-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/libthrift-0.9.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/log4j-1.2.16.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/lz4-1.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/metrics-core-2.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/netty-3.6.6.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/reporter-config-2.1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/slf4j-api-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/snakeyaml-1.11.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/snappy-java-1.0.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/snaptree-0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/stringtemplate-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/super-csv-2.1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/thrift-server-0.3.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/validation-api-1.0.0.GA.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/cassandra-driver-core-2.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/cassandra-driver-dse-2.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/metrics-core-3.0.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/netty-3.9.0.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/slf4j-api-1.7.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/slf4j-api-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/slf4j-log4j12-1.7.2.jar:::/home/pkolaczk/Projekty/datastax/bdp/resources/spark/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/activation-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/akka-actor_2.10-2.2.3-shaded-protobuf.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/akka-remote_2.10-2.2.3-shaded-protobuf.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/akka-slf4j_2.10-2.2.3-shaded-protobuf.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/akka-zeromq_2.10-2.2.3-shaded-protobuf.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/algebird-core_2.10-0.1.11.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/asm-4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/asm-commons-4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/asm-tree-4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/avro-1.7.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/avro-ipc-1.7.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/calliope_2.10-0.9.0-EA.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/chill_2.10-0.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/chill-java-0.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/colt-1.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-beanutils-1.7.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-beanutils-core-1.8.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-cli-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-codec-1.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-collections-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-compress-1.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-configuration-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-digester-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-el-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-httpclient-3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-io-2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-lang-2.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-logging-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/compress-lzf-1.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/concurrent-1.3.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/config-1.0.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/core-3.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/fastutil-6.4.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/flume-ng-sdk-1.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/gmetric4j-1.0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/guava-14.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/hadoop-client-1.0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/hbase-0.94.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/high-scale-lib-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/httpclient-4.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/httpcore-4.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-annotations-2.2.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-core-2.2.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-core-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-databind-2.2.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-jaxrs-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-mapper-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-xc-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jamon-runtime-2.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jansi-1.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jasper-compiler-5.5.23.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jasper-runtime-5.5.23.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/JavaEWAH-0.6.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/java-xmlbuilder-0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/javax.servlet-2.5.0.v201103041518.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jaxb-api-2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jaxb-impl-2.2.3-1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jblas-1.2.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jersey-core-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jersey-json-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jersey-server-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jets3t-0.9.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jettison-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-continuation-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-http-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-io-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-server-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-util-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-util-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jline-2.10.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jnr-constants-0.8.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jruby-complete-1.6.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jsp-2.1-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jsp-api-2.1-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jsr305-1.3.9.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jul-to-slf4j-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/kafka_2.10-0.8.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/kryo-2.21.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/libthrift-0.7.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/lift-json_2.10-2.5.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/mesos-0.13.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-annotation-2.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-core-2.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-core-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-ganglia-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-graphite-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-json-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-jvm-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/minlog-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/mqtt-client-0.4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/netty-3.5.9.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/netty-all-4.0.13.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/objenesis-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/oncrpc-1.0.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/paranamer-2.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/protobuf-java-2.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/protobuf-java-2.4.1-shaded.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/reflectasm-1.07-shaded.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/scala-compiler-2.10.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/scala-library-2.10.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/scala-reflect-2.10.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/servlet-api-2.5-20081211.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/servlet-api-2.5-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-bagel_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-core_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-examples_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-mllib_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-repl_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-flume_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-kafka_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-mqtt_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-twitter_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-zeromq_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/stax-api-1.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/stream-2.4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/twitter4j-core-3.0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/twitter4j-stream-3.0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/uncommons-maths-1.2.2a.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/velocity-1.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/xz-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/zeromq-scala-binding_2.10-0.0.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/zkclient-0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/zookeeper-3.4.5.jar:/home/pkolaczk/.spark/cassandra-context/spark-cassandra-context.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/conf::/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/commons-codec-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/commons-httpclient-3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/commons-io-2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/commons-logging-1.1.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/guava-14.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/hadoop-client-1.0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/httpclient-4.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/httpcore-4.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/javax.servlet-2.5.0.v201103041518.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/jets3t-0.7.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/shark_2.10-0.9.0.1-DSP-3062-SNAPSHOT.jar::/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/elephant-bird-hadoop-compat-4.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-core-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-examples-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-fairscheduler-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-streaming-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-test-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-tools-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/ant-1.6.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/automaton-1.11-8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-beanutils-1.7.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-beanutils-core-1.8.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-cli-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-codec-1.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-collections-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-configuration-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-digester-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-el-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-httpclient-3.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-lang-2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-logging-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-math-2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-net-1.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/core-3.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/ftplet-api-1.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/ftpserver-core-1.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/ftpserver-deprecated-1.0.0-M2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/hsqldb-1.8.0.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/httpclient-4.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/httpcore-4.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jackson-core-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jasper-compiler-5.5.12.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jasper-runtime-5.5.12.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/java-xmlbuilder-0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jets3t-0.9.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jetty-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jetty-util-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jsp-2.1-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jsp-api-2.1-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/kfs-0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/mina-core-2.0.0-M5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/oro-2.0.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/servlet-api-2.5-20081211.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/servlet-api-2.5-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/snappy-java-1.0.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/xmlenc-0.52.jar::/home/pkolaczk/Projekty/datastax/bdp/build/dse-4.5.0-SNAPSHOT.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-runtime-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/conf::/home/pkolaczk/Projekty/datastax/bdp/build/dse-4.5.0-SNAPSHOT.jar:/home/pkolaczk/Projekty/datastax/bdp/build/dse-4.5.0-SNAPSHOT.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-runtime-3.2.jar::/home/pkolaczk/Projekty/datastax/bdp/resources/hive/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/antlr-2.7.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/antlr-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/antlr-runtime-3.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/asm-4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/avro-1.7.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/avro-ipc-1.7.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/avro-mapred-1.7.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/bonecp-0.7.1.RELEASE.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-beanutils-1.7.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-beanutils-core-1.8.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-cli-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-codec-1.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-collections-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-compress-1.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-configuration-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-digester-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-io-2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-lang-2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-lang3-3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-logging-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-logging-api-1.0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-pool-1.5.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/datanucleus-api-jdo-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/datanucleus-core-3.2.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/datanucleus-rdbms-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/derby-10.4.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/guava-15.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-cli-0.12.0.3-20140319.091653-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-common-0.12.0.3-20140319.091659-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-exec-0.12.0.3-20140319.091716-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-hwi-0.12.0.3-20140319.091745-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-jdbc-0.12.0.3-20140319.091754-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-metastore-0.12.0.3-20140319.091801-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-serde-0.12.0.3-20140319.091811-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-service-0.12.0.3-20140319.091817-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-shims-0.12.0.3-20140319.091825-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/httpclient-4.2.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/httpcore-4.2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jackson-core-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jackson-mapper-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/JavaEWAH-0.3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/java-xmlbuilder-0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/javolution-5.5.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jdo-api-3.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jets3t-0.9.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jetty-util-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/json-20090211.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jta-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/libfb303-0.9.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/libthrift-0.9.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/log4j-1.2.16.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/netty-3.5.9.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/paranamer-2.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/protobuf-java-2.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/servlet-api-2.5-20081211.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/slf4j-api-1.6.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/snappy-0.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/snappy-java-1.0.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/ST4-4.0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/stringtemplate-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/velocity-1.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/xz-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/zookeeper-3.4.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/conf&quot; &quot;-XX:MaxPermSize=256M&quot; &quot;-XX:MaxPermSize=256M&quot; &quot;-Xms2048M&quot; &quot;-Xmx2048M&quot; &quot;org.apache.spark.executor.CoarseGrainedExecutorBackend&quot; &quot;akka.tcp://spark@m4600.local:45753/user/CoarseGrainedScheduler&quot; &quot;0&quot; &quot;127.0.0.1&quot; &quot;1&quot; &quot;akka.tcp://sparkWorker@127.0.0.1:45858/user/Worker&quot; &quot;app-20140505213300-0000&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13990200" author="gq" created="Tue, 6 May 2014 02:02:53 +0000"  >&lt;p&gt;Add conf/log4j.properties file&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;# Set everything to be logged to the console
#log4j.rootCategory=INFO,console
log4j.rootCategory=INFO,file
#log4j.rootCategory=DEBUG,file
#- size rotation with log cleanup.
log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.MaxFileSize=100MB
log4j.appender.file.MaxBackupIndex=10

#- File to log to and log format
log4j.appender.file.File=/opt/spark_local/logs/spark.log
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

log4j.logger.DataNucleus=DEBUG
# Ignore messages below warning level from Jetty, because it&apos;s a bit verbose
log4j.logger.org.eclipse.jetty=WARN
#log4j.logger.org.eclipse.jetty=DEBUG
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;log4j.appender.file.File=/opt/spark_local/logs/spark.log&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; change the directory to fit here&lt;/p&gt;</comment>
                            <comment id="13990206" author="gq" created="Tue, 6 May 2014 02:13:00 +0000"  >&lt;p&gt;What is the value of &lt;tt&gt;spark.akka.frameSize&lt;/tt&gt;? you can find it  in &lt;tt&gt;&lt;a href=&quot;http://host:4040/environment/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://host:4040/environment/&lt;/a&gt;&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="13990369" author="pkolaczk" created="Tue, 6 May 2014 07:06:25 +0000"  >&lt;p&gt;Hmm, it is not listed in the environment at all. What value does it need to have?&lt;br/&gt;
Should I expect parallelized collection partitions larger than akka.frame.size to cause problems?&lt;/p&gt;</comment>
                            <comment id="13990373" author="gq" created="Tue, 6 May 2014 07:15:07 +0000"  >&lt;p&gt;May be caused by the imprope &lt;tt&gt;spark.akka.frameSize&lt;/tt&gt; value&lt;br/&gt;
the value can be changed little, try &lt;tt&gt;5&lt;/tt&gt; .&lt;/p&gt;</comment>
                            <comment id="13990383" author="pkolaczk" created="Tue, 6 May 2014 07:29:36 +0000"  >&lt;p&gt;Setting &lt;tt&gt;spark.akka.frameSize&lt;/tt&gt; to &lt;tt&gt;20&lt;/tt&gt; helped. &lt;tt&gt;5&lt;/tt&gt; or &lt;tt&gt;10&lt;/tt&gt; wasn&apos;t enough.&lt;/p&gt;</comment>
                            <comment id="13990388" author="gq" created="Tue, 6 May 2014 07:42:55 +0000"  >&lt;p&gt;According to my not comprehensive test. 20 is too big.&lt;br/&gt;
A real example when 25889467 bytes serialized result be sent directly to driver &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L248&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Executor.scala#L248&lt;/a&gt; will cause a problem&lt;/p&gt;</comment>
                            <comment id="13990390" author="gq" created="Tue, 6 May 2014 07:45:25 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pwendell&quot; class=&quot;user-hover&quot; rel=&quot;pwendell&quot;&gt;pwendell&lt;/a&gt;  &lt;br/&gt;
What are your thoughts on this issue?&lt;/p&gt;</comment>
                            <comment id="13990417" author="pkolaczk" created="Tue, 6 May 2014 08:20:43 +0000"  >&lt;p&gt;I modified log4j config and this is what I got in the spark.log:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;14/05/06 10:17:29 INFO HttpServer: Starting HTTP Server
14/05/06 10:17:33 WARN Utils: Your hostname, m4600 resolves to a loopback address: 127.0.0.2; using 192.168.122.1 instead (on interface virbr0)
14/05/06 10:17:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/06 10:17:34 INFO Slf4jLogger: Slf4jLogger started
14/05/06 10:17:34 INFO Remoting: Starting remoting
14/05/06 10:17:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@m4600.local:33012]
14/05/06 10:17:34 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@m4600.local:33012]
14/05/06 10:17:34 INFO SparkEnv: Registering BlockManagerMaster
14/05/06 10:17:34 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140506101734-42f3
14/05/06 10:17:34 INFO MemoryStore: MemoryStore started with capacity 1178.1 MB.
14/05/06 10:17:34 INFO ConnectionManager: Bound socket to port 60842 with id = ConnectionManagerId(m4600.local,60842)
14/05/06 10:17:34 INFO BlockManagerMaster: Trying to register BlockManager
14/05/06 10:17:34 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager m4600.local:60842 with 1178.1 MB RAM
14/05/06 10:17:34 INFO BlockManagerMaster: Registered BlockManager
14/05/06 10:17:34 INFO HttpServer: Starting HTTP Server
14/05/06 10:17:34 INFO HttpBroadcast: Broadcast server started at http://192.168.122.1:51030
14/05/06 10:17:35 INFO SparkEnv: Registering MapOutputTracker
14/05/06 10:17:35 INFO HttpFileServer: HTTP File server directory is /tmp/spark-5013023c-f851-4398-a344-5493e62edd26
14/05/06 10:17:35 INFO HttpServer: Starting HTTP Server
14/05/06 10:17:35 INFO SparkUI: Started Spark Web UI at http://m4600.local:4040
14/05/06 10:17:35 INFO SharkContext: Added JAR /home/pkolaczk/.spark/cassandra-context/spark-cassandra-context.jar at http://192.168.122.1:49386/jars/spark-cassandra-context.jar with timestamp 1399364255576
14/05/06 10:17:35 INFO AppClient$ClientActor: Connecting to master spark://127.0.0.1:7077...
14/05/06 10:17:35 INFO Master: Registering app Spark shell
14/05/06 10:17:35 INFO Master: Registered app Spark shell with ID app-20140506101735-0001
14/05/06 10:17:35 INFO Master: Launching executor app-20140506101735-0001/0 on worker worker-20140506101633-127.0.0.1-44566
14/05/06 10:17:35 INFO Worker: Asked to launch executor app-20140506101735-0001/0 for Spark shell
14/05/06 10:17:35 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20140506101735-0001
14/05/06 10:17:35 INFO AppClient$ClientActor: Executor added: app-20140506101735-0001/0 on worker-20140506101633-127.0.0.1-44566 (127.0.0.1:44566) with 1 cores
14/05/06 10:17:35 INFO SparkDeploySchedulerBackend: Granted executor ID app-20140506101735-0001/0 on hostPort 127.0.0.1:44566 with 1 cores, 2.0 GB RAM
14/05/06 10:17:35 INFO AppClient$ClientActor: Executor updated: app-20140506101735-0001/0 is now RUNNING
14/05/06 10:17:36 INFO ExecutorRunner: Launch command: &quot;/opt/jdk/bin/java&quot; &quot;-cp&quot; &quot;:/home/pkolaczk/Projekty/datastax/bdp/build/dse-4.5.0-SNAPSHOT.jar:/home/pkolaczk/Projekty/datastax/bdp/build/maven-ant-tasks-2.1.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/cassandra-driver-core-2.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/commons-codec-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/commons-io-2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/guava-15.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/HdrHistogram-1.0.9.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/java-uuid-generator-3.1.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/jbcrypt-0.3m.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/jline-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/jna-3.4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/journalio-1.4.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/log4j-1.2.17.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/metrics-core-3.0.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/netty-3.9.0.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/netty-all-4.0.13.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/slf4j-api-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/slf4j-log4j12-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/tools/lib/stress.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-2.7.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-runtime-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/cassandra-all-2.0.7.31.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/cassandra-clientutil-2.0.7.31.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/cassandra-thrift-2.0.7.31.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-cli-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-codec-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-lang-2.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-lang3-3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/commons-logging-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/compress-lzf-0.8.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/concurrentlinkedhashmap-lru-1.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/disruptor-3.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/elephant-bird-hadoop-compat-4.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/guava-15.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/hibernate-validator-4.3.0.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/high-scale-lib-1.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/httpclient-4.2.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/httpcore-4.2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/jackson-core-asl-1.9.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/jackson-mapper-asl-1.9.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/jamm-0.2.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/jbcrypt-0.3m.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/joda-time-1.6.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/json-simple-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/libthrift-0.9.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/log4j-1.2.16.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/lz4-1.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/metrics-core-2.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/netty-3.6.6.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/reporter-config-2.1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/slf4j-api-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/snakeyaml-1.11.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/snappy-java-1.0.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/snaptree-0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/stringtemplate-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/super-csv-2.1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/thrift-server-0.3.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/validation-api-1.0.0.GA.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/cassandra-driver-core-2.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/cassandra-driver-dse-2.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/metrics-core-3.0.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/netty-3.9.0.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/../driver/lib/slf4j-api-1.7.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/slf4j-api-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/dse/lib/slf4j-log4j12-1.7.2.jar:::/home/pkolaczk/Projekty/datastax/bdp/resources/spark/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/activation-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/akka-actor_2.10-2.2.3-shaded-protobuf.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/akka-remote_2.10-2.2.3-shaded-protobuf.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/akka-slf4j_2.10-2.2.3-shaded-protobuf.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/akka-zeromq_2.10-2.2.3-shaded-protobuf.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/algebird-core_2.10-0.1.11.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/asm-4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/asm-commons-4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/asm-tree-4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/avro-1.7.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/avro-ipc-1.7.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/calliope_2.10-0.9.0-EA.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/chill_2.10-0.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/chill-java-0.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/colt-1.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-beanutils-1.7.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-beanutils-core-1.8.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-cli-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-codec-1.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-collections-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-compress-1.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-configuration-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-digester-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-el-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-httpclient-3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-io-2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-lang-2.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/commons-logging-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/compress-lzf-1.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/concurrent-1.3.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/config-1.0.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/core-3.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/fastutil-6.4.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/flume-ng-sdk-1.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/gmetric4j-1.0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/guava-14.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/hadoop-client-1.0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/hbase-0.94.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/high-scale-lib-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/httpclient-4.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/httpcore-4.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-annotations-2.2.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-core-2.2.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-core-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-databind-2.2.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-jaxrs-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-mapper-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jackson-xc-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jamon-runtime-2.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jansi-1.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jasper-compiler-5.5.23.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jasper-runtime-5.5.23.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/JavaEWAH-0.6.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/java-xmlbuilder-0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/javax.servlet-2.5.0.v201103041518.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jaxb-api-2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jaxb-impl-2.2.3-1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jblas-1.2.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jersey-core-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jersey-json-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jersey-server-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jets3t-0.9.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jettison-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-continuation-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-http-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-io-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-server-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-util-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jetty-util-7.6.8.v20121106.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jline-2.10.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jnr-constants-0.8.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jruby-complete-1.6.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jsp-2.1-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jsp-api-2.1-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jsr305-1.3.9.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/jul-to-slf4j-1.7.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/kafka_2.10-0.8.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/kryo-2.21.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/libthrift-0.7.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/lift-json_2.10-2.5.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/mesos-0.13.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-annotation-2.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-core-2.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-core-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-ganglia-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-graphite-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-json-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/metrics-jvm-3.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/minlog-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/mqtt-client-0.4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/netty-3.5.9.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/netty-all-4.0.13.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/objenesis-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/oncrpc-1.0.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/paranamer-2.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/protobuf-java-2.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/protobuf-java-2.4.1-shaded.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/reflectasm-1.07-shaded.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/scala-compiler-2.10.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/scala-library-2.10.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/scala-reflect-2.10.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/servlet-api-2.5-20081211.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/servlet-api-2.5-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-bagel_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-core_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-examples_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-mllib_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-repl_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-flume_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-kafka_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-mqtt_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-twitter_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/spark-streaming-zeromq_2.10-0.9.0-incubating.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/stax-api-1.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/stream-2.4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/twitter4j-core-3.0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/twitter4j-stream-3.0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/uncommons-maths-1.2.2a.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/velocity-1.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/xz-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/zeromq-scala-binding_2.10-0.0.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/zkclient-0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/lib/zookeeper-3.4.5.jar:/home/pkolaczk/.spark/cassandra-context/spark-cassandra-context.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/spark/conf::/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/commons-codec-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/commons-httpclient-3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/commons-io-2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/commons-logging-1.1.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/guava-14.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/hadoop-client-1.0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/httpclient-4.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/httpcore-4.3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/javax.servlet-2.5.0.v201103041518.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/jets3t-0.7.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/shark/lib/shark_2.10-0.9.0.1-DSP-3062-SNAPSHOT.jar::/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/elephant-bird-hadoop-compat-4.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-core-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-examples-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-fairscheduler-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-streaming-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-test-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/hadoop-tools-1.0.4.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/ant-1.6.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/automaton-1.11-8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-beanutils-1.7.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-beanutils-core-1.8.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-cli-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-codec-1.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-collections-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-configuration-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-digester-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-el-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-httpclient-3.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-lang-2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-logging-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-math-2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/commons-net-1.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/core-3.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/ftplet-api-1.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/ftpserver-core-1.0.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/ftpserver-deprecated-1.0.0-M2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/hsqldb-1.8.0.10.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/httpclient-4.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/httpcore-4.1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jackson-core-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jasper-compiler-5.5.12.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jasper-runtime-5.5.12.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/java-xmlbuilder-0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jets3t-0.9.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jetty-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jetty-util-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jsp-2.1-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/jsp-api-2.1-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/kfs-0.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/mina-core-2.0.0-M5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/oro-2.0.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/servlet-api-2.5-20081211.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/servlet-api-2.5-6.1.14.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/snappy-java-1.0.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/lib/xmlenc-0.52.jar::/home/pkolaczk/Projekty/datastax/bdp/build/dse-4.5.0-SNAPSHOT.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-runtime-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/conf::/home/pkolaczk/Projekty/datastax/bdp/build/dse-4.5.0-SNAPSHOT.jar:/home/pkolaczk/Projekty/datastax/bdp/build/dse-4.5.0-SNAPSHOT.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/cassandra/lib/antlr-runtime-3.2.jar::/home/pkolaczk/Projekty/datastax/bdp/resources/hive/conf:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/antlr-2.7.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/antlr-3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/antlr-runtime-3.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/asm-4.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/avro-1.7.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/avro-ipc-1.7.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/avro-mapred-1.7.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/bonecp-0.7.1.RELEASE.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-beanutils-1.7.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-beanutils-core-1.8.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-cli-1.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-codec-1.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-collections-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-compress-1.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-configuration-1.6.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-digester-1.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-io-2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-lang-2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-lang3-3.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-logging-1.1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-logging-api-1.0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/commons-pool-1.5.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/datanucleus-api-jdo-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/datanucleus-core-3.2.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/datanucleus-rdbms-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/derby-10.4.2.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/guava-15.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-cli-0.12.0.3-20140319.091653-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-common-0.12.0.3-20140319.091659-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-exec-0.12.0.3-20140319.091716-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-hwi-0.12.0.3-20140319.091745-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-jdbc-0.12.0.3-20140319.091754-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-metastore-0.12.0.3-20140319.091801-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-serde-0.12.0.3-20140319.091811-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-service-0.12.0.3-20140319.091817-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/hive-shims-0.12.0.3-20140319.091825-2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/httpclient-4.2.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/httpcore-4.2.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jackson-core-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jackson-mapper-asl-1.8.8.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/JavaEWAH-0.3.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/java-xmlbuilder-0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/javolution-5.5.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jdo-api-3.0.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jets3t-0.9.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jetty-util-6.1.26.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/json-20090211.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/jta-1.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/libfb303-0.9.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/libthrift-0.9.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/log4j-1.2.16.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/netty-3.5.9.Final.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/paranamer-2.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/protobuf-java-2.4.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/servlet-api-2.5-20081211.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/slf4j-api-1.6.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/snappy-0.2.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/snappy-java-1.0.5.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/ST4-4.0.4.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/stringtemplate-3.2.1.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/velocity-1.7.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/xz-1.0.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/lib/zookeeper-3.4.3.jar:/home/pkolaczk/Projekty/datastax/bdp/resources/hive/conf&quot; &quot;-Djava.library.path=:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/native/Linux-amd64-64/lib&quot; &quot;-Djava.system.class.loader=com.datastax.bdp.loader.DseClientClassLoader&quot; &quot;-XX:MaxPermSize=256M&quot; &quot;-Djava.library.path=:/home/pkolaczk/Projekty/datastax/bdp/resources/hadoop/native/Linux-amd64-64/lib&quot; &quot;-Djava.system.class.loader=com.datastax.bdp.loader.DseClientClassLoader&quot; &quot;-XX:MaxPermSize=256M&quot; &quot;-Xms2048M&quot; &quot;-Xmx2048M&quot; &quot;org.apache.spark.executor.CoarseGrainedExecutorBackend&quot; &quot;akka.tcp://spark@m4600.local:33012/user/CoarseGrainedScheduler&quot; &quot;0&quot; &quot;127.0.0.1&quot; &quot;1&quot; &quot;akka.tcp://sparkWorker@127.0.0.1:44566/user/Worker&quot; &quot;app-20140506101735-0001&quot;
14/05/06 10:17:37 INFO Slf4jLogger: Slf4jLogger started
14/05/06 10:17:37 INFO Remoting: Starting remoting
14/05/06 10:17:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkExecutor@127.0.0.1:39919]
14/05/06 10:17:38 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkExecutor@127.0.0.1:39919]
14/05/06 10:17:38 INFO CoarseGrainedExecutorBackend: Connecting to driver: akka.tcp://spark@m4600.local:33012/user/CoarseGrainedScheduler
14/05/06 10:17:38 INFO WorkerWatcher: Connecting to worker akka.tcp://sparkWorker@127.0.0.1:44566/user/Worker
14/05/06 10:17:38 INFO WorkerWatcher: Successfully connected to akka.tcp://sparkWorker@127.0.0.1:44566/user/Worker
14/05/06 10:17:38 INFO SparkDeploySchedulerBackend: Registered executor: Actor[akka.tcp://sparkExecutor@127.0.0.1:39919/user/Executor#-1863004534] with ID 0
14/05/06 10:17:38 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
14/05/06 10:17:38 INFO Executor: Using REPL class URI: http://192.168.122.1:58332
14/05/06 10:17:38 INFO Slf4jLogger: Slf4jLogger started
14/05/06 10:17:38 INFO Remoting: Starting remoting
14/05/06 10:17:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://spark@127.0.0.1:49111]
14/05/06 10:17:38 INFO Remoting: Remoting now listens on addresses: [akka.tcp://spark@127.0.0.1:49111]
14/05/06 10:17:38 INFO SparkEnv: Connecting to BlockManagerMaster: akka.tcp://spark@m4600.local:33012/user/BlockManagerMaster
14/05/06 10:17:38 INFO DiskBlockManager: Created local directory at /tmp/spark-local-20140506101738-4884
14/05/06 10:17:38 INFO MemoryStore: MemoryStore started with capacity 1178.1 MB.
14/05/06 10:17:38 INFO ConnectionManager: Bound socket to port 32898 with id = ConnectionManagerId(127.0.0.1,32898)
14/05/06 10:17:38 INFO BlockManagerMaster: Trying to register BlockManager
14/05/06 10:17:38 INFO BlockManagerMasterActor$BlockManagerInfo: Registering block manager 127.0.0.1:32898 with 1178.1 MB RAM
14/05/06 10:17:38 INFO BlockManagerMaster: Registered BlockManager
14/05/06 10:17:38 INFO SparkEnv: Connecting to MapOutputTracker: akka.tcp://spark@m4600.local:33012/user/MapOutputTracker
14/05/06 10:17:38 INFO HttpFileServer: HTTP File server directory is /tmp/spark-ed849647-1ea9-4446-9798-326ddf33c8da
14/05/06 10:17:38 INFO HttpServer: Starting HTTP Server
14/05/06 10:17:38 WARN Utils: Your hostname, m4600 resolves to a loopback address: 127.0.0.2; using 192.168.122.1 instead (on interface virbr0)
14/05/06 10:17:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
14/05/06 10:17:57 INFO SharkContext: Starting job: sum at &amp;lt;console&amp;gt;:24
14/05/06 10:17:57 INFO DAGScheduler: Got job 0 (sum at &amp;lt;console&amp;gt;:24) with 2 output partitions (allowLocal=false)
14/05/06 10:17:57 INFO DAGScheduler: Final stage: Stage 0 (sum at &amp;lt;console&amp;gt;:24)
14/05/06 10:17:57 INFO DAGScheduler: Parents of final stage: List()
14/05/06 10:17:57 INFO DAGScheduler: Missing parents: List()
14/05/06 10:17:57 INFO DAGScheduler: Submitting Stage 0 (MappedRDD[2] at numericRDDToDoubleRDDFunctions at &amp;lt;console&amp;gt;:24), which has no missing parents
14/05/06 10:17:58 INFO DAGScheduler: Submitting 2 missing tasks from Stage 0 (MappedRDD[2] at numericRDDToDoubleRDDFunctions at &amp;lt;console&amp;gt;:24)
14/05/06 10:17:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
14/05/06 10:17:58 INFO TaskSetManager: Starting task 0.0:0 as TID 0 on executor 0: 127.0.0.1 (PROCESS_LOCAL)
14/05/06 10:17:59 INFO TaskSetManager: Serialized task 0.0:0 as 13890653 bytes in 615 ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13990420" author="gq" created="Tue, 6 May 2014 08:26:46 +0000"  >&lt;p&gt;This is just a part of it,  the whole file upload?&lt;/p&gt;</comment>
                            <comment id="13990460" author="pkolaczk" created="Tue, 6 May 2014 09:20:36 +0000"  >&lt;p&gt;The whole part from before the moment I started the job.&lt;br/&gt;
It ends with &lt;tt&gt;14/05/06 10:17:59 INFO TaskSetManager: Serialized task 0.0:0 as 13890653 bytes in 615 ms&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="13990527" author="gq" created="Tue, 6 May 2014 10:48:22 +0000"  >&lt;p&gt;&lt;tt&gt;TaskDescription&lt;/tt&gt; instance is too big causes the issue. &lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/scheduler/cluster/CoarseGrainedSchedulerBackend.scala#L144&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;CoarseGrainedSchedulerBackend.scala#L144&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pwendell&quot; class=&quot;user-hover&quot; rel=&quot;pwendell&quot;&gt;pwendell&lt;/a&gt; This is a very serious bug&lt;/p&gt;</comment>
                            <comment id="13990711" author="pkolaczk" created="Tue, 6 May 2014 14:58:17 +0000"  >&lt;p&gt;Do you need more info / help reproducing this?&lt;br/&gt;
I&apos;m worried mostly not by the fact that it failed but because of the manifestation of the bug (no errors anywhere). &lt;br/&gt;
Is it possible we misconfigured something related to logging or setup?&lt;/p&gt;</comment>
                            <comment id="13990769" author="gq" created="Tue, 6 May 2014 15:49:15 +0000"  >&lt;p&gt;Thank you, temporarily need not, I roughly to locate.I&apos;m debugging&lt;/p&gt;</comment>
                            <comment id="13990960" author="pwendell" created="Tue, 6 May 2014 18:34:08 +0000"  >&lt;p&gt;We should probably add a check that the task is smaller than the akka frame size and throw an error message. Unfortunately akka fails silently here. See a similar check in the MapOutputTracker:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/MapOutputTracker.scala#L48&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/MapOutputTracker.scala#L48&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13991556" author="gq" created="Wed, 7 May 2014 05:25:21 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/694&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;The PR 694&lt;/a&gt;,but I think this solution imperfect.&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/executor/Executor.scala#L235&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Executor.scala#L235&lt;/a&gt; is a good solution.&lt;/p&gt;</comment>
                            <comment id="14011830" author="matei" created="Wed, 28 May 2014 23:42:32 +0000"  >&lt;p&gt;Merged the frame size check into 0.9.2 as well as 1.0.1&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12721507">SPARK-2156</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12643290" name="executor.jstack.txt" size="51063" author="pkolaczk" created="Sun, 4 May 2014 19:15:25 +0000"/>
                            <attachment id="12643288" name="master.jstack.txt" size="29484" author="pkolaczk" created="Sun, 4 May 2014 19:15:25 +0000"/>
                            <attachment id="12643289" name="repl.jstack.txt" size="96381" author="pkolaczk" created="Sun, 4 May 2014 19:15:25 +0000"/>
                            <attachment id="12643286" name="spark-hang.png" size="136236" author="pkolaczk" created="Sun, 4 May 2014 19:15:25 +0000"/>
                            <attachment id="12643287" name="worker.jstack.txt" size="33372" author="pkolaczk" created="Sun, 4 May 2014 19:15:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>390524</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 25 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1v9mv:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>390777</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>