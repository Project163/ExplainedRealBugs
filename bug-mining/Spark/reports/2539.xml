<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:33:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-10914] UnsafeRow serialization breaks when two machines have different Oops size</title>
                <link>https://issues.apache.org/jira/browse/SPARK-10914</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;&lt;b&gt;Updated description (by rxin on Oct 8, 2015)&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;To reproduce, launch Spark using&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;MASTER=local-cluster[2,1,1024] bin/spark-shell --conf &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.executor.extraJavaOptions=-XX:-UseCompressedOops&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then run the following&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 xx&quot;&lt;/span&gt;).collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The problem is that UnsafeRow contains 3 pieces of information when pointing to some data in memory (an object, a base offset, and length). When the row is serialized with Java/Kryo serialization, the object layout in memory can change if two machines have different pointer width (Oops in JVM).&lt;/p&gt;



&lt;p&gt;&lt;b&gt;Original bug report description&lt;/b&gt;:&lt;/p&gt;

&lt;p&gt;Using an inner join, to match together two integer columns, I generally get no results when there should be matches.  But the results vary and depend on whether the dataframes are coming from SQL, JSON, or cached, as well as the order in which I cache things and query them.&lt;/p&gt;

&lt;p&gt;This minimal example reproduces it consistently for me in the spark-shell, on new installs of both 1.5.0 and 1.5.1 (pre-built against Hadoop 2.6 from &lt;a href=&quot;http://spark.apache.org/downloads.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://spark.apache.org/downloads.html&lt;/a&gt;.)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-comment&quot;&gt;/* x is {&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt;:1}{&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt;:2} and y is just {&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;:1}{&quot;yy:2} */&lt;/span&gt;
val x = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 xx union all select 2&quot;&lt;/span&gt;) 
val y = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 yy union all select 2&quot;&lt;/span&gt;)

x.join(y, $&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt; === $&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;).count() &lt;span class=&quot;code-comment&quot;&gt;/* expect 2, get 0 */&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;/* If I cache both tables it works: */&lt;/span&gt;
x.cache()
y.cache()
x.join(y, $&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt; === $&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;).count() &lt;span class=&quot;code-comment&quot;&gt;/* expect 2, get 2 */&lt;/span&gt;

&lt;span class=&quot;code-comment&quot;&gt;/* but &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; still doesn&apos;t work: */&lt;/span&gt;
x.join(y, $&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt; === $&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;).filter(&lt;span class=&quot;code-quote&quot;&gt;&quot;yy=1&quot;&lt;/span&gt;).count() &lt;span class=&quot;code-comment&quot;&gt;/* expect 1, get 0 */&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>&lt;p&gt;Ubuntu 14.04 (spark-slave), 12.04 (master)&lt;/p&gt;</environment>
        <key id="12902169">SPARK-10914</key>
            <summary>UnsafeRow serialization breaks when two machines have different Oops size</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rxin">Reynold Xin</assignee>
                                    <reporter username="benm">Ben Moran</reporter>
                        <labels>
                            <label>correctness</label>
                    </labels>
                <created>Fri, 2 Oct 2015 17:49:08 +0000</created>
                <updated>Tue, 16 Jul 2019 22:51:55 +0000</updated>
                            <resolved>Fri, 9 Oct 2015 00:25:41 +0000</resolved>
                                    <version>1.5.0</version>
                    <version>1.5.1</version>
                                    <fixVersion>1.5.2</fixVersion>
                    <fixVersion>1.6.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14943855" author="cloud_fan" created="Mon, 5 Oct 2015 19:10:31 +0000"  >&lt;p&gt;hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benm&quot; class=&quot;user-hover&quot; rel=&quot;benm&quot;&gt;benm&lt;/a&gt;, I can&apos;t reproduce this bug on spark 1.5.1(downloaded binary version) on my mac locally, can you provide more details(local or cluster? jvm options?)? you can use `df.explain(true)` to print the plan tree so that we can see what&apos;s going on there.&lt;/p&gt;</comment>
                            <comment id="14945358" author="benm" created="Tue, 6 Oct 2015 17:03:00 +0000"  >&lt;p&gt;Thanks for looking into it.  I have narrowed it down a lot now.  It depends on the --executor-memory setting!&lt;/p&gt;

&lt;p&gt;For me using &quot;bin/spark-shell&quot; locally I don&apos;t see the problem, but I do see it when I use a standalone cluster. It reliably reproduces whenever I specify &quot;--executor-memory 32g&quot; or greater, but if I leave executor-memory unset or specify a value of 31g or less I get the correct result.&lt;/p&gt;

&lt;p&gt;Here&apos;s a correct run:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;spark@spark-master:~/spark-1.5.1-bin-hadoop2.6$ bin/spark-shell --master spark:&lt;span class=&quot;code-comment&quot;&gt;//spark-master:7077   --executor-memory 31g 
&lt;/span&gt;
scala&amp;gt; val x = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 xx union all select 2&quot;&lt;/span&gt;)
x: org.apache.spark.sql.DataFrame = [xx: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; val y = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 yy union all select 2&quot;&lt;/span&gt;)
y: org.apache.spark.sql.DataFrame = [yy: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; x.join(y, $&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt; === $&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;).count() &lt;span class=&quot;code-comment&quot;&gt;/* expect 2, get 2 */&lt;/span&gt;
res0: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = 2                     
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here&apos;s an incorrect run, with an explain plan (the explain is the same in any case):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;spark@spark-master:~/spark-1.5.1-bin-hadoop2.6$ bin/spark-shell --master spark:&lt;span class=&quot;code-comment&quot;&gt;//spark-master:7077   --executor-memory 32g
&lt;/span&gt;
scala&amp;gt; val x = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 xx union all select 2&quot;&lt;/span&gt;)
x: org.apache.spark.sql.DataFrame = [xx: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; val y = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 yy union all select 2&quot;&lt;/span&gt;)
y: org.apache.spark.sql.DataFrame = [yy: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; x.join(y, $&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt; === $&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;).explain()
== Physical Plan ==
BroadcastHashJoin [xx#0], [yy#2], BuildRight
 Union
  TungstenProject [1 AS xx#0]
   Scan OneRowRelation[]
  TungstenProject [2 AS _c0#1]
   Scan OneRowRelation[]
 Union
  TungstenProject [1 AS yy#2]
   Scan OneRowRelation[]
  TungstenProject [2 AS _c0#3]
   Scan OneRowRelation[]

scala&amp;gt; x.join(y, $&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt; === $&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;).count() &lt;span class=&quot;code-comment&quot;&gt;/* expect 2, get 0 */&lt;/span&gt;
res1: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = 0               
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I have two machines in my cluster:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;one is Ubuntu 12.04, running the spark-master node&lt;/li&gt;
	&lt;li&gt;one is Ubuntu 14.04, running the spark-slave node.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Both have 256Gb RAM.&lt;/p&gt;

&lt;p&gt;JVM on both machines is: oracle-java7-installer from PPA:&lt;br/&gt;
Using Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_80)&lt;/p&gt;
</comment>
                            <comment id="14945417" author="srowen" created="Tue, 6 Oct 2015 17:31:25 +0000"  >&lt;p&gt;One long-shot question &amp;#8211; can you figure out whether your JVM is using -XX:+UseCompressedOops by default? using -XX:+PrintFlagsFinal or something? it should switch off at 32gb but is often on by default in JVMs. I hope it&apos;s not the case that compressed OOPS throws off Tungsten.&lt;/p&gt;

&lt;p&gt;It could also be that bigger heap sizes let tasks all execute on the same machine and that happens to matter to reproducing this.&lt;/p&gt;</comment>
                            <comment id="14945418" author="srowen" created="Tue, 6 Oct 2015 17:31:26 +0000"  >&lt;p&gt;One long-shot question &amp;#8211; can you figure out whether your JVM is using -XX:+UseCompressedOops by default? using -XX:+PrintFlagsFinal or something? it should switch off at 32gb but is often on by default in JVMs. I hope it&apos;s not the case that compressed OOPS throws off Tungsten.&lt;/p&gt;

&lt;p&gt;It could also be that bigger heap sizes let tasks all execute on the same machine and that happens to matter to reproducing this.&lt;/p&gt;</comment>
                            <comment id="14945426" author="benm" created="Tue, 6 Oct 2015 17:33:43 +0000"  >&lt;p&gt;java  -XX:+PrintFlagsFinal says:&lt;br/&gt;
     bool UseCompressedOops                        := true            &lt;/p&gt;
{lp64_product}
&lt;p&gt;      &lt;/p&gt;

&lt;p&gt;Is there a way to turn that off and retest?&lt;/p&gt;</comment>
                            <comment id="14945436" author="srowen" created="Tue, 6 Oct 2015 17:39:40 +0000"  >&lt;p&gt;Sure, pass -XX:-UseCompressedOops. So if it fails with a small heap and this setting, maybe we have something. Worth checking, at least because it seems weird that it magically works with a certain heap size or below, and 32g is the magic boundary above which compressed oops can&apos;t be enabled, and references go back to being 64-bit instead of 32-bit.&lt;/p&gt;</comment>
                            <comment id="14945441" author="benm" created="Tue, 6 Oct 2015 17:42:02 +0000"  >&lt;p&gt;I just ran with &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;--executor-memory 100g --conf &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.executor.extraJavaOptions=-XX:-UseCompressedOops&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but the problem persists.  In the worker log it shows:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;15/10/06 18:36:36 INFO ExecutorRunner: Launch command: &lt;span class=&quot;code-quote&quot;&gt;&quot;/usr/lib/jvm/java-7-oracle/jre/bin/java&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-cp&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/spark/spark-1.5.1-bin-hadoop2.6/sbin/../conf/:/home/spark/spark-1.5.1-bin-hadoop2.6/lib/spark-assembly-1.5.1-hadoop2.6.0.jar:/home/spark/spark-1.5.1-bin-hadoop2.6/lib/datanucleus-core-3.2.10.jar:/home/spark/spark-1.5.1-bin-hadoop2.6/lib/datanucleus-rdbms-3.2.9.jar:/home/spark/spark-1.5.1-bin-hadoop2.6/lib/datanucleus-api-jdo-3.2.6.jar&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-Xms102400M&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-Xmx102400M&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-Dspark.driver.port=53169&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-XX:-UseCompressedOops&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-XX:MaxPermSize=256m&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.spark.executor.CoarseGrainedExecutorBackend&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--driver-url&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;akka.tcp:&lt;span class=&quot;code-comment&quot;&gt;//sparkDriver@10.122.82.99:53169/user/CoarseGrainedScheduler&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--executor-id&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;0&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--hostname&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;10.122.82.99&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--cores&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;20&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--app-id&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;app-20151006183636-0019&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--worker-url&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;akka.tcp://sparkWorker@10.122.82.99:51402/user/Worker&quot;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14945443" author="benm" created="Tue, 6 Oct 2015 17:44:20 +0000"  >&lt;p&gt;Ah, I did it the wrong way around!  With a &lt;b&gt;small&lt;/b&gt; heap and the option disabled it does indeed fail:&lt;/p&gt;

&lt;p&gt;--executor-memory 31g --conf &quot;spark.executor.extraJavaOptions=-XX:-UseCompressedOops&quot;&lt;/p&gt;

&lt;p&gt;gives the wrong result.&lt;/p&gt;</comment>
                            <comment id="14945638" author="srowen" created="Tue, 6 Oct 2015 19:42:30 +0000"  >&lt;p&gt;Hm, it could be a valid lead after all. The size estimator code is aware of 32-bit vs 64-bit pointers but a next line of inquiry might be to determine if somehow in your case it&apos;s detected incorrectly and that causes an error.  It sounds like compressed oops are off, but it thinks it&apos;s on. You could try adding &quot;-Dspark.test.useCompressedOops=false&quot; to see if it works then. That would pretty much confirm it. Then the question is what, for example SizeEstimator thinks for these values; if you can dig in to that and see what it comes up with that would help.&lt;/p&gt;

&lt;p&gt;I&apos;m assuming it is related to the part of the code that looks for compressed oops, but I wonder if somehow this affects Tungsten? CC &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt; for what may be a dumb question.&lt;/p&gt;</comment>
                            <comment id="14946623" author="benm" created="Wed, 7 Oct 2015 10:10:47 +0000"  >&lt;p&gt;I added a properties file to set spark.test.useCompressedOops=false.  This didn&apos;t seem to make any effect - it still gives wrong results for &amp;gt;=32gb, and correct results for &amp;lt;=31gb.&lt;/p&gt;

&lt;p&gt;I&apos;m not sufficiently familiar with the code to investigate what SizeEstimator thinks.  Have you any suggestions?&lt;/p&gt;</comment>
                            <comment id="14947307" author="srowen" created="Wed, 7 Oct 2015 18:16:35 +0000"  >&lt;p&gt;It fails with a small heap, right &amp;#8211; if you set -XX:-UseCompressedOops too? I mean do that, but also set spark.test.useCompressedOops=false to make sure SizeEstimator definitely thinks oops are disabled. Or: use a big heap, and spark.test.useCompressedOops=false&lt;/p&gt;

&lt;p&gt;I don&apos;t have a great system for investigating SizeEstimator other than to debug if you can, or just copy/paste that method that figures out if oops are on and see what it prints in your program.&lt;/p&gt;</comment>
                            <comment id="14947711" author="rxin" created="Wed, 7 Oct 2015 22:25:32 +0000"  >&lt;p&gt;I don&apos;t think size estimator would impact the result. &lt;/p&gt;

&lt;p&gt;If I understand this correctly, this fails with a small heap and compressed oops turned off? I can&apos;t reproduce it locally. I tried launching spark-shell using&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;bin/spark-shell --driver-java-options &lt;span class=&quot;code-quote&quot;&gt;&quot;-XX:-UseCompressedOops&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14948438" author="srowen" created="Thu, 8 Oct 2015 10:21:14 +0000"  >&lt;p&gt;I ran the latest master in standalone mode, with &lt;tt&gt;/bin/spark-shell --master spark://localhost:7077 --executor-memory 31g --conf &quot;spark.executor.extraJavaOptions=-XX:-UseCompressedOops&quot;&lt;/tt&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; val x = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 xx union all select 2&quot;&lt;/span&gt;)
x: org.apache.spark.sql.DataFrame = [xx: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; val y = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 yy union all select 2&quot;&lt;/span&gt;)
y: org.apache.spark.sql.DataFrame = [yy: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; x.join(y, $&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt; === $&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;).count()
res0: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = 5                                                                  
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Without the &lt;tt&gt;-XX:-UseCompressedOops&lt;/tt&gt; the answer is 2.&lt;/p&gt;

&lt;p&gt;Could be unrelated to &lt;tt&gt;SizeEstimator&lt;/tt&gt;, yes. I get 5 when setting &lt;tt&gt;spark.test.useCompressedOops=false&lt;/tt&gt; too, which seems to indicate it&apos;s not &lt;tt&gt;SizeEstimator&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Could it be something in the Tungsten machinery? I see it&apos;s part of the plan above. I wasn&apos;t sure how to test with that disabled.&lt;/p&gt;</comment>
                            <comment id="14948460" author="benm" created="Thu, 8 Oct 2015 10:38:06 +0000"  >&lt;p&gt;On latest master for me .count() also always seems to return 5 for everything! I think that is a separate bug - I think I saw it filed already but I can&apos;t find it now.&lt;/p&gt;</comment>
                            <comment id="14948464" author="benm" created="Thu, 8 Oct 2015 10:44:08 +0000"  >&lt;p&gt;I also don&apos;t see it if I run spark-shell without setting --master.&lt;/p&gt;</comment>
                            <comment id="14948486" author="srowen" created="Thu, 8 Oct 2015 11:08:45 +0000"  >&lt;p&gt;Still kind of guessing here... but what if the problem is that the computation spans machines that have a different oops configuration (driver vs executor) and that breaks some assumption in the low-level byte munging?&lt;/p&gt;</comment>
                            <comment id="14948492" author="benm" created="Thu, 8 Oct 2015 11:16:09 +0000"  >&lt;p&gt;I just tried moving the master to the worker box, so it&apos;s entirely on one machine.  (Ubuntu 14.04 + now Oracle JDK 1.8).&lt;/p&gt;

&lt;p&gt;It still reproduces the bug.  So, entirely on spark-worker:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;spark@spark-worker:~/spark-1.5.1-bin-hadoop2.6$ sbin/start-master.sh
spark@spark-worker:~/spark-1.5.1-bin-hadoop2.6$ sbin/start-slave.sh --master spark:&lt;span class=&quot;code-comment&quot;&gt;//spark-worker:7077
&lt;/span&gt;spark@spark-worker:~/spark-1.5.1-bin-hadoop2.6$ bin/spark-shell --master spark:&lt;span class=&quot;code-comment&quot;&gt;//spark-worker:7077  --conf &lt;span class=&quot;code-quote&quot;&gt;&quot;spark.executor.extraJavaOptions=-XX:-UseCompressedOops&quot;&lt;/span&gt;
&lt;/span&gt;log4j:WARN No appenders could be found &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; logger (org.apache.hadoop.metrics2.lib.MutableMetricsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http:&lt;span class=&quot;code-comment&quot;&gt;//logging.apache.org/log4j/1.2/faq.html#noconfig &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more info.
&lt;/span&gt;Using Spark&apos;s repl log4j profile: org/apache/spark/log4j-defaults-repl.properties
To adjust logging level use sc.setLogLevel(&lt;span class=&quot;code-quote&quot;&gt;&quot;INFO&quot;&lt;/span&gt;)
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  &apos;_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.5.1
      /_/

Using Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_60)
Type in expressions to have them evaluated.
Type :help &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more information.
15/10/08 12:15:12 WARN MetricsSystem: Using &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; name DAGScheduler &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; source because spark.app.id is not set.
Spark context available as sc.
15/10/08 12:15:14 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
15/10/08 12:15:14 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
15/10/08 12:15:19 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
15/10/08 12:15:20 WARN ObjectStore: Failed to get database &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;, returning NoSuchObjectException
15/10/08 12:15:21 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
15/10/08 12:15:21 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
15/10/08 12:15:21 WARN Connection: BoneCP specified but not present in CLASSPATH (or one of dependencies)
SQL context available as sqlContext.

scala&amp;gt; val x = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 xx union all select 2&quot;&lt;/span&gt;)
x: org.apache.spark.sql.DataFrame = [xx: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; val y = sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select 1 yy union all select 2&quot;&lt;/span&gt;)
y: org.apache.spark.sql.DataFrame = [yy: &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;]

scala&amp;gt; 

scala&amp;gt; x.join(y, $&lt;span class=&quot;code-quote&quot;&gt;&quot;xx&quot;&lt;/span&gt; === $&lt;span class=&quot;code-quote&quot;&gt;&quot;yy&quot;&lt;/span&gt;).count() &lt;span class=&quot;code-comment&quot;&gt;/* expect 2, get 0 */&lt;/span&gt; 
res0: &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt; = 0        

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;does give me the incorrect count.&lt;/p&gt;</comment>
                            <comment id="14948494" author="benm" created="Thu, 8 Oct 2015 11:16:40 +0000"  >&lt;p&gt;Either using the large heap, or -XX:-UseCompressedOops triggers the bug.&lt;/p&gt;</comment>
                            <comment id="14948511" author="srowen" created="Thu, 8 Oct 2015 11:34:23 +0000"  >&lt;p&gt;I don&apos;t think having it on one machine necessarily matters. You still have two JVMs in play; whereas you can&apos;t reproduce when just one JVM is involved. What if the driver has oops on, but the executor does not? and the results from the executor are parsed somewhere as if oops are on? Normally this would be wholly transparent to JVM bytecode but tungsten / SizeEstimator are depending in part on the actual representation of the object in memory.&lt;/p&gt;</comment>
                            <comment id="14948513" author="benm" created="Thu, 8 Oct 2015 11:38:11 +0000"  >&lt;p&gt;I think you&apos;ve got it - if I also turn off UseCompressedOops for the driver as well as the executor, it gives correct results:&lt;/p&gt;

&lt;p&gt; bin/spark-shell --master spark://spark-worker:7077  --conf &quot;spark.executor.extraJavaOptions=-XX:-UseCompressedOops&quot; --driver-java-options &quot;-XX:-UseCompressedOops&quot;&lt;/p&gt;


&lt;p&gt;Does this leave me with a viable workaround?  I&apos;m not sure of the impact of UseCompressedOops&lt;/p&gt;</comment>
                            <comment id="14949079" author="rxin" created="Thu, 8 Oct 2015 18:12:57 +0000"  >&lt;p&gt;OK I figured it out. Updated the description.&lt;/p&gt;</comment>
                            <comment id="14949114" author="apachespark" created="Thu, 8 Oct 2015 18:36:02 +0000"  >&lt;p&gt;User &apos;rxin&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/9030&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/9030&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12965268">SPARK-15156</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12911067">SPARK-11556</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13008182">SPARK-17706</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12907392">SPARK-11282</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13226619">SPARK-27406</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13226971">SPARK-27416</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 6 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2mjqn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>