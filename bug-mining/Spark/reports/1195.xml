<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:21:45 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-4908] Spark SQL built for Hive 13 fails under concurrent metadata queries</title>
                <link>https://issues.apache.org/jira/browse/SPARK-4908</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We are trunk: &lt;tt&gt;1.3.0-SNAPSHOT&lt;/tt&gt;, as of this commit: &lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/commit/3d0c37b8118f6057a663f959321a79b8061132b6&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/3d0c37b8118f6057a663f959321a79b8061132b6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We are using Spark built for Hive 13, using this option:&lt;br/&gt;
&lt;tt&gt;-Phive-0.13.1&lt;/tt&gt;&lt;/p&gt;

&lt;p&gt;In single-threaded mode, normal operations look fine. However, under concurrency, with at least 2 concurrent connections, metadata queries fail.&lt;/p&gt;

&lt;p&gt;For example, &lt;tt&gt;USE some_db&lt;/tt&gt;, &lt;tt&gt;SHOW TABLES&lt;/tt&gt;, and the implicit &lt;tt&gt;USE&lt;/tt&gt; statement when you pass a default schema in the JDBC URL, all fail.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;SELECT&lt;/tt&gt; queries like &lt;tt&gt;SELECT * FROM some_table&lt;/tt&gt; do not have this issue.&lt;/p&gt;

&lt;p&gt;Here is some example code:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;object main &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; App {
  &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.sql._
  &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.concurrent._
  &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.concurrent.duration._
  &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; scala.concurrent.ExecutionContext.Implicits.global

  &lt;span class=&quot;code-object&quot;&gt;Class&lt;/span&gt;.forName(&lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.hive.jdbc.HiveDriver&quot;&lt;/span&gt;)

  val host = &lt;span class=&quot;code-quote&quot;&gt;&quot;localhost&quot;&lt;/span&gt; &lt;span class=&quot;code-comment&quot;&gt;// update &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;
&lt;/span&gt;  val url = s&lt;span class=&quot;code-quote&quot;&gt;&quot;jdbc:hive2:&lt;span class=&quot;code-comment&quot;&gt;//${host}:10511/some_db&quot;&lt;/span&gt; // update &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;
&lt;/span&gt;
  val &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; = Future.traverse(1 to 3) { i =&amp;gt;
    Future {
      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Starting: &quot;&lt;/span&gt; + i)
      &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
        val conn = DriverManager.getConnection(url)
      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; {
        &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; e: Throwable =&amp;gt; e.printStackTrace()
        println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Failed: &quot;&lt;/span&gt; + i)
      }
      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Finishing: &quot;&lt;/span&gt; + i)
    }
  }

  Await.result(&lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt;, 2.minutes)

  println(&lt;span class=&quot;code-quote&quot;&gt;&quot;done!&quot;&lt;/span&gt;)
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the output:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Starting: 1
Starting: 3
Starting: 2
java.sql.SQLException: org.apache.spark.sql.execution.QueryExecutionException: FAILED: Operation cancelled
	at org.apache.hive.jdbc.Utils.verifySuccess(Utils.java:121)
	at org.apache.hive.jdbc.Utils.verifySuccessWithInfo(Utils.java:109)
	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:231)
	at org.apache.hive.jdbc.HiveConnection.configureConnection(HiveConnection.java:451)
	at org.apache.hive.jdbc.HiveConnection.&amp;lt;init&amp;gt;(HiveConnection.java:195)
	at org.apache.hive.jdbc.HiveDriver.connect(HiveDriver.java:105)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:270)
	at com.atscale.engine.connection.pool.main$$anonfun$30$$anonfun$apply$2.apply$mcV$sp(ConnectionManager.scala:896)
	at com.atscale.engine.connection.pool.main$$anonfun$30$$anonfun$apply$2.apply(ConnectionManager.scala:893)
	at com.atscale.engine.connection.pool.main$$anonfun$30$$anonfun$apply$2.apply(ConnectionManager.scala:893)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Failed: 3
Finishing: 3
java.sql.SQLException: org.apache.spark.sql.execution.QueryExecutionException: FAILED: Operation cancelled
	at org.apache.hive.jdbc.Utils.verifySuccess(Utils.java:121)
	at org.apache.hive.jdbc.Utils.verifySuccessWithInfo(Utils.java:109)
	at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:231)
	at org.apache.hive.jdbc.HiveConnection.configureConnection(HiveConnection.java:451)
	at org.apache.hive.jdbc.HiveConnection.&amp;lt;init&amp;gt;(HiveConnection.java:195)
	at org.apache.hive.jdbc.HiveDriver.connect(HiveDriver.java:105)
	at java.sql.DriverManager.getConnection(DriverManager.java:664)
	at java.sql.DriverManager.getConnection(DriverManager.java:270)
	at com.atscale.engine.connection.pool.main$$anonfun$30$$anonfun$apply$2.apply$mcV$sp(ConnectionManager.scala:896)
	at com.atscale.engine.connection.pool.main$$anonfun$30$$anonfun$apply$2.apply(ConnectionManager.scala:893)
	at com.atscale.engine.connection.pool.main$$anonfun$30$$anonfun$apply$2.apply(ConnectionManager.scala:893)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Failed: 2
Finishing: 2
Finishing: 1
done!
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here are the errors from Spark Logs:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;14/12/19 21:44:55 INFO thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO thriftserver.SparkExecuteStatementOperation: Running query &lt;span class=&quot;code-quote&quot;&gt;&apos;use as_adventure&apos;&lt;/span&gt;
14/12/19 21:44:55 INFO parse.ParseDriver: Parsing command: use as_adventure
14/12/19 21:44:55 INFO parse.ParseDriver: Parse Completed
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO parse.ParseDriver: Parsing command: use as_adventure
14/12/19 21:44:55 INFO parse.ParseDriver: Parse Completed
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=parse start=1419025495084 end=1419025495084 duration=0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Semantic Analysis Completed
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=semanticAnalyze start=1419025495084 end=1419025495084 duration=0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, properties:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=compile start=1419025495084 end=1419025495085 duration=1 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Starting command: use as_adventure
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=TimeToSubmit start=1419025495084 end=1419025495085 duration=1 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=runTasks start=1419025495085 end=1419025495098 duration=13 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=Driver.execute start=1419025495085 end=1419025495098 duration=13 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: OK
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=releaseLocks start=1419025495098 end=1419025495098 duration=0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=Driver.run start=1419025495084 end=1419025495098 duration=14 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
14/12/19 21:44:55 INFO thrift.ThriftCLIService: Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO thriftserver.SparkExecuteStatementOperation: Running query &lt;span class=&quot;code-quote&quot;&gt;&apos;use as_adventure&apos;&lt;/span&gt;
14/12/19 21:44:55 INFO thriftserver.SparkExecuteStatementOperation: Running query &lt;span class=&quot;code-quote&quot;&gt;&apos;use as_adventure&apos;&lt;/span&gt;
14/12/19 21:44:55 INFO thriftserver.SparkExecuteStatementOperation: Result Schema: List(result#274)
14/12/19 21:44:55 INFO parse.ParseDriver: Parsing command: use as_adventure
14/12/19 21:44:55 INFO parse.ParseDriver: Parse Completed
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO parse.ParseDriver: Parsing command: use as_adventure
14/12/19 21:44:55 INFO parse.ParseDriver: Parse Completed
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=parse start=1419025495165 end=1419025495165 duration=0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Semantic Analysis Completed
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=semanticAnalyze start=1419025495165 end=1419025495166 duration=1 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, properties:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=compile start=1419025495165 end=1419025495166 duration=1 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Starting command: use as_adventure
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=TimeToSubmit start=1419025495165 end=1419025495166 duration=1 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO parse.ParseDriver: Parsing command: use as_adventure
14/12/19 21:44:55 INFO parse.ParseDriver: Parse Completed
14/12/19 21:44:55 INFO session.SessionState: No Tez session required at &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; point. hive.execution.engine=mr.
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 WARN ql.Driver: Shutting down task : Stage-0:DDL
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO parse.ParseDriver: Parsing command: use as_adventure
14/12/19 21:44:55 INFO parse.ParseDriver: Parse Completed
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=parse start=1419025495173 end=1419025495174 duration=1 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Semantic Analysis Completed
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=semanticAnalyze start=1419025495174 end=1419025495174 duration=0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, properties:&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=compile start=1419025495172 end=1419025495177 duration=5 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO ql.Driver: Starting command: use as_adventure
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=TimeToSubmit start=1419025495172 end=1419025495177 duration=5 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=runTasks start=1419025495167 end=1419025495188 duration=21 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 ERROR ql.Driver: FAILED: Operation cancelled
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=Driver.execute start=1419025495166 end=1419025495189 duration=23 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=releaseLocks start=1419025495189 end=1419025495189 duration=0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 WARN ql.Driver: Shutting down task : Stage-0:DDL
14/12/19 21:44:55 ERROR hive.HiveContext:
======================
HIVE FAILURE OUTPUT
======================
RDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.&amp;lt;init&amp;gt;(SchemaRDD.scala:108)
	at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:94)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:161)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.metadata.HiveException(FAILED: Operation cancelled)
org.apache.hadoop.hive.ql.metadata.HiveException: FAILED: Operation cancelled
	at org.apache.hadoop.hive.ql.DriverContext.checkShutdown(DriverContext.java:125)
	at org.apache.hadoop.hive.ql.DriverContext.launching(DriverContext.java:91)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1497)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1270)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1088)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:911)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:901)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:305)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:276)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.execution.Command$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;execute(commands.scala:46)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:30)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:425)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:425)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.&amp;lt;init&amp;gt;(SchemaRDD.scala:108)
	at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:94)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:161)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

OK
OK
OK
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
OK
FAILED: Operation cancelled
FAILED: Hive Internal Error: java.lang.NullPointerException(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1194)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1088)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:911)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:901)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:305)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:276)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.execution.Command$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;execute(commands.scala:46)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:30)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:425)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:425)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.&amp;lt;init&amp;gt;(SchemaRDD.scala:108)
	at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:94)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:161)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

FAILED: Operation cancelled
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
FAILED: Operation cancelled
OK
OK
FAILED: Operation cancelled
OK
OK
FAILED: Operation cancelled
OK
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
FAILED: Operation cancelled

======================
END HIVE FAILURE OUTPUT
======================

14/12/19 21:44:55 ERROR thriftserver.SparkExecuteStatementOperation: Error executing query:
org.apache.spark.sql.execution.QueryExecutionException: FAILED: Operation cancelled
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:309)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:276)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.execution.Command$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;execute(commands.scala:46)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:30)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:425)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:425)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.&amp;lt;init&amp;gt;(SchemaRDD.scala:108)
	at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:94)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:161)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
14/12/19 21:44:55 WARN thrift.ThriftCLIService: Error executing statement:
org.apache.hive.service.cli.HiveSQLException: org.apache.spark.sql.execution.QueryExecutionException: FAILED: Operation cancelled
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:192)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=runTasks start=1419025495177 end=1419025495197 duration=20 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 ERROR ql.Driver: FAILED: Operation cancelled
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=Driver.execute start=1419025495177 end=1419025495200 duration=23 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 INFO log.PerfLogger: &amp;lt;/PERFLOG method=releaseLocks start=1419025495200 end=1419025495200 duration=0 from=org.apache.hadoop.hive.ql.Driver&amp;gt;
14/12/19 21:44:55 ERROR hive.HiveContext:
======================
HIVE FAILURE OUTPUT
======================
ache.spark.sql.SchemaRDD.&amp;lt;init&amp;gt;(SchemaRDD.scala:108)
	at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:94)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:161)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

FAILED: Hive Internal Error: org.apache.hadoop.hive.ql.metadata.HiveException(FAILED: Operation cancelled)
org.apache.hadoop.hive.ql.metadata.HiveException: FAILED: Operation cancelled
	at org.apache.hadoop.hive.ql.DriverContext.checkShutdown(DriverContext.java:125)
	at org.apache.hadoop.hive.ql.DriverContext.launching(DriverContext.java:91)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1497)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1270)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1088)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:911)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:901)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:305)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:276)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.execution.Command$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;execute(commands.scala:46)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:30)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:425)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:425)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.&amp;lt;init&amp;gt;(SchemaRDD.scala:108)
	at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:94)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:161)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

OK
OK
OK
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
OK
FAILED: Operation cancelled
FAILED: Hive Internal Error: java.lang.NullPointerException(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)
java.lang.NullPointerException
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1194)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1088)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:911)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:901)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:305)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:276)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.execution.Command$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;execute(commands.scala:46)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:30)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:425)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:425)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.&amp;lt;init&amp;gt;(SchemaRDD.scala:108)
	at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:94)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:161)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

FAILED: Operation cancelled
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
FAILED: Operation cancelled
OK
OK
FAILED: Operation cancelled
OK
OK
FAILED: Operation cancelled
OK
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
FAILED: Operation cancelled
FAILED: Operation cancelled
OK
FAILED: Operation cancelled
FAILED: Operation cancelled

======================
END HIVE FAILURE OUTPUT
======================

14/12/19 21:44:55 ERROR thriftserver.SparkExecuteStatementOperation: Error executing query:
org.apache.spark.sql.execution.QueryExecutionException: FAILED: Operation cancelled
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:309)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:276)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.execution.Command$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;execute(commands.scala:46)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:30)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd$lzycompute(SQLContext.scala:425)
	at org.apache.spark.sql.SQLContext$QueryExecution.toRdd(SQLContext.scala:425)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.&amp;lt;init&amp;gt;(SchemaRDD.scala:108)
	at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:94)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:161)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
14/12/19 21:44:55 WARN thrift.ThriftCLIService: Error executing statement:
org.apache.hive.service.cli.HiveSQLException: org.apache.spark.sql.execution.QueryExecutionException: FAILED: Operation cancelled
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(Shim13.scala:192)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:231)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:218)
	at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:79)
	at org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:37)
	at org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.hive.shims.HadoopShimsSecure.doAs(HadoopShimsSecure.java:493)
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:60)
	at com.sun.proxy.$Proxy18.executeStatementAsync(Unknown Source)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:233)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:344)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1313)
	at org.apache.hive.service.cli.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1298)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:55)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12762999">SPARK-4908</key>
            <summary>Spark SQL built for Hive 13 fails under concurrent metadata queries</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lian cheng">Cheng Lian</assignee>
                                    <reporter username="dyross">David Ross</reporter>
                        <labels>
                    </labels>
                <created>Fri, 19 Dec 2014 21:45:25 +0000</created>
                <updated>Mon, 12 Jan 2015 07:11:26 +0000</updated>
                            <resolved>Tue, 30 Dec 2014 19:25:21 +0000</resolved>
                                                    <fixVersion>1.2.1</fixVersion>
                    <fixVersion>1.3.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>3</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14256174" author="dyross" created="Mon, 22 Dec 2014 20:43:28 +0000"  >&lt;p&gt;Note that I noticed this line in the logs that seems to come from Hive logging (not spark code):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;14/12/19 21:44:55 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems to be tied to this config:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/hive/blob/branch-0.13/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java#L719&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hive/blob/branch-0.13/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java#L719&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have this to our &lt;tt&gt;hive-site.xml&lt;/tt&gt; in the spark &lt;tt&gt;conf&lt;/tt&gt; directory:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&amp;lt;property&amp;gt;
  &amp;lt;name&amp;gt;hive.support.concurrency&amp;lt;/name&amp;gt;
  &amp;lt;value&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And I still have the issue.&lt;/p&gt;

&lt;p&gt;Perhaps there is more I need to do to support concurrency?&lt;/p&gt;</comment>
                            <comment id="14260490" author="marmbrus" created="Mon, 29 Dec 2014 22:29:49 +0000"  >&lt;p&gt;You don&apos;t even need the JDBC server to cause the problem.  This seems to fail as well:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;(1 to 100).par.map { _ =&amp;gt; 
  sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;USE &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&quot;&lt;/span&gt;)
  sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SHOW TABLES&quot;&lt;/span&gt;)
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14260714" author="apachespark" created="Tue, 30 Dec 2014 03:11:13 +0000"  >&lt;p&gt;User &apos;marmbrus&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3834&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3834&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14261386" author="marmbrus" created="Tue, 30 Dec 2014 19:25:21 +0000"  >&lt;p&gt;Issue resolved by pull request 3834&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/3834&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/3834&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14264469" author="lian cheng" created="Mon, 5 Jan 2015 10:38:42 +0000"  >&lt;p&gt;Would like to add a comment about the root cause of this issue.  When serving a HiveQL query, Spark SQL&apos;s &lt;tt&gt;HiveContext.runHive&lt;/tt&gt; method gets a &lt;tt&gt;org.apache.hadoop.hive.ql.Driver&lt;/tt&gt; instance via &lt;tt&gt;CommandProcessFactory.get&lt;/tt&gt;, which creates and caches &lt;tt&gt;Driver&lt;/tt&gt; instances. In the case of &lt;tt&gt;HiveThriftServer2&lt;/tt&gt;, &lt;tt&gt;HiveContext.runHive&lt;/tt&gt; is called by multiple threads owned by a threaded executor of the Thrift server. However, &lt;tt&gt;Driver&lt;/tt&gt; is not thread safe, but cached &lt;tt&gt;Driver&lt;/tt&gt; instance can be accessed by multiple threads, thus causes problem. PR #3834 fixes this issue by synchronizing &lt;tt&gt;HiveContext.runHive&lt;/tt&gt;, which is valid.  On the other hand, HiveServer2 actually create a new &lt;tt&gt;Driver&lt;/tt&gt; instance for every served SQL query when initializing a &lt;tt&gt;SQLOperation&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dyross&quot; class=&quot;user-hover&quot; rel=&quot;dyross&quot;&gt;dyross&lt;/a&gt; When built against Hive 0.12.0, Spark SQL 1.2.0 also suffers this issue. The snippet doesn&apos;t show this because Hive 0.12.0 JDBC driver doesn&apos;t execute a &lt;tt&gt;USE &amp;lt;db&amp;gt;&lt;/tt&gt; statement to switch current database even if the JDBC connection URL specifies a database name. If you replace the lines in the &lt;tt&gt;try&lt;/tt&gt; block with:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      val conn = DriverManager.getConnection(url)
      val stmt = conn.createStatement()
      stmt.execute(&lt;span class=&quot;code-quote&quot;&gt;&quot;use hello;&quot;&lt;/span&gt;)
      stmt.close()
      println(&lt;span class=&quot;code-quote&quot;&gt;&quot;Finished: &quot;&lt;/span&gt; + i)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;you&apos;ll see exactly the same exceptions.&lt;/p&gt;</comment>
                            <comment id="14268892" author="dyross" created="Thu, 8 Jan 2015 06:34:01 +0000"  >&lt;p&gt;I&apos;ve verified that this is fixed on trunk. Since his commit says &quot;just a quick fix&quot;, I will let &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt; decide whether or not to keep this JIRA open.&lt;/p&gt;</comment>
                            <comment id="14268894" author="lian cheng" created="Thu, 8 Jan 2015 06:36:30 +0000"  >&lt;p&gt;It was considered as a &quot;quick fix&quot; because we hadn&apos;t figured out the root cause when the PR was submitted. But now it turned out to be a valid fix &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="14273271" author="apachespark" created="Mon, 12 Jan 2015 07:11:26 +0000"  >&lt;p&gt;User &apos;baishuo&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/4001&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/4001&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 45 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i23nbj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12329029">1.2.1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>