<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:14:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-1097] ConcurrentModificationException</title>
                <link>https://issues.apache.org/jira/browse/SPARK-1097</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;14/02/16 08:18:45 WARN TaskSetManager: Loss was due to java.util.ConcurrentModificationException
java.util.ConcurrentModificationException
	at java.util.HashMap$HashIterator.nextEntry(HashMap.java:926)
	at java.util.HashMap$KeyIterator.next(HashMap.java:960)
	at java.util.AbstractCollection.addAll(AbstractCollection.java:341)
	at java.util.HashSet.&amp;lt;init&amp;gt;(HashSet.java:117)
	at org.apache.hadoop.conf.Configuration.&amp;lt;init&amp;gt;(Configuration.java:554)
	at org.apache.hadoop.mapred.JobConf.&amp;lt;init&amp;gt;(JobConf.java:439)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:110)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.&amp;lt;init&amp;gt;(HadoopRDD.scala:154)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:149)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:64)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
	at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
	at org.apache.spark.rdd.UnionPartition.iterator(UnionRDD.scala:32)
	at org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:72)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
	at org.apache.spark.rdd.FlatMappedRDD.compute(FlatMappedRDD.scala:33)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
	at org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:241)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:232)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:161)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:102)
	at org.apache.spark.scheduler.Task.run(Task.scala:53)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$run$1.apply$mcV$sp(Executor.scala:213)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsUser(SparkHadoopUtil.scala:49)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:178)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12704582">SPARK-1097</key>
            <summary>ConcurrentModificationException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="colorant">Raymond Liu</assignee>
                                    <reporter username="Mistobaan">Fabrizio Milo</reporter>
                        <labels>
                    </labels>
                <created>Sun, 16 Feb 2014 14:31:49 +0000</created>
                <updated>Mon, 6 Oct 2014 23:06:02 +0000</updated>
                            <resolved>Fri, 13 Jun 2014 17:53:43 +0000</resolved>
                                    <version>0.9.0</version>
                                    <fixVersion>1.0.1</fixVersion>
                    <fixVersion>1.0.2</fixVersion>
                    <fixVersion>1.1.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="13953840" author="kasha" created="Thu, 27 Feb 2014 23:18:16 +0000"  >&lt;p&gt;What version of Hadoop is this? &lt;/p&gt;</comment>
                            <comment id="13957233" author="nravi" created="Wed, 2 Apr 2014 01:29:37 +0000"  >&lt;p&gt;Attached is a patch for this issue. Verified with mvn test/compile/install. The fix is to move HashSet initialization to the synchronized block right above it.&lt;/p&gt;</comment>
                            <comment id="13957335" author="srowen" created="Wed, 2 Apr 2014 04:52:02 +0000"  >&lt;p&gt;Standard procedure is to provide a pull request. But, you&apos;re suggesting a fix to Hadoop code, which belong in your Hadoop JIRA, yes. This can&apos;t fix the problem from the Spark end.&lt;/p&gt;

&lt;p&gt;(Eyeballing the Hadoop 2.2.0 code, I tend to agree with your patch. Mutation of finalParameters appears consistently synchronized, which means the constructor reading it to copy has to lock on the other Configuration or else exactly this can happen.)&lt;/p&gt;

&lt;p&gt;Is a workaround in Spark to synchronize on the Configuration object when calling this constructor? (I smell a deadlock risk.)&lt;br/&gt;
Or something crazy like trying the constructor until it doesn&apos;t fail this way?&lt;/p&gt;</comment>
                            <comment id="13957354" author="nravi" created="Wed, 2 Apr 2014 05:16:40 +0000"  >&lt;p&gt;The problem should be solved at the root. This issue can be exposed by other systems as well, in addition to Spark. The fix is straightforward and harmless. I can initiate a pull request as well.&lt;/p&gt;</comment>
                            <comment id="13957355" author="srowen" created="Wed, 2 Apr 2014 05:20:22 +0000"  >&lt;p&gt;I agree, but, we can&apos;t patch Hadoop from here. I&apos;m just saying that for purposes of a SPARK-* issue, in anything like the short-term, one would have to propose a workaround within Spark code, if anything. While also trying to fix it at the root, separately, in a HADOOP-* issue. (Spark does not have a copy of Hadoop, yesterday&apos;s April Fools joke aside.)&lt;/p&gt;</comment>
                            <comment id="13957958" author="nravi" created="Wed, 2 Apr 2014 18:00:31 +0000"  >&lt;p&gt;We can consider putting a workaround in Spark as well (for non-CDH users that may be running an older version of Hadoop and not updating it periodically). For now, this fix needs to go upstream, so we can backport it to CDH. The CDH-Spark bundle would then inherit this fix. The same issue has been noted in Hadoop-10456 as well. &lt;/p&gt;</comment>
                            <comment id="13958248" author="nravi" created="Wed, 2 Apr 2014 22:14:44 +0000"  >&lt;p&gt;Patch submitted against Hadoop-10456.&lt;/p&gt;</comment>
                            <comment id="13958671" author="ozawa" created="Thu, 3 Apr 2014 09:43:07 +0000"  >&lt;p&gt;A patch by Nishkam on &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10456&quot; title=&quot;Bug in Configuration.java exposed by Spark (ConcurrentModificationException)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10456&quot;&gt;&lt;del&gt;HADOOP-10456&lt;/del&gt;&lt;/a&gt; has been already reviewed and will be committed in a few days against hadoop&apos;s trunk.&lt;/p&gt;</comment>
                            <comment id="14020278" author="jblomo" created="Fri, 6 Jun 2014 19:33:25 +0000"  >&lt;p&gt;FYI still seeing this on spark 1.0, Hadoop 2.4&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.util.ConcurrentModificationException (java.util.ConcurrentModificationException)
java.util.HashMap$HashIterator.nextEntry(HashMap.java:922)
java.util.HashMap$KeyIterator.next(HashMap.java:956)
java.util.AbstractCollection.addAll(AbstractCollection.java:341)
java.util.HashSet.&amp;lt;init&amp;gt;(HashSet.java:117)
org.apache.hadoop.conf.Configuration.&amp;lt;init&amp;gt;(Configuration.java:671)
com.amazon.ws.emr.hadoop.fs.EmrFileSystem.initialize(EmrFileSystem.java:98)
org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2402)
org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:89)
org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2436)
org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2418)
org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)
org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)
org.apache.hadoop.mapred.LineRecordReader.&amp;lt;init&amp;gt;(LineRecordReader.java:107)
org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
org.apache.spark.rdd.HadoopRDD$$anon$1.&amp;lt;init&amp;gt;(HadoopRDD.scala:190)
org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:181)
org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:93)
org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
org.apache.spark.rdd.MappedRDD.compute(MappedRDD.scala:31)
org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
org.apache.spark.api.python.PythonRDD$WriterThread$$anonfun$run$1.apply$mcV$sp(PythonRDD.scala:200)
org.apache.spark.api.python.PythonRDD$WriterThread$$anonfun$run$1.apply(PythonRDD.scala:175)
org.apache.spark.api.python.PythonRDD$WriterThread$$anonfun$run$1.apply(PythonRDD.scala:175)
org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1160)
org.apache.spark.api.python.PythonRDD$WriterThread.run(PythonRDD.scala:174)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14020336" author="ozawa" created="Fri, 6 Jun 2014 20:39:36 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jblomo&quot; class=&quot;user-hover&quot; rel=&quot;jblomo&quot;&gt;jblomo&lt;/a&gt;, thank you for reporting. This issue is fixed in next minor Hadoop release - 2.4.1. Note that 2.4.0 doesn&apos;t include the fix.&lt;/p&gt;</comment>
                            <comment id="14020353" author="nravi" created="Fri, 6 Jun 2014 20:53:11 +0000"  >&lt;p&gt;Have initiated a PR for a workaround in Spark as well (for developers using &amp;lt; 2.4.1):&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/1000&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/1000&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14048653" author="colorant" created="Tue, 1 Jul 2014 08:47:50 +0000"  >&lt;p&gt;Summit another PR to actually(hopes) workaround this problem&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/1273&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/1273&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14075216" author="pwendell" created="Sat, 26 Jul 2014 01:58:41 +0000"  >&lt;p&gt;A follow up to this fix is in Spark 1.0.2:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/1409/files&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/1409/files&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12706073">SPARK-1388</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12706080">HADOOP-10456</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12727850">SPARK-2546</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12706073">SPARK-1388</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12638177" name="nravi_Conf_Spark-1388.patch" size="821" author="nravi" created="Wed, 2 Apr 2014 01:28:45 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>383110</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 17 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1u03z:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>383378</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>