<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:13:33 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-1802] Audit dependency graph when Spark is built with -Phive</title>
                <link>https://issues.apache.org/jira/browse/SPARK-1802</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;I&apos;d like to have binary release for 1.0 include Hive support. Since this isn&apos;t enabled by default in the build I don&apos;t think it&apos;s as well tested, so we should dig around a bit and decide if we need to e.g. add any excludes.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ mvn install -Phive -DskipTests &amp;amp;&amp;amp; mvn dependency:build-classpath -pl assembly | grep -v INFO | tr &lt;span class=&quot;code-quote&quot;&gt;&quot;:&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;\n&quot;&lt;/span&gt; |  awk &lt;span class=&quot;code-quote&quot;&gt;&apos; { FS=&lt;span class=&quot;code-quote&quot;&gt;&quot;/&quot;&lt;/span&gt;; print ( $(NF) ); }&apos;&lt;/span&gt; | sort &amp;gt; without_hive.txt

$ mvn install -Phive -DskipTests &amp;amp;&amp;amp; mvn dependency:build-classpath -Phive -pl assembly | grep -v INFO | tr &lt;span class=&quot;code-quote&quot;&gt;&quot;:&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;\n&quot;&lt;/span&gt; |  awk &lt;span class=&quot;code-quote&quot;&gt;&apos; { FS=&lt;span class=&quot;code-quote&quot;&gt;&quot;/&quot;&lt;/span&gt;; print ( $(NF) ); }&apos;&lt;/span&gt; | sort &amp;gt; with_hive.txt

$ diff without_hive.txt with_hive.txt
&amp;lt; antlr-2.7.7.jar
&amp;lt; antlr-3.4.jar
&amp;lt; antlr-runtime-3.4.jar
10,14d6
&amp;lt; avro-1.7.4.jar
&amp;lt; avro-ipc-1.7.4.jar
&amp;lt; avro-ipc-1.7.4-tests.jar
&amp;lt; avro-mapred-1.7.4.jar
&amp;lt; bonecp-0.7.1.RELEASE.jar
22d13
&amp;lt; commons-cli-1.2.jar
25d15
&amp;lt; commons-compress-1.4.1.jar
33,34d22
&amp;lt; commons-logging-1.1.1.jar
&amp;lt; commons-logging-api-1.0.4.jar
38d25
&amp;lt; commons-pool-1.5.4.jar
46,49d32
&amp;lt; datanucleus-api-jdo-3.2.1.jar
&amp;lt; datanucleus-core-3.2.2.jar
&amp;lt; datanucleus-rdbms-3.2.1.jar
&amp;lt; derby-10.4.2.0.jar
53,57d35
&amp;lt; hive-common-0.12.0.jar
&amp;lt; hive-exec-0.12.0.jar
&amp;lt; hive-metastore-0.12.0.jar
&amp;lt; hive-serde-0.12.0.jar
&amp;lt; hive-shims-0.12.0.jar
60,61d37
&amp;lt; httpclient-4.1.3.jar
&amp;lt; httpcore-4.1.3.jar
68d43
&amp;lt; JavaEWAH-0.3.2.jar
73d47
&amp;lt; javolution-5.5.1.jar
76d49
&amp;lt; jdo-api-3.0.1.jar
78d50
&amp;lt; jetty-6.1.26.jar
87d58
&amp;lt; jetty-util-6.1.26.jar
93d63
&amp;lt; json-20090211.jar
98d67
&amp;lt; jta-1.1.jar
103,104d71
&amp;lt; libfb303-0.9.0.jar
&amp;lt; libthrift-0.9.0.jar
112d78
&amp;lt; mockito-all-1.8.5.jar
136d101
&amp;lt; servlet-api-2.5-20081211.jar
139d103
&amp;lt; snappy-0.2.jar
144d107
&amp;lt; spark-hive_2.10-1.0.0.jar
151d113
&amp;lt; ST4-4.0.4.jar
153d114
&amp;lt; stringtemplate-3.2.1.jar
156d116
&amp;lt; velocity-1.7.jar
158d117
&amp;lt; xz-1.0.jar
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Some initial investigation suggests we may need to take some precaution surrounding (a) jetty and (b) servlet-api.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12713568">SPARK-1802</key>
            <summary>Audit dependency graph when Spark is built with -Phive</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="pwendell">Patrick Wendell</reporter>
                        <labels>
                    </labels>
                <created>Mon, 12 May 2014 06:27:16 +0000</created>
                <updated>Thu, 15 Jan 2015 09:08:39 +0000</updated>
                            <resolved>Mon, 19 May 2014 18:43:17 +0000</resolved>
                                                    <fixVersion>1.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="13994990" author="srowen" created="Mon, 12 May 2014 10:34:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pwendell&quot; class=&quot;user-hover&quot; rel=&quot;pwendell&quot;&gt;pwendell&lt;/a&gt; You can see my start on it here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/srowen/spark/commits/SPARK-1802&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/srowen/spark/commits/SPARK-1802&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://github.com/srowen/spark/commit/a856604cfc67cb58146ada01fda6dbbb2515fa00&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/srowen/spark/commit/a856604cfc67cb58146ada01fda6dbbb2515fa00&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This resolves the new issues you note in your diff.&lt;/p&gt;


&lt;p&gt;Next issue is that hive-exec, quite awfully, includes a copy of all of its transitive dependencies in its artifact. See &lt;a href=&quot;https://issues.apache.org/jira/browse/HIVE-5733&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HIVE-5733&lt;/a&gt; and note the warnings you&apos;ll get during assembly:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[WARNING] hive-exec-0.12.0.jar, libthrift-0.9.0.jar define 153 overlappping classes: 
[WARNING]   - org.apache.thrift.transport.TSaslTransport$SaslResponse
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;hive-exec is in fact used in this module. Aside from actual surgery on the artifact with the shade plugin, you can&apos;t control the dependencies as a result. This may be simply &quot;the best that can be done&quot; right now. If it has worked, it has worked.&lt;/p&gt;


&lt;p&gt;Am I right that the datanucleus JARs &lt;b&gt;are&lt;/b&gt; meant to be in the assembly, only for the Hive build?&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/688&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/688&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/610&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/610&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;That&apos;s good if so since that&apos;s what your diff shows.&lt;/p&gt;


&lt;p&gt;Finally, while we&apos;re here, I note that there are still a few JAR conflicts that turn up when you build the assembly &lt;b&gt;without&lt;/b&gt; Hive. (I&apos;m going to ignore conflicts in examples; these can be cleaned up but aren&apos;t really a big deal given its nature.)  We could touch those up too.&lt;/p&gt;

&lt;p&gt;This is in the normal build (and I know how to zap most of this problem):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[WARNING] commons-beanutils-core-1.8.0.jar, commons-beanutils-1.7.0.jar define 82 overlappping classes: 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These turn up in the Hadoop 2.x + YARN build:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[WARNING] servlet-api-2.5.jar, javax.servlet-3.0.0.v201112011016.jar define 42 overlappping classes: 
...
[WARNING] jcl-over-slf4j-1.7.5.jar, commons-logging-1.1.3.jar define 6 overlappping classes: 
...
[WARNING] activation-1.1.jar, javax.activation-1.1.0.v201105071233.jar define 17 overlappping classes: 
...
[WARNING] servlet-api-2.5.jar, javax.servlet-3.0.0.v201112011016.jar define 42 overlappping classes: 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These should be easy to track down. Shall I?&lt;/p&gt;</comment>
                            <comment id="13995646" author="pwendell" created="Mon, 12 May 2014 21:17:46 +0000"  >&lt;p&gt;Issue resolved by pull request 744&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/744&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/744&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13995815" author="srowen" created="Mon, 12 May 2014 23:35:07 +0000"  >&lt;p&gt;(Edited to fix comment about protobuf versions)&lt;/p&gt;

&lt;p&gt;I looked further into just what might go wrong by including hive-exec into the assembly, since it includes its dependencies directly (i.e. Maven can&apos;t manage around it.)&lt;/p&gt;

&lt;p&gt;Attached is a full dump of the conflicts.&lt;/p&gt;

&lt;p&gt;The ones that are potential issues appear to be the following, and one looks like it could be a deal-breaker &amp;#8211; protobuf &amp;#8211; since it&apos;s neither forwards nor backwards compatible. That is, I recommend testing this assembly with an &lt;b&gt;newer&lt;/b&gt; Hadoop that needs 2.5 and see if it croaks.&lt;/p&gt;

&lt;p&gt;The rest might be worked around but need some additional mojo to make sure the right version wins in the packaging.&lt;/p&gt;

&lt;p&gt;Certainly having hive-exec in the build is making me queasy!&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING&amp;#93;&lt;/span&gt; hive-exec-0.12.0.jar, libthrift-0.9.0.jar define 153 overlappping classes: &lt;/p&gt;

&lt;p&gt;HBase includes libthrift-0.8.0, but it&apos;s in examples, and so figure this is ignorable.&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING&amp;#93;&lt;/span&gt; hive-exec-0.12.0.jar, commons-lang-2.4.jar define 2 overlappping classes: &lt;/p&gt;

&lt;p&gt;Probably ignorable, but we have to make sure commons-lang-3.3.2 &apos;wins&apos; in the build.&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING&amp;#93;&lt;/span&gt; hive-exec-0.12.0.jar, jackson-core-asl-1.9.11.jar define 117 overlappping classes: &lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING&amp;#93;&lt;/span&gt; hive-exec-0.12.0.jar, jackson-mapper-asl-1.8.8.jar define 432 overlappping classes: &lt;/p&gt;

&lt;p&gt;Believe this are ignorable. (Not sure why the jackson versions are mismatched? another todo)&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING&amp;#93;&lt;/span&gt; hive-exec-0.12.0.jar, guava-14.0.1.jar define 1087 overlappping classes: &lt;/p&gt;

&lt;p&gt;Should be OK. Hive uses 11.0.2 like Hadoop; the build is already taking that particular risk. We need 14.0.1 to win.&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING&amp;#93;&lt;/span&gt; hive-exec-0.12.0.jar, protobuf-java-2.4.1.jar define 204 overlappping classes: &lt;/p&gt;

&lt;p&gt;Oof. Hive has protobuf &lt;b&gt;2.4.1&lt;/b&gt;. This has got to be a problem for newer Hadoop builds?&lt;/p&gt;

&lt;p&gt;(Edited to fix comment about protobuf versions)&lt;/p&gt;</comment>
                            <comment id="13995976" author="pwendell" created="Tue, 13 May 2014 02:46:28 +0000"  >&lt;p&gt;Let&apos;s keep this open given the ongoing discussion.&lt;/p&gt;</comment>
                            <comment id="13995987" author="gq" created="Tue, 13 May 2014 03:06:16 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/754&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Related work&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13996178" author="pwendell" created="Tue, 13 May 2014 08:17:49 +0000"  >&lt;p&gt;This protobuf thing is very troubling. The options here are pretty limited since they publish this assembly jar. I see a few:&lt;/p&gt;

&lt;p&gt;1. Publish a Hive 0.12 that uses our shaded protobuf 2.4.1 (we already published a shaded version of protobuf 2.4.1). I actually have this working in a local build of Hive 0.12, but I haven&apos;t tried to push it to sonatype yet:&lt;br/&gt;
&lt;a href=&quot;https://github.com/pwendell/hive/commits/branch-0.12-shaded-protobuf&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/pwendell/hive/commits/branch-0.12-shaded-protobuf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2. Upgrade our use of hive to 0.13 (which bumps to protobuf 2.5.0) and only support Spark SQL with Hadoop 2+ - that is, versions of Hadoop that have also bumped to protobuf 2.5.0. I&apos;m not sure how big of an effort that would be in terms of the code changes between 0.12 and 0.13. Spark didn&apos;t recompile trivially. I can talk to Michael Armbrust tomorrow morning about this.&lt;/p&gt;

&lt;p&gt;One thing I don&apos;t totally understand is how Hive itself deals with this conflict. For instance, if someone wants to run Hive 0.12 with Hadoop 2. Presumably both the Hive protobuf 2.4.1 and the HDFS client protobuf 2.5.0 will be in the JVM at the same time... I&apos;m not sure how they are isolated from each-other. HDP 2.1 for instance, seems to have both (&lt;a href=&quot;http://hortonworks.com/hdp/whats-new/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hortonworks.com/hdp/whats-new/&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="13996278" author="srowen" created="Tue, 13 May 2014 11:26:13 +0000"  >&lt;p&gt;First, I apologize, I misspoke above. Actually hive-exec 0.12.0 depends on protobuf 2.4.1. I got this wrong since I was evaluating dependencies under the Hadoop 2.3 profile.&lt;/p&gt;

&lt;p&gt;That leaves the same but opposite problem, meaning it probably won&apos;t work with later versions of Hadoop at some level.&lt;/p&gt;

&lt;p&gt;The &apos;right&apos; place to solve this is the hive-exec build, and I know there&apos;s a Hive JIRA open for this. Maybe people who are interested in making this work can push that through? But that&apos;s more of a medium-term answer.&lt;/p&gt;

&lt;p&gt;I suppose it&apos;s possible to &lt;b&gt;also&lt;/b&gt; vary the Hive version with Hadoop version? Assuming the Spark code can be made to work both ways, and I don&apos;t know that.This may or may not work as I don&apos;t know if Hive-Hadoop are compatible in exactly the same versions that they agree on protobuf.&lt;/p&gt;

&lt;p&gt;You could go ahead with testing the Hive-enabled build anyway, with crossed fingers.&lt;br/&gt;
You could look at deploying two artifacts, with and without Hive, and simply give in to combinatorial explosion for the short term.&lt;br/&gt;
You could say Hive builds are do-it-yourself for the short-term, and bring it back in the medium term if/when the project drops support for older Hadoop &amp;#8211; which may be becoming more attractive all the time &amp;#8211; and combinatorial mess is much less&lt;/p&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12714133">SPARK-1828</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12644517" name="hive-exec-jar-problems.txt" size="14710" author="srowen" created="Mon, 12 May 2014 23:35:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>391884</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 28 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1vhon:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>392087</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>