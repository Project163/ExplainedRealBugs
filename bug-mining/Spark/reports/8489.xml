<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:29:47 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-37259] JDBC read is always going to wrap the query in a select statement</title>
                <link>https://issues.apache.org/jira/browse/SPARK-37259</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The read jdbc is wrapping the query it sends to the database server inside a select statement and there is no way to override this currently.&lt;/p&gt;

&lt;p&gt;Initially I ran into this issue when trying to run a CTE query against SQL server and it fails, the details of the failure is in these cases:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/mssql-jdbc/issues/1340&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/microsoft/mssql-jdbc/issues/1340&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/mssql-jdbc/issues/1657&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/microsoft/mssql-jdbc/issues/1657&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/microsoft/sql-spark-connector/issues/147&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/microsoft/sql-spark-connector/issues/147&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-32825&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-32825&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-34928&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-34928&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I started to patch the code to get the query to run and ran into a few different items, if there is a way to add these features to allow this code path to run, this would be extremely helpful to running these type of edge case queries.&#160; These are basic examples here the actual queries are much more complex and would require significant time to rewrite.&lt;/p&gt;

&lt;p&gt;Inside JDBCOptions.scala the query is being set to either, using the dbtable this allows the query to be passed without modification&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
name.trim
or
s&lt;span class=&quot;code-quote&quot;&gt;&quot;(${subquery}) SPARK_GEN_SUBQ_${curId.getAndIncrement()}&quot;&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Inside JDBCRelation.scala this is going to try to get the schema for this query, and this ends up running dialect.getSchemaQuery which is doing:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
s&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT * FROM $table WHERE 1=0&quot;&lt;/span&gt;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Overriding the dialect here and initially just passing back the $table gets passed here and to the next issue which is in the compute function in JDBCRDD.scala&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val sqlText = s&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT $columnList FROM ${options.tableOrQuery} $myTableSampleClause&quot;&lt;/span&gt; + s&lt;span class=&quot;code-quote&quot;&gt;&quot; $myWhereClause $getGroupByClause $myLimitClause&quot;&lt;/span&gt;
&#160;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;For these two queries, about a CTE query and using temp tables, finding out the schema is difficult without actually running the query and for the temp table if you run it in the schema check that will have the table now exist and fail when it runs the actual query.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The way I patched these is by doing these two items:&lt;/p&gt;

&lt;p&gt;JDBCRDD.scala (compute)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&#160; &#160; val runQueryAsIs = options.parameters.getOrElse(&lt;span class=&quot;code-quote&quot;&gt;&quot;runQueryAsIs&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;).toBoolean
&#160; &#160; val sqlText = &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (runQueryAsIs) {
&#160; &#160; &#160; s&lt;span class=&quot;code-quote&quot;&gt;&quot;${options.tableOrQuery}&quot;&lt;/span&gt;
&#160; &#160; } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
&#160; &#160; &#160; s&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT $columnList FROM ${options.tableOrQuery} $myWhereClause&quot;&lt;/span&gt;
&#160; &#160; }

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;JDBCRelation.scala (getSchema)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val useCustomSchema = jdbcOptions.parameters.getOrElse(&lt;span class=&quot;code-quote&quot;&gt;&quot;useCustomSchema&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&quot;&lt;/span&gt;).toBoolean
&#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (useCustomSchema) {
&#160; &#160; &#160; val myCustomSchema = jdbcOptions.parameters.getOrElse(&lt;span class=&quot;code-quote&quot;&gt;&quot;customSchema&quot;&lt;/span&gt;, &quot;&quot;).toString
&#160; &#160; &#160; val newSchema = CatalystSqlParser.parseTableSchema(myCustomSchema)
&#160; &#160; &#160; logInfo(s&lt;span class=&quot;code-quote&quot;&gt;&quot;Going to &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; the &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; $newSchema because useCustomSchema is $useCustomSchema and passed in $myCustomSchema&quot;&lt;/span&gt;)
&#160; &#160; &#160; newSchema
&#160; &#160; } &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; {
&#160; &#160; &#160; val tableSchema = JDBCRDD.resolveTable(jdbcOptions)
&#160; &#160; &#160; jdbcOptions.customSchema match {
&#160; &#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; Some(customSchema) =&amp;gt; JdbcUtils.getCustomSchema(
&#160; &#160; &#160; &#160; tableSchema, customSchema, resolver)
&#160; &#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; None =&amp;gt; tableSchema
&#160; &#160; &#160; }
&#160; &#160; }&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;This is allowing the query to run as is, by using the dbtable option and then provide a custom schema that will bypass the dialect schema check&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Test queries&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
query1 = &quot;&quot;&quot;&#160;
SELECT 1 as DummyCOL
&quot;&quot;&quot;
query2 = &quot;&quot;&quot;&#160;
WITH DummyCTE AS
(
SELECT 1 as DummyCOL
)
SELECT *
FROM DummyCTE
&quot;&quot;&quot;
query3 = &quot;&quot;&quot;
(SELECT *
INTO #Temp1a
FROM
(SELECT @@VERSION as version) data
)
(SELECT *
FROM
#Temp1a)
&quot;&quot;&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Test schema&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
schema1 = &quot;&quot;&quot;
DummyXCOL INT
&quot;&quot;&quot;
schema2 = &quot;&quot;&quot;
DummyXCOL STRING
&quot;&quot;&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Test code&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
jdbcDFWorking = (
&#160; &#160; spark.read.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;jdbc&quot;&lt;/span&gt;)
&#160; &#160; .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;url&quot;&lt;/span&gt;, f&lt;span class=&quot;code-quote&quot;&gt;&quot;jdbc:sqlserver:&lt;span class=&quot;code-comment&quot;&gt;//{server}:{port};databaseName={database};&quot;&lt;/span&gt;)
&lt;/span&gt;&#160; &#160; .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;user&quot;&lt;/span&gt;, user)
&#160; &#160; .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;password&quot;&lt;/span&gt;, password)
&#160; &#160; .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;driver&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;&lt;/span&gt;)
&#160; &#160; .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;dbtable&quot;&lt;/span&gt;, queryx)
&#160; &#160; .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;customSchema&quot;&lt;/span&gt;, schemax)
&#160; &#160; .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;useCustomSchema&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;)
&#160; &#160; .option(&lt;span class=&quot;code-quote&quot;&gt;&quot;runQueryAsIs&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;&quot;&lt;/span&gt;)
&#160; &#160; .load()
)
&#160;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Currently we ran into this on these two special SQL server queries however we aren&apos;t sure if there is other DB&apos;s we are using that we haven&apos;t hit this type of issue yet, without going through this I didn&apos;t realize the query is always wrapped in the SELECT no matter what you do.&lt;/p&gt;

&lt;p&gt;This is on the Spark 3.1.2 and using the PySpark with the Python 3.7.11&lt;/p&gt;

&lt;p&gt;Thank you for your consideration and assistance to a way to fix this&lt;/p&gt;

&lt;p&gt;Kevin&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13410874">SPARK-37259</key>
            <summary>JDBC read is always going to wrap the query in a select statement</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="petertoth">Peter Toth</assignee>
                                    <reporter username="KevinAppelBofa">Kevin Appel</reporter>
                        <labels>
                    </labels>
                <created>Tue, 9 Nov 2021 15:21:31 +0000</created>
                <updated>Fri, 6 May 2022 21:30:00 +0000</updated>
                            <resolved>Fri, 6 May 2022 21:30:00 +0000</resolved>
                                    <version>3.1.2</version>
                                    <fixVersion>3.4.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="17446554" author="petertoth" created="Fri, 19 Nov 2021 15:56:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=KevinAppelBofa&quot; class=&quot;user-hover&quot; rel=&quot;KevinAppelBofa&quot;&gt;KevinAppelBofa&lt;/a&gt;, how about adding a new `withClause` to the JDBC options? Do you think you could split your CTE query to &quot;with clause&quot; and &quot;regular query&quot; parts manually and specify something like: .option(&quot;withClause&quot;, withClause).option(&quot;query&quot;, query)?&lt;br/&gt;
Because, that way we probably only need a small change to `sqlText` in `compute()` (&lt;a href=&quot;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JDBCRDD.scala#L370-L371):&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JDBCRDD.scala#L370-L371):&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    val sqlText = s&quot;$withClause SELECT $columnList FROM ${options.tableOrQuery} $myTableSampleClause&quot; +
      s&quot; $myWhereClause $getGroupByClause $myLimitClause&quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and also we could keep its other functionality.&lt;/p&gt;

&lt;p&gt;Sidenote: technically we could extract the WITH clause in MsSqlServerDialect and assemble a dialect specific `sqlText` there, but it is not that simple to do it...&lt;/p&gt;</comment>
                            <comment id="17447578" author="JIRAUSER279882" created="Mon, 22 Nov 2021 19:17:15 +0000"  >&lt;p&gt;It would be difficult to be able to actually split up the query into the parts, and to align one of the selects to match the one hard coded in the query; then the other issues issue about needing to patch into the dialect and handle how it passes that query today to get the schema and having a way to get that, without running the query twice.&lt;/p&gt;

&lt;p&gt;The other query that uses temp tables, in the sql server it is either #temptable or ##temptable is also still an issue because of how it getting wrapped in the select and the similar item if that runs the query to get the schema, then it actually creates the tables and the query fails when it runs since the table exists&lt;/p&gt;

&lt;p&gt;The other item is the query is going to do something to the query you pass in, so it would need to be based on dbtable being used that is only doing a trim; the query is wrapping:&lt;br/&gt;
s&quot;(${subquery}) SPARK_GEN_SUBQ_${curId.getAndIncrement()}&quot;&lt;br/&gt;
&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="17447972" author="apachespark" created="Tue, 23 Nov 2021 12:10:59 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34693&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34693&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17447980" author="petertoth" created="Tue, 23 Nov 2021 12:25:32 +0000"  >&lt;p&gt;I&apos;ve opened a PR: &lt;a href=&quot;https://github.com/apache/spark/pull/34693&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34693&lt;/a&gt; to support queries with CTE.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;to get the schema and having a way to get that, without running the query twice.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t think that running the query twice to get the schema would be an issue as Spark adds a `WHERE 1=0` clause to the query. MSSQL engine should optimize the query and quickly return the schema with empty results.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The other item is the query is going to do something to the query you pass in, so it would need to be based on dbtable being used that is only doing a trim; the query is wrapping:&lt;br/&gt;
s&quot;(${subquery}) SPARK_GEN_SUBQ_${curId.getAndIncrement()}&quot;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I don&apos;t think this is an issue, please see new unit tests in the PR.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The other query that uses temp tables, in the sql server it is either #temptable or ##temptable is also still an issue because of how it getting wrapped in the select and the similar item if that runs the query to get the schema, then it actually creates the tables and the query fails when it runs since the table exists&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I&apos;m not sure that temp tables fit into Spark&apos;s JDBC world. Let me check if we can workaround them with the new `withClause`...&lt;/p&gt;</comment>
                            <comment id="17449067" author="akhalymon" created="Thu, 25 Nov 2021 09:35:27 +0000"  >&lt;p&gt;I&apos;ve created another PR following &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=KevinAppelBofa&quot; class=&quot;user-hover&quot; rel=&quot;KevinAppelBofa&quot;&gt;KevinAppelBofa&lt;/a&gt;&#160; idea to unwrap the query and pass schema manually when the user chooses to do so. If let&apos;s say an option &apos;useRawQuery&apos; passed, the query will run as-is. The downside of this user has to provide schema manually. However, there are also advantages, as we are not running the query twice, and the user doesn&apos;t have to modify the query and split the &apos;with&apos; clause.&lt;/p&gt;

&lt;p&gt;PR link is &lt;a href=&quot;https://github.com/apache/spark/pull/34709&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34709&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=KevinAppelBofa&quot; class=&quot;user-hover&quot; rel=&quot;KevinAppelBofa&quot;&gt;KevinAppelBofa&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petertoth&quot; class=&quot;user-hover&quot; rel=&quot;petertoth&quot;&gt;petertoth&lt;/a&gt; what are your thoughts on this?&lt;/p&gt;</comment>
                            <comment id="17449072" author="apachespark" created="Thu, 25 Nov 2021 09:40:07 +0000"  >&lt;p&gt;User &apos;akhalymon-cv&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/34709&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/34709&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17450525" author="JIRAUSER279882" created="Mon, 29 Nov 2021 15:21:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=petertoth&quot; class=&quot;user-hover&quot; rel=&quot;petertoth&quot;&gt;petertoth&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=akhalymon&quot; class=&quot;user-hover&quot; rel=&quot;akhalymon&quot;&gt;akhalymon&lt;/a&gt; Thank you both for working on these patches, it took me a little bit to figure out how to test them but i got the Spark 3.3.0-SNAPSHOT compiled and then added both of your changes to different working copies and then recompile the spark-sql and then was able to test both of your changes.&#160; I added comments into the github pull request links with how the testing went so far&lt;/p&gt;</comment>
                            <comment id="17525784" author="JIRAUSER279882" created="Thu, 21 Apr 2022 15:26:51 +0000"  >&lt;p&gt;Both of these PR&apos;s were closed due to inactivity, I had tested them both and they both appeared to be working.&#160; Is it possible these could get re activated and one of them pushed to the end?&lt;/p&gt;

&lt;p&gt;Or is there someone new that could help to take this to the end and get this available in the main spark code base?&lt;/p&gt;

&lt;p&gt;I am working on Spark 3.2.1 now and I had recompiled the code to do the above items, we also have been using this code for a few months on Spark 3.1.2 and it is working for us to be able to handle the CTE queries against MSSQL&lt;/p&gt;</comment>
                            <comment id="17531185" author="apachespark" created="Tue, 3 May 2022 13:00:08 +0000"  >&lt;p&gt;User &apos;peter-toth&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/36440&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/36440&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10430"><![CDATA[Patch]]></customfieldvalue>
    <customfieldvalue key="10431"><![CDATA[Important]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 28 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0wkww:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>