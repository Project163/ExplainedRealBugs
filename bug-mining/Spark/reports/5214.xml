<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:56:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-21549] Spark fails to complete job correctly in case of OutputFormat which do not write into hdfs</title>
                <link>https://issues.apache.org/jira/browse/SPARK-21549</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Spark fails to complete job correctly in case of custom OutputFormat implementations.&lt;/p&gt;

&lt;p&gt;There are OutputFormat implementations which do not need to use &lt;b&gt;mapreduce.output.fileoutputformat.outputdir&lt;/b&gt; standard hadoop property.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/blob/v2.2.0/core/src/main/scala/org/apache/spark/internal/io/SparkHadoopMapReduceWriter.scala#L79&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;But spark reads this property from the configuration&lt;/a&gt; while setting up an OutputCommitter&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-javascript&quot;&gt;val committer = FileCommitProtocol.instantiate(
  className = classOf[HadoopMapReduceCommitProtocol].getName,
  jobId = stageId.toString,
  outputPath = conf.value.get(&lt;span class=&quot;code-quote&quot;&gt;&quot;mapreduce.output.fileoutputformat.outputdir&quot;&lt;/span&gt;),
  isAppend = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;).asInstanceOf[HadoopMapReduceCommitProtocol]
committer.setupJob(jobContext)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;... and then uses this property later on while &lt;a href=&quot;https://github.com/apache/spark/blob/v2.2.0/core/src/main/scala/org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.scala#L132&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;commiting the job&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/spark/blob/v2.2.0/core/src/main/scala/org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.scala#L141&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;aborting the job&lt;/a&gt;, &lt;a href=&quot;https://github.com/apache/spark/blob/v2.2.0/core/src/main/scala/org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.scala#L95&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;creating task&apos;s temp path&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In that cases when the job completes then following exception is thrown&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Can not create a Path from a &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; string
java.lang.IllegalArgumentException: Can not create a Path from a &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; string
  at org.apache.hadoop.fs.Path.checkPathArg(Path.java:123)
  at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:135)
  at org.apache.hadoop.fs.Path.&amp;lt;init&amp;gt;(Path.java:89)
  at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.absPathStagingDir(HadoopMapReduceCommitProtocol.scala:58)
  at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.abortJob(HadoopMapReduceCommitProtocol.scala:141)
  at org.apache.spark.internal.io.SparkHadoopMapReduceWriter$.write(SparkHadoopMapReduceWriter.scala:106)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1085)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1085)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsNewAPIHadoopDataset$1.apply(PairRDDFunctions.scala:1085)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
  at org.apache.spark.rdd.PairRDDFunctions.saveAsNewAPIHadoopDataset(PairRDDFunctions.scala:1084)
  ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So it seems that all the jobs which use OutputFormats which don&apos;t write data into HDFS-compatible file systems are broken.&lt;/p&gt;</description>
                <environment>&lt;p&gt;spark 2.2.0&lt;br/&gt;
scala 2.11&lt;/p&gt;</environment>
        <key id="13090560">SPARK-21549</key>
            <summary>Spark fails to complete job correctly in case of OutputFormat which do not write into hdfs</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="szhemzhitsky">Sergey Zhemzhitsky</assignee>
                                    <reporter username="szhemzhitsky">Sergey Zhemzhitsky</reporter>
                        <labels>
                    </labels>
                <created>Thu, 27 Jul 2017 16:45:58 +0000</created>
                <updated>Mon, 16 Oct 2017 01:43:05 +0000</updated>
                            <resolved>Sat, 7 Oct 2017 03:46:25 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.2.1</fixVersion>
                    <fixVersion>2.3.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="16105630" author="mridulm80" created="Fri, 28 Jul 2017 20:38:38 +0000"  >&lt;p&gt;This affects both mapred (&quot;mapred.output.dir&quot;) and mapreduce (&quot;mapreduce.output.fileoutputformat.outputdir&quot;) based OutputFormat&apos;s which do not set the properties referenced and is an incompatibility introduced in spark 2.2&lt;/p&gt;

&lt;p&gt;Workaround is to explicitly set the property to a dummy value (which is valid and writable by user - say /tmp).&lt;/p&gt;

&lt;p&gt;+CC &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=WeiqingYang&quot; class=&quot;user-hover&quot; rel=&quot;WeiqingYang&quot;&gt;WeiqingYang&lt;/a&gt; &lt;/p&gt;
</comment>
                            <comment id="16135545" author="szhemzhitsky" created="Mon, 21 Aug 2017 18:23:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mridulm80&quot; class=&quot;user-hover&quot; rel=&quot;mridulm80&quot;&gt;mridulm80&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=WeiqingYang&quot; class=&quot;user-hover&quot; rel=&quot;WeiqingYang&quot;&gt;WeiqingYang&lt;/a&gt; does it make sense to implement the provided workaround with valid and writable directory just within SparkHadoopMapRedceWriter if the needed property is not set, to prevent affecting all the jobs which don&apos;t write to hdfs, at least until there is a better solution?&lt;/p&gt;</comment>
                            <comment id="16171393" author="stevel@apache.org" created="Tue, 19 Sep 2017 09:24:53 +0000"  >&lt;p&gt;Linking to &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-20045&quot; title=&quot;Make sure SparkHadoopMapReduceWriter is resilient to failures of writers and committers&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-20045&quot;&gt;&lt;del&gt;SPARK-20045&lt;/del&gt;&lt;/a&gt;, which highlights the commit logic, especially the abort code, needs to be resilient to failures, including that of the invoked &lt;tt&gt;OutputCommitter.abort()&lt;/tt&gt; calls from raising exceptions. While people implementing committers should be expected to write resilient abort routines, you can&apos;t rely on it. Same for calling fs.delete()...it could also fall, so wrapping everything in an exception handler would at least make abort resilient.&lt;/p&gt;</comment>
                            <comment id="16171420" author="stevel@apache.org" created="Tue, 19 Sep 2017 09:43:06 +0000"  >&lt;ol&gt;
	&lt;li&gt;you can&apos;t rely on the committers having output and temp dirs. Subclasses of &lt;tt&gt;FileOutputCommitter&lt;/tt&gt; &lt;b&gt;must&lt;/b&gt;, though there&apos;s no official mechanism for querying that because &lt;tt&gt;getOutputPath()&lt;/tt&gt; is private.&lt;/li&gt;
	&lt;li&gt;Hadoop 3.0 has added (&lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-6956&quot; title=&quot;FileOutputCommitter to gain abstract superclass PathOutputCommitter&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-6956&quot;&gt;&lt;del&gt;MAPREDUCE-6956&lt;/del&gt;&lt;/a&gt;) a new superclass of &lt;tt&gt;FileOutputCommitter&lt;/tt&gt;, [PathOutputCommitter|&lt;a href=&quot;https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/PathOutputCommitter.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/output/PathOutputCommitter.java&lt;/a&gt; which pulls up getWorkingDir method to be more general (so that you can have output committers which tell spark and hive where their intermediate data should go, without them being subclasses of FileOutputCommitter.&lt;/li&gt;
	&lt;li&gt;I&apos;m happy to pull up &lt;tt&gt;getOutputPath&lt;/tt&gt; to that class, and if people can give me a patch for it &lt;b&gt;this week&lt;/b&gt; I&apos;ll add it for 3.0 beta 1.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Regarding the committer here, you might want to think of moving off/subclassing &lt;tt&gt;HadoopMapReduceCommitProtocol&lt;/tt&gt;. This is what I&apos;ve done in &lt;a href=&quot;https://github.com/hortonworks-spark/cloud-integration/blob/master/spark-cloud-integration/src/main/scala/com/hortonworks/spark/cloud/PathOutputCommitProtocol.scala&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;PathOutputCommitProtoco&lt;/a&gt;, though I can see it&apos;s still relying on the superclass to get that properly. Again, if we can patch the new PathOutputCommitter class for a getOutputPath I use that here. And yes, while that new mapreduce will take a long time to surface in spark core, you can use it independently, from later this year..&lt;/p&gt;

&lt;p&gt;If you are playing with different committers out of spark&apos;s own codebase, pick up the the ORC hive tests from &lt;a href=&quot;https://github.com/hortonworks-spark/cloud-integration/tree/master/cloud-examples/src/test/scala/org/apache/spark/sql/sources&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/hortonworks-spark/cloud-integration/tree/master/cloud-examples/src/test/scala/org/apache/spark/sql/sources&lt;/a&gt;. These are just some of the spark sql tests reworked slightly so that they&apos;ll work with any FileSystem impl. rather than just local &lt;a href=&quot;file://&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file://&lt;/a&gt; paths&lt;/p&gt;

&lt;p&gt;Ping me direct if you are playing with new committers, &amp;amp; look at &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-6823&quot; title=&quot;FileOutputFormat to support configurable PathOutputCommitter factory&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-6823&quot;&gt;&lt;del&gt;MAPREDUCE-6823&lt;/del&gt;&lt;/a&gt; to see if that&apos;d be useful to you (&amp;amp; how it could be improved, given its still not in the codebase)&lt;/p&gt;
</comment>
                            <comment id="16173175" author="apachespark" created="Wed, 20 Sep 2017 13:29:04 +0000"  >&lt;p&gt;User &apos;szhem&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19294&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19294&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16173184" author="szhemzhitsky" created="Wed, 20 Sep 2017 13:38:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mridulm80&quot; class=&quot;user-hover&quot; rel=&quot;mridulm80&quot;&gt;mridulm80&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=WeiqingYang&quot; class=&quot;user-hover&quot; rel=&quot;WeiqingYang&quot;&gt;WeiqingYang&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt;, &lt;/p&gt;

&lt;p&gt;I&apos;ve implemented the fix in this PR (&lt;a href=&quot;https://github.com/apache/spark/pull/19294&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19294&lt;/a&gt;), which sets user&apos;s current working directory (which is typically her home directory in case of distributed filesystems) as output directory.&lt;/p&gt;

&lt;p&gt;The patch allows using OutputFormats which write to external systems, databases, etc. by means of RDD API.&lt;br/&gt;
I far as I understand the requirement for output paths to be specified is only necessary to allow files to be committed to an absolute output location, that is not the case for output formats which write data to external systems. &lt;br/&gt;
So using user&apos;s working directory for such situations seems to be ok.&lt;/p&gt;
</comment>
                            <comment id="16173449" author="stevel@apache.org" created="Wed, 20 Sep 2017 16:29:30 +0000"  >&lt;p&gt;The &lt;tt&gt;newTaskTempFileAbsPath()&lt;/tt&gt; method is an interesting spot of code...I&apos;m still trying to work out when it is actually used. Some committers like &lt;tt&gt;ManifestFileCommitProtocol&lt;/tt&gt; don&apos;t support it all. &lt;/p&gt;

&lt;p&gt;However, if it is used, then your patch is going to cause problems if the dest FS != the default FS, because then the bit of the protocol which takes that list of temp files and renames() them into their destination is going to fail. I think you&apos;d be better off having the committer fail fast when an absolute path is asked for&lt;/p&gt;</comment>
                            <comment id="16173755" author="szhemzhitsky" created="Wed, 20 Sep 2017 20:05:52 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt; I&apos;ve updated PR to prevent using FileSystems at all. &lt;br/&gt;
Instead, there is just an additional check whether there are absolute files to rename during commit.&lt;/p&gt;</comment>
                            <comment id="16195563" author="mridulm80" created="Sat, 7 Oct 2017 03:46:25 +0000"  >&lt;p&gt;Issue resolved by pull request 19294&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19294&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19294&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16202865" author="apachespark" created="Fri, 13 Oct 2017 00:29:03 +0000"  >&lt;p&gt;User &apos;mridulm&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19487&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19487&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16204504" author="apachespark" created="Sat, 14 Oct 2017 06:24:04 +0000"  >&lt;p&gt;User &apos;mridulm&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/19497&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/19497&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13057870">SPARK-20045</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13103203">MAPREDUCE-6961</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 5 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3i3if:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>