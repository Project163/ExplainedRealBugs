<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:49:13 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-18353] spark.rpc.askTimeout defalut value is not 120s</title>
                <link>https://issues.apache.org/jira/browse/SPARK-18353</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;in &lt;a href=&quot;http://spark.apache.org/docs/latest/configuration.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://spark.apache.org/docs/latest/configuration.html&lt;/a&gt; &lt;br/&gt;
spark.rpc.askTimeout  120s	Duration for an RPC ask operation to wait before timing out&lt;br/&gt;
the defalut value is 120s as documented.&lt;/p&gt;

&lt;p&gt;However when I run &quot;spark-summit&quot; with standalone cluster mode:&lt;br/&gt;
the cmd is:&lt;br/&gt;
Launch Command: &quot;/opt/jdk1.8.0_102/bin/java&quot; &quot;-cp&quot; &quot;/opt/spark-2.0.1-bin-hadoop2.7/conf/:/opt/spark-2.0.1-bin-hadoop2.7/jars/*&quot; &quot;-Xmx1024M&quot; &quot;-Dspark.eventLog.enabled=true&quot; &quot;-Dspark.master=spark://9.111.159.127:7101&quot; &quot;-Dspark.driver.supervise=false&quot; &quot;-Dspark.app.name=org.apache.spark.examples.SparkPi&quot; &quot;-Dspark.submit.deployMode=cluster&quot; &quot;-Dspark.jars=&lt;a href=&quot;file:/opt/spark-1.6.1-bin-hadoop2.6/lib/spark-examples-1.6.1-hadoop2.6.0.jar&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/opt/spark-1.6.1-bin-hadoop2.6/lib/spark-examples-1.6.1-hadoop2.6.0.jar&lt;/a&gt;&quot; &quot;-Dspark.history.ui.port=18087&quot; &quot;-Dspark.rpc.askTimeout=10&quot; &quot;-Dspark.history.fs.logDirectory=&lt;a href=&quot;file:/opt/tmp/spark-event&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:/opt/tmp/spark-event&lt;/a&gt;&quot; &quot;-Dspark.eventLog.dir=&lt;a href=&quot;file:///opt/tmp/spark-event&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;file:///opt/tmp/spark-event&lt;/a&gt;&quot; &quot;org.apache.spark.deploy.worker.DriverWrapper&quot; &quot;spark://Worker@9.111.159.127:7103&quot; &quot;/opt/spark-2.0.1-bin-hadoop2.7/work/driver-20161109031939-0002/spark-examples-1.6.1-hadoop2.6.0.jar&quot; &quot;org.apache.spark.examples.SparkPi&quot; &quot;1000&quot;&lt;/p&gt;

&lt;p&gt;Dspark.rpc.askTimeout=10&lt;/p&gt;

&lt;p&gt;the value is 10, it is not the same as document.&lt;/p&gt;

&lt;p&gt;Note: when I summit to REST URL, it has no this issue.&lt;/p&gt;
</description>
                <environment>&lt;p&gt;Linux zzz 3.10.0-327.el7.x86_64 #1 SMP Thu Oct 29 17:29:29 EDT 2015 x86_64 x86_64 x86_64 GNU/Linux&lt;/p&gt;</environment>
        <key id="13019129">SPARK-18353</key>
            <summary>spark.rpc.askTimeout defalut value is not 120s</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="srowen">Sean R. Owen</assignee>
                                    <reporter username="JasonPan">Jason Pan</reporter>
                        <labels>
                    </labels>
                <created>Tue, 8 Nov 2016 07:24:22 +0000</created>
                <updated>Sat, 19 Nov 2016 11:29:02 +0000</updated>
                            <resolved>Sat, 19 Nov 2016 11:28:52 +0000</resolved>
                                    <version>1.6.1</version>
                    <version>2.0.1</version>
                                    <fixVersion>2.1.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15646795" author="jasonpan" created="Tue, 8 Nov 2016 07:39:07 +0000"  >&lt;p&gt;in org.apache.spark.deploy.Client,&lt;br/&gt;
there is one line:&lt;br/&gt;
conf.set(&quot;spark.rpc.askTimeout&quot;, &quot;10&quot;)&lt;/p&gt;

&lt;p&gt;should we remove this line?&lt;/p&gt;

&lt;p&gt;when use rest:&lt;br/&gt;
in org.apache.spark.deploy.rest.RestSubmissionClient , there is no this line.&lt;/p&gt;</comment>
                            <comment id="15647487" author="srowen" created="Tue, 8 Nov 2016 12:54:12 +0000"  >&lt;p&gt;It does seem like Client should not set this value to 10, given the docs and the rest of the code. That could be removed. Also, spark.rpc.askTimeout doesn&apos;t actually default to 120s, but defaults to spark.network.timeout, which defaults to 120s. It could be worth updating the docs for the several properties that also have this default.&lt;/p&gt;</comment>
                            <comment id="15647623" author="jasonpan" created="Tue, 8 Nov 2016 13:53:27 +0000"  >&lt;p&gt;Thanks.&lt;/p&gt;

&lt;p&gt;Yes, if spark.rpc.askTimeout is not configured, will use the value of spark.network.timeout. &lt;br/&gt;
The hard code in Client make behavior inconsistent with document, in addition, when we use &quot;--conf spark.rpc.askTimeout=&quot; in spark-summit command or set it in spark-default.conf, it will not take effect due to it is configured in org.apache.spark.deploy.Client, when the network is busy, we can have no way to increase the rpc ascTimeout.&lt;/p&gt;</comment>
                            <comment id="15651584" author="apachespark" created="Wed, 9 Nov 2016 17:57:06 +0000"  >&lt;p&gt;User &apos;srowen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15833&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15833&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15651807" author="srowen" created="Wed, 9 Nov 2016 19:21:31 +0000"  >&lt;p&gt;BTW &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=JasonPan&quot; class=&quot;user-hover&quot; rel=&quot;JasonPan&quot;&gt;JasonPan&lt;/a&gt; it looks like you&apos;re setting JVM props, and not using --conf ? does --conf make it work?&lt;/p&gt;</comment>
                            <comment id="15652543" author="jasonpan" created="Thu, 10 Nov 2016 00:48:13 +0000"  >&lt;p&gt;Hi Sean.&lt;/p&gt;

&lt;p&gt;I was using &quot;--conf&quot; to set the parameter when summit. It didn&apos;t work.&lt;/p&gt;</comment>
                            <comment id="15652576" author="jasonpan" created="Thu, 10 Nov 2016 01:06:29 +0000"  >&lt;p&gt;append the summit command:&lt;/p&gt;

&lt;p&gt;spark-submit --class org.apache.spark.examples.SparkPi --master spark://9.111.159.127:7101 --conf  spark.rpc.askTimeout=150 --deploy-mode cluster /opt/spark-1.6.1-bin-hadoop2.6/lib/spark-examples-1.6.1-hadoop2.6.0.jar 100000&lt;br/&gt;
the parameter doesn&apos;t work.&lt;/p&gt;

&lt;p&gt;Use rest: (6068 port is for rest)&lt;br/&gt;
spark-submit --class org.apache.spark.examples.SparkPi --master spark://9.111.159.127:6068 --conf  spark.rpc.askTimeout=150 --deploy-mode cluster /opt/spark-1.6.1-bin-hadoop2.6/lib/spark-examples-1.6.1-hadoop2.6.0.jar 100000&lt;br/&gt;
the parameter works.&lt;/p&gt;

&lt;p&gt;We now summit to rest url for a workaround, otherwise,  the &quot;spark.rpc.askTimeout&quot; is always 10 due to the hardcode.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;</comment>
                            <comment id="15652585" author="jasonpan" created="Thu, 10 Nov 2016 01:11:22 +0000"  >&lt;p&gt;No matter what the default value is at last,  I think we need a way to configure it.&lt;/p&gt;</comment>
                            <comment id="15653793" author="srowen" created="Thu, 10 Nov 2016 11:15:54 +0000"  >&lt;p&gt;Let me know what you think of the pull requests at &lt;a href=&quot;https://github.com/apache/spark/pull/15833&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15833&lt;/a&gt; &amp;#8211; does it reflect your understanding?&lt;/p&gt;</comment>
                            <comment id="15656029" author="jasonpan" created="Fri, 11 Nov 2016 03:46:21 +0000"  >&lt;p&gt;Yes, The pull requests make it can be set at least.&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
</comment>
                            <comment id="15656836" author="srowen" created="Fri, 11 Nov 2016 11:30:26 +0000"  >&lt;p&gt;Any chance you can actually try a build with the patch? or comment on the PR? there&apos;s a question about whether this actually addresses your issue.&lt;/p&gt;</comment>
                            <comment id="15672312" author="jasonpan" created="Thu, 17 Nov 2016 01:13:41 +0000"  >&lt;p&gt;Thanks sean. It works. &lt;/p&gt;

&lt;p&gt;Just for the doc: &quot;&amp;lt;td&amp;gt;&amp;lt;code&amp;gt;spark.network.timeout&amp;lt;/code&amp;gt;, or 10s in standalone clusters&amp;lt;/td&amp;gt;&quot;&lt;br/&gt;
Actually the default is not 10s in standalone when using rest.&lt;/p&gt;</comment>
                            <comment id="15679095" author="srowen" created="Sat, 19 Nov 2016 11:28:52 +0000"  >&lt;p&gt;Issue resolved by pull request 15833&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/15833&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/15833&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i361zj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>