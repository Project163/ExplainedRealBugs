<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:03:49 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-26680] StackOverflowError if Stream passed to groupBy</title>
                <link>https://issues.apache.org/jira/browse/SPARK-26680</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;This Java code results in a StackOverflowError:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
List&amp;lt;Column&amp;gt; groupByCols = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;();
groupByCols.add(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Column(&lt;span class=&quot;code-quote&quot;&gt;&quot;id1&quot;&lt;/span&gt;));
scala.collection.Seq&amp;lt;Column&amp;gt; groupByColsSeq =
    JavaConverters.asScalaIteratorConverter(groupByCols.iterator())
        .asScala().toSeq();
df.groupBy(groupByColsSeq).max(&lt;span class=&quot;code-quote&quot;&gt;&quot;id2&quot;&lt;/span&gt;).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;id1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;id2&quot;&lt;/span&gt;).show();
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The &lt;tt&gt;toSeq&lt;/tt&gt; method above produces a Stream. Passing a Stream to groupBy results in the StackOverflowError. In fact, the error can be produced more easily in spark-shell:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;scala&amp;gt; val df = spark.read.schema(&quot;id1 int, id2 int&quot;).csv(&quot;testinput.csv&quot;)
df: org.apache.spark.sql.DataFrame = [id1: int, id2: int]
scala&amp;gt; val groupBySeq = Stream(col(&quot;id1&quot;))
groupBySeq: scala.collection.immutable.Stream[org.apache.spark.sql.Column] = Stream(id1, ?)
scala&amp;gt; df.groupBy(groupBySeq: _*).max(&quot;id2&quot;).toDF(&quot;id1&quot;, &quot;id2&quot;).collect
java.lang.StackOverflowError
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1161)
  at scala.collection.immutable.Stream.drop(Stream.scala:797)
  at scala.collection.immutable.Stream.drop(Stream.scala:204)
  at scala.collection.LinearSeqOptimized.apply(LinearSeqOptimized.scala:66)
  at scala.collection.LinearSeqOptimized.apply$(LinearSeqOptimized.scala:65)
  at scala.collection.immutable.Stream.apply(Stream.scala:204)
  at org.apache.spark.sql.catalyst.expressions.BoundReference.doGenCode(BoundAttribute.scala:45)
  at org.apache.spark.sql.catalyst.expressions.Expression.$anonfun$genCode$3(Expression.scala:138)
  at scala.Option.getOrElse(Option.scala:138)
  at org.apache.spark.sql.catalyst.expressions.Expression.genCode(Expression.scala:133)
  at org.apache.spark.sql.execution.CodegenSupport.$anonfun$consume$3(WholeStageCodegenExec.scala:159)
  at scala.collection.immutable.Stream.$anonfun$map$1(Stream.scala:418)
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1171)
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1161)
  at scala.collection.immutable.Stream.drop(Stream.scala:797)
  at scala.collection.immutable.Stream.drop(Stream.scala:204)
  at scala.collection.LinearSeqOptimized.apply(LinearSeqOptimized.scala:66)
  at scala.collection.LinearSeqOptimized.apply$(LinearSeqOptimized.scala:65)
  at scala.collection.immutable.Stream.apply(Stream.scala:204)
  at org.apache.spark.sql.catalyst.expressions.BoundReference.doGenCode(BoundAttribute.scala:45)
  at org.apache.spark.sql.catalyst.expressions.Expression.$anonfun$genCode$3(Expression.scala:138)
  at scala.Option.getOrElse(Option.scala:138)
  at org.apache.spark.sql.catalyst.expressions.Expression.genCode(Expression.scala:133)
  at org.apache.spark.sql.execution.CodegenSupport.$anonfun$consume$3(WholeStageCodegenExec.scala:159)
...etc...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is due to the lazy nature of Streams. The method &lt;tt&gt;consume&lt;/tt&gt; in &lt;tt&gt;CodegenSupport&lt;/tt&gt; assumes that a map function will be eagerly evaluated:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
val inputVars =
        ctx.currentVars = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; &amp;lt;== the closure cares about &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;
        ctx.INPUT_ROW = row
        output.zipWithIndex.map { &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (attr, i) =&amp;gt;
          BoundReference(i, attr.dataType, attr.nullable).genCode(ctx)
-
-
-
    ctx.currentVars = inputVars
    ctx.INPUT_ROW = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
    ctx.freshNamePrefix = parent.variablePrefix
    val evaluated = evaluateRequiredVariables(output, inputVars, parent.usedInputs)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The closure passed to the map function assumes &lt;tt&gt;ctx.currentVars&lt;/tt&gt; will be set to null. But due to lazy evaluation, &lt;tt&gt;ctx.currentVars&lt;/tt&gt; is set to something else by the time the closure is actually called. Worse yet, &lt;tt&gt;ctx.currentVars&lt;/tt&gt; is set to the yet-to-be evaluated inputVars stream. The closure uses &lt;tt&gt;ctx.currentVars&lt;/tt&gt; (via the call &lt;tt&gt;genCode(ctx)&lt;/tt&gt;),&#160;therefore it ends up using the data structure it is attempting to create.&lt;/p&gt;

&lt;p&gt;You can recreate the problem is a&#160;vanilla&#160;Scala shell:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; p1: Seq[Any] = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
p1: Seq[Any] = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
scala&amp;gt; val s = Stream(1, 2).zipWithIndex.map { &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (x, i) =&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (p1 != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) p1(i) &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; x }
s: scala.collection.immutable.Stream[Any] = Stream(1, ?)
scala&amp;gt; p1 = s
p1: Seq[Any] = Stream(1, ?)
scala&amp;gt; s.foreach(println)
1
java.lang.StackOverflowError
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1166)
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1159)
  at scala.collection.immutable.Stream.$anonfun$map$1(Stream.scala:415)
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1169)
  at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1159)
... etc ...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Possible fixes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In &lt;tt&gt;DataSet.groupBy&lt;/tt&gt;, we could ensure the passed Seq is a List&#160;before passing it to RelationalGroupedDataset (simply by changing &lt;tt&gt;cols.map(&lt;em&gt;.expr)&lt;/tt&gt; to &lt;tt&gt;cols.toList.map(&lt;/em&gt;.expr)&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;In &lt;tt&gt;CodegenSupport.consume&lt;/tt&gt;, we could ensure that the map function is eagerly evaluated (simply by moving the existing match statement to handle the result from either path of the if statement).&lt;/li&gt;
	&lt;li&gt;Something else that hasn&apos;t occurred to me (opinions welcome).&lt;/li&gt;
&lt;/ul&gt;
</description>
                <environment></environment>
        <key id="13210853">SPARK-26680</key>
            <summary>StackOverflowError if Stream passed to groupBy</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bersprockets">Bruce Robbins</assignee>
                                    <reporter username="bersprockets">Bruce Robbins</reporter>
                        <labels>
                    </labels>
                <created>Mon, 21 Jan 2019 23:48:48 +0000</created>
                <updated>Tue, 27 Oct 2020 11:02:33 +0000</updated>
                            <resolved>Thu, 24 Jan 2019 10:23:11 +0000</resolved>
                                    <version>2.3.2</version>
                    <version>2.4.0</version>
                    <version>3.0.0</version>
                                    <fixVersion>2.3.3</fixVersion>
                    <fixVersion>2.4.1</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16748277" author="bersprockets" created="Mon, 21 Jan 2019 23:52:16 +0000"  >&lt;p&gt;I will make a PR for this, but I would like to&#160;hear any suggested solutions beyond the two that I proposed above.&lt;/p&gt;</comment>
                            <comment id="16748811" author="apachespark" created="Tue, 22 Jan 2019 15:07:09 +0000"  >&lt;p&gt;User &apos;bersprockets&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/23617&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/23617&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13337398">SPARK-33260</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 43 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|yi05c0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>