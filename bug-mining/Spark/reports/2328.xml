<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:31:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-7837] NPE when save as parquet in speculative tasks</title>
                <link>https://issues.apache.org/jira/browse/SPARK-7837</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The query is like &lt;tt&gt;df.orderBy(...).saveAsTable(...)&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;When there is no partitioning columns and there is a skewed key, I found the following exception in speculative tasks. After these failures, seems we could not call &lt;tt&gt;SparkHadoopMapRedUtil.commitTask&lt;/tt&gt; correctly.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.lang.NullPointerException
	at parquet.hadoop.InternalParquetRecordWriter.flushRowGroupToStore(InternalParquetRecordWriter.java:146)
	at parquet.hadoop.InternalParquetRecordWriter.close(InternalParquetRecordWriter.java:112)
	at parquet.hadoop.ParquetRecordWriter.close(ParquetRecordWriter.java:73)
	at org.apache.spark.sql.parquet.ParquetOutputWriter.close(newParquet.scala:115)
	at org.apache.spark.sql.sources.DefaultWriterContainer.abortTask(commands.scala:385)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation.org$apache$spark$sql$sources$InsertIntoHadoopFsRelation$$writeRows$1(commands.scala:150)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation$$anonfun$insert$1.apply(commands.scala:122)
	at org.apache.spark.sql.sources.InsertIntoHadoopFsRelation$$anonfun$insert$1.apply(commands.scala:122)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63)
	at org.apache.spark.scheduler.Task.run(Task.scala:70)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12832306">SPARK-7837</key>
            <summary>NPE when save as parquet in speculative tasks</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lian cheng">Cheng Lian</assignee>
                                    <reporter username="yhuai">Yin Huai</reporter>
                        <labels>
                    </labels>
                <created>Sat, 23 May 2015 00:15:37 +0000</created>
                <updated>Thu, 21 Jul 2022 12:46:17 +0000</updated>
                            <resolved>Mon, 17 Aug 2015 16:59:56 +0000</resolved>
                                    <version>1.4.0</version>
                                    <fixVersion>1.5.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="14563977" author="yhuai" created="Fri, 29 May 2015 00:25:41 +0000"  >&lt;p&gt;We have made the parquet reader side robust to files left in _temporary. So, this problem should have a much smaller impact. &lt;/p&gt;

&lt;p&gt;I am re-targeting it to 1.5. Will keep an eye on it and investigate the root cause.&lt;/p&gt;</comment>
                            <comment id="14587491" author="yhuai" created="Tue, 16 Jun 2015 05:12:22 +0000"  >&lt;p&gt;Seems &lt;a href=&quot;https://www.mail-archive.com/user@spark.apache.org/msg30327.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.mail-archive.com/user@spark.apache.org/msg30327.html&lt;/a&gt; is about the same issue.&lt;/p&gt;</comment>
                            <comment id="14628020" author="mkanchwala" created="Wed, 15 Jul 2015 13:04:20 +0000"  >&lt;p&gt;Facing the Same Issue at my End, I am processing around 68TB of data and transforming it to Parquet and I am also facing it. And this App is on Production, will really like it be resolved on highest priority in 1.5.0.&lt;/p&gt;

&lt;p&gt;Thanks Guys&lt;/p&gt;</comment>
                            <comment id="14628171" author="yhuai" created="Wed, 15 Jul 2015 14:48:43 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mkanchwala&quot; class=&quot;user-hover&quot; rel=&quot;mkanchwala&quot;&gt;mkanchwala&lt;/a&gt; One quick clarification question. Did your spark job fail because of the NPE? Or, your job succeeded but you saw the NPE in some speculative tasks? &lt;/p&gt;</comment>
                            <comment id="14628338" author="mkanchwala" created="Wed, 15 Jul 2015 16:46:07 +0000"  >&lt;p&gt;Job Succeeded But shown NPE, I am worried about any data loss between this transformation&lt;/p&gt;</comment>
                            <comment id="14628370" author="mkanchwala" created="Wed, 15 Jul 2015 17:10:03 +0000"  >&lt;p&gt;Also I notice that I completed my transformation to Parquet but after the job completion it is taking too much time to save the data to s3.&lt;/p&gt;

&lt;p&gt;Input : s3://&amp;lt;same-bucket&amp;gt;/input&lt;br/&gt;
Output : s3://&amp;lt;same-bucket&amp;gt;/output&lt;/p&gt;

&lt;p&gt;I have around 27K files and it is writing the data at a speed of 1k / 20 mins and my job completed in an hour, can you share the details with me why it&apos;s so slow for parquet?&lt;/p&gt;</comment>
                            <comment id="14628467" author="yhuai" created="Wed, 15 Jul 2015 18:05:09 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mkanchwala&quot; class=&quot;user-hover&quot; rel=&quot;mkanchwala&quot;&gt;mkanchwala&lt;/a&gt; There is a bug (&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-8406&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SPARK-8406&lt;/a&gt;), which potentially may cause data loss for a large job. Please use Spark 1.4.1 as soon as it is released (I think today or tomorrow) or manually apply the fix (&lt;a href=&quot;https://github.com/nemccarthy/spark/commit/ba365909b964fe5a5851d88f5f7b7edcd1998142&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/nemccarthy/spark/commit/ba365909b964fe5a5851d88f5f7b7edcd1998142&lt;/a&gt;) to your Spark 1.4.0 source code.&lt;/p&gt;

&lt;p&gt;Regarding the slowness of saving parquet files in S3, a possible cause is that Parquet&apos;s original output committer (&lt;tt&gt;org.apache.parquet.hadoop.ParquetOutputCommitter&lt;/tt&gt;) will first write data in the temporary dir and then move them to the right place when it commits tasks. This behavior is not necessary in most of the cases for S3 because &quot;S3 supports multiple writers outputting to the same file, where visibility is guaranteed to be atomic&quot; (&lt;a href=&quot;https://gist.github.com/aarondav/c513916e72101bbe14ec&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/aarondav/c513916e72101bbe14ec&lt;/a&gt;). Once you upgrade to Spark 1.4.1, you can set &lt;tt&gt;spark.sql.parquet.output.committer.class&lt;/tt&gt; to &lt;tt&gt;org.apache.spark.sql.parquet.DirectParquetOutputCommitter&lt;/tt&gt; in your hadoop conf, which will write output files directly to their final locations. The only case that is not safe to use DirectParquetOutputCommitter is when you append data to an existing table. In this case, Spark 1.4.1 will internally switch back to the original Parquet output committer.&lt;/p&gt;</comment>
                            <comment id="14628499" author="mkanchwala" created="Wed, 15 Jul 2015 18:23:14 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yhuai&quot; class=&quot;user-hover&quot; rel=&quot;yhuai&quot;&gt;yhuai&lt;/a&gt; for the update. Will be looking forward on Spark 1.4.1 release. Also I&apos;ve filed a seperate issue to the Parent Bug as &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-9072&quot; title=&quot;Parquet : Writing data to S3 very slowly&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-9072&quot;&gt;&lt;del&gt;SPARK-9072&lt;/del&gt;&lt;/a&gt; : Parquet : Writing data to S3 very slowly . Can you plan this and make the neccessary changes for the Same.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
</comment>
                            <comment id="14697724" author="yhuai" created="Fri, 14 Aug 2015 20:46:25 +0000"  >&lt;p&gt;When speculation is on, I can reproduce it every time I run&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.parallelize((1 to 100), 20).map { i =&amp;gt;
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (i == 4 || i == 29) &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(10000) &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(100)
  i
}.map(i =&amp;gt; Tuple1(i)).toDF(&lt;span class=&quot;code-quote&quot;&gt;&quot;i&quot;&lt;/span&gt;).write.mode(&lt;span class=&quot;code-quote&quot;&gt;&quot;overwrite&quot;&lt;/span&gt;).format(&lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;).save(&lt;span class=&quot;code-quote&quot;&gt;&quot;/home/yin/outputCommitter&quot;&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14698767" author="lian cheng" created="Sun, 16 Aug 2015 17:20:26 +0000"  >&lt;p&gt;Just a note to people who want to reproduce this issue:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;You need to start a Spark cluster with at least two workers running on two distinct nodes. Speculation isn&apos;t enabled when running in local mode or single node cluster. If you only have a single machine, you&apos;ll probably have to resort to VMs&lt;/li&gt;
	&lt;li&gt;Don&apos;t forget to set &lt;tt&gt;spark.speculation&lt;/tt&gt; to &lt;tt&gt;true&lt;/tt&gt; (it&apos;s &lt;tt&gt;false&lt;/tt&gt; by default)&lt;/li&gt;
&lt;/ol&gt;
</comment>
                            <comment id="14698949" author="yhuai" created="Mon, 17 Aug 2015 02:54:09 +0000"  >&lt;p&gt;ah i see the reason of the NPE. We actually called close twice. In DefaultWriterContainer&apos;s writeRows, we start to write out rows and at the end we call commitTask. In commitTask, we first call writer.close and then we call super.commitTask(). In writer.close, we triggered ParquetRecordWriter&apos;s close, which sets columnStore to null. Then, because the speculative task&apos;s commit is rejected (i.e. super.commitTask() is rejected by OutputCommitCoordinator), we cal labortTask, which triggers writer.close again. Inside writer.close we call ParquetRecordWriter&apos;s close and then we get NPE because columnStore is already set to null.&lt;/p&gt;</comment>
                            <comment id="14699036" author="lian cheng" created="Mon, 17 Aug 2015 05:37:31 +0000"  >&lt;p&gt;Good job!&lt;/p&gt;</comment>
                            <comment id="14699280" author="apachespark" created="Mon, 17 Aug 2015 09:43:03 +0000"  >&lt;p&gt;User &apos;liancheng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8236&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8236&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14699817" author="lian cheng" created="Mon, 17 Aug 2015 16:59:56 +0000"  >&lt;p&gt;Issue resolved by pull request 8236&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8236&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8236&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14699944" author="yhuai" created="Mon, 17 Aug 2015 18:01:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mkanchwala&quot; class=&quot;user-hover&quot; rel=&quot;mkanchwala&quot;&gt;mkanchwala&lt;/a&gt; Based on our investigate, the NPE was caused by calling &lt;tt&gt;close&lt;/tt&gt; of a Parquet record writer twice. The first time we call &lt;tt&gt;close&lt;/tt&gt;, parquet sets &lt;tt&gt;columnStore&lt;/tt&gt; (an parquet internal variable) to null and the second time we call &lt;tt&gt;close&lt;/tt&gt;, the NPE is triggered.&lt;/p&gt;

&lt;p&gt;This issue does not cause data loss.&lt;/p&gt;</comment>
                            <comment id="17569397" author="apachespark" created="Thu, 21 Jul 2022 12:45:22 +0000"  >&lt;p&gt;User &apos;LuciferYang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/37245&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/37245&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17569399" author="apachespark" created="Thu, 21 Jul 2022 12:46:17 +0000"  >&lt;p&gt;User &apos;LuciferYang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/37245&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/37245&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310060">
                    <name>Container</name>
                                                                <inwardlinks description="Is contained by">
                                        <issuelink>
            <issuekey id="12845347">SPARK-9072</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 16 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2f4pz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12332078">1.5.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>