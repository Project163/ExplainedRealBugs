<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:47:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-17261] Using HiveContext after re-creating SparkContext in Spark 2.0 throws &quot;Java.lang.illegalStateException: Cannot call methods on a stopped sparkContext&quot;</title>
                <link>https://issues.apache.org/jira/browse/SPARK-17261</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;After stopping SparkSession if we recreate it and use HiveContext in it. it will throw error.&lt;/p&gt;

&lt;p&gt;Steps to reproduce:&lt;br/&gt;
spark = SparkSession.builder.enableHiveSupport().getOrCreate()&lt;br/&gt;
spark.sql(&quot;show databases&quot;)&lt;br/&gt;
spark.stop()&lt;br/&gt;
spark = SparkSession.builder.enableHiveSupport().getOrCreate()&lt;br/&gt;
spark.sql(&quot;show databases&quot;)&lt;/p&gt;



&lt;p&gt;&quot;Java.lang.illegalStateException: Cannot call methods on a stopped sparkContext&quot;&lt;/p&gt;

&lt;p&gt;Above error occurs only in case of Pyspark not in SparkShell&lt;/p&gt;</description>
                <environment>&lt;p&gt;Amazon AWS EMR 5.0&lt;/p&gt;</environment>
        <key id="13000347">SPARK-17261</key>
            <summary>Using HiveContext after re-creating SparkContext in Spark 2.0 throws &quot;Java.lang.illegalStateException: Cannot call methods on a stopped sparkContext&quot;</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zjffdu">Jeff Zhang</assignee>
                                    <reporter username="rahuljain788">Rahul Jain</reporter>
                        <labels>
                    </labels>
                <created>Fri, 26 Aug 2016 11:48:16 +0000</created>
                <updated>Sat, 11 Mar 2017 20:45:04 +0000</updated>
                            <resolved>Fri, 2 Sep 2016 17:08:36 +0000</resolved>
                                    <version>2.0.0</version>
                                    <fixVersion>2.0.1</fixVersion>
                    <fixVersion>2.1.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15438838" author="srowen" created="Fri, 26 Aug 2016 11:56:33 +0000"  >&lt;p&gt;I think that&apos;s as intended. The context is actually pretty global. I don&apos;t think you are getting a different one. &lt;/p&gt;</comment>
                            <comment id="15438918" author="rahuljain788" created="Fri, 26 Aug 2016 13:19:46 +0000"  >&lt;p&gt;Thanks for replying, i am using the same commands in Spark-Shell and it works pretty fine. &lt;br/&gt;
In case of pyspark i am not actually able to access hive metastore but SQLContext works fine.&lt;/p&gt;</comment>
                            <comment id="15439613" author="dongjoon" created="Fri, 26 Aug 2016 19:14:36 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dakghar&quot; class=&quot;user-hover&quot; rel=&quot;dakghar&quot;&gt;dakghar&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For me, those seems not to work even in `spark-shell`. Could you add a `show` at the end? I tested and got the same result in 2.0.0 and current master branch.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.SparkSession
scala&amp;gt; val spark = SparkSession.builder.enableHiveSupport().getOrCreate()
scala&amp;gt; spark.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;show databases&quot;&lt;/span&gt;).show
+------------+
|databaseName|
+------------+
|     &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;|
+------------+

scala&amp;gt; spark.stop()
scala&amp;gt; val spark = SparkSession.builder.enableHiveSupport().getOrCreate()
scala&amp;gt; spark.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;show databases&quot;&lt;/span&gt;).show
16/08/26 12:09:22 ERROR Schema: Failed initialising database.
Unable to open a test connection to the given database. JDBC url = jdbc:derby:;databaseName=metastore_db;create=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, username = APP. Terminating connection pool (set lazyInit to &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; you expect to start your database after your app). Original Exception: ------
java.sql.SQLException: Failed to start database &lt;span class=&quot;code-quote&quot;&gt;&apos;metastore_db&apos;&lt;/span&gt; with &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@6b60d99c, see the next exception &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; details.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15444690" author="apachespark" created="Mon, 29 Aug 2016 03:40:05 +0000"  >&lt;p&gt;User &apos;zjffdu&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14857&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14857&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15444694" author="zjffdu" created="Mon, 29 Aug 2016 03:42:34 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=dongjoon&quot; class=&quot;user-hover&quot; rel=&quot;dongjoon&quot;&gt;dongjoon&lt;/a&gt; spark-shell works well for me. It seems your case is due to something else. &lt;/p&gt;</comment>
                            <comment id="15444961" author="rahuljain788" created="Mon, 29 Aug 2016 06:24:59 +0000"  >&lt;p&gt;i looked into &apos;zjffdu&apos; pull request and the changed code. From my understanding, this code change particularly addresses to SparkSession only and doesn&apos;t provide backward compatibility for previous spark version codes(Spark Context). I ran the below code in Spark 2.0 and it failed. &lt;/p&gt;

&lt;p&gt;&quot;&quot;&quot;&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; sc.stop()&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; sc._instantiatedContext = None&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; from  pyspark import SparkContext&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; from pyspark import HiveContext&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; sc = SparkContext()&lt;br/&gt;
16/08/29 06:20:18 WARN Utils: Service &apos;SparkUI&apos; could not bind on port 4040. Attempting port 4041.&lt;br/&gt;
16/08/29 06:20:18 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; sqlContext = HiveContext(sc)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; sqlContext.sql(&quot;show databases&quot;).collect()&lt;br/&gt;
Traceback (most recent call last):&lt;br/&gt;
  File &quot;&amp;lt;stdin&amp;gt;&quot;, line 1, in &amp;lt;module&amp;gt;&lt;br/&gt;
  File &quot;/usr/lib/spark/python/pyspark/sql/context.py&quot;, line 350, in sql&lt;br/&gt;
    return self.sparkSession.sql(sqlQuery)&lt;br/&gt;
  File &quot;/usr/lib/spark/python/pyspark/sql/session.py&quot;, line 541, in sql&lt;br/&gt;
    return DataFrame(self._jsparkSession.sql(sqlQuery), self._wrapped)&lt;br/&gt;
  File &quot;/usr/lib/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py&quot;, line 933, in _&lt;em&gt;call&lt;/em&gt;_&lt;br/&gt;
  File &quot;/usr/lib/spark/python/pyspark/sql/utils.py&quot;, line 63, in deco&lt;br/&gt;
    return f(*a, **kw)&lt;br/&gt;
  File &quot;/usr/lib/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py&quot;, line 312, in get_return_value&lt;br/&gt;
py4j.protocol.Py4JJavaError: An error occurred while calling o44.sql.&lt;br/&gt;
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.&lt;br/&gt;
This stopped SparkContext was created at:&lt;br/&gt;
&quot;&quot;&quot;&lt;/p&gt;</comment>
                            <comment id="15444981" author="zjffdu" created="Mon, 29 Aug 2016 06:39:06 +0000"  >&lt;p&gt;It works if you change &apos;sc._instantiatedContext = None&apos; to &apos;SparkSession._instantiatedContext = None&apos;.  The problem here is that SQLContext/HIveContext is created from SparkSession, although you create HiveContext, SparkSession will still be created first underneath. And here the SparkContext is stopped, but SparkSession don&apos;t know that, so it still use the stopped SparkContext. &lt;/p&gt;</comment>
                            <comment id="15459063" author="davies" created="Fri, 2 Sep 2016 17:08:38 +0000"  >&lt;p&gt;Issue resolved by pull request 14857&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14857&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14857&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15906305" author="apachespark" created="Sat, 11 Mar 2017 20:16:02 +0000"  >&lt;p&gt;User &apos;elviento&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17261&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17261&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15906309" author="apachespark" created="Sat, 11 Mar 2017 20:45:04 +0000"  >&lt;p&gt;User &apos;elviento&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17262&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17262&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 36 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i32uc7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>