<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:04:01 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-25158] Executor accidentally exit because ScriptTransformationWriterThread throws TaskKilledException.</title>
                <link>https://issues.apache.org/jira/browse/SPARK-25158</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;In production environment, user run Spark-Sql use transform features with config &apos;spark.speculation = true&apos;, sometimes job fails and we found many Executor Dead through `Executor Tab` of Spark ui and here are some relevant sample logs:&lt;/p&gt;

&lt;p&gt;Driver Side&#160; Log:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
18/08/14 16:17:52 INFO TaskSetManager: Starting task 2909.1 in stage 2.0 (TID 3929, executor.330, executor 7, partition 2909, PROCESS_LOCAL, 6791 bytes)
18/08/14 16:17:53 INFO TaskSetManager: Killing attempt 1 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; task 2909.1 in stage 2.0 (TID 3929) on executor.330 as the attempt 0 succeeded on executor.58
18/08/14 16:17:53 WARN TaskSetManager: Lost task 2909.1 in stage 2.0 (TID 3929, executor.330, executor 7): TaskKilled (killed intentionally)
18/08/14 16:17:53 INFO TaskSetManager: Task 2909.1 in stage 2.0 (TID 3929) failed, but another instance of the task has already succeeded, so not re-queuing the task to be re-executed.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Executor Side Log:&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
18/08/14 16:17:52 INFO Executor: Running task 2909.1 in stage 2.0 (TID 3929)
18/08/14 16:17:53 INFO Executor: Executor is trying to kill task 2909.1 in stage 2.0 (TID 3929)
18/08/14 16:17:53 ERROR ScriptTransformationWriterThread:
18/08/14 16:17:53 ERROR Utils: Uncaught exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-ScriptTransformation-Feed
org.apache.spark.TaskKilledException
at org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter$SortedIterator.loadNext(UnsafeInMemorySorter.java:295)
at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator.loadNext(UnsafeExternalSorter.java:573)
at org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:161)
at org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:148)
at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:380)
at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:893)
at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
at org.apache.spark.sql.hive.execution.ScriptTransformationWriterThread$$anonfun$run$1.apply$mcV$sp(ScriptTransformation.scala:289)
at org.apache.spark.sql.hive.execution.ScriptTransformationWriterThread$$anonfun$run$1.apply(ScriptTransformation.scala:278)
at org.apache.spark.sql.hive.execution.ScriptTransformationWriterThread$$anonfun$run$1.apply(ScriptTransformation.scala:278)
at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
at org.apache.spark.sql.hive.execution.ScriptTransformationWriterThread.run(ScriptTransformation.scala:278)
18/08/14 16:17:53 INFO Executor: Executor killed task 2909.1 in stage 2.0 (TID 3929)
18/08/14 16:17:53 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-ScriptTransformation-Feed,5,main]
org.apache.spark.TaskKilledException
at org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter$SortedIterator.loadNext(UnsafeInMemorySorter.java:295)
at org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter$SpillableIterator.loadNext(UnsafeExternalSorter.java:573)
at org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:161)
at org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:148)
at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)
at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:380)
at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)
at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:893)
at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
at org.apache.spark.sql.hive.execution.ScriptTransformationWriterThread$$anonfun$run$1.apply$mcV$sp(ScriptTransformation.scala:289)
at org.apache.spark.sql.hive.execution.ScriptTransformationWriterThread$$anonfun$run$1.apply(ScriptTransformation.scala:278)
at org.apache.spark.sql.hive.execution.ScriptTransformationWriterThread$$anonfun$run$1.apply(ScriptTransformation.scala:278)
at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
at org.apache.spark.sql.hive.execution.ScriptTransformationWriterThread.run(ScriptTransformation.scala:278)
18/08/14 16:17:53 INFO DiskBlockManager: Shutdown hook called
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Through analysis log of Task TID 3929, we found that the Task had completed the Task Kill process normally on the Driver side and Executor side, the discord was SparkUncaughtExceptionHandler captured and handled TaskKilledException, then Executor entering the Shutdown process. The following is the code part and analysis of the problem process &#65306;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
override def run(): Unit = Utils.logUncaughtExceptions {
...

&lt;span class=&quot;code-comment&quot;&gt;// We can&apos;t use Utils.tryWithSafeFinally here because we also need a `&lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt;` block, so
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;// let&apos;s use a variable to record whether the `&lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt;` block was hit due to an exception
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; threwException: &lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt; = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
val len = inputSchema.length
&lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
iter.map(outputProjection).foreach { row =&amp;gt; &lt;span class=&quot;code-comment&quot;&gt;// line 289
&lt;/span&gt;...
}
threwException = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
} &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; {
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; t: Throwable =&amp;gt;
&lt;span class=&quot;code-comment&quot;&gt;// An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; writing input, so kill the child process. According to the
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;// Javadoc &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; call will not &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; an exception:
&lt;/span&gt;_exception = t
proc.destroy()
&lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; t
} &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
...
}
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;TaskKill cmd will mark `interrupted=true` of TaskContext, forecach method in ScriptTransformationWriterThread trigger TaskKilledException throw and catch by ScriptTransformationWriterThread.&lt;/li&gt;
	&lt;li&gt;ScriptTransformationWriterThread catch TaskKilledException ,&#160; assign it to `_exception` and re-throw it.&lt;/li&gt;
	&lt;li&gt;ScriptTransformation in TaskRuner found `ScriptTransformationWriterThread.exception.isDefined` is true and throw TaskKilledException, it will handle by `catch block` in TaskRunner to complete TaskKill, we can confirm the conclusion from the log.&lt;/li&gt;
	&lt;li&gt;TaskKilledException re-throw by ScriptTransformationWriterThread will catch by Utils.logUncaughtExceptions method, logUncaughtExceptions method will log and re-throw it again.&lt;/li&gt;
	&lt;li&gt;ScriptTransformationWriterThread is sub Thread of TaskRuner, belonging to main ThreadGroup, so TaskKilledException throw from ScriptTransformationWriterThread will captured by SparkUncaughtExceptionHandler which registered during Executor start rather than TaskRunner&#65292; and SparkUncaughtExceptionHandler will log the TaskKilledException then call System.exit (SparkExitCode.UNCAUGHT_EXCEPTION) to shutdown Executor&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;From the above analysis we can be sure that any Throwable is thrown during the ScriptTransformationWriterThread run will lead Executor into the shutdown process, which is not appropriate. Current solution is add case matches for TaskKilledException in ScriptTransformationWriterThread catch block, only log and assign TaskKilledException to `_exception`, no longer rethrow it. We re-run the user job with this change and set `spark.speculation = true`, the problem no longer reappears.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13179868">SPARK-25158</key>
            <summary>Executor accidentally exit because ScriptTransformationWriterThread throws TaskKilledException.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="LuciferYang">Yang Jie</assignee>
                                    <reporter username="LuciferYang">Yang Jie</reporter>
                        <labels>
                    </labels>
                <created>Mon, 20 Aug 2018 06:09:13 +0000</created>
                <updated>Tue, 12 Feb 2019 05:06:44 +0000</updated>
                            <resolved>Tue, 12 Feb 2019 04:17:17 +0000</resolved>
                                    <version>2.1.0</version>
                    <version>2.2.0</version>
                    <version>2.3.0</version>
                                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16585467" author="apachespark" created="Mon, 20 Aug 2018 06:13:05 +0000"  >&lt;p&gt;User &apos;LuciferYang&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22149&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22149&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16765662" author="cloud_fan" created="Tue, 12 Feb 2019 04:17:17 +0000"  >&lt;p&gt;Issue resolved by pull request 22149&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/22149&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/22149&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311020" key="com.atlassian.jira.plugin.system.customfieldtypes:url">
                        <customfieldname>External issue URL</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[https://github.com/apache/spark/pull/22149]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 40 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3x7d3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>