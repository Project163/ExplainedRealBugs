<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:34:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-44846] PushFoldableIntoBranches in complex grouping expressions may cause bindReference error</title>
                <link>https://issues.apache.org/jira/browse/SPARK-44846</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;SQL:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
select c*2 as d from
(select &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(b &amp;gt; 1, 1, b) as c from
(select &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt;(a &amp;lt; 0, 0 ,a) as b from t group by b) t1
group by c) t2 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;ERROR:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Couldn&apos;t find _groupingexpression#15 in [&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((_groupingexpression#15 &amp;gt; 1)) 1 &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; _groupingexpression#15#16]
java.lang.IllegalStateException: Couldn&apos;t find _groupingexpression#15 in [&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((_groupingexpression#15 &amp;gt; 1)) 1 &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; _groupingexpression#15#16]
&#160; &#160; at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:80)
&#160; &#160; at org.apache.spark.sql.catalyst.expressions.BindReferences$$anonfun$bindReference$1.applyOrElse(BoundAttribute.scala:73)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1241)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1240)
&#160; &#160; at org.apache.spark.sql.catalyst.expressions.BinaryExpression.mapChildren(Expression.scala:653)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TernaryLike.mapChildren(TreeNode.scala:1272)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TernaryLike.mapChildren$(TreeNode.scala:1271)
&#160; &#160; at org.apache.spark.sql.catalyst.expressions.If.mapChildren(conditionalExpressions.scala:41)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:466)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)
&#160; &#160; at org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:533)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:466)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
&#160; &#160; at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:405)
&#160; &#160; at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReference(BoundAttribute.scala:73)
&#160; &#160; at org.apache.spark.sql.catalyst.expressions.BindReferences$.$anonfun$bindReferences$1(BoundAttribute.scala:94)
&#160; &#160; at scala.collection.immutable.List.map(List.scala:293)
&#160; &#160; at org.apache.spark.sql.catalyst.expressions.BindReferences$.bindReferences(BoundAttribute.scala:94)
&#160; &#160; at org.apache.spark.sql.execution.aggregate.HashAggregateExec.generateResultFunction(HashAggregateExec.scala:360)
&#160; &#160; at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduceWithKeys(HashAggregateExec.scala:538)
&#160; &#160; at org.apache.spark.sql.execution.aggregate.AggregateCodegenSupport.doProduce(AggregateCodegenSupport.scala:69)
&#160; &#160; at org.apache.spark.sql.execution.aggregate.AggregateCodegenSupport.doProduce$(AggregateCodegenSupport.scala:65)
&#160; &#160; at org.apache.spark.sql.execution.aggregate.HashAggregateExec.doProduce(HashAggregateExec.scala:49)
&#160; &#160; at org.apache.spark.sql.execution.CodegenSupport.$anonfun$produce$1(WholeStageCodegenExec.scala:97)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
&#160; &#160; at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
&#160; &#160; at org.apache.spark.sql.execution.CodegenSupport.produce(WholeStageCodegenExec.scala:92)
&#160; &#160; at org.apache.spark.sql.execution.CodegenSupport.produce$(WholeStageCodegenExec.scala:92)
&#160; &#160; at org.apache.spark.sql.execution.aggregate.HashAggregateExec.produce(HashAggregateExec.scala:49)
&#160; &#160; at org.apache.spark.sql.execution.WholeStageCodegenExec.doCodeGen(WholeStageCodegenExec.scala:660)
&#160; &#160; at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:723)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
&#160; &#160; at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)
&#160; &#160; at org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:93)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
&#160; &#160; at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)
&#160; &#160; at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$doExecute$1(AdaptiveSparkPlanExec.scala:386)
&#160; &#160; at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:402)
&#160; &#160; at org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.doExecute(AdaptiveSparkPlanExec.scala:386)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
&#160; &#160; at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
&#160; &#160; at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)
&#160; &#160; at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:207)
&#160; &#160; at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:206)
&#160; &#160; at org.apache.spark.sql.Dataset.rdd$lzycompute(Dataset.scala:3857)
&#160; &#160; at org.apache.spark.sql.Dataset.rdd(Dataset.scala:3855)
&#160; &#160; at org.apache.spark.sql.QueryTest$.$anonfun$getErrorMessageInCheckAnswer$1(QueryTest.scala:266)
&#160; &#160; at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
&#160; &#160; at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:209)
&#160; &#160; at org.apache.spark.sql.QueryTest$.getErrorMessageInCheckAnswer(QueryTest.scala:266)
&#160; &#160; at org.apache.spark.sql.QueryTest$.checkAnswer(QueryTest.scala:243)
&#160; &#160; at org.apache.spark.sql.QueryTest.checkAnswer(QueryTest.scala:151)
&#160; &#160; at org.apache.spark.sql.DataFrameSuite.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$737(DataFrameSuite.scala:3676)
&#160; &#160; at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
&#160; &#160; at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
&#160; &#160; at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
&#160; &#160; at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:95)
&#160; &#160; at org.apache.spark.sql.test.SQLTestUtilsBase.withTempView(SQLTestUtils.scala:276)
&#160; &#160; at org.apache.spark.sql.test.SQLTestUtilsBase.withTempView$(SQLTestUtils.scala:274)
&#160; &#160; at org.apache.spark.sql.DataFrameSuite.withTempView(DataFrameSuite.scala:60)
&#160; &#160; at org.apache.spark.sql.DataFrameSuite.$anonfun$&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt;$736(DataFrameSuite.scala:3667)
&#160; &#160; at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
&#160; &#160; at org.scalatest.enablers.Timed$$anon$1.timeoutAfter(Timed.scala:127)
&#160; &#160; at org.scalatest.concurrent.TimeLimits$.failAfterImpl(TimeLimits.scala:282)
&#160; &#160; at org.scalatest.concurrent.TimeLimits.failAfter(TimeLimits.scala:231)
&#160; &#160; at org.scalatest.concurrent.TimeLimits.failAfter$(TimeLimits.scala:230)
&#160; &#160; at org.apache.spark.SparkFunSuite.failAfter(SparkFunSuite.scala:69)
&#160; &#160; at org.apache.spark.SparkFunSuite.$anonfun$test$2(SparkFunSuite.scala:155)
&#160; &#160; at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)
&#160; &#160; at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)
&#160; &#160; at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
&#160; &#160; at org.scalatest.Transformer.apply(Transformer.scala:22)
&#160; &#160; at org.scalatest.Transformer.apply(Transformer.scala:20)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:226)
&#160; &#160; at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:227)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:224)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:236)
&#160; &#160; at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:236)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:218)
&#160; &#160; at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterEach$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$runTest(SparkFunSuite.scala:69)
&#160; &#160; at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)
&#160; &#160; at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)
&#160; &#160; at org.apache.spark.SparkFunSuite.runTest(SparkFunSuite.scala:69)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:269)
&#160; &#160; at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)
&#160; &#160; at scala.collection.immutable.List.foreach(List.scala:431)
&#160; &#160; at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
&#160; &#160; at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)
&#160; &#160; at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:269)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:268)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1564)
&#160; &#160; at org.scalatest.Suite.run(Suite.scala:1114)
&#160; &#160; at org.scalatest.Suite.run$(Suite.scala:1096)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(AnyFunSuite.scala:1564)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:273)
&#160; &#160; at org.scalatest.SuperEngine.runImpl(Engine.scala:535)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:273)
&#160; &#160; at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:272)
&#160; &#160; at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$&lt;span class=&quot;code-keyword&quot;&gt;super&lt;/span&gt;$run(SparkFunSuite.scala:69)
&#160; &#160; at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)
&#160; &#160; at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)
&#160; &#160; at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)
&#160; &#160; at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:69)
&#160; &#160; at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:47)
&#160; &#160; at org.scalatest.tools.Runner$.$anonfun$doRunRunRunDaDoRunRun$13(Runner.scala:1321)
&#160; &#160; at org.scalatest.tools.Runner$.$anonfun$doRunRunRunDaDoRunRun$13$adapted(Runner.scala:1315)
&#160; &#160; at scala.collection.immutable.List.foreach(List.scala:431)
&#160; &#160; at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:1315)
&#160; &#160; at org.scalatest.tools.Runner$.$anonfun$runOptionallyWithPassFailReporter$24(Runner.scala:992)
&#160; &#160; at org.scalatest.tools.Runner$.$anonfun$runOptionallyWithPassFailReporter$24$adapted(Runner.scala:970)
&#160; &#160; at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:1481)
&#160; &#160; at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:970)
&#160; &#160; at org.scalatest.tools.Runner$.run(Runner.scala:798)
&#160; &#160; at org.scalatest.tools.Runner.run(Runner.scala)
&#160; &#160; at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.runScalaTest2or3(ScalaTestRunner.java:38)
&#160; &#160; at org.jetbrains.plugins.scala.testingSupport.scalaTest.ScalaTestRunner.main(ScalaTestRunner.java:25)
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13547697">SPARK-44846</key>
            <summary>PushFoldableIntoBranches in complex grouping expressions may cause bindReference error</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="zhuml">Mingliang Zhu</assignee>
                                    <reporter username="zhuml">Mingliang Zhu</reporter>
                        <labels>
                    </labels>
                <created>Thu, 17 Aug 2023 09:05:45 +0000</created>
                <updated>Mon, 4 Sep 2023 12:48:17 +0000</updated>
                            <resolved>Mon, 4 Sep 2023 12:48:17 +0000</resolved>
                                    <version>3.4.1</version>
                                    <fixVersion>3.4.2</fixVersion>
                    <fixVersion>3.5.0</fixVersion>
                    <fixVersion>4.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="17757899" author="githubbot" created="Wed, 23 Aug 2023 09:17:55 +0000"  >&lt;p&gt;User &apos;zml1206&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/42531&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/42531&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17761037" author="ignitetcbot" created="Thu, 31 Aug 2023 16:52:57 +0000"  >&lt;p&gt;User &apos;zml1206&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/42633&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/42633&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17761816" author="q79969786" created="Mon, 4 Sep 2023 12:48:17 +0000"  >&lt;p&gt;Issue resolved by pull request 42633&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/42633&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/42633&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 10 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1jujs:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>