<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:29:18 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-38204] All state operators are at a risk of inconsistency between state partitioning and operator partitioning</title>
                <link>https://issues.apache.org/jira/browse/SPARK-38204</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Except stream-stream join, all stateful operators use ClusteredDistribution as a requirement of child distribution.&lt;/p&gt;

&lt;p&gt;ClusteredDistribution is very relaxed one - any output partitioning can satisfy the distribution if the partitioning can ensure all tuples having same grouping keys are placed in same partition.&lt;/p&gt;

&lt;p&gt;To illustrate an example, support we do streaming aggregation like below code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
df
  .withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;30 minutes&quot;&lt;/span&gt;)
  .groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;group1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;group2&quot;&lt;/span&gt;, window(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 minutes&quot;&lt;/span&gt;))
  .agg(count(&lt;span class=&quot;code-quote&quot;&gt;&quot;*&quot;&lt;/span&gt;)) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In the code, streaming aggregation operator will be involved in physical plan, which would have ClusteredDistribution(&quot;group1&quot;, &quot;group2&quot;, &quot;window&quot;).&lt;/p&gt;

&lt;p&gt;The problem is, various output partitionings can satisfy this distribution:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;RangePartitioning&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;This accepts exact and subset of the grouping key, with any order of keys (combination), with any sort order (asc/desc)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;HashPartitioning&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;This accepts exact and subset of the grouping key, with any order of keys (combination)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;(upcoming Spark 3.3.0+) DataSourcePartitioning&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;output partitioning provided by data source will be able to satisfy ClusteredDistribution, which will make things worse (assuming data source can provide different output partitioning relatively easier)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;e.g. even we only consider HashPartitioning, HashPartitioning(&quot;group1&quot;), HashPartitioning(&quot;group2&quot;), HashPartitioning(&quot;group1&quot;, &quot;group2&quot;), HashPartitioning(&quot;group2&quot;, &quot;group1&quot;), HashPartitioning(&quot;group1&quot;, &quot;group2&quot;, &quot;window&quot;), etc.&lt;/p&gt;

&lt;p&gt;The requirement of state partitioning is much more strict, since we should not change the partitioning once it is partitioned and built. &lt;b&gt;It should ensure that all tuples having same grouping keys are placed in same partition (same partition ID) across query lifetime.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;The impedance of distribution requirement between ClusteredDistribution and state partitioning leads correctness issue silently.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;For example, let&apos;s assume we have a streaming query like below:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
df
  .withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;30 minutes&quot;&lt;/span&gt;)
  .repartition(&lt;span class=&quot;code-quote&quot;&gt;&quot;group2&quot;&lt;/span&gt;)
  .groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;group1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;group2&quot;&lt;/span&gt;, window(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 minutes&quot;&lt;/span&gt;))
  .agg(count(&lt;span class=&quot;code-quote&quot;&gt;&quot;*&quot;&lt;/span&gt;)) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;repartition(&quot;group2&quot;) satisfies ClusteredDistribution(&quot;group1&quot;, &quot;group2&quot;, &quot;window&quot;), so Spark won&apos;t introduce additional shuffle there, and state partitioning would be HashPartitioning(&quot;group2&quot;).&lt;/p&gt;

&lt;p&gt;we run this query for a while, and stop the query, and change the manual partitioning like below:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
df
  .withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;30 minutes&quot;&lt;/span&gt;)
  .repartition(&lt;span class=&quot;code-quote&quot;&gt;&quot;group1&quot;&lt;/span&gt;)
  .groupBy(&lt;span class=&quot;code-quote&quot;&gt;&quot;group1&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;group2&quot;&lt;/span&gt;, window(&lt;span class=&quot;code-quote&quot;&gt;&quot;timestamp&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;10 minutes&quot;&lt;/span&gt;))
  .agg(count(&lt;span class=&quot;code-quote&quot;&gt;&quot;*&quot;&lt;/span&gt;)) &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;repartition(&quot;group1&quot;) also satisfies ClusteredDistribution(&quot;group1&quot;, &quot;group2&quot;, &quot;window&quot;), so Spark won&apos;t introduce additional shuffle there. That said, child output partitioning of streaming aggregation operator would be HashPartitioning(&quot;group1&quot;), whereas state partitioning is HashPartitioning(&quot;group2&quot;).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#recovery-semantics-after-changes-in-a-streaming-query&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#recovery-semantics-after-changes-in-a-streaming-query&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In SS guide doc we enumerate the unsupported modifications of the query during the lifetime of streaming query, but there is no notion of this.&lt;/p&gt;

&lt;p&gt;Making this worse, Spark doesn&apos;t store any information on state partitioning (that said, there is no way to validate), so &lt;b&gt;Spark simply allows this change and brings up correctness issue while the streaming query runs like no problem at all.&lt;/b&gt; The only way to indicate the correctness is from the result of the query.&lt;/p&gt;

&lt;p&gt;We have no idea whether end users already suffer from this in their queries or not. &lt;b&gt;The only way to look into is to list up all state rows and apply hash function with expected grouping keys, and confirm all rows provide the exact partition ID where they are in.&lt;/b&gt; If it turns out as broken, we will have to have a tool to &#8220;re&#8221;partition the state correctly, or in worst case, have to ask throwing out checkpoint and reprocess.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;This issue has been laid from the introduction of stateful operators (Spark 2.2+)&lt;/b&gt;, since HashClusteredDistribution (strict requirement) had introduced in Spark 2.3 and we didn&apos;t change stateful operators to use this distribution. stream-stream join hopefully used HashClusteredDistribution from Spark 2.3, so it seems to be safe.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13428304">SPARK-38204</key>
            <summary>All state operators are at a risk of inconsistency between state partitioning and operator partitioning</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kabhwan">Jungtaek Lim</assignee>
                                    <reporter username="kabhwan">Jungtaek Lim</reporter>
                        <labels>
                            <label>correctness</label>
                            <label>releasenotes</label>
                    </labels>
                <created>Mon, 14 Feb 2022 10:31:38 +0000</created>
                <updated>Wed, 23 Mar 2022 01:12:31 +0000</updated>
                            <resolved>Tue, 15 Mar 2022 20:30:15 +0000</resolved>
                                    <version>2.2.3</version>
                    <version>2.3.4</version>
                    <version>2.4.8</version>
                    <version>3.0.3</version>
                    <version>3.1.2</version>
                    <version>3.2.1</version>
                    <version>3.3.0</version>
                                    <fixVersion>3.3.0</fixVersion>
                    <fixVersion>3.2.2</fixVersion>
                                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17491927" author="kabhwan" created="Mon, 14 Feb 2022 10:33:18 +0000"  >&lt;p&gt;Since this is not a regression, we could change the priority to critical if we can&apos;t make it in the release period of Spark 3.3.&lt;/p&gt;</comment>
                            <comment id="17495915" author="kabhwan" created="Tue, 22 Feb 2022 07:33:19 +0000"  >&lt;p&gt;Let&#8217;s have a short-term fix first to make sure we no longer open the chance to mess up with new streaming query first. We can craft a long-term fix accounting existing queries on top of short-term fix.&lt;br/&gt;
&#160;&lt;/p&gt;</comment>
                            <comment id="17498706" author="apachespark" created="Mon, 28 Feb 2022 04:21:58 +0000"  >&lt;p&gt;User &apos;HeartSaVioR&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/35673&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/35673&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17507215" author="xuanyuan" created="Tue, 15 Mar 2022 20:30:15 +0000"  >&lt;p&gt;Issue resolved by pull request 35673&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/35673&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/35673&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17508541" author="apachespark" created="Fri, 18 Mar 2022 03:06:19 +0000"  >&lt;p&gt;User &apos;HeartSaVioR&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/35908&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/35908&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17508542" author="apachespark" created="Fri, 18 Mar 2022 03:06:55 +0000"  >&lt;p&gt;User &apos;HeartSaVioR&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/35908&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/35908&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 34 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0zjpc:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>