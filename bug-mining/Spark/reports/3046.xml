<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:37:19 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-10847] Pyspark - DataFrame - Optional Metadata with `None` triggers cryptic failure</title>
                <link>https://issues.apache.org/jira/browse/SPARK-10847</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;If the optional metadata passed to `pyspark.sql.types.StructField` includes a pythonic `None`, the `pyspark.SparkContext.createDataFrame` will fail with a very cryptic/unhelpful error.&lt;/p&gt;

&lt;p&gt;Here is a minimal reproducible example:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt;# Assumes sc exists
import pyspark.sql.types as types
sqlContext = SQLContext(sc)


literal_metadata = types.StructType([
    types.StructField(
        &apos;name&apos;,
        types.StringType(),
        nullable=True,
        metadata={&apos;comment&apos;: &apos;From accounting system.&apos;}
        ),
    types.StructField(
        &apos;age&apos;,
        types.IntegerType(),
        nullable=True,
        metadata={&apos;comment&apos;: None}
        ),
    ])

literal_rdd = sc.parallelize([
    [&apos;Bob&apos;, 34],
    [&apos;Dan&apos;, 42],
    ])
print(literal_rdd.take(2))

failed_dataframe = sqlContext.createDataFrame(
    literal_rdd,
    literal_metadata,
    )
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This produces the following ~stacktrace:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Traceback (most recent call last):
  File &quot;&amp;lt;stdin&amp;gt;&quot;, line 1, in &amp;lt;module&amp;gt;
  File &quot;&amp;lt;string&amp;gt;&quot;, line 28, in &amp;lt;module&amp;gt;
  File &quot;S:\ZQL\Software\Hotware\spark-1.5.0-bin-hadoop2.6\python\pyspark\sql\context.py&quot;, line 408, in createDataFrame
    jdf = self._ssql_ctx.applySchemaToPythonRDD(jrdd.rdd(), schema.json())
  File &quot;S:\ZQL\Software\Hotware\spark-1.5.0-bin-hadoop2.6\python\lib\py4j-0.8.2.1-src.zip\py4j\java_gateway.py&quot;, line 538, in __call__
  File &quot;S:\ZQL\Software\Hotware\spark-1.5.0-bin-hadoop2.6\python\pyspark\sql\utils.py&quot;, line 36, in deco
    return f(*a, **kw)
  File &quot;S:\ZQL\Software\Hotware\spark-1.5.0-bin-hadoop2.6\python\lib\py4j-0.8.2.1-src.zip\py4j\protocol.py&quot;, line 300, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o757.applySchemaToPythonRDD.
: java.lang.RuntimeException: Do not support type class scala.Tuple2.
	at org.apache.spark.sql.types.Metadata$$anonfun$fromJObject$1.apply(Metadata.scala:160)
	at org.apache.spark.sql.types.Metadata$$anonfun$fromJObject$1.apply(Metadata.scala:127)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at org.apache.spark.sql.types.Metadata$.fromJObject(Metadata.scala:127)
	at org.apache.spark.sql.types.DataType$.org$apache$spark$sql$types$DataType$$parseStructField(DataType.scala:173)
	at org.apache.spark.sql.types.DataType$$anonfun$parseDataType$1.apply(DataType.scala:148)
	at org.apache.spark.sql.types.DataType$$anonfun$parseDataType$1.apply(DataType.scala:148)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.types.DataType$.parseDataType(DataType.scala:148)
	at org.apache.spark.sql.types.DataType$.fromJson(DataType.scala:96)
	at org.apache.spark.sql.SQLContext.parseDataType(SQLContext.scala:961)
	at org.apache.spark.sql.SQLContext.applySchemaToPythonRDD(SQLContext.scala:970)
	at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:379)
	at py4j.Gateway.invoke(Gateway.java:259)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:207)
	at java.lang.Thread.run(Unknown Source)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I believe the most important line of the traceback is this one:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;py4j.protocol.Py4JJavaError: An error occurred while calling o757.applySchemaToPythonRDD.
: java.lang.RuntimeException: Do not support type class scala.Tuple2.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But it wasn&apos;t enough for me to figure out the problem; I had to steadily simplify my program until I could identify what caused the problem.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Windows 7&lt;br/&gt;
java version &quot;1.8.0_60&quot; (64bit)&lt;br/&gt;
Python 3.4.x&lt;/p&gt;

&lt;p&gt;Standalone cluster mode (not local&lt;span class=&quot;error&quot;&gt;&amp;#91;n&amp;#93;&lt;/span&gt;; a full local cluster)&lt;/p&gt;</environment>
        <key id="12896676">SPARK-10847</key>
            <summary>Pyspark - DataFrame - Optional Metadata with `None` triggers cryptic failure</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jason412">Jason C Lee</assignee>
                                    <reporter username="shea.parkes">Shea Parkes</reporter>
                        <labels>
                    </labels>
                <created>Sun, 27 Sep 2015 19:20:49 +0000</created>
                <updated>Wed, 27 Jan 2016 17:56:57 +0000</updated>
                            <resolved>Wed, 27 Jan 2016 17:56:19 +0000</resolved>
                                    <version>1.5.0</version>
                                    <fixVersion>1.5.3</fixVersion>
                    <fixVersion>1.6.1</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>PySpark</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="14933707" author="jasoncl" created="Mon, 28 Sep 2015 18:19:24 +0000"  >&lt;p&gt;I would like to work on this.&lt;/p&gt;</comment>
                            <comment id="14933924" author="shea.parkes" created="Mon, 28 Sep 2015 20:30:02 +0000"  >&lt;p&gt;This issue caused me to learn enough about Scala only to learn that the exception still wasn&apos;t helpful once I even knew what a scala.Tuple2 was.&lt;/p&gt;

&lt;p&gt;I&apos;m not planning on doing any further work on this, so to the extent you were waiting to avoid duplication of efforts with me, feel free to go ahead and knock it out.  I&apos;m not entirely familiar with the contribution guidelines, but I&apos;m sure you can work them out.&lt;/p&gt;

&lt;p&gt;In case it wasn&apos;t clear above, the line that triggers the error is:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt;metadata={&apos;comment&apos;: None}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thanks for the interest!&lt;/p&gt;</comment>
                            <comment id="14934044" author="jasoncl" created="Mon, 28 Sep 2015 21:14:06 +0000"  >&lt;p&gt;Instead of &lt;br/&gt;
Py4JJavaError: An error occurred while calling o757.applySchemaToPythonRDD.&lt;br/&gt;
: java.lang.RuntimeException: Do not support type class scala.Tuple2.&lt;/p&gt;

&lt;p&gt;Would it be helpful if the error message is this:&lt;br/&gt;
Py4JJavaError: An error occurred while calling o76.applySchemaToPythonRDD.&lt;br/&gt;
: java.lang.RuntimeException: Do not support type class java.lang.String : class org.json4s.JsonAST$JNull$.&lt;/p&gt;</comment>
                            <comment id="14941929" author="apachespark" created="Fri, 2 Oct 2015 23:02:02 +0000"  >&lt;p&gt;User &apos;jasoncl&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8969&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8969&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14941952" author="shea.parkes" created="Fri, 2 Oct 2015 23:20:18 +0000"  >&lt;p&gt;I appreciate your assistance!  I think your proposal is an improvement, but I think it would be better if the failure was triggered upon the creation of the StructType object - that&apos;s where the error actually occurred.&lt;/p&gt;

&lt;p&gt;The distance between the definition of the metadata and the import was much larger in my project; I think your new error message would still have me looking for NULL values in my data (instead of my metadata).  That&apos;s likely a part of my unfamiliarity of Scala, but I chased as far down the pyspark code as I could go and didn&apos;t figure it out without trial and error.&lt;/p&gt;

&lt;p&gt;I realize this might mean traversing an arbitrary dictionary in the StructType initialization looking for unallowed types, which might be unacceptable.  It would still be much more in line with &quot;Crash Early, Crash Often&quot; philosophy if it were possible to bomb at the creation of the metadata.&lt;/p&gt;

&lt;p&gt;Thanks again for the assistance!&lt;/p&gt;</comment>
                            <comment id="14941953" author="shea.parkes" created="Fri, 2 Oct 2015 23:21:22 +0000"  >&lt;p&gt;My apologies, I just read your patch and see you made it work even with Pythonic Nulls.  You rule sir; thanks a bunch.&lt;/p&gt;</comment>
                            <comment id="14943670" author="jasoncl" created="Mon, 5 Oct 2015 17:08:29 +0000"  >&lt;p&gt;You&apos;re welcome!&lt;/p&gt;</comment>
                            <comment id="15119887" author="yhuai" created="Wed, 27 Jan 2016 17:56:19 +0000"  >&lt;p&gt;Issue resolved by pull request 8969&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8969&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8969&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 42 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2lm13:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>