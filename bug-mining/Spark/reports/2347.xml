<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:31:34 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-9627] SQL job failed if the dataframe with string columns is cached</title>
                <link>https://issues.apache.org/jira/browse/SPARK-9627</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;r = random.Random()
def gen(i):
    d = date.today() - timedelta(r.randint(0, 5000))
    cat = str(r.randint(0, 20)) * 5
    c = r.randint(0, 1000)
    price = decimal.Decimal(r.randint(0, 100000)) / 100
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (d, cat, c, price)

schema = StructType().add(&lt;span class=&quot;code-quote&quot;&gt;&apos;date&apos;&lt;/span&gt;, DateType()).add(&lt;span class=&quot;code-quote&quot;&gt;&apos;cat&apos;&lt;/span&gt;, StringType()).add(&lt;span class=&quot;code-quote&quot;&gt;&apos;count&apos;&lt;/span&gt;, ShortType()).add(&lt;span class=&quot;code-quote&quot;&gt;&apos;price&apos;&lt;/span&gt;, DecimalType(5, 2))

#df = sqlContext.createDataFrame(sc.range(1&amp;lt;&amp;lt;24).map(gen), schema)
#df.show()
#df.write.parquet(&lt;span class=&quot;code-quote&quot;&gt;&apos;sales4&apos;&lt;/span&gt;)


df = sqlContext.read.parquet(&lt;span class=&quot;code-quote&quot;&gt;&apos;sales4&apos;&lt;/span&gt;)
df.cache()
df.count()
df.show()
print df.schema
raw_input()
r = df.groupBy(df.date, df.cat).agg(sum(df[&lt;span class=&quot;code-quote&quot;&gt;&apos;count&apos;&lt;/span&gt;] * df.price))
print r.explain(True)
r.show()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;StructType(List(StructField(date,DateType,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;),StructField(cat,StringType,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;),StructField(count,ShortType,&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;),StructField(price,DecimalType(5,2),&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;)))


== Parsed Logical Plan ==
&apos;Aggregate [date#0,cat#1], [date#0,cat#1,sum((count#2 * price#3)) AS sum((count * price))#70]
 Relation[date#0,cat#1,count#2,price#3] org.apache.spark.sql.parquet.ParquetRelation@5ec8f315

== Analyzed Logical Plan ==
date: date, cat: string, sum((count * price)): decimal(21,2)
Aggregate [date#0,cat#1], [date#0,cat#1,sum((change_decimal_precision(CAST(CAST(count#2, DecimalType(5,0)), DecimalType(11,2))) * change_decimal_precision(CAST(price#3, DecimalType(11,2))))) AS sum((count * price))#70]
 Relation[date#0,cat#1,count#2,price#3] org.apache.spark.sql.parquet.ParquetRelation@5ec8f315

== Optimized Logical Plan ==
Aggregate [date#0,cat#1], [date#0,cat#1,sum((change_decimal_precision(CAST(CAST(count#2, DecimalType(5,0)), DecimalType(11,2))) * change_decimal_precision(CAST(price#3, DecimalType(11,2))))) AS sum((count * price))#70]
 InMemoryRelation [date#0,cat#1,count#2,price#3], &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 10000, StorageLevel(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 1), (PhysicalRDD [date#0,cat#1,count#2,price#3], MapPartitionsRDD[3] at), None

== Physical Plan ==
NewAggregate with SortBasedAggregationIterator List(date#0, cat#1) ArrayBuffer((sum((change_decimal_precision(CAST(CAST(count#2, DecimalType(5,0)), DecimalType(11,2))) * change_decimal_precision(CAST(price#3, DecimalType(11,2)))))2,mode=Final,isDistinct=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;))
 TungstenSort [date#0 ASC,cat#1 ASC], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
  ConvertToUnsafe
   Exchange hashpartitioning(date#0,cat#1)
    NewAggregate with SortBasedAggregationIterator List(date#0, cat#1) ArrayBuffer((sum((change_decimal_precision(CAST(CAST(count#2, DecimalType(5,0)), DecimalType(11,2))) * change_decimal_precision(CAST(price#3, DecimalType(11,2)))))2,mode=Partial,isDistinct=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;))
     TungstenSort [date#0 ASC,cat#1 ASC], &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, 0
      ConvertToUnsafe
       InMemoryColumnarTableScan [date#0,cat#1,count#2,price#3], (InMemoryRelation [date#0,cat#1,count#2,price#3], &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 10000, StorageLevel(&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;, 1), (PhysicalRDD [date#0,cat#1,count#2,price#3], MapPartitionsRDD[3] at), None)

Code Generation: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
== RDD ==
None

15/08/04 23:21:53 ERROR TaskSetManager: Task 0 in stage 4.0 failed 1 times; aborting job
Traceback (most recent call last):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;t.py&quot;&lt;/span&gt;, line 34, in &amp;lt;module&amp;gt;
    r.show()
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/davies/work/spark/python/pyspark/sql/dataframe.py&quot;&lt;/span&gt;, line 258, in show
    print(self._jdf.showString(n, truncate))
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/davies/work/spark/python/lib/py4j/java_gateway.py&quot;&lt;/span&gt;, line 538, in __call__
    self.target_id, self.name)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/davies/work/spark/python/pyspark/sql/utils.py&quot;&lt;/span&gt;, line 36, in deco
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; f(*a, **kw)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/davies/work/spark/python/lib/py4j/protocol.py&quot;&lt;/span&gt;, line 300, in get_return_value
    format(target_id, &lt;span class=&quot;code-quote&quot;&gt;&apos;.&apos;&lt;/span&gt;, name), value)
py4j.protocol.Py4JJavaError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling o36.showString.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 10, localhost): java.lang.UnsupportedOperationException: tail of empty list
	at scala.collection.immutable.Nil$.tail(List.scala:339)
	at scala.collection.immutable.Nil$.tail(List.scala:334)
	at scala.reflect.internal.SymbolTable.popPhase(SymbolTable.scala:172)
	at scala.reflect.internal.Symbols$Symbol.typeParams(Symbols.scala:1491)
	at scala.reflect.internal.Types$NoArgsTypeRef.typeParams(Types.scala:2144)
	at scala.reflect.internal.Types$TypeRef.initializedTypeParams(Types.scala:2408)
	at scala.reflect.internal.Types$TypeRef.typeParamsMatchArgs(Types.scala:2409)
	at scala.reflect.internal.Types$AliasTypeRef$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;dealias(Types.scala:2232)
	at scala.reflect.internal.Types$TypeRef$$anon$3.dealias(Types.scala:2539)
	at scala.reflect.runtime.JavaMirrors$JavaMirror.typeToJavaClass(JavaMirrors.scala:1256)
	at scala.reflect.runtime.JavaMirrors$JavaMirror.runtimeClass(JavaMirrors.scala:202)
	at scala.reflect.runtime.JavaMirrors$JavaMirror.runtimeClass(JavaMirrors.scala:65)
	at org.apache.spark.sql.columnar.compression.DictionaryEncoding$Decoder.&amp;lt;init&amp;gt;(compressionSchemes.scala:277)
	at org.apache.spark.sql.columnar.compression.DictionaryEncoding$.decoder(compressionSchemes.scala:185)
	at org.apache.spark.sql.columnar.compression.DictionaryEncoding$.decoder(compressionSchemes.scala:177)
	at org.apache.spark.sql.columnar.compression.CompressibleColumnAccessor$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;initialize(CompressibleColumnAccessor.scala:31)
	at org.apache.spark.sql.columnar.NativeColumnAccessor.initialize(ColumnAccessor.scala:64)
	at org.apache.spark.sql.columnar.ColumnAccessor$class.$init$(ColumnAccessor.scala:33)
	at org.apache.spark.sql.columnar.BasicColumnAccessor.&amp;lt;init&amp;gt;(ColumnAccessor.scala:44)
	at org.apache.spark.sql.columnar.NativeColumnAccessor.&amp;lt;init&amp;gt;(ColumnAccessor.scala:64)
	at org.apache.spark.sql.columnar.StringColumnAccessor.&amp;lt;init&amp;gt;(ColumnAccessor.scala:92)
	at org.apache.spark.sql.columnar.ColumnAccessor$.apply(ColumnAccessor.scala:130)
	at org.apache.spark.sql.columnar.InMemoryColumnarTableScan$$anonfun$9$$anonfun$14$$anonfun$15.apply(InMemoryColumnarTableScan.scala:300)
	at org.apache.spark.sql.columnar.InMemoryColumnarTableScan$$anonfun$9$$anonfun$14$$anonfun$15.apply(InMemoryColumnarTableScan.scala:299)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.sql.columnar.InMemoryColumnarTableScan$$anonfun$9$$anonfun$14.apply(InMemoryColumnarTableScan.scala:299)
	at org.apache.spark.sql.columnar.InMemoryColumnarTableScan$$anonfun$9$$anonfun$14.apply(InMemoryColumnarTableScan.scala:297)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.sql.execution.UnsafeExternalRowSorter.sort(UnsafeExternalRowSorter.java:173)
	at org.apache.spark.sql.execution.TungstenSort$$anonfun$doExecute$3.apply(sort.scala:146)
	at org.apache.spark.sql.execution.TungstenSort$$anonfun$doExecute$3.apply(sort.scala:126)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$17.apply(RDD.scala:706)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12851595">SPARK-9627</key>
            <summary>SQL job failed if the dataframe with string columns is cached</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lian cheng">Cheng Lian</assignee>
                                    <reporter username="davies">Davies Liu</reporter>
                        <labels>
                    </labels>
                <created>Wed, 5 Aug 2015 06:25:14 +0000</created>
                <updated>Wed, 19 Aug 2015 20:58:17 +0000</updated>
                            <resolved>Wed, 19 Aug 2015 20:58:17 +0000</resolved>
                                    <version>1.5.0</version>
                                    <fixVersion>1.5.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="14661083" author="davies" created="Fri, 7 Aug 2015 00:04:01 +0000"  >&lt;p&gt;This is only failed when codegen is enabled, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lian+cheng&quot; class=&quot;user-hover&quot; rel=&quot;lian cheng&quot;&gt;lian cheng&lt;/a&gt; Could you help to looking in this?&lt;/p&gt;</comment>
                            <comment id="14661092" author="lian cheng" created="Fri, 7 Aug 2015 00:11:16 +0000"  >&lt;p&gt;Sure&lt;/p&gt;</comment>
                            <comment id="14701167" author="lian cheng" created="Tue, 18 Aug 2015 12:11:56 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=davies&quot; class=&quot;user-hover&quot; rel=&quot;davies&quot;&gt;davies&lt;/a&gt; I tried to reproduce this issue locally at a smaller scale with master revision dd0614fd618ad28cb77aecfbd49bb319b98fdba0, and it works fine. Could you help verifying whether it&apos;s still a problem now? I replaced &lt;tt&gt;1 &amp;lt;&amp;lt; 24&lt;/tt&gt; with &lt;tt&gt;1 &amp;lt;&amp;lt; 20&lt;/tt&gt; and used &lt;tt&gt;--driver-memory 4g --executor-memory 4g&lt;/tt&gt; while starting PySpark.&lt;/p&gt;</comment>
                            <comment id="14702387" author="davies" created="Wed, 19 Aug 2015 03:38:27 +0000"  >&lt;p&gt;The `df.show()` will succeed, but `df.groupBy(df.date, df.cat).agg(sum(df&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;#39;count&amp;#39;&amp;#93;&lt;/span&gt; * df.price))` will fail (you need to press enter to run it, or remove the `raw_input()` line)&lt;/p&gt;</comment>
                            <comment id="14702390" author="davies" created="Wed, 19 Aug 2015 03:39:19 +0000"  >&lt;p&gt;I can reproduce it with latest master.&lt;/p&gt;</comment>
                            <comment id="14702661" author="lian cheng" created="Wed, 19 Aug 2015 07:54:23 +0000"  >&lt;p&gt;OK I finally reproduced this issue. The tricky part is that, this bug lies in &lt;tt&gt;DictionaryEncoding&lt;/tt&gt;, while in-memory compression schemes are chosen dynamically, and the input data is randomly generated. I forced in-memory columnar builders to use &lt;tt&gt;DictionaryEncoding&lt;/tt&gt; by removing all other compression schemes.&lt;/p&gt;</comment>
                            <comment id="14702671" author="lian cheng" created="Wed, 19 Aug 2015 08:00:46 +0000"  >&lt;p&gt;A quick Googling suggesting that it&apos;s probably related to this Scala reflection API issue &lt;a href=&quot;https://issues.scala-lang.org/browse/SI-6240&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues.scala-lang.org/browse/SI-6240&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&apos;ll try to stop using the reflection API here to fix this issue.&lt;/p&gt;</comment>
                            <comment id="14702711" author="apachespark" created="Wed, 19 Aug 2015 08:45:09 +0000"  >&lt;p&gt;User &apos;liancheng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8306&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8306&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14703730" author="marmbrus" created="Wed, 19 Aug 2015 20:58:17 +0000"  >&lt;p&gt;Issue resolved by pull request 8306&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/8306&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/8306&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 13 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2d2gn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310921" key="com.pyxis.greenhopper.jira:gh-sprint">
                        <customfieldname>Sprint</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="168">Spark 1.5 doc/QA sprint</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12332078">1.5.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>