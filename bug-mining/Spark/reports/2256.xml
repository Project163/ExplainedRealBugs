<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:30:42 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-6923] Spark SQL CLI does not read Data Source schema correctly</title>
                <link>https://issues.apache.org/jira/browse/SPARK-6923</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;HiveContext hctx = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HiveContext(sc);
List&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; sample = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ArrayList&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt;();
sample.add( &lt;span class=&quot;code-quote&quot;&gt;&quot;{\&quot;&lt;/span&gt;id\&lt;span class=&quot;code-quote&quot;&gt;&quot;: \&quot;&lt;/span&gt;id_1\&lt;span class=&quot;code-quote&quot;&gt;&quot;, \&quot;&lt;/span&gt;age\&lt;span class=&quot;code-quote&quot;&gt;&quot;:1}&quot;&lt;/span&gt; );
RDD&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; sampleRDD = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; JavaSparkContext(sc).parallelize(sample).rdd();	
DataFrame df = hctx.jsonRDD(sampleRDD);
&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; table=&lt;span class=&quot;code-quote&quot;&gt;&quot;test&quot;&lt;/span&gt;;
df.saveAsTable(table, &lt;span class=&quot;code-quote&quot;&gt;&quot;json&quot;&lt;/span&gt;,SaveMode.Overwrite);
Table t = hctx.catalog().client().getTable(table);
&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println( t.getCols());
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;--------------------------------------------------------------&lt;br/&gt;
With the code above to save DataFrame to hive table,&lt;br/&gt;
Get table cols returns one column named &apos;col&apos;&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;FieldSchema(name:col, type:array&amp;lt;string&amp;gt;, comment:from deserializer)&amp;#93;&lt;/span&gt;&lt;br/&gt;
Expected return fields schema id, age.&lt;/p&gt;

&lt;p&gt;This results in the jdbc API cannot retrieves the table columns via ResultSet DatabaseMetaData.getColumns(String catalog, String schemaPattern,String tableNamePattern, String columnNamePattern)&lt;br/&gt;
But resultset metadata for query &quot; select * from test &quot;  contains fields id, age.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12821052">SPARK-6923</key>
            <summary>Spark SQL CLI does not read Data Source schema correctly</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="3">Duplicate</resolution>
                                        <assignee username="chenghao">Cheng Hao</assignee>
                                    <reporter username="pin_zhang">pin_zhang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Apr 2015 03:34:22 +0000</created>
                <updated>Fri, 7 Aug 2015 22:57:07 +0000</updated>
                            <resolved>Wed, 5 Aug 2015 02:36:15 +0000</resolved>
                                    <version>1.3.0</version>
                                    <fixVersion>1.5.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="14496887" author="marmbrus" created="Wed, 15 Apr 2015 20:34:12 +0000"  >&lt;p&gt;The catalog is a private API in HiveContext and is not expected to work for data source table.  If you want to know the schema of your table do:&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;hctx.table(&quot;tableName&quot;).schema&lt;/tt&gt;&lt;/p&gt;</comment>
                            <comment id="14497701" author="pin_zhang" created="Thu, 16 Apr 2015 08:04:51 +0000"  >&lt;p&gt;In spark1.1.0 client with the jdbc api to get the table schema&lt;br/&gt;
age(bigint), id(string)&lt;br/&gt;
while in spark1.3.0 &lt;/p&gt;
{name=col, type=array&amp;lt;string&amp;gt;}
&lt;p&gt;That&apos;s not expected.&lt;/p&gt;

&lt;p&gt;ArrayList&amp;lt;Map&amp;gt; results = new ArrayList();&lt;br/&gt;
DatabaseMetaData meta = cnn.getMetaData();			 &lt;br/&gt;
rsColumns = meta.getColumns(database, null, table, null);		&lt;br/&gt;
while (rsColumns.next()) {&lt;br/&gt;
	Map col = new HashMap();&lt;br/&gt;
	col.put(&quot;name&quot;, rsColumns.getString(&quot;COLUMN_NAME&quot;));&lt;br/&gt;
	String typeName = rsColumns.getString(&quot;TYPE_NAME&quot;);&lt;br/&gt;
	col.put(&quot;type&quot;, typeName);&lt;br/&gt;
	results.add(col);&lt;br/&gt;
}&lt;br/&gt;
rsColumns.close();&lt;/p&gt;</comment>
                            <comment id="14498271" author="marmbrus" created="Thu, 16 Apr 2015 16:48:40 +0000"  >&lt;p&gt;Only Spark 1.3 has the ability to read tables that are creates with the&lt;br/&gt;
datasource api.&lt;/p&gt;
</comment>
                            <comment id="14499141" author="pin_zhang" created="Fri, 17 Apr 2015 02:25:21 +0000"  >&lt;p&gt;Do you means if save data frame to the table that use the new datasource api to create table, the hive table won&apos;t support the jdbc api DatabaseMetaData .getColumns(database, null, table, null) to get the table columns that corresponding to the data frame fields?&lt;/p&gt;</comment>
                            <comment id="14502748" author="pin_zhang" created="Mon, 20 Apr 2015 13:01:29 +0000"  >&lt;p&gt;Hi, Michael&lt;br/&gt;
Can you help to comment on this issue?&lt;/p&gt;</comment>
                            <comment id="14503424" author="marmbrus" created="Mon, 20 Apr 2015 18:56:23 +0000"  >&lt;p&gt;You have to run Spark 1.3 in order to be able to read data source tables that were created with the new API that was added in Spark 1.3.&lt;/p&gt;</comment>
                            <comment id="14504409" author="pin_zhang" created="Tue, 21 Apr 2015 06:10:08 +0000"  >&lt;p&gt;Hi, Michael&lt;br/&gt;
  We run spark app in Spark1.3, and  use the CLIService in HiveServer2 to get the table schema, the call stack to get the schema as below&lt;br/&gt;
        HiveMetaStore$HMSHandler.get_fields(String, String) line: 2873	&lt;br/&gt;
	HiveMetaStore$HMSHandler.get_schema(String, String) line: 2946	&lt;br/&gt;
	NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available &lt;span class=&quot;error&quot;&gt;&amp;#91;native method&amp;#93;&lt;/span&gt;	&lt;br/&gt;
	NativeMethodAccessorImpl.invoke(Object, Object[]) line: 57	&lt;br/&gt;
	DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43	&lt;br/&gt;
	Method.invoke(Object, Object...) line: 606	&lt;br/&gt;
	RetryingHMSHandler.invoke(Object, Method, Object[]) line: 105	&lt;br/&gt;
	$Proxy9.get_schema(String, String) line: not available	&lt;br/&gt;
	HiveMetaStoreClient.getSchema(String, String) line: 1269	&lt;br/&gt;
	GetColumnsOperation.run() line: 139	&lt;br/&gt;
	HiveSessionImplwithUGI(HiveSessionImpl).getColumns(String, String, String, String) line: 359	&lt;br/&gt;
	NativeMethodAccessorImpl.invoke0(Method, Object, Object[]) line: not available &lt;span class=&quot;error&quot;&gt;&amp;#91;native method&amp;#93;&lt;/span&gt;	&lt;br/&gt;
	NativeMethodAccessorImpl.invoke(Object, Object[]) line: 57	&lt;br/&gt;
	DelegatingMethodAccessorImpl.invoke(Object, Object[]) line: 43	&lt;br/&gt;
	Method.invoke(Object, Object...) line: 606	&lt;br/&gt;
	HiveSessionProxy.invoke(Method, Object[]) line: 79	&lt;br/&gt;
	HiveSessionProxy.access$000(HiveSessionProxy, Method, Object[]) line: 37	&lt;br/&gt;
	HiveSessionProxy$1.run() line: 64	&lt;br/&gt;
	AccessController.doPrivileged(PrivilegedExceptionAction&amp;lt;T&amp;gt;, AccessControlContext) line: not available &lt;span class=&quot;error&quot;&gt;&amp;#91;native method&amp;#93;&lt;/span&gt;	&lt;br/&gt;
	Subject.doAs(Subject, PrivilegedExceptionAction&amp;lt;T&amp;gt;) line: 415	&lt;br/&gt;
	UserGroupInformation.doAs(PrivilegedExceptionAction&amp;lt;T&amp;gt;) line: 1548	&lt;br/&gt;
	Hadoop23Shims(HadoopShimsSecure).doAs(UserGroupInformation, PrivilegedExceptionAction&amp;lt;T&amp;gt;) line: 493	&lt;br/&gt;
	HiveSessionProxy.invoke(Object, Method, Object[]) line: 60	&lt;br/&gt;
	$Proxy17.getColumns(String, String, String, String) line: not available	&lt;br/&gt;
	SparkSQLCLIService(CLIService).getColumns(SessionHandle, String, String, String, String) line: 309	&lt;br/&gt;
	ThriftBinaryCLIService(ThriftCLIService).GetColumns(TGetColumnsReq) line: 433	&lt;br/&gt;
	TCLIService$Processor$GetColumns&amp;lt;I&amp;gt;.getResult(I, GetColumns_args) line: 1433	&lt;br/&gt;
	TCLIService$Processor$GetColumns&amp;lt;I&amp;gt;.getResult(Object, TBase) line: 1418	&lt;br/&gt;
	TCLIService$Processor$GetColumns&amp;lt;I&amp;gt;(ProcessFunction&amp;lt;I,T&amp;gt;).process(int, TProtocol, TProtocol, I) line: 39	&lt;br/&gt;
	TSetIpAddressProcessor&amp;lt;I&amp;gt;(TBaseProcessor&amp;lt;I&amp;gt;).process(TProtocol, TProtocol) line: 39	&lt;br/&gt;
	TSetIpAddressProcessor&amp;lt;I&amp;gt;.process(TProtocol, TProtocol) line: 55	&lt;br/&gt;
	TThreadPoolServer$WorkerProcess.run() line: 206	&lt;br/&gt;
	ThreadPoolExecutor.runWorker(ThreadPoolExecutor$Worker) line: 1145	&lt;br/&gt;
	ThreadPoolExecutor$Worker.run() line: 615	&lt;br/&gt;
	Thread.run() line: 745	&lt;/p&gt;

&lt;p&gt;   Don&apos;t you think the method should return the same table schema as that you said hctx.table(&quot;tableName&quot;).schema?&lt;/p&gt;</comment>
                            <comment id="14507182" author="pin_zhang" created="Wed, 22 Apr 2015 14:44:48 +0000"  >&lt;p&gt;Hi, Michael&lt;br/&gt;
Can you help to comment. we have a such usage to query hive table and the table is generated by DataFrame.&lt;/p&gt;</comment>
                            <comment id="14507629" author="marmbrus" created="Wed, 22 Apr 2015 18:39:16 +0000"  >&lt;p&gt;It sounds like you have hit a bug in the CLI.&lt;/p&gt;</comment>
                            <comment id="14510381" author="pin_zhang" created="Fri, 24 Apr 2015 02:41:28 +0000"  >&lt;p&gt;Hi, Michael&lt;br/&gt;
Is possible this CLI bug be fixed in Spark1.3?&lt;/p&gt;

&lt;p&gt;Please help to comment.&lt;br/&gt;
Thanks&lt;/p&gt;</comment>
                            <comment id="14516226" author="chenghao" created="Tue, 28 Apr 2015 02:44:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pin_zhang&quot; class=&quot;user-hover&quot; rel=&quot;pin_zhang&quot;&gt;pin_zhang&lt;/a&gt;, I agree &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=marmbrus&quot; class=&quot;user-hover&quot; rel=&quot;marmbrus&quot;&gt;marmbrus&lt;/a&gt;, you&apos;re hitting a bug in ThriftService.&lt;br/&gt;
I will submit a pull request for this.&lt;/p&gt;</comment>
                            <comment id="14516396" author="apachespark" created="Tue, 28 Apr 2015 05:22:23 +0000"  >&lt;p&gt;User &apos;chenghao-intel&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/5733&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/5733&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14516410" author="chenghao" created="Tue, 28 Apr 2015 05:35:24 +0000"  >&lt;p&gt;Sorry, after investigating, it probably not a bug of ThriftService. &lt;/p&gt;

&lt;p&gt;We save the data source table into Hive metastore in a hack way(without the fields information saved), however, some of the applications / components may still access the Hive Metastore via Hive API, which will cause in-consistency.&lt;/p&gt;

&lt;p&gt;In long term, we need to provide a Hive Storage Handler for wrapping the data source API, and then the external application based on Hive Metastore (like Pig) could access the &quot;data sourced&quot; table seamlessly.&lt;/p&gt;</comment>
                            <comment id="14521277" author="pin_zhang" created="Thu, 30 Apr 2015 10:24:59 +0000"  >&lt;p&gt;Hi, Cheng Hao&lt;br/&gt;
   Thanks for your reply!&lt;br/&gt;
   Do you mean if provide a wrapper for datasource api, the Hive Storage Handler can get the &quot;data sourced&quot; table schema correctly for the external application via Hive API?&lt;/p&gt;

&lt;p&gt;    If so, can it be fixed in Spark 1.3.x?&lt;/p&gt;
</comment>
                            <comment id="14658615" author="apachespark" created="Wed, 5 Aug 2015 18:10:03 +0000"  >&lt;p&gt;User &apos;liancheng&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/7967&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/7967&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                            <outwardlinks description="duplicates">
                                        <issuelink>
            <issuekey id="12829018">SPARK-7550</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12829018">SPARK-7550</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12853071">SPARK-9757</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 15 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2fqzr:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311620" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Shepherd</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>liancheng</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12310921" key="com.pyxis.greenhopper.jira:gh-sprint">
                        <customfieldname>Sprint</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="165">Spark 1.5 release</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12332078">1.5.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>