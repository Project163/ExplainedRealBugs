<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:45:25 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16299] Capture errors from R workers in daemon.R to avoid deletion of R session temporary directory</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16299</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Running SparkR unit tests randomly has the following error:&lt;/p&gt;

&lt;p&gt;Failed -------------------------------------------------------------------------&lt;br/&gt;
1. Error: pipeRDD() on RDDs (@test_rdd.R#428) ----------------------------------&lt;br/&gt;
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 792.0 failed 1 times, most recent failure: Lost task 0.0 in stage 792.0 (TID 1493, localhost): org.apache.spark.SparkException: R computation failed with&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 1&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 1&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 3&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 3&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 2&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; 2&lt;br/&gt;
ignoring SIGPIPE signal&lt;br/&gt;
Calls: source ... &amp;lt;Anonymous&amp;gt; -&amp;gt; lapply -&amp;gt; lapply -&amp;gt; FUN -&amp;gt; writeRaw -&amp;gt; writeBin&lt;br/&gt;
Execution halted&lt;br/&gt;
cannot open the connection&lt;br/&gt;
Calls: source ... computeFunc -&amp;gt; FUN -&amp;gt; system2 -&amp;gt; writeLines -&amp;gt; file&lt;br/&gt;
In addition: Warning message:&lt;br/&gt;
In file(con, &quot;w&quot;) :&lt;br/&gt;
  cannot open file &apos;/tmp/Rtmp0Gr1aU/file2de3efc94b3&apos;: No such file or directory&lt;br/&gt;
Execution halted&lt;br/&gt;
	at org.apache.spark.api.r.RRunner.compute(RRunner.scala:108)&lt;br/&gt;
	at org.apache.spark.api.r.BaseRRDD.compute(RRDD.scala:49)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)&lt;br/&gt;
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)&lt;br/&gt;
	at org.apache.spark.scheduler.Task.run(Task.scala:85)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;

&lt;p&gt;This is related to daemon R worker mode. By default, SparkR launches an R daemon worker per executor, and forks R workers from the daemon when necessary.&lt;/p&gt;

&lt;p&gt;The problem about forking R worker is that all forked R processes share a temporary directory, as documented at &lt;a href=&quot;https://stat.ethz.ch/R-manual/R-devel/library/base/html/tempfile.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://stat.ethz.ch/R-manual/R-devel/library/base/html/tempfile.html&lt;/a&gt;.&lt;br/&gt;
When any forked R worker exits either normally or caused by errors, the cleanup procedure of R will delete the temporary directory. This will affect the still-running forked R workers because any temporary files created by them under the temporary directories will be removed together. Also all future R workers that will be forked from the daemon will be affected if they use tempdir() or tempfile() to get tempoaray files because they will fail to create temporary files under the already-deleted session temporary directory.&lt;/p&gt;

&lt;p&gt;So in order for the daemon mode to work, this problem should be circumvented. In current dameon.R, R workers directly exits skipping the cleanup procedure of R so that the shared temporary directory won&apos;t be deleted.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      source(script)
      # Set SIGUSR1 so that child can exit
      tools::pskill(Sys.getpid(), tools::SIGUSR1)
      parallel:::mcexit(0L)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, this is a bug in daemon.R, that when there is any execution error in R workers, the error handling of R will finally go into the cleanup procedure. So try() should be used in daemon.R to catch any error in R workers, so that R workers will directly exit. &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;(source(script))
      # Set SIGUSR1 so that child can exit
      tools::pskill(Sys.getpid(), tools::SIGUSR1)
      parallel:::mcexit(0L)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12985063">SPARK-16299</key>
            <summary>Capture errors from R workers in daemon.R to avoid deletion of R session temporary directory</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sunrui">Sun Rui</assignee>
                                    <reporter username="sunrui">Sun Rui</reporter>
                        <labels>
                    </labels>
                <created>Wed, 29 Jun 2016 15:35:39 +0000</created>
                <updated>Fri, 1 Jul 2016 21:38:02 +0000</updated>
                            <resolved>Fri, 1 Jul 2016 21:37:22 +0000</resolved>
                                    <version>1.6.2</version>
                                    <fixVersion>2.0.0</fixVersion>
                                    <component>SparkR</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="15355462" author="apachespark" created="Wed, 29 Jun 2016 15:52:43 +0000"  >&lt;p&gt;User &apos;sun-rui&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/13975&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/13975&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15359680" author="shivaram" created="Fri, 1 Jul 2016 21:37:22 +0000"  >&lt;p&gt;Issue resolved by pull request 13975&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/13975&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/13975&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12985064">SPARK-16300</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 20 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30bon:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>