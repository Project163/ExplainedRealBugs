<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:53:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-20700] InferFiltersFromConstraints stackoverflows for query (v2)</title>
                <link>https://issues.apache.org/jira/browse/SPARK-20700</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following (complicated) query eventually fails with a stack overflow during optimization:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;CREATE TEMPORARY VIEW table_5(varchar0002_col_1, smallint_col_2, float_col_3, int_col_4, string_col_5, timestamp_col_6, string_col_7) AS VALUES
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;68&apos;&lt;/span&gt;, CAST(NULL AS SMALLINT), CAST(244.90413 AS FLOAT), -137, &lt;span class=&quot;code-quote&quot;&gt;&apos;571&apos;&lt;/span&gt;, TIMESTAMP(&lt;span class=&quot;code-quote&quot;&gt;&apos;2015-01-14 00:00:00.0&apos;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&apos;947&apos;&lt;/span&gt;),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;82&apos;&lt;/span&gt;, CAST(213 AS SMALLINT), CAST(53.184647 AS FLOAT), -724, &lt;span class=&quot;code-quote&quot;&gt;&apos;-278&apos;&lt;/span&gt;, TIMESTAMP(&lt;span class=&quot;code-quote&quot;&gt;&apos;1999-08-15 00:00:00.0&apos;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&apos;437&apos;&lt;/span&gt;),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;-7&apos;&lt;/span&gt;, CAST(-15 AS SMALLINT), CAST(NULL AS FLOAT), -890, &lt;span class=&quot;code-quote&quot;&gt;&apos;778&apos;&lt;/span&gt;, TIMESTAMP(&lt;span class=&quot;code-quote&quot;&gt;&apos;1991-05-23 00:00:00.0&apos;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&apos;630&apos;&lt;/span&gt;),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;22&apos;&lt;/span&gt;, CAST(676 AS SMALLINT), CAST(385.27386 AS FLOAT), CAST(NULL AS INT), &lt;span class=&quot;code-quote&quot;&gt;&apos;-10&apos;&lt;/span&gt;, TIMESTAMP(&lt;span class=&quot;code-quote&quot;&gt;&apos;1996-09-29 00:00:00.0&apos;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&apos;641&apos;&lt;/span&gt;),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;16&apos;&lt;/span&gt;, CAST(430 AS SMALLINT), CAST(187.23717 AS FLOAT), 989, CAST(NULL AS STRING), TIMESTAMP(&lt;span class=&quot;code-quote&quot;&gt;&apos;2024-04-21 00:00:00.0&apos;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&apos;-234&apos;&lt;/span&gt;),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;83&apos;&lt;/span&gt;, CAST(760 AS SMALLINT), CAST(-695.45386 AS FLOAT), -970, &lt;span class=&quot;code-quote&quot;&gt;&apos;330&apos;&lt;/span&gt;, CAST(NULL AS TIMESTAMP), &lt;span class=&quot;code-quote&quot;&gt;&apos;-740&apos;&lt;/span&gt;),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;68&apos;&lt;/span&gt;, CAST(-930 AS SMALLINT), CAST(NULL AS FLOAT), -915, &lt;span class=&quot;code-quote&quot;&gt;&apos;-766&apos;&lt;/span&gt;, CAST(NULL AS TIMESTAMP), CAST(NULL AS STRING)),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;48&apos;&lt;/span&gt;, CAST(692 AS SMALLINT), CAST(-220.59615 AS FLOAT), 940, &lt;span class=&quot;code-quote&quot;&gt;&apos;-514&apos;&lt;/span&gt;, CAST(NULL AS TIMESTAMP), &lt;span class=&quot;code-quote&quot;&gt;&apos;181&apos;&lt;/span&gt;),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;21&apos;&lt;/span&gt;, CAST(44 AS SMALLINT), CAST(NULL AS FLOAT), -175, &lt;span class=&quot;code-quote&quot;&gt;&apos;761&apos;&lt;/span&gt;, TIMESTAMP(&lt;span class=&quot;code-quote&quot;&gt;&apos;2016-06-30 00:00:00.0&apos;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&apos;487&apos;&lt;/span&gt;),
  (&lt;span class=&quot;code-quote&quot;&gt;&apos;50&apos;&lt;/span&gt;, CAST(953 AS SMALLINT), CAST(837.2948 AS FLOAT), 705, CAST(NULL AS STRING), CAST(NULL AS TIMESTAMP), &lt;span class=&quot;code-quote&quot;&gt;&apos;-62&apos;&lt;/span&gt;);

CREATE VIEW bools(a, b) as values (1, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;), (1, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;), (1, &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;);

SELECT
AVG(-13) OVER (ORDER BY COUNT(t1.smallint_col_2) DESC ROWS 27 PRECEDING ) AS float_col,
COUNT(t1.smallint_col_2) AS int_col
FROM table_5 t1
INNER JOIN (
SELECT
(MIN(-83) OVER (PARTITION BY t2.a ORDER BY t2.a, (t1.int_col_4) * (t1.int_col_4) ROWS BETWEEN CURRENT ROW AND 15 FOLLOWING)) NOT IN (-222, 928) AS boolean_col,
t2.a,
(t1.int_col_4) * (t1.int_col_4) AS int_col
FROM table_5 t1
LEFT JOIN bools t2 ON (t2.a) = (t1.int_col_4)
WHERE
(t1.smallint_col_2) &amp;gt; (t1.smallint_col_2)
GROUP BY
t2.a,
(t1.int_col_4) * (t1.int_col_4)
HAVING
((t1.int_col_4) * (t1.int_col_4)) IN ((t1.int_col_4) * (t1.int_col_4), SUM(t1.int_col_4))
) t2 ON (((t2.int_col) = (t1.int_col_4)) AND ((t2.a) = (t1.int_col_4))) AND ((t2.a) = (t1.smallint_col_2));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(I haven&apos;t tried to minimize this failing case yet).&lt;/p&gt;

&lt;p&gt;Based on sampled jstacks from the driver, it looks like the query might be repeatedly inferring filters from constraints and then pruning those filters.&lt;/p&gt;

&lt;p&gt;Here&apos;s part of the stack at the point where it stackoverflows:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[... repeats ...]
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;flatMap(TraversableLike.scala:241)
        at scala.collection.immutable.List.flatMap(List.scala:344)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;flatMap(TraversableLike.scala:241)
        at scala.collection.immutable.List.flatMap(List.scala:344)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;flatMap(TraversableLike.scala:241)
        at scala.collection.immutable.List.flatMap(List.scala:344)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;flatMap(TraversableLike.scala:241)
        at scala.collection.immutable.List.flatMap(List.scala:344)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;flatMap(TraversableLike.scala:241)
        at scala.collection.immutable.List.flatMap(List.scala:344)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$$anonfun$org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative$1.apply(Canonicalize.scala:50)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;flatMap(TraversableLike.scala:241)
        at scala.collection.immutable.List.flatMap(List.scala:344)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.org$apache$spark$sql$catalyst$expressions$Canonicalize$$gatherCommutative(Canonicalize.scala:50)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.orderCommutative(Canonicalize.scala:58)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.expressionReorder(Canonicalize.scala:63)
        at org.apache.spark.sql.catalyst.expressions.Canonicalize$.execute(Canonicalize.scala:36)
        at org.apache.spark.sql.catalyst.expressions.Expression.canonicalized$lzycompute(Expression.scala:158)
        - locked &amp;lt;0x00000007a298b940&amp;gt; (a org.apache.spark.sql.catalyst.expressions.Multiply)
        at org.apache.spark.sql.catalyst.expressions.Expression.canonicalized(Expression.scala:156)
        at org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$1.apply(Expression.scala:157)
        at org.apache.spark.sql.catalyst.expressions.Expression$$anonfun$1.apply(Expression.scala:157)
        at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
[...]
 at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at scala.collection.TraversableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;map(TraversableLike.scala:234)
        at scala.collection.immutable.List.map(List.scala:285)
        at org.apache.spark.sql.catalyst.expressions.Expression.canonicalized$lzycompute(Expression.scala:157)
        - locked &amp;lt;0x00000007a28b7170&amp;gt; (a org.apache.spark.sql.catalyst.expressions.EqualNullSafe)
        at org.apache.spark.sql.catalyst.expressions.Expression.canonicalized(Expression.scala:156)
        at org.apache.spark.sql.catalyst.expressions.ExpressionSet.add(ExpressionSet.scala:56)
        at org.apache.spark.sql.catalyst.expressions.ExpressionSet.$plus(ExpressionSet.scala:66)
        at org.apache.spark.sql.catalyst.expressions.ExpressionSet.$plus(ExpressionSet.scala:50)
        at scala.collection.SetLike$$anonfun$$plus$plus$1.apply(SetLike.scala:141)
        at scala.collection.SetLike$$anonfun$$plus$plus$1.apply(SetLike.scala:141)
        at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
        at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157)
        at scala.collection.Iterator$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(Iterator.scala:893)
        at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
        at scala.collection.IterableLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(IterableLike.scala:72)
        at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
        at scala.collection.immutable.HashSet$HashSetCollision1.foreach(HashSet.scala:462)
        at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
        at scala.collection.immutable.HashSet$HashTrieSet.foreach(HashSet.scala:972)
        at scala.collection.TraversableOnce$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(TraversableOnce.scala:157)
        at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104)
        at scala.collection.TraversableOnce$class.$div$colon(TraversableOnce.scala:151)
        at scala.collection.AbstractTraversable.$div$colon(Traversable.scala:104)
        at scala.collection.SetLike$class.$plus$plus(SetLike.scala:141)
        at org.apache.spark.sql.catalyst.expressions.ExpressionSet.$plus$plus(ExpressionSet.scala:50)
        at scala.collection.SetLike$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;union(SetLike.scala:163)
        at org.apache.spark.sql.catalyst.expressions.ExpressionSet.union(ExpressionSet.scala:50)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.getRelevantConstraints(QueryPlan.scala:35)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints$lzycompute(QueryPlan.scala:187)
        - locked &amp;lt;0x000000079a7ebaa8&amp;gt; (a org.apache.spark.sql.catalyst.plans.logical.Join)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints(QueryPlan.scala:187)
        at org.apache.spark.sql.catalyst.plans.logical.Filter.validConstraints(basicLogicalOperators.scala:138)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints$lzycompute(QueryPlan.scala:187)
        - locked &amp;lt;0x000000079a7eba58&amp;gt; (a org.apache.spark.sql.catalyst.plans.logical.Filter)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints(QueryPlan.scala:187)
        at org.apache.spark.sql.catalyst.plans.logical.Aggregate.validConstraints(basicLogicalOperators.scala:571)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints$lzycompute(QueryPlan.scala:187)
        - locked &amp;lt;0x000000079a7eb958&amp;gt; (a org.apache.spark.sql.catalyst.plans.logical.Aggregate)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints(QueryPlan.scala:187)
        at org.apache.spark.sql.catalyst.plans.logical.Filter.validConstraints(basicLogicalOperators.scala:138)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints$lzycompute(QueryPlan.scala:187)
        - locked &amp;lt;0x000000079a7eb908&amp;gt; (a org.apache.spark.sql.catalyst.plans.logical.Filter)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints(QueryPlan.scala:187)
        at org.apache.spark.sql.catalyst.plans.logical.Project.validConstraints(basicLogicalOperators.scala:65)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints$lzycompute(QueryPlan.scala:187)
        - locked &amp;lt;0x000000079a7eb328&amp;gt; (a org.apache.spark.sql.catalyst.plans.logical.Project)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints(QueryPlan.scala:187)
        at org.apache.spark.sql.catalyst.plans.logical.Join.validConstraints(basicLogicalOperators.scala:320)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints$lzycompute(QueryPlan.scala:187)
        - locked &amp;lt;0x000000079a7eb2c0&amp;gt; (a org.apache.spark.sql.catalyst.plans.logical.Join)
        at org.apache.spark.sql.catalyst.plans.QueryPlan.constraints(QueryPlan.scala:187)
        at org.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints$$anonfun$inferFilters$1.applyOrElse(Optimizer.scala:642)
        at org.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints$$anonfun$inferFilters$1.applyOrElse(Optimizer.scala:629)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
        at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:266)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
        at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
        at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:256)
        at org.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints.inferFilters(Optimizer.scala:629)
        at org.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints.apply(Optimizer.scala:623)
        at org.apache.spark.sql.catalyst.optimizer.InferFiltersFromConstraints.apply(Optimizer.scala:620)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:85)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:82)
        at scala.collection.LinearSeqOptimized$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foldLeft(LinearSeqOptimized.scala:124)
        at scala.collection.immutable.List.foldLeft(List.scala:84)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:82)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:74)
        at scala.collection.immutable.List.foreach(List.scala:381)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:74)
        at org.apache.spark.sql.execution.QueryExecution.optimizedPlan$lzycompute(QueryExecution.scala:79)
        - locked &amp;lt;0x0000000787ea2848&amp;gt; (a org.apache.spark.sql.execution.QueryExecution)
        at org.apache.spark.sql.execution.QueryExecution.optimizedPlan(QueryExecution.scala:79)
        at org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:85)
        - locked &amp;lt;0x0000000787ea2848&amp;gt; (a org.apache.spark.sql.execution.QueryExecution)
        at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:81)
        at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:90)
        - locked &amp;lt;0x0000000787ea2848&amp;gt; (a org.apache.spark.sql.execution.QueryExecution)
[...]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I suspect this is similar to &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-17733&quot; title=&quot;InferFiltersFromConstraints rule never terminates for query&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-17733&quot;&gt;&lt;del&gt;SPARK-17733&lt;/del&gt;&lt;/a&gt;, another bug where &lt;tt&gt;InferFiltersFromConstraints&lt;/tt&gt;, so I&apos;ll cc &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jiangxb1987&quot; class=&quot;user-hover&quot; rel=&quot;jiangxb1987&quot;&gt;jiangxb1987&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sameerag&quot; class=&quot;user-hover&quot; rel=&quot;sameerag&quot;&gt;sameerag&lt;/a&gt; who worked on that earlier fix.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13070965">SPARK-20700</key>
            <summary>InferFiltersFromConstraints stackoverflows for query (v2)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jiangxb1987">Xingbo Jiang</assignee>
                                    <reporter username="joshrosen">Josh Rosen</reporter>
                        <labels>
                    </labels>
                <created>Wed, 10 May 2017 21:30:57 +0000</created>
                <updated>Thu, 18 May 2017 06:34:27 +0000</updated>
                            <resolved>Thu, 18 May 2017 06:34:27 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>Optimizer</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="16006201" author="jiangxb1987" created="Thu, 11 May 2017 10:18:33 +0000"  >&lt;p&gt;I&apos;m working on this, thank you!&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=joshrosen&quot; class=&quot;user-hover&quot; rel=&quot;joshrosen&quot;&gt;joshrosen&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16008286" author="jiangxb1987" created="Fri, 12 May 2017 15:29:59 +0000"  >&lt;p&gt;I&apos;ve reproduced this case, will dive further into it this weekend.&lt;/p&gt;</comment>
                            <comment id="16013199" author="jiangxb1987" created="Tue, 16 May 2017 22:21:16 +0000"  >&lt;p&gt;In the previous approach we used `aliasMap` to link an `Attribute` to the expression with potentially the form `f(a, b)`, but we only searched the `expressions` and `children.expressions` for this, which is not enough when an `Alias` may lies deep in the logical plan. In that case, we can&apos;t generate the valid equivalent constraint classes and thus we fail at preventing the recursive deductions.&lt;/p&gt;

&lt;p&gt;I&apos;ll send a PR to fix this later today.&lt;/p&gt;</comment>
                            <comment id="16014458" author="apachespark" created="Wed, 17 May 2017 17:30:04 +0000"  >&lt;p&gt;User &apos;jiangxb1987&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/18020&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/18020&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13008709">SPARK-17733</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 26 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3esuf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>