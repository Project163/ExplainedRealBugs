<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:16:38 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3114] Python UDFS broken in Spark SQL</title>
                <link>https://issues.apache.org/jira/browse/SPARK-3114</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;Python UDFs were inadvertently broken in SparkSQL by the PySpark broadcast-optimization commit:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;**********************************************************************
File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/joshrosen/Documents/Spark/python/pyspark/sql.py&quot;&lt;/span&gt;, line 975, in pyspark.sql.SQLContext.registerFunction
Failed example:
    sqlCtx.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT twoArgs(&lt;span class=&quot;code-quote&quot;&gt;&apos;test&apos;&lt;/span&gt;, 1)&quot;&lt;/span&gt;).collect()
Exception raised:
    Traceback (most recent call last):
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/&lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;/Library/Frameworks/Python.framework/Versions/2.6/lib/python2.6/doctest.py&quot;&lt;/span&gt;, line 1253, in __run
        compileflags, 1) in test.globs
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;&amp;lt;doctest pyspark.sql.SQLContext.registerFunction[5]&amp;gt;&quot;&lt;/span&gt;, line 1, in &amp;lt;module&amp;gt;
        sqlCtx.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;SELECT twoArgs(&lt;span class=&quot;code-quote&quot;&gt;&apos;test&apos;&lt;/span&gt;, 1)&quot;&lt;/span&gt;).collect()
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/joshrosen/Documents/Spark/python/pyspark/sql.py&quot;&lt;/span&gt;, line 1615, in collect
        rows = RDD.collect(self)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/joshrosen/Documents/Spark/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 725, in collect
        bytesInJava = self._jrdd.collect().iterator()
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/joshrosen/Documents/Spark/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py&quot;&lt;/span&gt;, line 538, in __call__
        self.target_id, self.name)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/joshrosen/Documents/Spark/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py&quot;&lt;/span&gt;, line 300, in get_return_value
        format(target_id, &lt;span class=&quot;code-quote&quot;&gt;&apos;.&apos;&lt;/span&gt;, name), value)
    Py4JJavaError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling o607.collect.
    : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 60.0 failed 1 times, most recent failure: Lost task 0.0 in stage 60.0 (TID 141, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyspark/worker.py&quot;&lt;/span&gt;, line 75, in main
        command = ser._read_with_length(infile)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyspark/serializers.py&quot;&lt;/span&gt;, line 150, in _read_with_length
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.loads(obj)
      File &lt;span class=&quot;code-quote&quot;&gt;&quot;pyspark/serializers.py&quot;&lt;/span&gt;, line 420, in loads
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.serializer.loads(zlib.decompress(obj))
    error: Error -3 &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; decompressing data: incorrect header check

            org.apache.spark.api.python.PythonRDD$$anon$1.read(PythonRDD.scala:124)
            org.apache.spark.api.python.PythonRDD$$anon$1.&amp;lt;init&amp;gt;(PythonRDD.scala:154)
            org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:87)
            org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
            org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
            org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
            org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
            org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
            org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
            org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
            org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
            org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:87)
            org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
            org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
            org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
            org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
            org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
            org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
            org.apache.spark.sql.SchemaRDD.compute(SchemaRDD.scala:115)
            org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
            org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
            org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:35)
            org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
            org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
            org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
            org.apache.spark.scheduler.Task.run(Task.scala:54)
            org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:199)
            java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
            java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
            java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
    Driver stacktrace:
    	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1153)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1142)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1141)
    	at scala.collection.mutable.ResizableArray$&lt;span class=&quot;code-keyword&quot;&gt;class.&lt;/span&gt;foreach(ResizableArray.scala:59)
    	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
    	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1141)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:682)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:682)
    	at scala.Option.foreach(Option.scala:236)
    	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:682)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessActor$$anonfun$receive$2.applyOrElse(DAGScheduler.scala:1359)
    	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:498)
    	at akka.actor.ActorCell.invoke(ActorCell.scala:456)
    	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:237)
    	at akka.dispatch.Mailbox.run(Mailbox.scala:219)
    	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:386)
    	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The zlib compression was introduced in a recent commit for improving PySpark&#8217;s broadcast variable performance (&lt;a href=&quot;https://github.com/apache/spark/pull/1912&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/1912&lt;/a&gt;).  It looks like the worker is expecting to receive a zlib-compressed command, but somehow is receiving something else.  &lt;/p&gt;

&lt;p&gt;It looks like the code that registers Python UDFs doesn&#8217;t perform this compression, leading to this issue:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        self._ssql_ctx.registerPython(name,
                                      bytearray(CloudPickleSerializer().dumps(command)),
                                      env,
                                      includes,
                                      self._sc.pythonExec,
                                      self._sc._javaAccumulator,
                                      str(returnType))
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The root problem here is that the SparkSQL Python tests weren&apos;t run by Jenkins.  I think the problem is that PySpark&#8217;s SparkSQL tests are skipped unless _RUN_SQL_TESTS is true, and this is variable is only set when we detect changes to SparkSQL.  Instead, it should always be set when running the PySpark tests.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12734903">SPARK-3114</key>
            <summary>Python UDFS broken in Spark SQL</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="joshrosen">Josh Rosen</assignee>
                                    <reporter username="joshrosen">Josh Rosen</reporter>
                        <labels>
                    </labels>
                <created>Tue, 19 Aug 2014 00:34:07 +0000</created>
                <updated>Tue, 19 Aug 2014 03:43:29 +0000</updated>
                            <resolved>Tue, 19 Aug 2014 03:43:29 +0000</resolved>
                                    <version>1.1.0</version>
                                    <fixVersion>1.1.0</fixVersion>
                                    <component>PySpark</component>
                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14101625" author="apachespark" created="Tue, 19 Aug 2014 00:52:09 +0000"  >&lt;p&gt;User &apos;davies&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2026&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2026&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14101713" author="apachespark" created="Tue, 19 Aug 2014 02:02:02 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2027&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2027&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>412843</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 14 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1z0pz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>412829</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12326686">1.1.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>