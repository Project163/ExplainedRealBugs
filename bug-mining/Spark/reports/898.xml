<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:19:11 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-3426] Sort-based shuffle compression behavior is inconsistent</title>
                <link>https://issues.apache.org/jira/browse/SPARK-3426</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We have the following configs:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;spark.shuffle.compress
spark.shuffle.spill.compress
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When these two diverge, sort-based shuffle fails with a compression exception under certain workloads. This is because in sort-based shuffle we serve the index file (using spark.shuffle.spill.compress) as a normal shuffle file (using spark.shuffle.compress). It was unfortunate in retrospect that these two configs were exposed so we can&apos;t easily remove them.&lt;/p&gt;

&lt;p&gt;Here is how this can be reproduced. Set the following in your spark-defaults.conf:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;spark.master                  local-cluster[1,1,512]
spark.shuffle.spill.compress  &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
spark.shuffle.compress        &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
spark.shuffle.manager         sort
spark.shuffle.memoryFraction  0.001
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Then run the following in spark-shell:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;sc.parallelize(0 until 100000).map(i =&amp;gt; (i/4, i)).groupByKey().collect()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This leads to compression errors, such as the following:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 8, joshs-mbp): java.io.IOException: FAILED_TO_UNCOMPRESS(5)
[info]         org.xerial.snappy.SnappyNative.throw_error(SnappyNative.java:84)
[info]         org.xerial.snappy.SnappyNative.rawUncompress(Native Method)
[info]         org.xerial.snappy.Snappy.rawUncompress(Snappy.java:444)
[info]         org.xerial.snappy.Snappy.uncompress(Snappy.java:480)
[info]         org.xerial.snappy.SnappyInputStream.readFully(SnappyInputStream.java:127)
[info]         org.xerial.snappy.SnappyInputStream.readHeader(SnappyInputStream.java:88)
[info]         org.xerial.snappy.SnappyInputStream.&amp;lt;init&amp;gt;(SnappyInputStream.java:58)
[info]         org.apache.spark.io.SnappyCompressionCodec.compressedInputStream(CompressionCodec.scala:128)
[info]         org.apache.spark.storage.BlockManager.wrapForCompression(BlockManager.scala:1090)
[info]         org.apache.spark.storage.BlockManager.getLocalShuffleFromDisk(BlockManager.scala:350)
[info]         org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchLocalBlocks$1$$anonfun$apply$4.apply(ShuffleBlockFetcherIterator.scala:196)
[info]         org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchLocalBlocks$1$$anonfun$apply$4.apply(ShuffleBlockFetcherIterator.scala:196)
[info]         org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:243)
[info]         org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:52)
[info]         scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
[info]         org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
[info]         org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
[info]         org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:129)
[info]         org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:58)
[info]         org.apache.spark.shuffle.hash.HashShuffleReader.read(HashShuffleReader.scala:46)
[info]         org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:92)
[info]         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
[info]         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
[info]         org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
[info]         org.apache.spark.scheduler.Task.run(Task.scala:56)
[info]         org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
[info]         java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
[info]         java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
[info]         java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Similarly, with&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;spark.shuffle.spill.compress  &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
spark.shuffle.compress        &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;we see&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;info]   org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 8, joshs-mbp): java.io.StreamCorruptedException: invalid stream header: 82534E41
[info]         java.io.ObjectInputStream.readStreamHeader(ObjectInputStream.java:804)
[info]         java.io.ObjectInputStream.&amp;lt;init&amp;gt;(ObjectInputStream.java:299)
[info]         org.apache.spark.serializer.JavaDeserializationStream$$anon$1.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
[info]         org.apache.spark.serializer.JavaDeserializationStream.&amp;lt;init&amp;gt;(JavaSerializer.scala:57)
[info]         org.apache.spark.serializer.JavaSerializerInstance.deserializeStream(JavaSerializer.scala:95)
[info]         org.apache.spark.storage.BlockManager.getLocalShuffleFromDisk(BlockManager.scala:355)
[info]         org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchLocalBlocks$1$$anonfun$apply$4.apply(ShuffleBlockFetcherIterator.scala:197)
[info]         org.apache.spark.storage.ShuffleBlockFetcherIterator$$anonfun$fetchLocalBlocks$1$$anonfun$apply$4.apply(ShuffleBlockFetcherIterator.scala:197)
[info]         org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:244)
[info]         org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:52)
[info]         scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
[info]         org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:30)
[info]         org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
[info]         org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:129)
[info]         org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:58)
[info]         org.apache.spark.shuffle.hash.HashShuffleReader.read(HashShuffleReader.scala:46)
[info]         org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:92)
[info]         org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:262)
[info]         org.apache.spark.rdd.RDD.iterator(RDD.scala:229)
[info]         org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)
[info]         org.apache.spark.scheduler.Task.run(Task.scala:56)
[info]         org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:181)
[info]         java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
[info]         java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
[info]         java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="12739711">SPARK-3426</key>
            <summary>Sort-based shuffle compression behavior is inconsistent</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="joshrosen">Josh Rosen</assignee>
                                    <reporter username="andrewor14">Andrew Or</reporter>
                        <labels>
                    </labels>
                <created>Sat, 6 Sep 2014 18:09:48 +0000</created>
                <updated>Wed, 22 Oct 2014 22:12:29 +0000</updated>
                            <resolved>Wed, 22 Oct 2014 22:12:28 +0000</resolved>
                                    <version>1.1.0</version>
                    <version>1.2.0</version>
                                    <fixVersion>1.1.1</fixVersion>
                    <fixVersion>1.2.0</fixVersion>
                                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="14170386" author="jerryshao" created="Tue, 14 Oct 2014 02:23:26 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrewor14&quot; class=&quot;user-hover&quot; rel=&quot;andrewor14&quot;&gt;andrewor14&lt;/a&gt;, are you going to fix this issue, what is plan to fix this: remove &quot;spark.shuffle.spill.compress&quot; to keep the consistency or just modify the code in ExternalSorter to fit this inconsistency? &lt;/p&gt;

&lt;p&gt;We&apos;ve also met this issue and seems two solutions are both not so good, what is your opinion?&lt;/p&gt;

&lt;p&gt;Thanks a lot.&lt;/p&gt;</comment>
                            <comment id="14170395" author="jerryshao" created="Tue, 14 Oct 2014 02:35:30 +0000"  >&lt;p&gt;Sorry about that, I just saw the PR (&lt;a href=&quot;https://github.com/apache/spark/pull/2247&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2247&lt;/a&gt;) discuss about this.&lt;/p&gt;</comment>
                            <comment id="14179336" author="joshrosen" created="Tue, 21 Oct 2014 23:48:07 +0000"  >&lt;p&gt;I&apos;ve edited this issue to list the actual exception that&apos;s produced.  This may explain another one of the distinct Snappy errors that we&apos;ve seen.  I&apos;ll start working on a fix now.&lt;/p&gt;</comment>
                            <comment id="14179355" author="joshrosen" created="Tue, 21 Oct 2014 23:58:41 +0000"  >&lt;p&gt;Based on the discussion in that PR, it sounds folks would rather fix the underlying bug rather than changing / ignoring configurations.  I&apos;ll look into a small, targeted fix for this.&lt;/p&gt;</comment>
                            <comment id="14179660" author="apachespark" created="Wed, 22 Oct 2014 07:00:50 +0000"  >&lt;p&gt;User &apos;JoshRosen&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/2890&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/2890&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14180638" author="joshrosen" created="Wed, 22 Oct 2014 22:12:29 +0000"  >&lt;p&gt;Fixed in 1.1.1. and 1.2.0 by my PR.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12743065">SPARK-3630</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12738728">SPARK-3367</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 4 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1zrif:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12327368">1.1.1</customfieldvalue>
    <customfieldvalue id="12327369">1.2.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>