<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:18:04 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-32148] LEFT JOIN generating non-deterministic and unexpected result (regression in Spark 3.0)</title>
                <link>https://issues.apache.org/jira/browse/SPARK-32148</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When upgrading from Spark 2.4.6 to 3.0.0 I found that previously working LEFT JOINs now output unexpected results.&lt;/p&gt;

&lt;p&gt;Below is a minimal example to run in &lt;tt&gt;spark-shell&lt;/tt&gt; to demonstrate this. In it there are 3 events on the left side of the join and two on the right.&lt;br/&gt;
 The expected output should contain two matching pairs and one item on the left side without a matching right side, so that it should be output with the right side fields being &lt;tt&gt;NULL&lt;/tt&gt;. The join condition is that event times must be max. 30sec apart and the IDs must match.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-scala&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; spark.implicits._
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.Encoders
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.functions.expr
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.streaming.OutputMode
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.sql.Timestamp
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; java.util.UUID

&lt;span class=&quot;code-comment&quot;&gt;// Structure of left and right data items
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;LeftEntry(eventTime: Timestamp, id: String, comment: String)
&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;RightEntry(eventTime: Timestamp, id: String, name: String)

&lt;span class=&quot;code-comment&quot;&gt;// Some test data
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; leftData = Vector(
  LeftEntry(Timestamp.valueOf(&lt;span class=&quot;code-quote&quot;&gt;&quot;2020-01-01 00:00:00&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;abc&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;has no join partner&quot;&lt;/span&gt;),
  LeftEntry(Timestamp.valueOf(&lt;span class=&quot;code-quote&quot;&gt;&quot;2020-01-02 00:00:00&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;abc&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;joined &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; A&quot;&lt;/span&gt;),
  LeftEntry(Timestamp.valueOf(&lt;span class=&quot;code-quote&quot;&gt;&quot;2020-01-02 01:00:00&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;abc&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;joined &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; B&quot;&lt;/span&gt;)
)

&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; rightData = Vector(
  RightEntry(Timestamp.valueOf(&lt;span class=&quot;code-quote&quot;&gt;&quot;2020-01-02 00:00:10&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;abc&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;A&quot;&lt;/span&gt;),
  RightEntry(Timestamp.valueOf(&lt;span class=&quot;code-quote&quot;&gt;&quot;2020-01-02 00:59:59&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;abc&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;B&quot;&lt;/span&gt;)
)

&lt;span class=&quot;code-comment&quot;&gt;// Write test data, that we will stream from later (random output directories; alternatively we could delete the directories after each run)
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; leftFilePath = s&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/demo-left-data-${UUID.randomUUID()}&quot;&lt;/span&gt;
spark.createDataset(leftData).write.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;).save(leftFilePath)
&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; rightFilePath = s&lt;span class=&quot;code-quote&quot;&gt;&quot;/tmp/demo-right-data-${UUID.randomUUID()}&quot;&lt;/span&gt;
spark.createDataset(rightData).write.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;parquet&quot;&lt;/span&gt;).save(rightFilePath)

&lt;span class=&quot;code-comment&quot;&gt;// Read data from Parquet as stream
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; leftStream = spark.readStream
  .schema(Encoders.product[LeftEntry].schema)
  .parquet(leftFilePath)
  .withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;eventTime&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;2 minutes&quot;&lt;/span&gt;)
&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; rightStream = spark.readStream
  .schema(Encoders.product[RightEntry].schema)
  .parquet(rightFilePath)
  .withWatermark(&lt;span class=&quot;code-quote&quot;&gt;&quot;eventTime&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;4 minutes&quot;&lt;/span&gt;)

&lt;span class=&quot;code-comment&quot;&gt;// Define Join
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; joinExpression = expr(
  s&quot;&quot;&quot;
     |leftStream.id = rightStream.id AND
     |leftStream.eventTime BETWEEN
     |  rightStream.eventTime - INTERVAL 30 seconds AND
     |  rightStream.eventTime + INTERVAL 30 seconds
    &quot;&quot;&quot;.stripMargin
)
&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; joinedData = leftStream.as(&lt;span class=&quot;code-quote&quot;&gt;&quot;leftStream&quot;&lt;/span&gt;)
  .join(
    rightStream.as(&lt;span class=&quot;code-quote&quot;&gt;&quot;rightStream&quot;&lt;/span&gt;),
    joinExpression,
    &lt;span class=&quot;code-quote&quot;&gt;&quot;left&quot;&lt;/span&gt;
  )

&lt;span class=&quot;code-comment&quot;&gt;// Run query
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; query = joinedData.writeStream
  .format(&lt;span class=&quot;code-quote&quot;&gt;&quot;memory&quot;&lt;/span&gt;)
  .queryName(&lt;span class=&quot;code-quote&quot;&gt;&quot;myQuery&quot;&lt;/span&gt;)
  .outputMode(OutputMode.Append())
  .start()
query.processAllAvailable()

&lt;span class=&quot;code-comment&quot;&gt;// Print results
&lt;/span&gt;spark
  .table(query.name)
  .show(truncate = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When this is executed with Spark 2.4.6, the result is as expected and deterministic:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+-------------------+---+-------------------+-------------------+----+----+
|eventTime          |id |comment            |eventTime          |id  |name|
+-------------------+---+-------------------+-------------------+----+----+
|2020-01-02 00:00:00|abc|joined with A      |2020-01-02 00:00:10|abc |A   |
|2020-01-02 01:00:00|abc|joined with B      |2020-01-02 00:59:59|abc |B   |
|2020-01-01 00:00:00|abc|has no join partner|null               |null|null|  &#8592; as expected
+-------------------+---+-------------------+-------------------+----+----+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;When running the same code snippet with Spark 3.0.0, the result is non-deterministically one of these two:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+-------------------+---+-------------+-------------------+----+----+
|eventTime          |id |comment      |eventTime          |id  |name|
+-------------------+---+-------------+-------------------+----+----+
|2020-01-02 01:00:00|abc|joined with B|2020-01-02 00:59:59|abc |B   |
|2020-01-02 00:00:00|abc|joined with A|2020-01-02 00:00:10|abc |A   |
|2020-01-02 00:00:00|abc|joined with A|null               |null|null|  &#8592; this entry was already joined with &quot;A&quot; above,
+-------------------+---+-------------+-------------------+----+----+    but is now here once more without it&apos;s right join side
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+-------------------+---+-------------+-------------------+----+----+
|eventTime          |id |comment      |eventTime          |id  |name|
+-------------------+---+-------------+-------------------+----+----+
|2020-01-02 00:00:00|abc|joined with A|2020-01-02 00:00:10|abc |A   |
|2020-01-02 01:00:00|abc|joined with B|2020-01-02 00:59:59|abc |B   |
|2020-01-02 01:00:00|abc|joined with B|null               |null|null|  &#8592; this entry was already joined with &quot;B&quot; above,
+-------------------+---+-------------+-------------------+----+----+    but is now here once more without it&apos;s right join side
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;... with &lt;tt&gt;&quot;has no join partner&quot;&lt;/tt&gt; completely missing, and instead one of the actually joinable left-side items repeated without the right-side fields.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;In case the input data is modified, so that the non-joinable event additionally has a different ID, then Spark 3.0 generates correct output:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-scala&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// [...]
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;val&lt;/span&gt; leftData = Vector(
  LeftEntry(Timestamp.valueOf(&lt;span class=&quot;code-quote&quot;&gt;&quot;2020-01-01 00:00:00&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;ddd&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;has no join partner&quot;&lt;/span&gt;),
                                                    &lt;span class=&quot;code-comment&quot;&gt;// &#8593;&#8593;&#8593; changed
&lt;/span&gt;  LeftEntry(Timestamp.valueOf(&lt;span class=&quot;code-quote&quot;&gt;&quot;2020-01-02 00:00:00&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;abc&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;joined &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; A&quot;&lt;/span&gt;),
  LeftEntry(Timestamp.valueOf(&lt;span class=&quot;code-quote&quot;&gt;&quot;2020-01-02 01:00:00&quot;&lt;/span&gt;), &lt;span class=&quot;code-quote&quot;&gt;&quot;abc&quot;&lt;/span&gt;, &lt;span class=&quot;code-quote&quot;&gt;&quot;joined &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; B&quot;&lt;/span&gt;)
)
&lt;span class=&quot;code-comment&quot;&gt;// [...]&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+-------------------+---+-------------------+-------------------+----+----+
|eventTime          |id |comment            |eventTime          |id  |name|
+-------------------+---+-------------------+-------------------+----+----+
|2020-01-02 00:00:00|abc|joined with A      |2020-01-02 00:00:10|abc |A   |
|2020-01-02 01:00:00|abc|joined with B      |2020-01-02 00:59:59|abc |B   |
|2020-01-01 00:00:00|ddd|has no join partner|null               |null|null|
+-------------------+---+-------------------+-------------------+----+----+
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13314462">SPARK-32148</key>
            <summary>LEFT JOIN generating non-deterministic and unexpected result (regression in Spark 3.0)</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="kabhwan">Jungtaek Lim</assignee>
                                    <reporter username="hiddenbit">Michael</reporter>
                        <labels>
                            <label>correctness</label>
                    </labels>
                <created>Wed, 1 Jul 2020 12:01:52 +0000</created>
                <updated>Thu, 9 Jul 2020 07:39:55 +0000</updated>
                            <resolved>Thu, 9 Jul 2020 07:39:55 +0000</resolved>
                                    <version>3.0.0</version>
                                    <fixVersion>3.0.1</fixVersion>
                    <fixVersion>3.1.0</fixVersion>
                                    <component>SQL</component>
                    <component>Structured Streaming</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="17149754" author="kabhwan" created="Thu, 2 Jul 2020 00:20:32 +0000"  >&lt;p&gt;Looking into it. Looks like a problem indeed (if then this should be a blocker) but want to make it sure.&lt;/p&gt;</comment>
                            <comment id="17149780" author="cloud_fan" created="Thu, 2 Jul 2020 02:29:25 +0000"  >&lt;p&gt;I assume this is for streaming join? I&apos;m marking it as a blocker since it&apos;s correctness bug&lt;/p&gt;</comment>
                            <comment id="17149922" author="hiddenbit" created="Thu, 2 Jul 2020 05:55:01 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cloud_fan&quot; class=&quot;user-hover&quot; rel=&quot;cloud_fan&quot;&gt;cloud_fan&lt;/a&gt;, yes the issue is with stream-stream joins. Stream-batch joins and pure batch joins seem not to be affected.&lt;/p&gt;</comment>
                            <comment id="17149934" author="apachespark" created="Thu, 2 Jul 2020 06:03:23 +0000"  >&lt;p&gt;User &apos;HeartSaVioR&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28975&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28975&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17149935" author="apachespark" created="Thu, 2 Jul 2020 06:03:43 +0000"  >&lt;p&gt;User &apos;HeartSaVioR&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28975&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28975&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17149948" author="kabhwan" created="Thu, 2 Jul 2020 06:10:06 +0000"  >&lt;p&gt;Just submitted a fix. Unfortunately existing UTs don&apos;t seem to be affected by the problematic part.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hiddenbit&quot; class=&quot;user-hover&quot; rel=&quot;hiddenbit&quot;&gt;hiddenbit&lt;/a&gt; Do you have any other kinds of queries broken by Spark 3.0.0? Your reproducer is very helpful to trace down the issue - we&apos;d be more confident if we have more kinds of queries to verify.&lt;/p&gt;</comment>
                            <comment id="17149960" author="hiddenbit" created="Thu, 2 Jul 2020 06:22:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kabhwan&quot; class=&quot;user-hover&quot; rel=&quot;kabhwan&quot;&gt;kabhwan&lt;/a&gt; thanks a lot for taking care of this so fast!&lt;/p&gt;

&lt;p&gt;After the upgrade we only had one unit-test failing, from which I condensed the reported minimal example. Our other queries seem to work as before.&lt;/p&gt;</comment>
                            <comment id="17154288" author="cloud_fan" created="Thu, 9 Jul 2020 07:39:55 +0000"  >&lt;p&gt;Issue resolved by pull request 28975&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/28975&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/28975&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 18 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0gd80:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>