<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 19:05:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-27907] HiveUDAF should return NULL in case of 0 rows</title>
                <link>https://issues.apache.org/jira/browse/SPARK-27907</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When query returns zero rows, the HiveUDAFFunction throws NPE&lt;/p&gt;

&lt;p&gt;CASE 1:&lt;br/&gt;
create table abc(a int)&lt;br/&gt;
select histogram_numeric(a,2) from abc // NPE&lt;/p&gt;

&lt;p&gt;Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 0, localhost, executor driver): java.lang.NullPointerException&lt;br/&gt;
	at org.apache.spark.sql.hive.HiveUDAFFunction.eval(hiveUDFs.scala:471)&lt;br/&gt;
	at org.apache.spark.sql.hive.HiveUDAFFunction.eval(hiveUDFs.scala:315)&lt;br/&gt;
	at org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.eval(interfaces.scala:543)&lt;br/&gt;
	at org.apache.spark.sql.execution.aggregate.AggregationIterator.$anonfun$generateResultProjection$5(AggregationIterator.scala:231)&lt;br/&gt;
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.outputForEmptyGroupingKeyWithoutInput(ObjectAggregationIterator.scala:97)&lt;br/&gt;
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$2(ObjectHashAggregateExec.scala:132)&lt;br/&gt;
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$2$adapted(ObjectHashAggregateExec.scala:107)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:839)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:839)&lt;br/&gt;
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)&lt;br/&gt;
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)&lt;br/&gt;
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)&lt;br/&gt;
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)&lt;br/&gt;
	at org.apache.spark.scheduler.Task.run(Task.scala:122)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:425)&lt;br/&gt;
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:428)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;


&lt;p&gt;CASE 2:&lt;/p&gt;

&lt;p&gt;create table abc(a int)&lt;br/&gt;
insert into abc values (1)&lt;br/&gt;
select histogram_numeric(a,2) from abc where a=3 //NPE&lt;/p&gt;

&lt;p&gt;Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 5, localhost, executor driver): java.lang.NullPointerException&lt;br/&gt;
	at org.apache.spark.sql.hive.HiveUDAFFunction.serialize(hiveUDFs.scala:477)&lt;br/&gt;
	at org.apache.spark.sql.hive.HiveUDAFFunction.serialize(hiveUDFs.scala:315)&lt;br/&gt;
	at org.apache.spark.sql.catalyst.expressions.aggregate.TypedImperativeAggregate.serializeAggregateBufferInPlace(interfaces.scala:570)&lt;br/&gt;
	at org.apache.spark.sql.execution.aggregate.AggregationIterator.$anonfun$generateResultProjection$6(AggregationIterator.scala:254)&lt;br/&gt;
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.outputForEmptyGroupingKeyWithoutInput(ObjectAggregationIterator.scala:97)&lt;br/&gt;
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$2(ObjectHashAggregateExec.scala:132)&lt;br/&gt;
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$2$adapted(ObjectHashAggregateExec.scala:107)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:839)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:839)&lt;br/&gt;
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)&lt;br/&gt;
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:327)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:291)&lt;br/&gt;
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)&lt;br/&gt;
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:94)&lt;br/&gt;
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)&lt;br/&gt;
	at org.apache.spark.scheduler.Task.run(Task.scala:122)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:425)&lt;br/&gt;
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1350)&lt;br/&gt;
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:428)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)&lt;br/&gt;
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)&lt;br/&gt;
	at java.lang.Thread.run(Thread.java:745)&lt;/p&gt;</description>
                <environment></environment>
        <key id="13236951">SPARK-27907</key>
            <summary>HiveUDAF should return NULL in case of 0 rows</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ajithshetty">Ajith S</assignee>
                                    <reporter username="ajithshetty">Ajith S</reporter>
                        <labels>
                            <label>correctness</label>
                    </labels>
                <created>Fri, 31 May 2019 19:08:47 +0000</created>
                <updated>Mon, 2 Mar 2020 21:18:36 +0000</updated>
                            <resolved>Sun, 2 Jun 2019 17:56:34 +0000</resolved>
                                    <version>2.3.4</version>
                    <version>2.4.3</version>
                                    <fixVersion>2.3.4</fixVersion>
                    <fixVersion>2.4.4</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16854028" author="dongjoon" created="Sun, 2 Jun 2019 17:30:22 +0000"  >&lt;p&gt;Hi, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ajithshetty&quot; class=&quot;user-hover&quot; rel=&quot;ajithshetty&quot;&gt;ajithshetty&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Did you see this in Spark 2.3.3, too? For me, it works like the following.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
scala&amp;gt; spark.version
res0: &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; = 2.3.3

scala&amp;gt; sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;create table abc(a &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt;)&quot;&lt;/span&gt;)

scala&amp;gt; sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select histogram_numeric(a,2) from abc&quot;&lt;/span&gt;).show
+------------------------+
|histogram_numeric( a, 2)|
+------------------------+
| &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;|
+------------------------+&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16854041" author="dongjoon" created="Sun, 2 Jun 2019 17:56:34 +0000"  >&lt;p&gt;I removed 2.3.x from the affected versions. And, this is resolved via &lt;a href=&quot;https://github.com/apache/spark/pull/24762&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/24762&lt;/a&gt;&#160;(master/branch-2.4).&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16854050" author="dongjoon" created="Sun, 2 Jun 2019 18:32:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-24935&quot; title=&quot;Problem with Executing Hive UDF&amp;#39;s from Spark 2.2 Onwards&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-24935&quot;&gt;&lt;del&gt;SPARK-24935&lt;/del&gt;&lt;/a&gt; seems to be the root cause of this regression.&lt;/p&gt;</comment>
                            <comment id="16854052" author="dongjoon" created="Sun, 2 Jun 2019 18:34:24 +0000"  >&lt;p&gt;I checked that&#160;2.3.4-SNAPSHOT has this issue because of&#160; &lt;del&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-24935&quot; title=&quot;Problem with Executing Hive UDF&amp;#39;s from Spark 2.2 Onwards&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-24935&quot;&gt;&lt;del&gt;SPARK-24935&lt;/del&gt;&lt;/a&gt;.&lt;/del&gt;&#160;I backported this patch to `branch-2.3`, too.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13174856">SPARK-24935</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 24 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z03b68:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>