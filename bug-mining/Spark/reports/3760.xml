<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:45:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-16329] select * from temp_table_no_cols fails</title>
                <link>https://issues.apache.org/jira/browse/SPARK-16329</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;The following works with spark 1.5.1, but not anymore with spark 1.6.0:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.{ DataFrame, Row }
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; org.apache.spark.sql.types.StructType

val rddNoCols = sqlContext.sparkContext.parallelize(1 to 10).map(_ =&amp;gt; Row.empty)
val dfNoCols = sqlContext.createDataFrame(rddNoCols, StructType(Seq.empty))

dfNoCols.registerTempTable(&lt;span class=&quot;code-quote&quot;&gt;&quot;temp_table_no_cols&quot;&lt;/span&gt;)

sqlContext.sql(&lt;span class=&quot;code-quote&quot;&gt;&quot;select * from temp_table_no_cols&quot;&lt;/span&gt;).show
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;spark 1.5.1 result:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;++
||
++
||
||
||
||
||
||
||
||
||
||
++
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;spark 1.6.0 result:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.IllegalArgumentException: requirement failed
        at scala.Predef$.require(Predef.scala:221)
        at org.apache.spark.sql.catalyst.analysis.UnresolvedStar.expand(unresolved.scala:199)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$10$$anonfun$applyOrElse$14.apply(Analyzer.scala:354)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$10$$anonfun$applyOrElse$14.apply(Analyzer.scala:353)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251)
        at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:251)
        at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
        at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
        at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:251)
        at scala.collection.AbstractTraversable.flatMap(Traversable.scala:105)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$10.applyOrElse(Analyzer.scala:353)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$$anonfun$apply$10.applyOrElse(Analyzer.scala:347)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:57)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:57)
        at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:53)
        at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:56)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.apply(Analyzer.scala:347)
        at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveReferences$.apply(Analyzer.scala:328)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:83)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:80)
        at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:111)
        at scala.collection.immutable.List.foldLeft(List.scala:84)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:80)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:72)
        at scala.collection.immutable.List.foreach(List.scala:318)
        at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:72)
        at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:36)
        at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:36)
        at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:34)
        at org.apache.spark.sql.DataFrame.&amp;lt;init&amp;gt;(DataFrame.scala:133)
        at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:52)
        at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:817)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:28)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:33)
        at $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:35)
        at $iwC$$iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:37)
        at $iwC$$iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:39)
        at $iwC$$iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:41)
        at $iwC$$iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:43)
        at $iwC.&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:45)
        at &amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:47)
        at .&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:51)
        at .&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)
        at .&amp;lt;init&amp;gt;(&amp;lt;console&amp;gt;:7)
        at .&amp;lt;clinit&amp;gt;(&amp;lt;console&amp;gt;)
        at $print(&amp;lt;console&amp;gt;)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
        at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)
        at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
        at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
        at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
        at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
        at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
        at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
        at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
        at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
        at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
        at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
        at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
        at org.apache.spark.repl.Main$.main(Main.scala:31)
        at org.apache.spark.repl.Main.main(Main.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I can understand why tables with no columns might not be supported in SQL, but in that case I would say that the &lt;tt&gt;dfNoCols.registerTempTable()&lt;/tt&gt; call should fail with a more descriptive error.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12985731">SPARK-16329</key>
            <summary>select * from temp_table_no_cols fails</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="smilegator">Xiao Li</assignee>
                                    <reporter username="i.adri">Adrian Ionescu</reporter>
                        <labels>
                    </labels>
                <created>Thu, 30 Jun 2016 11:53:40 +0000</created>
                <updated>Mon, 4 Jul 2016 05:12:04 +0000</updated>
                            <resolved>Sun, 3 Jul 2016 08:51:26 +0000</resolved>
                                    <version>1.6.0</version>
                    <version>1.6.1</version>
                    <version>1.6.2</version>
                                    <fixVersion>2.1.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="15357545" author="smilegator" created="Thu, 30 Jun 2016 17:50:58 +0000"  >&lt;p&gt;You still can get what you need by &lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;val rddNoCols = sqlContext.sparkContext.parallelize(1 to 10).map(_ =&amp;gt; Row.empty)
val dfNoCols = sqlContext.createDataFrame(rddNoCols, StructType(Seq.empty))
dfNoCols.show
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Any use case for Spark SQL to support such a scenario? Otherwise, I agreed on a better error message we should issue.&lt;/p&gt;</comment>
                            <comment id="15357729" author="i.adri" created="Thu, 30 Jun 2016 19:42:29 +0000"  >&lt;p&gt;Well, this is a simplified example. In reality we assemble the SparkSql query text at run-time, based on user input.&lt;/p&gt;

&lt;p&gt;Sure, working with the Dataframe directly, as you suggest, is possible and it&apos;s what we&apos;re now doing as a workaround, but it requires special casing that would be nice to avoid...&lt;/p&gt;</comment>
                            <comment id="15357758" author="smilegator" created="Thu, 30 Jun 2016 19:59:05 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rxin&quot; class=&quot;user-hover&quot; rel=&quot;rxin&quot;&gt;rxin&lt;/a&gt;What do you think about this? Should we just issue an error message in this case? Thanks!&lt;/p&gt;</comment>
                            <comment id="15357792" author="maropu" created="Thu, 30 Jun 2016 20:27:19 +0000"  >&lt;p&gt;Additional info; the result of the current master is the same with that of v1.5.1, that is, it just returns an empty table.&lt;/p&gt;</comment>
                            <comment id="15357798" author="rxin" created="Thu, 30 Jun 2016 20:30:38 +0000"  >&lt;p&gt;We can fix 1.6.&lt;/p&gt;</comment>
                            <comment id="15357803" author="smilegator" created="Thu, 30 Jun 2016 20:33:57 +0000"  >&lt;p&gt;Which behavior is preferred? &lt;/p&gt;</comment>
                            <comment id="15357804" author="smilegator" created="Thu, 30 Jun 2016 20:35:37 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=maropu&quot; class=&quot;user-hover&quot; rel=&quot;maropu&quot;&gt;maropu&lt;/a&gt; I can reproduce it in the master. It reports a misleading exception.&lt;/p&gt;</comment>
                            <comment id="15357817" author="maropu" created="Thu, 30 Jun 2016 20:45:55 +0000"  >&lt;p&gt;Oh, my bad.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;val rddNoCols = sqlContext.sparkContext.parallelize(1 to 10).map(_ =&amp;gt; Row.empty)
val dfNoCols = sqlContext.createDataFrame(rddNoCols, StructType(Seq.empty))
dfNoCols.show
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above query passed though, the original one threw the exception.&lt;/p&gt;</comment>
                            <comment id="15357824" author="smilegator" created="Thu, 30 Jun 2016 20:47:30 +0000"  >&lt;p&gt;nvm, thank you for your confirmation!&lt;/p&gt;</comment>
                            <comment id="15357826" author="maropu" created="Thu, 30 Jun 2016 20:48:27 +0000"  >&lt;p&gt;One idea to fix this is to follow the behaviour of other databases,  e.g. the example of postgresql is as follows;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;postgres=# create table test_rel();
CREATE TABLE
postgres=# select * from test_rel;
--
(0 rows)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15357831" author="smilegator" created="Thu, 30 Jun 2016 20:52:59 +0000"  >&lt;p&gt;In Hive, we are unable to create a table with 0 column. That is the decision we have to make &lt;/p&gt;</comment>
                            <comment id="15357845" author="maropu" created="Thu, 30 Jun 2016 21:01:52 +0000"  >&lt;p&gt;Tables with no columns make less sense, so the Hive way seems more reasonable to me.&lt;/p&gt;</comment>
                            <comment id="15357897" author="rxin" created="Thu, 30 Jun 2016 21:34:41 +0000"  >&lt;p&gt;Hmmm I tend to like Postgres more &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;It&apos;s a real database. &lt;/p&gt;</comment>
                            <comment id="15357910" author="smilegator" created="Thu, 30 Jun 2016 21:45:27 +0000"  >&lt;p&gt;I see. Will try to do it.&lt;/p&gt;

&lt;p&gt;Just FYI, I tried it in DB2. &lt;/p&gt;

&lt;p&gt;db2 =&amp;gt; create table t2()&lt;br/&gt;
DB21034E  The command was processed as an SQL statement because it was not a &lt;br/&gt;
valid Command Line Processor command.  During SQL processing it returned:&lt;br/&gt;
SQL0104N  An unexpected token &quot;)&quot; was found following &quot;create table t2(&quot;.  &lt;br/&gt;
Expected tokens may include:  &quot;&amp;lt;table_element_list&amp;gt;&quot;.  SQLSTATE=42601&lt;/p&gt;</comment>
                            <comment id="15358212" author="maropu" created="Fri, 1 Jul 2016 01:48:59 +0000"  >&lt;p&gt;FYI: I also checked in mysql;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;mysql&amp;gt; create table test_rel();
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the right syntax to use near &lt;span class=&quot;code-quote&quot;&gt;&apos;)&apos;&lt;/span&gt; at line 1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15358221" author="maropu" created="Fri, 1 Jul 2016 01:57:49 +0000"  >&lt;p&gt;I found there is the similar issue in `Dataset#drop`&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;DATA(a: Int)
val df1 = Seq(DATA(1)).toDF
val df2 = df1.drop($&lt;span class=&quot;code-quote&quot;&gt;&quot;a&quot;&lt;/span&gt;)
df2.select($&lt;span class=&quot;code-quote&quot;&gt;&quot;*&quot;&lt;/span&gt;).show
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This also threw the exception.&lt;/p&gt;</comment>
                            <comment id="15358226" author="smilegator" created="Fri, 1 Jul 2016 02:01:00 +0000"  >&lt;p&gt;We might hit multiple issues for supporting tables with zero column. &lt;/p&gt;</comment>
                            <comment id="15358230" author="smilegator" created="Fri, 1 Jul 2016 02:05:33 +0000"  >&lt;p&gt;If we support Dataframe with zero column, I think we should also support it for SQL interface. So far, the exposed issues exist in star expansion. Let me fix this at first. You can continue to fix the remaining issues. Thanks!&lt;/p&gt;</comment>
                            <comment id="15358236" author="maropu" created="Fri, 1 Jul 2016 02:07:34 +0000"  >&lt;p&gt;okay, thanks!&lt;/p&gt;</comment>
                            <comment id="15358306" author="apachespark" created="Fri, 1 Jul 2016 03:12:05 +0000"  >&lt;p&gt;User &apos;gatorsmile&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14007&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14007&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15358510" author="i.adri" created="Fri, 1 Jul 2016 06:55:49 +0000"  >&lt;p&gt;Wow, you guys are moving fast &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
Thanks!&lt;/p&gt;</comment>
                            <comment id="15360801" author="apachespark" created="Mon, 4 Jul 2016 03:45:04 +0000"  >&lt;p&gt;User &apos;gatorsmile&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14040&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14040&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15360837" author="apachespark" created="Mon, 4 Jul 2016 05:12:04 +0000"  >&lt;p&gt;User &apos;gatorsmile&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/14042&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/14042&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 20 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30d6f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>