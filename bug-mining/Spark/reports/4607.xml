<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:51:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-19348] pyspark.ml.Pipeline gets corrupted under multi threaded use</title>
                <link>https://issues.apache.org/jira/browse/SPARK-19348</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;When pyspark.ml.Pipeline objects are constructed concurrently in separate python threads, it is observed that the stages used to construct a pipeline object get corrupted i.e the stages supplied to a Pipeline object in one thread appear inside a different Pipeline object constructed in a different thread. &lt;/p&gt;

&lt;p&gt;Things work fine if construction of pyspark.ml.Pipeline objects is serialized, so this looks like a thread safety problem with pyspark.ml.Pipeline object construction. &lt;/p&gt;

&lt;p&gt;Confirmed that the problem exists with Spark 1.6.x as well as 2.x.&lt;/p&gt;

&lt;p&gt;While the corruption of the Pipeline stages is easily caught, we need to know if performing other pipeline operations, such as pyspark.ml.pipeline.fit( ) are also affected by the underlying cause of this problem. That is, whether other pipeline operations like pyspark.ml.pipeline.fit( )  may be performed in separate threads (on distinct pipeline objects) concurrently without any cross contamination between them.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13037317">SPARK-19348</key>
            <summary>pyspark.ml.Pipeline gets corrupted under multi threaded use</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="bryanc">Bryan Cutler</assignee>
                                    <reporter username="vijoshi">Vinayak Joshi</reporter>
                        <labels>
                    </labels>
                <created>Tue, 24 Jan 2017 09:54:57 +0000</created>
                <updated>Wed, 8 Mar 2017 04:47:19 +0000</updated>
                            <resolved>Wed, 8 Mar 2017 04:47:19 +0000</resolved>
                                    <version>1.6.0</version>
                    <version>2.0.0</version>
                    <version>2.1.0</version>
                    <version>2.2.0</version>
                                    <fixVersion>2.0.3</fixVersion>
                    <fixVersion>2.1.1</fixVersion>
                    <fixVersion>2.2.0</fixVersion>
                                    <component>ML</component>
                    <component>PySpark</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="15835946" author="vijoshi" created="Tue, 24 Jan 2017 10:01:33 +0000"  >&lt;p&gt;Refer the attached pyspark_pipeline_threads.py file containing the complete code to reproduce the issue. It can be run on the pyspark shell or in a jupyter notebook. &lt;/p&gt;</comment>
                            <comment id="15850705" author="bryanc" created="Thu, 2 Feb 2017 23:08:10 +0000"  >&lt;p&gt;The problem here is with the @keyword_only decorator that is used in the Pipeline constructor (and every other ML class also).  It relies on saving the params, stages in this case, to a static class variable.  When multiple threads call the wrapped constructor, it becomes a race condition to read from that static variable before it is over-written by another thread.  I can put up a potential fix, but it affects all of PySpark ML so it would need to be checked out carefully.&lt;/p&gt;

&lt;p&gt;As a workaround, you could just protect the construction of &lt;tt&gt;Pipeline&lt;/tt&gt; with a shared lock.  Other calls to &lt;tt&gt;fit&lt;/tt&gt; etc, should be ok since they don&apos;t use that keyword_only decorator.&lt;/p&gt;</comment>
                            <comment id="15850726" author="apachespark" created="Thu, 2 Feb 2017 23:27:06 +0000"  >&lt;p&gt;User &apos;BryanCutler&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/16782&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/16782&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15856700" author="peterdkirchner" created="Tue, 7 Feb 2017 20:07:47 +0000"  >&lt;p&gt;To save folks some time, the keyword_only decorator came in to pyspark/ml/util.py with &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4586&quot; title=&quot;Python API for ML Pipeline&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-4586&quot;&gt;&lt;del&gt;SPARK-4586&lt;/del&gt;&lt;/a&gt;&lt;br/&gt;
design:&lt;br/&gt;
&lt;a href=&quot;https://docs.google.com/document/d/1vL-4f5Xm-7t-kwVSaBylP_ZPrktPZjaOb2dWONtZU2s/edit&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://docs.google.com/document/d/1vL-4f5Xm-7t-kwVSaBylP_ZPrktPZjaOb2dWONtZU2s/edit&lt;/a&gt;&lt;br/&gt;
commit:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/commit/cd4a15366244657c4b7936abe5054754534366f2#diff-dd5670d3fb55faba1859e9778e4026e5&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/commit/cd4a15366244657c4b7936abe5054754534366f2#diff-dd5670d3fb55faba1859e9778e4026e5&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15856922" author="peterdkirchner" created="Tue, 7 Feb 2017 22:19:52 +0000"  >&lt;p&gt;Two things happen with this wrapper.&lt;/p&gt;

&lt;p&gt;First, it appears to me (after confirming with some simplified examples) that the modifications to incoming arguments made in the body of the wrapped function are lost (to take the pipeline.py example, stages=) when they are not updated in the dictionary that is passed in the calls made from inside the wrapped functions.  The decorator explicitly states that it saves the &apos;actual input arguments&apos; but does not clarify why.  It seems as if the wrapped code should either update the dictionary or that lines of code that have no lasting effect should be deleted.&lt;/p&gt;

&lt;p&gt;Second, bryanc has pointed out that passing the kwargs to the wrapped function via a static class variable is thread-unsafe within each of the many ml classes that use the decorator.  Passing the kwargs as an instance variable as bryanc has proposed seems satisfactory for the second solution, as would using a thread-local class variable.  Both require changes to any files using the decorator. Locking in the decorator, if it could be implemented in spite of the nested calls of decorated functions, could confine the changes to the decorator definition.  Passing the wrapper&apos;s kwargs dictionary as an additional entry in the kwargs dictionary passed to the wrapped function would be threadsafe but change the public API of many functions.  It looks possible for a decorator to introspect the wrapped function&apos;s parameters in which case the wrapper could pass the dictionary on one of those keywords (the purpose being to leave the public API intact), then inside the wrapped function there would need to be code to detect the wrapper, retrieve the dictionary and restore the coopted variable.  (As-is, the wrapped functions already have wrapper-specific code in order to function.)&lt;/p&gt;</comment>
                            <comment id="15859737" author="peterdkirchner" created="Thu, 9 Feb 2017 16:22:33 +0000"  >&lt;p&gt;Per the above, perhaps a fix could address both threadsafety and the orphaned modifications to variables in the wrapped function bodies.  For instance, in Pipeline._&lt;em&gt;init&lt;/em&gt;&lt;em&gt;() and setParams() the fix could remove references to _input_kwargs and instead invoke setParams(stages=stages) within __init&lt;/em&gt;_() and _set(stages=stages) within setParams(), respectively,  Parallel changes would be needed in all wrapped functions but the resulting code would be functional, readable, and threadsafe.&lt;/p&gt;

&lt;p&gt;A fix for Pipeline alone is insufficient, because multiple pipelines could have stages consisting of instances of the same class, e.g. LogisticRegression.  All the classes using @keyword_only need to be addressed by whatever fix is decided upon.&lt;/p&gt;</comment>
                            <comment id="15899979" author="apachespark" created="Tue, 7 Mar 2017 19:20:02 +0000"  >&lt;p&gt;User &apos;BryanCutler&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17193&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17193&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15900699" author="josephkb" created="Wed, 8 Mar 2017 04:47:19 +0000"  >&lt;p&gt;Issue resolved by pull request 17195&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/17195&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/17195&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12849085" name="pyspark_pipeline_threads.py" size="2741" author="vijoshi" created="Tue, 24 Jan 2017 10:00:45 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 36 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i394en:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311620" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
                        <customfieldname>Shepherd</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>josephkb</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                            <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12338608">2.0.3</customfieldvalue>
    <customfieldvalue id="12338779">2.1.1</customfieldvalue>
    <customfieldvalue id="12338275">2.2.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>