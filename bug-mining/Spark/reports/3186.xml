<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:38:59 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-13631] getPreferredLocations race condition in spark 1.6.0?</title>
                <link>https://issues.apache.org/jira/browse/SPARK-13631</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;We are seeing something that looks a lot like a regression from spark 1.2. When we run jobs with multiple threads, we have a crash somewhere inside getPreferredLocations, as was fixed in &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4454&quot; title=&quot;Race condition in DAGScheduler&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-4454&quot;&gt;&lt;del&gt;SPARK-4454&lt;/del&gt;&lt;/a&gt;. Except now it&apos;s inside org.apache.spark.MapOutputTrackerMaster.getLocationsWithLargestOutputs instead of DAGScheduler directly.&lt;/p&gt;

&lt;p&gt;I tried Spark 1.2 post-&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4454&quot; title=&quot;Race condition in DAGScheduler&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-4454&quot;&gt;&lt;del&gt;SPARK-4454&lt;/del&gt;&lt;/a&gt; (before this patch it&apos;s only slightly flaky), 1.4.1, and 1.5.2 and all are fine. 1.6.0 immediately crashes on our threaded test case, though once in a while it passes.&lt;/p&gt;

&lt;p&gt;The stack trace is huge, but starts like this:&lt;/p&gt;

&lt;p&gt;Caused by: java.lang.NullPointerException: null&lt;br/&gt;
	at org.apache.spark.MapOutputTrackerMaster.getLocationsWithLargestOutputs(MapOutputTracker.scala:406)&lt;br/&gt;
	at org.apache.spark.MapOutputTrackerMaster.getPreferredLocationsForShuffle(MapOutputTracker.scala:366)&lt;br/&gt;
	at org.apache.spark.rdd.ShuffledRDD.getPreferredLocations(ShuffledRDD.scala:92)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$preferredLocations$2.apply(RDD.scala:257)&lt;br/&gt;
	at org.apache.spark.rdd.RDD$$anonfun$preferredLocations$2.apply(RDD.scala:257)&lt;br/&gt;
	at scala.Option.getOrElse(Option.scala:120)&lt;br/&gt;
	at org.apache.spark.rdd.RDD.preferredLocations(RDD.scala:256)&lt;br/&gt;
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$getPreferredLocsInternal(DAGScheduler.scala:1545)&lt;/p&gt;

&lt;p&gt;The full trace is available here:&lt;br/&gt;
&lt;a href=&quot;https://gist.github.com/andy256/97611f19924bbf65cf49&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/andy256/97611f19924bbf65cf49&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12946345">SPARK-13631</key>
            <summary>getPreferredLocations race condition in spark 1.6.0?</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="asloane">Andy Sloane</assignee>
                                    <reporter username="asloane">Andy Sloane</reporter>
                        <labels>
                    </labels>
                <created>Thu, 3 Mar 2016 00:27:33 +0000</created>
                <updated>Sun, 17 May 2020 17:47:17 +0000</updated>
                            <resolved>Wed, 9 Mar 2016 10:26:16 +0000</resolved>
                                    <version>1.6.0</version>
                                    <fixVersion>1.6.2</fixVersion>
                    <fixVersion>2.0.0</fixVersion>
                                    <component>Scheduler</component>
                    <component>Spark Core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="15177261" author="asloane" created="Thu, 3 Mar 2016 05:48:28 +0000"  >&lt;p&gt;Did some digging with git bisect.&lt;/p&gt;

&lt;p&gt;It turns out to be directly linked to &lt;tt&gt;spark.shuffle.reduceLocality.enabled&lt;/tt&gt;. The difference between Spark 1.6 and 1.5 here is that 1.5 has it &lt;tt&gt;false&lt;/tt&gt; by default, and 1.6 has it &lt;tt&gt;true&lt;/tt&gt; by default.&lt;/p&gt;

&lt;p&gt;Setting it to false cures this in 1.6, and setting it to true causes it to re-emerge in 1.5.&lt;/p&gt;</comment>
                            <comment id="15177502" author="asloane" created="Thu, 3 Mar 2016 08:54:17 +0000"  >&lt;p&gt;Further bisecting with the reduceLocality flag forced to true confirmed; &lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-2774&quot; title=&quot;Set preferred locations for reduce tasks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SPARK-2774&quot;&gt;&lt;del&gt;SPARK-2774&lt;/del&gt;&lt;/a&gt; / commit 96a7c888d806adfdb2c722025a1079ed7eaa2052 introduced the function that&apos;s failing here with a note that it&apos;s known not to be thread safe. But it seems we&apos;re calling it in a multithreaded context and when the exception occurs, mapStatuses contains an entry for the shuffle, but it&apos;s an array full of nulls (I am guessing it&apos;s because &lt;tt&gt;registerShuffle&lt;/tt&gt; was called but none of the map outputs have been registered yet).&lt;/p&gt;

&lt;p&gt;So, the following sort of lame patch seems to fix it, but I&apos;m not totally sure about its correctness, or whether we&apos;re doing something as Spark clients that&apos;s causing us to get into a bad state (we have several threads running jobs concurrently):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;diff --git a/core/src/main/scala/org/apache/spark/MapOutputTracker.scala b/core/src/main/scala/org/apache/spark/MapOutputTracker.scala
index 72355cd..c0f1a36 100644
--- a/core/src/main/scala/org/apache/spark/MapOutputTracker.scala
+++ b/core/src/main/scala/org/apache/spark/MapOutputTracker.scala
@@ -394,28 +394,32 @@ &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt;[spark] &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;MapOutputTrackerMaster(conf: SparkConf)
       fractionThreshold: &lt;span class=&quot;code-object&quot;&gt;Double&lt;/span&gt;)
     : Option[Array[BlockManagerId]] = {
 
-    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (mapStatuses.contains(shuffleId)) {
-      val statuses = mapStatuses(shuffleId)
-      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (statuses.nonEmpty) {
-        &lt;span class=&quot;code-comment&quot;&gt;// HashMap to add up sizes of all blocks at the same location
&lt;/span&gt;-        val locs = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashMap[BlockManagerId, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;]
-        &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; totalOutputSize = 0L
-        &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; mapIdx = 0
-        &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (mapIdx &amp;lt; statuses.length) {
-          val status = statuses(mapIdx)
-          val blockSize = status.getSizeForBlock(reducerId)
-          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (blockSize &amp;gt; 0) {
-            locs(status.location) = locs.getOrElse(status.location, 0L) + blockSize
-            totalOutputSize += blockSize
+    val statuses = mapStatuses.get(shuffleId).orNull
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (statuses != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+      statuses.&lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; {
+        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (statuses.nonEmpty) {
+          &lt;span class=&quot;code-comment&quot;&gt;// HashMap to add up sizes of all blocks at the same location
&lt;/span&gt;+          val locs = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; HashMap[BlockManagerId, &lt;span class=&quot;code-object&quot;&gt;Long&lt;/span&gt;]
+          &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; totalOutputSize = 0L
+          &lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt; mapIdx = 0
+          &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (mapIdx &amp;lt; statuses.length) {
+            val status = statuses(mapIdx)
+            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (status != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
+              val blockSize = status.getSizeForBlock(reducerId)
+              &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (blockSize &amp;gt; 0) {
+                locs(status.location) = locs.getOrElse(status.location, 0L) + blockSize
+                totalOutputSize += blockSize
+              }
+            }
+            mapIdx = mapIdx + 1
+          }
+          val topLocs = locs.filter { &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (loc, size) =&amp;gt;
+            size.toDouble / totalOutputSize &amp;gt;= fractionThreshold
+          }
+          &lt;span class=&quot;code-comment&quot;&gt;// Return &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we have any locations which satisfy the required threshold
&lt;/span&gt;+          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (topLocs.nonEmpty) {
+            &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Some(topLocs.map(_._1).toArray)
           }
-          mapIdx = mapIdx + 1
-        }
-        val topLocs = locs.filter { &lt;span class=&quot;code-keyword&quot;&gt;case&lt;/span&gt; (loc, size) =&amp;gt;
-          size.toDouble / totalOutputSize &amp;gt;= fractionThreshold
-        }
-        &lt;span class=&quot;code-comment&quot;&gt;// Return &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; we have any locations which satisfy the required threshold
&lt;/span&gt;-        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (topLocs.nonEmpty) {
-          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; Some(topLocs.map(_._1).toArray)
         }
       }
     }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15177508" author="srowen" created="Thu, 3 Mar 2016 08:59:41 +0000"  >&lt;p&gt;(Propose it as a pull request)&lt;/p&gt;</comment>
                            <comment id="15177893" author="asloane" created="Thu, 3 Mar 2016 14:44:01 +0000"  >&lt;p&gt;I will.. It was late and I was brain-dumping..&lt;/p&gt;</comment>
                            <comment id="15178710" author="asloane" created="Thu, 3 Mar 2016 22:13:47 +0000"  >&lt;p&gt;Did a little more testing, added some logs, and confirmed my latest hypothesis:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;16/03/03 11:26:23 INFO MapOutputTrackerMaster: &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[dag-scheduler-event-loop,5,main] Registering shuffle 18 with 1 empty maps (registerShuffle)
16/03/03 11:26:23 INFO MapOutputTrackerMaster: &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[pipeline-thread-FlowAnnotatorPipeline,5,main] getting locations &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; shuffle 18 reducer 0/1 (getLocationsWithLargestOutputs)
16/03/03 11:26:23 INFO MapOutputTrackerMaster: &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[dag-scheduler-event-loop,5,main] Registering shuffle 18 with 1 map outputs (registerMapOutputs)
16/03/03 11:26:23 INFO MapOutputTrackerMaster: &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[dag-scheduler-event-loop,5,main] getting locations &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; shuffle 18 reducer 0/1 (getLocationsWithLargestOutputs)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As I suspected, the call to &lt;tt&gt;getLocationsWithLargestOutputs&lt;/tt&gt; in one thread is getting interleaved between &lt;tt&gt;registerShuffle&lt;/tt&gt; and &lt;tt&gt;registerMapOutputs&lt;/tt&gt; in another thread. I think there are two jobs which both depend on the output of a shuffle stage, and each are waiting for the stage to be marked finished.&lt;/p&gt;

&lt;p&gt;So there might be a better fix in addition to the above, which is to prevent the task outside the event loop from attempting to schedule before the map outputs are registered. I noticed that DAGScheduler calls &lt;tt&gt;markStageAsFinished&lt;/tt&gt; before calling &lt;tt&gt;registerMapOutputs&lt;/tt&gt;, but switching the order doesn&apos;t seem to help things. Still trying to understand the sequence of events here.&lt;/p&gt;</comment>
                            <comment id="15178980" author="asloane" created="Fri, 4 Mar 2016 00:05:43 +0000"  >&lt;p&gt;Hm. I see, it&apos;s just a coincidence that a thread tends to get scheduled from the thread pool while the shuffle task is running, and tries to schedule a new job based on the locations of the (currently in-process) shuffle tasks. There&apos;s no blocking wait on an RDD happening that&apos;s causing this job to kick off &amp;#8211; it&apos;s just trying to schedule it.&lt;/p&gt;

&lt;p&gt;It seems like we&apos;d want to defer finding preferred locations on an RDD which is currently being computed, somehow, but the job planning seems to happen completely up front and there aren&apos;t any indicators in an individual RDD that it&apos;s presently being computed. Which means we are probably unnecessarily recomputing RDDs in this multithreaded scheme.&lt;/p&gt;
</comment>
                            <comment id="15179019" author="apachespark" created="Fri, 4 Mar 2016 00:32:04 +0000"  >&lt;p&gt;User &apos;a1k0n&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11505&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11505&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15186925" author="srowen" created="Wed, 9 Mar 2016 10:26:16 +0000"  >&lt;p&gt;Issue resolved by pull request 11505&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/11505&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/11505&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 36 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2u2bb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>