<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:28:33 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-7792] HiveContext registerTempTable not thread safe</title>
                <link>https://issues.apache.org/jira/browse/SPARK-7792</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;ThreadRepro {
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; void main(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;[] args) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception{
       &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ThreadRepro().sparkPerfTest();
    }

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void sparkPerfTest(){

        &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; AtomicLong counter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; AtomicLong();
        SparkConf conf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkConf();
        conf.setAppName(&lt;span class=&quot;code-quote&quot;&gt;&quot;My Application&quot;&lt;/span&gt;);
        conf.setMaster(&lt;span class=&quot;code-quote&quot;&gt;&quot;local[7]&quot;&lt;/span&gt;);
        SparkContext sc = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SparkContext(conf);

        org.apache.spark.sql.hive.HiveContext hc = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.apache.spark.sql.hive.HiveContext(sc);
        &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; poolSize = 10;
        ExecutorService pool = Executors.newFixedThreadPool(poolSize);
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i=0; i&amp;lt;poolSize;i++ )
            pool.execute(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; QueryJob(hc, i, counter));

        pool.shutdown();
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
            pool.awaitTermination(60, TimeUnit.MINUTES);
        }&lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt;(Exception e){
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; interrupted&quot;&lt;/span&gt;);
        }
        &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;All jobs complete&quot;&lt;/span&gt;);
        &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot; Counter is &quot;&lt;/span&gt;+counter.get());

    }
}

&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;QueryJob &lt;span class=&quot;code-keyword&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Runnable&lt;/span&gt;{
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; threadId;
    org.apache.spark.sql.hive.HiveContext sqlContext;
    &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; key;
    AtomicLong counter;
    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; AtomicLong local_counter = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; AtomicLong();

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; QueryJob(org.apache.spark.sql.hive.HiveContext _sqlContext,&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; id,AtomicLong ctr){

        threadId = &lt;span class=&quot;code-quote&quot;&gt;&quot;thread_&quot;&lt;/span&gt;+id;
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.sqlContext= _sqlContext;
        &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.counter = ctr;
    }
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void run() {
        &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; i = 0; i &amp;lt; 100; i++) {
            &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; tblName = threadId +&lt;span class=&quot;code-quote&quot;&gt;&quot;_&quot;&lt;/span&gt;+i;
            DataFrame df = sqlContext.emptyDataFrame();
            df.registerTempTable(tblName);
            &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; _query = &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;select count(*) from %s&quot;&lt;/span&gt;,tblName);
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.format(&lt;span class=&quot;code-quote&quot;&gt;&quot; registered table %s; catalog (%s) &quot;&lt;/span&gt;,tblName,debugTables()));
            List&amp;lt;Row&amp;gt; res;
            &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
                res = sqlContext.sql(_query).collectAsList();
            }&lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (Exception e){
                &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;*Exception &quot;&lt;/span&gt;+ debugTables() +&lt;span class=&quot;code-quote&quot;&gt;&quot;**&quot;&lt;/span&gt;);
                &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; e;
            }
            sqlContext.dropTempTable(tblName);
            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot; dropped table &quot;&lt;/span&gt;+tblName);
            &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
                &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.sleep(3000);&lt;span class=&quot;code-comment&quot;&gt;//lets make &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; a not-so-tight loop
&lt;/span&gt;            }&lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt;(Exception e){
                &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(&lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; interrupted&quot;&lt;/span&gt;);
            }
        }
    }

    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; debugTables(){
        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; v = Joiner.on(&lt;span class=&quot;code-quote&quot;&gt;&apos;,&apos;&lt;/span&gt;).join(sqlContext.tableNames());
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (v==&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)&lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &quot;&quot;; &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; v;
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;this will periodically produce the following:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt; registered table thread_0_50; catalog (thread_1_50)&lt;br/&gt;
 registered table thread_4_50; catalog (thread_4_50,thread_1_50)&lt;br/&gt;
 registered table thread_1_50; catalog (thread_1_50)&lt;br/&gt;
 dropped table thread_1_50&lt;br/&gt;
 dropped table thread_4_50&lt;br/&gt;
*Exception **&lt;br/&gt;
Exception in thread &quot;pool-6-thread-1&quot; java.lang.Error: org.apache.spark.sql.AnalysisException: no such table thread_0_50; line 1 pos 21&lt;br/&gt;
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1151)&lt;br/&gt;
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)&lt;br/&gt;
  at java.lang.Thread.run(Thread.java:745)&lt;br/&gt;
Caused by: org.apache.spark.sql.AnalysisException: no such table thread_0_50; line 1 pos 21&lt;br/&gt;
  at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.getTable(Analyzer.scala:177)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$6.applyOrElse(Analyzer.scala:186)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$6.applyOrElse(Analyzer.scala:181)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:188)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:188)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:187)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:208)&lt;br/&gt;
  at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)&lt;br/&gt;
  at scala.collection.Iterator$class.foreach(Iterator.scala:727)&lt;br/&gt;
  at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)&lt;br/&gt;
  at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)&lt;br/&gt;
  at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)&lt;br/&gt;
  at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)&lt;br/&gt;
  at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)&lt;br/&gt;
  at scala.collection.AbstractIterator.to(Iterator.scala:1157)&lt;br/&gt;
  at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)&lt;br/&gt;
  at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)&lt;br/&gt;
  at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)&lt;br/&gt;
  at scala.collection.AbstractIterator.toArray(Iterator.scala:1157)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildrenDown(TreeNode.scala:238)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:193)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:178)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:181)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:171)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1$$anonfun$apply$2.apply(RuleExecutor.scala:61)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1$$anonfun$apply$2.apply(RuleExecutor.scala:59)&lt;br/&gt;
  at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:111)&lt;br/&gt;
  at scala.collection.immutable.List.foldLeft(List.scala:84)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1.apply(RuleExecutor.scala:59)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$apply$1.apply(RuleExecutor.scala:51)&lt;br/&gt;
  at scala.collection.immutable.List.foreach(List.scala:318)&lt;br/&gt;
  at org.apache.spark.sql.catalyst.rules.RuleExecutor.apply(RuleExecutor.scala:51)&lt;br/&gt;
  at org.apache.spark.sql.SQLContext$QueryExecution.analyzed$lzycompute(SQLContext.scala:1082)&lt;br/&gt;
  at org.apache.spark.sql.SQLContext$QueryExecution.analyzed(SQLContext.scala:1082)&lt;br/&gt;
  at org.apache.spark.sql.SQLContext$QueryExecution.assertAnalyzed(SQLContext.scala:1080)&lt;br/&gt;
  at org.apache.spark.sql.DataFrame.&amp;lt;init&amp;gt;(DataFrame.scala:133)&lt;br/&gt;
  at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)&lt;br/&gt;
  at org.apache.spark.sql.hive.HiveContext.sql(HiveContext.scala:101)&lt;br/&gt;
  at test.unit.QueryJob.run(ThreadRepro.java:93)&lt;br/&gt;
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Line 93 is the .sql call...&lt;/p&gt;</description>
                <environment></environment>
        <key id="12831852">SPARK-7792</key>
            <summary>HiveContext registerTempTable not thread safe</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="navis">Navis Ryu</assignee>
                                    <reporter username="yanakad">Yana Kadiyska</reporter>
                        <labels>
                    </labels>
                <created>Thu, 21 May 2015 16:06:23 +0000</created>
                <updated>Wed, 10 Jun 2015 02:33:41 +0000</updated>
                            <resolved>Wed, 10 Jun 2015 02:33:41 +0000</resolved>
                                    <version>1.3.1</version>
                                    <fixVersion>1.5.0</fixVersion>
                                    <component>SQL</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14576681" author="apachespark" created="Mon, 8 Jun 2015 07:08:03 +0000"  >&lt;p&gt;User &apos;navis&apos; has created a pull request for this issue:&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/6699&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/spark/pull/6699&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 24 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2f207:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>