<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 18:12:03 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SPARK-1034] Py4JException on PySpark Cartesian Result</title>
                <link>https://issues.apache.org/jira/browse/SPARK-1034</link>
                <project id="12315420" key="SPARK">Spark</project>
                    <description>&lt;p&gt;RDD operations on results of the Pyspark Cartesian method return Py4JException.&lt;/p&gt;



&lt;p&gt;Here&apos;s a few examples&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-style: solid;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeHeader panelHeader&quot; style=&quot;border-bottom-width: 1px;border-bottom-style: solid;&quot;&gt;&lt;b&gt;$ bin/pyspark&lt;/b&gt;&lt;/div&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&amp;gt;&amp;gt;&amp;gt; rdd1=sc.parallelize([1,2,3,4,5,1])
&amp;gt;&amp;gt;&amp;gt; rdd2=sc.parallelize([11,12,13,14,15,11])
&amp;gt;&amp;gt;&amp;gt; rdd1.cartesian(rdd2).map(lambda x: x[0] + x[1]).collect()
Traceback (most recent call last):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;&amp;lt;stdin&amp;gt;&quot;&lt;/span&gt;, line 1, in &amp;lt;module&amp;gt;
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 446, in collect
    bytesInJava = self._jrdd.collect().iterator()
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 1041, in _jrdd
    class_tag)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/lib/py4j-0.8.1-src.zip/py4j/java_gateway.py&quot;&lt;/span&gt;, line 669, in __call__
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/lib/py4j-0.8.1-src.zip/py4j/protocol.py&quot;&lt;/span&gt;, line 304, in get_return_value
py4j.protocol.Py4JError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling None.org.apache.spark.api.python.PythonRDD. Trace:
py4j.Py4JException: Constructor org.apache.spark.api.python.PythonRDD([&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.rdd.CartesianRDD, class [B, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.HashMap, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.ArrayList, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.ArrayList, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.Accumulator, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;scala.reflect.ManifestFactory$$anon$2]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:184)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:202)
	at py4j.Gateway.invoke(Gateway.java:213)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:79)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:68)
	at py4j.GatewayConnection.run(GatewayConnection.java:207)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)


&amp;gt;&amp;gt;&amp;gt; 
&amp;gt;&amp;gt;&amp;gt; rdd1.cartesian(rdd2).count()
Traceback (most recent call last):
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;&amp;lt;stdin&amp;gt;&quot;&lt;/span&gt;, line 1, in &amp;lt;module&amp;gt;
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 525, in count
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.mapPartitions(lambda i: [sum(1 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; _ in i)]).sum()
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 516, in sum
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; self.mapPartitions(lambda x: [sum(x)]).reduce(&lt;span class=&quot;code-keyword&quot;&gt;operator&lt;/span&gt;.add)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 482, in reduce
    vals = self.mapPartitions(func).collect()
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 446, in collect
    bytesInJava = self._jrdd.collect().iterator()
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/pyspark/rdd.py&quot;&lt;/span&gt;, line 1041, in _jrdd
    class_tag)
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/lib/py4j-0.8.1-src.zip/py4j/java_gateway.py&quot;&lt;/span&gt;, line 669, in __call__
  File &lt;span class=&quot;code-quote&quot;&gt;&quot;/Users/tshinagawa/Documents/Spark/RCs/spark-0.9.0-incubating-rc2/python/lib/py4j-0.8.1-src.zip/py4j/protocol.py&quot;&lt;/span&gt;, line 304, in get_return_value
py4j.protocol.Py4JError: An error occurred &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; calling None.org.apache.spark.api.python.PythonRDD. Trace:
py4j.Py4JException: Constructor org.apache.spark.api.python.PythonRDD([&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.rdd.CartesianRDD, class [B, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.HashMap, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.ArrayList, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.lang.&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;java.util.ArrayList, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.apache.spark.Accumulator, &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;scala.reflect.ManifestFactory$$anon$2]) does not exist
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:184)
	at py4j.reflection.ReflectionEngine.getConstructor(ReflectionEngine.java:202)
	at py4j.Gateway.invoke(Gateway.java:213)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:79)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:68)
	at py4j.GatewayConnection.run(GatewayConnection.java:207)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:744)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I see this issue after the custom serializer change.&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/incubator-spark/commit/cbb7f04aef2220ece93dea9f3fa98b5db5f270d6&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/incubator-spark/commit/cbb7f04aef2220ece93dea9f3fa98b5db5f270d6&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12704777">SPARK-1034</key>
            <summary>Py4JException on PySpark Cartesian Result</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="joshrosen">Josh Rosen</assignee>
                                    <reporter username="mrt">Taka Shinagawa</reporter>
                        <labels>
                    </labels>
                <created>Sun, 19 Jan 2014 12:27:51 +0000</created>
                <updated>Sat, 26 Jul 2014 22:26:26 +0000</updated>
                            <resolved>Thu, 23 Jan 2014 19:47:49 +0000</resolved>
                                    <version>0.9.0</version>
                                    <fixVersion>0.9.0</fixVersion>
                                    <component>PySpark</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="13953570" author="broxton" created="Wed, 22 Jan 2014 23:12:22 +0000"  >&lt;p&gt;I can confirm that I see this bug as well using Spark 0.9.1.  It appears that collect() works correctly:&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; test_rdd1 = sc.parallelize(range(5), 2)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; test_rdd2 = test_rdd1.cartesian(test_rdd1)&lt;br/&gt;
&amp;gt;&amp;gt;&amp;gt; print test_rdd2.collect()&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;(0, 0), (0, 1), (1, 0), (1, 1), (0, 2), (0, 3), (1, 2), (1, 3), (0, 4), (1, 4), (2, 0), (2, 1), (3, 0), (3, 1), (4, 0), (4, 1), (2, 2), (2, 3), (3, 2), (3, 3), (2, 4), (3, 4), (4, 2), (4, 3), (4, 4)&amp;#93;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;However, other operations like map(), count(), and reduce() produce the same exception that Taka has reported above.&lt;/p&gt;</comment>
                            <comment id="13953571" author="broxton" created="Thu, 23 Jan 2014 01:29:41 +0000"  >&lt;p&gt;After spending a little bit of time delving into the code, I can say that this problem appears to occur at line 1038 of rdd.py when the PythonRDD object is constructed.&lt;/p&gt;

&lt;p&gt;        python_rdd = self.ctx._jvm.PythonRDD(self._prev_jrdd.rdd(),&lt;br/&gt;
            bytearray(pickled_command), env, includes, self.preservesPartitioning,&lt;br/&gt;
            self.ctx.pythonExec, broadcast_vars, self.ctx._javaAccumulator,&lt;br/&gt;
            class_tag)&lt;/p&gt;

&lt;p&gt;It appears that Py4J can&apos;t find the corresponding Java constructor when this function is called on a Cartesian RDD.  I added the following debugging code immediately before line 1038:&lt;/p&gt;

&lt;p&gt;        print &apos;---&apos;&lt;br/&gt;
        print self._prev_jrdd.rdd()&lt;br/&gt;
        print len(bytearray(pickled_command))&lt;br/&gt;
        print env&lt;br/&gt;
        print includes&lt;br/&gt;
        print self.preservesPartitioning&lt;br/&gt;
        print self.ctx.pythonExec&lt;br/&gt;
        print broadcast_vars&lt;br/&gt;
        print self.ctx._javaAccumulator&lt;br/&gt;
        print class_tag&lt;br/&gt;
        print &apos;---&apos;&lt;/p&gt;

&lt;p&gt;This prints out each argument that is passed to the PythonRDD constructor.   Having made this change, I ran this in Spark:&lt;/p&gt;

&lt;p&gt;  test_rdd = sc.parallelize(range(5), 2)  &lt;br/&gt;
  print test_rdd.count()                            # THIS WORKS!!&lt;/p&gt;

&lt;p&gt;which produced this debugging output on the console:&lt;/p&gt;

&lt;p&gt;------&lt;br/&gt;
ParallelCollectionRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt; at parallelize at PythonRDD.scala:206&lt;br/&gt;
1431&lt;br/&gt;
{}&lt;br/&gt;
[]&lt;br/&gt;
False&lt;br/&gt;
python&lt;br/&gt;
[]&lt;br/&gt;
[]&lt;br/&gt;
Array&lt;span class=&quot;error&quot;&gt;&amp;#91;byte&amp;#93;&lt;/span&gt;&lt;br/&gt;
&amp;#8212;&lt;/p&gt;

&lt;p&gt;However, when I run this:&lt;/p&gt;

&lt;p&gt;  test_rdd1 = sc.parallelize(range(5), 2)  &lt;br/&gt;
  test_rdd2= test_rdd1.cartesian(test_rdd1)&lt;br/&gt;
  print test_rdd2.count()                          # FAILS WITH Py4J EXCEPTION&lt;/p&gt;

&lt;p&gt;I get this debugging output:&lt;/p&gt;

&lt;p&gt;&amp;#8212;&lt;br/&gt;
CartesianRDD&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; at cartesian at NativeMethodAccessorImpl.java:-2&lt;br/&gt;
1506&lt;br/&gt;
{}&lt;br/&gt;
[]&lt;br/&gt;
False&lt;br/&gt;
python&lt;br/&gt;
[]&lt;br/&gt;
[]&lt;br/&gt;
Object&lt;br/&gt;
&amp;#8212;&lt;/p&gt;

&lt;p&gt;Since both ParallelCollectionRDD and CartesianRDD are subclasses of the same RDD superclass, I suspect that the meaningful difference between the &quot;working&quot; and &quot;not working&quot; version is the last argument to the constructor: the class_tag.  It appears that the class_tag of a cartesian RDD is a Scala object of some sort, whereas the class_tag of the first RDD was Array&lt;span class=&quot;error&quot;&gt;&amp;#91;Byte&amp;#93;&lt;/span&gt;.  &lt;/p&gt;

&lt;p&gt;I spent a little bit of time poking around PythonRDD.scala to see if I could understand why the constructor only worked with the first set of arguments, but I&apos;m afraid I cannot see what is causing this bug.  But, hopefully you will find this info useful when you fix this bug.  Thanks!&lt;/p&gt;</comment>
                            <comment id="13953572" author="mrt" created="Thu, 23 Jan 2014 01:56:22 +0000"  >&lt;p&gt;Michael, thanks for the info. I&apos;m also looking into the same place.&lt;/p&gt;</comment>
                            <comment id="13953577" author="joshrosen" created="Thu, 23 Jan 2014 15:19:49 +0000"  >&lt;p&gt;Thanks for reporting this bug, and for the detailed investigation so far.&lt;/p&gt;

&lt;p&gt;Michael, in both cases in your example, &lt;tt&gt;class_tag&lt;/tt&gt; is actually a Scala ClassTag object and that &lt;tt&gt;Array[Byte]&lt;/tt&gt; and &lt;tt&gt;Object&lt;/tt&gt; are the results of calling &lt;tt&gt;toString()&lt;/tt&gt; on those ClassTags.&lt;/p&gt;

&lt;p&gt;In cartesian, we&apos;re trying to wrap a &lt;tt&gt;JavaPairRDD&amp;lt;Array&amp;lt;Byte&amp;gt;, Array&amp;lt;Byte&amp;gt;&amp;gt;&lt;/tt&gt; into a PythonRDD.  The ClassTag for this &lt;tt&gt;JavaRDD&amp;lt;Tuple2&amp;lt;Array&amp;lt;Byte&amp;gt;, Array&amp;lt;Byte&amp;gt;&amp;gt;&amp;gt;&lt;/tt&gt; should be a &lt;tt&gt;ClassTag&amp;lt;Tuple2&amp;lt;Array&amp;lt;Byte&amp;gt;, Array&amp;lt;Byte&amp;gt;&amp;gt;&lt;/tt&gt; (or a &lt;tt&gt;ClassTag&amp;lt;Tuple2&amp;lt;?, ?&amp;gt;&amp;gt;&lt;/tt&gt;).  The root problem here may actually be in JavaPairRDD&apos;s classTag:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;scala&amp;gt; val x = sc.parallelize(Seq(Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;](0))).map(x =&amp;gt; (x, x))
x: org.apache.spark.rdd.RDD[(Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;], Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;])] = MappedRDD[7] at map at &amp;lt;console&amp;gt;:18

scala&amp;gt; JavaPairRDD.fromJavaRDD(x).classTag
res15: scala.reflect.ClassTag[(Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;], Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;])] = &lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;

scala&amp;gt; JavaRDD.fromRDD(x).classTag
res17: scala.reflect.ClassTag[(Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;], Array[&lt;span class=&quot;code-object&quot;&gt;Byte&lt;/span&gt;])] = scala.Tuple2
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This turns out to be caused by a line in JavaPairRDD that constructed its ClassTag by casting an AnyRef ClassTag, when it should have just used the underlying ScalaRDD&apos;s &lt;tt&gt;elementClassTag&lt;/tt&gt; (since it&apos;s already of the right type):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;override val classTag: ClassTag[(K, V)] =
    implicitly[ClassTag[AnyRef]].asInstanceOf[ClassTag[Tuple2[K, V]]]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;should be &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  override val classTag: ClassTag[(K, V)] = rdd.elementClassTag
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;ve submitted this fix as part of a pull request: &lt;a href=&quot;https://github.com/apache/incubator-spark/pull/501&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/incubator-spark/pull/501&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="13953576" author="mrt" created="Thu, 23 Jan 2014 15:55:15 +0000"  >&lt;p&gt;Josh, &lt;br/&gt;
thanks for the quick fix! I&apos;ve confirmed this change fixes the problem.&lt;/p&gt;</comment>
                            <comment id="13953578" author="broxton" created="Thu, 23 Jan 2014 16:47:39 +0000"  >&lt;p&gt;Hi Josh,&lt;/p&gt;

&lt;p&gt;Yes, I can confirm that this fixes it for me as well.  Tremendous thanks for taking a look at this, and for taking the time to explain the fix.  &lt;/p&gt;

&lt;p&gt;Now back to data analysis!&lt;/p&gt;

&lt;p&gt;Best,&lt;/p&gt;

&lt;p&gt;  -Michael&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12728437">SPARK-2601</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>383927</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 43 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1u55j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>384195</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>