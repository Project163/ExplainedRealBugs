diff --git a/src/yb/tserver/tablet_server.cc b/src/yb/tserver/tablet_server.cc
index 6eb63339f1..b34c22cd47 100644
--- a/src/yb/tserver/tablet_server.cc
+++ b/src/yb/tserver/tablet_server.cc
@@ -1292,8 +1292,9 @@ Status TabletServer::CreateXClusterConsumer() {
   };
 
   xcluster_consumer_ = VERIFY_RESULT(tserver::CreateXClusterConsumer(
-      std::move(get_leader_term), std::move(connect_to_pg), std::move(get_namespace_info),
-      proxy_cache_.get(), this));
+      std::move(get_leader_term), permanent_uuid(), *client(), std::move(connect_to_pg),
+      std::move(get_namespace_info), GetXClusterContext(), metric_entity()));
+
   return Status::OK();
 }
 
diff --git a/src/yb/tserver/xcluster_consumer.cc b/src/yb/tserver/xcluster_consumer.cc
index e37e86a850..eaec956e1b 100644
--- a/src/yb/tserver/xcluster_consumer.cc
+++ b/src/yb/tserver/xcluster_consumer.cc
@@ -17,7 +17,6 @@
 #include "yb/cdc/xcluster_util.h"
 #include "yb/client/session.h"
 #include "yb/client/table_handle.h"
-#include "yb/client/table_info.h"
 #include "yb/client/yb_op.h"
 #include "yb/client/yb_table_name.h"
 
@@ -27,14 +26,12 @@
 #include "yb/master/master_heartbeat.pb.h"
 
 #include "yb/rpc/messenger.h"
-#include "yb/rpc/proxy.h"
 #include "yb/rpc/rpc.h"
 #include "yb/rpc/secure_stream.h"
 #include "yb/tserver/xcluster_consumer.h"
 #include "yb/tserver/tserver_xcluster_context_if.h"
 #include "yb/tserver/xcluster_consumer_auto_flags_info.h"
 #include "yb/tserver/xcluster_output_client.h"
-#include "yb/tserver/tablet_server.h"
 #include "yb/tserver/xcluster_poller.h"
 
 #include "yb/cdc/cdc_consumer.pb.h"
@@ -50,6 +47,7 @@
 #include "yb/util/callsite_profiling.h"
 #include "yb/util/flags.h"
 #include "yb/util/logging.h"
+#include "yb/util/path_util.h"
 #include "yb/util/shared_lock.h"
 #include "yb/util/size_literals.h"
 #include "yb/util/status_log.h"
@@ -140,36 +138,13 @@ void XClusterClient::Shutdown() {
 }
 
 Result<std::unique_ptr<XClusterConsumerIf>> CreateXClusterConsumer(
-    std::function<int64_t(const TabletId&)> get_leader_term, ConnectToPostgresFunc connect_to_pg,
-    GetNamespaceInfoFunc get_namespace_info, rpc::ProxyCache* proxy_cache, TabletServer* tserver) {
-  auto master_addrs = tserver->options().GetMasterAddresses();
-  std::vector<std::string> hostport_strs;
-  hostport_strs.reserve(master_addrs->size());
-  for (const auto& hp : *master_addrs) {
-    hostport_strs.push_back(HostPort::ToCommaSeparatedString(hp));
-  }
-
-  auto local_client = std::make_unique<XClusterClient>();
-  rpc::MessengerBuilder messenger_builder("xcluster-consumer");
-
-  if (FLAGS_use_node_to_node_encryption) {
-    local_client->secure_context = VERIFY_RESULT(rpc::SetupSecureContext(
-        /*root_dir=*/"", /*name=*/"", rpc::SecureContextType::kInternal, &messenger_builder));
-  }
-  local_client->messenger = VERIFY_RESULT(messenger_builder.Build());
-
-  local_client->client = VERIFY_RESULT(
-      client::YBClientBuilder()
-          .master_server_addrs(hostport_strs)
-          .set_client_name("XClusterConsumerLocal")
-          .default_rpc_timeout(MonoDelta::FromMilliseconds(FLAGS_cdc_write_rpc_timeout_ms))
-          .Build(local_client->messenger.get()));
-
-  local_client->client->SetLocalTabletServer(tserver->permanent_uuid(), tserver->proxy(), tserver);
+    std::function<int64_t(const TabletId&)> get_leader_term, const std::string& ts_uuid,
+    client::YBClient& local_client, ConnectToPostgresFunc connect_to_pg_func,
+    GetNamespaceInfoFunc get_namespace_info_func, const TserverXClusterContextIf& xcluster_context,
+    const scoped_refptr<MetricEntity>& server_metric_entity) {
   auto xcluster_consumer = std::make_unique<XClusterConsumer>(
-      std::move(get_leader_term), proxy_cache, tserver->permanent_uuid(), std::move(local_client),
-      std::move(connect_to_pg), std::move(get_namespace_info), tserver->GetXClusterContext(),
-      tserver->metric_entity());
+      std::move(get_leader_term), ts_uuid, local_client, std::move(connect_to_pg_func),
+      std::move(get_namespace_info_func), xcluster_context, server_metric_entity);
 
   RETURN_NOT_OK(xcluster_consumer->Init());
 
@@ -177,15 +152,14 @@ Result<std::unique_ptr<XClusterConsumerIf>> CreateXClusterConsumer(
 }
 
 XClusterConsumer::XClusterConsumer(
-    std::function<int64_t(const TabletId&)> get_leader_term, rpc::ProxyCache* proxy_cache,
-    const string& ts_uuid, std::unique_ptr<XClusterClient> local_client,
-    ConnectToPostgresFunc connect_to_pg_func, GetNamespaceInfoFunc get_namespace_info_func,
-    const TserverXClusterContextIf& xcluster_context,
+    std::function<int64_t(const TabletId&)> get_leader_term, const string& ts_uuid,
+    client::YBClient& local_client, ConnectToPostgresFunc connect_to_pg_func,
+    GetNamespaceInfoFunc get_namespace_info_func, const TserverXClusterContextIf& xcluster_context,
     const scoped_refptr<MetricEntity>& server_metric_entity)
     : get_leader_term_func_(std::move(get_leader_term)),
       rpcs_(new rpc::Rpcs),
       log_prefix_(Format("[TS $0]: ", ts_uuid)),
-      local_client_(std::move(local_client)),
+      local_client_(local_client),
       last_safe_time_published_at_(MonoTime::Now()),
       connect_to_pg_func_(std::move(connect_to_pg_func)),
       get_namespace_info_func_(std::move(get_namespace_info_func)),
@@ -199,7 +173,7 @@ XClusterConsumer::XClusterConsumer(
       &FLAGS_apply_changes_max_send_rate_mbps, "xclusterConsumerRateLimiter",
       std::bind(&XClusterConsumer::SetRateLimiterSpeed, this)));
 
-  auto_flags_version_handler_ = std::make_unique<AutoFlagsVersionHandler>(local_client_->client);
+  auto_flags_version_handler_ = std::make_unique<AutoFlagsVersionHandler>(&local_client_);
 
   metric_apply_failure_count_ =
       METRIC_xcluster_consumer_apply_failure_count.Instantiate(server_metric_entity);
@@ -270,8 +244,6 @@ void XClusterConsumer::Shutdown() {
     client->Shutdown();
   }
 
-  local_client_->Shutdown();
-
   for (const auto& poller : pollers_to_shutdown) {
     poller->CompleteShutdown();
   }
@@ -763,12 +735,6 @@ int32_t XClusterConsumer::cluster_config_version() const {
 }
 
 Status XClusterConsumer::ReloadCertificates() {
-  if (local_client_->secure_context) {
-    RETURN_NOT_OK(rpc::ReloadSecureContextKeysAndCertificates(
-        local_client_->secure_context.get(), "" /* node_name */, "" /* root_dir*/,
-        rpc::SecureContextType::kInternal));
-  }
-
   SharedLock read_lock(pollers_map_mutex_);
   for (const auto& [replication_group_id, client] : remote_clients_) {
     if (!client->secure_context) {
@@ -816,28 +782,26 @@ Status XClusterConsumer::PublishXClusterSafeTime() {
     return Status::OK();
   }
 
-  auto& client = local_client_->client;
-
   static const client::YBTableName safe_time_table_name(
       YQL_DATABASE_CQL, master::kSystemNamespaceName, master::kXClusterSafeTimeTableName);
 
   if (!xcluster_safe_time_table_ready_) {
     // Master has not created the table yet. Nothing to do for now.
-    if (!VERIFY_RESULT(client->TableExists(safe_time_table_name))) {
+    if (!VERIFY_RESULT(local_client_.TableExists(safe_time_table_name))) {
       return Status::OK();
     }
-    RETURN_NOT_OK(client->WaitForCreateTableToFinish(safe_time_table_name));
+    RETURN_NOT_OK(local_client_.WaitForCreateTableToFinish(safe_time_table_name));
 
     xcluster_safe_time_table_ready_ = true;
   }
 
   if (!safe_time_table_) {
     auto table = std::make_unique<client::TableHandle>();
-    RETURN_NOT_OK(table->Open(safe_time_table_name, client.get()));
+    RETURN_NOT_OK(table->Open(safe_time_table_name, &local_client_));
     safe_time_table_.swap(table);
   }
 
-  auto session = client->NewSession(client->default_rpc_timeout());
+  auto session = local_client_.NewSession(local_client_.default_rpc_timeout());
   for (auto& [producer_info, safe_time] : safe_time_map) {
     const auto op = safe_time_table_->NewWriteOp(QLWriteRequestPB::QL_STMT_UPDATE);
     auto* const req = op->mutable_request();
@@ -855,7 +819,7 @@ Status XClusterConsumer::PublishXClusterSafeTime() {
   // We dont use TEST_Flush here since it gets stuck on shutdown (#19402).
   auto future = session->FlushFuture();
   SCHECK(
-      future.wait_for(client->default_rpc_timeout().ToSteadyDuration()) ==
+      future.wait_for(local_client_.default_rpc_timeout().ToSteadyDuration()) ==
           std::future_status::ready,
       IllegalState, "Failed to flush to XClusterSafeTime table");
 
diff --git a/src/yb/tserver/xcluster_consumer.h b/src/yb/tserver/xcluster_consumer.h
index bb2c87fe3b..f3b43468a4 100644
--- a/src/yb/tserver/xcluster_consumer.h
+++ b/src/yb/tserver/xcluster_consumer.h
@@ -78,9 +78,9 @@ struct XClusterClient {
 class XClusterConsumer : public XClusterConsumerIf {
  public:
   XClusterConsumer(
-      std::function<int64_t(const TabletId&)> get_leader_term, rpc::ProxyCache* proxy_cache,
-      const std::string& ts_uuid, std::unique_ptr<XClusterClient> local_client,
-      ConnectToPostgresFunc connect_to_pg_func, GetNamespaceInfoFunc get_namespace_info_func,
+      std::function<int64_t(const TabletId&)> get_leader_term, const std::string& ts_uuid,
+      client::YBClient& local_client, ConnectToPostgresFunc connect_to_pg_func,
+      GetNamespaceInfoFunc get_namespace_info_func,
       const TserverXClusterContextIf& xcluster_context,
       const scoped_refptr<MetricEntity>& server_metric_entity);
 
@@ -232,7 +232,7 @@ class XClusterConsumer : public XClusterConsumerIf {
   std::unique_ptr<rpc::Rpcs> rpcs_;
 
   std::string log_prefix_;
-  std::shared_ptr<XClusterClient> local_client_;
+  client::YBClient& local_client_;
 
   // map: {replication_group_id : ...}.
   std::unordered_map<xcluster::ReplicationGroupId, std::shared_ptr<XClusterClient>> remote_clients_
diff --git a/src/yb/tserver/xcluster_consumer_auto_flags_info.cc b/src/yb/tserver/xcluster_consumer_auto_flags_info.cc
index 778039b14f..4e1ff59513 100644
--- a/src/yb/tserver/xcluster_consumer_auto_flags_info.cc
+++ b/src/yb/tserver/xcluster_consumer_auto_flags_info.cc
@@ -36,8 +36,7 @@ void AutoFlagVersionInfo::SetMaxReportedVersion(uint32 max_reported_version) {
   max_reported_version_.store(max_reported_version, std::memory_order_release);
 }
 
-AutoFlagsVersionHandler::AutoFlagsVersionHandler(std::shared_ptr<client::YBClient> client)
-    : client_(std::move(client)) {}
+AutoFlagsVersionHandler::AutoFlagsVersionHandler(client::YBClient* client) : client_(client) {}
 
 void AutoFlagsVersionHandler::InsertOrUpdate(
     const xcluster::ReplicationGroupId& replication_group_id, uint32 compatible_version,
diff --git a/src/yb/tserver/xcluster_consumer_auto_flags_info.h b/src/yb/tserver/xcluster_consumer_auto_flags_info.h
index f4457cda4b..e6e790592f 100644
--- a/src/yb/tserver/xcluster_consumer_auto_flags_info.h
+++ b/src/yb/tserver/xcluster_consumer_auto_flags_info.h
@@ -54,7 +54,7 @@ class AutoFlagVersionInfo : public AutoFlagsCompatibleVersion {
 // the yb-master. This will ensure that each version per replication group is reported only once.
 class AutoFlagsVersionHandler {
  public:
-  explicit AutoFlagsVersionHandler(std::shared_ptr<client::YBClient> client);
+  explicit AutoFlagsVersionHandler(client::YBClient* client);
   virtual ~AutoFlagsVersionHandler() = default;
 
   void InsertOrUpdate(
@@ -75,7 +75,7 @@ class AutoFlagsVersionHandler {
       const xcluster::ReplicationGroupId& replication_group_id, uint32 new_version) const;
 
  private:
-  std::shared_ptr<client::YBClient> client_;
+  client::YBClient* client_;
 
   mutable std::shared_mutex mutex_;
   std::unordered_map<xcluster::ReplicationGroupId, std::shared_ptr<AutoFlagVersionInfo>>
diff --git a/src/yb/tserver/xcluster_consumer_if.h b/src/yb/tserver/xcluster_consumer_if.h
index 8c2756358a..37de9ceee1 100644
--- a/src/yb/tserver/xcluster_consumer_if.h
+++ b/src/yb/tserver/xcluster_consumer_if.h
@@ -45,6 +45,7 @@ class ProxyCache;
 namespace tserver {
 
 class TabletServer;
+class TserverXClusterContextIf;
 class XClusterPoller;
 
 class XClusterConsumerIf {
@@ -79,8 +80,10 @@ typedef std::function<Result<std::pair<NamespaceId, NamespaceName>>(const Tablet
     GetNamespaceInfoFunc;
 
 Result<std::unique_ptr<XClusterConsumerIf>> CreateXClusterConsumer(
-    std::function<int64_t(const TabletId&)> get_leader_term, ConnectToPostgresFunc connect_to_pg,
-    GetNamespaceInfoFunc get_namespace_info, rpc::ProxyCache* proxy_cache, TabletServer* tserver);
+    std::function<int64_t(const TabletId&)> get_leader_term, const std::string& ts_uuid,
+    client::YBClient& local_client, ConnectToPostgresFunc connect_to_pg_func,
+    GetNamespaceInfoFunc get_namespace_info_func, const TserverXClusterContextIf& xcluster_context,
+    const scoped_refptr<MetricEntity>& server_metric_entity);
 
 }  // namespace tserver
 }  // namespace yb
diff --git a/src/yb/tserver/xcluster_ddl_queue_handler-test.cc b/src/yb/tserver/xcluster_ddl_queue_handler-test.cc
index c976ed68ae..5e018c8d41 100644
--- a/src/yb/tserver/xcluster_ddl_queue_handler-test.cc
+++ b/src/yb/tserver/xcluster_ddl_queue_handler-test.cc
@@ -25,6 +25,7 @@
 #include "yb/master/master_ddl.pb.h"
 #include "yb/tserver/xcluster_ddl_queue_handler.h"
 
+#include "yb/tserver/xcluster_output_client.h"
 #include "yb/util/monotime.h"
 #include "yb/util/result.h"
 #include "yb/util/test_util.h"
diff --git a/src/yb/tserver/xcluster_ddl_queue_handler.cc b/src/yb/tserver/xcluster_ddl_queue_handler.cc
index 5a53d4a52c..176b643aa3 100644
--- a/src/yb/tserver/xcluster_ddl_queue_handler.cc
+++ b/src/yb/tserver/xcluster_ddl_queue_handler.cc
@@ -21,6 +21,7 @@
 #include "yb/common/hybrid_time.h"
 #include "yb/common/json_util.h"
 #include "yb/master/master_replication.pb.h"
+#include "yb/tserver/xcluster_output_client.h"
 #include "yb/yql/pgwrapper/libpq_utils.h"
 
 DEFINE_test_flag(bool, xcluster_ddl_queue_handler_cache_connection, true,
@@ -91,13 +92,15 @@ Result<rapidjson::Document> ParseSerializedJson(const std::string& raw_json_data
 }  // namespace
 
 XClusterDDLQueueHandler::XClusterDDLQueueHandler(
-    std::shared_ptr<XClusterClient> local_client, const NamespaceName& namespace_name,
+    client::YBClient* local_client, const NamespaceName& namespace_name,
     const NamespaceId& namespace_id, ConnectToPostgresFunc connect_to_pg_func)
     : local_client_(local_client),
       namespace_name_(namespace_name),
       namespace_id_(namespace_id),
       connect_to_pg_func_(std::move(connect_to_pg_func)) {}
 
+XClusterDDLQueueHandler::~XClusterDDLQueueHandler() {}
+
 Status XClusterDDLQueueHandler::ProcessDDLQueueTable(const XClusterOutputClientResponse& response) {
   DCHECK(response.status.ok());
 
@@ -225,7 +228,7 @@ Status XClusterDDLQueueHandler::InitPGConnection() {
   }
   // Create pg connection if it doesn't exist.
   // TODO(#20693) Create prepared statements as part of opening the connection.
-  CoarseTimePoint deadline = CoarseMonoClock::Now() + local_client_->client->default_rpc_timeout();
+  CoarseTimePoint deadline = CoarseMonoClock::Now() + local_client_->default_rpc_timeout();
   pg_conn_ = std::make_unique<pgwrapper::PGConn>(
       VERIFY_RESULT(connect_to_pg_func_(namespace_name_, deadline)));
 
@@ -249,7 +252,7 @@ Status XClusterDDLQueueHandler::InitPGConnection() {
 }
 
 Result<HybridTime> XClusterDDLQueueHandler::GetXClusterSafeTimeForNamespace() {
-  return local_client_->client->GetXClusterSafeTimeForNamespace(
+  return local_client_->GetXClusterSafeTimeForNamespace(
       namespace_id_, master::XClusterSafeTimeFilter::DDL_QUEUE);
 }
 
diff --git a/src/yb/tserver/xcluster_ddl_queue_handler.h b/src/yb/tserver/xcluster_ddl_queue_handler.h
index a52943ee95..54aba08648 100644
--- a/src/yb/tserver/xcluster_ddl_queue_handler.h
+++ b/src/yb/tserver/xcluster_ddl_queue_handler.h
@@ -11,18 +11,16 @@
 // under the License.
 //
 
-#include <rapidjson/document.h>
-#include "yb/client/yb_table_name.h"
-#include "yb/tserver/xcluster_consumer.h"
-#include "yb/tserver/xcluster_output_client.h"
-#include "yb/yql/pgwrapper/libpq_utils.h"
-
 #pragma once
 
+#include "yb/tserver/xcluster_consumer_if.h"
+
 namespace yb {
 
 namespace tserver {
 
+struct XClusterOutputClientResponse;
+
 // Handler for the ddl_queue table, used for xCluster DDL replication.
 // This handler is called by XClusterPoller after ApplyChanges has been processed successfully for
 // the ddl_queue tablet.
@@ -34,9 +32,9 @@ namespace tserver {
 class XClusterDDLQueueHandler {
  public:
   XClusterDDLQueueHandler(
-      std::shared_ptr<XClusterClient> local_client, const NamespaceName& namespace_name,
+      client::YBClient* local_client, const NamespaceName& namespace_name,
       const NamespaceId& namespace_id, ConnectToPostgresFunc connect_to_pg_func);
-  virtual ~XClusterDDLQueueHandler() = default;
+  virtual ~XClusterDDLQueueHandler();
 
   Status ProcessDDLQueueTable(const XClusterOutputClientResponse& response);
 
@@ -64,7 +62,7 @@ class XClusterDDLQueueHandler {
   virtual Result<std::vector<std::tuple<int64, int64, std::string>>> GetRowsToProcess(
       const HybridTime& apply_safe_time);
 
-  const std::shared_ptr<XClusterClient> local_client_;
+  client::YBClient* local_client_;
 
   std::unique_ptr<pgwrapper::PGConn> pg_conn_;
   NamespaceName namespace_name_;
diff --git a/src/yb/tserver/xcluster_output_client.cc b/src/yb/tserver/xcluster_output_client.cc
index b1783cc47b..25e85e1cec 100644
--- a/src/yb/tserver/xcluster_output_client.cc
+++ b/src/yb/tserver/xcluster_output_client.cc
@@ -12,8 +12,6 @@
 
 #include "yb/tserver/xcluster_output_client.h"
 
-#include <shared_mutex>
-
 #include "yb/cdc/cdc_types.h"
 #include "yb/cdc/xcluster_rpc.h"
 
@@ -26,27 +24,21 @@
 #include "yb/client/meta_cache.h"
 #include "yb/client/table.h"
 #include "yb/dockv/doc_key.h"
-#include "yb/docdb/docdb.h"
-
-#include "yb/gutil/strings/join.h"
 
 #include "yb/master/master_replication.pb.h"
 
 #include "yb/rocksdb/rate_limiter.h"
-#include "yb/rocksdb/util/rate_limiter.h"
 
 #include "yb/rpc/rpc.h"
 #include "yb/rpc/rpc_fwd.h"
 #include "yb/tserver/xcluster_consumer.h"
 #include "yb/tserver/xcluster_poller.h"
-#include "yb/tserver/tserver_service.proxy.h"
 #include "yb/tserver/xcluster_write_interface.h"
 #include "yb/util/flags.h"
 #include "yb/util/logging.h"
 #include "yb/util/net/net_util.h"
 #include "yb/util/result.h"
 #include "yb/util/status.h"
-#include "yb/util/stol_utils.h"
 #include "yb/util/stopwatch.h"
 
 DECLARE_int32(cdc_write_rpc_timeout_ms);
@@ -94,10 +86,10 @@ namespace tserver {
 
 XClusterOutputClient::XClusterOutputClient(
     XClusterPoller* xcluster_poller, const xcluster::ConsumerTabletInfo& consumer_tablet_info,
-    const xcluster::ProducerTabletInfo& producer_tablet_info,
-    const std::shared_ptr<XClusterClient>& local_client, ThreadPool* thread_pool, rpc::Rpcs* rpcs,
-    bool use_local_tserver, rocksdb::RateLimiter* rate_limiter)
-    : XClusterAsyncExecutor(thread_pool, local_client->messenger.get(), rpcs),
+    const xcluster::ProducerTabletInfo& producer_tablet_info, client::YBClient& local_client,
+    ThreadPool* thread_pool, rpc::Rpcs* rpcs, bool use_local_tserver,
+    rocksdb::RateLimiter* rate_limiter)
+    : XClusterAsyncExecutor(thread_pool, local_client.messenger(), rpcs),
       xcluster_poller_(xcluster_poller),
       consumer_tablet_info_(consumer_tablet_info),
       producer_tablet_info_(producer_tablet_info),
@@ -197,14 +189,14 @@ void XClusterOutputClient::ApplyChanges(std::shared_ptr<cdc::GetChangesResponseP
   // Ensure we have a connection to the consumer table cached.
   if (!table_) {
     HANDLE_ERROR_AND_RETURN_IF_NOT_OK(
-        local_client_->client->OpenTable(consumer_tablet_info_.table_id, &table_));
+        local_client_.OpenTable(consumer_tablet_info_.table_id, &table_));
   }
 
   timeout_ms_ = MonoDelta::FromMilliseconds(FLAGS_cdc_read_rpc_timeout_ms);
   // Using this future as a barrier to get all the tablets before processing.  Ordered iteration
   // matters: we need to ensure that each record is handled sequentially.
-  all_tablets_result_ = local_client_->client->LookupAllTabletsFuture(
-      table_, CoarseMonoClock::now() + timeout_ms_).get();
+  all_tablets_result_ =
+      local_client_.LookupAllTabletsFuture(table_, CoarseMonoClock::now() + timeout_ms_).get();
 
   HANDLE_ERROR_AND_RETURN_IF_NOT_OK(ProcessChangesStartingFromIndex(0));
 }
@@ -245,8 +237,10 @@ Status XClusterOutputClient::ProcessChangesStartingFromIndex(int start) {
           break;
         default: {
           std::string partition_key = record.key(0).key();
-          auto tablet_result = local_client_->client->LookupTabletByKeyFuture(
-              table_, partition_key, CoarseMonoClock::now() + timeout_ms_).get();
+          auto tablet_result = local_client_
+                                   .LookupTabletByKeyFuture(
+                                       table_, partition_key, CoarseMonoClock::now() + timeout_ms_)
+                                   .get();
           RETURN_NOT_OK(ProcessRecordForTablet(record, tablet_result));
           break;
         }
@@ -443,7 +437,7 @@ Result<bool> XClusterOutputClient::ProcessMetaOp(const cdc::CDCRecordPB& record)
           InternalError, "Fail due to FLAGS_TEST_xcluster_consumer_fail_after_process_split_op");
     }
 
-    RETURN_NOT_OK(local_client_->client->UpdateConsumerOnProducerSplit(
+    RETURN_NOT_OK(local_client_.UpdateConsumerOnProducerSplit(
         producer_tablet_info_.replication_group_id, producer_tablet_info_.stream_id, split_info));
   } else if (record.operation() == cdc::CDCRecordPB::CHANGE_METADATA) {
     if (!VERIFY_RESULT(ProcessChangeMetadataOp(record))) {
@@ -480,8 +474,7 @@ void XClusterOutputClient::SendNextCDCWriteToTablet(std::unique_ptr<WriteRequest
 
   // Send in nullptr for RemoteTablet since cdc rpc now gets the tablet_id from the write request.
   *handle = rpc::xcluster::CreateXClusterWriteRpc(
-      deadline, nullptr /* RemoteTablet */, table_, local_client_->client.get(),
-      write_request.get(),
+      deadline, nullptr /* RemoteTablet */, table_, &local_client_, write_request.get(),
       [weak_ptr = weak_from_this(), this, handle, rpcs = rpcs_](
           const Status& status, WriteResponsePB&& resp) {
         RpcCallback(
@@ -510,7 +503,7 @@ void XClusterOutputClient::UpdateSchemaVersionMapping(
   // Send in nullptr for RemoteTablet since cdc rpc now gets the tablet_id from the write
   // request.
   *handle = rpc::xcluster::CreateGetCompatibleSchemaVersionRpc(
-      deadline, nullptr, local_client_->client.get(), req,
+      deadline, nullptr, &local_client_, req,
       [weak_ptr = weak_from_this(), this, handle, rpcs = rpcs_](
           const Status& status, const GetCompatibleSchemaVersionRequestPB& req,
           GetCompatibleSchemaVersionResponsePB&& resp) {
@@ -565,7 +558,7 @@ void XClusterOutputClient::DoSchemaVersionCheckDone(
   tablet::ChangeMetadataRequestPB meta;
   meta.set_tablet_id(producer_tablet_info_.tablet_id);
   master::UpdateConsumerOnProducerMetadataResponsePB response;
-  Status s = local_client_->client->UpdateConsumerOnProducerMetadata(
+  Status s = local_client_.UpdateConsumerOnProducerMetadata(
       producer_tablet_info_.replication_group_id, producer_tablet_info_.stream_id, meta,
       colocation_id, producer_schema_version, resp.compatible_schema_version(), &response);
   if (!s.ok()) {
@@ -705,9 +698,9 @@ bool XClusterOutputClient::IncProcessedRecordCount() {
 
 std::shared_ptr<XClusterOutputClient> CreateXClusterOutputClient(
     XClusterPoller* xcluster_poller, const xcluster::ConsumerTabletInfo& consumer_tablet_info,
-    const xcluster::ProducerTabletInfo& producer_tablet_info,
-    const std::shared_ptr<XClusterClient>& local_client, ThreadPool* thread_pool, rpc::Rpcs* rpcs,
-    bool use_local_tserver, rocksdb::RateLimiter* rate_limiter) {
+    const xcluster::ProducerTabletInfo& producer_tablet_info, client::YBClient& local_client,
+    ThreadPool* thread_pool, rpc::Rpcs* rpcs, bool use_local_tserver,
+    rocksdb::RateLimiter* rate_limiter) {
   return std::make_unique<XClusterOutputClient>(
       xcluster_poller, consumer_tablet_info, producer_tablet_info, local_client, thread_pool, rpcs,
       use_local_tserver, rate_limiter);
diff --git a/src/yb/tserver/xcluster_output_client.h b/src/yb/tserver/xcluster_output_client.h
index 0d54b54b89..eead7dcf48 100644
--- a/src/yb/tserver/xcluster_output_client.h
+++ b/src/yb/tserver/xcluster_output_client.h
@@ -14,7 +14,6 @@
 #include "yb/cdc/xcluster_types.h"
 #include "yb/consensus/opid_util.h"
 #include "yb/tserver/xcluster_async_executor.h"
-#include "yb/cdc/cdc_util.h"
 
 #include "yb/client/client_fwd.h"
 #include "yb/rpc/rpc_fwd.h"
@@ -49,9 +48,9 @@ class XClusterOutputClient : public XClusterAsyncExecutor {
  public:
   XClusterOutputClient(
       XClusterPoller* xcluster_poller, const xcluster::ConsumerTabletInfo& consumer_tablet_info,
-      const xcluster::ProducerTabletInfo& producer_tablet_info,
-      const std::shared_ptr<XClusterClient>& local_client, ThreadPool* thread_pool, rpc::Rpcs* rpcs,
-      bool use_local_tserver, rocksdb::RateLimiter* rate_limiter);
+      const xcluster::ProducerTabletInfo& producer_tablet_info, client::YBClient& local_client,
+      ThreadPool* thread_pool, rpc::Rpcs* rpcs, bool use_local_tserver,
+      rocksdb::RateLimiter* rate_limiter);
   ~XClusterOutputClient();
   void StartShutdown() override;
   void CompleteShutdown() override;
@@ -133,7 +132,7 @@ class XClusterOutputClient : public XClusterAsyncExecutor {
   const xcluster::ProducerTabletInfo producer_tablet_info_;
   cdc::XClusterSchemaVersionMap schema_versions_ GUARDED_BY(lock_);
   cdc::ColocatedSchemaVersionMap colocated_schema_version_map_ GUARDED_BY(lock_);
-  std::shared_ptr<XClusterClient> local_client_;
+  client::YBClient& local_client_;
 
   bool use_local_tserver_;
 
@@ -169,9 +168,9 @@ class XClusterOutputClient : public XClusterAsyncExecutor {
 
 std::shared_ptr<XClusterOutputClient> CreateXClusterOutputClient(
     XClusterPoller* xcluster_poller, const xcluster::ConsumerTabletInfo& consumer_tablet_info,
-    const xcluster::ProducerTabletInfo& producer_tablet_info,
-    const std::shared_ptr<XClusterClient>& local_client, ThreadPool* thread_pool, rpc::Rpcs* rpcs,
-    bool use_local_tserver, rocksdb::RateLimiter* rate_limiter);
+    const xcluster::ProducerTabletInfo& producer_tablet_info, client::YBClient& local_client,
+    ThreadPool* thread_pool, rpc::Rpcs* rpcs, bool use_local_tserver,
+    rocksdb::RateLimiter* rate_limiter);
 
 } // namespace tserver
 } // namespace yb
diff --git a/src/yb/tserver/xcluster_poller.cc b/src/yb/tserver/xcluster_poller.cc
index 689f2b9740..7158f6e286 100644
--- a/src/yb/tserver/xcluster_poller.cc
+++ b/src/yb/tserver/xcluster_poller.cc
@@ -20,21 +20,17 @@
 
 #include "yb/cdc/xcluster_rpc.h"
 #include "yb/cdc/cdc_service.pb.h"
-#include "yb/cdc/cdc_service.proxy.h"
 #include "yb/client/client.h"
 
 #include "yb/consensus/opid_util.h"
 
 #include "yb/gutil/dynamic_annotations.h"
 #include "yb/util/callsite_profiling.h"
-#include "yb/rpc/messenger.h"
 #include "yb/tserver/xcluster_consumer_auto_flags_info.h"
 #include "yb/util/flags.h"
 #include "yb/util/format.h"
 #include "yb/util/logging.h"
 #include "yb/util/scope_exit.h"
-#include "yb/util/source_location.h"
-#include "yb/util/status_log.h"
 #include "yb/util/threadpool.h"
 #include "yb/util/unique_lock.h"
 
@@ -115,11 +111,11 @@ XClusterPoller::XClusterPoller(
     const xcluster::ConsumerTabletInfo& consumer_tablet_info,
     const NamespaceId& consumer_namespace_id,
     std::shared_ptr<const AutoFlagsCompatibleVersion> auto_flags_version, ThreadPool* thread_pool,
-    rpc::Rpcs* rpcs, const std::shared_ptr<XClusterClient>& local_client,
+    rpc::Rpcs* rpcs, client::YBClient& local_client,
     const std::shared_ptr<XClusterClient>& producer_client, XClusterConsumer* xcluster_consumer,
     SchemaVersion last_compatible_consumer_schema_version, int64_t leader_term,
     std::function<int64_t(const TabletId&)> get_leader_term)
-    : XClusterAsyncExecutor(thread_pool, local_client->messenger.get(), rpcs),
+    : XClusterAsyncExecutor(thread_pool, local_client.messenger(), rpcs),
       producer_tablet_info_(producer_tablet_info),
       consumer_tablet_info_(consumer_tablet_info),
       consumer_namespace_id_(consumer_namespace_id),
@@ -157,7 +153,7 @@ void XClusterPoller::InitDDLQueuePoller(
   Init(use_local_tserver, rate_limiter);
 
   ddl_queue_handler_ = std::make_shared<XClusterDDLQueueHandler>(
-      local_client_, namespace_name, consumer_namespace_id_, std::move(connect_to_pg_func));
+      &local_client_, namespace_name, consumer_namespace_id_, std::move(connect_to_pg_func));
 }
 
 void XClusterPoller::StartShutdown() {
diff --git a/src/yb/tserver/xcluster_poller.h b/src/yb/tserver/xcluster_poller.h
index 6d791570d8..d562c67bc8 100644
--- a/src/yb/tserver/xcluster_poller.h
+++ b/src/yb/tserver/xcluster_poller.h
@@ -54,7 +54,7 @@ class XClusterPoller : public XClusterAsyncExecutor {
       const xcluster::ConsumerTabletInfo& consumer_tablet_info,
       const NamespaceId& consumer_namespace_id,
       std::shared_ptr<const AutoFlagsCompatibleVersion> auto_flags_version, ThreadPool* thread_pool,
-      rpc::Rpcs* rpcs, const std::shared_ptr<XClusterClient>& local_client,
+      rpc::Rpcs* rpcs, client::YBClient& local_client,
       const std::shared_ptr<XClusterClient>& producer_client, XClusterConsumer* xcluster_consumer,
       SchemaVersion last_compatible_consumer_schema_version, int64_t leader_term,
       std::function<int64_t(const TabletId&)> get_leader_term);
@@ -157,7 +157,7 @@ class XClusterPoller : public XClusterAsyncExecutor {
   std::atomic<SchemaVersion> last_compatible_consumer_schema_version_;
   std::function<int64_t(const TabletId&)> get_leader_term_;
 
-  const std::shared_ptr<XClusterClient> local_client_;
+  client::YBClient& local_client_;
   std::shared_ptr<XClusterOutputClient> output_client_;
   std::shared_ptr<XClusterClient> producer_client_;
   std::shared_ptr<XClusterDDLQueueHandler> ddl_queue_handler_;
