diff --git a/src/yb/integration-tests/master_path_handlers-itest.cc b/src/yb/integration-tests/master_path_handlers-itest.cc
index 13b4cfecf2..49ff78a490 100644
--- a/src/yb/integration-tests/master_path_handlers-itest.cc
+++ b/src/yb/integration-tests/master_path_handlers-itest.cc
@@ -72,8 +72,8 @@ DECLARE_bool(TEST_tserver_disable_heartbeat);
 
 DECLARE_int32(follower_unavailable_considered_failed_sec);
 
-DECLARE_int32(cleanup_split_tablets_interval_sec);
 DECLARE_int32(catalog_manager_bg_task_wait_ms);
+DECLARE_int32(cleanup_split_tablets_interval_sec);
 DECLARE_int32(tserver_heartbeat_metrics_interval_ms);
 DECLARE_bool(enable_automatic_tablet_splitting);
 DECLARE_bool(TEST_skip_deleting_split_tablets);
@@ -167,6 +167,11 @@ class MasterPathHandlersBaseItest : public YBMiniClusterTestBase<T> {
     return table;
   }
 
+  void DeleteTestTable() {
+    auto client = CHECK_RESULT(cluster_->CreateClient());
+    CHECK_OK(client->DeleteTable(table_name, /*wait=*/true));
+  }
+
   Result<std::string> GetLeaderlessTabletsString() {
     faststring result;
     auto url = "/tablet-replication";
@@ -208,6 +213,39 @@ class MasterPathHandlersItest : public MasterPathHandlersBaseItest<MiniCluster>
     client_ = ASSERT_RESULT(cluster_->CreateClient());
   }
 
+  void ExpectLoadDistributionViewTabletsShown(int tablet_count) {
+    // This code expects that we have 3 TServers, 1 table, and RF 3.
+    int expected_replicas = tablet_count * 3;
+
+    faststring result;
+    ASSERT_OK(GetUrl("/load-distribution", &result));
+    const auto webpage = result.ToString();
+
+    // Endpoint output includes:
+    //   test_table</a></td><td>1</td><td>1/1</td><td>1/0</td><td>1/0</td></tr></table>
+    //
+    // (First # is total number of tablets, later are #peers/#leaders for each TServer.)
+    std::string num_cell = "<td>([0-9]+)</td>";
+    std::string num_pair_cell = "<td>([0-9]+)/[0-9]+</td>";
+    const std::regex regex(
+        "test_table</a></td>" + num_cell + num_pair_cell + num_pair_cell + num_pair_cell +
+        "</tr></table>");
+    std::smatch match;
+    std::regex_search(webpage, match, regex);
+
+    ASSERT_TRUE(!match.empty()) << "Load distribution view does not seem to contain information "
+                                   "about the test table in the expected format";
+
+    ASSERT_EQ(match.size(), 5);  // [0] is full match
+    EXPECT_EQ(std::stoi(match[1].str()), tablet_count);
+
+    int peers = 0;
+    for (int i = 2; i < 5; i++) {
+      peers += std::stoi(match[i].str());
+    }
+    EXPECT_EQ(peers, expected_replicas);
+  }
+
  protected:
   std::unique_ptr<client::YBClient> client_;
 };
@@ -712,7 +750,7 @@ TEST_F_EX(
       {table_name}, false /* add_indexes */, 30 /* timeout_secs */, false /* is_compaction */));
   ASSERT_OK(catalog_manager.TEST_SplitTablet(tablet, 1 /* split_hash_code */));
 
-  // The parent tablet should be retained because it's in a PITR snapshot.
+  // The parent tablet should be retained because of the snapshot schedule.
   ASSERT_OK(WaitFor(
       [&]() { return tablet->LockForRead()->is_hidden(); },
       30s /* timeout */,
@@ -1533,6 +1571,72 @@ TEST_F(MasterPathHandlersItestExtraTS, LoadDistributionViewWithFailedTServer) {
   ASSERT_OK(GetUrl("/load-distribution", &out));
 }
 
+TEST_F_EX(
+    MasterPathHandlersItest, LoadDistributionViewExcludesDeletedSplitParents,
+    TabletSplitMasterPathHandlersItest) {
+  // Start with 3 regular tablets.
+  CreateTestTable(3 /* num_tablets */);
+  ExpectLoadDistributionViewTabletsShown(3);
+
+  // Split the first tablet, resulting in it becoming a split parent; 2 new children tablets are
+  // created as part of this.
+  client::TableHandle table;
+  ASSERT_OK(table.Open(table_name, client_.get()));
+  InsertRows(table, /* num_rows_to_insert = */ 500);
+  auto& catalog_manager = ASSERT_RESULT(cluster_->GetLeaderMiniMaster())->catalog_manager();
+  auto tablet = ASSERT_RESULT(catalog_manager.GetTableInfo(table->id())->GetTablets())[0];
+  ASSERT_OK(yb_admin_client_->FlushTables(
+      {table_name}, false /* add_indexes */, 30 /* timeout_secs */, false /* is_compaction */));
+  ASSERT_OK(catalog_manager.TEST_SplitTablet(tablet, 1 /* split_hash_code */));
+  ASSERT_OK(WaitFor(
+      [&]() { return tablet->LockForRead()->is_deleted(); }, 30s /* timeout */,
+      "Wait for tablet split to complete and parent to be deleted"));
+  ExpectLoadDistributionViewTabletsShown(4);
+}
+
+TEST_F_EX(
+    MasterPathHandlersItest, LoadDistributionViewIncludesHiddenSplitParents,
+    TabletSplitMasterPathHandlersItest) {
+  // Start with 3 regular tablets.
+  CreateTestTable(3 /* num_tablets */);
+  ExpectLoadDistributionViewTabletsShown(3);
+
+  // Create a snapshot schedule.
+  client::TableHandle table;
+  ASSERT_OK(table.Open(table_name, client_.get()));
+  InsertRows(table, /* num_rows_to_insert = */ 500);
+  auto& catalog_manager = ASSERT_RESULT(cluster_->GetLeaderMiniMaster())->catalog_manager();
+  auto tablet = ASSERT_RESULT(catalog_manager.GetTableInfo(table->id())->GetTablets())[0];
+  auto snapshot_util = std::make_unique<client::SnapshotTestUtil>();
+  snapshot_util->SetProxy(&client_->proxy_cache());
+  snapshot_util->SetCluster(cluster_.get());
+  const auto kInterval = 2s * kTimeMultiplier;
+  const auto kRetention = kInterval * 2;
+  auto schedule_id = ASSERT_RESULT(snapshot_util->CreateSchedule(
+      nullptr, YQL_DATABASE_CQL, table->name().namespace_name(),
+      client::WaitSnapshot::kFalse, kInterval, kRetention));
+  ASSERT_OK(snapshot_util->WaitScheduleSnapshot(schedule_id));
+  auto schedules = ASSERT_RESULT(snapshot_util->ListSchedules(schedule_id));
+  ASSERT_EQ(schedules.size(), 1);
+
+  // Split the first tablet, resulting in it becoming a split parent; 2 new children tablets are
+  // created as part of this.
+  ASSERT_OK(yb_admin_client_->FlushTables(
+      {table_name}, false /* add_indexes */, 30 /* timeout_secs */, false /* is_compaction */));
+  ASSERT_OK(catalog_manager.TEST_SplitTablet(tablet, 1 /* split_hash_code */));
+  // The parent tablet should be retained because of the snapshot schedule.
+  ASSERT_OK(WaitFor(
+      [&]() { return tablet->LockForRead()->is_hidden(); },
+      30s /* timeout */,
+      "Wait for tablet split to complete and parent to be hidden"));
+  // We continue to count the split tablet because it is hidden not deleted.
+  ExpectLoadDistributionViewTabletsShown(5);
+
+  // Delete the table; it and its tablets will be retained as hidden due to the schedule.
+  DeleteTestTable();
+  ExpectLoadDistributionViewTabletsShown(5);
+}
+
 TEST_F(MasterPathHandlersItest, StatefulServices) {
   auto client = ASSERT_RESULT(cluster_->CreateClient());
   const auto service_name = StatefulServiceKind_Name(StatefulServiceKind::TEST_ECHO);
diff --git a/src/yb/master/README b/src/yb/master/README
index 732d8f2bf6..9ccbbf884b 100644
--- a/src/yb/master/README
+++ b/src/yb/master/README
@@ -155,7 +155,8 @@ This is the current control flow:
 
   2. Cleanup deleted tables & tablets (FIXME: is this implemented?):
      - Remove the tables/tablets with "deleted" state from "sys.catalog"
-     - Remove the tablets with "deleted" state from the in-memory map
+     - [not done 10/2024, TODO(#15043)] Remove the tablets with
+       "deleted" state from the in-memory map
      - Remove the tables with "deleted" state from the in-memory map
 
 When the TS receives a CreateTablet() RPC, it will attempt to create the tablet
diff --git a/src/yb/master/catalog_entity_info.h b/src/yb/master/catalog_entity_info.h
index 6e7f760f79..2ba9eb24bf 100644
--- a/src/yb/master/catalog_entity_info.h
+++ b/src/yb/master/catalog_entity_info.h
@@ -791,10 +791,13 @@ class TableInfo : public RefCountedThreadSafe<TableInfo>,
   // At any point in time it contains only the active tablets (defined in the comment on tablets_).
   std::map<PartitionKey, std::weak_ptr<TabletInfo>> partitions_ GUARDED_BY(lock_);
   // At any point in time it contains both active and inactive tablets.
+  //
   // Currently there are two cases for a tablet to be categorized as inactive:
-  // 1) Not yet deleted split parent tablets for which we've already
-  //    registered child split tablets.
-  // 2) Tablets that are marked as HIDDEN for PITR.
+  // 1) Tablets that have been marked HIDDEN; for example, for PITR or xCluster.
+  // 2) Tablets that have been/are being DELETED.
+  //
+  // Currently, we do not remove tablets we have deleted from tablets_.
+  // TODO(#15043): remove tablets from tablets_ once they have been deleted from all TServers.
   std::unordered_map<TabletId, std::weak_ptr<TabletInfo>> tablets_ GUARDED_BY(lock_);
 
   // Protects partitions_ and tablets_.
diff --git a/src/yb/master/catalog_manager.cc b/src/yb/master/catalog_manager.cc
index 39fff63d42..c1f3198fee 100644
--- a/src/yb/master/catalog_manager.cc
+++ b/src/yb/master/catalog_manager.cc
@@ -10605,7 +10605,8 @@ Status CatalogManager::DeleteOrHideTabletsAndSendRequests(
     auto& tablet_lock = tablet_data.lock;
 
     // Inactive tablet now, so remove it from partitions_.
-    // After all the tablets have been deleted from the tservers, we remove it from tablets_.
+    // TODO(#15043): After all the tablet's replicas have been deleted from the tservers, remove
+    //               it from tablets_.
     VERIFY_RESULT(tablet->table()->RemoveTablet(tablet->id(), DeactivateOnly::kTrue));
 
     if (hide_only) {
diff --git a/src/yb/master/master-path-handlers.cc b/src/yb/master/master-path-handlers.cc
index 5eec4db1e4..a8e099a2ea 100644
--- a/src/yb/master/master-path-handlers.cc
+++ b/src/yb/master/master-path-handlers.cc
@@ -3383,6 +3383,9 @@ Status MasterPathHandlers::CalculateTabletMap(TabletCountMap* tablet_map) {
     TabletInfos tablets = VERIFY_RESULT(table->GetTablets(IncludeInactive::kTrue));
     bool is_user_table = master_->catalog_manager()->IsUserCreatedTable(*table);
     for (const auto& tablet : tablets) {
+      if (tablet->LockForRead()->is_deleted()) {
+        continue;
+      }
       auto replication_locations = tablet->GetReplicaLocations();
       for (const auto& replica : *replication_locations) {
         auto& counts = (*tablet_map)[replica.first];
@@ -3439,6 +3442,9 @@ Result<MasterPathHandlers::TServerTree> MasterPathHandlers::CalculateTServerTree
     TabletInfos tablets = VERIFY_RESULT(table->GetTablets(IncludeInactive::kTrue));
 
     for (const auto& tablet : tablets) {
+      if (tablet->LockForRead()->is_deleted()) {
+        continue;
+      }
       auto replica_locations = tablet->GetReplicaLocations();
       for (const auto& replica : *replica_locations) {
         tserver_tree[replica.first][tablet->table()->id()].emplace_back(
@@ -3498,17 +3504,24 @@ void MasterPathHandlers::RenderLoadBalancerViewPanel(
     }
     const string& table_name = table_locked->name();
     const string& table_id = table->id();
-    auto tablet_count = table->TabletCount(IncludeInactive::kTrue);
+
+    std::unordered_set<TabletId> tablet_ids;
+    for (const auto& [_, table_tree] : tserver_tree) {
+      for (const auto& [_, replicas] : table_tree) {
+        for (const auto& replica : replicas) {
+          tablet_ids.insert(replica.tablet_id);
+        }
+      }
+    }
+    auto tablet_count = tablet_ids.size();
 
     *output << Format(
         "<tr>"
         "<td>$0</td>"
         "<td><a href=\"/table?id=$1\">$2</a></td>"
         "<td>$3</td>",
-        EscapeForHtmlToString(keyspace),
-        UrlEncodeToString(table_id),
-        EscapeForHtmlToString(table_name),
-        tablet_count);
+        EscapeForHtmlToString(keyspace), UrlEncodeToString(table_id),
+        EscapeForHtmlToString(table_name), tablet_count);
     for (auto& desc : descs) {
       uint64 num_replicas = 0;
       uint64 num_leaders = 0;
diff --git a/src/yb/master/master-path-handlers.h b/src/yb/master/master-path-handlers.h
index 31e9b32f27..a730b36c90 100644
--- a/src/yb/master/master-path-handlers.h
+++ b/src/yb/master/master-path-handlers.h
@@ -301,7 +301,7 @@ class MasterPathHandlers {
   Status CalculateTabletMap(TabletCountMap* tablet_map);
 
   // Calculate tserver tree for ALL tables if max_table_count == -1.
-  // Otherwise, do not perform calculation if number of tables is less than max_table_count.
+  // Otherwise, do not perform calculation if number of tables is more than max_table_count.
   Result<TServerTree> CalculateTServerTree(int max_table_count);
   void RenderLoadBalancerViewPanel(
       const TServerTree& tserver_tree, const std::vector<std::shared_ptr<TSDescriptor>>& descs,
