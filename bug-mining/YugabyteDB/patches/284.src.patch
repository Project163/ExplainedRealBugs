diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
index b5183a81b4..88dd43be35 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
@@ -15,6 +15,7 @@ SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
 
 -- Verify that regular tables are captured.
 CREATE TABLE foo(i int PRIMARY KEY);
+INSERT INTO foo(i) VALUES (1), (2), (3);
 -- Check with manual replication flags enabled, ddl string is captured with flag.
 SET yb_xcluster_ddl_replication.enable_manual_ddl_replication = 1;
 CREATE TABLE manual_foo(i int PRIMARY KEY);
@@ -44,6 +45,14 @@ SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end
 -- Test tables partitioned by their primary key or a column.
 CREATE TABLE foo_partitioned_by_pkey(id int, PRIMARY KEY (id)) PARTITION BY RANGE (id);
 CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id);
+CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10);
+CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20);
+INSERT INTO foo_partitioned_by_col(id) VALUES (1), (2), (3), (10), (11), (12);
+-- Test for relations that trigger nonconcurrent backfills.
+CREATE INDEX NONCONCURRENTLY nonconcurrent_foo on foo(i);
+CREATE INDEX NONCONCURRENTLY on foo(i);  -- test without a name
+ALTER TABLE foo ADD CONSTRAINT constraint_foo UNIQUE (i);
+CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id);
 -- Now test dropping these tables.
 DROP TABLE foo;
 -- Check with manual replication flags enabled, ddl string is captured with flag.
@@ -55,21 +64,27 @@ DROP TABLE unique_foo;
 DROP TABLE foo_partitioned_by_pkey;
 DROP TABLE foo_partitioned_by_col;
 SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
-                                                                                                                                                  yb_data                                                                                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+                                                                                                                                                                                                         yb_data                                                                                                                                                                                                          
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
  {"user": "yugabyte", "query": "CREATE TABLE manual_foo(i int PRIMARY KEY);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "manual_replication": true}
  {"user": "yugabyte", "query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS;", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "extra_foo", "relfile_oid": "***"}]}
  {"user": "yugabyte", "query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "unique_foo", "relfile_oid": "***"}, {"is_index": true, "rel_name": "unique_foo_u_key", "relfile_oid": "***"}]}
  {"user": "yugabyte", "query": "CREATE TABLE foo_partitioned_by_pkey(id int, PRIMARY KEY (id)) PARTITION BY RANGE (id);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo_partitioned_by_pkey", "relfile_oid": "***"}]}
  {"user": "yugabyte", "query": "CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo_partitioned_by_col", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "partition1", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "partition2", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE INDEX NONCONCURRENTLY nonconcurrent_foo on foo(i);", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "nonconcurrent_foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE INDEX NONCONCURRENTLY on foo(i);", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_i_idx", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "ALTER TABLE foo ADD CONSTRAINT constraint_foo UNIQUE (i);", "schema": "public", "version": 1, "command_tag": "ALTER TABLE", "new_rel_map": [{"is_index": true, "rel_name": "constraint_foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id);", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "partitioned_index", "relfile_oid": "***"}, {"is_index": true, "rel_name": "partition1_id_idx", "relfile_oid": "***"}, {"is_index": true, "rel_name": "partition2_id_idx", "relfile_oid": "***"}]}
  {"user": "yugabyte", "query": "DROP TABLE foo;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
  {"user": "yugabyte", "query": "DROP TABLE manual_foo;", "schema": "public", "version": 1, "command_tag": "DROP TABLE", "manual_replication": true}
  {"user": "yugabyte", "query": "DROP TABLE extra_foo;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
  {"user": "yugabyte", "query": "DROP TABLE unique_foo;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
  {"user": "yugabyte", "query": "DROP TABLE foo_partitioned_by_pkey;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
  {"user": "yugabyte", "query": "DROP TABLE foo_partitioned_by_col;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
-(12 rows)
+(18 rows)
 
 SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end_time;
                                                 yb_data                                                 
@@ -80,13 +95,19 @@ SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end
  {"query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE);"}
  {"query": "CREATE TABLE foo_partitioned_by_pkey(id int, PRIMARY KEY (id)) PARTITION BY RANGE (id);"}
  {"query": "CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id);"}
+ {"query": "CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10);"}
+ {"query": "CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20);"}
+ {"query": "CREATE INDEX NONCONCURRENTLY nonconcurrent_foo on foo(i);"}
+ {"query": "CREATE INDEX NONCONCURRENTLY on foo(i);"}
+ {"query": "ALTER TABLE foo ADD CONSTRAINT constraint_foo UNIQUE (i);"}
+ {"query": "CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id);"}
  {"query": "DROP TABLE foo;"}
  {"query": "DROP TABLE manual_foo;"}
  {"query": "DROP TABLE extra_foo;"}
  {"query": "DROP TABLE unique_foo;"}
  {"query": "DROP TABLE foo_partitioned_by_pkey;"}
  {"query": "DROP TABLE foo_partitioned_by_col;"}
-(12 rows)
+(18 rows)
 
 -- Test mix of temp and regular tables.
 CREATE TEMP TABLE temp_foo(i int PRIMARY KEY);
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
index ceee019a85..670c65e174 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
@@ -175,6 +175,7 @@ SPI_TextArrayGetElement(HeapTuple spi_tuple, int column_id, int element_index)
 
 	array = DatumGetArrayTypeP(array_datum);
 	element_type = ARR_ELEMTYPE(array);
+
 	if (element_type != TEXTOID)
 		elog(ERROR, "Expected text[] but found different type %u",
 			 element_type);
@@ -200,8 +201,41 @@ IsTempSchema(const char *schema_name)
 }
 
 Oid
-GetColocationIdFromRelation(Relation *rel)
+GetColocationIdForTableRewrite(Relation *rel)
+{
+	/*
+	 * Table rewrites have some staleness with updating the relcache and
+	 * yb_table_properties, especially with indexes. Need to explicitly get a
+	 * new table desc to get the up to date values.
+	 */
+	Oid			dbid = YBCGetDatabaseOid(*rel);
+	Oid			relfileNodeId = YbGetRelfileNodeId(*rel);
+	bool		not_found = false;
+	YbcPgTableDesc yb_tabledesc = NULL;
+	YbcTablePropertiesData table_props;
+
+	HandleYBStatusIgnoreNotFound(YBCPgGetTableDesc(dbid,
+												   relfileNodeId,
+												   &yb_tabledesc),
+								 &not_found);
+	if (not_found)
+		return InvalidOid;
+
+	HandleYBStatusIgnoreNotFound(YBCPgGetTableProperties(yb_tabledesc,
+														 &table_props),
+								 &not_found);
+	if (not_found || !table_props.is_colocated)
+		return InvalidOid;
+
+	return table_props.colocation_id;
+}
+
+Oid
+GetColocationIdFromRelation(Relation *rel, bool is_table_rewrite)
 {
+	if (is_table_rewrite)
+		return GetColocationIdForTableRewrite(rel);
+
 	YbcTableProperties table_props = YbTryGetTableProperties(*rel);
 
 	if (!table_props || !table_props->is_colocated)
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
index 932f1ffbc9..f16e048729 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
@@ -87,8 +87,8 @@ extern char *SPI_TextArrayGetElement(HeapTuple spi_tuple, int column_id,
 /* If true, any object in this schema is a temporary object. */
 extern bool IsTempSchema(const char *schema_name);
 
-/* Returns the relation's colocation id or 0 if not colocated. */
-extern Oid	GetColocationIdFromRelation(Relation *rel);
+/* Returns the relation's colocation id or InvalidOid (0) if not colocated. */
+extern Oid	GetColocationIdFromRelation(Relation *rel, bool is_table_rewrite);
 
 extern char *get_typname(Oid pg_type_oid);
 
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
index 2f947cbdf3..bc5bb12bb8 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
@@ -17,6 +17,7 @@
 
 #include "postgres.h"
 
+#include "catalog/partition.h"
 #include "catalog/pg_am_d.h"
 #include "catalog/pg_amop_d.h"
 #include "catalog/pg_amproc_d.h"
@@ -29,6 +30,7 @@
 #include "catalog/pg_foreign_data_wrapper_d.h"
 #include "catalog/pg_foreign_server_d.h"
 #include "catalog/pg_foreign_table_d.h"
+#include "catalog/pg_inherits.h"
 #include "catalog/pg_namespace_d.h"
 #include "catalog/pg_opclass_d.h"
 #include "catalog/pg_operator_d.h"
@@ -156,6 +158,7 @@ static List *rewritten_table_oid_list = NIL;
 	X(CMDTAG_REVOKE) \
 	X(CMDTAG_SECURITY_LABEL)
 
+/* Struct Definitions. */
 typedef struct YbNewRelMapEntry
 {
 	char	   *name;
@@ -178,6 +181,10 @@ typedef struct YbNameToOidMapEntry
 	Oid			oid;
 } YbNameToOidMapEntry;
 
+/* Forward Declarations. */
+static bool ShouldReplicateNewRelation(Oid rel_oid, List **new_rel_list, bool is_table_rewrite);
+
+
 bool
 IsIndex(Relation rel)
 {
@@ -231,19 +238,35 @@ IsSequence(Oid rel_oid)
 	return relkind == RELKIND_SEQUENCE;
 }
 
+void
+ReplicateInheritedRelations(Oid rel_oid, List **new_rel_list, bool is_table_rewrite)
+{
+	List	   *children = find_inheritance_children(rel_oid, NoLock);
+	ListCell   *cell;
+
+	foreach(cell, children)
+	{
+		Oid			child_oid = lfirst_oid(cell);
+
+		ShouldReplicateNewRelation(child_oid, new_rel_list, is_table_rewrite);
+	}
+}
+
 /*
  * This function handles both new relation from create table/index,
  * and also new relations as a result of table rewrites.
+ * Returns whether the relation should be replicated (eg false if
+ * table is a temp table or a primary key index).
  *
  * This function does not handle sequences.
  */
 bool
-ShouldReplicateNewRelation(Oid rel_oid, List **new_rel_list)
+ShouldReplicateNewRelation(Oid rel_oid, List **new_rel_list, bool is_table_rewrite)
 {
 	Relation	rel = RelationIdGetRelation(rel_oid);
 
 	if (!rel)
-		elog(ERROR, "Could not find relation with OID %d", rel_oid);
+		elog(ERROR, "Could not find relation with OID %u", rel_oid);
 
 	/* Ignore temporary tables. */
 	if (!IsYBBackedRelation(rel))
@@ -263,15 +286,71 @@ ShouldReplicateNewRelation(Oid rel_oid, List **new_rel_list)
 
 	new_rel_entry->name = pstrdup(RelationGetRelationName(rel));
 	new_rel_entry->relfile_oid = YbGetRelfileNodeId(rel);
-	new_rel_entry->colocation_id = GetColocationIdFromRelation(&rel);
+	new_rel_entry->colocation_id = GetColocationIdFromRelation(&rel, is_table_rewrite);
 	new_rel_entry->is_index = IsIndex(rel);
 
 	*new_rel_list = lappend(*new_rel_list, new_rel_entry);
 
 	RelationClose(rel);
+
+	/* Also loop over children relations. */
+	ReplicateInheritedRelations(rel_oid, new_rel_list, is_table_rewrite);
+
 	return true;
 }
 
+void
+HandleAlterColumnAddIndex(AlterTableCmd *subcmd, Oid rel_oid,
+						  List **new_rel_list)
+{
+	/* Need to fetch the index oid from the index name. */
+	IndexStmt  *index = (IndexStmt *) subcmd->def;
+
+	/* Skip primary keys for YB. */
+	if (index->primary)
+		return;
+
+	if (index->idxname == NULL)
+	{
+		/*
+		 * Default name is being used. It is difficult for us to get the name
+		 * that did end up getting picked for this index. In this case, we
+		 * will just collect info for all indexes on the table.
+		 */
+		Relation	rel = RelationIdGetRelation(rel_oid);
+		List	   *indexes = RelationGetIndexList(rel);
+
+		RelationClose(rel);
+		ListCell   *cell;
+
+		foreach(cell, indexes)
+		{
+			Oid			index_oid = lfirst_oid(cell);
+
+			ShouldReplicateNewRelation(index_oid, new_rel_list, /* is_table_rewrite= */ false);
+		}
+
+		list_free(indexes);
+		return;
+	}
+
+	/* We do have the index name, so can use that. */
+	Relation	rel = RelationIdGetRelation(rel_oid);
+	Oid			index_oid = get_relname_relid(index->idxname,
+											  RelationGetNamespace(rel));
+
+	RelationClose(rel);
+
+	if (index_oid == InvalidOid)
+		elog(ERROR,
+			 "Could not find index with name %s for parent relation %d",
+			 index->idxname,
+			 rel_oid);
+
+	/* Once we have the OID, we can capture its info. */
+	ShouldReplicateNewRelation(index_oid, new_rel_list, /* is_table_rewrite= */ false);
+}
+
 void
 CheckAlterColumnTypeDDL(Oid rel_oid, CollectedCommand *cmd, List **new_rel_list,
 						bool is_table_rewrite, bool is_temporary_object)
@@ -301,24 +380,7 @@ CheckAlterColumnTypeDDL(Oid rel_oid, CollectedCommand *cmd, List **new_rel_list,
 				case AT_AddIndex:
 				case AT_ReAddIndex:
 					{
-						/* Need to fetch the index oid from the index name. */
-						IndexStmt  *index = (IndexStmt *) subcmd->def;
-
-						/*
-						 * Skip processing the index if null (eg adding
-						 * primary key).
-						 */
-						if (index->indexOid == InvalidOid)
-							break;
-
-						Relation	rel = RelationIdGetRelation(rel_oid);
-						Oid			index_oid = get_relname_relid(index->idxname,
-																  RelationGetNamespace(rel));
-
-						RelationClose(rel);
-
-						/* Once we have the oid, we can capture its info. */
-						ShouldReplicateNewRelation(index_oid, new_rel_list);
+						HandleAlterColumnAddIndex(subcmd, rel_oid, new_rel_list);
 						break;
 					}
 				default:
@@ -343,13 +405,8 @@ ProcessRewrittenIndexes(Oid rel_oid, const char *schema_name, List **new_rel_lis
 	StringInfoData query_buf;
 
 	initStringInfo(&query_buf);
-	/*
-	 * Also get colocation_id from yb_table_properties here.
-	 * Ideally we could use GetColocationIdFromRelation, but that returns stale
-	 * colocation_id for these rewritten indexes..
-	 */
 	appendStringInfo(&query_buf,
-					 "SELECT c.oid, (yb_table_properties(c.oid)).colocation_id FROM pg_class c "
+					 "SELECT c.oid FROM pg_class c "
 					 "JOIN pg_indexes i ON c.relname = i.indexname "
 					 "WHERE i.tablename = '%s' AND i.schemaname = '%s';",
 					 rewritten_table_name, schema_name);
@@ -371,17 +428,8 @@ ProcessRewrittenIndexes(Oid rel_oid, const char *schema_name, List **new_rel_lis
 	{
 		HeapTuple	spi_tuple = SPI_tuptable->vals[i];
 		Oid			rewritten_index_oid = SPI_GetOid(spi_tuple, 1);
-		Oid			colocation_id = SPI_GetOidIfExists(spi_tuple, 2);
-		Relation	rewritten_index = RelationIdGetRelation(rewritten_index_oid);
 
-		YbNewRelMapEntry *rewritten_index_entry = palloc(sizeof(struct YbNewRelMapEntry));
-
-		rewritten_index_entry->name = pstrdup(RelationGetRelationName(rewritten_index));
-		rewritten_index_entry->relfile_oid = YbGetRelfileNodeId(rewritten_index);
-		rewritten_index_entry->colocation_id = colocation_id;
-		rewritten_index_entry->is_index = true;
-		*new_rel_list = lappend(*new_rel_list, rewritten_index_entry);
-		RelationClose(rewritten_index);
+		ShouldReplicateNewRelation(rewritten_index_oid, new_rel_list, /* is_table_rewrite */ true);
 	}
 
 	SPI_processed = saved_processed;
@@ -679,7 +727,7 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 			command_tag == CMDTAG_CREATE_INDEX)
 		{
 			should_replicate_ddl |=
-				ShouldReplicateNewRelation(obj_id, &new_rel_list);
+				ShouldReplicateNewRelation(obj_id, &new_rel_list, /* is_table_rewrite */ false);
 		}
 		else if (command_tag == CMDTAG_CREATE_TYPE ||
 				 command_tag == CMDTAG_ALTER_TYPE)
@@ -733,7 +781,7 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 			 * of the table is updated to reference this new DocDB table,
 			 */
 			should_replicate_ddl |=
-				ShouldReplicateNewRelation(obj_id, &new_rel_list);
+				ShouldReplicateNewRelation(obj_id, &new_rel_list, /* is_table_rewrite */ true);
 
 			/*
 			 * Add all indexes that are associated with this table, as table
@@ -793,6 +841,13 @@ ProcessSourceEventTriggerTableRewrite()
 	HeapTuple	spi_tuple = SPI_tuptable->vals[0];
 	Oid			rewritten_table_oid = SPI_GetOid(spi_tuple, TABLE_REWRITE_OBJID_COLUMN_ID);
 
+	/* This event trigger doesn't trigger on parent tables, so need to check. */
+	Oid			parent_table_oid = InvalidOid;
+
+	if (has_superclass(rewritten_table_oid))
+		parent_table_oid = get_partition_parent(rewritten_table_oid,
+												 /* even_if_detached= */ true);
+
 	/*
 	 * Add the rewritten table to the list of rewritten tables, so that ddl end
 	 * event triggers can process the rewritten table.
@@ -800,6 +855,8 @@ ProcessSourceEventTriggerTableRewrite()
 	MemoryContext oldcontext = MemoryContextSwitchTo(TopMemoryContext);
 
 	rewritten_table_oid_list = lappend_oid(rewritten_table_oid_list, rewritten_table_oid);
+	if (parent_table_oid != InvalidOid)
+		rewritten_table_oid_list = lappend_oid(rewritten_table_oid_list, parent_table_oid);
 	MemoryContextSwitchTo(oldcontext);
 }
 
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/create_drop_table.sql b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/create_drop_table.sql
index 0a44effe7d..272a7b17ce 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/create_drop_table.sql
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/create_drop_table.sql
@@ -9,6 +9,7 @@ SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
 
 -- Verify that regular tables are captured.
 CREATE TABLE foo(i int PRIMARY KEY);
+INSERT INTO foo(i) VALUES (1), (2), (3);
 
 -- Check with manual replication flags enabled, ddl string is captured with flag.
 SET yb_xcluster_ddl_replication.enable_manual_ddl_replication = 1;
@@ -27,6 +28,15 @@ SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end
 -- Test tables partitioned by their primary key or a column.
 CREATE TABLE foo_partitioned_by_pkey(id int, PRIMARY KEY (id)) PARTITION BY RANGE (id);
 CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id);
+CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10);
+CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20);
+INSERT INTO foo_partitioned_by_col(id) VALUES (1), (2), (3), (10), (11), (12);
+
+-- Test for relations that trigger nonconcurrent backfills.
+CREATE INDEX NONCONCURRENTLY nonconcurrent_foo on foo(i);
+CREATE INDEX NONCONCURRENTLY on foo(i);  -- test without a name
+ALTER TABLE foo ADD CONSTRAINT constraint_foo UNIQUE (i);
+CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id);
 
 -- Now test dropping these tables.
 DROP TABLE foo;
diff --git a/src/yb/integration-tests/xcluster/sql/nonconcurrent_backfills1.sql b/src/yb/integration-tests/xcluster/sql/nonconcurrent_backfills1.sql
new file mode 100644
index 0000000000..56d1df9e18
--- /dev/null
+++ b/src/yb/integration-tests/xcluster/sql/nonconcurrent_backfills1.sql
@@ -0,0 +1,34 @@
+--
+-- NONCONCURRENT BACKFILL TESTS
+--
+
+-- Testing DDLs that perform nonconcurrent backfills. These need special handling
+-- to ensure that we do not rerun the backfill step on the target.
+
+-- Nonconcurrent indexes.
+CREATE TABLE foo(i int PRIMARY KEY, j int);
+INSERT INTO foo VALUES (1, 1), (2, 2), (3, 3);
+
+CREATE INDEX NONCONCURRENTLY ON foo (j);
+CREATE INDEX NONCONCURRENTLY nonconcurrent_foo ON foo (j);
+
+-- Add unique constraint.
+ALTER TABLE foo ADD CONSTRAINT unique_foo UNIQUE (j);
+
+-- Partitioned indexes.
+CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id);
+CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10);
+CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20);
+INSERT INTO foo_partitioned_by_col(id) VALUES (1), (2), (3);
+
+CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id);
+
+-- Also add a unique constraint on a partitioned table.
+ALTER TABLE foo_partitioned_by_col ADD CONSTRAINT unique_foo_partitioned UNIQUE (id);
+
+-- Perform a table rewrite, then ensure that another nonconcurrent backfill still works.
+ALTER TABLE foo_partitioned_by_col ADD COLUMN created_at
+        TIMESTAMP DEFAULT clock_timestamp() NOT NULL;
+
+INSERT INTO foo_partitioned_by_col (id) VALUES (4);
+CREATE INDEX ON foo_partitioned_by_col (created_at);
diff --git a/src/yb/integration-tests/xcluster/sql/nonconcurrent_backfills2.sql b/src/yb/integration-tests/xcluster/sql/nonconcurrent_backfills2.sql
new file mode 100644
index 0000000000..58029e7139
--- /dev/null
+++ b/src/yb/integration-tests/xcluster/sql/nonconcurrent_backfills2.sql
@@ -0,0 +1,6 @@
+--
+-- NONCONCURRENT BACKFILL TESTS
+--
+
+DROP TABLE foo CASCADE;
+DROP TABLE foo_partitioned_by_col CASCADE;
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
index dd7d06aa1e..e733397fb8 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
@@ -360,4 +360,8 @@ TEST_F(XClusterPgRegressDDLReplicationTest, PgRegressCreateDropSequence) {
   ASSERT_OK(TestPgRegress("create_sequence.sql", "drop_sequence.sql"));
 }
 
+TEST_P(XClusterPgRegressDDLReplicationParamTest, PgRegressNonconcurrentBackfills) {
+  ASSERT_OK(TestPgRegress("nonconcurrent_backfills1.sql", "nonconcurrent_backfills2.sql"));
+}
+
 }  // namespace yb
