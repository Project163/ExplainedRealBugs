diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_colocated_table.out b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_colocated_table.out
index 591fb553d0..cfb277b2d9 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_colocated_table.out
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_colocated_table.out
@@ -11,25 +11,25 @@ CREATE TEMP TABLE temp_foo(i int PRIMARY KEY);
 -- Verify that colocated tables are allowed.
 CREATE TABLE coloc_foo(i int PRIMARY KEY);
 SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
-                                                                                                                yb_data                                                                                                                 
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- {"user": "yugabyte", "query": "CREATE TABLE coloc_foo(i int PRIMARY KEY);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "coloc_foo", "relfile_oid": "***", "colocation_id": "***"}]}
+                                                                                                                yb_data                                                                                                                
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE TABLE coloc_foo(i int PRIMARY KEY)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "coloc_foo", "relfile_oid": "***", "colocation_id": "***"}]}
 (1 row)
 
 -- Verify that non-colocated table is captured.
 CREATE TABLE non_coloc_foo(i int PRIMARY KEY) WITH (COLOCATION = false);
 SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
-                                                                                                                     yb_data                                                                                                                      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- {"user": "yugabyte", "query": "CREATE TABLE coloc_foo(i int PRIMARY KEY);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "coloc_foo", "relfile_oid": "***", "colocation_id": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE non_coloc_foo(i int PRIMARY KEY) WITH (COLOCATION = false);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "non_coloc_foo", "relfile_oid": "***"}]}
+                                                                                                                     yb_data                                                                                                                     
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE TABLE coloc_foo(i int PRIMARY KEY)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "coloc_foo", "relfile_oid": "***", "colocation_id": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE non_coloc_foo(i int PRIMARY KEY) WITH (COLOCATION = false)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "non_coloc_foo", "relfile_oid": "***"}]}
 (2 rows)
 
 SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end_time;
-                                        yb_data                                        
----------------------------------------------------------------------------------------
- {"query": "CREATE TABLE coloc_foo(i int PRIMARY KEY);"}
- {"query": "CREATE TABLE non_coloc_foo(i int PRIMARY KEY) WITH (COLOCATION = false);"}
+                                       yb_data                                        
+--------------------------------------------------------------------------------------
+ {"query": "CREATE TABLE coloc_foo(i int PRIMARY KEY)"}
+ {"query": "CREATE TABLE non_coloc_foo(i int PRIMARY KEY) WITH (COLOCATION = false)"}
 (2 rows)
 
 select * from TEST_verify_replicated_ddls();
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_index.out b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_index.out
index b800d69410..24b2d5c7f6 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_index.out
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_index.out
@@ -13,9 +13,9 @@ CREATE INDEX foo_idx_temp on temp_foo(a);
 DROP INDEX foo_idx_temp;
 DROP TABLE temp_foo;
 SELECT yb_data FROM public.TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
-                                                            yb_data                                                             
---------------------------------------------------------------------------------------------------------------------------------
- {"user": "yugabyte", "query": "CREATE SCHEMA create_index;", "schema": "public", "version": 1, "command_tag": "CREATE SCHEMA"}
+                                                            yb_data                                                            
+-------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE SCHEMA create_index", "schema": "public", "version": 1, "command_tag": "CREATE SCHEMA"}
 (1 row)
 
 -- Create base table.
@@ -30,25 +30,25 @@ SET ROLE new_role;
 CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS;
 SET ROLE NONE;
 SELECT yb_data FROM public.TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
-                                                                                                                                      yb_data                                                                                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- {"user": "yugabyte", "query": "CREATE SCHEMA create_index;", "schema": "public", "version": 1, "command_tag": "CREATE SCHEMA"}
- {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY, a int, b text, c int);", "schema": "create_index", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE INDEX foo_idx_simple ON foo(a);", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_simple", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE UNIQUE INDEX foo_idx_unique ON foo(b);", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_unique", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE INDEX foo_idx_filtered ON foo(c ASC, a) WHERE a > c;", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_filtered", "relfile_oid": "***"}]}
- {"user": "new_role", "query": "CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS;", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_include", "relfile_oid": "***"}]}
+                                                                                                                                     yb_data                                                                                                                                      
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE SCHEMA create_index", "schema": "public", "version": 1, "command_tag": "CREATE SCHEMA"}
+ {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY, a int, b text, c int)", "schema": "create_index", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE INDEX foo_idx_simple ON foo(a)", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_simple", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE UNIQUE INDEX foo_idx_unique ON foo(b)", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_unique", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE INDEX foo_idx_filtered ON foo(c ASC, a) WHERE a > c", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_filtered", "relfile_oid": "***"}]}
+ {"user": "new_role", "query": "CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_include", "relfile_oid": "***"}]}
 (6 rows)
 
 SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end_time;
-                                           yb_data                                            
-----------------------------------------------------------------------------------------------
- {"query": "CREATE SCHEMA create_index;"}
- {"query": "CREATE TABLE foo(i int PRIMARY KEY, a int, b text, c int);"}
- {"query": "CREATE INDEX foo_idx_simple ON foo(a);"}
- {"query": "CREATE UNIQUE INDEX foo_idx_unique ON foo(b);"}
- {"query": "CREATE INDEX foo_idx_filtered ON foo(c ASC, a) WHERE a > c;"}
- {"query": "CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS;"}
+                                           yb_data                                           
+---------------------------------------------------------------------------------------------
+ {"query": "CREATE SCHEMA create_index"}
+ {"query": "CREATE TABLE foo(i int PRIMARY KEY, a int, b text, c int)"}
+ {"query": "CREATE INDEX foo_idx_simple ON foo(a)"}
+ {"query": "CREATE UNIQUE INDEX foo_idx_unique ON foo(b)"}
+ {"query": "CREATE INDEX foo_idx_filtered ON foo(c ASC, a) WHERE a > c"}
+ {"query": "CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS"}
 (6 rows)
 
 -- Now drop these indexes.
@@ -58,31 +58,31 @@ DROP INDEX foo_idx_filtered;
 -- Drop base table and cascade deletion of other indexes.
 DROP TABLE foo;
 SELECT yb_data FROM public.TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
-                                                                                                                                      yb_data                                                                                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- {"user": "yugabyte", "query": "CREATE SCHEMA create_index;", "schema": "public", "version": 1, "command_tag": "CREATE SCHEMA"}
- {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY, a int, b text, c int);", "schema": "create_index", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE INDEX foo_idx_simple ON foo(a);", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_simple", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE UNIQUE INDEX foo_idx_unique ON foo(b);", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_unique", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE INDEX foo_idx_filtered ON foo(c ASC, a) WHERE a > c;", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_filtered", "relfile_oid": "***"}]}
- {"user": "new_role", "query": "CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS;", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_include", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "DROP INDEX foo_idx_unique;", "schema": "create_index", "version": 1, "command_tag": "DROP INDEX"}
- {"user": "yugabyte", "query": "DROP INDEX foo_idx_filtered;", "schema": "create_index", "version": 1, "command_tag": "DROP INDEX"}
- {"user": "yugabyte", "query": "DROP TABLE foo;", "schema": "create_index", "version": 1, "command_tag": "DROP TABLE"}
+                                                                                                                                     yb_data                                                                                                                                      
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE SCHEMA create_index", "schema": "public", "version": 1, "command_tag": "CREATE SCHEMA"}
+ {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY, a int, b text, c int)", "schema": "create_index", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE INDEX foo_idx_simple ON foo(a)", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_simple", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE UNIQUE INDEX foo_idx_unique ON foo(b)", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_unique", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE INDEX foo_idx_filtered ON foo(c ASC, a) WHERE a > c", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_filtered", "relfile_oid": "***"}]}
+ {"user": "new_role", "query": "CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS", "schema": "create_index", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_idx_include", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "DROP INDEX foo_idx_unique", "schema": "create_index", "version": 1, "command_tag": "DROP INDEX"}
+ {"user": "yugabyte", "query": "DROP INDEX foo_idx_filtered", "schema": "create_index", "version": 1, "command_tag": "DROP INDEX"}
+ {"user": "yugabyte", "query": "DROP TABLE foo", "schema": "create_index", "version": 1, "command_tag": "DROP TABLE"}
 (9 rows)
 
 SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end_time;
-                                           yb_data                                            
-----------------------------------------------------------------------------------------------
- {"query": "CREATE SCHEMA create_index;"}
- {"query": "CREATE TABLE foo(i int PRIMARY KEY, a int, b text, c int);"}
- {"query": "CREATE INDEX foo_idx_simple ON foo(a);"}
- {"query": "CREATE UNIQUE INDEX foo_idx_unique ON foo(b);"}
- {"query": "CREATE INDEX foo_idx_filtered ON foo(c ASC, a) WHERE a > c;"}
- {"query": "CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS;"}
- {"query": "DROP INDEX foo_idx_unique;"}
- {"query": "DROP INDEX foo_idx_filtered;"}
- {"query": "DROP TABLE foo;"}
+                                           yb_data                                           
+---------------------------------------------------------------------------------------------
+ {"query": "CREATE SCHEMA create_index"}
+ {"query": "CREATE TABLE foo(i int PRIMARY KEY, a int, b text, c int)"}
+ {"query": "CREATE INDEX foo_idx_simple ON foo(a)"}
+ {"query": "CREATE UNIQUE INDEX foo_idx_unique ON foo(b)"}
+ {"query": "CREATE INDEX foo_idx_filtered ON foo(c ASC, a) WHERE a > c"}
+ {"query": "CREATE INDEX foo_idx_include ON foo(lower(b)) INCLUDE (a) SPLIT INTO 2 TABLETS"}
+ {"query": "DROP INDEX foo_idx_unique"}
+ {"query": "DROP INDEX foo_idx_filtered"}
+ {"query": "DROP TABLE foo"}
 (9 rows)
 
 select * from public.TEST_verify_replicated_ddls();
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
index 88dd43be35..9d52309228 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
@@ -25,21 +25,21 @@ CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1
 -- Verify that info for unique constraint indexes are also captured.
 CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE);
 SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
-                                                                                                                                                  yb_data                                                                                                                                                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE manual_foo(i int PRIMARY KEY);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "manual_replication": true}
- {"user": "yugabyte", "query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS;", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "extra_foo", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "unique_foo", "relfile_oid": "***"}, {"is_index": true, "rel_name": "unique_foo_u_key", "relfile_oid": "***"}]}
+                                                                                                                                                 yb_data                                                                                                                                                  
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE manual_foo(i int PRIMARY KEY)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "manual_replication": true}
+ {"user": "yugabyte", "query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "extra_foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "unique_foo", "relfile_oid": "***"}, {"is_index": true, "rel_name": "unique_foo_u_key", "relfile_oid": "***"}]}
 (4 rows)
 
 SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end_time;
-                                                yb_data                                                 
---------------------------------------------------------------------------------------------------------
- {"query": "CREATE TABLE foo(i int PRIMARY KEY);"}
- {"query": "CREATE TABLE manual_foo(i int PRIMARY KEY);"}
- {"query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS;"}
- {"query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE);"}
+                                                yb_data                                                
+-------------------------------------------------------------------------------------------------------
+ {"query": "CREATE TABLE foo(i int PRIMARY KEY)"}
+ {"query": "CREATE TABLE manual_foo(i int PRIMARY KEY)"}
+ {"query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS"}
+ {"query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE)"}
 (4 rows)
 
 -- Test tables partitioned by their primary key or a column.
@@ -64,49 +64,49 @@ DROP TABLE unique_foo;
 DROP TABLE foo_partitioned_by_pkey;
 DROP TABLE foo_partitioned_by_col;
 SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
-                                                                                                                                                                                                         yb_data                                                                                                                                                                                                          
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
- {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE manual_foo(i int PRIMARY KEY);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "manual_replication": true}
- {"user": "yugabyte", "query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS;", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "extra_foo", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "unique_foo", "relfile_oid": "***"}, {"is_index": true, "rel_name": "unique_foo_u_key", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE foo_partitioned_by_pkey(id int, PRIMARY KEY (id)) PARTITION BY RANGE (id);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo_partitioned_by_pkey", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo_partitioned_by_col", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "partition1", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20);", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "partition2", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE INDEX NONCONCURRENTLY nonconcurrent_foo on foo(i);", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "nonconcurrent_foo", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE INDEX NONCONCURRENTLY on foo(i);", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_i_idx", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "ALTER TABLE foo ADD CONSTRAINT constraint_foo UNIQUE (i);", "schema": "public", "version": 1, "command_tag": "ALTER TABLE", "new_rel_map": [{"is_index": true, "rel_name": "constraint_foo", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id);", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "partitioned_index", "relfile_oid": "***"}, {"is_index": true, "rel_name": "partition1_id_idx", "relfile_oid": "***"}, {"is_index": true, "rel_name": "partition2_id_idx", "relfile_oid": "***"}]}
- {"user": "yugabyte", "query": "DROP TABLE foo;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
- {"user": "yugabyte", "query": "DROP TABLE manual_foo;", "schema": "public", "version": 1, "command_tag": "DROP TABLE", "manual_replication": true}
- {"user": "yugabyte", "query": "DROP TABLE extra_foo;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
- {"user": "yugabyte", "query": "DROP TABLE unique_foo;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
- {"user": "yugabyte", "query": "DROP TABLE foo_partitioned_by_pkey;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
- {"user": "yugabyte", "query": "DROP TABLE foo_partitioned_by_col;", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
+                                                                                                                                                                                                         yb_data                                                                                                                                                                                                         
+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE manual_foo(i int PRIMARY KEY)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "manual_replication": true}
+ {"user": "yugabyte", "query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "extra_foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "unique_foo", "relfile_oid": "***"}, {"is_index": true, "rel_name": "unique_foo_u_key", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE foo_partitioned_by_pkey(id int, PRIMARY KEY (id)) PARTITION BY RANGE (id)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo_partitioned_by_pkey", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo_partitioned_by_col", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "partition1", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "partition2", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE INDEX NONCONCURRENTLY nonconcurrent_foo on foo(i)", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "nonconcurrent_foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE INDEX NONCONCURRENTLY on foo(i)", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "foo_i_idx", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "ALTER TABLE foo ADD CONSTRAINT constraint_foo UNIQUE (i)", "schema": "public", "version": 1, "command_tag": "ALTER TABLE", "new_rel_map": [{"is_index": true, "rel_name": "constraint_foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id)", "schema": "public", "version": 1, "command_tag": "CREATE INDEX", "new_rel_map": [{"is_index": true, "rel_name": "partitioned_index", "relfile_oid": "***"}, {"is_index": true, "rel_name": "partition1_id_idx", "relfile_oid": "***"}, {"is_index": true, "rel_name": "partition2_id_idx", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "DROP TABLE foo", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
+ {"user": "yugabyte", "query": "DROP TABLE manual_foo", "schema": "public", "version": 1, "command_tag": "DROP TABLE", "manual_replication": true}
+ {"user": "yugabyte", "query": "DROP TABLE extra_foo", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
+ {"user": "yugabyte", "query": "DROP TABLE unique_foo", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
+ {"user": "yugabyte", "query": "DROP TABLE foo_partitioned_by_pkey", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
+ {"user": "yugabyte", "query": "DROP TABLE foo_partitioned_by_col", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
 (18 rows)
 
 SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end_time;
-                                                yb_data                                                 
---------------------------------------------------------------------------------------------------------
- {"query": "CREATE TABLE foo(i int PRIMARY KEY);"}
- {"query": "CREATE TABLE manual_foo(i int PRIMARY KEY);"}
- {"query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS;"}
- {"query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE);"}
- {"query": "CREATE TABLE foo_partitioned_by_pkey(id int, PRIMARY KEY (id)) PARTITION BY RANGE (id);"}
- {"query": "CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id);"}
- {"query": "CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10);"}
- {"query": "CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20);"}
- {"query": "CREATE INDEX NONCONCURRENTLY nonconcurrent_foo on foo(i);"}
- {"query": "CREATE INDEX NONCONCURRENTLY on foo(i);"}
- {"query": "ALTER TABLE foo ADD CONSTRAINT constraint_foo UNIQUE (i);"}
- {"query": "CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id);"}
- {"query": "DROP TABLE foo;"}
- {"query": "DROP TABLE manual_foo;"}
- {"query": "DROP TABLE extra_foo;"}
- {"query": "DROP TABLE unique_foo;"}
- {"query": "DROP TABLE foo_partitioned_by_pkey;"}
- {"query": "DROP TABLE foo_partitioned_by_col;"}
+                                                yb_data                                                
+-------------------------------------------------------------------------------------------------------
+ {"query": "CREATE TABLE foo(i int PRIMARY KEY)"}
+ {"query": "CREATE TABLE manual_foo(i int PRIMARY KEY)"}
+ {"query": "CREATE TABLE extra_foo(i int PRIMARY KEY) WITH (COLOCATION = false) SPLIT INTO 1 TABLETS"}
+ {"query": "CREATE TABLE unique_foo(i int PRIMARY KEY, u text UNIQUE)"}
+ {"query": "CREATE TABLE foo_partitioned_by_pkey(id int, PRIMARY KEY (id)) PARTITION BY RANGE (id)"}
+ {"query": "CREATE TABLE foo_partitioned_by_col(id int) PARTITION BY RANGE (id)"}
+ {"query": "CREATE TABLE partition1 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (1) TO (10)"}
+ {"query": "CREATE TABLE partition2 PARTITION OF foo_partitioned_by_col FOR VALUES FROM (10) TO (20)"}
+ {"query": "CREATE INDEX NONCONCURRENTLY nonconcurrent_foo on foo(i)"}
+ {"query": "CREATE INDEX NONCONCURRENTLY on foo(i)"}
+ {"query": "ALTER TABLE foo ADD CONSTRAINT constraint_foo UNIQUE (i)"}
+ {"query": "CREATE UNIQUE INDEX partitioned_index ON foo_partitioned_by_col(id)"}
+ {"query": "DROP TABLE foo"}
+ {"query": "DROP TABLE manual_foo"}
+ {"query": "DROP TABLE extra_foo"}
+ {"query": "DROP TABLE unique_foo"}
+ {"query": "DROP TABLE foo_partitioned_by_pkey"}
+ {"query": "DROP TABLE foo_partitioned_by_col"}
 (18 rows)
 
 -- Test mix of temp and regular tables.
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
index 95496060eb..48e08b8a2f 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
@@ -272,3 +272,16 @@ IsMatViewCommand(CommandTag command_tag)
 		command_tag == CMDTAG_REFRESH_MATERIALIZED_VIEW ||
 		command_tag == CMDTAG_DROP_MATERIALIZED_VIEW;
 }
+
+bool
+IsExtensionDdl(CommandTag command_tag)
+{
+	if (command_tag == CMDTAG_CREATE_EXTENSION ||
+		command_tag == CMDTAG_DROP_EXTENSION ||
+		command_tag == CMDTAG_ALTER_EXTENSION)
+	{
+		return true;
+	}
+
+	return false;
+}
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
index 4f99724f04..ba754c9ba8 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
@@ -94,4 +94,6 @@ extern char *get_typname(Oid pg_type_oid);
 
 extern bool IsMatViewCommand(CommandTag command_tag);
 
+extern bool IsExtensionDdl(CommandTag command_tag);
+
 #endif
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/json_util.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/json_util.c
index f4ee050eba..3112a51f8d 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/json_util.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/json_util.c
@@ -59,14 +59,20 @@ AddBoolJsonEntry(JsonbParseState *state, char *key_buf, bool val)
 
 void
 AddStringJsonEntry(JsonbParseState *state, char *key_buf, const char *val)
+{
+	AddNStringJsonEntry(state, key_buf, val, strlen(val));
+}
+
+void
+AddNStringJsonEntry(JsonbParseState *state, char *key_buf, const char *val, Size len)
 {
 	AddJsonKey(state, key_buf);
 
 	JsonbValue	value;
 
 	value.type = jbvString;
-	value.val.string.len = strlen(val);
-	value.val.string.val = pstrdup(val);
+	value.val.string.len = len;
+	value.val.string.val = pnstrdup(val, len);
 
 	(void) pushJsonbValue(&state, WJB_VALUE, &value);
 }
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/json_util.h b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/json_util.h
index 182d0f6b8e..526736ca24 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/json_util.h
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/json_util.h
@@ -23,9 +23,10 @@
 
 #include "utils/jsonb.h"
 
-void		AddJsonKey(JsonbParseState *state, char *key_buf);
-void		AddNumericJsonEntry(JsonbParseState *state, char *key_buf, int64 val);
-void		AddStringJsonEntry(JsonbParseState *state, char *key_buf, const char *val);
-void		AddBoolJsonEntry(JsonbParseState *state, char *key_buf, bool val);
+extern void AddJsonKey(JsonbParseState *state, char *key_buf);
+extern void AddNumericJsonEntry(JsonbParseState *state, char *key_buf, int64 val);
+extern void AddStringJsonEntry(JsonbParseState *state, char *key_buf, const char *val);
+extern void AddNStringJsonEntry(JsonbParseState *state, char *key_buf, const char *val, Size len);
+extern void AddBoolJsonEntry(JsonbParseState *state, char *key_buf, bool val);
 
 #endif
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_xcluster_ddl_replication.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_xcluster_ddl_replication.c
index 3e6076f844..a6590f43cc 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_xcluster_ddl_replication.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_xcluster_ddl_replication.c
@@ -20,13 +20,14 @@
 
 #include "catalog/pg_type_d.h"
 #include "commands/event_trigger.h"
+#include "commands/extension.h"
 #include "executor/spi.h"
 #include "extension_util.h"
 #include "json_util.h"
-#include "nodes/pg_list.h"
 #include "source_ddl_end_handler.h"
 #include "utils/builtins.h"
 #include "utils/fmgrprotos.h"
+#include "utils/queryjumble.h"
 
 PG_MODULE_MAGIC;
 
@@ -36,8 +37,8 @@ PG_MODULE_MAGIC;
  */
 
 static bool enable_manual_ddl_replication = false;
-char	   *ddl_queue_primary_key_ddl_end_time = NULL;
-char	   *ddl_queue_primary_key_queue_id = NULL;
+char		*ddl_queue_primary_key_ddl_end_time = NULL;
+char 		*ddl_queue_primary_key_queue_id = NULL;
 
 static const struct config_enum_entry replication_role_overrides[] = {
 	{"", XCLUSTER_ROLE_UNSPECIFIED, /* hidden */ false},
@@ -58,21 +59,25 @@ static const struct config_enum_entry replication_role_overrides[] = {
 static int	replication_role = XCLUSTER_ROLE_UNAVAILABLE;
 static int	replication_role_override = XCLUSTER_ROLE_UNSPECIFIED;
 
-/* Current nesting depth of ExecutorRun+ProcessUtility calls */
-static int	exec_nested_level = 0;
-
-static bool captured_by_extension = false;
-
-/* Check if the top level statement is a extension DDL. */
-static bool is_extension_ddl = false;
+/*
+ * Information about the current DDL.
+ * The query string, location and length represent the substring of the query
+ * that is currently being processed. This enables to capture only the DDL part
+ * of a multi-statement query, or a FUNCTION with multiple statements.
+ */
+const char *query_string = NULL;
+int query_location = 0;
+int query_len = 0;
+Node *parsetree = NULL;
 
-/* Check if this is a DDL related to our own extension. */
-static bool is_self_extension_ddl = false;
+/* Information about an extension that is being created. */
+bool is_in_extension_ddl = false;
+bool is_self_extension_ddl = false;
+char *current_extension_name = NULL;
 
 /*
  * Util functions.
  */
-static void EvaluateTopDdlCommand(CommandTag command_tag);
 static void RecordTempRelationDDL();
 static void XClusterProcessUtility(PlannedStmt *pstmt,
 								   const char *queryString,
@@ -200,10 +205,18 @@ FetchReplicationRole()
 }
 
 bool
-IsDisabled()
+IsDisabled(CommandTag command_tag)
 {
-	return !captured_by_extension || (replication_role != XCLUSTER_ROLE_AUTOMATIC_SOURCE &&
-									  replication_role != XCLUSTER_ROLE_AUTOMATIC_TARGET);
+	/*
+	 * Disabled if we are not in xCluster automatic mode.
+	 * Disabled for our own extension.
+	 * Disabled if we are in an extension DDL and not handling the top level
+	 * query.
+	 */
+	return (replication_role != XCLUSTER_ROLE_AUTOMATIC_SOURCE &&
+			replication_role != XCLUSTER_ROLE_AUTOMATIC_TARGET) ||
+		   is_self_extension_ddl ||
+		   (is_in_extension_ddl && !IsExtensionDdl(command_tag));
 }
 
 bool
@@ -295,7 +308,7 @@ InsertIntoReplicatedDDLs(int64 ddl_end_time, int64 query_id)
 	JsonbParseState *state = NULL;
 
 	(void) pushJsonbValue(&state, WJB_BEGIN_OBJECT, NULL);
-	(void) AddStringJsonEntry(state, "query", debug_query_string);
+	(void) AddNStringJsonEntry(state, "query", query_string, query_len);
 	JsonbValue *jsonb_val = pushJsonbValue(&state, WJB_END_OBJECT, NULL);
 	Jsonb	   *jsonb = JsonbValueToJsonb(jsonb_val);
 
@@ -304,99 +317,6 @@ InsertIntoReplicatedDDLs(int64 ddl_end_time, int64 query_id)
 	CLOSE_MEM_CONTEXT_AND_SPI;
 }
 
-bool
-IsExtensionDdl(CommandTag command_tag)
-{
-	if (command_tag == CMDTAG_CREATE_EXTENSION ||
-		command_tag == CMDTAG_DROP_EXTENSION ||
-		command_tag == CMDTAG_ALTER_EXTENSION)
-	{
-		return true;
-	}
-
-	return false;
-}
-
-/*
- * Extensions DDLs result in multiple DDL statements being executed during
- * create/alter/drop of extensions. This function checks whether the current
- * DDL is being executed as part of an Extension DDL such as CREATE/ALTER/DROP
- * extension.
- */
-bool
-IsCurrentDdlPartOfExtensionDdlBatch()
-{
-	return is_extension_ddl && exec_nested_level > 1;
-}
-
-/*
- * Reports an error if the query string has multiple commands in it, or a
- * command tag that doesn't match up with the one captured from the event
- * trigger.
- *
- * Some clients can send multiple commands together as one single query string.
- * This can cause issues for this extension:
- * - If the query has a mix of DDL and DML commands, then we'd end up
- *   replicating those rows twice.
- * - Even if the query has multiple DDLs in it, it is simpler to handle these
- *   individually. Eg. we may need to add additional modifications for each
- *   individual DDL (eg setting oids).
- */
-void
-DisallowMultiStatementQueries(CommandTag command_tag)
-{
-	List	   *parse_tree = pg_parse_query(debug_query_string);
-	ListCell   *lc;
-	int			count = 0;
-
-	foreach(lc, parse_tree)
-	{
-		++count;
-		RawStmt    *stmt = (RawStmt *) lfirst(lc);
-		CommandTag	stmt_command_tag = CreateCommandTag(stmt->stmt);
-
-		/*
-		 * Exception for SELECT ... INTO: The parser tags this as a SELECT,
-		 * so we must check the parsed statement for an IntoClause.
-		 */
-		if (command_tag == CMDTAG_SELECT_INTO &&
-			stmt_command_tag == CMDTAG_SELECT &&
-			((SelectStmt *) stmt->stmt)->intoClause != NULL)
-		{
-			stmt_command_tag = CMDTAG_SELECT_INTO;
-		}
-
-		/*
-		 * Only Extension DDLs are allowed to be part of multi-statement as
-		 * they typically executes multiple DDLs under the covers.
-		 */
-		if (!IsExtensionDdl(stmt_command_tag))
-		{
-			if (count > 1 || command_tag != stmt_command_tag)
-				elog(ERROR,
-					 "Database is replicating DDLs for xCluster. In this mode only "
-					 "a single DDL command is allowed in the query string.\n"
-					 "Please run the commands one at a time.\n"
-					 "Full query string: %s. \n"
-					 "Statement 1: %s\n"
-					 "Statement 2: %s",
-					 debug_query_string,
-					 GetCommandTagName(command_tag),
-					 GetCommandTagName(stmt_command_tag));
-		}
-		else if (!IsPassThroughDdlCommandSupported(command_tag))
-		{
-			elog(ERROR,
-				 "Database is replicating DDLs for xCluster. Extension cannot be supported "
-				 "because it contains DDLs that are not yet supported by replication. \n"
-				 "Full query string: %s. \n"
-				 "Unsupported DDL within extension : %s\n",
-				 debug_query_string,
-				 GetCommandTagName(command_tag));
-		}
-	}
-}
-
 void
 HandleSourceDDLEnd(EventTriggerData *trig_data)
 {
@@ -413,7 +333,7 @@ HandleSourceDDLEnd(EventTriggerData *trig_data)
 
 	(void) pushJsonbValue(&state, WJB_BEGIN_OBJECT, NULL);
 	(void) AddNumericJsonEntry(state, "version", 1);
-	(void) AddStringJsonEntry(state, "query", debug_query_string);
+	(void) AddNStringJsonEntry(state, "query", query_string, query_len);
 	(void) AddStringJsonEntry(state, "command_tag",
 							  GetCommandTagName(trig_data->tag));
 
@@ -545,9 +465,6 @@ HandleSourceTableRewrite(EventTriggerData *trig_data)
 void
 HandleSourceDDLStart(EventTriggerData *trig_data)
 {
-	if (is_self_extension_ddl)
-		return;
-
 	/* By default we don't replicate. */
 	yb_should_replicate_ddl = false;
 	if (enable_manual_ddl_replication)
@@ -560,31 +477,21 @@ HandleSourceDDLStart(EventTriggerData *trig_data)
 		return;
 	}
 
-	/*
-	 * Do some initial checks here before the source query runs.
-	 */
-	DisallowMultiStatementQueries(trig_data->tag);
 	ClearRewrittenTableOidList();
 }
 
 void
 HandleTargetDDLStart(EventTriggerData *trig_data)
 {
-	if (IsCurrentDdlPartOfExtensionDdlBatch())
-		return;
-
 	yb_xcluster_target_ddl_bypass = false;
 
 	/* Bypass DDLs executed in manual mode, or from the target poller. */
-	if (enable_manual_ddl_replication ||
-		yb_xcluster_automatic_mode_target_ddl || is_self_extension_ddl)
+	if (enable_manual_ddl_replication || yb_xcluster_automatic_mode_target_ddl)
 	{
 		yb_xcluster_target_ddl_bypass = true;
 		return;
 	}
 
-	DisallowMultiStatementQueries(trig_data->tag);
-
 	/*
 	 * Allow DDLs related to materialized views.
 	 * Temp relations are bypassed in RecordTempRelationDDL.
@@ -594,6 +501,80 @@ HandleTargetDDLStart(EventTriggerData *trig_data)
 	yb_xcluster_target_ddl_bypass = IsMatViewCommand(trig_data->tag);
 }
 
+static char *
+GetExtensionName(CommandTag tag)
+{
+	/*
+	 * In the case where we are creating our own extension, we only start
+	 * capturing DDLs mid way and miss the top level command tag. So rely instead
+	 * on the creating_extension global variable.
+	 */
+	if (creating_extension)
+		tag = CMDTAG_CREATE_EXTENSION;
+
+	switch (tag)
+	{
+		case CMDTAG_CREATE_EXTENSION:
+				return ((CreateExtensionStmt *) parsetree)->extname;
+		case CMDTAG_ALTER_EXTENSION:
+				return ((AlterExtensionStmt *) parsetree)->extname;
+		case CMDTAG_DROP_EXTENSION:
+			{
+				DropStmt   *stmt = (DropStmt *) parsetree;
+
+				/* Ensure there is at least one object in the list. */
+				if (stmt->objects == NULL || list_length(stmt->objects) != 1)
+				{
+					elog(WARNING, "Unexpected number of objects in DROP EXTENSION statement");
+					return NULL;
+				}
+
+				Node	   *object = linitial(stmt->objects);
+
+				if (!IsA(object, String))
+				{
+					elog(WARNING, "Unexpected object type in DROP EXTENSION statement");
+					return NULL;
+				}
+
+				return strVal(castNode(String, object));
+			}
+		default:
+			return NULL;
+	}
+}
+
+void
+EvaluateExtensionDDL(CommandTag command_tag)
+{
+	if (!is_in_extension_ddl)
+		return;
+
+	if (current_extension_name == NULL)
+	{
+		current_extension_name = GetExtensionName(command_tag);
+
+		if (current_extension_name != NULL &&
+			strcmp(current_extension_name, EXTENSION_NAME) == 0)
+			is_self_extension_ddl = true;
+	}
+
+	if (is_self_extension_ddl)
+		return;
+
+	/* Disallow extensions that contain complex DDLs like CREATE TABLE. */
+	if (!IsPassThroughDdlCommandSupported(command_tag))
+	{
+		elog(ERROR,
+			 "Database is replicating DDLs for xCluster. Extension %s is not "
+			 "supported because it contains unsupported DDLs within the "
+			 "extension script. Create the extension before adding the "
+			 "database to xCluster.\n"
+			 "Unsupported DDL within extension : %s\n",
+			 current_extension_name, GetCommandTagName(command_tag));
+	}
+}
+
 PG_FUNCTION_INFO_V1(handle_ddl_start);
 Datum
 handle_ddl_start(PG_FUNCTION_ARGS)
@@ -601,29 +582,24 @@ handle_ddl_start(PG_FUNCTION_ARGS)
 	if (!CALLED_AS_EVENT_TRIGGER(fcinfo))	/* internal error */
 		elog(ERROR, "not fired by event trigger manager");
 
-	/*
-	 * Only process statements that have been captured by the trigger at the top
-	 * level. This allows us to bypass creation of our own extension which we
-	 * won't capture until the trigger is created, which happens in a nested
-	 * level.
-	 */
-	if (exec_nested_level == 1)
-		captured_by_extension = true;
+	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
 
 	FetchReplicationRole();
-	if (IsDisabled())
-		PG_RETURN_NULL();
+	EvaluateExtensionDDL(trig_data->tag);
 
-	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
+	if (IsDisabled(trig_data->tag))
+		PG_RETURN_NULL();
 
-	if (exec_nested_level == 1)
-		EvaluateTopDdlCommand(trig_data->tag);
+	/*
+	 * Given a possibly multi-statement source string, confine our attention to
+	 * the relevant part of the string.
+	 */
+	query_string = CleanQuerytext(query_string, &query_location, &query_len);
 
 	if (IsReplicationSource())
 	{
 		HandleSourceDDLStart(trig_data);
 	}
-
 	if (IsReplicationTarget())
 	{
 		HandleTargetDDLStart(trig_data);
@@ -639,30 +615,30 @@ handle_ddl_end(PG_FUNCTION_ARGS)
 	if (!CALLED_AS_EVENT_TRIGGER(fcinfo))	/* internal error */
 		elog(ERROR, "not fired by event trigger manager");
 
-	if (IsDisabled())
-		PG_RETURN_NULL();
-
 	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
 
-	if (is_self_extension_ddl)
+	if (IsDisabled(trig_data->tag))
 		PG_RETURN_NULL();
 
+	Assert(query_string != NULL);
+	Assert(query_len > 0);
+
 	/*
 	 * Capture the DDL as long as its not a step within another Extension DDL
 	 * batch.
 	 */
-	if (!IsCurrentDdlPartOfExtensionDdlBatch())
+	if (IsReplicationSource())
+	{
+		HandleSourceDDLEnd(trig_data);
+	}
+	if (IsReplicationTarget())
 	{
-		if (IsReplicationSource())
-		{
-			HandleSourceDDLEnd(trig_data);
-		}
-		if (IsReplicationTarget())
-		{
-			HandleTargetDDLEnd(trig_data);
-		}
+		HandleTargetDDLEnd(trig_data);
 	}
 
+	query_string = NULL;
+	query_len = 0;
+
 	PG_RETURN_NULL();
 }
 
@@ -673,15 +649,12 @@ handle_sql_drop(PG_FUNCTION_ARGS)
 	if (!CALLED_AS_EVENT_TRIGGER(fcinfo))	/* internal error */
 		elog(ERROR, "not fired by event trigger manager");
 
-	if (IsDisabled())
-		PG_RETURN_NULL();
-
 	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
 
-	if (is_self_extension_ddl)
+	if (IsDisabled(trig_data->tag))
 		PG_RETURN_NULL();
 
-	if (IsReplicationSource() && !IsCurrentDdlPartOfExtensionDdlBatch())
+	if (IsReplicationSource())
 	{
 		HandleSourceSQLDrop(trig_data);
 	}
@@ -696,12 +669,9 @@ handle_table_rewrite(PG_FUNCTION_ARGS)
 	if (!CALLED_AS_EVENT_TRIGGER(fcinfo))	/* internal error */
 		elog(ERROR, "not fired by event trigger manager");
 
-	if (IsDisabled())
-		PG_RETURN_NULL();
-
 	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
 
-	if (is_self_extension_ddl)
+	if (IsDisabled(trig_data->tag))
 		PG_RETURN_NULL();
 
 	if (IsReplicationSource())
@@ -712,76 +682,6 @@ handle_table_rewrite(PG_FUNCTION_ARGS)
 	PG_RETURN_NULL();
 }
 
-static char *
-GetExtensionName(CommandTag tag, List *parse_tree)
-{
-	switch (tag)
-	{
-		case CMDTAG_CREATE_EXTENSION:
-			{
-				CreateExtensionStmt *stmt;
-
-				stmt = (CreateExtensionStmt *)
-					linitial_node(RawStmt, parse_tree)->stmt;
-
-				return stmt->extname;
-			}
-		case CMDTAG_ALTER_EXTENSION:
-			{
-				AlterExtensionStmt *stmt;
-
-				stmt = (AlterExtensionStmt *)
-					linitial_node(RawStmt, parse_tree)->stmt;
-
-				return stmt->extname;
-			}
-		case CMDTAG_DROP_EXTENSION:
-			{
-				DropStmt   *stmt;
-
-				stmt = (DropStmt *)
-					linitial_node(RawStmt, parse_tree)->stmt;
-
-				/* Ensure there is at least one object in the list. */
-				if (stmt->objects == NULL || list_length(stmt->objects) != 1)
-				{
-					elog(WARNING, "Unexpected number of objects in DROP EXTENSION statement");
-					return NULL;
-				}
-
-				Node	   *object = linitial(stmt->objects);
-
-				if (!IsA(object, String))
-				{
-					elog(WARNING, "Unexpected object type in DROP EXTENSION statement");
-					return NULL;
-				}
-
-				return strVal(castNode(String, object));
-			}
-		default:
-			return NULL;
-	}
-}
-
-static void
-EvaluateTopDdlCommand(CommandTag command_tag)
-{
-	is_extension_ddl = false;
-	is_self_extension_ddl = false;
-
-	if (IsExtensionDdl(command_tag))
-	{
-		is_extension_ddl = true;
-		List	   *parse_tree = pg_parse_query(debug_query_string);
-		char	   *extname = GetExtensionName(command_tag, parse_tree);
-
-		is_self_extension_ddl = extname != NULL &&
-			strcmp(extname, EXTENSION_NAME) == 0;
-	}
-
-}
-
 static void
 RecordTempRelationDDL()
 {
@@ -796,10 +696,8 @@ RecordTempRelationDDL()
 }
 
 void
-HandleTopUtilityCommandStart()
+HandleQueryStart(PlannedStmt *pstmt, const char *queryString, bool is_top_level_query)
 {
-	captured_by_extension = false;
-
 	/*
 	 * For DDLs that are handled by the handle_ddl_start event trigger,
 	 * HandleTargetDDLStart will set yb_xcluster_target_ddl_bypass to false and
@@ -808,13 +706,43 @@ HandleTopUtilityCommandStart()
 	 * allow it to pass through.
 	 */
 	yb_xcluster_target_ddl_bypass = true;
+
+	/*
+	 * For extension DDLs, only capture the top level query.
+	 */
+	if (!is_in_extension_ddl)
+	{
+		query_location = pstmt->stmt_location;
+		query_len = pstmt->stmt_len;
+		query_string = queryString;
+		parsetree = pstmt->utilityStmt;
+	}
+
+	if (is_top_level_query && IsExtensionDdl(CreateCommandTag(parsetree)))
+	{
+		is_in_extension_ddl = true;
+	}
 }
 
 void
-HandleTopUtilityCommandEnd()
+HandleQueryEnd(bool is_top_level_query)
 {
-	captured_by_extension = false;
-	yb_xcluster_target_ddl_bypass = false;
+	if (is_top_level_query)
+	{
+		is_in_extension_ddl = false;
+		is_self_extension_ddl = false;
+		current_extension_name = NULL;
+	}
+
+	/*
+	 * For extension DDLs, retain the query string and length until the top
+	 * level query ends.
+	 */
+	if (!is_in_extension_ddl)
+	{
+		query_string = NULL;
+		query_len = 0;
+	}
 }
 
 static void
@@ -827,10 +755,11 @@ XClusterProcessUtility(PlannedStmt *pstmt,
 					   DestReceiver *dest,
 					   QueryCompletion *qc)
 {
-	exec_nested_level++;
+	bool is_top_level_query = (context == PROCESS_UTILITY_TOPLEVEL);
+	bool isCompleteQuery = (context != PROCESS_UTILITY_SUBCOMMAND);
 
-	if (exec_nested_level == 1)
-		HandleTopUtilityCommandStart();
+	if (isCompleteQuery)
+		HandleQueryStart(pstmt, queryString, is_top_level_query);
 
 	PG_TRY();
 	{
@@ -843,10 +772,8 @@ XClusterProcessUtility(PlannedStmt *pstmt,
 	}
 	PG_FINALLY();
 	{
-		if (exec_nested_level == 1)
-			HandleTopUtilityCommandEnd();
-
-		exec_nested_level--;
+		if (isCompleteQuery)
+			HandleQueryEnd(is_top_level_query);
 	}
 	PG_END_TRY();
 }
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
index efa2e81165..e7fcdf7b11 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
@@ -40,6 +40,8 @@
 #include "yb/util/sync_point.h"
 #include "yb/util/tsan_util.h"
 
+#include "yb/yql/pgwrapper/libpq_utils.h"
+
 DECLARE_int32(cdc_state_checkpoint_update_interval_ms);
 DECLARE_bool(enable_pg_cron);
 DECLARE_int32(timestamp_history_retention_interval_sec);
@@ -534,12 +536,12 @@ TEST_F(XClusterDDLReplicationTest, CreateTableWithEnum) {
 
 }
 
-TEST_F(XClusterDDLReplicationTest, BlockMultistatementQuery) {
+TEST_F(XClusterDDLReplicationTest, MultistatementQuery) {
   ASSERT_OK(SetUpClustersAndReplication());
 
   // Have to do this through ysqlsh -c since that sends the whole
   // query string as a single command.
-  auto call_multistatement_query = [&](const std::string& query) {
+  auto call_multistatement_query = [&](const std::string& query) -> Status {
     std::vector<std::string> args;
     args.push_back(GetPgToolPath("ysqlsh"));
     args.push_back("--host");
@@ -551,25 +553,32 @@ TEST_F(XClusterDDLReplicationTest, BlockMultistatementQuery) {
     args.push_back("-c");
     args.push_back(query);
 
-    auto s = CallAdminVec(args);
-    LOG(INFO) << "Command output: " << s;
-    ASSERT_NOK(s);
-    ASSERT_TRUE(
-        s.status().message().Contains("only a single DDL command is allowed in the query string"));
+    auto output = VERIFY_RESULT(CallAdminVec(args));
+    LOG(INFO) << "Command output: " << output;
+    return Status::OK();
   };
 
-  call_multistatement_query(
-      "CREATE TABLE multistatement(i int PRIMARY KEY);"
-      "INSERT INTO multistatement VALUES (1);");
-  call_multistatement_query(
-      "SELECT 1;"
-      "CREATE TABLE multistatement(i int PRIMARY KEY);");
-  call_multistatement_query(
-      "CREATE TABLE multistatement1(i int PRIMARY KEY);"
-      "CREATE TABLE multistatement2(i int PRIMARY KEY);");
-  call_multistatement_query(
-      "CREATE TABLE multistatement(i int);"
-      "CREATE UNIQUE INDEX ON multistatement(i);");
+  ASSERT_OK(
+      call_multistatement_query("CREATE TABLE tbl1(i int PRIMARY KEY);"
+                                "INSERT INTO tbl1 VALUES (1);"));
+  ASSERT_OK(
+      call_multistatement_query("SELECT 1;"
+                                "CREATE TABLE tbl2(i int PRIMARY KEY);"));
+  ASSERT_OK(
+      call_multistatement_query("CREATE TEMP TABLE tmp1(i int PRIMARY KEY);"
+                                "DROP TABLE tmp1;"
+                                "INSERT INTO tbl2 VALUES(3);"
+                                "CREATE TABLE tbl3(i int PRIMARY KEY);"));
+  ASSERT_OK(
+      call_multistatement_query("CREATE TABLE tbl4(key int);"
+                                "CREATE UNIQUE INDEX ON tbl4(key);"));
+
+  ASSERT_OK(
+      call_multistatement_query("INSERT INTO tbl4 VALUES (1);"
+                                "DROP TABLE tbl1, tbl2;"));
+
+  ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+  ASSERT_OK(VerifyWrittenRecords(std::vector<TableName>{"tbl4"}));
 }
 
 TEST_F(XClusterDDLReplicationTest, CreateIndex) {
@@ -3602,4 +3611,115 @@ TEST_F(XClusterDDLReplicationTest, CreateTableAs) {
   InsertAndVerify(kIntoTableCase3, /*initial_row_count=*/10);
 }
 
+// Verify pg_partman + pg_cron + Switchover works.
+TEST_F(XClusterDDLReplicationSwitchoverTest, PartmanExtension) {
+  ANNOTATE_UNPROTECTED_WRITE(FLAGS_enable_pg_cron) = true;
+  ANNOTATE_UNPROTECTED_WRITE(FLAGS_ysql_pg_conf_csv) = "cron.yb_job_list_refresh_interval=10";
+
+  ASSERT_OK(SetUpClusters());
+  ASSERT_OK(RunOnBothClusters([this](Cluster* cluster) -> Status {
+    auto conn = VERIFY_RESULT(cluster->ConnectToDB(namespace_name));
+    RETURN_NOT_OK(conn.Execute("CREATE SCHEMA partman"));
+    RETURN_NOT_OK(conn.Execute("CREATE EXTENSION pg_partman WITH SCHEMA partman"));
+    RETURN_NOT_OK(conn.Execute("CREATE EXTENSION pg_cron"));
+    return Status::OK();
+  }));
+  ASSERT_OK(CheckpointReplicationGroup(kReplicationGroupId, /*require_no_bootstrap_needed=*/false));
+  ASSERT_OK(CreateReplicationFromCheckpoint());
+
+  ASSERT_RESULT(producer_conn_->Fetch(R"#(
+    SELECT cron.schedule(
+        'Run maintenance job',
+        '5 seconds',
+        'SELECT partman.run_maintenance()'
+    );)#"));
+
+  ASSERT_OK(producer_conn_->Execute(R"#(
+    CREATE TABLE orders(
+      order_id SERIAL,
+      order_date DATE NOT NULL,
+      customer_id INT) PARTITION BY RANGE (order_date);)#"));
+
+  ASSERT_OK(producer_conn_->FetchAllAsString(R"#(
+    SELECT partman.create_parent(
+      p_parent_table => 'public.orders',
+      p_control => 'order_date',
+      p_type => 'native',
+      p_interval => 'monthly',
+      p_premake => 1);)#"));
+
+  int64_t expected_table_count = 4;
+
+  auto validate_table_count = [this, &expected_table_count]() {
+    const auto select_table_names =
+        "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='public'";
+
+    ASSERT_OK(LoggedWaitFor(
+        [this, select_table_names, expected_table_count]() -> Result<bool> {
+          auto table_count = VERIFY_RESULT(producer_conn_->FetchRow<int64_t>(select_table_names));
+          return table_count == expected_table_count;
+          // Wait for 3x the cron job interval.
+        },
+        MonoDelta::FromMinutes(3),
+        Format("Wait for Producer table count to be $0", expected_table_count)));
+
+    ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+    auto table_count = ASSERT_RESULT(consumer_conn_->FetchRow<int64_t>(select_table_names));
+    ASSERT_EQ(table_count, expected_table_count);
+  };
+
+  ASSERT_NO_FATALS(validate_table_count());
+
+  // Insert some data into the table and verify it is replicated.
+  const auto select_data = "SELECT customer_id FROM orders ORDER BY order_date";
+  ASSERT_OK(
+      producer_conn_->Execute("INSERT INTO orders (order_date, customer_id) VALUES (current_date, "
+                              "1), (current_date + 1, 2)"));
+  auto producer_data = ASSERT_RESULT(producer_conn_->FetchAllAsString(select_data));
+  ASSERT_EQ(producer_data, "1; 2");
+  ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+  auto consumer_data = ASSERT_RESULT(consumer_conn_->FetchAllAsString(select_data));
+  ASSERT_EQ(consumer_data, producer_data);
+
+  // Update the premake so that cron job creates one more partition.
+  ASSERT_OK(producer_conn_->Execute("UPDATE partman.part_config SET premake = 2"));
+  expected_table_count++;
+  ASSERT_NO_FATALS(validate_table_count());
+
+  ASSERT_OK(Switchover());
+
+  // Update premake again after the switchover.
+  ASSERT_OK(producer_conn_->Execute("UPDATE partman.part_config SET premake = 3"));
+  expected_table_count++;
+  ASSERT_NO_FATALS(validate_table_count());
+
+  // Make sure we can drop the extension, but we cannot recreate it while the database is in
+  // automatic mode.
+  ASSERT_OK(producer_conn_->Execute("DROP EXTENSION pg_partman"));
+  ASSERT_NOK_STR_CONTAINS(
+      producer_conn_->Execute("CREATE EXTENSION pg_partman WITH SCHEMA partman"),
+      "Extension pg_partman is not supported because it contains unsupported DDLs within the "
+      "extension script");
+}
+
+TEST_F(XClusterDDLReplicationTest, FuncWithDDLsAndDMLs) {
+  ASSERT_OK(SetUpClustersAndReplication());
+
+  // create a function which takes a table name as an argument and creates a table with that name
+  // and inserts 10 rows into it.
+  ASSERT_OK(producer_conn_->Execute(
+      R"#(
+      CREATE FUNCTION create_and_insert_table(table_name text)
+      RETURNS void AS $$ BEGIN
+        EXECUTE 'CREATE TABLE ' || quote_ident(table_name) || ' (key int PRIMARY KEY)';
+        EXECUTE 'INSERT INTO ' || quote_ident(table_name) || ' VALUES (1), (2), (3), (4), (5), (6),
+          (7), (8), (9), (10)';
+      END;
+      $$ LANGUAGE plpgsql;
+      )#"));
+  ASSERT_OK(producer_conn_->FetchAllAsString("SELECT create_and_insert_table('test_table');"));
+  ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+  ASSERT_OK(VerifyWrittenRecords(std::vector<TableName>{"test_table"}));
+}
+
 }  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_test_base.h b/src/yb/integration-tests/xcluster/xcluster_test_base.h
index cbde6dda8f..37d2323f97 100644
--- a/src/yb/integration-tests/xcluster/xcluster_test_base.h
+++ b/src/yb/integration-tests/xcluster/xcluster_test_base.h
@@ -326,6 +326,9 @@ class XClusterTestBase : public YBTest {
     if (!status.ok()) {
       return status.CloneAndAppend(error);
     }
+    if (!error.empty()) {
+      LOG(ERROR) << "Error: " << error;
+    }
     return output;
   }
 
diff --git a/src/yb/master/catalog_manager_util.cc b/src/yb/master/catalog_manager_util.cc
index 7afab4a516..1515f0ca51 100644
--- a/src/yb/master/catalog_manager_util.cc
+++ b/src/yb/master/catalog_manager_util.cc
@@ -581,7 +581,10 @@ Status ExecutePgsqlStatements(
       req, resp.get(), controller.get(), [controller, resp, cb = std::move(callback)]() {
         Status status = controller->status();
         if (status.ok() && resp->has_error()) {
-          status = StatusFromPB(resp->error().status());
+          // Underlying error code could be NetworkError from libpq. Convert it to IllegalState.
+          status = STATUS_FORMAT(
+              IllegalState, "Error executing pgsql statements: $0",
+              resp->error().status().message());
         }
         cb(status);
       });
