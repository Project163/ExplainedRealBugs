diff --git a/src/postgres/src/backend/catalog/index.c b/src/postgres/src/backend/catalog/index.c
index 98c5b11206..718d8d2af2 100644
--- a/src/postgres/src/backend/catalog/index.c
+++ b/src/postgres/src/backend/catalog/index.c
@@ -2347,7 +2347,7 @@ index_drop(Oid indexId, bool concurrent, bool concurrent_lock_mode)
 
 	if (IsYugaByteEnabled() &&
 		userIndexRelation->rd_rel->relpersistence == RELPERSISTENCE_TEMP)
-		YBCDdlEnableForceCatalogModification();
+		YBCRecordTempRelationDDL();
 
 	/*
 	 * Drop Index Concurrently is more or less the reverse process of Create
diff --git a/src/postgres/src/backend/catalog/namespace.c b/src/postgres/src/backend/catalog/namespace.c
index e7c4fdf125..94169d1f60 100644
--- a/src/postgres/src/backend/catalog/namespace.c
+++ b/src/postgres/src/backend/catalog/namespace.c
@@ -4008,7 +4008,7 @@ InitTempTableNamespace(void)
 	Assert(!OidIsValid(myTempNamespace));
 
 	if (IsYugaByteEnabled())
-		YBCDdlEnableForceCatalogModification();
+		YBCRecordTempRelationDDL();
 
 	/*
 	 * First, do permission check to see if we are authorized to make temp
@@ -4315,7 +4315,7 @@ RemoveTempRelations(Oid tempNamespaceId)
 			YBAddDdlTxnState(YB_DDL_MODE_SILENT_ALTERING);
 		else
 			YBIncrementDdlNestingLevel(YB_DDL_MODE_SILENT_ALTERING);
-		YBCDdlEnableForceCatalogModification();
+		YBCRecordTempRelationDDL();
 	}
 	performDeletion(&object, DROP_CASCADE,
 					PERFORM_DELETION_INTERNAL |
diff --git a/src/postgres/src/backend/commands/indexcmds.c b/src/postgres/src/backend/commands/indexcmds.c
index 9ddfbada41..7055f848c9 100644
--- a/src/postgres/src/backend/commands/indexcmds.c
+++ b/src/postgres/src/backend/commands/indexcmds.c
@@ -1626,7 +1626,7 @@ DefineIndex(Oid relationId,
 
 	if (IsYugaByteEnabled() &&
 		rel->rd_rel->relpersistence == RELPERSISTENCE_TEMP)
-		YBCDdlEnableForceCatalogModification();
+		YBCRecordTempRelationDDL();
 
 	indexRelationId =
 		index_create(rel, indexRelationName, indexRelationId, parentIndexId,
diff --git a/src/postgres/src/backend/commands/tablecmds.c b/src/postgres/src/backend/commands/tablecmds.c
index d873a2e821..06f5926d88 100644
--- a/src/postgres/src/backend/commands/tablecmds.c
+++ b/src/postgres/src/backend/commands/tablecmds.c
@@ -838,7 +838,7 @@ DefineRelation(CreateStmt *stmt, char relkind, Oid ownerId,
 
 	if (IsYugaByteEnabled() &&
 		stmt->relation->relpersistence == RELPERSISTENCE_TEMP)
-		YBCDdlEnableForceCatalogModification();
+		YBCRecordTempRelationDDL();
 
 	/*
 	 * Determine the lockmode to use when scanning parents.  A self-exclusive
@@ -1776,7 +1776,7 @@ RemoveRelations(DropStmt *drop)
 	}
 
 	if (only_temp_tables)
-		YBCDdlEnableForceCatalogModification();
+		YBCRecordTempRelationDDL();
 
 	performMultipleDeletions(objects, drop->behavior, flags);
 
@@ -1956,6 +1956,7 @@ ExecuteTruncate(TruncateStmt *stmt, bool yb_is_top_level, List **yb_relids)
 	List	   *relids = NIL;
 	List	   *relids_logged = NIL;
 	ListCell   *cell;
+	bool yb_only_temp_tables = true;
 
 	/*
 	 * Open, exclusive-lock, and check all the explicitly-specified relations
@@ -1978,6 +1979,8 @@ ExecuteTruncate(TruncateStmt *stmt, bool yb_is_top_level, List **yb_relids)
 
 		/* open the relation, we already hold a lock on it */
 		rel = table_open(myrelid, NoLock);
+		yb_only_temp_tables = yb_only_temp_tables &&
+			rel->rd_rel->relpersistence == RELPERSISTENCE_TEMP;
 
 		/*
 		 * RangeVarGetRelidExtended() has done most checks with its callback,
@@ -2008,6 +2011,8 @@ ExecuteTruncate(TruncateStmt *stmt, bool yb_is_top_level, List **yb_relids)
 
 				/* find_all_inheritors already got lock */
 				rel = table_open(childrelid, NoLock);
+				yb_only_temp_tables = yb_only_temp_tables &&
+					rel->rd_rel->relpersistence == RELPERSISTENCE_TEMP;
 
 				/*
 				 * It is possible that the parent table has children that are
@@ -2048,6 +2053,9 @@ ExecuteTruncate(TruncateStmt *stmt, bool yb_is_top_level, List **yb_relids)
 					 errhint("Do not specify the ONLY keyword, or use TRUNCATE ONLY on the partitions directly.")));
 	}
 
+	if (yb_only_temp_tables)
+		YBCRecordTempRelationDDL();
+
 	ExecuteTruncateGuts(rels, relids, relids_logged,
 						stmt->behavior, stmt->restart_seqs, yb_is_top_level);
 
@@ -4537,7 +4545,7 @@ AlterTable(AlterTableStmt *stmt, LOCKMODE lockmode,
 
 	if (IsYugaByteEnabled() &&
 		rel->rd_rel->relpersistence == RELPERSISTENCE_TEMP)
-		YBCDdlEnableForceCatalogModification();
+		YBCRecordTempRelationDDL();
 
 	ATController(stmt, rel, stmt->cmds, stmt->relation->inh, lockmode, context);
 }
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/Makefile b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/Makefile
index 1b8489726c..1e8be7f0e6 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/Makefile
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/Makefile
@@ -4,7 +4,7 @@ PGFILEDESC = "yb_xcluster_ddl_replication - YugaByte xCluster DDL replication"
 
 EXTENSION = yb_xcluster_ddl_replication
 DATA = yb_xcluster_ddl_replication--1.0.sql
-SHLIB_LINK += -L$(YB_BUILD_ROOT)/lib -lyb_pggate
+SHLIB_LINK += -L$(YB_BUILD_ROOT)/lib -lyb_pggate -lyb_pggate_util
 
 MODULE_big = yb_xcluster_ddl_replication
 OBJS = \
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
index 670c65e174..0ab7bd1c23 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
@@ -263,3 +263,12 @@ get_typname(Oid pg_type_oid)
 	ReleaseSysCache(type_tuple);
 	return type_name;
 }
+
+bool
+IsMatViewCommand(CommandTag command_tag)
+{
+	return command_tag == CMDTAG_CREATE_MATERIALIZED_VIEW ||
+		   command_tag == CMDTAG_ALTER_MATERIALIZED_VIEW ||
+		   command_tag == CMDTAG_REFRESH_MATERIALIZED_VIEW ||
+		   command_tag == CMDTAG_DROP_MATERIALIZED_VIEW;
+}
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
index f16e048729..a01d8a2805 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
@@ -92,4 +92,6 @@ extern Oid	GetColocationIdFromRelation(Relation *rel, bool is_table_rewrite);
 
 extern char *get_typname(Oid pg_type_oid);
 
+extern bool	IsMatViewCommand(CommandTag command_tag);
+
 #endif
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
index aff9b1466f..4f3ba1e3a2 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
@@ -727,6 +727,7 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 	List	   *sequence_info_list = NIL;
 	List	   *type_info_list = NIL;
 	bool		found_temp = false;
+	bool		found_matview = false;
 
 	/*
 	 * As long as there is at least one command that needs to be replicated, we
@@ -837,6 +838,10 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 					ShouldReplicateTruncatedRelation(obj_id, &new_rel_list);
 
 		}
+		else if (IsMatViewCommand(command_tag))
+		{
+			found_matview = true;
+		}
 		else if (IsPassThroughDdlSupported(command_tag_name))
 		{
 			should_replicate_ddl = !is_temporary_object;
@@ -848,11 +853,20 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 		}
 	}
 
-	if (found_temp && should_replicate_ddl)
-		ereport(ERROR,
+	if (should_replicate_ddl)
+	{
+		if (found_temp)
+			ereport(ERROR,
 				(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
-				 errmsg("unsupported mix of temporary and persisted objects in DDL command"),
-				 errdetail("%s", kManualReplicationErrorMsg)));
+				errmsg("unsupported mix of temporary and persisted objects in DDL command"),
+				errdetail("%s", kManualReplicationErrorMsg)));
+
+		if (found_matview)
+			ereport(ERROR,
+				(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+				errmsg("unsupported mix of materialized view and other DDL commands"),
+				errdetail("%s", kManualReplicationErrorMsg)));
+	}
 
 	ProcessNewRelationsList(state, &new_rel_list);
 
@@ -901,8 +915,14 @@ ProcessSourceEventTriggerTableRewrite()
 }
 
 bool
-ProcessSourceEventTriggerDroppedObjects()
+ProcessSourceEventTriggerDroppedObjects(CommandTag	tag)
 {
+	/*
+	 * Matview related DDLs are not replicated.
+	 */
+	if (IsMatViewCommand(tag))
+		return false;
+
 	StringInfoData query_buf;
 
 	initStringInfo(&query_buf);
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.h b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.h
index 5c6b4bab2d..098302888c 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.h
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.h
@@ -42,7 +42,7 @@ bool		ProcessSourceEventTriggerDDLCommands(JsonbParseState *state);
 /*
  * Same as above but for pg_catalog.pg_event_trigger_dropped_objects().
  */
-bool		ProcessSourceEventTriggerDroppedObjects();
+bool		ProcessSourceEventTriggerDroppedObjects(CommandTag	tag);
 
 /*
  * Retrieve and store the OID of the table that is about to be rewritten.
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_xcluster_ddl_replication.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_xcluster_ddl_replication.c
index fbbc7df82e..fa22086f74 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_xcluster_ddl_replication.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_xcluster_ddl_replication.c
@@ -58,12 +58,30 @@ static const struct config_enum_entry replication_role_overrides[] = {
 static int	replication_role = XCLUSTER_ROLE_UNAVAILABLE;
 static int	replication_role_override = XCLUSTER_ROLE_UNSPECIFIED;
 
+/* Current nesting depth of ExecutorRun+ProcessUtility calls */
+static int	exec_nested_level = 0;
+
+static bool captured_by_extension = false;
+
+/* Check if the top level statement is a extension DDL. */
+static bool is_extension_ddl = false;
+
+/* Check if this is a DDL related to our own extension. */
+static bool is_self_extension_ddl = false;
+
 /*
  * Util functions.
  */
-
-static bool IsInIgnoreList(EventTriggerData *trig_data);
-
+static void EvaluateTopDdlCommand(CommandTag command_tag);
+static void RecordTempRelationDDL();
+static void XClusterProcessUtility(PlannedStmt *pstmt,
+								   const char *queryString,
+								   bool readOnlyTree,
+								   ProcessUtilityContext context,
+								   ParamListInfo params,
+								   QueryEnvironment *queryEnv,
+								   DestReceiver *dest,
+								   QueryCompletion *qc);
 
 /*
  * Per DDL Variables.
@@ -77,9 +95,8 @@ static bool IsInIgnoreList(EventTriggerData *trig_data);
  */
 static bool yb_should_replicate_ddl = false;
 
-/*
- * Assign hooks.
- */
+static YbcRecordTempRelationDDL_hook_type prev_YBCRecordTempRelationDDL = NULL;
+static ProcessUtility_hook_type prev_ProcessUtility = NULL;
 
 /*
  * The GUC variables `enable_manual_ddl_replication` and
@@ -157,6 +174,13 @@ _PG_init(void)
 							 PGC_SUSET,
 							 0,
 							 NULL, assign_TEST_replication_role_override, NULL);
+
+	prev_YBCRecordTempRelationDDL = YBCRecordTempRelationDDL_hook;
+	YBCRecordTempRelationDDL_hook = RecordTempRelationDDL;
+
+	prev_ProcessUtility = ProcessUtility_hook;
+	ProcessUtility_hook = XClusterProcessUtility;
+
 }
 
 void
@@ -178,7 +202,7 @@ FetchReplicationRole()
 bool
 IsDisabled()
 {
-	return (replication_role != XCLUSTER_ROLE_AUTOMATIC_SOURCE &&
+	return !captured_by_extension || (replication_role != XCLUSTER_ROLE_AUTOMATIC_SOURCE &&
 			replication_role != XCLUSTER_ROLE_AUTOMATIC_TARGET);
 }
 
@@ -300,29 +324,9 @@ IsExtensionDdl(CommandTag command_tag)
  * extension.
  */
 bool
-IsCurrentDdlPartOfExtensionDdlBatch(CommandTag command_tag)
+IsCurrentDdlPartOfExtensionDdlBatch()
 {
-	/* Extension DDL cannot be executed within another extension DDL. */
-	if (IsExtensionDdl(command_tag))
-	{
-		return false;
-	}
-
-	List	   *parse_tree = pg_parse_query(debug_query_string);
-	ListCell   *lc;
-
-	foreach(lc, parse_tree)
-	{
-		RawStmt    *stmt = (RawStmt *) lfirst(lc);
-		CommandTag	stmt_command_tag = CreateCommandTag(stmt->stmt);
-
-		if (IsExtensionDdl(stmt_command_tag))
-		{
-			return true;
-		}
-	}
-
-	return false;
+	return is_extension_ddl && exec_nested_level > 1;
 }
 
 /*
@@ -468,6 +472,15 @@ HandleTargetDDLEnd(EventTriggerData *trig_data)
 	/* Manual DDLs are not captured at all on the target. */
 	if (enable_manual_ddl_replication)
 		return;
+
+	/*
+	 * DDLs on target are blocked in pg_client_session before they can modify
+	 * the catalog, so if a user executed DDL got this far then it means this is a
+	 * pass through DDL command.
+	 */
+	if (!yb_xcluster_automatic_mode_target_ddl)
+		return;
+
 	/*
 	 * We expect ddl_queue_primary_key_* variables to have been set earlier in
 	 * the transaction by the ddl_queue handler.
@@ -494,7 +507,7 @@ HandleSourceSQLDrop(EventTriggerData *trig_data)
 
 	INIT_MEM_CONTEXT_AND_SPI_CONNECT("yb_xcluster_ddl_replication.HandleSourceSQLDrop context");
 
-	yb_should_replicate_ddl |= ProcessSourceEventTriggerDroppedObjects();
+	yb_should_replicate_ddl |= ProcessSourceEventTriggerDroppedObjects(trig_data->tag);
 
 	CLOSE_MEM_CONTEXT_AND_SPI;
 }
@@ -521,6 +534,9 @@ HandleSourceTableRewrite(EventTriggerData *trig_data)
 void
 HandleSourceDDLStart(EventTriggerData *trig_data)
 {
+	if (is_self_extension_ddl)
+		return;
+
 	/* By default we don't replicate. */
 	yb_should_replicate_ddl = false;
 	if (enable_manual_ddl_replication)
@@ -540,6 +556,33 @@ HandleSourceDDLStart(EventTriggerData *trig_data)
 	ClearRewrittenTableOidList();
 }
 
+void
+HandleTargetDDLStart(EventTriggerData *trig_data)
+{
+	if (IsCurrentDdlPartOfExtensionDdlBatch())
+		return;
+
+	yb_xcluster_target_ddl_bypass = false;
+
+	/* Bypass DDLs executed in manual mode, or from the target poller. */
+	if (enable_manual_ddl_replication ||
+		yb_xcluster_automatic_mode_target_ddl || is_self_extension_ddl)
+	{
+		yb_xcluster_target_ddl_bypass = true;
+		return;
+	}
+
+	DisallowMultiStatementQueries(trig_data->tag);
+
+	/*
+	 * Allow DDLs related to materialized views.
+	 * Temp relations are bypassed in RecordTempRelationDDL.
+	 * DDLs that are not caught by the trigger (ex CREATE DATABASE) are bypassed
+	 * in XClusterProcessUtility.
+	 */
+	yb_xcluster_target_ddl_bypass = IsMatViewCommand(trig_data->tag);
+}
+
 PG_FUNCTION_INFO_V1(handle_ddl_start);
 Datum
 handle_ddl_start(PG_FUNCTION_ARGS)
@@ -547,20 +590,34 @@ handle_ddl_start(PG_FUNCTION_ARGS)
 	if (!CALLED_AS_EVENT_TRIGGER(fcinfo))	/* internal error */
 		elog(ERROR, "not fired by event trigger manager");
 
+	/*
+	 * Only process statements that have been captured by the trigger at the top
+	 * level. This allows us to bypass creation of our own extension which we
+	 * won't capture until the trigger is created, which happens in a nested
+	 * level.
+	 */
+	if (exec_nested_level == 1)
+		captured_by_extension = true;
+
 	FetchReplicationRole();
 	if (IsDisabled())
 		PG_RETURN_NULL();
 
 	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
 
-	if (IsInIgnoreList(trig_data))
-		PG_RETURN_NULL();
+	if (exec_nested_level == 1)
+		EvaluateTopDdlCommand(trig_data->tag);
 
 	if (IsReplicationSource())
 	{
 		HandleSourceDDLStart(trig_data);
 	}
 
+	if (IsReplicationTarget())
+	{
+		HandleTargetDDLStart(trig_data);
+	}
+
 	PG_RETURN_NULL();
 }
 
@@ -576,14 +633,14 @@ handle_ddl_end(PG_FUNCTION_ARGS)
 
 	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
 
-	if (IsInIgnoreList(trig_data))
+	if (is_self_extension_ddl)
 		PG_RETURN_NULL();
 
 	/*
 	 * Capture the DDL as long as its not a step within another Extension DDL
 	 * batch.
 	 */
-	if (!IsCurrentDdlPartOfExtensionDdlBatch(trig_data->tag))
+	if (!IsCurrentDdlPartOfExtensionDdlBatch())
 	{
 		if (IsReplicationSource())
 		{
@@ -610,16 +667,14 @@ handle_sql_drop(PG_FUNCTION_ARGS)
 
 	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
 
-	if (IsInIgnoreList(trig_data))
+	if (is_self_extension_ddl)
 		PG_RETURN_NULL();
 
-	if (IsReplicationSource() && !IsCurrentDdlPartOfExtensionDdlBatch(trig_data->tag))
+	if (IsReplicationSource() && !IsCurrentDdlPartOfExtensionDdlBatch())
 	{
 		HandleSourceSQLDrop(trig_data);
 	}
 
-	/* HandleTargetDDLEnd will be handled in handle_ddl_end. */
-
 	PG_RETURN_NULL();
 }
 
@@ -635,7 +690,7 @@ handle_table_rewrite(PG_FUNCTION_ARGS)
 
 	EventTriggerData *trig_data = (EventTriggerData *) fcinfo->context;
 
-	if (IsInIgnoreList(trig_data))
+	if (is_self_extension_ddl)
 		PG_RETURN_NULL();
 
 	if (IsReplicationSource())
@@ -698,21 +753,88 @@ GetExtensionName(CommandTag tag, List *parse_tree)
 	}
 }
 
-static bool
-IsInIgnoreList(EventTriggerData *trig_data)
+static void
+EvaluateTopDdlCommand(CommandTag command_tag)
 {
-	if (!IsExtensionDdl(trig_data->tag))
+	is_extension_ddl = false;
+	is_self_extension_ddl = false;
+
+	if (IsExtensionDdl(command_tag))
 	{
-		return false;
+		is_extension_ddl = true;
+		List *parse_tree = pg_parse_query(debug_query_string);
+		char *extname = GetExtensionName(command_tag, parse_tree);
+		is_self_extension_ddl = extname != NULL &&
+								strcmp(extname, EXTENSION_NAME) == 0;
 	}
 
-	List	   *parse_tree = pg_parse_query(debug_query_string);
-	char	   *extname = GetExtensionName(trig_data->tag, parse_tree);
+}
+
+static void
+RecordTempRelationDDL()
+{
+	/*
+	 * If we are manually running a DDL on a temp relation on the target, then do not block it.
+	 */
+	if (IsReplicationTarget())
+		yb_xcluster_target_ddl_bypass = true;
+
+	if (prev_YBCRecordTempRelationDDL)
+		prev_YBCRecordTempRelationDDL();
+}
+
+void
+HandleTopUtilityCommandStart()
+{
+	captured_by_extension = false;
+
+	/*
+	 * For DDLs that are handled by the handle_ddl_start event trigger,
+	 * HandleTargetDDLStart will set yb_xcluster_target_ddl_bypass to false and
+	 * then allow them on a case by case basis. For any DDL that is not handled
+	 * by the trigger, we will set yb_xcluster_target_ddl_bypass to true and
+	 * allow it to pass through.
+	 */
+	yb_xcluster_target_ddl_bypass = true;
+}
+
+void
+HandleTopUtilityCommandEnd()
+{
+	captured_by_extension = false;
+	yb_xcluster_target_ddl_bypass = false;
+}
+
+static void
+XClusterProcessUtility(PlannedStmt *pstmt,
+					   const char *queryString,
+					   bool readOnlyTree,
+					   ProcessUtilityContext context,
+					   ParamListInfo params,
+					   QueryEnvironment *queryEnv,
+					   DestReceiver *dest,
+					   QueryCompletion *qc)
+{
+	exec_nested_level++;
 
-	if (extname != NULL && strcmp(extname, EXTENSION_NAME) == 0)
+	if (exec_nested_level == 1)
+		HandleTopUtilityCommandStart();
+
+	PG_TRY();
 	{
-		return true;
+		if (prev_ProcessUtility)
+			prev_ProcessUtility(pstmt, queryString, readOnlyTree, context,
+								params, queryEnv, dest, qc);
+		else
+			standard_ProcessUtility(pstmt, queryString, readOnlyTree, context,
+									params, queryEnv, dest, qc);
 	}
+	PG_FINALLY();
+	{
+		if (exec_nested_level == 1)
+			HandleTopUtilityCommandEnd();
 
-	return false;
+		exec_nested_level--;
+	}
+	PG_END_TRY();
 }
diff --git a/src/yb/integration-tests/upgrade-tests/ysql_ddl_whitelist-test.cc b/src/yb/integration-tests/upgrade-tests/ysql_ddl_whitelist-test.cc
index faa3380b65..167f5854d3 100644
--- a/src/yb/integration-tests/upgrade-tests/ysql_ddl_whitelist-test.cc
+++ b/src/yb/integration-tests/upgrade-tests/ysql_ddl_whitelist-test.cc
@@ -50,6 +50,9 @@ TEST_F(YsqlDdlWhitelistTest, TestDDLBlocking) {
   ASSERT_STMT_OK("CREATE INDEX temp_idx ON test_temp_table_with_pk (b)");
   ASSERT_STMT_OK("DROP INDEX temp_idx");
 
+  // Truncate a temp table.
+  ASSERT_STMT_OK("TRUNCATE TABLE test_temp_table_with_pk");
+
   // Drop a collection of temp tables.
   ASSERT_STMT_OK("CREATE TEMP TABLE test_temp_table (id INT)");
   ASSERT_STMT_OK("DROP TABLE test_temp_table, test_temp_table_with_pk");
@@ -61,9 +64,12 @@ TEST_F(YsqlDdlWhitelistTest, TestDDLBlocking) {
   ASSERT_DDL_NOK("ALTER TABLE normal_table ADD COLUMN c INT");
   ASSERT_DDL_NOK("CREATE INDEX normal_idx2 ON normal_table (b)");
   ASSERT_DDL_NOK("DROP INDEX normal_idx");
+  ASSERT_DDL_NOK("TRUNCATE TABLE normal_table");
 
-  // Ensure mix of temp and normal table drops are not allowed.
+  // Ensure mix of temp and normal table truncate and drop are not allowed.
   ASSERT_STMT_OK("CREATE TEMP TABLE test_temp_table (id INT)");
+  ASSERT_DDL_NOK("TRUNCATE TABLE normal_table, test_temp_table");
+  ASSERT_DDL_NOK("DROP TABLE normal_table, test_temp_table");
   ASSERT_DDL_NOK("DROP TABLE test_temp_table, normal_table");
 
   // Ensure yb_force_catalog_update_on_next_ddl works as expected.
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
index 568271b32f..583678855c 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
@@ -68,14 +68,21 @@ const MonoDelta kTimeout = 60s * kTimeMultiplier;
 class XClusterDDLReplicationTest : public XClusterDDLReplicationTestBase {
  public:
   Status SetUpClustersAndCheckpointReplicationGroup(
-      bool is_colocated = false, bool start_yb_controller_servers = false) {
-    RETURN_NOT_OK(SetUpClusters(is_colocated, start_yb_controller_servers));
+      const SetupParams& params = XClusterDDLReplicationTestBase::kDefaultParams) {
+    RETURN_NOT_OK(SetUpClusters(params));
     RETURN_NOT_OK(
         CheckpointReplicationGroup(kReplicationGroupId, /*require_no_bootstrap_needed=*/false));
     // Bootstrap here would have no effect because the database is empty so we skip it for the test.
     return Status::OK();
   }
 
+  Status SetUpClustersAndReplication(
+      const SetupParams& params = XClusterDDLReplicationTestBase::kDefaultParams) {
+    RETURN_NOT_OK(SetUpClustersAndCheckpointReplicationGroup(params));
+    RETURN_NOT_OK(CreateReplicationFromCheckpoint());
+    return Status::OK();
+  }
+
   // Precondition: a bootstrap is not actually needed.
   // For example, the two databases might both be completely empty.
   // This is not the same as whether or not IsXClusterBootstrapRequired will return false.
@@ -100,8 +107,7 @@ class XClusterDDLReplicationTest : public XClusterDDLReplicationTestBase {
 
 // In automatic mode, sequences_data should have been created on both universe.
 TEST_F(XClusterDDLReplicationTest, CheckSequenceDataTable) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   ASSERT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
     auto table_info = VERIFY_RESULT(cluster->mini_cluster_->GetLeaderMiniMaster())
@@ -113,8 +119,7 @@ TEST_F(XClusterDDLReplicationTest, CheckSequenceDataTable) {
 }
 
 TEST_F(XClusterDDLReplicationTest, BasicSetupAlterTeardown) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto source_xcluster_client = client::XClusterClient(*producer_client());
   const auto target_master_address = consumer_cluster()->GetMasterAddresses();
@@ -171,8 +176,7 @@ TEST_F(XClusterDDLReplicationTest, YB_NEVER_DEBUG_TEST(CheckpointMultipleDatabas
 }
 
 TEST_F(XClusterDDLReplicationTest, YB_DISABLE_TEST_ON_MACOS(SurviveRestarts)) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   {
     TEST_SetThreadPrefixScoped prefix_se("NP");
@@ -270,8 +274,7 @@ TEST_F(XClusterDDLReplicationTest, TestExtensionDeletionWithMultipleReplicationG
 
 TEST_F(XClusterDDLReplicationTest, DisableSplitting) {
   // Ensure that splitting of xCluster DDL Replication tables is disabled on both sides.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   for (auto* cluster : {&producer_cluster_, &consumer_cluster_}) {
     for (const auto& table : {xcluster::kDDLQueueTableName, xcluster::kDDLReplicatedTableName}) {
@@ -295,8 +298,10 @@ TEST_F(XClusterDDLReplicationTest, DDLReplicationTablesNotColocated) {
   }
 
   // Ensure that xCluster DDL Replication system tables are not colocated.
-
-  ASSERT_OK(SetUpClusters(/*is_colocated=*/true, /*start_yb_controller_servers=*/true));
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  params.start_yb_controller_servers = true;
+  ASSERT_OK(SetUpClusters(params));
   // Create a colocated table so that we can run xCluster setup.
   ASSERT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
     RETURN_NOT_OK(CreateYsqlTable(
@@ -328,7 +333,9 @@ TEST_F(XClusterDDLReplicationTest, Bootstrapping) {
     GTEST_SKIP() << "This test does not work with yb_backup.py";
   }
 
-  ASSERT_OK(SetUpClusters(/*is_colocated=*/false, /*start_yb_controller_servers=*/true));
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.start_yb_controller_servers = true;
+  ASSERT_OK(SetUpClusters(params));
   auto producer_table_name = ASSERT_RESULT(CreateYsqlTable(
       /*idx=*/1, /*num_tablets=*/3, &producer_cluster_));
 
@@ -343,7 +350,9 @@ TEST_F(XClusterDDLReplicationTest, BootstrappingEmptyTable) {
     GTEST_SKIP() << "This test does not work with yb_backup.py";
   }
 
-  ASSERT_OK(SetUpClusters(/*is_colocated=*/false, /*start_yb_controller_servers=*/true));
+  auto param = XClusterDDLReplicationTestBase::kDefaultParams;
+  param.start_yb_controller_servers = true;
+  ASSERT_OK(SetUpClusters(param));
   auto producer_table_name = ASSERT_RESULT(CreateYsqlTable(
       /*idx=*/1, /*num_tablets=*/3, &producer_cluster_));
 
@@ -362,7 +371,9 @@ TEST_F(XClusterDDLReplicationTest, YB_DISABLE_TEST(BootstrappingWithNoTables)) {
     GTEST_SKIP() << "This test does not work with yb_backup.py";
   }
 
-  ASSERT_OK(SetUpClusters(/*is_colocated=*/false, /*start_yb_controller_servers=*/true));
+  auto param = XClusterDDLReplicationTestBase::kDefaultParams;
+  param.start_yb_controller_servers = true;
+  ASSERT_OK(SetUpClusters(param));
 
   ASSERT_OK(CheckpointReplicationGroupOnNamespaces({namespace_name}));
   ASSERT_OK(BackupFromProducer());
@@ -371,8 +382,7 @@ TEST_F(XClusterDDLReplicationTest, YB_DISABLE_TEST(BootstrappingWithNoTables)) {
 }
 
 TEST_F(XClusterDDLReplicationTest, CreateTable) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   // Create a simple table.
   auto producer_table_name = ASSERT_RESULT(CreateYsqlTable(
@@ -484,8 +494,7 @@ TEST_F(XClusterDDLReplicationTest, CreateTableWithEnum) {
 }
 
 TEST_F(XClusterDDLReplicationTest, BlockMultistatementQuery) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   // Have to do this through ysqlsh -c since that sends the whole
   // query string as a single command.
@@ -523,8 +532,7 @@ TEST_F(XClusterDDLReplicationTest, BlockMultistatementQuery) {
 }
 
 TEST_F(XClusterDDLReplicationTest, CreateIndex) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   const std::string kBaseTableName = "base_table";
   const std::string kColumn2Name = "a";
@@ -582,8 +590,7 @@ TEST_F(XClusterDDLReplicationTest, IndexCreationImmediatelyAfterInsert) {
   // Test creating an index soon after inserting rows. Ensures that we are picking an appropriate
   // backfill time that isn't just the xCluster safe time (which may not work for ddl replication as
   // the ddl_queue table holds up safe time).
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
   auto producer_conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
   auto consumer_conn = ASSERT_RESULT(consumer_cluster_.ConnectToDB(namespace_name));
   ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
@@ -628,8 +635,7 @@ TEST_F(XClusterDDLReplicationTest, NonconcurrentBackfills) {
   // Test commands that trigger nonconcurrent backfills.
   // Want to ensure that we don't trigger the backfill on the target, otherwise we may see duplicate
   // rows.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   const std::string kBaseTableName = "base_table";
   const std::string kColumn2Name = "a";
@@ -682,8 +688,7 @@ TEST_F(XClusterDDLReplicationTest, NonconcurrentBackfills) {
 }
 
 TEST_F(XClusterDDLReplicationTest, NonconcurrentBackfillsWithPartitions) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   const auto kPartitionedTableName = "partitioned_table";
   const auto kPartitionedIndexName = "partitioned_index";
@@ -724,8 +729,7 @@ TEST_F(XClusterDDLReplicationTest, ExactlyOnceReplication) {
   // Test that DDLs are only replicated exactly once.
   const int kNumTablets = 3;
 
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   // Fail next DDL query and continue to process it.
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_xcluster_ddl_queue_handler_fail_at_end) = true;
@@ -760,8 +764,7 @@ TEST_F(XClusterDDLReplicationTest, ExactlyOnceReplication) {
 }
 
 TEST_F(XClusterDDLReplicationTest, DDLsWithinTransaction) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto p_conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
   // Run a bunch of DDLs within a transaction, each of which depend on previous ones so the exact
@@ -784,8 +787,7 @@ TEST_F(XClusterDDLReplicationTest, DDLsWithinTransaction) {
 }
 
 TEST_F(XClusterDDLReplicationTest, PauseTargetOnRepeatedFailures) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto p_conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
   ASSERT_OK(p_conn.Execute("CREATE TABLE test_table_1 (key int PRIMARY KEY);"));
@@ -827,8 +829,7 @@ TEST_F(XClusterDDLReplicationTest, DuplicateTableNames) {
   const int kNumTablets = 3;
   const int kNumRowsTable1 = 10;
   const int kNumRowsTable2 = 3 * kNumRowsTable1;
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   // Pause replication.
   ASSERT_OK(ToggleUniverseReplication(
@@ -869,8 +870,7 @@ TEST_F(XClusterDDLReplicationTest, RepeatedCreateAndDropTable) {
   // Test when a table is created and dropped multiple times.
   // Decrease number of iterations for slower build types.
   const int kNumIterations = (IsSanitizer() || kIsMac) ? 3 : 10;
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   // Pause replication.
   ASSERT_OK(ToggleUniverseReplication(
@@ -902,8 +902,7 @@ TEST_F(XClusterDDLReplicationTest, AddRenamedTable) {
   // Test that when a table is renamed, the new table is correctly linked to the source table.
   const std::string kTableNewName = "renamed_table";
 
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   // Pause replication.
   ASSERT_OK(ToggleUniverseReplication(
@@ -949,8 +948,9 @@ TEST_F(XClusterDDLReplicationTest, AddRenamedTable) {
 }
 
 TEST_F(XClusterDDLReplicationTest, CreateColocatedTables) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup(/*is_colocated=*/true));
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  ASSERT_OK(SetUpClustersAndReplication(params));
 
   ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
 
@@ -984,8 +984,9 @@ TEST_F(XClusterDDLReplicationTest, CreateColocatedTables) {
 }
 
 TEST_F(XClusterDDLReplicationTest, CreateColocatedIndexes) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup(/*is_colocated=*/true));
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  ASSERT_OK(SetUpClustersAndReplication(params));
 
   ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
 
@@ -1029,8 +1030,9 @@ TEST_F(XClusterDDLReplicationTest, CreateColocatedIndexes) {
 }
 
 TEST_F(XClusterDDLReplicationTest, CreateColocatedTableWithPause) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup(/*is_colocated=*/true));
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  ASSERT_OK(SetUpClustersAndReplication(params));
 
   ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
 
@@ -1084,8 +1086,9 @@ TEST_F(XClusterDDLReplicationTest, CreateColocatedTableWithPause) {
 }
 
 TEST_F(XClusterDDLReplicationTest, CreateColocatedTableWithSourceFailures) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup(/*is_colocated=*/true));
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  ASSERT_OK(SetUpClustersAndReplication(params));
 
   ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
 
@@ -1132,8 +1135,9 @@ TEST_F(XClusterDDLReplicationTest, CreateColocatedTableWithSourceFailures) {
 }
 
 TEST_F(XClusterDDLReplicationTest, CreateColocatedTableWithTargetFailures) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup(/*is_colocated=*/true));
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  ASSERT_OK(SetUpClustersAndReplication(params));
 
   ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
 
@@ -1174,8 +1178,9 @@ TEST_F(XClusterDDLReplicationTest, CreateColocatedTableWithTargetFailures) {
 }
 
 TEST_F(XClusterDDLReplicationTest, ColocatedHistoricalSchemasWithCompactions) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup(/*is_colocated=*/true));
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  ASSERT_OK(SetUpClustersAndReplication(params));
   ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
 
   const auto kNewTableName = "new_colocated_table";
@@ -1243,8 +1248,9 @@ TEST_F(XClusterDDLReplicationTest, ColocatedHistoricalSchemasWithCompactions) {
 
 TEST_F(XClusterDDLReplicationTest, AlterExistingColocatedTable) {
   // Test alters on a table that is already part of replication.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup(/*is_colocated=*/true));
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  ASSERT_OK(SetUpClustersAndReplication(params));
 
   auto producer_conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
   ASSERT_OK(
@@ -1264,8 +1270,7 @@ TEST_F(XClusterDDLReplicationTest, AlterExistingColocatedTable) {
 
 TEST_F(XClusterDDLReplicationTest, ExtraOidAllocationsOnTarget) {
   const auto kNumIterations = 20;
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
   google::SetVLOGLevel("catalog_manager*", 1);
   google::SetVLOGLevel("pg_client_service*", 1);
 
@@ -1302,8 +1307,7 @@ TEST_F(XClusterDDLReplicationTest, IncrementalSafeTimeBumpWithDdlQueueStepdowns)
   // miss processing some commit_times/DDLs.
   const auto kTableName = "test_table";
   const auto kTableNameRename = "renamed_table";
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto get_and_verify_safe_time_batch =
       [&](int expected_size, bool expected_has_apply_safe_time) -> Result<xcluster::SafeTimeBatch> {
@@ -1395,8 +1399,7 @@ TEST_F(XClusterDDLReplicationTest, IncrementalSafeTimeBumpWithDdlQueueStepdowns)
 
 TEST_F(XClusterDDLReplicationTest, IncrementalSafeTimeBumpDropColumn) {
   const auto kTableName = "drop_col_test";
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   SyncPoint::GetInstance()->LoadDependency(
       {{.predecessor = "XClusterDDLQueueHandler::DdlQueueSafeTimeBumped",
@@ -1459,8 +1462,7 @@ TEST_F(XClusterDDLReplicationTest, HandleEarlierApplySafeTime) {
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_xcluster_producer_modify_sent_apply_safe_time_ms) = -5000;
 
   const auto kTableName = "initial_table";
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto producer_conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
 
@@ -1527,8 +1529,7 @@ class XClusterDDLReplicationSwitchoverTest : public XClusterDDLReplicationTest {
 
 TEST_F(XClusterDDLReplicationSwitchoverTest, SwitchoverWithWorkload) {
   // Set up replication from A to B.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   ASSERT_OK(ValidateReplicationRole(*cluster_A_, "source"));
   ASSERT_OK(ValidateReplicationRole(*cluster_B_, "target"));
@@ -1604,8 +1605,7 @@ TEST_F(XClusterDDLReplicationSwitchoverTest, SwitchoverWithWorkload) {
 
 TEST_F(XClusterDDLReplicationSwitchoverTest, SwitchoverWithPendingDDL) {
   // Set up replication from A to B.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   ASSERT_OK(ValidateReplicationRole(*cluster_A_, "source"));
   ASSERT_OK(ValidateReplicationRole(*cluster_B_, "target"));
@@ -1705,8 +1705,7 @@ TEST_F(XClusterDDLReplicationSwitchoverTest, SwitchoverWithPendingSequenceBump)
   const int kInitialSequenceValue = 7777700;
 
   // Set up replication from A to B.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   // Create a sequence on A, let its creation replicate then bump it
   // 10 times but do not let the bumps replicate via pausing
@@ -1804,8 +1803,7 @@ TEST_F(XClusterDDLReplicationSwitchoverTest, SwitchoverBumpsAboveUsedOids) {
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_ysql_oid_cache_prefetch_size) = 1;
 
   // Set up replication from A to B.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   // Log information about OID reservations; search logs for (case insensitive) "reserve".
   google::SetVLOGLevel("catalog_manager*", 2);
@@ -1859,7 +1857,6 @@ TEST_F(XClusterDDLReplicationSwitchoverTest, SwitchoverBumpsAboveUsedOids) {
 
 TEST_F(XClusterDDLReplicationSwitchoverTest, PgCron) {
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_enable_pg_cron) = true;
-  ANNOTATE_UNPROTECTED_WRITE(FLAGS_ysql_cron_database_name) = "test_db";
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_ysql_pg_conf_csv) = "cron.yb_job_list_refresh_interval=10";
 
   ASSERT_OK(SetUpClusters());
@@ -1936,8 +1933,7 @@ using XClusterDDLReplicationFailoverTest = XClusterDDLReplicationSwitchoverTest;
 
 TEST_F(XClusterDDLReplicationFailoverTest, FailoverWithPendingAlterDDLs) {
   // Set up replication from A to B.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto& sync_point = *SyncPoint::GetInstance();
   sync_point.LoadDependency(
@@ -2025,8 +2021,9 @@ TEST_F(XClusterDDLReplicationFailoverTest, FailoverWithPendingAlterDDLs) {
 }
 
 TEST_F(XClusterDDLReplicationFailoverTest, ColocatedFailoverWithPendingCreate) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup(/*is_colocated=*/true));
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+  params.is_colocated = true;
+  ASSERT_OK(SetUpClustersAndReplication(params));
   ASSERT_OK(EnablePITROnClusters());
 
   // Increase the retention interval to ensure nothing is cleaned up early.
@@ -2125,7 +2122,9 @@ TEST_F(XClusterDDLReplicationSetupTest, ReplicationSetUpBumpsOidCounter) {
   // Cache only 30 OIDs at a time; see below for why this value was chosen.
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_ysql_oid_cache_prefetch_size) = 30;
 
-  ASSERT_OK(SetUpClusters(/*is_colocated=*/false, /*start_yb_controller_servers=*/true));
+  auto param = XClusterDDLReplicationTestBase::kDefaultParams;
+  param.start_yb_controller_servers = true;
+  ASSERT_OK(SetUpClusters(param));
 
   // Create a giant enum on cluster A.
   {
@@ -2248,13 +2247,9 @@ class XClusterDDLReplicationAddDropColumnTest : public XClusterDDLReplicationTes
  public:
   void SetUp() override {
     YB_SKIP_TEST_IN_TSAN();
-    XClusterDDLReplicationTest::SetUp();
-    ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-    ASSERT_OK(CreateReplicationFromCheckpoint());
-    producer_conn_ = std::make_unique<pgwrapper::PGConn>(
-        ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name)));
-    consumer_conn_ = std::make_unique<pgwrapper::PGConn>(
-        ASSERT_RESULT(consumer_cluster_.ConnectToDB(namespace_name)));
+    TEST_SETUP_SUPER(XClusterDDLReplicationTest);
+
+    ASSERT_OK(SetUpClustersAndReplication());
 
     auto consumer_namespace_id = ASSERT_RESULT(GetNamespaceId(consumer_client()));
     consumer_database_oid_ = ASSERT_RESULT(GetPgsqlDatabaseOid(consumer_namespace_id));
@@ -2394,9 +2389,6 @@ class XClusterDDLReplicationAddDropColumnTest : public XClusterDDLReplicationTes
       "SELECT column_name, data_type FROM information_schema.columns WHERE table_name = '$0' ORDER "
       "BY column_name";
 
-  std::unique_ptr<pgwrapper::PGConn> producer_conn_;
-  std::unique_ptr<pgwrapper::PGConn> consumer_conn_;
-
   std::string paused_expected_data_output_;
   std::string paused_expected_schema_output_;
 
@@ -2424,7 +2416,9 @@ TEST_F(XClusterDDLReplicationTest, DocdbNextColumnAboveLastUsedColumn) {
   if (!UseYbController()) {
     GTEST_SKIP() << "This test does not work with yb_backup.py";
   }
-  ASSERT_OK(SetUpClusters(/*is_colocated=*/false, /*start_yb_controller_servers=*/true));
+  auto param = XClusterDDLReplicationTestBase::kDefaultParams;
+  param.start_yb_controller_servers = true;
+  ASSERT_OK(SetUpClusters(param));
 
   {
     auto conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
@@ -2455,8 +2449,7 @@ TEST_F(XClusterDDLReplicationTest, DocdbNextColumnAboveLastUsedColumn) {
 }
 
 TEST_F(XClusterDDLReplicationTest, FailedSchemaChangeOnSource) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
   ASSERT_OK(conn.Execute("CREATE TABLE my_table (x INT);"));
@@ -2486,8 +2479,7 @@ TEST_F(XClusterDDLReplicationTest, FailedSchemaChangeOnSource) {
 }
 
 TEST_F(XClusterDDLReplicationTest, FailedSchemaChangeOnSourceWithPartitioning) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
   ASSERT_OK(conn.Execute("CREATE TABLE my_table (x INT) PARTITION BY RANGE (x);"));
@@ -2520,8 +2512,7 @@ TEST_F(XClusterDDLReplicationTest, FailedSchemaChangeOnSourceWithPartitioning) {
 }
 
 TEST_F(XClusterDDLReplicationTest, FailedSchemaChangeOnTarget) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
   ASSERT_OK(conn.Execute("CREATE TABLE my_table (x INT);"));
@@ -2551,8 +2542,7 @@ TEST_F(XClusterDDLReplicationTest, FailedSchemaChangeOnTarget) {
 }
 
 TEST_F(XClusterDDLReplicationTest, ColumnIdsOnFailover) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   ASSERT_OK(EnablePITROnClusters());
 
@@ -2604,8 +2594,7 @@ TEST_F(XClusterDDLReplicationTest, ColumnIdsOnFailover) {
 TEST_F(XClusterDDLReplicationTest, RollbackPreservesDeletedColumns) {
   // Set up xCluster automatic mode replication so we will be rolling back next DocDB column IDs
   // counter as part of failed DDLs.
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   auto conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
   ASSERT_OK(conn.Execute("CREATE TABLE my_table (x INT);"));
@@ -2634,8 +2623,7 @@ TEST_F(XClusterDDLReplicationTest, RollbackPreservesDeletedColumns) {
 // Make sure we can create Colocated db and table on both clusters that is not affected by an the
 // replication of a different database.
 TEST_F(XClusterDDLReplicationTest, CreateNonXClusterColocatedDb) {
-  ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  ASSERT_OK(SetUpClustersAndReplication());
 
   const auto kColocatedDB = "colocated_db";
   const auto kCreateTableStmt = "CREATE TABLE tbl1(a int)";
@@ -2656,14 +2644,9 @@ class XClusterDDLReplicationTableRewriteTest : public XClusterDDLReplicationTest
  public:
   void SetUp() override {
     YB_SKIP_TEST_IN_TSAN();
-    XClusterDDLReplicationTest::SetUp();
-    ASSERT_OK(SetUpClustersAndCheckpointReplicationGroup());
-    ASSERT_OK(CreateReplicationFromCheckpoint());
+    TEST_SETUP_SUPER(XClusterDDLReplicationTest);
 
-    producer_conn_ = std::make_unique<pgwrapper::PGConn>(
-        ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name)));
-    consumer_conn_ = std::make_unique<pgwrapper::PGConn>(
-        ASSERT_RESULT(consumer_cluster_.ConnectToDB(namespace_name)));
+    ASSERT_OK(SetUpClustersAndReplication());
 
     // Create a base table and insert some rows.
     ASSERT_OK(producer_conn_->ExecuteFormat(
@@ -2706,8 +2689,6 @@ class XClusterDDLReplicationTableRewriteTest : public XClusterDDLReplicationTest
 
   const std::string kBaseTableName_ = "base_table";
   const std::string kColumn2Name_ = "b";
-  std::unique_ptr<pgwrapper::PGConn> producer_conn_;
-  std::unique_ptr<pgwrapper::PGConn> consumer_conn_;
   client::YBTableName producer_base_table_name_;
 };
 
@@ -2860,7 +2841,9 @@ TEST_F(XClusterDDLReplicationTest, BackupRestorePreservesEnumSortValue) {
     GTEST_SKIP() << "This test does not work with yb_backup.py";
   }
 
-  ASSERT_OK(SetUpClusters(/*is_colocated=*/false, /*start_yb_controller_servers=*/true));
+  auto param = XClusterDDLReplicationTestBase::kDefaultParams;
+  param.start_yb_controller_servers = true;
+  ASSERT_OK(SetUpClusters(param));
   {
     auto conn = std::make_unique<pgwrapper::PGConn>(
         ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name)));
@@ -2983,7 +2966,9 @@ TEST_F(XClusterDDLReplicationTest, BackupRestorePreservesEnumSortValue) {
   }
 }
 
-TEST_F(XClusterDDLReplicationTableRewriteTest, TruncateTable) {
+TEST_F(XClusterDDLReplicationTest, TruncateTable) {
+  ASSERT_OK(SetUpClustersAndReplication());
+
   // Create a table with a sequence.
   const auto table_name = "tbl1";
   ASSERT_OK(producer_conn_->Execute("CREATE TABLE tbl1(id SERIAL PRIMARY KEY, col1 int)"));
@@ -3021,14 +3006,8 @@ TEST_F(XClusterDDLReplicationTableRewriteTest, TruncateTable) {
 
   // But just truncate the temp table should work on each side independently.
   ASSERT_OK(producer_conn_->Execute("TRUNCATE TABLE tbl_tmp"));
-  // TODO(#25885): Remove the need to set enable_manual_ddl_replication to use temp tables on
-  // target.
-  ASSERT_OK(consumer_conn_->Execute(
-      "SET yb_xcluster_ddl_replication.enable_manual_ddl_replication TO TRUE"));
   ASSERT_OK(consumer_conn_->Execute("CREATE TEMP TABLE tbl_tmp2(id int)"));
   ASSERT_OK(consumer_conn_->Execute("TRUNCATE TABLE tbl_tmp2"));
-  ASSERT_OK(consumer_conn_->Execute(
-      "SET yb_xcluster_ddl_replication.enable_manual_ddl_replication TO FALSE"));
 
   // Pause DDL replication and run the truncate followed by insert.
   auto ddl_queue_table = ASSERT_RESULT(GetYsqlTable(
@@ -3050,4 +3029,113 @@ TEST_F(XClusterDDLReplicationTableRewriteTest, TruncateTable) {
   ASSERT_OK(verify_data());
 }
 
+// Make sure we can run a variety of DDLs related to temp tables on both clusters.
+TEST_F(XClusterDDLReplicationTest, TempTableDDLs) {
+  ASSERT_OK(SetUpClustersAndReplication());
+
+  master::GetUniverseReplicationResponsePB resp;
+  ASSERT_OK(VerifyUniverseReplication(&resp));
+  ASSERT_EQ(resp.entry().tables_size(), 2);  // ddl_queue + sequences_data
+
+  auto test_temp_table = [&](pgwrapper::PGConn& conn) -> Status {
+    RETURN_NOT_OK(conn.Execute("CREATE TEMP TABLE test_temp (id int PRIMARY KEY, name text)"));
+    RETURN_NOT_OK(conn.Execute("INSERT INTO test_temp VALUES (1, 'test')"));
+    RETURN_NOT_OK(conn.Execute("CREATE INDEX ON test_temp (name)"));
+    RETURN_NOT_OK(conn.Execute("ALTER TABLE test_temp ADD COLUMN age int"));
+    RETURN_NOT_OK(conn.Execute("INSERT INTO test_temp VALUES (2, 'test2', 25)"));
+    RETURN_NOT_OK(conn.Execute("ALTER TABLE test_temp DROP COLUMN age"));
+    RETURN_NOT_OK(conn.Execute("DROP TABLE test_temp"));
+
+    return Status::OK();
+  };
+
+  LOG(INFO) << "Testing temp table on producer";
+  ASSERT_OK(test_temp_table(*producer_conn_));
+
+  LOG(INFO) << "Testing temp table on consumer";
+  ASSERT_OK(test_temp_table(*consumer_conn_));
+
+  ASSERT_OK(VerifyUniverseReplication(&resp));
+  ASSERT_EQ(resp.entry().tables_size(), 2);
+}
+
+// Make sure we can run a variety of DDLs related to materialized views on both clusters.
+TEST_F(XClusterDDLReplicationTest, MatViewDDLs) {
+  ASSERT_OK(SetUpClustersAndReplication());
+
+  ASSERT_OK(producer_conn_->Execute("CREATE TABLE tbl1(a int)"));
+  ASSERT_OK(producer_conn_->Execute("INSERT INTO tbl1 VALUES (1), (2), (3)"));
+  ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+
+  master::GetUniverseReplicationResponsePB resp;
+  ASSERT_OK(VerifyUniverseReplication(&resp));
+  ASSERT_EQ(resp.entry().tables_size(), 3);  // ddl_queue + base_table + tbl1 + sequences_data
+
+  // Create a materialized view on the producer.
+  auto perform_mv_ddls = [this](pgwrapper::PGConn& conn) -> Result<std::string> {
+    RETURN_NOT_OK(conn.Execute("CREATE MATERIALIZED VIEW mv1 AS SELECT * FROM tbl1 WHERE a > 1"));
+    RETURN_NOT_OK(conn.Execute("REFRESH MATERIALIZED VIEW mv1"));
+    RETURN_NOT_OK(conn.Execute("ALTER MATERIALIZED VIEW mv1 RENAME TO mv2"));
+    RETURN_NOT_OK(WaitForSafeTimeToAdvanceToNow());
+    auto view_data = VERIFY_RESULT(conn.FetchAllAsString("SELECT * FROM mv2 ORDER BY a"));
+    RETURN_NOT_OK(conn.Execute("DROP MATERIALIZED VIEW mv2"));
+    return view_data;
+  };
+
+  auto producer_data = ASSERT_RESULT(perform_mv_ddls(*producer_conn_));
+  ASSERT_EQ(producer_data, "2; 3");
+  auto consumer_data = ASSERT_RESULT(perform_mv_ddls(*consumer_conn_));
+
+  ASSERT_EQ(consumer_data, producer_data);
+
+  ASSERT_OK(VerifyUniverseReplication(&resp));
+  ASSERT_EQ(resp.entry().tables_size(), 3);
+}
+
+// Validate that the user cannot run arbitrary DDLs on the target cluster when in automatic mode.
+TEST_F(XClusterDDLReplicationTest, DDLsOnTarget) {
+  ASSERT_OK(SetUpClustersAndReplication());
+
+  ASSERT_OK(producer_conn_->Execute("CREATE TABLE tbl1(a int, b text)"));
+  ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+
+  constexpr auto kExpectedErrorMsg =
+      "DDL operations are forbidden on a database that is the target of automatic mode xCluster "
+      "replication";
+
+  const std::vector<std::string> kDisallowedDDLs = {
+      "CREATE TABLE test_table (id int PRIMARY KEY, name text)",
+      "CREATE INDEX ON tbl1 (b)",
+      "ALTER TABLE tbl1 ADD COLUMN age int",
+      "ALTER TABLE tbl1 DROP COLUMN b",
+      "DROP TABLE tbl1",
+      "CREATE TYPE test_type AS ENUM ('A', 'B')",
+      "CREATE SCHEMA test_schema",
+      "CREATE SEQUENCE test_sequence",
+  };
+
+  for (const auto& ddl : kDisallowedDDLs) {
+    LOG(INFO) << "Executing: " << ddl;
+    if (ddl.contains("CREATE INDEX")) {
+      // TODO(#28135): Create index creates a DocDB table before making pg catalog changes causing
+      // it to fail with a bootstrapping error.
+      ASSERT_NOK(consumer_conn_->Execute(ddl));
+    } else {
+      ASSERT_NOK_STR_CONTAINS(consumer_conn_->Execute(ddl), kExpectedErrorMsg);
+    }
+  }
+
+  // With manual mode we should be able to execute DDLs except those that create new DocDB Tables.
+  ASSERT_OK(consumer_conn_->Execute(
+      "SET yb_xcluster_ddl_replication.enable_manual_ddl_replication TO TRUE"));
+  for (const auto& ddl : kDisallowedDDLs) {
+    LOG(INFO) << "Executing: " << ddl;
+    if (ddl.contains("CREATE TABLE") || ddl.contains("CREATE INDEX")) {
+      ASSERT_NOK(consumer_conn_->Execute(ddl));
+    } else {
+      ASSERT_OK(consumer_conn_->Execute(ddl));
+    }
+  }
+}
+
 }  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
index 474ee58c79..4a93ee60eb 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
@@ -191,7 +191,9 @@ class XClusterPgRegressDDLReplicationTest : public XClusterDDLReplicationTestBas
     const auto sub_dir = "test_xcluster_ddl_replication_sql";
     const auto test_sql_dir = JoinPathSegments(env_util::GetRootDir(sub_dir), sub_dir, "sql");
 
-    RETURN_NOT_OK(SetUpClusters(is_colocated_));
+    auto params = XClusterDDLReplicationTestBase::kDefaultParams;
+    params.is_colocated = is_colocated_;
+    RETURN_NOT_OK(SetUpClusters(params));
 
     if (!pre_execution_sql_text.empty()) {
       RETURN_NOT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.cc
index 5bfba39867..0fe837c1ed 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.cc
@@ -37,32 +37,39 @@ using namespace std::chrono_literals;
 
 namespace yb {
 
+XClusterYsqlTestBase::SetupParams XClusterDDLReplicationTestBase::kDefaultParams{
+    // By default start with no consumer or producer tables.
+    .num_consumer_tablets = {},
+    .num_producer_tablets = {},
+    // We only create one pg proxy per cluster, so we need to ensure that the target ddl_queue
+    // table leader is on that tserver (so that setting xcluster context works properly).
+    .replication_factor = 1,
+    .num_masters = 1,
+    .ranged_partitioned = false,
+    .is_colocated = false,
+    .use_different_database_oids = false,
+    .start_yb_controller_servers = false,
+};
+
 void XClusterDDLReplicationTestBase::SetUp() {
-  XClusterYsqlTestBase::SetUp();
-  ANNOTATE_UNPROTECTED_WRITE(FLAGS_enable_xcluster_api_v2) = true;
+  TEST_SETUP_SUPER(XClusterYsqlTestBase);
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_xcluster_ddl_queue_handler_log_queries) = true;
 }
 
-Status XClusterDDLReplicationTestBase::SetUpClusters(
-    bool is_colocated, bool start_yb_controller_servers) {
-  namespace_name = is_colocated ? "colocated_test_db" : "test_db";
-  const SetupParams kDefaultParams{
-      // By default start with no consumer or producer tables.
-      .num_consumer_tablets = {},
-      .num_producer_tablets = {},
-      // We only create one pg proxy per cluster, so we need to ensure that the target ddl_queue
-      // table leader is on that tserver (so that setting xcluster context works properly).
-      .replication_factor = 1,
-      .num_masters = 1,
-      .ranged_partitioned = false,
-      .is_colocated = is_colocated,
-      .use_different_database_oids = true,
-      .start_yb_controller_servers = start_yb_controller_servers,
-  };
-  RETURN_NOT_OK(XClusterYsqlTestBase::SetUpClusters(kDefaultParams));
-  if (is_colocated) {
+Status XClusterDDLReplicationTestBase::SetUpClusters(const SetupParams& params) {
+  namespace_name = params.is_colocated
+                       ? "colocated_test_db"
+                       : (params.use_different_database_oids ? "test_db" : "yugabyte");
+
+  RETURN_NOT_OK(XClusterYsqlTestBase::SetUpClusters(params));
+  if (params.is_colocated) {
     RETURN_NOT_OK(CreateInitialColocatedTable());
   }
+
+  producer_conn_ = std::make_unique<pgwrapper::PGConn>(
+      VERIFY_RESULT(producer_cluster_.ConnectToDB(namespace_name)));
+  consumer_conn_ = std::make_unique<pgwrapper::PGConn>(
+      VERIFY_RESULT(consumer_cluster_.ConnectToDB(namespace_name)));
   return Status::OK();
 }
 
@@ -115,14 +122,17 @@ Status XClusterDDLReplicationTestBase::RestoreToConsumer(
     return GetTempDir(Format("backup_$0", namespace_name));
   };
 
+  consumer_conn_.reset();
   // Restore to new databases on the consumer.
   for (const auto& namespace_name : namespace_names) {
-    (void)DropDatabase(consumer_cluster_, namespace_name);
+    RETURN_NOT_OK(DropDatabase(consumer_cluster_, namespace_name));
     RETURN_NOT_OK(RunBackupCommand(
         {"--backup_location", BackupDir(namespace_name), "--keyspace",
          Format("ysql.$0", namespace_name), "restore"},
         &*consumer_cluster_.mini_cluster_));
   }
+  consumer_conn_ = std::make_unique<pgwrapper::PGConn>(
+      VERIFY_RESULT(consumer_cluster_.ConnectToDB(namespace_name)));
   return Status::OK();
 }
 
@@ -262,6 +272,7 @@ bool XClusterDDLReplicationTestBase::SetReplicationDirection(
   replication_direction_ = replication_direction;
   std::swap(consumer_cluster_, producer_cluster_);
   std::swap(consumer_table_, producer_table_);
+  std::swap(consumer_conn_, producer_conn_);
   LOG(INFO) << "Switched replication direction to "
             << (replication_direction_ == ReplicationDirection::AToB ? "A -> B" : "B -> A");
   return true;
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.h b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.h
index ef89c958b9..04a23ce013 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.h
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.h
@@ -31,7 +31,9 @@ class XClusterDDLReplicationTestBase : public XClusterYsqlTestBase {
     return true;
   }
 
-  Status SetUpClusters(bool is_colocated = false, bool start_yb_controller_servers = false);
+  static SetupParams kDefaultParams;
+
+  Status SetUpClusters(const SetupParams& params = kDefaultParams);
 
   virtual Status CheckpointReplicationGroup(
       const xcluster::ReplicationGroupId& replication_group_id = kReplicationGroupId,
@@ -85,6 +87,9 @@ class XClusterDDLReplicationTestBase : public XClusterYsqlTestBase {
 
   const std::string kInitialColocatedTableName = "initial_colocated_table";
 
+  std::unique_ptr<pgwrapper::PGConn> producer_conn_;
+  std::unique_ptr<pgwrapper::PGConn> consumer_conn_;
+
  private:
   tools::TmpDirProvider tmp_dir_;
 
diff --git a/src/yb/tserver/pg_client.proto b/src/yb/tserver/pg_client.proto
index 45cbf0e87f..d4d378424d 100644
--- a/src/yb/tserver/pg_client.proto
+++ b/src/yb/tserver/pg_client.proto
@@ -770,6 +770,8 @@ message PgPerformOptionsPB {
   // - Clamps the read uncertainty window.
   // See the commit desc for more info.
   bool clamp_uncertainty_window = 24;
+
+  bool xcluster_target_ddl_bypass = 26;
 }
 
 message PgPerformRequestPB {
diff --git a/src/yb/tserver/pg_client_session.cc b/src/yb/tserver/pg_client_session.cc
index 7ed5c564b0..d7e046c02f 100644
--- a/src/yb/tserver/pg_client_session.cc
+++ b/src/yb/tserver/pg_client_session.cc
@@ -2726,14 +2726,33 @@ class PgClientSession::Impl {
     return ReleaseObjectLocksIfNecessary(txn, used_session_kind, deadline);
   }
 
-  Status DoPerform(
-      const PgTablesQueryResult& tables, const PerformQueryDataPtr& data, CoarseTimePoint deadline,
-      rpc::RpcContext* context = nullptr) {
-    auto& options = *data->req.mutable_options();
-    VLOG(5) << "Perform request: " << data->req.ShortDebugString();
-    if (!(options.ddl_mode() || options.yb_non_ddl_txn_for_sys_tables_allowed()) &&
-        xcluster_context() &&
-        xcluster_context()->IsReadOnlyMode(options.namespace_id())) {
+  template <class DataPtr, class Options>
+  Status ValidateRequestForXCluster(const Options& options, const DataPtr& data) {
+    if (options.yb_non_ddl_txn_for_sys_tables_allowed() || !xcluster_context()) {
+      return Status::OK();
+    }
+
+    if (options.ddl_mode()) {
+      // In xCluster Automatic mode, DDLs are not allowed on the target database unless it is run
+      // via the target poller or in forced manual mode.
+      if (xcluster_context()->GetXClusterRole(options.namespace_id()) ==
+              XClusterNamespaceInfoPB::AUTOMATIC_TARGET &&
+          !options.xcluster_target_ddl_bypass()) {
+        // Force catalog modifications is set for temp table, and in-place materialized view
+        // refresh. These DDLs are safe to perform on xCluster target in automatic mode.
+        for (const auto& op : data->req.ops()) {
+          SCHECK(
+              !op.has_write(), IllegalState,
+              "DDL operations are forbidden on a database that is the target of automatic mode "
+              "xCluster replication");
+        }
+      }
+
+      return Status::OK();
+    }
+
+    // DMLs.
+    if (xcluster_context()->IsReadOnlyMode(options.namespace_id())) {
       for (const auto& op : data->req.ops()) {
         if (op.has_write() && !op.write().is_backfill()) {
           TEST_SYNC_POINT_CALLBACK("WriteDetectedOnXClusterReadOnlyModeTarget", nullptr);
@@ -2746,6 +2765,17 @@ class PgClientSession::Impl {
       }
     }
 
+    return Status::OK();
+  }
+
+  Status DoPerform(
+      const PgTablesQueryResult& tables, const PerformQueryDataPtr& data, CoarseTimePoint deadline,
+      rpc::RpcContext* context = nullptr) {
+    auto& options = *data->req.mutable_options();
+    VLOG(5) << "Perform request: " << data->req.ShortDebugString();
+
+    RETURN_NOT_OK(ValidateRequestForXCluster(options, data));
+
     if (options.has_caching_info()) {
       VLOG_WITH_PREFIX(3)
           << "Executing read from response cache for session " << data->req.session_id();
diff --git a/src/yb/tserver/xcluster_poller.cc b/src/yb/tserver/xcluster_poller.cc
index 5e9776779f..4f6677072d 100644
--- a/src/yb/tserver/xcluster_poller.cc
+++ b/src/yb/tserver/xcluster_poller.cc
@@ -593,7 +593,7 @@ void XClusterPoller::HandleApplyChangesResponse(XClusterOutputClientResponse res
 
       // If processing ddl_queue table fails, then retry just this part (don't repeat ApplyChanges).
       ScheduleFuncWithDelay(
-          GetAtomicFlag(&FLAGS_xcluster_safe_time_update_interval_secs),
+          FLAGS_xcluster_safe_time_update_interval_secs * MonoTime::kMillisecondsPerSecond,
           BIND_FUNCTION_AND_ARGS(XClusterPoller::HandleApplyChangesResponse, std::move(response)));
       return;
     }
diff --git a/src/yb/yql/pggate/pg_txn_manager.cc b/src/yb/yql/pggate/pg_txn_manager.cc
index c4976ed806..125b89f560 100644
--- a/src/yb/yql/pggate/pg_txn_manager.cc
+++ b/src/yb/yql/pggate/pg_txn_manager.cc
@@ -683,6 +683,7 @@ Status PgTxnManager::SetupPerformOptions(
   options->set_trace_requested(enable_tracing_);
   options->set_txn_serial_no(serial_no_.txn());
   options->set_active_sub_transaction_id(active_sub_transaction_id_);
+  options->set_xcluster_target_ddl_bypass(yb_xcluster_target_ddl_bypass);
 
   if (use_saved_priority_) {
     options->set_use_existing_priority(true);
diff --git a/src/yb/yql/pggate/util/ybc_guc.cc b/src/yb/yql/pggate/util/ybc_guc.cc
index c5a95103cc..2ad29d4ec0 100644
--- a/src/yb/yql/pggate/util/ybc_guc.cc
+++ b/src/yb/yql/pggate/util/ybc_guc.cc
@@ -133,3 +133,5 @@ bool yb_ddl_transaction_block_enabled = false;
 bool yb_disable_ddl_transaction_block_for_read_committed = false;
 
 int yb_fk_references_cache_limit = 65535;
+
+bool yb_xcluster_target_ddl_bypass = false;
diff --git a/src/yb/yql/pggate/util/ybc_guc.h b/src/yb/yql/pggate/util/ybc_guc.h
index df75ab7e79..45ef42a3eb 100644
--- a/src/yb/yql/pggate/util/ybc_guc.h
+++ b/src/yb/yql/pggate/util/ybc_guc.h
@@ -293,6 +293,8 @@ extern int32_t yb_sampling_algorithm;
 
 extern int yb_fk_references_cache_limit;
 
+extern bool yb_xcluster_target_ddl_bypass;
+
 #ifdef __cplusplus
 } // extern "C"
 #endif
diff --git a/src/yb/yql/pggate/ybc_pggate.cc b/src/yb/yql/pggate/ybc_pggate.cc
index cf3e4bcc79..7b5955c812 100644
--- a/src/yb/yql/pggate/ybc_pggate.cc
+++ b/src/yb/yql/pggate/ybc_pggate.cc
@@ -209,6 +209,9 @@ bool PreloadAdditionalCatalogListValidator(const char* flag_name, const std::str
 
 DEFINE_validator(ysql_catalog_preload_additional_table_list, PreloadAdditionalCatalogListValidator);
 
+YbcRecordTempRelationDDL_hook_type YBCRecordTempRelationDDL_hook =
+    &YBCDdlEnableForceCatalogModification;
+
 namespace yb::pggate {
 
 //--------------------------------------------------------------------------------------------------
@@ -3161,6 +3164,12 @@ YbcStatus YBCPgRegisterSnapshotReadTime(
       pgapi->RegisterSnapshotReadTime(read_time, use_read_time), handle ? handle : &tmp_handle);
 }
 
+void YBCRecordTempRelationDDL() {
+  if (YBCRecordTempRelationDDL_hook) {
+    YBCRecordTempRelationDDL_hook();
+  }
+}
+
 void YBCDdlEnableForceCatalogModification() {
   pgapi->DdlEnableForceCatalogModification();
 }
diff --git a/src/yb/yql/pggate/ybc_pggate.h b/src/yb/yql/pggate/ybc_pggate.h
index c8b2f33f89..40bd6a491a 100644
--- a/src/yb/yql/pggate/ybc_pggate.h
+++ b/src/yb/yql/pggate/ybc_pggate.h
@@ -35,6 +35,9 @@ typedef const void * YbcConstSliceVector;
 typedef void * YbcSliceSet;
 typedef const void * YbcConstSliceSet;
 
+typedef void (*YbcRecordTempRelationDDL_hook_type)();
+extern YbcRecordTempRelationDDL_hook_type YBCRecordTempRelationDDL_hook;
+
 typedef struct {
   YbcStatus ybc_status;
   YbcPgExplicitRowLockErrorInfo error_info;
@@ -997,6 +1000,11 @@ YbcStatus YBCPgRestoreReadPoint(YbcReadPointHandle read_point);
 YbcStatus YBCPgRegisterSnapshotReadTime(
     uint64_t read_time, bool use_read_time, YbcReadPointHandle* handle);
 
+// Records the current statement as a temporary relation DDL statement.
+void YBCRecordTempRelationDDL();
+
+// Allow the DDL to modify the pg catalog even if it has been blocked for YSQL major upgrades. This
+// should only be used for DDLs that are safe to perform during a YSQL major upgrade.
 void YBCDdlEnableForceCatalogModification();
 
 uint64_t YBCGetCurrentHybridTimeLsn();
diff --git a/src/yb/yql/pgwrapper/pg_wrapper.cc b/src/yb/yql/pgwrapper/pg_wrapper.cc
index e7dc31a80a..251caa5059 100644
--- a/src/yb/yql/pgwrapper/pg_wrapper.cc
+++ b/src/yb/yql/pgwrapper/pg_wrapper.cc
@@ -608,6 +608,7 @@ Result<string> WritePostgresConfig(const PgProcessConf& conf) {
   metricsLibs.push_back("yb_pg_metrics");
   metricsLibs.push_back("pgaudit");
   metricsLibs.push_back("pg_hint_plan");
+  metricsLibs.push_back("yb_xcluster_ddl_replication");
 
   if (FLAGS_enable_pg_cron) {
     metricsLibs.push_back("pg_cron");
