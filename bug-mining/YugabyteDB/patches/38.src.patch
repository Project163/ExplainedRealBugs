diff --git a/src/yb/cdc/xcluster_types.h b/src/yb/cdc/xcluster_types.h
index 7494100972..8b8d4b0dac 100644
--- a/src/yb/cdc/xcluster_types.h
+++ b/src/yb/cdc/xcluster_types.h
@@ -65,4 +65,5 @@ struct XClusterTabletInfo {
 
   const std::string& producer_tablet_id() const { return producer_tablet_info.tablet_id; }
 };
+
 }  // namespace yb::xcluster
diff --git a/src/yb/client/CMakeLists.txt b/src/yb/client/CMakeLists.txt
index 4eec55e57b..c1c11cc112 100644
--- a/src/yb/client/CMakeLists.txt
+++ b/src/yb/client/CMakeLists.txt
@@ -67,6 +67,7 @@ set(CLIENT_SRCS
   transaction_rpc.cc
   universe_key_client.cc
   value.cc
+  xcluster_client.cc
   yb_op.cc
   yb_table_name.cc
 )
diff --git a/src/yb/client/client-internal.cc b/src/yb/client/client-internal.cc
index 0563b4f9ab..bdf185e4f0 100644
--- a/src/yb/client/client-internal.cc
+++ b/src/yb/client/client-internal.cc
@@ -314,6 +314,13 @@ YB_CLIENT_SPECIALIZE_SIMPLE_EX(Replication, XClusterDeleteOutboundReplicationGro
 YB_CLIENT_SPECIALIZE_SIMPLE_EX(Replication, XClusterAddNamespaceToOutboundReplicationGroup);
 YB_CLIENT_SPECIALIZE_SIMPLE_EX(Replication, XClusterRemoveNamespaceFromOutboundReplicationGroup);
 
+#define YB_CLIENT_SPECIALIZE_SIMPLE_EX_EACH(i, data, set) YB_CLIENT_SPECIALIZE_SIMPLE_EX set
+
+#define YB_CLIENT_SPECIALIZE_SIMPLE_FOR(rpcs) \
+  BOOST_PP_SEQ_FOR_EACH(YB_CLIENT_SPECIALIZE_SIMPLE_EX_EACH, ~, rpcs)
+
+YB_CLIENT_SPECIALIZE_SIMPLE_FOR(CLIENT_SYNC_LEADER_MASTER_RPC_LIST)
+
 YBClient::Data::Data()
     : leader_master_rpc_(rpcs_.InvalidHandle()),
       latest_observed_hybrid_time_(YBClient::kNoHybridTime),
diff --git a/src/yb/client/client.cc b/src/yb/client/client.cc
index abbd58b0d5..11a60b8bda 100644
--- a/src/yb/client/client.cc
+++ b/src/yb/client/client.cc
@@ -332,6 +332,19 @@ void FillFromRepeatedTabletLocations(
             BOOST_PP_CAT(method, Async))); \
   } while(0);
 
+#define IMPLEMENT_SYNC_LEADER_MASTER_RPC_IMP(service, method) \
+  Result<master::BOOST_PP_CAT(method, ResponsePB)> YBClient::method( \
+      const master::BOOST_PP_CAT(method, RequestPB) & req) { \
+    master::BOOST_PP_CAT(method, ResponsePB) resp; \
+    CALL_SYNC_LEADER_MASTER_RPC_EX(service, req, resp, method); \
+    return resp; \
+  }
+
+#define IMPLEMENT_SYNC_LEADER_MASTER_RPC(i, data, set) IMPLEMENT_SYNC_LEADER_MASTER_RPC_IMP set
+
+#define IMPLEMENT_SYNC_LEADER_MASTER_RPCS(rpcs) \
+  BOOST_PP_SEQ_FOR_EACH(IMPLEMENT_SYNC_LEADER_MASTER_RPC, ~, rpcs)
+
 // Adapts between the internal LogSeverity and the client's YBLogSeverity.
 static void LoggingAdapterCB(YBLoggingCallback* user_cb,
                              LogSeverity severity,
@@ -2890,5 +2903,7 @@ Result<master::StatefulServiceInfoPB> YBClient::GetStatefulServiceLocation(
   return std::move(resp.service_info());
 }
 
+IMPLEMENT_SYNC_LEADER_MASTER_RPCS(CLIENT_SYNC_LEADER_MASTER_RPC_LIST);
+
 }  // namespace client
 }  // namespace yb
diff --git a/src/yb/client/client.h b/src/yb/client/client.h
index 8b2218edd6..f4c53be661 100644
--- a/src/yb/client/client.h
+++ b/src/yb/client/client.h
@@ -83,6 +83,24 @@
 #include "yb/util/strongly_typed_bool.h"
 #include "yb/util/threadpool.h"
 
+#define DECLARE_SYNC_LEADER_MASTER_RPC_IMP(service, method) \
+  Result<master::BOOST_PP_CAT(method, ResponsePB)> method( \
+      const master::BOOST_PP_CAT(method, RequestPB)& req);
+
+#define DECLARE_SYNC_LEADER_MASTER_RPC(i, data, set) DECLARE_SYNC_LEADER_MASTER_RPC_IMP set
+
+#define DECLARE_SYNC_LEADER_MASTER_RPCS(rpcs) \
+  BOOST_PP_SEQ_FOR_EACH(DECLARE_SYNC_LEADER_MASTER_RPC, ~, rpcs)
+
+// Add the methods that we want to invoke on master leader here.
+// These functions will take a const reference to the request of the corresponding type as input and
+// return a Result of the appropriate response.
+// Ex: Result<SetupUniverseReplicationResponsePB>
+// SetupUniverseReplication(SetupUniverseReplicationRequestPB req);
+#define CLIENT_SYNC_LEADER_MASTER_RPC_LIST \
+  ((Replication, SetupUniverseReplication)) \
+  ((Replication, IsSetupUniverseReplicationDone)) \
+
 template<class T> class scoped_refptr;
 
 namespace yb {
@@ -998,6 +1016,8 @@ class YBClient {
   Result<google::protobuf::RepeatedPtrField<master::SnapshotInfoPB>> ListSnapshots(
       const TxnSnapshotId& snapshot_id = TxnSnapshotId::Nil(), bool prepare_for_backup = false);
 
+  DECLARE_SYNC_LEADER_MASTER_RPCS(CLIENT_SYNC_LEADER_MASTER_RPC_LIST);
+
   rpc::Messenger* messenger() const;
 
   const scoped_refptr<MetricEntity>& metric_entity() const;
@@ -1088,3 +1108,7 @@ Result<TableId> GetTableId(YBClient* client, const YBTableName& table_name);
 
 }  // namespace client
 }  // namespace yb
+
+#undef DECLARE_SYNC_LEADER_MASTER_RPC_IMP
+#undef DECLARE_SYNC_LEADER_MASTER_RPC
+#undef DECLARE_SYNC_LEADER_MASTER_RPCS
diff --git a/src/yb/client/xcluster_client.cc b/src/yb/client/xcluster_client.cc
new file mode 100644
index 0000000000..f6f7f42f0b
--- /dev/null
+++ b/src/yb/client/xcluster_client.cc
@@ -0,0 +1,118 @@
+// Copyright (c) YugabyteDB, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
+// in compliance with the License.  You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software distributed under the License
+// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+// or implied.  See the License for the specific language governing permissions and limitations
+// under the License.
+//
+
+#include "yb/client/xcluster_client.h"
+
+#include "yb/client/client.h"
+#include "yb/master/master_defaults.h"
+#include "yb/rpc/messenger.h"
+#include "yb/rpc/proxy.h"
+#include "yb/rpc/secure_stream.h"
+#include "yb/server/secure.h"
+#include "yb/util/path_util.h"
+
+DECLARE_bool(use_node_to_node_encryption);
+
+namespace yb::client {
+
+XClusterRemoteClient::XClusterRemoteClient(const std::string& certs_for_cdc_dir, MonoDelta timeout)
+    : certs_for_cdc_dir_(certs_for_cdc_dir), timeout_(timeout) {}
+
+XClusterRemoteClient::~XClusterRemoteClient() {
+  if (messenger_) {
+    messenger_->Shutdown();
+  }
+}
+
+Status XClusterRemoteClient::Init(
+    const xcluster::ReplicationGroupId& replication_group_id,
+    const std::vector<HostPort>& remote_masters) {
+  SCHECK(!remote_masters.empty(), InvalidArgument, "No master addresses provided");
+  const auto master_addrs = HostPort::ToCommaSeparatedString(remote_masters);
+
+  rpc::MessengerBuilder messenger_builder("xcluster-remote");
+  std::string certs_dir;
+
+  if (FLAGS_use_node_to_node_encryption) {
+    if (!certs_for_cdc_dir_.empty()) {
+      certs_dir = JoinPathSegments(certs_for_cdc_dir_, replication_group_id.ToString());
+    }
+    secure_context_ = VERIFY_RESULT(server::SetupSecureContext(
+        certs_dir, /*root_dir=*/"", /*name=*/"", server::SecureContextType::kInternal,
+        &messenger_builder));
+  }
+  messenger_ = VERIFY_RESULT(messenger_builder.Build());
+
+  yb_client_ = VERIFY_RESULT(YBClientBuilder()
+                                 .add_master_server_addr(master_addrs)
+                                 .default_admin_operation_timeout(timeout_)
+                                 .Build(messenger_.get()));
+
+  return Status::OK();
+}
+
+Result<UniverseUuid> XClusterRemoteClient::SetupUniverseReplication(
+    const xcluster::ReplicationGroupId& replication_group_id,
+    const std::vector<HostPort>& source_master_addresses,
+    const std::vector<NamespaceName>& namespace_names, const std::vector<TableId>& source_table_ids,
+    const std::vector<xrepl::StreamId>& bootstrap_ids, Transactional transactional) {
+  master::SetupUniverseReplicationRequestPB req;
+  req.set_replication_group_id(replication_group_id.ToString());
+  req.set_transactional(transactional);
+
+  HostPortsToPBs(source_master_addresses, req.mutable_producer_master_addresses());
+
+  req.mutable_producer_table_ids()->Reserve(narrow_cast<int>(source_table_ids.size()));
+  for (const auto& table_id : source_table_ids) {
+    req.add_producer_table_ids(table_id);
+  }
+
+  for (const auto& bootstrap_id : bootstrap_ids) {
+    req.add_producer_bootstrap_ids(bootstrap_id.ToString());
+  }
+
+  auto resp = VERIFY_RESULT(yb_client_->SetupUniverseReplication(req));
+
+  if (resp.has_error()) {
+    auto status = StatusFromPB(resp.error().status());
+    if (!status.ok() && !status.IsAlreadyPresent()) {
+      return status;
+    }
+  }
+
+  // universe_uuid will be set even when IsAlreadyPresent error is returned.
+  SCHECK(!resp.universe_uuid().empty(), IllegalState, "Universe UUID is empty");
+
+  return UniverseUuid::FromString(resp.universe_uuid());
+}
+
+Result<master::IsOperationDoneResult> XClusterRemoteClient::IsSetupUniverseReplicationDone(
+    const xcluster::ReplicationGroupId& replication_group_id) {
+  master::IsSetupUniverseReplicationDoneRequestPB req;
+  req.set_replication_group_id(replication_group_id.ToString());
+
+  auto resp = VERIFY_RESULT(yb_client_->IsSetupUniverseReplicationDone(req));
+  if (resp.has_error()) {
+    return StatusFromPB(resp.error().status());
+  }
+
+  Status status;
+  if (resp.has_replication_error()) {
+    // IsSetupUniverseReplicationDoneRequestPB will contain an OK status on success.
+    status = StatusFromPB(resp.replication_error());
+  }
+
+  return master::IsOperationDoneResult(resp.done(), std::move(status));
+}
+
+}  // namespace yb::client
diff --git a/src/yb/client/xcluster_client.h b/src/yb/client/xcluster_client.h
new file mode 100644
index 0000000000..40da35132d
--- /dev/null
+++ b/src/yb/client/xcluster_client.h
@@ -0,0 +1,78 @@
+// Copyright (c) YugabyteDB, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
+// in compliance with the License.  You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software distributed under the License
+// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+// or implied.  See the License for the specific language governing permissions and limitations
+// under the License.
+//
+
+#pragma once
+
+#include <string>
+#include <google/protobuf/repeated_field.h>
+
+#include "yb/cdc/xrepl_types.h"
+#include "yb/cdc/xcluster_types.h"
+#include "yb/common/common_net.pb.h"
+#include "yb/common/entity_ids_types.h"
+#include "yb/master/xcluster/master_xcluster_types.h"
+#include "yb/util/net/net_util.h"
+#include "yb/util/strongly_typed_string.h"
+#include "yb/util/strongly_typed_uuid.h"
+
+namespace yb {
+
+YB_STRONGLY_TYPED_UUID_DECL(UniverseUuid);
+
+namespace master {
+class MasterReplicationProxy;
+}  // namespace master
+
+namespace rpc {
+class Messenger;
+class ProxyCache;
+class SecureContext;
+}  // namespace rpc
+
+namespace client {
+class YBClient;
+
+// A wrapper over YbClient to handle xCluster related RPCs sent to a different yb universe.
+// This class performs serialization of C++ objects to PBs and vice versa.
+class XClusterRemoteClient {
+ public:
+  XClusterRemoteClient(const std::string& certs_for_cdc_dir, MonoDelta timeout);
+  virtual ~XClusterRemoteClient();
+
+  virtual Status Init(
+      const xcluster::ReplicationGroupId& replication_group_id,
+      const std::vector<HostPort>& remote_masters);
+
+  YB_STRONGLY_TYPED_BOOL(Transactional);
+  // This requires flag enable_xcluster_api_v2 to be set.
+  virtual Result<UniverseUuid> SetupUniverseReplication(
+      const xcluster::ReplicationGroupId& replication_group_id,
+      const std::vector<HostPort>& source_master_addresses,
+      const std::vector<NamespaceName>& namespace_names,
+      const std::vector<TableId>& source_table_ids,
+      const std::vector<xrepl::StreamId>& bootstrap_ids, Transactional transactional);
+
+  virtual Result<master::IsOperationDoneResult> IsSetupUniverseReplicationDone(
+      const xcluster::ReplicationGroupId& replication_group_id);
+
+ private:
+  const std::string certs_for_cdc_dir_;
+  const MonoDelta timeout_;
+  std::unique_ptr<rpc::SecureContext> secure_context_;
+  std::unique_ptr<rpc::Messenger> messenger_;
+
+  std::unique_ptr<client::YBClient> yb_client_;
+};
+
+}  // namespace client
+}  // namespace yb
diff --git a/src/yb/integration-tests/CMakeLists.txt b/src/yb/integration-tests/CMakeLists.txt
index d1c40405e0..396c5a4d04 100644
--- a/src/yb/integration-tests/CMakeLists.txt
+++ b/src/yb/integration-tests/CMakeLists.txt
@@ -218,6 +218,7 @@ ADD_YB_TEST(transaction-test)
 ADD_YB_TEST(encryption-test)
 ADD_YB_TEST(secure_connection_test)
 ADD_YB_TEST(xcluster/xcluster_consistency-test)
+ADD_YB_TEST(xcluster/xcluster_db_scope-test)
 ADD_YB_TEST(xcluster/xcluster_dr-itest)
 ADD_YB_TEST(xcluster/xcluster_upgrade-test)
 ADD_YB_TEST(xcluster/xcluster_safe_time-itest)
diff --git a/src/yb/integration-tests/xcluster/xcluster_db_scope-test.cc b/src/yb/integration-tests/xcluster/xcluster_db_scope-test.cc
new file mode 100644
index 0000000000..56c71e9922
--- /dev/null
+++ b/src/yb/integration-tests/xcluster/xcluster_db_scope-test.cc
@@ -0,0 +1,155 @@
+// Copyright (c) YugabyteDB, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
+// in compliance with the License.  You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software distributed under the License
+// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+// or implied.  See the License for the specific language governing permissions and limitations
+// under the License.
+//
+
+#include "yb/client/table.h"
+#include "yb/integration-tests/xcluster/xcluster_ysql_test_base.h"
+#include "yb/master/master_replication.proxy.h"
+#include "yb/master/mini_master.h"
+#include "yb/util/backoff_waiter.h"
+
+DECLARE_bool(TEST_enable_xcluster_api_v2);
+
+using namespace std::chrono_literals;
+
+namespace yb {
+
+const MonoDelta kTimeout = 60s * kTimeMultiplier;
+
+class XClusterDBScopedTest : public XClusterYsqlTestBase {
+ public:
+  struct SetupParams {
+    std::vector<uint32_t> num_consumer_tablets = {3};
+    std::vector<uint32_t> num_producer_tablets = {3};
+    uint32_t replication_factor = 3;
+    uint32_t num_masters = 1;
+    bool ranged_partitioned = false;
+  };
+
+  XClusterDBScopedTest() = default;
+  ~XClusterDBScopedTest() = default;
+
+  virtual void SetUp() override {
+    XClusterYsqlTestBase::SetUp();
+    ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_enable_xcluster_api_v2) = true;
+  }
+
+  Status SetUpClusters() {
+    static const SetupParams kDefaultParams;
+    return SetUpClusters(kDefaultParams);
+  }
+
+  Status SetUpClusters(const SetupParams& params) {
+    return XClusterYsqlTestBase::SetUpWithParams(
+        params.num_consumer_tablets, params.num_producer_tablets, params.replication_factor,
+        params.num_masters, params.ranged_partitioned);
+  }
+
+  Result<master::MasterReplicationProxy> GetMasterProxy(Cluster& cluster) {
+    return master::MasterReplicationProxy(
+        &cluster.client_->proxy_cache(),
+        VERIFY_RESULT(cluster.mini_cluster_->GetLeaderMiniMaster())->bound_rpc_addr());
+  }
+
+  Result<master::MasterReplicationProxy> GetProducerMasterProxy() {
+    return GetMasterProxy(producer_cluster_);
+  }
+
+  Status CheckpointReplicationGroup() {
+    auto producer_namespace_id = VERIFY_RESULT(GetNamespaceId(producer_client()));
+    auto namespace_id_out = VERIFY_RESULT(producer_client()->XClusterCreateOutboundReplicationGroup(
+        kReplicationGroupId, {namespace_name}));
+    SCHECK_EQ(namespace_id_out.size(), 1, IllegalState, "Namespace count does not match");
+    SCHECK_EQ(
+        namespace_id_out[0], producer_namespace_id, IllegalState, "NamespaceId does not match");
+
+    std::promise<Result<bool>> promise;
+    auto future = promise.get_future();
+    RETURN_NOT_OK(producer_client()->IsXClusterBootstrapRequired(
+        CoarseMonoClock::now() + kTimeout, kReplicationGroupId, producer_namespace_id,
+        [&promise](Result<bool> res) { promise.set_value(res); }));
+    auto bootstrap_required = VERIFY_RESULT(future.get());
+    SCHECK(!bootstrap_required, IllegalState, "Bootstrap should not be required");
+
+    return Status::OK();
+  }
+
+  Result<bool> IsCreateXClusterReplicationDone() {
+    master::IsCreateXClusterReplicationDoneRequestPB req;
+    master::IsCreateXClusterReplicationDoneResponsePB resp;
+    req.set_replication_group_id(kReplicationGroupId.ToString());
+    auto master_addr = consumer_cluster()->GetMasterAddresses();
+    auto hp_vec = VERIFY_RESULT(HostPort::ParseStrings(master_addr, 0));
+    HostPortsToPBs(hp_vec, req.mutable_target_master_addresses());
+
+    auto master_proxy = VERIFY_RESULT(GetProducerMasterProxy());
+
+    rpc::RpcController rpc;
+    rpc.set_timeout(MonoDelta::FromSeconds(kRpcTimeout));
+
+    RETURN_NOT_OK(master_proxy.IsCreateXClusterReplicationDone(req, &resp, &rpc));
+
+    if (resp.has_error()) {
+      return StatusFromPB(resp.error().status());
+    }
+
+    return resp.done();
+  }
+
+  Status WaitForCreateReplicationToFinish() {
+    return WaitFor([this]() { return IsCreateXClusterReplicationDone(); }, kTimeout, __func__);
+  }
+
+  Status CreateReplicationFromCheckpoint() {
+    RETURN_NOT_OK(SetupCertificates(kReplicationGroupId));
+
+    master::CreateXClusterReplicationRequestPB req;
+    master::CreateXClusterReplicationResponsePB resp;
+    req.set_replication_group_id(kReplicationGroupId.ToString());
+    auto master_addr = consumer_cluster()->GetMasterAddresses();
+    auto hp_vec = VERIFY_RESULT(HostPort::ParseStrings(master_addr, 0));
+    HostPortsToPBs(hp_vec, req.mutable_target_master_addresses());
+
+    auto master_proxy = VERIFY_RESULT(GetProducerMasterProxy());
+
+    rpc::RpcController rpc;
+    rpc.set_timeout(MonoDelta::FromSeconds(kRpcTimeout));
+
+    RETURN_NOT_OK(master_proxy.CreateXClusterReplication(req, &resp, &rpc));
+
+    if (resp.has_error()) {
+      return StatusFromPB(resp.error().status());
+    }
+
+    return WaitForCreateReplicationToFinish();
+  }
+};
+
+TEST_F(XClusterDBScopedTest, TestCreateWithCheckpoint) {
+  ASSERT_OK(SetUpClusters());
+
+  ASSERT_OK(CheckpointReplicationGroup());
+  ASSERT_OK(CreateReplicationFromCheckpoint());
+
+  // Verify that universe was setup on consumer.
+  master::GetUniverseReplicationResponsePB resp;
+  ASSERT_OK(VerifyUniverseReplication(&resp));
+  ASSERT_EQ(resp.entry().replication_group_id(), kReplicationGroupId);
+  ASSERT_EQ(resp.entry().tables_size(), 1);
+  ASSERT_EQ(resp.entry().tables(0), producer_table_->id());
+
+  ASSERT_OK(InsertRowsInProducer(0, 50));
+
+  ASSERT_OK(VerifyWrittenRecords());
+}
+
+}  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_test_base.cc b/src/yb/integration-tests/xcluster/xcluster_test_base.cc
index 36d9fd4b56..2c4dfda399 100644
--- a/src/yb/integration-tests/xcluster/xcluster_test_base.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_test_base.cc
@@ -281,11 +281,8 @@ Status XClusterTestBase::SetupUniverseReplication(
       bootstrap_ids, opts);
 }
 
-Status XClusterTestBase::SetupUniverseReplication(
-    MiniCluster* producer_cluster, MiniCluster* consumer_cluster, YBClient* consumer_client,
-    const xcluster::ReplicationGroupId& replication_group_id,
-    const std::vector<TableId>& producer_table_ids,
-    const std::vector<xrepl::StreamId>& bootstrap_ids, SetupReplicationOptions opts) {
+Status XClusterTestBase::SetupCertificates(
+    const xcluster::ReplicationGroupId& replication_group_id) {
   // If we have certs for encryption in FLAGS_certs_dir then we need to copy it over to the
   // replication_group_id subdirectory in FLAGS_certs_for_cdc_dir.
   if (!FLAGS_certs_for_cdc_dir.empty() && !FLAGS_certs_dir.empty()) {
@@ -301,6 +298,16 @@ Status XClusterTestBase::SetupUniverseReplication(
     LOG(INFO) << "Copied certs from " << FLAGS_certs_dir << " to " << universe_sub_dir;
   }
 
+  return Status::OK();
+}
+
+Status XClusterTestBase::SetupUniverseReplication(
+    MiniCluster* producer_cluster, MiniCluster* consumer_cluster, YBClient* consumer_client,
+    const xcluster::ReplicationGroupId& replication_group_id,
+    const std::vector<TableId>& producer_table_ids,
+    const std::vector<xrepl::StreamId>& bootstrap_ids, SetupReplicationOptions opts) {
+  RETURN_NOT_OK(SetupCertificates(replication_group_id));
+
   master::SetupUniverseReplicationRequestPB req;
   master::SetupUniverseReplicationResponsePB resp;
 
diff --git a/src/yb/integration-tests/xcluster/xcluster_test_base.h b/src/yb/integration-tests/xcluster/xcluster_test_base.h
index fcb11bbc2e..9b5ab510b6 100644
--- a/src/yb/integration-tests/xcluster/xcluster_test_base.h
+++ b/src/yb/integration-tests/xcluster/xcluster_test_base.h
@@ -331,6 +331,8 @@ class XClusterTestBase : public YBTest {
     return CoarseMonoClock::Now() + propagation_timeout_;
   }
 
+  Status SetupCertificates(const xcluster::ReplicationGroupId& replication_group_id);
+
   Cluster producer_cluster_;
   Cluster consumer_cluster_;
   MonoDelta propagation_timeout_;
diff --git a/src/yb/integration-tests/xcluster/xcluster_ysql-test.cc b/src/yb/integration-tests/xcluster/xcluster_ysql-test.cc
index 784bb2f93d..a20739701b 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ysql-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ysql-test.cc
@@ -155,38 +155,6 @@ class XClusterYsqlTest : public XClusterYsqlTestBase {
       std::vector<uint32_t> consumer_tablet_counts, std::vector<uint32_t> producer_tablet_counts,
       uint32_t num_tablet_servers = 1, bool range_partitioned = false);
 
-  Status SetUpWithParams(
-      const std::vector<uint32_t>& num_consumer_tablets,
-      const std::vector<uint32_t>& num_producer_tablets, uint32_t replication_factor,
-      uint32_t num_masters = 1, const bool ranged_partitioned = false) {
-    RETURN_NOT_OK(Initialize(replication_factor, num_masters));
-
-    SCHECK_EQ(
-        num_consumer_tablets.size(), num_producer_tablets.size(), IllegalState,
-        Format(
-            "Num consumer tables: $0 num producer tables: $1 must be equal.",
-            num_consumer_tablets.size(), num_producer_tablets.size()));
-
-    RETURN_NOT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
-      const auto* num_tablets = &num_producer_tablets;
-      if (cluster == &consumer_cluster_) {
-        num_tablets = &num_consumer_tablets;
-      }
-
-      for (uint32_t i = 0; i < num_tablets->size(); i++) {
-        auto table_name = VERIFY_RESULT(CreateYsqlTable(
-            i, num_tablets->at(i), cluster, boost::none /* tablegroup */, false /* colocated */,
-            ranged_partitioned));
-        std::shared_ptr<client::YBTable> table;
-        RETURN_NOT_OK(cluster->client_->OpenTable(table_name, &table));
-        cluster->tables_.push_back(table);
-      }
-      return Status::OK();
-    }));
-
-    return PostSetUp();
-  }
-
   std::string GetCompleteTableName(const YBTableName& table) {
     // Append schema name before table name, if schema is available.
     return table.has_pgschema_name() ? Format("$0.$1", table.pgschema_name(), table.table_name())
diff --git a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.cc b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.cc
index fd0422b2a5..11f9258d91 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.cc
@@ -766,4 +766,37 @@ void XClusterYsqlTestBase::TestReplicationWithSchemaChanges(
   ASSERT_OK(InsertRowsInProducer(301, 350));
   ASSERT_OK(VerifyWrittenRecords());
 }
+
+Status XClusterYsqlTestBase::SetUpWithParams(
+    const std::vector<uint32_t>& num_consumer_tablets,
+    const std::vector<uint32_t>& num_producer_tablets, uint32_t replication_factor,
+    uint32_t num_masters, const bool ranged_partitioned) {
+  RETURN_NOT_OK(Initialize(replication_factor, num_masters));
+
+  SCHECK_EQ(
+      num_consumer_tablets.size(), num_producer_tablets.size(), IllegalState,
+      Format(
+          "Num consumer tables: $0 num producer tables: $1 must be equal.",
+          num_consumer_tablets.size(), num_producer_tablets.size()));
+
+  RETURN_NOT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
+    const auto* num_tablets = &num_producer_tablets;
+    if (cluster == &consumer_cluster_) {
+      num_tablets = &num_consumer_tablets;
+    }
+
+    for (uint32_t i = 0; i < num_tablets->size(); i++) {
+      auto table_name = VERIFY_RESULT(CreateYsqlTable(
+          i, num_tablets->at(i), cluster, boost::none /* tablegroup */, false /* colocated */,
+          ranged_partitioned));
+      std::shared_ptr<client::YBTable> table;
+      RETURN_NOT_OK(cluster->client_->OpenTable(table_name, &table));
+      cluster->tables_.push_back(table);
+    }
+    return Status::OK();
+  }));
+
+  return PostSetUp();
+}
+
 }  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
index 77d7134667..c8442415b9 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
+++ b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
@@ -22,6 +22,12 @@ class XClusterYsqlTestBase : public XClusterTestBase {
  public:
   void SetUp() override;
   Status InitClusters(const MiniClusterOptions& opts) override;
+
+  Status SetUpWithParams(
+      const std::vector<uint32_t>& num_consumer_tablets,
+      const std::vector<uint32_t>& num_producer_tablets, uint32_t replication_factor,
+      uint32_t num_masters = 1, const bool ranged_partitioned = false);
+
   Status InitProducerClusterOnly(const MiniClusterOptions& opts);
   Status Initialize(uint32_t replication_factor, uint32_t num_masters = 1);
 
diff --git a/src/yb/master/catalog_entity_info.proto b/src/yb/master/catalog_entity_info.proto
index dfdc22b853..4f4a37634b 100644
--- a/src/yb/master/catalog_entity_info.proto
+++ b/src/yb/master/catalog_entity_info.proto
@@ -21,6 +21,7 @@ import "yb/cdc/xcluster_producer.proto";
 import "yb/common/common.proto";
 import "yb/common/common_net.proto";
 import "yb/common/common_types.proto";
+import "yb/common/wire_protocol.proto";
 import "yb/consensus/metadata.proto";
 import "yb/master/master_types.proto";
 
@@ -635,6 +636,16 @@ message SysUniverseReplicationEntryPB {
   optional bool transactional = 11; // [default = false]
 
   optional uint32 validated_local_auto_flags_config_version = 12;
+
+  // DB Scoped repication.
+  message DBScopeInfo {
+    message NamespaceInfo {
+      required string consumer_namespace_id = 1;
+      required string producer_namespace_id = 2;
+    }
+    repeated NamespaceInfo namespace_infos = 13;
+  }
+  optional DBScopeInfo db_scoped_info = 13;
 }
 
 message XClusterSafeTimePB {
@@ -765,6 +776,9 @@ message SysXClusterOutboundReplicationGroupEntryPB {
     message TableInfoPB {
       optional bytes stream_id = 1;
       optional bool is_checkpointing = 2; // [default = false]
+      // Was this stream checkpointed as part of the initial bootstrap, or was
+      // it added later by a newly created table?
+      optional bool is_part_of_initial_bootstrap = 3;
     }
     // Table id -> TableInfoPB
     map<string, TableInfoPB> table_infos = 2;
@@ -774,4 +788,25 @@ message SysXClusterOutboundReplicationGroupEntryPB {
 
   // Namespace Id -> NamespaceInfoPB
   map<string, NamespaceInfoPB> namespace_infos = 1;
+
+  message TargetUniverseInfo {
+    required bytes universe_uuid = 1;
+
+    enum State {
+      CREATING_REPLICATION_GROUP = 0;
+      FAILED = 1;
+      REPLICATING = 2;
+    }
+    required State state = 2 [ default = CREATING_REPLICATION_GROUP ];
+
+    optional AppStatusPB error_status = 3; // Set when status is FAILED
+  }
+
+  optional TargetUniverseInfo target_universe_info = 2;
+
+  enum State {
+    READY = 0;
+    DELETED = 1;
+  }
+  optional State state = 3 [ default = READY ];
 }
diff --git a/src/yb/master/catalog_manager.cc b/src/yb/master/catalog_manager.cc
index f30cb165d6..99e5fcf986 100644
--- a/src/yb/master/catalog_manager.cc
+++ b/src/yb/master/catalog_manager.cc
@@ -1684,6 +1684,18 @@ Status CatalogManager::GetUniverseKeyRegistryFromOtherMastersAsync() {
   return Status::OK();
 }
 
+Result<std::vector<HostPort>> CatalogManager::GetMasterAddressHostPorts() {
+  std::vector<HostPort> result;
+  consensus::ConsensusStatePB state;
+  RETURN_NOT_OK(GetCurrentConfig(&state));
+
+  for (const auto& peer : state.config().peers()) {
+    HostPortsFromPBs(peer.last_known_private_addr(), &result);
+    HostPortsFromPBs(peer.last_known_broadcast_addr(), &result);
+  }
+  return result;
+}
+
 std::vector<std::string> CatalogManager::GetMasterAddresses() {
   std::vector<std::string> result;
   consensus::ConsensusStatePB state;
diff --git a/src/yb/master/catalog_manager.h b/src/yb/master/catalog_manager.h
index d28e2d8cb1..ba20766dd2 100644
--- a/src/yb/master/catalog_manager.h
+++ b/src/yb/master/catalog_manager.h
@@ -1144,6 +1144,7 @@ class CatalogManager : public tserver::TabletPeerLookupIf,
   Status GetUniverseKeyRegistryFromOtherMastersAsync();
 
   std::vector<std::string> GetMasterAddresses();
+  Result<std::vector<HostPort>> GetMasterAddressHostPorts();
 
   // Returns true if there is at-least one snapshot schedule on any database/keyspace
   // in the cluster.
@@ -2959,6 +2960,8 @@ class CatalogManager : public tserver::TabletPeerLookupIf,
   Result<scoped_refptr<UniverseReplicationInfo>> CreateUniverseReplicationInfoForProducer(
       const xcluster::ReplicationGroupId& replication_group_id,
       const google::protobuf::RepeatedPtrField<HostPortPB>& master_addresses,
+      const std::vector<NamespaceId>& producer_namespace_ids,
+      const std::vector<NamespaceId>& consumer_namespace_ids,
       const google::protobuf::RepeatedPtrField<std::string>& table_ids, bool transactional);
 
   Result<scoped_refptr<UniverseReplicationBootstrapInfo>>
diff --git a/src/yb/master/master_replication.proto b/src/yb/master/master_replication.proto
index c9249b3156..e483d9445d 100644
--- a/src/yb/master/master_replication.proto
+++ b/src/yb/master/master_replication.proto
@@ -265,10 +265,16 @@ message SetupUniverseReplicationRequestPB {
   repeated string producer_bootstrap_ids = 4;
   // Is the created replication group transactionally consistent.
   optional bool transactional = 5; // [default = false]
+
+  // Used for DB Scoped replication.
+  repeated string namespace_names = 6; // YSQL database names.
+  repeated string producer_namespace_ids = 7;
 }
 
 message SetupUniverseReplicationResponsePB {
   optional MasterErrorPB error = 1;
+
+  optional string universe_uuid = 2;
 }
 
 message DeleteUniverseReplicationRequestPB {
@@ -580,6 +586,32 @@ message GetXClusterStreamsResponsePB {
   repeated TableInfo table_infos = 4;
 }
 
+message CreateXClusterReplicationRequestPB {
+  required string replication_group_id = 1;
+
+  repeated HostPortPB target_master_addresses = 2;
+}
+
+message CreateXClusterReplicationResponsePB {
+  optional MasterErrorPB error = 1;
+}
+
+message IsCreateXClusterReplicationDoneRequestPB {
+  required string replication_group_id = 1;
+
+  repeated HostPortPB target_master_addresses = 2;
+}
+
+message IsCreateXClusterReplicationDoneResponsePB {
+  optional MasterErrorPB error = 1;
+
+  optional bool done = 2; // [default = false]
+
+  // Only set when done is true. OK if the created succeeded or the error if it
+  // failed.
+  optional AppStatusPB replication_error = 3;
+}
+
 service MasterReplication {
   option (yb.rpc.custom_service_name) = "yb.master.MasterService";
 
@@ -668,4 +700,10 @@ service MasterReplication {
       returns (IsXClusterBootstrapRequiredResponsePB);
   rpc GetXClusterStreams(GetXClusterStreamsRequestPB)
       returns (GetXClusterStreamsResponsePB);
+
+  // xCluster APIsV2
+  rpc CreateXClusterReplication(CreateXClusterReplicationRequestPB)
+      returns (CreateXClusterReplicationResponsePB);
+  rpc IsCreateXClusterReplicationDone(IsCreateXClusterReplicationDoneRequestPB)
+      returns (IsCreateXClusterReplicationDoneResponsePB);
 }
diff --git a/src/yb/master/master_replication_service.cc b/src/yb/master/master_replication_service.cc
index 917bd34786..1ae5096a1c 100644
--- a/src/yb/master/master_replication_service.cc
+++ b/src/yb/master/master_replication_service.cc
@@ -69,6 +69,8 @@ class MasterReplicationServiceImpl : public MasterServiceBase, public MasterRepl
       (XClusterDeleteOutboundReplicationGroup)
       (IsXClusterBootstrapRequired)
       (GetXClusterStreams)
+      (CreateXClusterReplication)
+      (IsCreateXClusterReplicationDone)
   )
 };
 
diff --git a/src/yb/master/xcluster/master_xcluster_types.h b/src/yb/master/xcluster/master_xcluster_types.h
index 52d7d50e0d..23c55076bb 100644
--- a/src/yb/master/xcluster/master_xcluster_types.h
+++ b/src/yb/master/xcluster/master_xcluster_types.h
@@ -34,11 +34,14 @@ struct NamespaceCheckpointInfo {
     }
   };
   std::vector<TableInfo> table_infos;
+};
+
+struct IsOperationDoneResult {
+  IsOperationDoneResult() : done(false) {}
+  IsOperationDoneResult(bool done, Status status) : done(done), status(std::move(status)) {}
 
-  bool operator==(const NamespaceCheckpointInfo& rhs) const {
-    return initial_bootstrap_required == rhs.initial_bootstrap_required &&
-           table_infos == rhs.table_infos;
-  }
+  bool done;      // Indicates of the operation completed.
+  Status status;  // If the operation completed and it failed, this will contain the error.
 };
 
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_manager.cc b/src/yb/master/xcluster/xcluster_manager.cc
index 1ff17a9e2b..c3d45d31e2 100644
--- a/src/yb/master/xcluster/xcluster_manager.cc
+++ b/src/yb/master/xcluster/xcluster_manager.cc
@@ -240,6 +240,8 @@ Status XClusterManager::IsXClusterBootstrapRequired(
     rpc::RpcContext* rpc, const LeaderEpoch& epoch) {
   SCHECK(req->has_namespace_id(), InvalidArgument, "Namespace id must be specified");
 
+  LOG_FUNC_AND_RPC;
+
   auto bootstrap_required = VERIFY_RESULT(IsBootstrapRequired(
       xcluster::ReplicationGroupId(req->replication_group_id()), req->namespace_id()));
 
@@ -258,6 +260,8 @@ Status XClusterManager::GetXClusterStreams(
     rpc::RpcContext* rpc, const LeaderEpoch& epoch) {
   SCHECK(req->has_namespace_id(), InvalidArgument, "Namespace id must be specified");
 
+  LOG_FUNC_AND_RPC;
+
   std::vector<std::pair<TableName, PgSchemaName>> table_names;
   for (const auto& table_name : req->table_infos()) {
     table_names.emplace_back(table_name.table_name(), table_name.pg_schema_name());
@@ -283,6 +287,37 @@ Status XClusterManager::GetXClusterStreams(
   return Status::OK();
 }
 
+Status XClusterManager::CreateXClusterReplication(
+    const CreateXClusterReplicationRequestPB* req, CreateXClusterReplicationResponsePB* resp,
+    rpc::RpcContext* rpc, const LeaderEpoch& epoch) {
+  LOG_FUNC_AND_RPC;
+
+  std::vector<HostPort> target_master_addresses;
+  HostPortsFromPBs(req->target_master_addresses(), &target_master_addresses);
+
+  return XClusterSourceManager::CreateXClusterReplication(
+      xcluster::ReplicationGroupId(req->replication_group_id()), target_master_addresses, epoch);
+}
+
+Status XClusterManager::IsCreateXClusterReplicationDone(
+    const IsCreateXClusterReplicationDoneRequestPB* req,
+    IsCreateXClusterReplicationDoneResponsePB* resp, rpc::RpcContext* rpc,
+    const LeaderEpoch& epoch) {
+  LOG_FUNC_AND_RPC;
+
+  std::vector<HostPort> target_master_addresses;
+  HostPortsFromPBs(req->target_master_addresses(), &target_master_addresses);
+
+  auto create_result = VERIFY_RESULT(XClusterSourceManager::IsCreateXClusterReplicationDone(
+      xcluster::ReplicationGroupId(req->replication_group_id()), target_master_addresses, epoch));
+
+  resp->set_done(create_result.done);
+  if (create_result.done) {
+    StatusToPB(create_result.status, resp->mutable_replication_error());
+  }
+  return Status::OK();
+}
+
 std::vector<std::shared_ptr<PostTabletCreateTaskBase>> XClusterManager::GetPostTabletCreateTasks(
     const TableInfoPtr& table_info, const LeaderEpoch& epoch) {
   std::vector<std::shared_ptr<PostTabletCreateTaskBase>> result;
diff --git a/src/yb/master/xcluster/xcluster_manager.h b/src/yb/master/xcluster/xcluster_manager.h
index 95f8124dcd..0256ae3714 100644
--- a/src/yb/master/xcluster/xcluster_manager.h
+++ b/src/yb/master/xcluster/xcluster_manager.h
@@ -117,6 +117,13 @@ class XClusterManager : public XClusterManagerIf,
   Status GetXClusterStreams(
       const GetXClusterStreamsRequestPB* req, GetXClusterStreamsResponsePB* resp,
       rpc::RpcContext* rpc, const LeaderEpoch& epoch);
+  Status CreateXClusterReplication(
+      const CreateXClusterReplicationRequestPB* req, CreateXClusterReplicationResponsePB* resp,
+      rpc::RpcContext* rpc, const LeaderEpoch& epoch);
+  Status IsCreateXClusterReplicationDone(
+      const IsCreateXClusterReplicationDoneRequestPB* req,
+      IsCreateXClusterReplicationDoneResponsePB* resp, rpc::RpcContext* rpc,
+      const LeaderEpoch& epoch);
 
   std::vector<std::shared_ptr<PostTabletCreateTaskBase>> GetPostTabletCreateTasks(
       const TableInfoPtr& table_info, const LeaderEpoch& epoch);
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
index 032d337b9a..e2551f605a 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
@@ -13,12 +13,88 @@
 
 #include "yb/master/xcluster/xcluster_outbound_replication_group.h"
 
+#include "yb/client/xcluster_client.h"
 #include "yb/master/catalog_entity_info.h"
 
 #include "yb/util/test_util.h"
 
 namespace yb::master {
 
+const UniverseUuid kTargetUniverseUuid = UniverseUuid::GenerateRandom();
+
+inline bool operator==(const NamespaceCheckpointInfo& lhs, const NamespaceCheckpointInfo& rhs) {
+  return YB_STRUCT_EQUALS(initial_bootstrap_required, table_infos);
+}
+
+class XClusterRemoteClientMocked : public client::XClusterRemoteClient {
+ public:
+  XClusterRemoteClientMocked() : client::XClusterRemoteClient("na", MonoDelta::kMax) {}
+
+  Status Init(
+      const xcluster::ReplicationGroupId& replication_group_id,
+      const std::vector<HostPort>& remote_masters) override {
+    return Status::OK();
+  }
+
+  Result<UniverseUuid> SetupUniverseReplication(
+      const xcluster::ReplicationGroupId& replication_group_id,
+      const std::vector<HostPort>& source_master_addresses,
+      const std::vector<NamespaceName>& namespace_names,
+      const std::vector<TableId>& source_table_ids,
+      const std::vector<xrepl::StreamId>& bootstrap_ids, Transactional transactional) override {
+    replication_group_id_ = replication_group_id;
+    source_master_addresses_ = source_master_addresses;
+    namespace_names_ = namespace_names;
+    source_table_ids_ = source_table_ids;
+    bootstrap_ids_ = bootstrap_ids;
+    transactional_ = transactional;
+
+    return kTargetUniverseUuid;
+  }
+
+  Result<IsOperationDoneResult> IsSetupUniverseReplicationDone(
+      const xcluster::ReplicationGroupId& replication_group_id) override {
+    return is_setup_universe_replication_done_;
+  }
+
+  xcluster::ReplicationGroupId replication_group_id_;
+  std::vector<HostPort> source_master_addresses_;
+  std::vector<NamespaceName> namespace_names_;
+  std::vector<TableId> source_table_ids_;
+  std::vector<xrepl::StreamId> bootstrap_ids_;
+  bool transactional_;
+
+  Result<IsOperationDoneResult> is_setup_universe_replication_done_ =
+      IsOperationDoneResult(true, Status::OK());
+};
+
+class XClusterOutboundReplicationGroupMocked : public XClusterOutboundReplicationGroup {
+ public:
+  explicit XClusterOutboundReplicationGroupMocked(
+      const xcluster::ReplicationGroupId& replication_group_id, HelperFunctions helper_functions)
+      : XClusterOutboundReplicationGroup(replication_group_id, {}, std::move(helper_functions)) {
+    remote_client_ = std::make_shared<XClusterRemoteClientMocked>();
+  }
+
+  void SetRemoteClient(std::shared_ptr<XClusterRemoteClientMocked> remote_client) {
+    remote_client_ = remote_client;
+  }
+
+  bool IsDeleted() const {
+    SharedLock m_l(mutex_);
+    return outbound_rg_info_->LockForRead()->pb.state() ==
+           SysXClusterOutboundReplicationGroupEntryPB::DELETED;
+  }
+
+ private:
+  virtual Result<std::shared_ptr<client::XClusterRemoteClient>> GetRemoteClient(
+      const std::vector<HostPort>& remote_masters) const override {
+    return remote_client_;
+  }
+
+  std::shared_ptr<XClusterRemoteClientMocked> remote_client_;
+};
+
 class XClusterOutboundReplicationGroupMockedTest : public YBTest {
  public:
   const NamespaceName kNamespaceName = "db1";
@@ -56,8 +132,9 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
     return table_info;
   }
 
-  XClusterOutboundReplicationGroup CreateReplicationGroup() {
-    return XClusterOutboundReplicationGroup(kReplicationGroupId, {}, helper_functions);
+  std::shared_ptr<XClusterOutboundReplicationGroupMocked> CreateReplicationGroup() {
+    return std::make_shared<XClusterOutboundReplicationGroupMocked>(
+        kReplicationGroupId, helper_functions);
   }
 
   xrepl::StreamId CreateXClusterStream(const TableId& table_id) {
@@ -75,6 +152,14 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
           [this](YQLDatabase db_type, const NamespaceName& namespace_name) {
             return namespace_ids[namespace_name];
           },
+      .get_namespace_name_func = [this](const NamespaceId& namespace_id) -> Result<NamespaceName> {
+        for (const auto& [name, id] : namespace_ids) {
+          if (id == namespace_id) {
+            return name;
+          }
+        }
+        return STATUS_FORMAT(NotFound, "Namespace $0 not found", namespace_id);
+      },
       .get_tables_func =
           [this](const NamespaceId& namespace_id) { return namespace_tables[namespace_id]; },
       .bootstrap_tables_func =
@@ -140,7 +225,8 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
 TEST_F(XClusterOutboundReplicationGroupMockedTest, TestMultipleTable) {
   CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName);
   CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2);
-  auto outbound_rg = CreateReplicationGroup();
+  auto outbound_rg_ptr = CreateReplicationGroup();
+  auto& outbound_rg = *outbound_rg_ptr;
 
   auto namespace_id = ASSERT_RESULT(outbound_rg.AddNamespace(kEpoch, kNamespaceName, kDeadline));
   ASSERT_EQ(namespace_id, kNamespaceId);
@@ -176,6 +262,10 @@ TEST_F(XClusterOutboundReplicationGroupMockedTest, TestMultipleTable) {
 
   ASSERT_OK(outbound_rg.Delete(kEpoch));
   ASSERT_FALSE(outbound_rg.GetNamespaceCheckpointInfo(kNamespaceId));
+  auto result = outbound_rg.GetMetadata();
+  ASSERT_NOK(result);
+  ASSERT_TRUE(result.status().IsNotFound());
+  ASSERT_TRUE(outbound_rg.IsDeleted());
 
   // We should have 0 streams now.
   ASSERT_TRUE(xcluster_streams.empty());
@@ -192,7 +282,8 @@ TEST_F(XClusterOutboundReplicationGroupMockedTest, AddDeleteNamespaces) {
   CreateTable(namespace_id_2, ns2_table_id_1, kTableName1, kPgSchemaName);
   CreateTable(namespace_id_2, ns2_table_id_2, kTableName2, kPgSchemaName);
 
-  auto outbound_rg = CreateReplicationGroup();
+  auto outbound_rg_ptr = CreateReplicationGroup();
+  auto& outbound_rg = *outbound_rg_ptr;
   auto out_namespace_id =
       ASSERT_RESULT(outbound_rg.AddNamespaces(kEpoch, {kNamespaceName}, kDeadline));
   ASSERT_EQ(out_namespace_id.size(), 1);
@@ -246,4 +337,66 @@ TEST_F(XClusterOutboundReplicationGroupMockedTest, AddDeleteNamespaces) {
   ASSERT_TRUE(xcluster_streams.empty());
 }
 
+TEST_F(XClusterOutboundReplicationGroupMockedTest, CreateTargetReplicationGroup) {
+  CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName);
+
+  auto outbound_rg_ptr = CreateReplicationGroup();
+  auto& outbound_rg = *outbound_rg_ptr;
+  auto remote_client = std::make_shared<XClusterRemoteClientMocked>();
+  outbound_rg.SetRemoteClient(remote_client);
+
+  ASSERT_OK(outbound_rg.AddNamespace(kEpoch, kNamespaceName, kDeadline));
+
+  ASSERT_OK(outbound_rg.CreateXClusterReplication({}, {}, kEpoch));
+
+  ASSERT_EQ(remote_client->replication_group_id_, kReplicationGroupId);
+  ASSERT_EQ(remote_client->namespace_names_, std::vector<NamespaceName>{kNamespaceName});
+  ASSERT_EQ(remote_client->source_table_ids_.size(), 1);
+  ASSERT_EQ(remote_client->source_table_ids_[0], kTableId1);
+  ASSERT_EQ(remote_client->bootstrap_ids_.size(), xcluster_streams.size());
+
+  remote_client->is_setup_universe_replication_done_ = IsOperationDoneResult(false, Status::OK());
+
+  auto create_result = ASSERT_RESULT(outbound_rg.IsCreateXClusterReplicationDone({}, kEpoch));
+  ASSERT_FALSE(create_result.done);
+
+  // Fail the Setup.
+  const auto error_str = "Failed by test";
+  remote_client->is_setup_universe_replication_done_ = STATUS(IllegalState, error_str);
+  auto result = outbound_rg.IsCreateXClusterReplicationDone({}, kEpoch);
+  ASSERT_NOK(result);
+  ASSERT_STR_CONTAINS(result.status().ToString(), error_str);
+
+  auto pb = ASSERT_RESULT(outbound_rg.GetMetadata());
+  ASSERT_TRUE(pb.has_target_universe_info());
+  ASSERT_EQ(pb.target_universe_info().universe_uuid(), kTargetUniverseUuid.ToString());
+  ASSERT_EQ(
+      pb.target_universe_info().state(),
+      SysXClusterOutboundReplicationGroupEntryPB::TargetUniverseInfo::CREATING_REPLICATION_GROUP);
+
+  remote_client->is_setup_universe_replication_done_ =
+      IsOperationDoneResult(true, STATUS(IllegalState, error_str));
+  create_result = ASSERT_RESULT(outbound_rg.IsCreateXClusterReplicationDone({}, kEpoch));
+  ASSERT_TRUE(create_result.done);
+  ASSERT_STR_CONTAINS(create_result.status.ToString(), error_str);
+
+  pb = ASSERT_RESULT(outbound_rg.GetMetadata());
+  ASSERT_FALSE(pb.has_target_universe_info());
+
+  // Success case.
+  remote_client->is_setup_universe_replication_done_ = IsOperationDoneResult(true, Status::OK());
+
+  ASSERT_OK(outbound_rg.CreateXClusterReplication({}, {}, kEpoch));
+  create_result = ASSERT_RESULT(outbound_rg.IsCreateXClusterReplicationDone({}, kEpoch));
+  ASSERT_TRUE(create_result.done);
+  ASSERT_OK(create_result.status);
+
+  pb = ASSERT_RESULT(outbound_rg.GetMetadata());
+  ASSERT_TRUE(pb.has_target_universe_info());
+  ASSERT_EQ(pb.target_universe_info().universe_uuid(), kTargetUniverseUuid.ToString());
+  ASSERT_EQ(
+      pb.target_universe_info().state(),
+      SysXClusterOutboundReplicationGroupEntryPB::TargetUniverseInfo::REPLICATING);
+}
+
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
index ba7848750a..021e5e4c4b 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
@@ -12,7 +12,12 @@
 //
 
 #include "yb/master/xcluster/xcluster_outbound_replication_group.h"
+#include "yb/client/xcluster_client.h"
 #include "yb/master/catalog_entity_info.h"
+#include "yb/master/xcluster_rpc_tasks.h"
+
+DECLARE_int32(cdc_read_rpc_timeout_ms);
+DECLARE_string(certs_for_cdc_dir);
 
 namespace yb::master {
 
@@ -38,8 +43,28 @@ XClusterOutboundReplicationGroup::XClusterOutboundReplicationGroup(
   outbound_rg_info_->Load(outbound_replication_group_pb);
 }
 
-SysXClusterOutboundReplicationGroupEntryPB XClusterOutboundReplicationGroup::GetMetadata() const {
+Result<XClusterOutboundReplicationGroupInfo::ReadLock>
+XClusterOutboundReplicationGroup::LockForRead() const {
   auto l = outbound_rg_info_->LockForRead();
+  SCHECK_NE(
+      l->pb.state(), SysXClusterOutboundReplicationGroupEntryPB::DELETED, NotFound,
+      ToString() + " is deleted");
+  return l;
+}
+
+Result<XClusterOutboundReplicationGroupInfo::WriteLock>
+XClusterOutboundReplicationGroup::LockForWrite() {
+  auto l = outbound_rg_info_->LockForWrite();
+  SCHECK_NE(
+      l->pb.state(), SysXClusterOutboundReplicationGroupEntryPB::DELETED, NotFound,
+      ToString() + " is deleted");
+  return l;
+}
+
+Result<SysXClusterOutboundReplicationGroupEntryPB> XClusterOutboundReplicationGroup::GetMetadata()
+    const {
+  SharedLock m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForRead());
   return l->pb;
 }
 
@@ -53,6 +78,9 @@ Status XClusterOutboundReplicationGroup::Upsert(
 Result<SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB>
 XClusterOutboundReplicationGroup::BootstrapTables(
     const std::vector<TableInfoPtr>& table_infos, CoarseTimePoint deadline) {
+  VLOG_WITH_PREFIX_AND_FUNC(1) << yb::ToString(table_infos);
+
+  SCHECK(!table_infos.empty(), InvalidArgument, "No tables to bootstrap");
   SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB ns_info;
   ns_info.set_state(SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB::CHECKPOINTING);
 
@@ -70,6 +98,7 @@ XClusterOutboundReplicationGroup::BootstrapTables(
 
     SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB::TableInfoPB table_info;
     table_info.set_stream_id(bootstrap_ids[i].ToString());
+    table_info.set_is_part_of_initial_bootstrap(true);
     ns_info.mutable_table_infos()->insert({table_infos[i]->id(), std::move(table_info)});
   }
 
@@ -83,8 +112,10 @@ Result<NamespaceId> XClusterOutboundReplicationGroup::AddNamespaceInternal(
     const NamespaceName& namespace_name, CoarseTimePoint deadline,
     XClusterOutboundReplicationGroupInfo::WriteLock& l) {
   SCHECK(!namespace_name.empty(), InvalidArgument, "Namespace name cannot be empty");
-  auto namespace_id =
-      VERIFY_RESULT(helper_functions_.get_namespace_id_func(YQL_DATABASE_PGSQL, namespace_name));
+  VLOG_WITH_PREFIX_AND_FUNC(1) << namespace_name;
+
+  auto namespace_id = VERIFY_RESULT(
+      helper_functions_.get_namespace_id_func(YQLDatabase::YQL_DATABASE_PGSQL, namespace_name));
 
   auto& outbound_group_pb = l.mutable_data()->pb;
 
@@ -104,7 +135,8 @@ Result<NamespaceId> XClusterOutboundReplicationGroup::AddNamespaceInternal(
 Result<std::vector<NamespaceId>> XClusterOutboundReplicationGroup::AddNamespaces(
     const LeaderEpoch& epoch, const std::vector<NamespaceName>& namespace_names,
     CoarseTimePoint deadline) {
-  auto l = outbound_rg_info_->LockForWrite();
+  std::lock_guard m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForWrite());
 
   std::vector<NamespaceId> namespace_ids;
   for (const auto& namespace_name : namespace_names) {
@@ -117,7 +149,8 @@ Result<std::vector<NamespaceId>> XClusterOutboundReplicationGroup::AddNamespaces
 
 Result<NamespaceId> XClusterOutboundReplicationGroup::AddNamespace(
     const LeaderEpoch& epoch, const NamespaceName& namespace_name, CoarseTimePoint deadline) {
-  auto l = outbound_rg_info_->LockForWrite();
+  std::lock_guard m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForWrite());
   auto namespace_id = VERIFY_RESULT(AddNamespaceInternal(namespace_name, deadline, l));
   RETURN_NOT_OK(Upsert(l, epoch));
 
@@ -159,7 +192,8 @@ Status XClusterOutboundReplicationGroup::DeleteNamespaceStreams(
 
 Status XClusterOutboundReplicationGroup::RemoveNamespace(
     const LeaderEpoch& epoch, const NamespaceId& namespace_id) {
-  auto l = outbound_rg_info_->LockForWrite();
+  std::lock_guard m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForWrite());
   auto& outbound_group_pb = l.mutable_data()->pb;
 
   RETURN_NOT_OK(DeleteNamespaceStreams(epoch, namespace_id, outbound_group_pb));
@@ -170,13 +204,15 @@ Status XClusterOutboundReplicationGroup::RemoveNamespace(
 }
 
 Status XClusterOutboundReplicationGroup::Delete(const LeaderEpoch& epoch) {
-  auto l = outbound_rg_info_->LockForWrite();
+  std::lock_guard m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForWrite());
   auto& outbound_group_pb = l.mutable_data()->pb;
 
   for (const auto& [namespace_id, _] : *outbound_group_pb.mutable_namespace_infos()) {
     RETURN_NOT_OK(DeleteNamespaceStreams(epoch, namespace_id, outbound_group_pb));
   }
   outbound_group_pb.mutable_namespace_infos()->clear();
+  outbound_group_pb.set_state(SysXClusterOutboundReplicationGroupEntryPB::DELETED);
 
   auto status = helper_functions_.delete_from_sys_catalog_func(epoch, outbound_rg_info_.get());
   l.CommitOrWarn(status, "updating xClusterOutboundReplicationGroup in sys-catalog");
@@ -186,15 +222,16 @@ Status XClusterOutboundReplicationGroup::Delete(const LeaderEpoch& epoch) {
 
 Result<std::optional<bool>> XClusterOutboundReplicationGroup::IsBootstrapRequired(
     const NamespaceId& namespace_id) const {
-  auto l = outbound_rg_info_->LockForRead();
+  SharedLock m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForRead());
   auto& outbound_group = l->pb;
   SCHECK(
       outbound_group.namespace_infos().count(namespace_id) > 0, NotFound,
       Format("Namespace $0 not found in $1", namespace_id, ToString()));
 
   auto& namespace_info = outbound_group.namespace_infos().at(namespace_id);
-  if (namespace_info.state() !=
-      SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB::READY) {
+  if (namespace_info.state() ==
+      SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB::CHECKPOINTING) {
     return std::nullopt;
   }
 
@@ -205,7 +242,8 @@ Result<std::optional<NamespaceCheckpointInfo>>
 XClusterOutboundReplicationGroup::GetNamespaceCheckpointInfo(
     const NamespaceId& namespace_id,
     const std::vector<std::pair<TableName, PgSchemaName>>& table_names) const {
-  auto l = outbound_rg_info_->LockForRead();
+  SharedLock m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForRead());
   auto& outbound_group = l->pb;
   SCHECK(
       outbound_group.namespace_infos().count(namespace_id) > 0, NotFound,
@@ -273,4 +311,123 @@ XClusterOutboundReplicationGroup::GetNamespaceCheckpointInfo(
   return ns_info;
 }
 
+Result<std::shared_ptr<client::XClusterRemoteClient>>
+XClusterOutboundReplicationGroup::GetRemoteClient(
+    const std::vector<HostPort>& remote_masters) const {
+  auto client = std::make_shared<client::XClusterRemoteClient>(
+      FLAGS_certs_for_cdc_dir, MonoDelta::FromMilliseconds(FLAGS_cdc_read_rpc_timeout_ms));
+  RETURN_NOT_OK(client->Init(Id(), remote_masters));
+  return client;
+}
+
+Status XClusterOutboundReplicationGroup::CreateXClusterReplication(
+    const std::vector<HostPort>& source_master_addresses,
+    const std::vector<HostPort>& target_master_addresses, const LeaderEpoch& epoch) {
+  std::lock_guard m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForWrite());
+  auto& outbound_group = l.mutable_data()->pb;
+
+  if (outbound_group.has_target_universe_info()) {
+    // Already exists.
+    // TODO(#20810): make sure master_addresses atleast partially overlap.
+    return Status::OK();
+  }
+
+  std::vector<NamespaceName> namespace_names;
+  std::vector<TableId> source_table_ids;
+  std::vector<xrepl::StreamId> bootstrap_ids;
+  for (const auto& [ns_id, ns_info] : outbound_group.namespace_infos()) {
+    SCHECK_EQ(
+        ns_info.state(), SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB::READY,
+        TryAgain, Format("Namespace $0 is not yet ready to start replicating", ns_id));
+
+    namespace_names.push_back(VERIFY_RESULT(helper_functions_.get_namespace_name_func(ns_id)));
+
+    auto all_tables = VERIFY_RESULT(helper_functions_.get_tables_func(ns_id));
+
+    for (const auto& [table_id, table_info] : ns_info.table_infos()) {
+      if (!table_info.is_part_of_initial_bootstrap()) {
+        // Only include tables that were part of the initial bootstrap as only those are backed up
+        // and restored on the target. The remaining will get added as DDLs execute.
+        continue;
+      }
+      // This is not expected since the namespace is marked ready.
+      RSTATUS_DCHECK(
+          !table_info.is_checkpointing(), IllegalState, Format("Table $0 is not yet ready"));
+
+      source_table_ids.push_back(table_id);
+      bootstrap_ids.push_back(VERIFY_RESULT(xrepl::StreamId::FromString(table_info.stream_id())));
+    }
+  }
+
+  auto remote_client = VERIFY_RESULT(GetRemoteClient(target_master_addresses));
+
+  auto target_uuid = VERIFY_RESULT(remote_client->SetupUniverseReplication(
+      Id(), source_master_addresses, namespace_names, source_table_ids, bootstrap_ids,
+      client::XClusterRemoteClient::Transactional::kTrue));
+
+  auto* target_universe_info = l.mutable_data()->pb.mutable_target_universe_info();
+
+  target_universe_info->set_universe_uuid(target_uuid.ToString());
+  target_universe_info->set_state(
+      SysXClusterOutboundReplicationGroupEntryPB::TargetUniverseInfo::CREATING_REPLICATION_GROUP);
+
+  RETURN_NOT_OK(Upsert(l, epoch));
+
+  // TODO(#20810): Start a async task that will poll for IsCreateXClusterReplicationDone and update
+  // the state.
+
+  return Status::OK();
+}
+
+Result<IsOperationDoneResult> XClusterOutboundReplicationGroup::IsCreateXClusterReplicationDone(
+    const std::vector<HostPort>& target_master_addresses, const LeaderEpoch& epoch) {
+  std::lock_guard m_l(mutex_);
+  auto l = VERIFY_RESULT(LockForWrite());
+  auto& outbound_group = l.mutable_data()->pb;
+  SCHECK(outbound_group.has_target_universe_info(), IllegalState, "Target universe info not found");
+
+  auto& target_universe = *outbound_group.mutable_target_universe_info();
+
+  if (target_universe.state() ==
+      SysXClusterOutboundReplicationGroupEntryPB::TargetUniverseInfo::REPLICATING) {
+    return IsOperationDoneResult(true, Status::OK());
+  }
+
+  IsOperationDoneResult setup_result;
+  if (target_universe.state() ==
+      SysXClusterOutboundReplicationGroupEntryPB_TargetUniverseInfo::FAILED) {
+    setup_result.done = true;
+    if (target_universe.has_error_status()) {
+      setup_result.status = StatusFromPB(target_universe.error_status());
+    } else {
+      setup_result.status = STATUS(
+          IllegalState, "Failed to create replication group on target cluster",
+          target_universe.universe_uuid());
+    }
+  } else {
+    // TODO(#20810): Remove this once async task that polls for IsCreateXClusterReplicationDone gets
+    // added.
+    auto remote_client = VERIFY_RESULT(GetRemoteClient(target_master_addresses));
+    setup_result = VERIFY_RESULT(remote_client->IsSetupUniverseReplicationDone(Id()));
+  }
+
+  if (!setup_result.done) {
+    return setup_result;
+  }
+
+  if (setup_result.status.ok()) {
+    target_universe.set_state(
+        SysXClusterOutboundReplicationGroupEntryPB::TargetUniverseInfo::REPLICATING);
+  } else {
+    LOG_WITH_PREFIX(WARNING) << "Failed to create replication group on target cluster: "
+                             << setup_result.status;
+    // Clear the target info so that it can be retried later.
+    outbound_group.clear_target_universe_info();
+  }
+  RETURN_NOT_OK(Upsert(l, epoch));
+
+  return setup_result;
+}
+
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group.h b/src/yb/master/xcluster/xcluster_outbound_replication_group.h
index a2930896df..1fc97bcc6f 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group.h
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group.h
@@ -16,14 +16,25 @@
 #include "yb/master/xcluster/master_xcluster_types.h"
 #include "yb/master/xcluster/xcluster_catalog_entity.h"
 
+#include "yb/cdc/xcluster_types.h"
+
+#include "yb/gutil/thread_annotations.h"
+
 namespace yb {
+
+namespace client {
+class XClusterRemoteClient;
+}  // namespace client
+
 namespace master {
 
-class XClusterOutboundReplicationGroup {
+class XClusterOutboundReplicationGroup
+    : public std::enable_shared_from_this<XClusterOutboundReplicationGroup> {
  public:
   struct HelperFunctions {
     const std::function<Result<NamespaceId>(YQLDatabase, const NamespaceName&)>
         get_namespace_id_func;
+    const std::function<Result<NamespaceName>(const NamespaceId&)> get_namespace_name_func;
     const std::function<Result<std::vector<TableInfoPtr>>(const NamespaceId&)> get_tables_func;
     const std::function<Result<std::vector<xrepl::StreamId>>(
         const std::vector<TableInfoPtr>&, CoarseTimePoint)>
@@ -44,52 +55,85 @@ class XClusterOutboundReplicationGroup {
       const SysXClusterOutboundReplicationGroupEntryPB& outbound_replication_group_pb,
       HelperFunctions helper_functions);
 
+  virtual ~XClusterOutboundReplicationGroup() = default;
+
   const xcluster::ReplicationGroupId& Id() const { return outbound_rg_info_->ReplicationGroupId(); }
 
   std::string ToString() const { return Format("xClusterOutboundReplicationGroup $0", Id()); }
-  std::string LogPrefix() const { return ToString(); }
+  std::string LogPrefix() const { return Format("$0 :", ToString()); }
+
+  Result<SysXClusterOutboundReplicationGroupEntryPB> GetMetadata() const EXCLUDES(mutex_);
 
   SysXClusterOutboundReplicationGroupEntryPB GetMetadata() const;
 
   Result<std::vector<NamespaceId>> AddNamespaces(
       const LeaderEpoch& epoch, const std::vector<NamespaceName>& namespace_names,
-      CoarseTimePoint deadline);
+      CoarseTimePoint deadline) EXCLUDES(mutex_);
 
   Result<NamespaceId> AddNamespace(
-      const LeaderEpoch& epoch, const NamespaceName& namespace_name, CoarseTimePoint deadline);
+      const LeaderEpoch& epoch, const NamespaceName& namespace_name, CoarseTimePoint deadline)
+      EXCLUDES(mutex_);
 
-  Status RemoveNamespace(const LeaderEpoch& epoch, const NamespaceId& namespace_id);
+  Status RemoveNamespace(const LeaderEpoch& epoch, const NamespaceId& namespace_id)
+      EXCLUDES(mutex_);
 
-  Status Delete(const LeaderEpoch& epoch);
+  Status Delete(const LeaderEpoch& epoch) EXCLUDES(mutex_);
 
   // Returns std::nullopt if the namespace is not yet ready.
-  Result<std::optional<bool>> IsBootstrapRequired(const NamespaceId& namespace_id) const;
+  Result<std::optional<bool>> IsBootstrapRequired(const NamespaceId& namespace_id) const
+      EXCLUDES(mutex_);
 
   using TableSchemaNamePair = std::pair<TableName, PgSchemaName>;
 
   // Returns std::nullopt if the namespace is not yet ready.
   Result<std::optional<NamespaceCheckpointInfo>> GetNamespaceCheckpointInfo(
       const NamespaceId& namespace_id,
-      const std::vector<TableSchemaNamePair>& table_names = {}) const;
+      const std::vector<TableSchemaNamePair>& table_names = {}) const EXCLUDES(mutex_);
+
+  Status CreateXClusterReplication(
+      const std::vector<HostPort>& source_master_addresses,
+      const std::vector<HostPort>& target_master_addresses, const LeaderEpoch& epoch)
+      EXCLUDES(mutex_);
+
+  Result<IsOperationDoneResult> IsCreateXClusterReplicationDone(
+      const std::vector<HostPort>& target_master_addresses, const LeaderEpoch& epoch)
+      EXCLUDES(mutex_);
 
  private:
+  friend class XClusterOutboundReplicationGroupMocked;
+
+  // LockForRead and LockForWrite are used to get a read or write lock on the outbound_rg_info_ and
+  // ensure the group is not deleted.
+  // The normal Cow object XClusterOutboundReplicationGroupInfo read lock allows concurrent reads
+  // and writes. We do not want this behavior, so these functions are guarded with the mutex_.
+  Result<XClusterOutboundReplicationGroupInfo::ReadLock> LockForRead() const
+      REQUIRES_SHARED(mutex_);
+  Result<XClusterOutboundReplicationGroupInfo::WriteLock> LockForWrite() REQUIRES(mutex_);
+
   Result<NamespaceId> AddNamespaceInternal(
       const NamespaceName& namespace_name, CoarseTimePoint deadline,
-      XClusterOutboundReplicationGroupInfo::WriteLock& l);
+      XClusterOutboundReplicationGroupInfo::WriteLock& l) REQUIRES(mutex_);
 
-  Status Upsert(XClusterOutboundReplicationGroupInfo::WriteLock& l, const LeaderEpoch& epoch);
+  Status Upsert(XClusterOutboundReplicationGroupInfo::WriteLock& l, const LeaderEpoch& epoch)
+      REQUIRES(mutex_);
 
   // Deletes all the streams for the given namespace.
   Status DeleteNamespaceStreams(
       const LeaderEpoch& epoch, const NamespaceId& namespace_id,
-      const SysXClusterOutboundReplicationGroupEntryPB& pb);
+      const SysXClusterOutboundReplicationGroupEntryPB& pb) REQUIRES(mutex_);
 
   Result<SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB> BootstrapTables(
-      const std::vector<TableInfoPtr>& table_infos, CoarseTimePoint deadline);
+      const std::vector<TableInfoPtr>& table_infos, CoarseTimePoint deadline) REQUIRES(mutex_);
+
+  virtual Result<std::shared_ptr<client::XClusterRemoteClient>> GetRemoteClient(
+      const std::vector<HostPort>& remote_masters) const;
 
   HelperFunctions helper_functions_;
 
+  mutable std::shared_mutex mutex_;
   std::unique_ptr<XClusterOutboundReplicationGroupInfo> outbound_rg_info_;
+
+  DISALLOW_COPY_AND_ASSIGN(XClusterOutboundReplicationGroup);
 };
 
 }  // namespace master
diff --git a/src/yb/master/xcluster/xcluster_source_manager.cc b/src/yb/master/xcluster/xcluster_source_manager.cc
index 55fe518333..9e53e3077f 100644
--- a/src/yb/master/xcluster/xcluster_source_manager.cc
+++ b/src/yb/master/xcluster/xcluster_source_manager.cc
@@ -18,6 +18,7 @@
 #include "yb/master/xcluster/xcluster_catalog_entity.h"
 
 #include "yb/rpc/rpc_context.h"
+#include "yb/util/scope_exit.h"
 
 using namespace std::placeholders;
 
@@ -83,8 +84,12 @@ void XClusterSourceManager::DumpState(std::ostream& out, bool on_disk_dump) cons
   out << "XClusterOutboundReplicationGroups:\n";
 
   for (const auto& [replication_group_id, outbound_rg] : outbound_replication_group_map_) {
-    out << "  ReplicationGroupId: " << replication_group_id
-        << "\n  metadata: " << outbound_rg.GetMetadata().ShortDebugString() << "\n";
+    auto metadata = outbound_rg->GetMetadata();
+    if (metadata.ok()) {
+      out << "  ReplicationGroupId: " << replication_group_id
+          << "\n  metadata: " << metadata->ShortDebugString() << "\n";
+    }
+    // else deleted.
   }
 }
 
@@ -106,7 +111,8 @@ Status XClusterSourceManager::InsertOutboundReplicationGroup(
   return Status::OK();
 }
 
-XClusterOutboundReplicationGroup XClusterSourceManager::InitOutboundReplicationGroup(
+std::shared_ptr<XClusterOutboundReplicationGroup>
+XClusterSourceManager::InitOutboundReplicationGroup(
     const xcluster::ReplicationGroupId& replication_group_id,
     const SysXClusterOutboundReplicationGroupEntryPB& metadata) {
   XClusterOutboundReplicationGroup::HelperFunctions helper_functions = {
@@ -115,6 +121,10 @@ XClusterOutboundReplicationGroup XClusterSourceManager::InitOutboundReplicationG
               YQLDatabase db_type, const NamespaceName& namespace_name) {
             return catalog_manager.GetNamespaceId(db_type, namespace_name);
           },
+      .get_namespace_name_func =
+          [&catalog_manager = catalog_manager_](const NamespaceId& namespace_id) {
+            return catalog_manager.GetNamespaceName(namespace_id);
+          },
       .get_tables_func =
           [this](const NamespaceId& namespace_id) { return GetTablesToReplicate(namespace_id); },
       .bootstrap_tables_func =
@@ -141,25 +151,22 @@ XClusterOutboundReplicationGroup XClusterSourceManager::InitOutboundReplicationG
           },
   };
 
-  return XClusterOutboundReplicationGroup(
+  return std::make_shared<XClusterOutboundReplicationGroup>(
       replication_group_id, metadata, std::move(helper_functions));
 }
 
-Result<XClusterOutboundReplicationGroup*> XClusterSourceManager::GetOutboundReplicationGroup(
-    const xcluster::ReplicationGroupId& replication_group_id) {
-  return const_cast<XClusterOutboundReplicationGroup*>(
-      VERIFY_RESULT(const_cast<const XClusterSourceManager*>(this)->GetOutboundReplicationGroup(
-          replication_group_id)));
-}
-
-Result<const XClusterOutboundReplicationGroup*> XClusterSourceManager::GetOutboundReplicationGroup(
+Result<std::shared_ptr<XClusterOutboundReplicationGroup>>
+XClusterSourceManager::GetOutboundReplicationGroup(
     const xcluster::ReplicationGroupId& replication_group_id) const {
+  SharedLock l(outbound_replication_group_map_mutex_);
   auto outbound_replication_group =
       FindOrNull(outbound_replication_group_map_, replication_group_id);
+  // Value can be nullptr during create, before writing to sys_catalog. These should also be treated
+  // as NotFound.
   SCHECK(
-      outbound_replication_group, NotFound,
+      outbound_replication_group && *outbound_replication_group, NotFound,
       Format("xClusterOutboundReplicationGroup $0 not found", replication_group_id));
-  return outbound_replication_group;
+  return *outbound_replication_group;
 }
 
 Result<std::vector<TableInfoPtr>> XClusterSourceManager::GetTablesToReplicate(
@@ -216,20 +223,34 @@ Result<std::vector<NamespaceId>> XClusterSourceManager::CreateOutboundReplicatio
     const xcluster::ReplicationGroupId& replication_group_id,
     const std::vector<NamespaceName>& namespace_names, const LeaderEpoch& epoch,
     CoarseTimePoint deadline) {
-  std::lock_guard l(outbound_replication_group_map_mutex_);
-  SCHECK(
-      !outbound_replication_group_map_.contains(replication_group_id), IllegalState,
-      "xClusterOutboundReplicationGroup $0 already exists", replication_group_id);
+  {
+    std::lock_guard l(outbound_replication_group_map_mutex_);
+    SCHECK(
+        !outbound_replication_group_map_.contains(replication_group_id), IllegalState,
+        "xClusterOutboundReplicationGroup $0 already exists", replication_group_id);
+
+    // Insert a temporary nullptr in order to reserve the Id.
+    outbound_replication_group_map_.emplace(replication_group_id, nullptr);
+  }
+
+  // If we fail anywhere after this we need to return the Id we have reserved.
+  auto se = ScopeExit([this, &replication_group_id]() {
+    std::lock_guard l(outbound_replication_group_map_mutex_);
+    outbound_replication_group_map_.erase(replication_group_id);
+  });
 
   SysXClusterOutboundReplicationGroupEntryPB metadata;  // Empty metadata.
   auto outbound_replication_group = InitOutboundReplicationGroup(replication_group_id, metadata);
 
   // This will persist the group to SysCatalog.
   auto namespace_ids =
-      VERIFY_RESULT(outbound_replication_group.AddNamespaces(epoch, namespace_names, deadline));
+      VERIFY_RESULT(outbound_replication_group->AddNamespaces(epoch, namespace_names, deadline));
 
-  outbound_replication_group_map_.emplace(
-      replication_group_id, std::move(outbound_replication_group));
+  se.Cancel();
+  {
+    std::lock_guard l(outbound_replication_group_map_mutex_);
+    outbound_replication_group_map_[replication_group_id] = std::move(outbound_replication_group);
+  }
 
   return namespace_ids;
 }
@@ -237,7 +258,6 @@ Result<std::vector<NamespaceId>> XClusterSourceManager::CreateOutboundReplicatio
 Result<NamespaceId> XClusterSourceManager::AddNamespaceToOutboundReplicationGroup(
     const xcluster::ReplicationGroupId& replication_group_id, const NamespaceName& namespace_name,
     const LeaderEpoch& epoch, CoarseTimePoint deadline) {
-  std::lock_guard l(outbound_replication_group_map_mutex_);
   auto outbound_replication_group =
       VERIFY_RESULT(GetOutboundReplicationGroup(replication_group_id));
 
@@ -247,7 +267,6 @@ Result<NamespaceId> XClusterSourceManager::AddNamespaceToOutboundReplicationGrou
 Status XClusterSourceManager::RemoveNamespaceFromOutboundReplicationGroup(
     const xcluster::ReplicationGroupId& replication_group_id, const NamespaceId& namespace_id,
     const LeaderEpoch& epoch) {
-  std::lock_guard l(outbound_replication_group_map_mutex_);
   auto outbound_replication_group =
       VERIFY_RESULT(GetOutboundReplicationGroup(replication_group_id));
 
@@ -256,14 +275,16 @@ Status XClusterSourceManager::RemoveNamespaceFromOutboundReplicationGroup(
 
 Status XClusterSourceManager::DeleteOutboundReplicationGroup(
     const xcluster::ReplicationGroupId& replication_group_id, const LeaderEpoch& epoch) {
-  std::lock_guard l(outbound_replication_group_map_mutex_);
   auto outbound_replication_group =
       VERIFY_RESULT(GetOutboundReplicationGroup(replication_group_id));
 
   // This will remove the group from SysCatalog.
   RETURN_NOT_OK(outbound_replication_group->Delete(epoch));
 
-  outbound_replication_group_map_.erase(replication_group_id);
+  {
+    std::lock_guard l(outbound_replication_group_map_mutex_);
+    outbound_replication_group_map_.erase(replication_group_id);
+  }
 
   return Status::OK();
 }
@@ -271,10 +292,8 @@ Status XClusterSourceManager::DeleteOutboundReplicationGroup(
 Result<std::optional<bool>> XClusterSourceManager::IsBootstrapRequired(
     const xcluster::ReplicationGroupId& replication_group_id,
     const NamespaceId& namespace_id) const {
-  SharedLock l(outbound_replication_group_map_mutex_);
   auto outbound_replication_group =
-      VERIFY_RESULT(const_cast<const XClusterSourceManager*>(this)->GetOutboundReplicationGroup(
-          replication_group_id));
+      VERIFY_RESULT(GetOutboundReplicationGroup(replication_group_id));
 
   return outbound_replication_group->IsBootstrapRequired(namespace_id);
 }
@@ -282,11 +301,29 @@ Result<std::optional<bool>> XClusterSourceManager::IsBootstrapRequired(
 Result<std::optional<NamespaceCheckpointInfo>> XClusterSourceManager::GetXClusterStreams(
     const xcluster::ReplicationGroupId& replication_group_id, const NamespaceId& namespace_id,
     std::vector<std::pair<TableName, PgSchemaName>> opt_table_names) const {
-  SharedLock l(outbound_replication_group_map_mutex_);
   auto outbound_replication_group =
       VERIFY_RESULT(GetOutboundReplicationGroup(replication_group_id));
 
   return outbound_replication_group->GetNamespaceCheckpointInfo(namespace_id, opt_table_names);
 }
 
+Status XClusterSourceManager::CreateXClusterReplication(
+    const xcluster::ReplicationGroupId& replication_group_id,
+    const std::vector<HostPort>& target_master_addresses, const LeaderEpoch& epoch) {
+  auto source_master_addresses = VERIFY_RESULT(catalog_manager_.GetMasterAddressHostPorts());
+  auto outbound_replication_group =
+      VERIFY_RESULT(GetOutboundReplicationGroup(replication_group_id));
+  return outbound_replication_group->CreateXClusterReplication(
+      source_master_addresses, target_master_addresses, epoch);
+}
+
+Result<IsOperationDoneResult> XClusterSourceManager::IsCreateXClusterReplicationDone(
+    const xcluster::ReplicationGroupId& replication_group_id,
+    const std::vector<HostPort>& target_master_addresses, const LeaderEpoch& epoch) {
+  auto outbound_replication_group =
+      VERIFY_RESULT(GetOutboundReplicationGroup(replication_group_id));
+  return outbound_replication_group->IsCreateXClusterReplicationDone(
+      target_master_addresses, epoch);
+}
+
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_source_manager.h b/src/yb/master/xcluster/xcluster_source_manager.h
index 8993500dab..fd86a5d2b5 100644
--- a/src/yb/master/xcluster/xcluster_source_manager.h
+++ b/src/yb/master/xcluster/xcluster_source_manager.h
@@ -77,23 +77,27 @@ class XClusterSourceManager {
       const xcluster::ReplicationGroupId& replication_group_id, const NamespaceId& namespace_id,
       std::vector<std::pair<TableName, PgSchemaName>> opt_table_names) const;
 
+  Status CreateXClusterReplication(
+      const xcluster::ReplicationGroupId& replication_group_id,
+      const std::vector<HostPort>& target_master_addresses, const LeaderEpoch& epoch);
+
+  Result<IsOperationDoneResult> IsCreateXClusterReplicationDone(
+      const xcluster::ReplicationGroupId& replication_group_id,
+      const std::vector<HostPort>& target_master_addresses, const LeaderEpoch& epoch);
+
  private:
   Status InsertOutboundReplicationGroup(
       const std::string& replication_group_id,
       const SysXClusterOutboundReplicationGroupEntryPB& metadata)
       EXCLUDES(outbound_replication_group_map_mutex_);
 
-  XClusterOutboundReplicationGroup InitOutboundReplicationGroup(
+  std::shared_ptr<XClusterOutboundReplicationGroup> InitOutboundReplicationGroup(
       const xcluster::ReplicationGroupId& replication_group_id,
       const SysXClusterOutboundReplicationGroupEntryPB& metadata);
 
-  Result<XClusterOutboundReplicationGroup*> GetOutboundReplicationGroup(
-      const xcluster::ReplicationGroupId& replication_group_id)
-      REQUIRES(outbound_replication_group_map_mutex_);
-
-  Result<const XClusterOutboundReplicationGroup*> GetOutboundReplicationGroup(
+  Result<std::shared_ptr<XClusterOutboundReplicationGroup>> GetOutboundReplicationGroup(
       const xcluster::ReplicationGroupId& replication_group_id) const
-      REQUIRES_SHARED(outbound_replication_group_map_mutex_);
+      EXCLUDES(outbound_replication_group_map_mutex_);
 
   Result<std::vector<TableInfoPtr>> GetTablesToReplicate(const NamespaceId& namespace_id);
 
@@ -105,7 +109,10 @@ class XClusterSourceManager {
   SysCatalogTable& sys_catalog_;
 
   mutable std::shared_mutex outbound_replication_group_map_mutex_;
-  std::map<xcluster::ReplicationGroupId, XClusterOutboundReplicationGroup>
+  // Map of XClusterOutboundReplicationGroups.
+  // Value will be nullptr if the group is being created and not yet written to the sys_catalog.
+  // This is done to ensure multiple create operations on the same Id are not allowed.
+  std::map<xcluster::ReplicationGroupId, std::shared_ptr<XClusterOutboundReplicationGroup>>
       outbound_replication_group_map_ GUARDED_BY(outbound_replication_group_map_mutex_);
 
   DISALLOW_COPY_AND_ASSIGN(XClusterSourceManager);
diff --git a/src/yb/master/xrepl_catalog_manager.cc b/src/yb/master/xrepl_catalog_manager.cc
index a9496047a1..92ba9dc9ed 100644
--- a/src/yb/master/xrepl_catalog_manager.cc
+++ b/src/yb/master/xrepl_catalog_manager.cc
@@ -2568,7 +2568,13 @@ Result<scoped_refptr<UniverseReplicationInfo>>
 CatalogManager::CreateUniverseReplicationInfoForProducer(
     const xcluster::ReplicationGroupId& replication_group_id,
     const google::protobuf::RepeatedPtrField<HostPortPB>& master_addresses,
+    const std::vector<NamespaceId>& producer_namespace_ids,
+    const std::vector<NamespaceId>& consumer_namespace_ids,
     const google::protobuf::RepeatedPtrField<std::string>& table_ids, bool transactional) {
+  SCHECK_EQ(
+      producer_namespace_ids.size(), consumer_namespace_ids.size(), InvalidArgument,
+      "We should have the namespaceIds from both producer and consumer");
+
   scoped_refptr<UniverseReplicationInfo> ri;
   {
     TRACE("Acquired catalog manager lock");
@@ -2576,8 +2582,7 @@ CatalogManager::CreateUniverseReplicationInfoForProducer(
 
     if (FindPtrOrNull(universe_replication_map_, replication_group_id) != nullptr) {
       return STATUS(
-          InvalidArgument, "Producer already present", replication_group_id.ToString(),
-          MasterError(MasterErrorPB::INVALID_REQUEST));
+          AlreadyPresent, "Replication group already present", replication_group_id.ToString());
     }
   }
 
@@ -2587,6 +2592,15 @@ CatalogManager::CreateUniverseReplicationInfoForProducer(
   SysUniverseReplicationEntryPB* metadata = &ri->mutable_metadata()->mutable_dirty()->pb;
   metadata->set_replication_group_id(replication_group_id.ToString());
   metadata->mutable_producer_master_addresses()->CopyFrom(master_addresses);
+
+  if (!producer_namespace_ids.empty()) {
+    auto* db_scoped_info = metadata->mutable_db_scoped_info();
+    for (size_t i = 0; i < producer_namespace_ids.size(); i++) {
+      auto* ns_info = db_scoped_info->mutable_namespace_infos()->Add();
+      ns_info->set_producer_namespace_id(producer_namespace_ids[i]);
+      ns_info->set_consumer_namespace_id(consumer_namespace_ids[i]);
+    }
+  }
   metadata->mutable_tables()->CopyFrom(table_ids);
   metadata->set_state(SysUniverseReplicationEntryPB::INITIALIZING);
   metadata->set_transactional(transactional);
@@ -3091,9 +3105,32 @@ Status CatalogManager::SetupUniverseReplication(
     }
   }
 
+  SCHECK_EQ(
+      req->namespace_names_size(), req->producer_namespace_ids_size(), InvalidArgument,
+      "Incorrect number of namespace names and producer namespace ids");
+
+  std::vector<NamespaceId> producer_namespace_ids, consumer_namespace_ids;
+  for (int i = 0; i < req->namespace_names_size(); ++i) {
+    NamespaceIdentifierPB ns_id;
+    ns_id.set_database_type(YQLDatabase::YQL_DATABASE_PGSQL);
+    ns_id.set_name(req->namespace_names(i));
+    auto ns_info = VERIFY_RESULT(FindNamespace(ns_id));
+    consumer_namespace_ids.push_back(ns_info->id());
+    producer_namespace_ids.push_back(req->producer_namespace_ids(i));
+  }
+
+  // We should set the universe uuid even if we fail with AlreadyPresent error.
+  {
+    auto l = ClusterConfig()->LockForRead();
+    if (l->pb.has_universe_uuid()) {
+      resp->set_universe_uuid(l->pb.universe_uuid());
+    }
+  }
+
   auto ri = VERIFY_RESULT(CreateUniverseReplicationInfoForProducer(
       xcluster::ReplicationGroupId(req->replication_group_id()), req->producer_master_addresses(),
-      req->producer_table_ids(), setup_info.transactional));
+      producer_namespace_ids, consumer_namespace_ids, req->producer_table_ids(),
+      setup_info.transactional));
 
   // Initialize the CDC Stream by querying the Producer server for RPC sanity checks.
   auto result = ri->GetOrCreateXClusterRpcTasks(req->producer_master_addresses());
