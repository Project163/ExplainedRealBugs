diff --git a/src/yb/client/async_rpc.cc b/src/yb/client/async_rpc.cc
index a4d057bfa7..a4b0cf92b4 100644
--- a/src/yb/client/async_rpc.cc
+++ b/src/yb/client/async_rpc.cc
@@ -238,8 +238,8 @@ void AsyncRpc::Finished(const Status& status) {
     if (PREDICT_FALSE(ANNOTATE_UNPROTECTED_READ(FLAGS_TEST_asyncrpc_finished_set_timedout))) {
       new_status = STATUS(
           TimedOut, "Fake TimedOut for testing due to FLAGS_TEST_asyncrpc_finished_set_timedout");
-      TEST_SYNC_POINT("AsyncRpc::Finished:SetTimedOut:1");
-      TEST_SYNC_POINT("AsyncRpc::Finished:SetTimedOut:2");
+      DEBUG_ONLY_TEST_SYNC_POINT("AsyncRpc::Finished:SetTimedOut:1");
+      DEBUG_ONLY_TEST_SYNC_POINT("AsyncRpc::Finished:SetTimedOut:2");
     }
 
   }
diff --git a/src/yb/client/session.cc b/src/yb/client/session.cc
index a7ae347914..f44236fd5d 100644
--- a/src/yb/client/session.cc
+++ b/src/yb/client/session.cc
@@ -204,7 +204,7 @@ void BatcherFlushDone(
     retry_batcher->Add(op);
   }
 
-  TEST_SYNC_POINT("BatcherFlushDone:Retry:1");
+  DEBUG_ONLY_TEST_SYNC_POINT("BatcherFlushDone:Retry:1");
 
   FlushBatcherAsync(retry_batcher, std::move(callback), batcher_config,
       internal::IsWithinTransactionRetry::kTrue);
diff --git a/src/yb/client/stateful_services/stateful_service_client_base.cc b/src/yb/client/stateful_services/stateful_service_client_base.cc
index bf8e7b0e2e..66532b4bf4 100644
--- a/src/yb/client/stateful_services/stateful_service_client_base.cc
+++ b/src/yb/client/stateful_services/stateful_service_client_base.cc
@@ -123,14 +123,10 @@ Status StatefulServiceClientBase::InvokeRpcSync(
         rpc_func) {
   CoarseBackoffWaiter waiter(deadline, 1s /* max_wait */, 100ms /* base_delay */);
 
-#ifndef NDEBUG
   uint64 attempts = 0;
-#endif
   bool first_run = true;
   while (true) {
-#ifndef NDEBUG
     ++attempts;
-#endif
     if (!first_run) {
       SCHECK(
           waiter.Wait(), TimedOut, "RPC call to $0 timed out after $1 attempt(s)", service_name_,
diff --git a/src/yb/integration-tests/stateful_services/stateful_service-itest.cc b/src/yb/integration-tests/stateful_services/stateful_service-itest.cc
index 7f2c635bbb..7c186d158d 100644
--- a/src/yb/integration-tests/stateful_services/stateful_service-itest.cc
+++ b/src/yb/integration-tests/stateful_services/stateful_service-itest.cc
@@ -281,8 +281,6 @@ TEST_F(StatefulServiceTest, TestEchoService) {
   ASSERT_OK(initial_leader->Start());
 }
 
-// The below tests use SyncPoint so can only run in DEBUG mode.
-#ifndef NDEBUG
 TEST_F(StatefulServiceTest, TestLeadershipChange) {
   // If the tablet leader changes in the middle of a RPC, but after the write then the RPC should
   // still fail. The StatefulServiceClient should retry the RPC on the new leader such that the
@@ -409,6 +407,5 @@ TEST_F(StatefulServiceTest, TestWriteDuringLeadershipChange) {
   ASSERT_EQ(count_err, 0);
   ASSERT_EQ(count_term_err, 1);
 }
-#endif
 
 }  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_ysql_index-test.cc b/src/yb/integration-tests/xcluster/xcluster_ysql_index-test.cc
index 100d968bd2..f7dffcbac1 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ysql_index-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ysql_index-test.cc
@@ -284,7 +284,6 @@ TEST_F(XClusterYsqlIndexTest, FailedCreateIndex) {
   ASSERT_OK(ValidateRows());
 }
 
-#ifndef NDEBUG
 TEST_F(XClusterYsqlIndexTest, MasterFailoverRetryAddTableToXcluster) {
   ASSERT_OK(producer_conn_->Execute(kCreateIndexStmt));
 
@@ -320,7 +319,6 @@ TEST_F(XClusterYsqlIndexTest, MasterFailoverRetryAddTableToXcluster) {
 
   ASSERT_OK(ValidateRows());
 }
-#endif
 
 // TODO(Hari): #16758 Test collocated table
 
diff --git a/src/yb/master/catalog_manager.cc b/src/yb/master/catalog_manager.cc
index 86ec0eed1b..c922164a4b 100644
--- a/src/yb/master/catalog_manager.cc
+++ b/src/yb/master/catalog_manager.cc
@@ -3220,7 +3220,7 @@ Status CatalogManager::DeleteNotServingTablet(
   const auto tablet_info = VERIFY_RESULT(GetTabletInfo(tablet_id));
 
   if (PREDICT_FALSE(FLAGS_TEST_reject_delete_not_serving_tablet_rpc)) {
-    TEST_SYNC_POINT("CatalogManager::DeleteNotServingTablet:Reject");
+    DEBUG_ONLY_TEST_SYNC_POINT("CatalogManager::DeleteNotServingTablet:Reject");
     return STATUS(
         InvalidArgument, "Rejecting due to FLAGS_TEST_reject_delete_not_serving_tablet_rpc");
   }
diff --git a/src/yb/rocksdb/db/auto_roll_logger.cc b/src/yb/rocksdb/db/auto_roll_logger.cc
index bf01cafe45..562f237ec4 100644
--- a/src/yb/rocksdb/db/auto_roll_logger.cc
+++ b/src/yb/rocksdb/db/auto_roll_logger.cc
@@ -53,9 +53,9 @@ AutoRollLogger::AutoRollLogger(Env* env, const std::string& dbname,
 
 // -- AutoRollLogger
 Status AutoRollLogger::ResetLogger() {
-  TEST_SYNC_POINT("AutoRollLogger::ResetLogger:BeforeNewLogger");
+  DEBUG_ONLY_TEST_SYNC_POINT("AutoRollLogger::ResetLogger:BeforeNewLogger");
   status_ = env_->NewLogger(log_fname_, &logger_);
-  TEST_SYNC_POINT("AutoRollLogger::ResetLogger:AfterNewLogger");
+  DEBUG_ONLY_TEST_SYNC_POINT("AutoRollLogger::ResetLogger:AfterNewLogger");
 
   if (!status_.ok()) {
     return status_;
diff --git a/src/yb/rocksdb/db/auto_roll_logger.h b/src/yb/rocksdb/db/auto_roll_logger.h
index 141df9c529..9ca51de89c 100644
--- a/src/yb/rocksdb/db/auto_roll_logger.h
+++ b/src/yb/rocksdb/db/auto_roll_logger.h
@@ -81,7 +81,7 @@ class AutoRollLogger : public Logger {
       // pin down the current logger_ instance before releasing the mutex.
       logger = logger_;
     }
-    TEST_SYNC_POINT("AutoRollLogger::Flush:PinnedLogger");
+    DEBUG_ONLY_TEST_SYNC_POINT("AutoRollLogger::Flush:PinnedLogger");
     if (logger) {
       logger->Flush();
     }
diff --git a/src/yb/rocksdb/db/compaction.cc b/src/yb/rocksdb/db/compaction.cc
index cd26d87eef..964dd69532 100644
--- a/src/yb/rocksdb/db/compaction.cc
+++ b/src/yb/rocksdb/db/compaction.cc
@@ -334,10 +334,10 @@ bool Compaction::InputCompressionMatchesOutput() const {
   bool matches = (GetCompressionType(*cfd_->ioptions(), start_level_,
                                      base_level) == output_compression_);
   if (matches) {
-    TEST_SYNC_POINT("Compaction::InputCompressionMatchesOutput:Matches");
+    DEBUG_ONLY_TEST_SYNC_POINT("Compaction::InputCompressionMatchesOutput:Matches");
     return true;
   }
-  TEST_SYNC_POINT("Compaction::InputCompressionMatchesOutput:DidntMatch");
+  DEBUG_ONLY_TEST_SYNC_POINT("Compaction::InputCompressionMatchesOutput:DidntMatch");
   return matches;
 }
 
diff --git a/src/yb/rocksdb/db/compaction_job.cc b/src/yb/rocksdb/db/compaction_job.cc
index 09ca95eb49..bab0997574 100644
--- a/src/yb/rocksdb/db/compaction_job.cc
+++ b/src/yb/rocksdb/db/compaction_job.cc
@@ -443,7 +443,7 @@ void CompactionJob::GenSubcompactionBoundaries() {
 }
 
 Result<FileNumbersHolder> CompactionJob::Run() {
-  TEST_SYNC_POINT("CompactionJob::Run():Start");
+  DEBUG_ONLY_TEST_SYNC_POINT("CompactionJob::Run():Start");
   log_buffer_->FlushBufferToLog();
   LogCompaction();
 
@@ -504,7 +504,7 @@ Result<FileNumbersHolder> CompactionJob::Run() {
   UpdateCompactionStats();
   RecordCompactionIOStats();
   LogFlush(db_options_.info_log);
-  TEST_SYNC_POINT("CompactionJob::Run():End");
+  DEBUG_ONLY_TEST_SYNC_POINT("CompactionJob::Run():End");
 
   compact_->status = status;
   return file_numbers_holder;
@@ -622,7 +622,7 @@ void CompactionJob::ProcessKeyValueCompaction(
       existing_snapshots_.empty() ? 0 : existing_snapshots_.back(),
       compact_->compaction->level(), db_options_.statistics.get());
 
-  TEST_SYNC_POINT("CompactionJob::Run():Inprogress");
+  DEBUG_ONLY_TEST_SYNC_POINT("CompactionJob::Run():Inprogress");
 
   Slice* start = sub_compact->start;
   Slice* end = sub_compact->end;
@@ -904,7 +904,7 @@ Status CompactionJob::FinishCompactionOutputFile(
       if (db_bg_error_->ok()) {
         s = STATUS(IOError, "Max allowed space was reached");
         *db_bg_error_ = s;
-        TEST_SYNC_POINT(
+        DEBUG_ONLY_TEST_SYNC_POINT(
             "CompactionJob::FinishCompactionOutputFile:MaxAllowedSpaceReached");
       }
     }
diff --git a/src/yb/rocksdb/db/compaction_picker.cc b/src/yb/rocksdb/db/compaction_picker.cc
index e19cd4fb55..9c63414c29 100644
--- a/src/yb/rocksdb/db/compaction_picker.cc
+++ b/src/yb/rocksdb/db/compaction_picker.cc
@@ -672,7 +672,7 @@ std::unique_ptr<Compaction> CompactionPicker::CompactRange(
   // level0 compaction in this case? looks like this is the reason for #16798.
   if ((input_level == 0) && (!level0_compactions_in_progress_.empty())) {
     // Only one level 0 compaction allowed
-    TEST_SYNC_POINT("CompactionPicker::CompactRange:Conflict");
+    DEBUG_ONLY_TEST_SYNC_POINT("CompactionPicker::CompactRange:Conflict");
     *manual_conflict = true;
     return nullptr;
   }
@@ -755,7 +755,7 @@ std::unique_ptr<Compaction> CompactionPicker::CompactRange(
     return nullptr;
   }
 
-  TEST_SYNC_POINT_CALLBACK("CompactionPicker::CompactRange:Return", compaction.get());
+  DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("CompactionPicker::CompactRange:Return", compaction.get());
   if (input_level == 0) {
     MarkL0FilesForDeletion(vstorage, &ioptions_);
     level0_compactions_in_progress_.insert(compaction.get());
@@ -1185,7 +1185,7 @@ std::unique_ptr<Compaction> LevelCompactionPicker::PickCompaction(
                                      dummy_compaction_options_fifo);
   }
 
-  TEST_SYNC_POINT_CALLBACK("LevelCompactionPicker::PickCompaction:Return", c.get());
+  DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("LevelCompactionPicker::PickCompaction:Return", c.get());
 
   return c;
 }
@@ -1238,7 +1238,7 @@ bool LevelCompactionPicker::PickCompactionBySize(VersionStorageInfo* vstorage,
   // could be made better by looking at key-ranges that are
   // being compacted at level 0.
   if (level == 0 && !level0_compactions_in_progress_.empty()) {
-    TEST_SYNC_POINT("LevelCompactionPicker::PickCompactionBySize:0");
+    DEBUG_ONLY_TEST_SYNC_POINT("LevelCompactionPicker::PickCompactionBySize:0");
     return false;
   }
 
@@ -1522,7 +1522,7 @@ std::unique_ptr<Compaction> UniversalCompactionPicker::PickCompaction(
       return result;
     }
   }
-  TEST_SYNC_POINT("UniversalCompactionPicker::PickCompaction:SkippingCompaction");
+  DEBUG_ONLY_TEST_SYNC_POINT("UniversalCompactionPicker::PickCompaction:SkippingCompaction");
   return nullptr;
 }
 
diff --git a/src/yb/rocksdb/db/db_filesnapshot.cc b/src/yb/rocksdb/db/db_filesnapshot.cc
index 694a5413b5..b9e961be8e 100644
--- a/src/yb/rocksdb/db/db_filesnapshot.cc
+++ b/src/yb/rocksdb/db/db_filesnapshot.cc
@@ -112,8 +112,8 @@ Status DBImpl::GetLiveFiles(std::vector<std::string> &ret,
       cfd->Ref();
       mutex_.Unlock();
       status = FlushMemTable(cfd, FlushOptions());
-      TEST_SYNC_POINT("DBImpl::GetLiveFiles:1");
-      TEST_SYNC_POINT("DBImpl::GetLiveFiles:2");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::GetLiveFiles:1");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::GetLiveFiles:2");
       mutex_.Lock();
       cfd->Unref();
       if (!status.ok()) {
diff --git a/src/yb/rocksdb/db/db_impl.cc b/src/yb/rocksdb/db/db_impl.cc
index d497329130..312bd598c9 100644
--- a/src/yb/rocksdb/db/db_impl.cc
+++ b/src/yb/rocksdb/db/db_impl.cc
@@ -2016,8 +2016,7 @@ Result<FileNumbersHolder> DBImpl::FlushMemTableToOutputFile(
     }
     if (sfm->IsMaxAllowedSpaceReached() && bg_error_.ok()) {
       bg_error_ = STATUS(IOError, "Max allowed space was reached");
-      TEST_SYNC_POINT(
-          "DBImpl::FlushMemTableToOutputFile:MaxAllowedSpaceReached");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::FlushMemTableToOutputFile:MaxAllowedSpaceReached");
     }
   }
   return file_number_holder;
@@ -2214,8 +2213,8 @@ Status DBImpl::CompactRange(const CompactRangeOptions& options,
       } else if (output_level > final_output_level) {
         final_output_level = output_level;
       }
-      TEST_SYNC_POINT("DBImpl::RunManualCompaction()::1");
-      TEST_SYNC_POINT("DBImpl::RunManualCompaction()::2");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::RunManualCompaction()::1");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::RunManualCompaction()::2");
     }
   }
   if (!s.ok()) {
@@ -2421,8 +2420,8 @@ Status DBImpl::CompactFilesImpl(
       listener->OnCompactionStarted();
     }
     auto file_numbers_holder = compaction_job.Run();
-    TEST_SYNC_POINT("CompactFilesImpl:2");
-    TEST_SYNC_POINT("CompactFilesImpl:3");
+    DEBUG_ONLY_TEST_SYNC_POINT("CompactFilesImpl:2");
+    DEBUG_ONLY_TEST_SYNC_POINT("CompactFilesImpl:3");
     mutex_.Lock();
 
     status = compaction_job.Install(*c->mutable_cf_options());
@@ -2812,8 +2811,8 @@ Status DBImpl::SyncWAL() {
     status = directories_.GetWalDir()->Fsync();
   }
 
-  TEST_SYNC_POINT("DBImpl::SyncWAL:BeforeMarkLogsSynced:1");
-  TEST_SYNC_POINT("DBImpl::SyncWAL:BeforeMarkLogsSynced:2");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::SyncWAL:BeforeMarkLogsSynced:1");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::SyncWAL:BeforeMarkLogsSynced:2");
 
   {
     InstrumentedMutexLock l(&mutex_);
@@ -2871,7 +2870,7 @@ Status DBImpl::RunManualCompaction(ColumnFamilyData* cfd, int input_level, int o
     uint32_t output_path_id, const Slice* begin, const Slice* end, bool exclusive,
     CompactionReason compaction_reason, uint64_t file_number_upper_bound,
     uint64_t input_size_limit_per_job, bool disallow_trivial_move) {
-  TEST_SYNC_POINT("DBImpl::RunManualCompaction");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::RunManualCompaction");
 
   DCHECK(input_level == ColumnFamilyData::kCompactAllLevels ||
          input_level >= 0);
@@ -2932,10 +2931,10 @@ Status DBImpl::RunManualCompaction(ColumnFamilyData* cfd, int input_level, int o
   // others will wait on a condition variable until it completes.
 
   AddManualCompaction(&manual_compaction);
-  TEST_SYNC_POINT_CALLBACK("DBImpl::RunManualCompaction:NotScheduled", &mutex_);
+  DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("DBImpl::RunManualCompaction:NotScheduled", &mutex_);
   if (exclusive) {
     while (unscheduled_compactions_ + bg_compaction_scheduled_ + compaction_tasks_.size() > 0) {
-      TEST_SYNC_POINT("DBImpl::RunManualCompaction()::Conflict");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::RunManualCompaction()::Conflict");
       MaybeScheduleFlushOrCompaction();
       while (bg_compaction_scheduled_ + compaction_tasks_.size() > 0) {
         RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,
@@ -2974,7 +2973,7 @@ Status DBImpl::RunManualCompaction(ColumnFamilyData* cfd, int input_level, int o
       DCHECK(!exclusive || !manual_conflict)
           << "exclusive manual compactions should not see a conflict during CompactRange";
       if (manual_conflict) {
-        TEST_SYNC_POINT("DBImpl::RunManualCompaction()::Conflict");
+        DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::RunManualCompaction()::Conflict");
       }
 
       // TODO(pscompact): what if the system has only one compaction ever and it is finished
@@ -3135,7 +3134,7 @@ Status DBImpl::WaitForFlushMemTable(ColumnFamilyData* cfd) {
 
 Status DBImpl::EnableAutoCompaction(
     const std::vector<ColumnFamilyHandle*>& column_family_handles) {
-  TEST_SYNC_POINT("DBImpl::EnableAutoCompaction");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::EnableAutoCompaction");
   Status s;
   for (auto cf_ptr : column_family_handles) {
     Status status =
@@ -3308,21 +3307,21 @@ void DBImpl::SchedulePendingCompaction(ColumnFamilyData* cfd) {
       ++unscheduled_compactions_;
     }
   }
-  TEST_SYNC_POINT("DBImpl::SchedulePendingCompaction:Done");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::SchedulePendingCompaction:Done");
 }
 
 void DBImpl::BGWorkFlush(void* db) {
   IOSTATS_SET_THREAD_POOL_ID(Env::Priority::HIGH);
-  TEST_SYNC_POINT("DBImpl::BGWorkFlush");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::BGWorkFlush");
   reinterpret_cast<DBImpl*>(db)->BackgroundCallFlush(nullptr /* cfd */);
-  TEST_SYNC_POINT("DBImpl::BGWorkFlush:done");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::BGWorkFlush:done");
 }
 
 void DBImpl::BGWorkCompaction(void* arg) {
   CompactionArg ca = *(reinterpret_cast<CompactionArg*>(arg));
   delete reinterpret_cast<CompactionArg*>(arg);
   IOSTATS_SET_THREAD_POOL_ID(Env::Priority::LOW);
-  TEST_SYNC_POINT("DBImpl::BGWorkCompaction");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::BGWorkCompaction");
   reinterpret_cast<DBImpl*>(ca.db)->BackgroundCallCompaction(ca.m);
 }
 
@@ -3332,7 +3331,7 @@ void DBImpl::UnscheduleCallback(void* arg) {
   if (ca.m != nullptr) {
     ca.m->compaction.reset();
   }
-  TEST_SYNC_POINT("DBImpl::UnscheduleCallback");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::UnscheduleCallback");
 }
 
 Result<FileNumbersHolder> DBImpl::BackgroundFlush(
@@ -3513,7 +3512,7 @@ void DBImpl::BackgroundCallCompaction(ManualCompaction* m, std::unique_ptr<Compa
     }
 
     s = yb::ResultToStatus(file_numbers_holder);
-    TEST_SYNC_POINT("BackgroundCallCompaction:1");
+    DEBUG_ONLY_TEST_SYNC_POINT("BackgroundCallCompaction:1");
     WaitAfterBackgroundError(s, "compaction", &log_buffer);
   }
 
@@ -3655,9 +3654,9 @@ Result<FileNumbersHolder> DBImpl::BackgroundCompaction(
 
     if (is_large_compaction) {
       num_running_large_compactions_++;
-      TEST_SYNC_POINT("DBImpl:BackgroundCompaction:LargeCompaction");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl:BackgroundCompaction:LargeCompaction");
     } else {
-      TEST_SYNC_POINT("DBImpl:BackgroundCompaction:SmallCompaction");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl:BackgroundCompaction:SmallCompaction");
     }
 
     if (c != nullptr) {
@@ -3709,7 +3708,7 @@ Result<FileNumbersHolder> DBImpl::BackgroundCompaction(
                 c->num_input_files(0));
     *made_progress = true;
   } else if (!trivial_move_disallowed && c->IsTrivialMove()) {
-    TEST_SYNC_POINT("DBImpl::BackgroundCompaction:TrivialMove");
+    DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::BackgroundCompaction:TrivialMove");
 
     compaction_job_stats.num_input_files = c->num_input_files(0);
 
@@ -3760,8 +3759,7 @@ Result<FileNumbersHolder> DBImpl::BackgroundCompaction(
     *made_progress = true;
   } else {
     int output_level  __attribute__((unused)) = c->output_level();
-    TEST_SYNC_POINT_CALLBACK("DBImpl::BackgroundCompaction:NonTrivial",
-                             &output_level);
+    DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("DBImpl::BackgroundCompaction:NonTrivial", &output_level);
 
     SequenceNumber earliest_write_conflict_snapshot;
     std::vector<SequenceNumber> snapshot_seqs =
@@ -3781,7 +3779,7 @@ Result<FileNumbersHolder> DBImpl::BackgroundCompaction(
 
     mutex_.Unlock();
     result = compaction_job.Run();
-    TEST_SYNC_POINT("DBImpl::BackgroundCompaction:NonTrivial:AfterRun");
+    DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::BackgroundCompaction:NonTrivial:AfterRun");
     mutex_.Lock();
 
     status = compaction_job.Install(*c->mutable_cf_options());
@@ -4453,7 +4451,7 @@ Status DBImpl::AddFile(ColumnFamilyHandle* column_family,
       }
     }
 
-    TEST_SYNC_POINT("DBImpl::AddFile:FileCopied");
+    DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::AddFile:FileCopied");
     if (!status.ok()) {
       return status;
     }
@@ -5445,7 +5443,7 @@ Status DBImpl::DelayWrite(uint64_t num_bytes) {
     if (delay > 0) {
       mutex_.Unlock();
       delayed = true;
-      TEST_SYNC_POINT("DBImpl::DelayWrite:Sleep");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::DelayWrite:Sleep");
       // hopefully we don't have to sleep more than 2 billion microseconds
       env_->SleepForMicroseconds(static_cast<int>(delay));
       mutex_.Lock();
@@ -5456,7 +5454,7 @@ Status DBImpl::DelayWrite(uint64_t num_bytes) {
     // in this case.
     while (bg_error_.ok() && write_controller_.IsStopped() && !IsShuttingDown()) {
       delayed = true;
-      TEST_SYNC_POINT("DBImpl::DelayWrite:Wait");
+      DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::DelayWrite:Wait");
       bg_cv_.Wait();
     }
   }
@@ -6012,7 +6010,7 @@ Status DBImpl::DeleteFile(std::string name) {
       return STATUS(InvalidArgument, "File in level 0, but not oldest");
     }
 
-    TEST_SYNC_POINT("DBImpl::DeleteFile:DecidedToDelete");
+    DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::DeleteFile:DecidedToDelete");
 
     metadata->being_deleted = true;
 
@@ -6509,7 +6507,7 @@ Status DB::Open(const DBOptions& db_options, const std::string& dbname,
       }
     }
   }
-  TEST_SYNC_POINT("DBImpl::Open:Opened");
+  DEBUG_ONLY_TEST_SYNC_POINT("DBImpl::Open:Opened");
   Status persist_options_status;
   if (s.ok()) {
     // Persist RocksDB Options before scheduling the compaction.
diff --git a/src/yb/rocksdb/db/flush_job.cc b/src/yb/rocksdb/db/flush_job.cc
index 09833a6f16..8afcf09383 100644
--- a/src/yb/rocksdb/db/flush_job.cc
+++ b/src/yb/rocksdb/db/flush_job.cc
@@ -118,7 +118,7 @@ FlushJob::FlushJob(const std::string& dbname, ColumnFamilyData* cfd,
       event_logger_(event_logger) {
   // Update the thread status to indicate flush.
   ReportStartedFlush();
-  TEST_SYNC_POINT("FlushJob::FlushJob()");
+  DEBUG_ONLY_TEST_SYNC_POINT("FlushJob::FlushJob()");
 }
 
 FlushJob::~FlushJob() {
@@ -192,7 +192,7 @@ Result<FileNumbersHolder> FlushJob::Run(FileMetaData* file_meta) {
   if (!fnum.ok()) {
     cfd_->imm()->RollbackMemtableFlush(mems, meta.fd.GetNumber());
   } else {
-    TEST_SYNC_POINT("FlushJob::InstallResults");
+    DEBUG_ONLY_TEST_SYNC_POINT("FlushJob::InstallResults");
     // Replace immutable memtable with the generated Table
     Status s = cfd_->imm()->InstallMemtableFlushResults(
         cfd_, mutable_cf_options_, mems, versions_, db_mutex_,
@@ -278,8 +278,8 @@ Result<FileNumbersHolder> FlushJob::WriteLevel0Table(
           "[%s] [JOB %d] Level-0 flush table #%" PRIu64 ": started",
           cfd_->GetName().c_str(), job_context_->job_id, meta->fd.GetNumber());
 
-      TEST_SYNC_POINT_CALLBACK("FlushJob::WriteLevel0Table:output_compression",
-                               &output_compression_);
+      DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK(
+          "FlushJob::WriteLevel0Table:output_compression", &output_compression_);
       s = BuildTable(dbname_,
                      db_options_.env,
                      *cfd_->ioptions(),
@@ -322,13 +322,13 @@ Result<FileNumbersHolder> FlushJob::WriteLevel0Table(
       EventHelpers::LogAndNotifyTableFileCreation(
           event_logger_, db_options_.listeners,
           meta->fd, info);
-      TEST_SYNC_POINT("FlushJob::LogAndNotifyTableFileCreation()");
+      DEBUG_ONLY_TEST_SYNC_POINT("FlushJob::LogAndNotifyTableFileCreation()");
     }
 
     if (!db_options_.disableDataSync && output_file_directory_ != nullptr) {
       RETURN_NOT_OK(output_file_directory_->Fsync());
     }
-    TEST_SYNC_POINT("FlushJob::WriteLevel0Table");
+    DEBUG_ONLY_TEST_SYNC_POINT("FlushJob::WriteLevel0Table");
     db_mutex_->Lock();
   }
 
diff --git a/src/yb/rocksdb/db/forward_iterator.cc b/src/yb/rocksdb/db/forward_iterator.cc
index 4edbb71c7e..805ade994c 100644
--- a/src/yb/rocksdb/db/forward_iterator.cc
+++ b/src/yb/rocksdb/db/forward_iterator.cc
@@ -390,14 +390,14 @@ void ForwardIterator::SeekInternal(const Slice& internal_key,
       is_prev_inclusive_ = true;
     }
 
-    TEST_SYNC_POINT_CALLBACK("ForwardIterator::SeekInternal:Immutable", this);
+    DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("ForwardIterator::SeekInternal:Immutable", this);
   } else if (current_ && current_ != mutable_iter_) {
     // current_ is one of immutable iterators, push it back to the heap
     immutable_min_heap_.push(current_);
   }
 
   UpdateCurrent();
-  TEST_SYNC_POINT_CALLBACK("ForwardIterator::SeekInternal:Return", this);
+  DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("ForwardIterator::SeekInternal:Return", this);
 }
 
 const KeyValueEntry& ForwardIterator::Next() {
@@ -456,7 +456,7 @@ const KeyValueEntry& ForwardIterator::Next() {
     }
   }
   UpdateCurrent();
-  TEST_SYNC_POINT_CALLBACK("ForwardIterator::Next:Return", this);
+  DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("ForwardIterator::Next:Return", this);
   return Entry();
 }
 
@@ -553,11 +553,11 @@ void ForwardIterator::RenewIterators() {
     if (found) {
       if (l0_iters_[iold] == nullptr) {
         l0_iters_new.push_back(nullptr);
-        TEST_SYNC_POINT_CALLBACK("ForwardIterator::RenewIterators:Null", this);
+        DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("ForwardIterator::RenewIterators:Null", this);
       } else {
         l0_iters_new.push_back(l0_iters_[iold]);
         l0_iters_[iold] = nullptr;
-        TEST_SYNC_POINT_CALLBACK("ForwardIterator::RenewIterators:Copy", this);
+        DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("ForwardIterator::RenewIterators:Copy", this);
       }
       continue;
     }
diff --git a/src/yb/rocksdb/db/table_cache.cc b/src/yb/rocksdb/db/table_cache.cc
index 70c108f063..9d2c9bb642 100644
--- a/src/yb/rocksdb/db/table_cache.cc
+++ b/src/yb/rocksdb/db/table_cache.cc
@@ -164,7 +164,7 @@ Status TableCache::DoGetTableReader(
     }
     (*table_reader)->SetDataFileReader(std::move(data_file_reader));
   }
-  TEST_SYNC_POINT("TableCache::GetTableReader:0");
+  DEBUG_ONLY_TEST_SYNC_POINT("TableCache::GetTableReader:0");
   return s;
 }
 
@@ -178,8 +178,7 @@ Status TableCache::FindTable(const EnvOptions& env_options,
   uint64_t number = fd.GetNumber();
   Slice key = GetSliceForFileNumber(&number);
   *handle = cache_->Lookup(key, query_id);
-  TEST_SYNC_POINT_CALLBACK("TableCache::FindTable:0",
-      const_cast<bool*>(&no_io));
+  DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("TableCache::FindTable:0", const_cast<bool*>(&no_io));
 
   if (*handle == nullptr) {
     if (no_io) {  // Don't do IO and return a not-found status
diff --git a/src/yb/rocksdb/db/version_set.cc b/src/yb/rocksdb/db/version_set.cc
index 96b2f4cd13..fffd31b3ed 100644
--- a/src/yb/rocksdb/db/version_set.cc
+++ b/src/yb/rocksdb/db/version_set.cc
@@ -2385,7 +2385,7 @@ Status VersionSet::LogAndApply(ColumnFamilyData* column_family_data,
 
     mu->Unlock();
 
-    TEST_SYNC_POINT("VersionSet::LogAndApply:WriteManifest");
+    DEBUG_ONLY_TEST_SYNC_POINT("VersionSet::LogAndApply:WriteManifest");
     if (!edit->IsColumnFamilyManipulation() &&
         db_options_->max_open_files == -1) {
       // unlimited table cache. Pre-load table handle now.
@@ -2472,13 +2472,13 @@ Status VersionSet::LogAndApply(ColumnFamilyData* column_family_data,
     }
 
     if (edit->is_column_family_drop_) {
-      TEST_SYNC_POINT("VersionSet::LogAndApply::ColumnFamilyDrop:0");
-      TEST_SYNC_POINT("VersionSet::LogAndApply::ColumnFamilyDrop:1");
-      TEST_SYNC_POINT("VersionSet::LogAndApply::ColumnFamilyDrop:2");
+      DEBUG_ONLY_TEST_SYNC_POINT("VersionSet::LogAndApply::ColumnFamilyDrop:0");
+      DEBUG_ONLY_TEST_SYNC_POINT("VersionSet::LogAndApply::ColumnFamilyDrop:1");
+      DEBUG_ONLY_TEST_SYNC_POINT("VersionSet::LogAndApply::ColumnFamilyDrop:2");
     }
 
     LogFlush(db_options_->info_log);
-    TEST_SYNC_POINT("VersionSet::LogAndApply:WriteManifestDone");
+    DEBUG_ONLY_TEST_SYNC_POINT("VersionSet::LogAndApply:WriteManifestDone");
     mu->Lock();
 
     if (!obsolete_manifest.empty()) {
diff --git a/src/yb/rocksdb/db/wal_manager.cc b/src/yb/rocksdb/db/wal_manager.cc
index e05cc9ae73..5b85f76b06 100644
--- a/src/yb/rocksdb/db/wal_manager.cc
+++ b/src/yb/rocksdb/db/wal_manager.cc
@@ -69,8 +69,8 @@ Status WalManager::GetSortedWalFiles(VectorLogPtr* files) {
   // Reproduce the race condition where a log file is moved
   // to archived dir, between these two sync points, used in
   // (DBTest,TransactionLogIteratorRace)
-  TEST_SYNC_POINT("WalManager::GetSortedWalFiles:1");
-  TEST_SYNC_POINT("WalManager::GetSortedWalFiles:2");
+  DEBUG_ONLY_TEST_SYNC_POINT("WalManager::GetSortedWalFiles:1");
+  DEBUG_ONLY_TEST_SYNC_POINT("WalManager::GetSortedWalFiles:2");
 
   files->clear();
   // list wal files in archive dir.
@@ -279,10 +279,10 @@ void WalManager::PurgeObsoleteWALFiles() {
 void WalManager::ArchiveWALFile(const std::string& fname, uint64_t number) {
   auto archived_log_name = ArchivedLogFileName(db_options_.wal_dir, number);
   // The sync point below is used in (DBTest,TransactionLogIteratorRace)
-  TEST_SYNC_POINT("WalManager::PurgeObsoleteFiles:1");
+  DEBUG_ONLY_TEST_SYNC_POINT("WalManager::PurgeObsoleteFiles:1");
   Status s = env_->RenameFile(fname, archived_log_name);
   // The sync point below is used in (DBTest,TransactionLogIteratorRace)
-  TEST_SYNC_POINT("WalManager::PurgeObsoleteFiles:2");
+  DEBUG_ONLY_TEST_SYNC_POINT("WalManager::PurgeObsoleteFiles:2");
   RLOG(InfoLogLevel::INFO_LEVEL, db_options_.info_log,
       "Move log file %s to %s -- %s\n", fname.c_str(),
       archived_log_name.c_str(), s.ToString().c_str());
@@ -325,8 +325,8 @@ Status WalManager::GetSortedWalsOfType(const std::string& path,
       // Reproduce the race condition where a log file is moved
       // to archived dir, between these two sync points, used in
       // (DBTest,TransactionLogIteratorRace)
-      TEST_SYNC_POINT("WalManager::GetSortedWalsOfType:1");
-      TEST_SYNC_POINT("WalManager::GetSortedWalsOfType:2");
+      DEBUG_ONLY_TEST_SYNC_POINT("WalManager::GetSortedWalsOfType:1");
+      DEBUG_ONLY_TEST_SYNC_POINT("WalManager::GetSortedWalsOfType:2");
 
       uint64_t size_bytes;
       s = env_->GetFileSize(LogFileName(path, number), &size_bytes);
diff --git a/src/yb/rocksdb/db/write_thread.cc b/src/yb/rocksdb/db/write_thread.cc
index 4c9ac46398..c902d67602 100644
--- a/src/yb/rocksdb/db/write_thread.cc
+++ b/src/yb/rocksdb/db/write_thread.cc
@@ -238,13 +238,13 @@ void WriteThread::JoinBatchGroup(Writer* w) {
   bool linked_as_leader;
   LinkOne(w, &linked_as_leader);
 
-  TEST_SYNC_POINT_CALLBACK("WriteThread::JoinBatchGroup:Wait", w);
+  DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("WriteThread::JoinBatchGroup:Wait", w);
 
   if (!linked_as_leader) {
     AwaitState(w,
                STATE_GROUP_LEADER | STATE_PARALLEL_FOLLOWER | STATE_COMPLETED,
                &ctx);
-    TEST_SYNC_POINT_CALLBACK("WriteThread::JoinBatchGroup:DoneWaiting", w);
+    DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("WriteThread::JoinBatchGroup:DoneWaiting", w);
   }
 }
 
@@ -445,7 +445,7 @@ void WriteThread::EnterUnbatched(Writer* w, InstrumentedMutex* mu) {
   LinkOne(w, &linked_as_leader);
   if (!linked_as_leader) {
     mu->Unlock();
-    TEST_SYNC_POINT("WriteThread::EnterUnbatched:Wait");
+    DEBUG_ONLY_TEST_SYNC_POINT("WriteThread::EnterUnbatched:Wait");
     AwaitState(w, STATE_GROUP_LEADER, &ctx);
     mu->Lock();
   }
diff --git a/src/yb/rocksdb/table/merger.cc b/src/yb/rocksdb/table/merger.cc
index 3f7b048190..eaae990ae0 100644
--- a/src/yb/rocksdb/table/merger.cc
+++ b/src/yb/rocksdb/table/merger.cc
@@ -241,11 +241,11 @@ class MergingIteratorBase final : public InternalIterator {
           child.Seek(key());
           if (child.Valid()) {
             // Child is at first entry >= key().  Step back one to be < key()
-            TEST_SYNC_POINT_CALLBACK("MergeIterator::Prev:BeforePrev", &child);
+            DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("MergeIterator::Prev:BeforePrev", &child);
             child.Prev();
           } else {
             // Child has no entries >= key().  Position at last entry.
-            TEST_SYNC_POINT("MergeIterator::Prev:BeforeSeekToLast");
+            DEBUG_ONLY_TEST_SYNC_POINT("MergeIterator::Prev:BeforeSeekToLast");
             child.SeekToLast();
           }
         }
diff --git a/src/yb/rocksdb/util/delete_scheduler.cc b/src/yb/rocksdb/util/delete_scheduler.cc
index 0b367542fa..63ecee1f67 100644
--- a/src/yb/rocksdb/util/delete_scheduler.cc
+++ b/src/yb/rocksdb/util/delete_scheduler.cc
@@ -144,7 +144,7 @@ Status DeleteScheduler::MoveToTrash(const std::string& file_path,
 }
 
 void DeleteScheduler::BackgroundEmptyTrash() {
-  TEST_SYNC_POINT("DeleteScheduler::BackgroundEmptyTrash");
+  DEBUG_ONLY_TEST_SYNC_POINT("DeleteScheduler::BackgroundEmptyTrash");
 
   while (true) {
     MutexLock l(&mu_);
@@ -179,8 +179,8 @@ void DeleteScheduler::BackgroundEmptyTrash() {
       uint64_t total_penlty =
           ((total_deleted_bytes * kMicrosInSecond) / rate_bytes_per_sec_);
       while (!closing_ && !cv_.TimedWait(start_time + total_penlty)) {}
-      TEST_SYNC_POINT_CALLBACK("DeleteScheduler::BackgroundEmptyTrash:Wait",
-                               &total_penlty);
+      DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK(
+          "DeleteScheduler::BackgroundEmptyTrash:Wait", &total_penlty);
 
       pending_files_--;
       if (pending_files_ == 0) {
@@ -197,7 +197,7 @@ Status DeleteScheduler::DeleteTrashFile(const std::string& path_in_trash,
   uint64_t file_size;
   Status s = env_->GetFileSize(path_in_trash, &file_size);
   if (s.ok()) {
-    TEST_SYNC_POINT("DeleteScheduler::DeleteTrashFile:DeleteFile");
+    DEBUG_ONLY_TEST_SYNC_POINT("DeleteScheduler::DeleteTrashFile:DeleteFile");
     s = env_->DeleteFile(path_in_trash);
   }
 
diff --git a/src/yb/rocksdb/util/file_reader_writer.cc b/src/yb/rocksdb/util/file_reader_writer.cc
index 7893558af2..879a42c77c 100644
--- a/src/yb/rocksdb/util/file_reader_writer.cc
+++ b/src/yb/rocksdb/util/file_reader_writer.cc
@@ -109,7 +109,7 @@ Status WritableFileWriter::Append(const Slice& data) {
 
   {
     IOSTATS_TIMER_GUARD(prepare_write_nanos);
-    TEST_SYNC_POINT("WritableFileWriter::Append:BeforePrepareWrite");
+    DEBUG_ONLY_TEST_SYNC_POINT("WritableFileWriter::Append:BeforePrepareWrite");
     writable_file_->PrepareWrite(static_cast<size_t>(GetFileSize()), left);
   }
 
@@ -281,9 +281,9 @@ Status WritableFileWriter::SyncWithoutFlush(bool use_fsync) {
       "Can't WritableFileWriter::SyncWithoutFlush() because "
       "WritableFile::IsSyncThreadSafe() is false");
   }
-  TEST_SYNC_POINT("WritableFileWriter::SyncWithoutFlush:1");
+  DEBUG_ONLY_TEST_SYNC_POINT("WritableFileWriter::SyncWithoutFlush:1");
   Status s = SyncInternal(use_fsync);
-  TEST_SYNC_POINT("WritableFileWriter::SyncWithoutFlush:2");
+  DEBUG_ONLY_TEST_SYNC_POINT("WritableFileWriter::SyncWithoutFlush:2");
   return s;
 }
 
@@ -294,7 +294,7 @@ Status WritableFileWriter::InvalidateCache(size_t offset, size_t length) {
 Status WritableFileWriter::SyncInternal(bool use_fsync) {
   Status s;
   IOSTATS_TIMER_GUARD(fsync_nanos);
-  TEST_SYNC_POINT("WritableFileWriter::SyncInternal:0");
+  DEBUG_ONLY_TEST_SYNC_POINT("WritableFileWriter::SyncInternal:0");
   if (use_fsync) {
     s = writable_file_->Fsync();
   } else {
@@ -305,7 +305,7 @@ Status WritableFileWriter::SyncInternal(bool use_fsync) {
 
 Status WritableFileWriter::RangeSync(uint64_t offset, uint64_t nbytes) {
   IOSTATS_TIMER_GUARD(range_sync_nanos);
-  TEST_SYNC_POINT("WritableFileWriter::RangeSync:0");
+  DEBUG_ONLY_TEST_SYNC_POINT("WritableFileWriter::RangeSync:0");
   return writable_file_->RangeSync(offset, nbytes);
 }
 
@@ -343,7 +343,7 @@ Status WritableFileWriter::WriteBuffered(const char* data, size_t size) {
 
     {
       IOSTATS_TIMER_GUARD(write_nanos);
-      TEST_SYNC_POINT("WritableFileWriter::Flush:BeforeAppend");
+      DEBUG_ONLY_TEST_SYNC_POINT("WritableFileWriter::Flush:BeforeAppend");
       s = writable_file_->Append(Slice(src, allowed));
       if (!s.ok()) {
         return s;
@@ -399,7 +399,7 @@ Status WritableFileWriter::WriteUnbuffered() {
 
     {
       IOSTATS_TIMER_GUARD(write_nanos);
-      TEST_SYNC_POINT("WritableFileWriter::Flush:BeforeAppend");
+      DEBUG_ONLY_TEST_SYNC_POINT("WritableFileWriter::Flush:BeforeAppend");
       // Unbuffered writes must be positional
       s = writable_file_->PositionedAppend(Slice(src, size), write_offset);
       if (!s.ok()) {
diff --git a/src/yb/rocksdb/util/options_parser.cc b/src/yb/rocksdb/util/options_parser.cc
index 33d86024e6..69612b6500 100644
--- a/src/yb/rocksdb/util/options_parser.cc
+++ b/src/yb/rocksdb/util/options_parser.cc
@@ -52,7 +52,7 @@ Status PersistRocksDBOptions(const DBOptions& db_opt,
                              const std::string& file_name, Env* env,
                              const IncludeHeader include_header,
                              const IncludeFileVersion include_file_version) {
-  TEST_SYNC_POINT("PersistRocksDBOptions:start");
+  DEBUG_ONLY_TEST_SYNC_POINT("PersistRocksDBOptions:start");
   if (cf_names.size() != cf_opts.size()) {
     return STATUS(InvalidArgument,
         "cf_names.size() and cf_opts.size() must be the same");
diff --git a/src/yb/rocksdb/util/posix_logger.h b/src/yb/rocksdb/util/posix_logger.h
index 7f232b528a..ba8724524e 100644
--- a/src/yb/rocksdb/util/posix_logger.h
+++ b/src/yb/rocksdb/util/posix_logger.h
@@ -75,7 +75,7 @@ class PosixLogger : public Logger {
     fclose(file_);
   }
   virtual void Flush() override {
-    TEST_SYNC_POINT_CALLBACK("PosixLogger::Flush:BeginCallback", nullptr);
+    DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK("PosixLogger::Flush:BeginCallback", nullptr);
     {
       bool expected_flush_pending = true;
       // TODO: use a weaker memory order?
diff --git a/src/yb/rocksdb/util/sst_file_manager_impl.cc b/src/yb/rocksdb/util/sst_file_manager_impl.cc
index ad7038f2bd..22e7a6b602 100644
--- a/src/yb/rocksdb/util/sst_file_manager_impl.cc
+++ b/src/yb/rocksdb/util/sst_file_manager_impl.cc
@@ -50,7 +50,7 @@ Status SstFileManagerImpl::OnAddFile(const std::string& file_path) {
     MutexLock l(&mu_);
     OnAddFileImpl(file_path, file_size);
   }
-  TEST_SYNC_POINT("SstFileManagerImpl::OnAddFile");
+  DEBUG_ONLY_TEST_SYNC_POINT("SstFileManagerImpl::OnAddFile");
   return s;
 }
 
@@ -59,7 +59,7 @@ Status SstFileManagerImpl::OnDeleteFile(const std::string& file_path) {
     MutexLock l(&mu_);
     OnDeleteFileImpl(file_path);
   }
-  TEST_SYNC_POINT("SstFileManagerImpl::OnDeleteFile");
+  DEBUG_ONLY_TEST_SYNC_POINT("SstFileManagerImpl::OnDeleteFile");
   return Status::OK();
 }
 
@@ -70,7 +70,7 @@ Status SstFileManagerImpl::OnMoveFile(const std::string& old_path,
     OnAddFileImpl(new_path, tracked_files_[old_path]);
     OnDeleteFileImpl(old_path);
   }
-  TEST_SYNC_POINT("SstFileManagerImpl::OnMoveFile");
+  DEBUG_ONLY_TEST_SYNC_POINT("SstFileManagerImpl::OnMoveFile");
   return Status::OK();
 }
 
diff --git a/src/yb/rocksdb/util/testutil.h b/src/yb/rocksdb/util/testutil.h
index 302a913fa8..538083a809 100644
--- a/src/yb/rocksdb/util/testutil.h
+++ b/src/yb/rocksdb/util/testutil.h
@@ -49,12 +49,15 @@
 #include "yb/util/slice.h"
 
 DECLARE_bool(never_fsync);
+DECLARE_bool(TEST_enable_sync_points);
+
 namespace rocksdb {
 class SequentialFileReader;
 
 class RocksDBTest : public ::testing::Test {
  public:
   RocksDBTest() {
+    ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_enable_sync_points) = true;
     ANNOTATE_UNPROTECTED_WRITE(FLAGS_never_fsync) = true;
   }
 };
diff --git a/src/yb/tablet/write_query.cc b/src/yb/tablet/write_query.cc
index af52cf25cd..936b260145 100644
--- a/src/yb/tablet/write_query.cc
+++ b/src/yb/tablet/write_query.cc
@@ -519,7 +519,7 @@ Status WriteQuery::DoExecute() {
       transactional_table, write_batch.has_transaction(), deadline(), partial_range_key_intents,
       tablet->shared_lock_manager()));
 
-  TEST_SYNC_POINT("WriteQuery::DoExecute::PreparedDocWriteOps");
+  DEBUG_ONLY_TEST_SYNC_POINT("WriteQuery::DoExecute::PreparedDocWriteOps");
 
   auto* transaction_participant = tablet->transaction_participant();
   docdb::WaitQueue* wait_queue = nullptr;
diff --git a/src/yb/tserver/tablet_service.cc b/src/yb/tserver/tablet_service.cc
index aa934be0a7..7736129cee 100644
--- a/src/yb/tserver/tablet_service.cc
+++ b/src/yb/tserver/tablet_service.cc
@@ -2081,8 +2081,8 @@ void TabletServiceImpl::Read(const ReadRequestPB* req,
         static CountDownLatch row_mark_exclusive_latch(FLAGS_TEST_wait_row_mark_exclusive_count);
         row_mark_exclusive_latch.CountDown();
         row_mark_exclusive_latch.Wait();
-        TEST_SYNC_POINT("TabletServiceImpl::Read::RowMarkExclusive:1");
-        TEST_SYNC_POINT("TabletServiceImpl::Read::RowMarkExclusive:2");
+        DEBUG_ONLY_TEST_SYNC_POINT("TabletServiceImpl::Read::RowMarkExclusive:1");
+        DEBUG_ONLY_TEST_SYNC_POINT("TabletServiceImpl::Read::RowMarkExclusive:2");
         break;
       }
     }
diff --git a/src/yb/util/sync_point-test.cc b/src/yb/util/sync_point-test.cc
index a05051ba49..21919548ec 100644
--- a/src/yb/util/sync_point-test.cc
+++ b/src/yb/util/sync_point-test.cc
@@ -43,20 +43,21 @@
 #include "yb/util/test_macros.h"
 #include "yb/util/thread.h"
 
+DECLARE_bool(TEST_enable_sync_points);
+
 using std::string;
 using std::vector;
 
 namespace yb {
 
-#ifndef NDEBUG
 static void RunThread(bool *var) {
   *var = true;
   TEST_SYNC_POINT("first");
 }
-#endif
 
 TEST(SyncPointTest, TestSyncPoint) {
-#ifndef NDEBUG
+  ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_enable_sync_points) = true;
+
   // Set up a sync point "second" that depends on "first".
   vector<SyncPoint::Dependency> dependencies;
   dependencies.push_back({"first", "second"});
@@ -74,9 +75,6 @@ TEST(SyncPointTest, TestSyncPoint) {
   ASSERT_TRUE(var);
 
   thread->Join();
-#else
-  LOG(INFO) << "Test skipped in release mode.";
-#endif // NDEBUG
 }
 
 } // namespace yb
diff --git a/src/yb/util/sync_point.cc b/src/yb/util/sync_point.cc
index f36d6f298d..64f898f380 100644
--- a/src/yb/util/sync_point.cc
+++ b/src/yb/util/sync_point.cc
@@ -18,10 +18,12 @@
 // under the License.
 //
 
+#include "yb/util/flags.h"
 #include "yb/util/logging.h"
 #include "yb/util/sync_point.h"
 
-#ifndef NDEBUG
+DEFINE_test_flag(bool, enable_sync_points, false, "Enable sync points for testing.");
+
 namespace yb {
 
 SyncPoint* SyncPoint::GetInstance() {
@@ -110,5 +112,9 @@ void SyncPoint::Process(const std::string& point, void* cb_arg) {
   cv_.notify_all();
 }
 
+void TEST_sync_point(const std::string& point, void* cb_arg) {
+  if (PREDICT_FALSE(FLAGS_TEST_enable_sync_points)) {
+    yb::SyncPoint::GetInstance()->Process(point, cb_arg);
+  }
+}
 }  // namespace yb
-#endif  // NDEBUG
diff --git a/src/yb/util/sync_point.h b/src/yb/util/sync_point.h
index e0010a020d..5d51811c21 100644
--- a/src/yb/util/sync_point.h
+++ b/src/yb/util/sync_point.h
@@ -25,21 +25,15 @@
 #include <unordered_set>
 #include <vector>
 
-#ifdef NDEBUG
-#define TEST_SYNC_POINT(x)
-#define TEST_SYNC_POINT_CALLBACK(x, y)
-#else
-
 namespace yb {
 
 // This class provides facility to reproduce race conditions deterministically
 // in unit tests.
-// Developer could specify sync points in the codebase via TEST_SYNC_POINT.
-// Each sync point represents a position in the execution stream of a thread.
-// In the unit test, 'Happens After' relationship among sync points could be
-// setup via SyncPoint::LoadDependency, to reproduce a desired interleave of
-// threads execution.
-// Refer to (DBTest,TransactionLogIteratorRace), for an example use case.
+// Developer could specify sync points in the codebase via TEST_SYNC_POINT and
+// DEBUG_ONLY_TEST_SYNC_POINT. Each sync point represents a position in the execution stream of a
+// thread. In the unit test, 'Happens After' relationship among sync points could be setup via
+// SyncPoint::LoadDependency, to reproduce a desired interleave of threads execution. Refer to
+// (DBTest,TransactionLogIteratorRace), for an example use case.
 
 class SyncPoint {
  public:
@@ -67,9 +61,8 @@ class SyncPoint {
   // remove the execution trace of all sync points
   void ClearTrace();
 
-  // triggered by TEST_SYNC_POINT, blocking execution until all predecessors
-  // are executed.
-  // And/or call registered callback functionn, with argument `cb_arg`
+  // triggered by TEST_SYNC_POINT and DEBUG_ONLY_TEST_SYNC_POINT, blocking execution until all
+  // predecessors are executed. And/or call registered callback function, with argument `cb_arg`
   void Process(const std::string& point, void* cb_arg = nullptr);
 
   // TODO: it might be useful to provide a function that blocks until all
@@ -93,15 +86,26 @@ class SyncPoint {
   int num_callbacks_running_ = 0;
 };
 
-}  // namespace yb
+void TEST_sync_point(const std::string& point, void* cb_arg = nullptr);
 
 // Use TEST_SYNC_POINT to specify sync points inside code base.
 // Sync points can have happens-after depedency on other sync points,
 // configured at runtime via SyncPoint::LoadDependency. This could be
 // utilized to re-produce race conditions between threads.
 // See TransactionLogIteratorRace in db_test.cc for an example use case.
-// TEST_SYNC_POINT is no op in release build.
-#define TEST_SYNC_POINT(x) yb::SyncPoint::GetInstance()->Process(x)
-#define TEST_SYNC_POINT_CALLBACK(x, y) \
-    yb::SyncPoint::GetInstance()->Process(x, y)
+#define TEST_SYNC_POINT(x) yb::TEST_sync_point(x)
+
+#define TEST_SYNC_POINT_CALLBACK(x, y) yb::TEST_sync_point(x, y)
+
+// Use DEBUG_ONLY_TEST_SYNC_POINT in perf sensitive code path. It is no op in release build.
+// Sync point processing only happens in test mode (FLAGS_TEST_running_test), but it still requires
+// a function call and boolean check which in some places need to be avoided.
+#ifdef NDEBUG
+#define DEBUG_ONLY_TEST_SYNC_POINT(x)
+#define DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK(x, y)
+#else
+#define DEBUG_ONLY_TEST_SYNC_POINT(x) TEST_SYNC_POINT(x)
+#define DEBUG_ONLY_TEST_SYNC_POINT_CALLBACK(x, y) TEST_SYNC_POINT_CALLBACK(x, y)
 #endif  // NDEBUG
+
+}  // namespace yb
diff --git a/src/yb/util/test_util.cc b/src/yb/util/test_util.cc
index 031b268351..69c9c2eb63 100644
--- a/src/yb/util/test_util.cc
+++ b/src/yb/util/test_util.cc
@@ -59,6 +59,7 @@ DEFINE_NON_RUNTIME_string(test_leave_files, "on_failure",
 DEFINE_NON_RUNTIME_int32(test_random_seed, 0, "Random seed to use for randomized tests");
 DECLARE_int64(memory_limit_hard_bytes);
 DECLARE_bool(enable_tracing);
+DECLARE_bool(TEST_enable_sync_points);
 DECLARE_bool(TEST_running_test);
 DECLARE_bool(never_fsync);
 DECLARE_string(vmodule);
@@ -133,6 +134,7 @@ YBTest::~YBTest() {
 
 void YBTest::SetUp() {
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_running_test) = true;
+  ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_enable_sync_points) = true;
 
   InitSpinLockContentionProfiling();
   InitGoogleLoggingSafeBasic("yb_test");
diff --git a/src/yb/yql/pgwrapper/pg_namespace_master_restart-test.cc b/src/yb/yql/pgwrapper/pg_namespace_master_restart-test.cc
index 74e4a14d5a..b8a9e506c8 100644
--- a/src/yb/yql/pgwrapper/pg_namespace_master_restart-test.cc
+++ b/src/yb/yql/pgwrapper/pg_namespace_master_restart-test.cc
@@ -41,8 +41,7 @@ class PgNamespaceMasterRestartTest : public PgMiniTestBase {
   }
 };
 
-#ifndef NDEBUG
-TEST_F(PgNamespaceMasterRestartTest, YB_DISABLE_TEST_IN_TSAN(CreateNamespaceWithDelay)) {
+TEST_F(PgNamespaceMasterRestartTest, CreateNamespaceWithDelay) {
   SyncPoint::GetInstance()->LoadDependency(
       {{"CatalogManager::ProcessPendingNamespace:Fail",
         "PgNamespaceMasterRestartTest::CreateNamespaceWithDelay:WaitForFail"}});
@@ -79,7 +78,6 @@ TEST_F(PgNamespaceMasterRestartTest, YB_DISABLE_TEST_IN_TSAN(CreateNamespaceWith
       "SELECT * FROM pg_database where datname = 'test_db'"));
   ASSERT_EQ(0, PQntuples(res.get()));
 }
-#endif // NDEBUG
 
 } // namespace pgwrapper
 } // namespace yb
