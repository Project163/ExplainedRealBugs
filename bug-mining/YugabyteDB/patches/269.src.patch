diff --git a/src/yb/integration-tests/CMakeLists.txt b/src/yb/integration-tests/CMakeLists.txt
index 14677b85ba..743b69b9ef 100644
--- a/src/yb/integration-tests/CMakeLists.txt
+++ b/src/yb/integration-tests/CMakeLists.txt
@@ -225,6 +225,8 @@ ADD_YB_TEST(load_balancer_multi_table-test)
 ADD_YB_TEST(load_balancer_colocated_tables-test)
 ADD_YB_TEST(load_balancer_respect_affinity-test)
 ADD_YB_TEST(load_balancer_placement_policy-test)
+ADD_YB_TEST(sys_catalog-itest)
+YB_TEST_TARGET_LINK_LIBRARIES(sys_catalog-itest pg_wrapper_test_base)
 ADD_YB_TEST(sys_catalog_respect_affinity-test)
 ADD_YB_TEST(restart-test)
 ADD_YB_TEST(yb-ts-cli-itest)
diff --git a/src/yb/integration-tests/sys_catalog-itest.cc b/src/yb/integration-tests/sys_catalog-itest.cc
new file mode 100644
index 0000000000..5df0acce60
--- /dev/null
+++ b/src/yb/integration-tests/sys_catalog-itest.cc
@@ -0,0 +1,147 @@
+// Copyright (c) YugabyteDB, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
+// in compliance with the License.  You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software distributed under the License
+// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+// or implied.  See the License for the specific language governing permissions and limitations
+// under the License.
+
+#include <regex>
+#include <string>
+
+#include <gtest/gtest.h>
+
+#include "yb/master/catalog_manager_if.h"
+#include "yb/master/master_ddl.pb.h"
+#include "yb/master/sys_catalog.h"
+
+#include "yb/yql/pgwrapper/pg_mini_test_base.h"
+
+namespace yb::master {
+
+class SysCatalogITest : public pgwrapper::PgMiniTestBase {
+ public:
+  void SetUp() override {
+    TEST_SETUP_SUPER(pgwrapper::PgMiniTestBase);
+
+    master::GetNamespaceInfoResponsePB resp;
+    ASSERT_OK(client_->GetNamespaceInfo(
+        /*namespace_id=*/std::string(), namespace_name, YQL_DATABASE_PGSQL, &resp));
+    namespace_id_ = resp.namespace_().id();
+
+    google::SetVLOGLevel("catalog_manager*", 1);
+  }
+
+  const std::string namespace_name = "yugabyte";
+  NamespaceId namespace_id_;
+};
+
+TEST_F(SysCatalogITest, ReadHighestNormalPreservableOid) {
+  auto conn = ASSERT_RESULT(ConnectToDB(namespace_name));
+  auto database_oid = ASSERT_RESULT(GetPgsqlDatabaseOid(namespace_id_));
+  auto sys_catalog = ASSERT_RESULT(catalog_manager())->sys_catalog();
+
+  auto original_highest_oid =
+      ASSERT_RESULT(sys_catalog->ReadHighestNormalPreservableOid(database_oid));
+  // Make sure all the OIDs we are going to use are higher than any of the starting OIDs.
+  ASSERT_LT(original_highest_oid, 20'000);
+
+  // Create secondary space OIDs of each of the kinds we preserve.
+  {
+    // Here @ will be replaced by the lowest secondary space OID.
+    std::string command = R"(
+       SET yb_binary_restore = true;
+       SET yb_ignore_pg_class_oids = false;
+       SELECT pg_catalog.binary_upgrade_set_next_pg_type_oid((@)::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_array_pg_type_oid((@+1)::pg_catalog.oid);
+       CREATE TYPE high_enum AS ENUM ();
+       SELECT pg_catalog.binary_upgrade_set_next_pg_enum_oid((@+2)::pg_catalog.oid);
+       ALTER TYPE high_enum ADD VALUE 'red';
+       SELECT pg_catalog.binary_upgrade_set_next_heap_pg_class_oid((@+3)::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_heap_relfilenode((@+4)::pg_catalog.oid);
+       CREATE SEQUENCE high_sequence;
+      )";
+    ASSERT_OK(conn.Execute(std::regex_replace(
+        command, std::regex{"@"}, std::to_string(kPgFirstSecondarySpaceObjectId))));
+    auto oid = ASSERT_RESULT(sys_catalog->ReadHighestNormalPreservableOid(database_oid));
+    // The addition of these OIDs should not have changed the highest normal space OID at all.
+    ASSERT_EQ(oid, original_highest_oid);
+  }
+
+  {
+    // Run CREATE TYPE new_enum AS ENUM ('red', 'orange'); but using 50000-50001 as pg_enum OIDs.
+    ASSERT_OK(conn.Execute(R"(
+       SET yb_binary_restore = true;
+       SET yb_ignore_pg_class_oids = false;
+       SELECT pg_catalog.binary_upgrade_set_next_pg_type_oid('30000'::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_array_pg_type_oid('30001'::pg_catalog.oid);
+
+       CREATE TYPE new_enum AS ENUM ();
+       SELECT pg_catalog.binary_upgrade_set_next_pg_enum_oid('50000'::pg_catalog.oid);
+       ALTER TYPE new_enum ADD VALUE 'red';
+       SELECT pg_catalog.binary_upgrade_set_next_pg_enum_oid('50001'::pg_catalog.oid);
+       ALTER TYPE new_enum ADD VALUE 'orange';
+      )"));
+    auto oid = ASSERT_RESULT(sys_catalog->ReadHighestNormalPreservableOid(database_oid));
+    EXPECT_EQ(oid, 50'001);
+  }
+
+  {
+    // Run CREATE SEQUENCE new_sequence; using pg_class OID 60000.
+    ASSERT_OK(conn.Execute(R"(
+       SET yb_binary_restore = true;
+       SET yb_ignore_pg_class_oids = false;
+       SELECT pg_catalog.binary_upgrade_set_next_heap_pg_class_oid('60000'::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_heap_relfilenode('30010'::pg_catalog.oid);
+
+       CREATE SEQUENCE new_sequence;
+      )"));
+    auto oid = ASSERT_RESULT(sys_catalog->ReadHighestNormalPreservableOid(database_oid));
+    EXPECT_EQ(oid, 60000);
+  }
+
+  {
+    // Run CREATE TYPE new_composite AS (x int); using pg_type OID 70000-70001.
+    ASSERT_OK(conn.Execute(R"(
+       SET yb_binary_restore = true;
+       SET yb_ignore_pg_class_oids = false;
+       SELECT pg_catalog.binary_upgrade_set_next_pg_type_oid('70000'::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_array_pg_type_oid('70001'::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_heap_pg_class_oid('30020'::pg_catalog.oid);
+
+       CREATE TYPE new_composite AS (x int);
+      )"));
+    auto oid = ASSERT_RESULT(sys_catalog->ReadHighestNormalPreservableOid(database_oid));
+    EXPECT_EQ(oid, 70'001);
+  }
+
+  {
+    // Run CREATE TABLE public.my_table (x integer); attempting to use pg_relfilenode 80000.
+    ASSERT_OK(conn.Execute(R"(
+       SET yb_binary_restore = true;
+       SET yb_ignore_pg_class_oids = false;
+       SELECT pg_catalog.binary_upgrade_set_next_pg_type_oid('30030'::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_array_pg_type_oid('30031'::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_heap_pg_class_oid('30032'::pg_catalog.oid);
+       SELECT pg_catalog.binary_upgrade_set_next_heap_relfilenode('80000'::pg_catalog.oid);
+
+       CREATE TABLE my_table (x integer);
+      )"));
+
+    // TODO(yhaddad): fix Postgres to honor binary_upgrade_set_next_heap_relfilenode directive then
+    // update this test to expect 80'000.
+    //
+    // (Currently this directive is not honored, which prevents this test from testing the
+    // relfilenode case.)
+    LOG(INFO) << ASSERT_RESULT(conn.FetchAllAsString("SELECT oid, relfilenode FROM pg_class;"));
+    auto oid = ASSERT_RESULT(sys_catalog->ReadHighestNormalPreservableOid(database_oid));
+    // EXPECT_EQ(oid, 80'000);
+    EXPECT_EQ(oid, 70'001);
+  }
+}
+
+}  // namespace yb::master
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
index 69877b948c..38473e36df 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
@@ -1318,6 +1318,80 @@ TEST_F(XClusterDDLReplicationSwitchoverTest, SwitchoverBumpsAboveUsedOids) {
   ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
 }
 
+using XClusterDDLReplicationSetupTest = XClusterDDLReplicationSwitchoverTest;
+
+TEST_F(XClusterDDLReplicationSetupTest, ReplicationSetUpBumpsOidCounter) {
+  if (!UseYbController()) {
+    GTEST_SKIP() << "This test does not work with yb_backup.py";
+  }
+
+  // The resulting statement will consume 100 pg_enum OIDs.
+  auto CreateGiantEnumStatement = [](std::string name) {
+    std::string result = Format("CREATE TYPE $0 AS ENUM ('l0'", name);
+    for (int i = 1; i < 100; i++) {
+      result += Format(", 'l$0'", i);
+    }
+    return result + ");";
+  };
+
+  google::SetVLOGLevel("catalog_manager*", 1);
+  google::SetVLOGLevel("pg_client_service*", 1);
+  google::SetVLOGLevel("xcluster_source_manager", 1);
+  // Cache only 30 OIDs at a time; see below for why this value was chosen.
+  ANNOTATE_UNPROTECTED_WRITE(FLAGS_ysql_oid_cache_prefetch_size) = 30;
+
+  ASSERT_OK(SetUpClusters(/*is_colocated=*/false, /*start_yb_controller_servers=*/true));
+
+  // Create a giant enum on cluster A.
+  {
+    auto conn = ASSERT_RESULT(cluster_A_->ConnectToDB(namespace_name));
+    ASSERT_OK(conn.Execute(CreateGiantEnumStatement("first_enum")));
+    // Backup requires at least one table so create one.
+    ASSERT_OK(conn.Execute("CREATE TABLE my_table (x INT);"));
+  }
+
+  // Reset OID counters on A by backing up then restoring the database on cluster A.
+  ASSERT_OK(BackupFromProducer());
+  SetReplicationDirection(ReplicationDirection::BToA);
+  ASSERT_OK(RestoreToConsumer());
+  SetReplicationDirection(ReplicationDirection::AToB);
+
+  // Allocate a few OIDs on A to force caching of normal space OIDs.
+  {
+    auto conn = ASSERT_RESULT(cluster_A_->ConnectToDB(namespace_name));
+    ASSERT_OK(conn.Execute("CREATE TABLE exercise_cache (x INT);"));
+  }
+
+  // Set up xCluster replication with a nonempty database.
+  ASSERT_OK(CheckpointReplicationGroupOnNamespaces({namespace_name}));
+  ASSERT_OK(BackupFromProducer());
+  ASSERT_OK(RestoreToConsumer());
+  ASSERT_OK(CreateReplicationFromCheckpoint());
+
+  // At this point, in the absence of OID cache invalidation, we would still have OIDs cached on A
+  // from before replication was set up.  (Replication setup does create some objects, consuming
+  // OIDs, but not enough to exhaust the cache size of 30 we have set.)
+  //
+  // Importantly, we do not have enough OIDs cached to handle an entire giant enum.
+
+  {
+    // Drop via manual DDL replication the enum on only cluster A.
+    auto conn = ASSERT_RESULT(cluster_A_->ConnectToDB(namespace_name));
+    ASSERT_OK(conn.Execute(R"(
+                     SET yb_xcluster_ddl_replication.enable_manual_ddl_replication=1;
+                     DROP TYPE first_enum;
+                     SET yb_xcluster_ddl_replication.enable_manual_ddl_replication=0;)"));
+    ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+
+    // Now create a new giant enum via normal DDL replication.  If we did not bump up the normal
+    // space OID counter and invalidate on A then this will cause a OID collision on cluster B
+    // because the new enum on A will use OIDs freed up by dropping the previous enum but those OIDs
+    // are still in use on B because the previous enum still exists there.
+    ASSERT_OK(conn.Execute(CreateGiantEnumStatement("second_enum")));
+    ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+  }
+}
+
 class XClusterDDLReplicationAddDropColumnTest : public XClusterDDLReplicationTest {
  public:
   void SetUp() override {
diff --git a/src/yb/master/sys_catalog.cc b/src/yb/master/sys_catalog.cc
index 55e12f5e98..aae53668a9 100644
--- a/src/yb/master/sys_catalog.cc
+++ b/src/yb/master/sys_catalog.cc
@@ -42,23 +42,19 @@
 
 #include "yb/common/colocated_util.h"
 #include "yb/common/pg_catversions.h"
-#include "yb/master/ysql/ysql_manager_if.h"
-#include "yb/qlexpr/index.h"
-#include "yb/dockv/partial_row.h"
-#include "yb/dockv/partition.h"
-#include "yb/common/tablespace_parser.h"
-#include "yb/common/ql_value.h"
 #include "yb/common/ql_protocol_util.h"
-#include "yb/common/schema_pbutil.h"
+#include "yb/common/ql_value.h"
 #include "yb/common/schema.h"
+#include "yb/common/schema_pbutil.h"
+#include "yb/common/tablespace_parser.h"
 #include "yb/common/wire_protocol.h"
 
 #include "yb/consensus/consensus.h"
 #include "yb/consensus/consensus_meta.h"
 #include "yb/consensus/consensus_peers.h"
-#include "yb/consensus/multi_raft_batcher.h"
 #include "yb/consensus/log.h"
 #include "yb/consensus/log_anchor_registry.h"
+#include "yb/consensus/multi_raft_batcher.h"
 #include "yb/consensus/opid_util.h"
 #include "yb/consensus/quorum_util.h"
 #include "yb/consensus/retryable_requests.h"
@@ -66,26 +62,26 @@
 
 #include "yb/docdb/doc_rowwise_iterator.h"
 #include "yb/docdb/docdb_pgapi.h"
+#include "yb/dockv/partial_row.h"
+#include "yb/dockv/partition.h"
 
 #include "yb/fs/fs_manager.h"
 
 #include "yb/gutil/bind.h"
-#include "yb/gutil/casts.h"
-#include "yb/gutil/strings/escaping.h"
-#include "yb/gutil/strings/split.h"
 
-#include "yb/master/master_auto_flags_manager.h"
-#include "yb/master/catalog_entity_info.h"
-#include "yb/master/catalog_manager_if.h"
 #include "yb/master/catalog_manager.h"
+#include "yb/master/catalog_manager_if.h"
 #include "yb/master/master.h"
+#include "yb/master/master_auto_flags_manager.h"
 #include "yb/master/master_snapshot_coordinator.h"
 #include "yb/master/master_util.h"
 #include "yb/master/sys_catalog_writer.h"
+#include "yb/master/ysql/ysql_manager_if.h"
+
+#include "yb/qlexpr/index.h"
 
 #include "yb/rpc/thread_pool.h"
 
-#include "yb/tablet/operations/write_operation.h"
 #include "yb/tablet/operations/change_metadata_operation.h"
 #include "yb/tablet/tablet.h"
 #include "yb/tablet/tablet_bootstrap_if.h"
@@ -99,7 +95,6 @@
 #include "yb/tserver/tserver.pb.h"
 
 #include "yb/util/debug/trace_event.h"
-#include "yb/util/flags.h"
 #include "yb/util/format.h"
 #include "yb/util/logging.h"
 #include "yb/util/metrics.h"
@@ -161,8 +156,7 @@ DEFINE_test_flag(int32, sys_catalog_write_rejection_percentage, 0,
 DEFINE_test_flag(double, simulate_catalog_message_read_failure, 0.0,
                  "Inject random failure of pg_yb_invalidation_messages read from sys_catalog.");
 
-namespace yb {
-namespace master {
+namespace yb::master {
 
 namespace {
 
@@ -1685,6 +1679,75 @@ Result<uint32_t> SysCatalogTable::ReadPgYbTablegroupOid(const uint32_t database_
   return kPgInvalidOid;
 }
 
+Result<uint32_t> SysCatalogTable::ReadHighestNormalPreservableOid(uint32_t database_oid) {
+  auto request_scope = VERIFY_RESULT(VERIFY_RESULT(Tablet())->CreateRequestScope());
+  LongOperationTracker long_operation_tracker("ReadHighestNormalPreservableOid", 3s);
+
+  // XCluster needs to be able preserve OIDs for pg_enum, pg_type, and pg_class; pg_class's
+  // relfilenodes needs to be kept distinct from its OIDs so we include those as well.
+  const std::vector<uint32_t> table_oids = {kPgEnumTableOid, kPgTypeTableOid, kPgClassTableOid};
+  uint32_t maximum_normal_oid = 0;
+  for (const auto table_oid : table_oids) {
+    auto read_data = VERIFY_RESULT(TableReadData(database_oid, table_oid, ReadHybridTime()));
+    const auto& schema = read_data.schema();
+
+    dockv::ReaderProjection projection;
+    const auto oid_col_id = VERIFY_RESULT(schema.ColumnIdByName("oid")).rep();
+    const bool relfilenode_present = table_oid == kPgClassTableOid;
+    const auto relfilenode_col_id =
+        relfilenode_present ? VERIFY_RESULT(schema.ColumnIdByName("relfilenode")).rep() : 0;
+    if (relfilenode_present) {
+      projection.Init(schema, {oid_col_id, relfilenode_col_id});
+    } else {
+      projection.Init(schema, {oid_col_id});
+    }
+
+    auto iter = VERIFY_RESULT(read_data.NewUninitializedIterator(projection));
+    {
+      const dockv::KeyEntryValues empty_key_components;
+      // We are doing a full table scan in the forward direction here because there is no index for
+      // relfilenode.
+      docdb::DocPgsqlScanSpec spec(
+          schema, rocksdb::kDefaultQueryId, empty_key_components, empty_key_components,
+          /*condition=*/nullptr, /*hash_code=*/std::nullopt,
+          /*max_hash_code=*/std::nullopt);
+      RETURN_NOT_OK(iter->Init(spec));
+    }
+
+    qlexpr::QLTableRow row;
+    while (VERIFY_RESULT(iter->FetchNext(&row))) {
+      const auto& oid_col = row.GetValue(oid_col_id);
+      SCHECK(
+          oid_col, IllegalState,
+          "Could not read oid column from table ID $0 from database ID $1:", read_data.table_id,
+          database_oid);
+      const uint32_t oid = oid_col->uint32_value();
+      if (oid < kPgUpperBoundNormalObjectId) {
+        maximum_normal_oid = std::max(maximum_normal_oid, oid);
+      } else if (!relfilenode_present) {
+        // Because OID is the primary key (ascending) for these tables, if we do not need to look at
+        // relfilenode, then we can exit as soon as we have seen an OID at or above
+        // kPgUpperBoundNormalObjectId.
+        break;
+      }
+
+      if (!relfilenode_present) {
+        continue;
+      }
+      const auto& relfilenode_col = row.GetValue(relfilenode_col_id);
+      SCHECK(
+          relfilenode_col, IllegalState,
+          "Could not read relfilenode column from table ID $0 from database ID $1:",
+          read_data.table_id, database_oid);
+      const uint32_t relfilenode = relfilenode_col->uint32_value();
+      if (relfilenode < kPgUpperBoundNormalObjectId) {
+        maximum_normal_oid = std::max(maximum_normal_oid, relfilenode);
+      }
+    }
+  }
+  return maximum_normal_oid;
+}
+
 Result<DbOidVersionToMessageListMap>
 SysCatalogTable::ReadYsqlCatalogInvalationMessages() {
   if (RandomActWithProbability(FLAGS_TEST_simulate_catalog_message_read_failure)) {
@@ -2136,5 +2199,4 @@ Result<std::unique_ptr<docdb::YQLRowwiseIteratorIf>> PgTableReadData::NewIterato
   return tablet->NewRowIterator(projection, read_hybrid_time, table_id);
 }
 
-} // namespace master
-} // namespace yb
+} // namespace yb::master
diff --git a/src/yb/master/sys_catalog.h b/src/yb/master/sys_catalog.h
index 41a9de8172..0fb7d7b701 100644
--- a/src/yb/master/sys_catalog.h
+++ b/src/yb/master/sys_catalog.h
@@ -51,8 +51,6 @@
 #include "yb/master/sys_catalog_types.h"
 #include "yb/master/sys_catalog_constants.h"
 
-#include "yb/tablet/snapshot_coordinator.h"
-
 #include "yb/tserver/tablet_memory_manager.h"
 
 #include "yb/rpc/thread_pool.h"
@@ -105,7 +103,7 @@ struct PgTableReadData {
 //   as a "normal table", instead we have Master APIs to query the table.
 class SysCatalogTable {
  public:
-  typedef Callback<Status()> ElectedLeaderCallback;
+  using ElectedLeaderCallback = Callback<Status ()>;
 
   // 'leader_cb_' is invoked whenever this node is elected as a leader
   // of the consensus configuration for this tablet, including for local standalone
@@ -232,7 +230,7 @@ class SysCatalogTable {
     return Status::OK();
   }
 
-  typedef std::function<Status(const ReadHybridTime&, HybridTime*)> ReadRestartFn;
+  using ReadRestartFn = std::function<Status (const ReadHybridTime &, HybridTime *)>;
   Status ReadWithRestarts(
       const ReadRestartFn& fn,
       tablet::RequireLease require_lease = tablet::RequireLease::kTrue) const;
@@ -303,6 +301,10 @@ class SysCatalogTable {
   Result<uint32_t> ReadPgYbTablegroupOid(const uint32_t database_oid,
                                          const std::string& grpname);
 
+  // Scan database database_oid's catalog tables to find the highest normal space OID that xCluster
+  // needs to preserve and return it.
+  Result<uint32_t> ReadHighestNormalPreservableOid(uint32_t database_oid);
+
   // Copy the content of co-located tables in sys catalog as a batch.
   Status CopyPgsqlTables(const std::vector<TableId>& source_table_ids,
                          const std::vector<TableId>& target_table_ids,
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
index a44187333e..45fba8b37b 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
@@ -166,7 +166,7 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
   }
 
   void SetUp() override {
-    YBTest::SetUp();
+    TEST_SETUP_SUPER(YBTest);
     LOG(INFO) << "Test uses automatic mode: " << UseAutomaticMode();
     ANNOTATE_UNPROTECTED_WRITE(FLAGS_xcluster_enable_ddl_replication) = UseAutomaticMode();
   }
@@ -312,6 +312,8 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
 
         return Status::OK();
       },
+      .set_normal_oid_counter_above_all_normal_oids_func =
+          [](NamespaceId namespace_id) -> Status { return Status::OK(); },
       .get_normal_oid_higher_than_any_used_normal_oid_func =
           [](NamespaceId namespace_id) -> Result<uint32_t> { return 100'000; },
       .get_namespace_func =
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group.h b/src/yb/master/xcluster/xcluster_outbound_replication_group.h
index 552d78c9be..6acdd027a1 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group.h
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group.h
@@ -39,6 +39,8 @@ class XClusterOutboundReplicationGroup
  public:
   struct HelperFunctions {
     const std::function<Status()> create_sequences_data_table_func;
+    const std::function<Status(NamespaceId namespace_id)>
+        set_normal_oid_counter_above_all_normal_oids_func;
     const std::function<Result<uint32_t>(NamespaceId namespace_id)>
         get_normal_oid_higher_than_any_used_normal_oid_func;
     const std::function<Result<scoped_refptr<NamespaceInfo>>(const NamespaceIdentifierPB&)>
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.cc
index 2cbe5a0cac..efb167f902 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.cc
@@ -73,7 +73,19 @@ Status XClusterCheckpointNamespaceTask::FirstStep() {
         namespace_id_, sequence_table_alias_id, epoch_));
   }
 
-  return SetupDDLReplicationExtension();
+  ScheduleNextStep([this] { return BumpOidCounter(); }, "BumpOidCounter");
+  return Status::OK();
+}
+
+Status XClusterCheckpointNamespaceTask::BumpOidCounter() {
+  if (outbound_replication_group_.AutomaticDDLMode()) {
+    RETURN_NOT_OK(outbound_replication_group_.helper_functions_
+                      .set_normal_oid_counter_above_all_normal_oids_func(namespace_id_));
+  }
+
+  ScheduleNextStep(
+      [this] { return SetupDDLReplicationExtension(); }, "SetupDDLReplicationExtension");
+  return Status::OK();
 }
 
 Status XClusterCheckpointNamespaceTask::SetupDDLReplicationExtension() {
@@ -84,9 +96,7 @@ Status XClusterCheckpointNamespaceTask::SetupDDLReplicationExtension() {
             &XClusterCheckpointNamespaceTask::SetupDDLReplicationExtensionCallback, this, _1));
   }
 
-  ScheduleNextStep(
-      std::bind(&XClusterCheckpointNamespaceTask::CreateStreams, this), "CreateStreams");
-
+  ScheduleNextStep([this] { return CreateStreams(); }, "CreateStreams");
   return Status::OK();
 }
 
@@ -106,16 +116,14 @@ Status XClusterCheckpointNamespaceTask::PrepareDDLQueueTable(Status status) {
   RETURN_NOT_OK(
       outbound_replication_group_.SetDDLQueueTableIsPartOfInitialBootstrap(namespace_id_, epoch_));
 
-  ScheduleNextStep(
-      std::bind(&XClusterCheckpointNamespaceTask::CreateStreams, this), "CreateStreams");
+  ScheduleNextStep([this] { return CreateStreams(); }, "CreateStreams");
   return Status::OK();
 }
 
 Status XClusterCheckpointNamespaceTask::CreateStreams() {
   RETURN_NOT_OK(
       outbound_replication_group_.CreateStreamsForInitialBootstrap(namespace_id_, epoch_));
-  ScheduleNextStep(
-      std::bind(&XClusterCheckpointNamespaceTask::CheckpointStreams, this), "CheckpointStreams");
+  ScheduleNextStep([this] { return CheckpointStreams(); }, "CheckpointStreams");
   return Status::OK();
 }
 
@@ -129,8 +137,7 @@ Status XClusterCheckpointNamespaceTask::CheckpointStreams() {
   if (!status.ok() && status.IsTryAgain()) {
     LOG_WITH_PREFIX(WARNING) << "Failed to checkpoint streams: " << status << ". Scheduling retry";
     ScheduleNextStepWithDelay(
-        std::bind(&XClusterCheckpointNamespaceTask::CheckpointStreams, this), "CheckpointStreams",
-        GetDelayWithBackoff());
+        [this] { return CheckpointStreams(); }, "CheckpointStreams", GetDelayWithBackoff());
     return Status::OK();
   }
 
@@ -159,8 +166,7 @@ Status XClusterCheckpointNamespaceTask::MarkTablesAsCheckpointed(
     LOG_WITH_PREFIX(INFO) << "Failed to checkpoint streams with retryable error: "
                           << result.status() << ". Scheduling retry";
     ScheduleNextStepWithDelay(
-        std::bind(&XClusterCheckpointNamespaceTask::CheckpointStreams, this), "CheckpointStreams",
-        GetDelayWithBackoff());
+        [this] { return CheckpointStreams(); }, "CheckpointStreams", GetDelayWithBackoff());
     return Status::OK();
   }
 
@@ -169,8 +175,7 @@ Status XClusterCheckpointNamespaceTask::MarkTablesAsCheckpointed(
     // All tables have been checkpointed and the replication group is now READY.
     Complete();
   } else {
-    ScheduleNextStep(
-        std::bind(&XClusterCheckpointNamespaceTask::CheckpointStreams, this), "CheckpointStreams");
+    ScheduleNextStep([this] { return CheckpointStreams(); }, "CheckpointStreams");
   }
   return Status::OK();
 }
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.h b/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.h
index ba72520fd9..2761f8360d 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.h
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.h
@@ -45,10 +45,11 @@ class XClusterCheckpointNamespaceTask : public MultiStepCatalogEntityTask {
   Status FirstStep() override;
 
  private:
-  Status CreateStreams();
+  Status BumpOidCounter();
   Status SetupDDLReplicationExtension();
   void SetupDDLReplicationExtensionCallback(Status status);
   Status PrepareDDLQueueTable(Status status);
+  Status CreateStreams();
 
   Status CheckpointStreams();
   void CheckpointStreamsCallback(XClusterCheckpointStreamsResult result);
diff --git a/src/yb/master/xcluster/xcluster_source_manager.cc b/src/yb/master/xcluster/xcluster_source_manager.cc
index 75cd49eb9e..75040793f9 100644
--- a/src/yb/master/xcluster/xcluster_source_manager.cc
+++ b/src/yb/master/xcluster/xcluster_source_manager.cc
@@ -210,6 +210,10 @@ XClusterSourceManager::InitOutboundReplicationGroup(
                 CoarseMonoClock::now() +
                     MonoDelta::FromSeconds(FLAGS_xcluster_ysql_statement_timeout_sec));
           },
+      .set_normal_oid_counter_above_all_normal_oids_func =
+          [this](NamespaceId namespace_id) {
+            return SetNormalOidCounterAboveAllNormalOids(namespace_id);
+          },
       .get_normal_oid_higher_than_any_used_normal_oid_func =
           [client_future = master_.client_future()](NamespaceId namespace_id) -> Result<uint32_t> {
         auto* yb_client = client_future.get();
@@ -534,6 +538,22 @@ class XClusterCreateStreamContextImpl : public XClusterCreateStreamsContext {
   std::vector<TableId> table_ids;
 };
 
+Status XClusterSourceManager::SetNormalOidCounterAboveAllNormalOids(NamespaceId namespace_id) {
+  auto database_oid = VERIFY_RESULT(GetPgsqlDatabaseOid(namespace_id));
+  VLOG(1) << "Calling ReadHighestNormalPreservableOid on database OID " << database_oid;
+  auto highest_oid = VERIFY_RESULT(sys_catalog_.ReadHighestNormalPreservableOid(database_oid));
+  auto* yb_client = master_.client_future().get();
+  SCHECK(yb_client, IllegalState, "Client not initialized or shutting down");
+  VLOG(1) << "Bumping normal space OID for database OID " << database_oid << " above "
+          << highest_oid;
+  uint32_t begin_oid, end_oid;
+  RETURN_NOT_OK(yb_client->ReservePgsqlOids(
+      namespace_id, /*next_oid=*/highest_oid, /*count=*/1, &begin_oid, &end_oid,
+      /*use_secondary_space=*/false));
+  VLOG(1) << "Invalidating TServer OID caches for database OID " << database_oid;
+  return catalog_manager_.InvalidateTserverOidCaches();
+}
+
 Result<std::unique_ptr<XClusterCreateStreamsContext>>
 XClusterSourceManager::CreateStreamsForDbScoped(
     const std::vector<TableId>& table_ids, const LeaderEpoch& epoch) {
@@ -1201,7 +1221,7 @@ Status XClusterSourceManager::MarkIndexBackfillCompleted(
         for (const auto& stream : tables_to_stream_map_.at(index_id)) {
           LOG(INFO) << "Checkpointing xCluster stream " << stream->StreamId() << " of index "
                     << index_id << " to its end of WAL";
-          table_streams.push_back({index_id, stream->StreamId()});
+          table_streams.emplace_back(index_id, stream->StreamId());
         }
       }
     }
diff --git a/src/yb/master/xcluster/xcluster_source_manager.h b/src/yb/master/xcluster/xcluster_source_manager.h
index ca2f3a3a20..2dbbff0cb4 100644
--- a/src/yb/master/xcluster/xcluster_source_manager.h
+++ b/src/yb/master/xcluster/xcluster_source_manager.h
@@ -207,6 +207,8 @@ class XClusterSourceManager {
       const xcluster::ReplicationGroupId& replication_group_id) const
       EXCLUDES(outbound_replication_group_map_mutex_);
 
+  Status SetNormalOidCounterAboveAllNormalOids(NamespaceId namespace_id);
+
   Result<std::unique_ptr<XClusterCreateStreamsContext>> CreateStreamsForDbScoped(
       const std::vector<TableId>& table_ids, const LeaderEpoch& epoch);
   Result<xrepl::StreamId> CreateNonTxnStreamForNewTable(
