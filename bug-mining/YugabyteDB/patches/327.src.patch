diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
index 9d52309228..2bacdf5a31 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/create_drop_table.out
@@ -109,20 +109,3 @@ SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end
  {"query": "DROP TABLE foo_partitioned_by_col"}
 (18 rows)
 
--- Test mix of temp and regular tables.
-CREATE TEMP TABLE temp_foo(i int PRIMARY KEY);
-CREATE TABLE foo(i int PRIMARY KEY);
-DROP TABLE temp_foo, foo; -- should fail
-ERROR:  unsupported DROP command, found mix of temporary and persisted objects in DDL command
-DETAIL:  To manually replicate, run DDL on the source followed by the target with SET yb_xcluster_ddl_replication.enable_manual_ddl_replication = true
-DROP TABLE foo, temp_foo; -- should fail
-ERROR:  unsupported DROP command, found mix of temporary and persisted objects in DDL command
-DETAIL:  To manually replicate, run DDL on the source followed by the target with SET yb_xcluster_ddl_replication.enable_manual_ddl_replication = true
-DROP TABLE temp_foo;
-DROP TABLE foo;
-select * from TEST_verify_replicated_ddls();
- test_verify_replicated_ddls 
------------------------------
- t
-(1 row)
-
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/materialized_views.out b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/materialized_views.out
new file mode 100644
index 0000000000..f37e96afbd
--- /dev/null
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/materialized_views.out
@@ -0,0 +1,56 @@
+CALL TEST_reset();
+SELECT yb_xcluster_ddl_replication.get_replication_role();
+ get_replication_role 
+----------------------
+ source
+(1 row)
+
+CREATE TABLE products (
+    id INT PRIMARY KEY,
+    category TEXT,
+    price NUMERIC
+);
+CREATE MATERIALIZED VIEW product_summary AS
+  SELECT category, COUNT(*) as item_count
+  FROM products
+  GROUP BY category;
+-- TODO(#28514): Uncomment this test case as part of new materialized view implementation
+-- COMMENT ON MATERIALIZED VIEW product_summary
+--   IS 'Stores the total count of products per category.';
+ALTER MATERIALIZED VIEW product_summary RENAME TO product_inventory;
+REFRESH MATERIALIZED VIEW product_inventory;
+DROP MATERIALIZED VIEW product_inventory;
+SELECT yb_data FROM public.TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
+                                                                                                                            yb_data                                                                                                                            
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE TABLE products (\n    id INT PRIMARY KEY,\n    category TEXT,\n    price NUMERIC\n)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "products", "relfile_oid": "***"}]}
+(1 row)
+
+-- Test dropping materialized views using other DROP commands
+-- DROP SCHEMA
+CREATE SCHEMA IF NOT EXISTS permanent_schema;
+CREATE TABLE permanent_schema.my_table (id INT);
+CREATE MATERIALIZED VIEW permanent_schema.my_mview AS SELECT 'hello' AS greeting;
+DROP SCHEMA permanent_schema CASCADE;
+NOTICE:  drop cascades to 2 other objects
+DETAIL:  drop cascades to materialized view permanent_schema.my_mview
+drop cascades to table permanent_schema.my_table
+ERROR:  unsupported drop of materialized view permanent_schema.my_mview
+DETAIL:  This database is being replicated using xCluster automatic mode, which only supports dropping materialized views via DROP MATERIALIZED VIEW.
+HINT:  Drop materialized views using DROP MATERIALIZED VIEW.
+-- DROP ROLE
+CREATE ROLE drop_me_role;
+SET ROLE drop_me_role;
+CREATE TEMP TABLE my_temp_object (id INT);
+CREATE MATERIALIZED VIEW my_mview AS SELECT 'hello' AS greeting;
+RESET ROLE;
+DROP OWNED BY drop_me_role;
+ERROR:  unsupported drop of materialized view public.my_mview
+DETAIL:  This database is being replicated using xCluster automatic mode, which only supports dropping materialized views via DROP MATERIALIZED VIEW.
+HINT:  Drop materialized views using DROP MATERIALIZED VIEW.
+select * from TEST_verify_replicated_ddls();
+ test_verify_replicated_ddls 
+-----------------------------
+ t
+(1 row)
+
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/mixed_temporary_and_persistent.out b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/mixed_temporary_and_persistent.out
new file mode 100644
index 0000000000..39cbe1a7ea
--- /dev/null
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/mixed_temporary_and_persistent.out
@@ -0,0 +1,27 @@
+CALL TEST_reset();
+SELECT yb_xcluster_ddl_replication.get_replication_role();
+ get_replication_role 
+----------------------
+ source
+(1 row)
+
+-- Test dropping mix of temp and regular tables.
+CREATE TEMP TABLE temp_foo(i int PRIMARY KEY);
+CREATE TABLE foo(i int PRIMARY KEY);
+DROP TABLE temp_foo, foo; -- should fail
+ERROR:  cannot drop temporary and permanent objects in one command
+DETAIL:  This database is being replicated using xCluster automatic mode, which does not support DDLs that simultaneously drop both temporary and permanent objects.
+HINT:  Drop the temporary objects separately from the permanent ones using multiple commands.
+DROP TABLE foo, temp_foo; -- should fail
+ERROR:  cannot drop temporary and permanent objects in one command
+DETAIL:  This database is being replicated using xCluster automatic mode, which does not support DDLs that simultaneously drop both temporary and permanent objects.
+HINT:  Drop the temporary objects separately from the permanent ones using multiple commands.
+DROP TABLE temp_foo;
+DROP TABLE foo;
+SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
+                                                                                              yb_data                                                                                              
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "DROP TABLE foo", "schema": "public", "version": 1, "command_tag": "DROP TABLE"}
+(2 rows)
+
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/truncate.out b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/truncate.out
new file mode 100644
index 0000000000..3ac5177a5d
--- /dev/null
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/expected/truncate.out
@@ -0,0 +1,22 @@
+CALL TEST_reset();
+SELECT yb_xcluster_ddl_replication.get_replication_role();
+ get_replication_role 
+----------------------
+ source
+(1 row)
+
+CREATE TEMP TABLE temp_foo(i int PRIMARY KEY);
+CREATE TABLE foo(i int PRIMARY KEY);
+TRUNCATE foo, temp_foo;  -- should fail
+ERROR:  unsupported mix of temporary and permanent objects
+DETAIL:  This database is being replicated using xCluster automatic mode, which does not support DDLs that simultaneously use both temporary and permanent objects.
+HINT:  Using multiple commands, manipulate the temporary objects separately from the permanent ones.
+TRUNCATE foo;
+TRUNCATE temp_foo;
+SELECT yb_data FROM public.TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
+                                                                                              yb_data                                                                                              
+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ {"user": "yugabyte", "query": "CREATE TABLE foo(i int PRIMARY KEY)", "schema": "public", "version": 1, "command_tag": "CREATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
+ {"user": "yugabyte", "query": "TRUNCATE foo", "schema": "public", "version": 1, "command_tag": "TRUNCATE TABLE", "new_rel_map": [{"rel_name": "foo", "relfile_oid": "***"}]}
+(2 rows)
+
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
index 48e08b8a2f..5f70bfb706 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.c
@@ -200,6 +200,70 @@ IsTempSchema(const char *schema_name)
 	return schema_name && !strcmp(schema_name, "pg_temp");
 }
 
+bool
+IsTemporaryHelper(char *thing_kind, Oid thing_oid, char *thing_table,
+				  char *relation_oid_column)
+{
+	StringInfoData query;
+	bool		isnull;
+	Datum		is_temp_datum;
+	HeapTuple	tuple;
+	TupleDesc	tupdesc;
+
+	/*
+	 * Each kind of "thing" has a dedicated table indexed by its OID.  We need
+	 * to move from that row to the relation it is associated with in order
+	 * to find that relation's temporary-ness.
+	 */
+
+	SPI_push();
+	initStringInfo(&query);
+	appendStringInfo(&query,
+					 "SELECT (c.relpersistence = 't') "
+					 "FROM pg_catalog.pg_class AS c "
+					 "JOIN pg_catalog.%s AS t ON c.oid = t.%s "
+					 "WHERE t.oid = %u",
+					 thing_table, relation_oid_column, thing_oid);
+
+	int exec_result = SPI_execute(query.data, /* read_only= */ true,
+								  /* tcount= */ 0);
+	if (exec_result != SPI_OK_SELECT)
+		elog(ERROR, "SPI_exec failed (error %d): %s", exec_result, query.data);
+	pfree(query.data);
+
+	if (SPI_processed == 0)
+		elog(ERROR, "could not find %s with OID %u", thing_kind, thing_oid);
+
+	tupdesc = SPI_tuptable->tupdesc;
+	tuple = SPI_tuptable->vals[0];
+	is_temp_datum = SPI_getbinval(tuple, tupdesc, 1, &isnull);
+	/* A null result here would indicate catalog corruption */
+	if (isnull)
+		elog(ERROR, "relpersistence check returned null for %s %u", thing_kind,
+			 thing_oid);
+
+	SPI_pop();
+	return DatumGetBool(is_temp_datum);
+}
+
+bool
+IsTemporaryPolicy(Oid policy_oid)
+{
+	return IsTemporaryHelper("policy", policy_oid, "pg_policy", "polrelid");
+}
+
+bool
+IsTemporaryTrigger(Oid trigger_oid)
+{
+	return IsTemporaryHelper("trigger", trigger_oid, "pg_trigger", "tgrelid");
+}
+
+bool
+IsTemporaryRule(Oid rule_oid)
+{
+	return IsTemporaryHelper("rule", rule_oid, "pg_rewrite", "ev_class");
+}
+
 Oid
 GetColocationIdForTableRewrite(Relation *rel)
 {
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
index ba754c9ba8..271baa26e9 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/extension_util.h
@@ -87,6 +87,12 @@ extern char *SPI_TextArrayGetElement(HeapTuple spi_tuple, int column_id,
 /* If true, any object in this schema is a temporary object. */
 extern bool IsTempSchema(const char *schema_name);
 
+extern bool IsTemporaryPolicy(Oid policy_oid);
+
+extern bool IsTemporaryTrigger(Oid trigger_oid);
+
+extern bool IsTemporaryRule(Oid rule_oid);
+
 /* Returns the relation's colocation id or InvalidOid (0) if not colocated. */
 extern Oid	GetColocationIdFromRelation(Relation *rel, bool is_table_rewrite);
 
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
index 184336a347..b1efd82b2a 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/source_ddl_end_handler.c
@@ -59,10 +59,11 @@
 #include "utils/palloc.h"
 #include "utils/rel.h"
 
-#define DDL_END_OBJID_COLUMN_ID		  1
-#define DDL_END_COMMAND_TAG_COLUMN_ID 2
-#define DDL_END_SCHEMA_NAME_COLUMN_ID 3
-#define DDL_END_COMMAND_COLUMN_ID     4
+#define DDL_END_CLASSID_COLUMN_ID	  1
+#define DDL_END_OBJID_COLUMN_ID		  2
+#define DDL_END_COMMAND_TAG_COLUMN_ID 3
+#define DDL_END_SCHEMA_NAME_COLUMN_ID 4
+#define DDL_END_COMMAND_COLUMN_ID     5
 
 #define SQL_DROP_CLASS_ID_COLUMN_ID	     1
 #define SQL_DROP_IS_TEMP_COLUMN_ID	     2
@@ -588,6 +589,7 @@ AddTypeInfo(Oid pg_type_oid, char *schema, List **type_info_list)
 
 typedef struct YbCommandInfo
 {
+	Oid			class_id;
 	Oid			oid;
 	char	   *command_tag_name;
 	char	   *schema;			/* may be NULL */
@@ -601,8 +603,8 @@ GetSourceEventTriggerDDLCommands(YbCommandInfo **info_array_out)
 
 	initStringInfo(&query_buf);
 	appendStringInfo(&query_buf,
-					 "SELECT objid, command_tag, schema_name, command FROM "
-					 "pg_catalog.pg_event_trigger_ddl_commands()");
+					 "SELECT classid, objid, command_tag, schema_name, command "
+					 "FROM pg_catalog.pg_event_trigger_ddl_commands()");
 	int			exec_res = SPI_execute(query_buf.data,
 									   true,	/* readonly */
 									   0);	/* tcount */
@@ -629,8 +631,14 @@ GetSourceEventTriggerDDLCommands(YbCommandInfo **info_array_out)
 		if (command_tag != CMDTAG_GRANT && command_tag != CMDTAG_REVOKE
 			&& command_tag != CMDTAG_ALTER_DEFAULT_PRIVILEGES)
 		{
+			info->class_id = SPI_GetOid(spi_tuple, DDL_END_CLASSID_COLUMN_ID);
 			info->oid = SPI_GetOid(spi_tuple, DDL_END_OBJID_COLUMN_ID);
 		}
+		else
+		{
+			info->class_id = InvalidOid;
+			info->oid = InvalidOid;
+		}
 		info->schema = SPI_GetText(spi_tuple, DDL_END_SCHEMA_NAME_COLUMN_ID);
 		info->command = GetCollectedCommand(spi_tuple, DDL_END_COMMAND_COLUMN_ID);
 	}
@@ -732,7 +740,7 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 	List	   *sequence_info_list = NIL;
 	List	   *type_info_list = NIL;
 	bool		found_temp = false;
-	bool		found_matview = false;
+	bool		found_materialized_view_command = false;
 
 	/*
 	 * As long as there is at least one command that needs to be replicated, we
@@ -748,12 +756,17 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 		CommandTag	command_tag = GetCommandTagEnum(info->command_tag_name);
 		char	   *schema = info->schema;
 
+		bool		is_temporary_object = IsTempSchema(schema);
 		/*
-		 * The below works for objects with names but not nameless parts.
-		 * TODO(#25885): add code to handle nameless parts.
+		 * The above works for most objects, but in a few cases Postgres does
+		 * not provide the schema; we thus have to handle those separately here.
 		 */
-		bool		is_temporary_object = IsTempSchema(schema);
-
+		if (info->class_id == PolicyRelationId)
+			is_temporary_object = IsTemporaryPolicy(info->oid);
+		else if (info->class_id == TriggerRelationId)
+			is_temporary_object = IsTemporaryTrigger(info->oid);
+		else if (info->class_id == RewriteRelationId)
+			is_temporary_object = IsTemporaryRule(info->oid);
 		found_temp |= is_temporary_object;
 
 		if (command_tag == CMDTAG_CREATE_TABLE ||
@@ -847,7 +860,7 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 		}
 		else if (IsMatViewCommand(command_tag))
 		{
-			found_matview = true;
+			found_materialized_view_command = true;
 		}
 		else if (IsPassThroughDdlSupported(command_tag_name))
 		{
@@ -865,14 +878,23 @@ ProcessSourceEventTriggerDDLCommands(JsonbParseState *state)
 		if (found_temp)
 			ereport(ERROR,
 					(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
-					 errmsg("unsupported mix of temporary and persisted objects in DDL command"),
-					 errdetail("%s", kManualReplicationErrorMsg)));
-
-		if (found_matview)
+					 errmsg("unsupported mix of temporary and permanent objects"),
+					 errdetail("This database is being replicated using xCluster "
+							   "automatic mode, which does not support DDLs "
+							   "that simultaneously use both temporary and "
+							   "permanent objects."),
+					 errhint("Using multiple commands, manipulate the temporary "
+							 "objects separately from the permanent ones.")));
+
+		/* The next error should not be possible. */
+		/* TODO(#28514): remove this code because it will no longer be an error. */
+		if (found_materialized_view_command)
 			ereport(ERROR,
 					(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
-					 errmsg("unsupported mix of materialized view and other DDL commands"),
-					 errdetail("%s", kManualReplicationErrorMsg)));
+					 errmsg("unsupported mix of materialized view and other DDLs"),
+					 errdetail("This database is being replicated using xCluster "
+							   "automatic mode, which does not support this "
+							   "command.")));
 	}
 
 	ProcessNewRelationsList(state, &new_rel_list);
@@ -925,7 +947,9 @@ bool
 ProcessSourceEventTriggerDroppedObjects(CommandTag tag)
 {
 	/*
-	 * Matview related DDLs are not replicated.
+	 * We choose to not replicate materialized view DDLs (e.g., DROP
+	 * MATERIALIZED VIEW).  Note that commands like DROP SCHEMA can also drop
+	 * materialized views and are handled separately below.
 	 */
 	if (IsMatViewCommand(tag))
 		return false;
@@ -942,12 +966,12 @@ ProcessSourceEventTriggerDroppedObjects(CommandTag tag)
 	if (exec_res != SPI_OK_SELECT)
 		elog(ERROR, "SPI_exec failed (error %d): %s", exec_res, query_buf.data);
 
+	bool		found_temp = false;
 	/*
 	 * As long as there is at least one command that needs to be replicated, we
 	 * will set this to true and replicate the entire query string.
 	 */
 	bool		should_replicate_ddl = false;
-	bool		found_temp = false;
 
 	for (int row = 0; row < SPI_processed; row++)
 	{
@@ -966,6 +990,7 @@ ProcessSourceEventTriggerDroppedObjects(CommandTag tag)
 		if (is_temp)
 		{
 			found_temp = true;
+			/* Postgres does not support temporary materialized views. */
 			continue;
 		}
 
@@ -989,7 +1014,6 @@ ProcessSourceEventTriggerDroppedObjects(CommandTag tag)
 			case OperatorRelationId:
 			case PolicyRelationId:
 			case ProcedureRelationId:
-			case RelationRelationId:
 			case RewriteRelationId:
 			case StatisticExtRelationId:
 			case TriggerRelationId:
@@ -1002,6 +1026,31 @@ ProcessSourceEventTriggerDroppedObjects(CommandTag tag)
 			case UserMappingRelationId:
 				should_replicate_ddl = true;
 				break;
+			case RelationRelationId:
+			{
+				const char *object_type = SPI_GetText(spi_tuple,
+													  SQL_DROP_OBJECT_TYPE_COLUMN_ID);
+				const char *schema_name = SPI_GetText(spi_tuple,
+													  SQL_DROP_SCHEMA_NAME_COLUMN_ID);
+				const char *object_name = SPI_GetText(spi_tuple,
+													  SQL_DROP_OBJECT_NAME_COLUMN_ID);
+				bool is_materialized_view = !strcmp(object_type, "materialized "
+																 "view");
+				if (is_materialized_view)
+					ereport(ERROR,
+							(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
+							 errmsg("unsupported drop of materialized view %s.%s",
+									schema_name, object_name),
+							 errdetail("This database is being replicated using "
+									   "xCluster automatic mode, which only "
+									   "supports dropping materialized views "
+									   "via DROP MATERIALIZED VIEW."),
+							 errhint("Drop materialized views using DROP "
+									 "MATERIALIZED VIEW.")));
+
+				should_replicate_ddl = true;
+			}
+			break;
 			default:
 				{
 					const char *object_type = SPI_GetText(spi_tuple,
@@ -1012,7 +1061,7 @@ ProcessSourceEventTriggerDroppedObjects(CommandTag tag)
 														  SQL_DROP_OBJECT_NAME_COLUMN_ID);
 
 					elog(ERROR,
-						 "Unsupported Drop DDL for xCluster replicated DB: %s "
+						 "unsupported Drop DDL for xCluster replicated DB: %s "
 						 "(class_id: %d), object_name: %s.%s\n%s",
 						 object_type, class_id, schema_name, object_name,
 						 kManualReplicationErrorMsg);
@@ -1023,9 +1072,13 @@ ProcessSourceEventTriggerDroppedObjects(CommandTag tag)
 	if (found_temp && should_replicate_ddl)
 		ereport(ERROR,
 				(errcode(ERRCODE_FEATURE_NOT_SUPPORTED),
-				 errmsg("unsupported DROP command, found mix of "
-						"temporary and persisted objects in DDL command"),
-				 errdetail("%s", kManualReplicationErrorMsg)));
+				 errmsg("cannot drop temporary and permanent objects in one command"),
+				 errdetail("This database is being replicated using xCluster "
+						   "automatic mode, which does not support DDLs "
+						   "that simultaneously drop both temporary and "
+						   "permanent objects."),
+				 errhint("Drop the temporary objects separately from the "
+						 "permanent ones using multiple commands.")));
 
 	return should_replicate_ddl;
 }
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/create_drop_table.sql b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/create_drop_table.sql
index 272a7b17ce..3a041573ae 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/create_drop_table.sql
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/create_drop_table.sql
@@ -53,13 +53,3 @@ DROP TABLE foo_partitioned_by_col;
 
 SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
 SELECT yb_data FROM yb_xcluster_ddl_replication.replicated_ddls ORDER BY ddl_end_time;
-
--- Test mix of temp and regular tables.
-CREATE TEMP TABLE temp_foo(i int PRIMARY KEY);
-CREATE TABLE foo(i int PRIMARY KEY);
-DROP TABLE temp_foo, foo; -- should fail
-DROP TABLE foo, temp_foo; -- should fail
-DROP TABLE temp_foo;
-DROP TABLE foo;
-
-select * from TEST_verify_replicated_ddls();
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/materialized_views.sql b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/materialized_views.sql
new file mode 100644
index 0000000000..b459b71203
--- /dev/null
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/materialized_views.sql
@@ -0,0 +1,43 @@
+CALL TEST_reset();
+SELECT yb_xcluster_ddl_replication.get_replication_role();
+
+CREATE TABLE products (
+    id INT PRIMARY KEY,
+    category TEXT,
+    price NUMERIC
+);
+
+CREATE MATERIALIZED VIEW product_summary AS
+  SELECT category, COUNT(*) as item_count
+  FROM products
+  GROUP BY category;
+
+-- TODO(#28514): Uncomment this test case as part of new materialized view implementation
+-- COMMENT ON MATERIALIZED VIEW product_summary
+--   IS 'Stores the total count of products per category.';
+
+ALTER MATERIALIZED VIEW product_summary RENAME TO product_inventory;
+
+REFRESH MATERIALIZED VIEW product_inventory;
+
+DROP MATERIALIZED VIEW product_inventory;
+
+SELECT yb_data FROM public.TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
+
+
+-- Test dropping materialized views using other DROP commands
+-- DROP SCHEMA
+CREATE SCHEMA IF NOT EXISTS permanent_schema;
+CREATE TABLE permanent_schema.my_table (id INT);
+CREATE MATERIALIZED VIEW permanent_schema.my_mview AS SELECT 'hello' AS greeting;
+DROP SCHEMA permanent_schema CASCADE;
+
+-- DROP ROLE
+CREATE ROLE drop_me_role;
+SET ROLE drop_me_role;
+CREATE TEMP TABLE my_temp_object (id INT);
+CREATE MATERIALIZED VIEW my_mview AS SELECT 'hello' AS greeting;
+RESET ROLE;
+DROP OWNED BY drop_me_role;
+
+select * from TEST_verify_replicated_ddls();
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/mixed_temporary_and_persistent.sql b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/mixed_temporary_and_persistent.sql
new file mode 100644
index 0000000000..d5cf92966c
--- /dev/null
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/mixed_temporary_and_persistent.sql
@@ -0,0 +1,13 @@
+CALL TEST_reset();
+SELECT yb_xcluster_ddl_replication.get_replication_role();
+
+
+-- Test dropping mix of temp and regular tables.
+CREATE TEMP TABLE temp_foo(i int PRIMARY KEY);
+CREATE TABLE foo(i int PRIMARY KEY);
+DROP TABLE temp_foo, foo; -- should fail
+DROP TABLE foo, temp_foo; -- should fail
+DROP TABLE temp_foo;
+DROP TABLE foo;
+
+SELECT yb_data FROM TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/truncate.sql b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/truncate.sql
new file mode 100644
index 0000000000..8c5862fa80
--- /dev/null
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/sql/truncate.sql
@@ -0,0 +1,10 @@
+CALL TEST_reset();
+SELECT yb_xcluster_ddl_replication.get_replication_role();
+
+CREATE TEMP TABLE temp_foo(i int PRIMARY KEY);
+CREATE TABLE foo(i int PRIMARY KEY);
+TRUNCATE foo, temp_foo;  -- should fail
+TRUNCATE foo;
+TRUNCATE temp_foo;
+
+SELECT yb_data FROM public.TEST_filtered_ddl_queue() ORDER BY ddl_end_time;
diff --git a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_schedule b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_schedule
index ea1d3136ed..5da42e2abc 100644
--- a/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_schedule
+++ b/src/postgres/yb-extensions/yb_xcluster_ddl_replication/yb_schedule
@@ -5,5 +5,9 @@ test: routines
 test: create_drop_table
 test: create_drop_index
 
+test: mixed_temporary_and_persistent
+test: truncate
+test: materialized_views
+
 test: colocated_setup
 test: create_colocated_table
diff --git a/src/yb/integration-tests/xcluster/sql/temporary_objects.sql b/src/yb/integration-tests/xcluster/sql/temporary_objects.sql
index 443af6f25e..3eaa32c749 100644
--- a/src/yb/integration-tests/xcluster/sql/temporary_objects.sql
+++ b/src/yb/integration-tests/xcluster/sql/temporary_objects.sql
@@ -93,16 +93,15 @@ CREATE TEMP TABLE temp_table_for_check (
 ALTER TABLE temp_table_for_check DROP CONSTRAINT temp_table_for_check_age_check;
 
 -- Create a temporary table and enable RLS
--- Uncomment as part of #25885
--- CREATE TEMP TABLE temp_table_for_rls (
---     id INT PRIMARY KEY,
---     sensitive_data TEXT
--- );
--- ALTER TABLE temp_table_for_rls ENABLE ROW LEVEL SECURITY;
--- -- Create a policy
--- CREATE POLICY temp_my_policy ON temp_table_for_rls USING (id > 1);
--- -- Drop the policy
--- DROP POLICY temp_my_policy ON temp_table_for_rls;
+CREATE TEMP TABLE temp_table_for_rls (
+    id INT PRIMARY KEY,
+    sensitive_data TEXT
+);
+ALTER TABLE temp_table_for_rls ENABLE ROW LEVEL SECURITY;
+-- Create a policy
+CREATE POLICY temp_my_policy ON temp_table_for_rls USING (id > 1);
+-- Drop the policy
+DROP POLICY temp_my_policy ON temp_table_for_rls;
 
 
 --
@@ -129,26 +128,36 @@ CREATE INDEX temp_index_on_value ON temp_complex_table (value);
 ALTER TABLE temp_complex_table ENABLE ROW LEVEL SECURITY;
 
 -- Add a Row-Level Security Policy
--- Uncomment as part of #25885
--- CREATE POLICY temp_policy ON temp_complex_table 
---     FOR SELECT USING (id > 0);
-
--- Attach a trigger to the table
--- Uncomment as part of #25885
--- CREATE FUNCTION temp_trigger_function() RETURNS trigger AS $$
--- BEGIN
---     NEW.value := UPPER(NEW.value);
---     RETURN NEW;
--- END;
--- $$ LANGUAGE plpgsql;
--- CREATE TRIGGER temp_trigger
---     BEFORE INSERT ON temp_complex_table
---     FOR EACH ROW EXECUTE FUNCTION temp_trigger_function();
+CREATE POLICY temp_policy ON temp_complex_table 
+    FOR SELECT USING (id > 0);
+
+-- Attach a trigger to the table; function here is a temporary object as well.
+CREATE FUNCTION pg_temp.temp_trigger_function() RETURNS trigger AS $$
+BEGIN
+    NEW.value := UPPER(NEW.value);
+    RETURN NEW;
+END;
+$$ LANGUAGE plpgsql;
+CREATE TRIGGER temp_trigger
+    BEFORE INSERT ON temp_complex_table
+    FOR EACH ROW EXECUTE FUNCTION pg_temp.temp_trigger_function();
 
 -- Create a sequence and attach it to a column
--- Uncomment this as part of #24080
--- CREATE TEMP SEQUENCE temp_sequence START 1;
--- ALTER TABLE temp_complex_table ALTER COLUMN id SET DEFAULT nextval('temp_sequence');
+CREATE TEMP SEQUENCE temp_sequence START 1;
+ALTER TABLE temp_complex_table ALTER COLUMN id SET DEFAULT nextval('temp_sequence');
 
 -- Finally, DROP everything using CASCADE
 DROP TABLE temp_complex_table CASCADE;
+DROP FUNCTION pg_temp.temp_trigger_function;
+
+
+-- Temporary rule case:
+CREATE TEMP TABLE temp_table_for_rule (
+    id INT PRIMARY KEY
+);
+-- Create a rule
+CREATE RULE _test_temp_rule AS
+    ON UPDATE TO temp_table_for_rule
+    DO INSTEAD NOTHING;
+-- Drop the rule
+DROP RULE _test_temp_rule ON temp_table_for_rule;
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
index e7fcdf7b11..03a06949dd 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
@@ -3271,7 +3271,7 @@ TEST_F(XClusterDDLReplicationTest, TruncateTable) {
   {
     ASSERT_OK(producer_conn_->Execute("CREATE TEMP TABLE tbl_tmp(id int)"));
     const auto expected_err_msg =
-        "unsupported mix of temporary and persisted objects in DDL command";
+        "unsupported mix of temporary and permanent objects";
     ASSERT_NOK_STR_CONTAINS(
         producer_conn_->Execute("TRUNCATE TABLE tbl_tmp, tbl1"), expected_err_msg);
     ASSERT_NOK_STR_CONTAINS(
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
index b0cbf289c4..14f0f83c65 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
@@ -403,13 +403,10 @@ TEST_F(XClusterPgRegressDDLReplicationTest, PgRegressCreateDropTemp) {
 
   // Ensure no DDLs on temporary objects got replicated.  For this test, there should be no DDLs on
   // non-temporary objects so it suffices to check that the count of replicated DDLs is 0.
-  //
-  // TODO(#25885): When triggers are working and uncommented in the test, this will have to be
-  // adjusted to exclude DDLs for creating functions as they are non-temporary objects.
   auto conn = ASSERT_RESULT(producer_cluster_.ConnectToDB(namespace_name));
-  auto num_replicated_ddls = ASSERT_RESULT(
-      conn.FetchRowAsString("SELECT count(*) FROM yb_xcluster_ddl_replication.ddl_queue;", ","));
-  ASSERT_EQ(num_replicated_ddls, "0");
+  auto num_replicated_ddls = ASSERT_RESULT(conn.FetchRow<pgwrapper::PGUint64>(
+      "SELECT count(*) FROM yb_xcluster_ddl_replication.ddl_queue;"));
+  ASSERT_EQ(num_replicated_ddls, 0);
 }
 
 TEST_F(XClusterPgRegressDDLReplicationTest, PgRegressCreateDropSequence) {
