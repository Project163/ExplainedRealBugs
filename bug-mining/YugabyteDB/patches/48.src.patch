diff --git a/src/yb/client/xcluster_client.cc b/src/yb/client/xcluster_client.cc
index f6f7f42f0b..37dddb8820 100644
--- a/src/yb/client/xcluster_client.cc
+++ b/src/yb/client/xcluster_client.cc
@@ -61,14 +61,16 @@ Status XClusterRemoteClient::Init(
   return Status::OK();
 }
 
-Result<UniverseUuid> XClusterRemoteClient::SetupUniverseReplication(
+Result<UniverseUuid> XClusterRemoteClient::SetupDbScopedUniverseReplication(
     const xcluster::ReplicationGroupId& replication_group_id,
     const std::vector<HostPort>& source_master_addresses,
-    const std::vector<NamespaceName>& namespace_names, const std::vector<TableId>& source_table_ids,
-    const std::vector<xrepl::StreamId>& bootstrap_ids, Transactional transactional) {
+    const std::vector<NamespaceName>& namespace_names,
+    const std::vector<NamespaceId>& source_namespace_ids,
+    const std::vector<TableId>& source_table_ids,
+    const std::vector<xrepl::StreamId>& bootstrap_ids) {
   master::SetupUniverseReplicationRequestPB req;
   req.set_replication_group_id(replication_group_id.ToString());
-  req.set_transactional(transactional);
+  req.set_transactional(true);  // Db Scoped replication is always transactional.
 
   HostPortsToPBs(source_master_addresses, req.mutable_producer_master_addresses());
 
@@ -81,6 +83,16 @@ Result<UniverseUuid> XClusterRemoteClient::SetupUniverseReplication(
     req.add_producer_bootstrap_ids(bootstrap_id.ToString());
   }
 
+  SCHECK_EQ(
+      namespace_names.size(), source_namespace_ids.size(), InvalidArgument,
+      "Namespace names and IDs count must match");
+  for (const auto& namespace_name : namespace_names) {
+    req.add_namespace_names(namespace_name);
+  }
+  for (const auto& namespace_id : source_namespace_ids) {
+    req.add_producer_namespace_ids(namespace_id);
+  }
+
   auto resp = VERIFY_RESULT(yb_client_->SetupUniverseReplication(req));
 
   if (resp.has_error()) {
@@ -115,4 +127,41 @@ Result<master::IsOperationDoneResult> XClusterRemoteClient::IsSetupUniverseRepli
   return master::IsOperationDoneResult(resp.done(), std::move(status));
 }
 
+Status XClusterRemoteClient::GetXClusterTableCheckpointInfos(
+    const xcluster::ReplicationGroupId& replication_group_id, const NamespaceId& namespace_id,
+    const std::vector<TableName>& table_names, const std::vector<PgSchemaName>& pg_schema_names,
+    BootstrapProducerCallback user_callback) {
+  auto callback =
+      [cb = std::move(user_callback)](Result<master::GetXClusterStreamsResponsePB> result) -> void {
+    Status status;
+    if (!result) {
+      status = std::move(result.status());
+    } else if (result->has_error()) {
+      status = StatusFromPB(result->error().status());
+    } else if (result->not_ready()) {
+      status = STATUS_FORMAT(IllegalState, "XCluster stream is not ready");
+    }
+
+    if (!status.ok()) {
+      cb(status);
+      return;
+    }
+    std::vector<TableId> producer_table_ids;
+    std::vector<std::string> stream_ids;
+    for (const auto& table_info : result->table_infos()) {
+      producer_table_ids.emplace_back(table_info.table_id());
+      stream_ids.emplace_back(table_info.xrepl_stream_id());
+    }
+
+    // With Db scoped replication we do not currently return the bootstrap time. For more info check
+    // AddTableToXClusterTargetTask::BootstrapTableCallback.
+    cb(std::make_tuple(std::move(producer_table_ids), std::move(stream_ids), HybridTime::kInvalid));
+  };
+
+  RETURN_NOT_OK(yb_client_->GetXClusterStreams(
+      CoarseMonoClock::Now() + yb_client_->default_admin_operation_timeout(), replication_group_id,
+      namespace_id, table_names, pg_schema_names, std::move(callback)));
+
+  return Status::OK();
+}
 }  // namespace yb::client
diff --git a/src/yb/client/xcluster_client.h b/src/yb/client/xcluster_client.h
index 40da35132d..2d3c201796 100644
--- a/src/yb/client/xcluster_client.h
+++ b/src/yb/client/xcluster_client.h
@@ -18,6 +18,7 @@
 
 #include "yb/cdc/xrepl_types.h"
 #include "yb/cdc/xcluster_types.h"
+#include "yb/client/client_fwd.h"
 #include "yb/common/common_net.pb.h"
 #include "yb/common/entity_ids_types.h"
 #include "yb/master/xcluster/master_xcluster_types.h"
@@ -55,16 +56,22 @@ class XClusterRemoteClient {
 
   YB_STRONGLY_TYPED_BOOL(Transactional);
   // This requires flag enable_xcluster_api_v2 to be set.
-  virtual Result<UniverseUuid> SetupUniverseReplication(
+  virtual Result<UniverseUuid> SetupDbScopedUniverseReplication(
       const xcluster::ReplicationGroupId& replication_group_id,
       const std::vector<HostPort>& source_master_addresses,
       const std::vector<NamespaceName>& namespace_names,
+      const std::vector<NamespaceId>& source_namespace_ids,
       const std::vector<TableId>& source_table_ids,
-      const std::vector<xrepl::StreamId>& bootstrap_ids, Transactional transactional);
+      const std::vector<xrepl::StreamId>& bootstrap_ids);
 
   virtual Result<master::IsOperationDoneResult> IsSetupUniverseReplicationDone(
       const xcluster::ReplicationGroupId& replication_group_id);
 
+  Status GetXClusterTableCheckpointInfos(
+      const xcluster::ReplicationGroupId& replication_group_id, const NamespaceId& namespace_id,
+      const std::vector<TableName>& table_names, const std::vector<PgSchemaName>& pg_schema_names,
+      BootstrapProducerCallback user_callback);
+
  private:
   const std::string certs_for_cdc_dir_;
   const MonoDelta timeout_;
diff --git a/src/yb/integration-tests/CMakeLists.txt b/src/yb/integration-tests/CMakeLists.txt
index fb25a472be..180b146484 100644
--- a/src/yb/integration-tests/CMakeLists.txt
+++ b/src/yb/integration-tests/CMakeLists.txt
@@ -219,7 +219,7 @@ ADD_YB_TEST(transaction-test)
 ADD_YB_TEST(encryption-test)
 ADD_YB_TEST(secure_connection_test)
 ADD_YB_TEST(xcluster/xcluster_consistency-test)
-ADD_YB_TEST(xcluster/xcluster_db_scope-test)
+ADD_YB_TEST(xcluster/xcluster_db_scoped-test)
 ADD_YB_TEST(xcluster/xcluster_dr-itest)
 ADD_YB_TEST(xcluster/xcluster_upgrade-test)
 ADD_YB_TEST(xcluster/xcluster_safe_time-itest)
diff --git a/src/yb/integration-tests/xcluster/xcluster_db_scope-test.cc b/src/yb/integration-tests/xcluster/xcluster_db_scope-test.cc
deleted file mode 100644
index 56c71e9922..0000000000
--- a/src/yb/integration-tests/xcluster/xcluster_db_scope-test.cc
+++ /dev/null
@@ -1,155 +0,0 @@
-// Copyright (c) YugabyteDB, Inc.
-//
-// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
-// in compliance with the License.  You may obtain a copy of the License at
-//
-// http://www.apache.org/licenses/LICENSE-2.0
-//
-// Unless required by applicable law or agreed to in writing, software distributed under the License
-// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
-// or implied.  See the License for the specific language governing permissions and limitations
-// under the License.
-//
-
-#include "yb/client/table.h"
-#include "yb/integration-tests/xcluster/xcluster_ysql_test_base.h"
-#include "yb/master/master_replication.proxy.h"
-#include "yb/master/mini_master.h"
-#include "yb/util/backoff_waiter.h"
-
-DECLARE_bool(TEST_enable_xcluster_api_v2);
-
-using namespace std::chrono_literals;
-
-namespace yb {
-
-const MonoDelta kTimeout = 60s * kTimeMultiplier;
-
-class XClusterDBScopedTest : public XClusterYsqlTestBase {
- public:
-  struct SetupParams {
-    std::vector<uint32_t> num_consumer_tablets = {3};
-    std::vector<uint32_t> num_producer_tablets = {3};
-    uint32_t replication_factor = 3;
-    uint32_t num_masters = 1;
-    bool ranged_partitioned = false;
-  };
-
-  XClusterDBScopedTest() = default;
-  ~XClusterDBScopedTest() = default;
-
-  virtual void SetUp() override {
-    XClusterYsqlTestBase::SetUp();
-    ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_enable_xcluster_api_v2) = true;
-  }
-
-  Status SetUpClusters() {
-    static const SetupParams kDefaultParams;
-    return SetUpClusters(kDefaultParams);
-  }
-
-  Status SetUpClusters(const SetupParams& params) {
-    return XClusterYsqlTestBase::SetUpWithParams(
-        params.num_consumer_tablets, params.num_producer_tablets, params.replication_factor,
-        params.num_masters, params.ranged_partitioned);
-  }
-
-  Result<master::MasterReplicationProxy> GetMasterProxy(Cluster& cluster) {
-    return master::MasterReplicationProxy(
-        &cluster.client_->proxy_cache(),
-        VERIFY_RESULT(cluster.mini_cluster_->GetLeaderMiniMaster())->bound_rpc_addr());
-  }
-
-  Result<master::MasterReplicationProxy> GetProducerMasterProxy() {
-    return GetMasterProxy(producer_cluster_);
-  }
-
-  Status CheckpointReplicationGroup() {
-    auto producer_namespace_id = VERIFY_RESULT(GetNamespaceId(producer_client()));
-    auto namespace_id_out = VERIFY_RESULT(producer_client()->XClusterCreateOutboundReplicationGroup(
-        kReplicationGroupId, {namespace_name}));
-    SCHECK_EQ(namespace_id_out.size(), 1, IllegalState, "Namespace count does not match");
-    SCHECK_EQ(
-        namespace_id_out[0], producer_namespace_id, IllegalState, "NamespaceId does not match");
-
-    std::promise<Result<bool>> promise;
-    auto future = promise.get_future();
-    RETURN_NOT_OK(producer_client()->IsXClusterBootstrapRequired(
-        CoarseMonoClock::now() + kTimeout, kReplicationGroupId, producer_namespace_id,
-        [&promise](Result<bool> res) { promise.set_value(res); }));
-    auto bootstrap_required = VERIFY_RESULT(future.get());
-    SCHECK(!bootstrap_required, IllegalState, "Bootstrap should not be required");
-
-    return Status::OK();
-  }
-
-  Result<bool> IsCreateXClusterReplicationDone() {
-    master::IsCreateXClusterReplicationDoneRequestPB req;
-    master::IsCreateXClusterReplicationDoneResponsePB resp;
-    req.set_replication_group_id(kReplicationGroupId.ToString());
-    auto master_addr = consumer_cluster()->GetMasterAddresses();
-    auto hp_vec = VERIFY_RESULT(HostPort::ParseStrings(master_addr, 0));
-    HostPortsToPBs(hp_vec, req.mutable_target_master_addresses());
-
-    auto master_proxy = VERIFY_RESULT(GetProducerMasterProxy());
-
-    rpc::RpcController rpc;
-    rpc.set_timeout(MonoDelta::FromSeconds(kRpcTimeout));
-
-    RETURN_NOT_OK(master_proxy.IsCreateXClusterReplicationDone(req, &resp, &rpc));
-
-    if (resp.has_error()) {
-      return StatusFromPB(resp.error().status());
-    }
-
-    return resp.done();
-  }
-
-  Status WaitForCreateReplicationToFinish() {
-    return WaitFor([this]() { return IsCreateXClusterReplicationDone(); }, kTimeout, __func__);
-  }
-
-  Status CreateReplicationFromCheckpoint() {
-    RETURN_NOT_OK(SetupCertificates(kReplicationGroupId));
-
-    master::CreateXClusterReplicationRequestPB req;
-    master::CreateXClusterReplicationResponsePB resp;
-    req.set_replication_group_id(kReplicationGroupId.ToString());
-    auto master_addr = consumer_cluster()->GetMasterAddresses();
-    auto hp_vec = VERIFY_RESULT(HostPort::ParseStrings(master_addr, 0));
-    HostPortsToPBs(hp_vec, req.mutable_target_master_addresses());
-
-    auto master_proxy = VERIFY_RESULT(GetProducerMasterProxy());
-
-    rpc::RpcController rpc;
-    rpc.set_timeout(MonoDelta::FromSeconds(kRpcTimeout));
-
-    RETURN_NOT_OK(master_proxy.CreateXClusterReplication(req, &resp, &rpc));
-
-    if (resp.has_error()) {
-      return StatusFromPB(resp.error().status());
-    }
-
-    return WaitForCreateReplicationToFinish();
-  }
-};
-
-TEST_F(XClusterDBScopedTest, TestCreateWithCheckpoint) {
-  ASSERT_OK(SetUpClusters());
-
-  ASSERT_OK(CheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
-
-  // Verify that universe was setup on consumer.
-  master::GetUniverseReplicationResponsePB resp;
-  ASSERT_OK(VerifyUniverseReplication(&resp));
-  ASSERT_EQ(resp.entry().replication_group_id(), kReplicationGroupId);
-  ASSERT_EQ(resp.entry().tables_size(), 1);
-  ASSERT_EQ(resp.entry().tables(0), producer_table_->id());
-
-  ASSERT_OK(InsertRowsInProducer(0, 50));
-
-  ASSERT_OK(VerifyWrittenRecords());
-}
-
-}  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_db_scoped-test.cc b/src/yb/integration-tests/xcluster/xcluster_db_scoped-test.cc
new file mode 100644
index 0000000000..51f9c613a1
--- /dev/null
+++ b/src/yb/integration-tests/xcluster/xcluster_db_scoped-test.cc
@@ -0,0 +1,114 @@
+// Copyright (c) YugabyteDB, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
+// in compliance with the License.  You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software distributed under the License
+// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+// or implied.  See the License for the specific language governing permissions and limitations
+// under the License.
+//
+
+#include "yb/client/table.h"
+#include "yb/client/yb_table_name.h"
+#include "yb/integration-tests/xcluster/xcluster_ysql_test_base.h"
+#include "yb/master/master_replication.proxy.h"
+#include "yb/master/mini_master.h"
+#include "yb/util/backoff_waiter.h"
+
+DECLARE_bool(TEST_enable_xcluster_api_v2);
+
+using namespace std::chrono_literals;
+
+namespace yb {
+
+const MonoDelta kTimeout = 60s * kTimeMultiplier;
+
+class XClusterDBScopedTest : public XClusterYsqlTestBase {
+ public:
+  struct SetupParams {
+    std::vector<uint32_t> num_consumer_tablets = {3};
+    std::vector<uint32_t> num_producer_tablets = {3};
+    uint32_t replication_factor = 3;
+    uint32_t num_masters = 1;
+    bool ranged_partitioned = false;
+  };
+
+  XClusterDBScopedTest() = default;
+  ~XClusterDBScopedTest() = default;
+
+  virtual void SetUp() override {
+    XClusterYsqlTestBase::SetUp();
+    ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_enable_xcluster_api_v2) = true;
+  }
+
+  Status SetUpClusters() {
+    static const SetupParams kDefaultParams;
+    return SetUpClusters(kDefaultParams);
+  }
+
+  Status SetUpClusters(const SetupParams& params) {
+    return XClusterYsqlTestBase::SetUpWithParams(
+        params.num_consumer_tablets, params.num_producer_tablets, params.replication_factor,
+        params.num_masters, params.ranged_partitioned);
+  }
+};
+
+TEST_F(XClusterDBScopedTest, TestCreateWithCheckpoint) {
+  ASSERT_OK(SetUpClusters());
+
+  ASSERT_OK(CheckpointReplicationGroup());
+  ASSERT_OK(CreateReplicationFromCheckpoint());
+
+  // Verify that universe was setup on consumer.
+  master::GetUniverseReplicationResponsePB resp;
+  ASSERT_OK(VerifyUniverseReplication(&resp));
+  ASSERT_EQ(resp.entry().replication_group_id(), kReplicationGroupId);
+  ASSERT_EQ(resp.entry().tables_size(), 1);
+  ASSERT_EQ(resp.entry().tables(0), producer_table_->id());
+
+  ASSERT_OK(InsertRowsInProducer(0, 50));
+
+  ASSERT_OK(VerifyWrittenRecords());
+}
+
+TEST_F(XClusterDBScopedTest, CreateTable) {
+  ASSERT_OK(SetUpClusters());
+  ASSERT_OK(CheckpointReplicationGroup());
+  ASSERT_OK(CreateReplicationFromCheckpoint());
+
+  // Creating a new table on target first should fail.
+  ASSERT_NOK(CreateYsqlTable(
+      /*idx=*/1, /*num_tablets=*/3, &consumer_cluster_));
+
+  auto new_producer_table_name = ASSERT_RESULT(CreateYsqlTable(
+      /*idx=*/1, /*num_tablets=*/3, &producer_cluster_));
+  std::shared_ptr<client::YBTable> new_producer_table;
+  ASSERT_OK(producer_client()->OpenTable(new_producer_table_name, &new_producer_table));
+
+  ASSERT_OK(InsertRowsInProducer(0, 50, new_producer_table));
+
+  auto new_consumer_table_name = ASSERT_RESULT(CreateYsqlTable(
+      /*idx=*/1, /*num_tablets=*/3, &consumer_cluster_));
+  std::shared_ptr<client::YBTable> new_consumer_table;
+  ASSERT_OK(consumer_client()->OpenTable(new_consumer_table_name, &new_consumer_table));
+
+  // Verify that universe was setup on consumer.
+  master::GetUniverseReplicationResponsePB resp;
+  ASSERT_OK(VerifyUniverseReplication(&resp));
+  ASSERT_EQ(resp.entry().replication_group_id(), kReplicationGroupId);
+  ASSERT_EQ(resp.entry().tables_size(), 2);
+
+  ASSERT_OK(VerifyWrittenRecords(new_producer_table, new_consumer_table));
+
+  // Insert some rows to the initial table.
+  ASSERT_OK(InsertRowsInProducer(0, 10, producer_table_));
+  ASSERT_OK(VerifyWrittenRecords());
+
+  // Make sure the other table remains unchanged.
+  ASSERT_OK(VerifyWrittenRecords(new_producer_table, new_consumer_table));
+}
+
+}  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_test_base.cc b/src/yb/integration-tests/xcluster/xcluster_test_base.cc
index 2c4dfda399..47d07c94b4 100644
--- a/src/yb/integration-tests/xcluster/xcluster_test_base.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_test_base.cc
@@ -30,6 +30,7 @@
 #include "yb/integration-tests/cdc_test_util.h"
 #include "yb/integration-tests/mini_cluster.h"
 #include "yb/master/catalog_manager_if.h"
+#include "yb/master/master.h"
 #include "yb/master/master_ddl.pb.h"
 #include "yb/master/master_ddl.proxy.h"
 #include "yb/master/master_defaults.h"
@@ -61,6 +62,16 @@ namespace yb {
 using client::YBClient;
 using client::YBTableName;
 
+namespace {
+
+Result<master::MasterReplicationProxy> GetMasterProxy(XClusterTestBase::Cluster& cluster) {
+  return master::MasterReplicationProxy(
+      &cluster.client_->proxy_cache(),
+      VERIFY_RESULT(cluster.mini_cluster_->GetLeaderMiniMaster())->bound_rpc_addr());
+}
+
+}  // namespace
+
 Status XClusterTestBase::PostSetUp() {
   if (!producer_tables_.empty()) {
     producer_table_ = producer_tables_.front();
@@ -890,6 +901,24 @@ Status XClusterTestBase::WaitForSafeTime(
   return Status::OK();
 }
 
+Status XClusterTestBase::WaitForSafeTimeToAdvanceToNow() {
+  auto producer_master = VERIFY_RESULT(producer_cluster()->GetLeaderMiniMaster())->master();
+  HybridTime now = producer_master->clock()->Now();
+  for (auto ts : producer_cluster()->mini_tablet_servers()) {
+    now.MakeAtLeast(ts->server()->clock()->Now());
+  }
+
+  master::GetNamespaceInfoResponsePB resp;
+  RETURN_NOT_OK(consumer_client()->GetNamespaceInfo(
+      std::string() /* namespace_id */, namespace_name, YQL_DATABASE_PGSQL, &resp));
+  if (resp.has_error()) {
+    return StatusFromPB(resp.error().status());
+  }
+  auto namespace_id = resp.namespace_().id();
+
+  return WaitForSafeTime(namespace_id, now);
+}
+
 Status XClusterTestBase::PauseResumeXClusterProducerStreams(
     const std::vector<xrepl::StreamId>& stream_ids, bool is_paused) {
   master::PauseResumeXClusterProducerStreamsRequestPB req;
@@ -1000,4 +1029,8 @@ Result<TableId> XClusterTestBase::GetColocatedDatabaseParentTableId() {
   // Colocated database
   return GetTablegroupParentTable(&producer_cluster_, namespace_name);
 }
+
+Result<master::MasterReplicationProxy> XClusterTestBase::GetProducerMasterProxy() {
+  return GetMasterProxy(producer_cluster_);
+}
 } // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_test_base.h b/src/yb/integration-tests/xcluster/xcluster_test_base.h
index 9b5ab510b6..e1866f4da1 100644
--- a/src/yb/integration-tests/xcluster/xcluster_test_base.h
+++ b/src/yb/integration-tests/xcluster/xcluster_test_base.h
@@ -107,6 +107,8 @@ class XClusterTestBase : public YBTest {
     HybridTime::TEST_SetPrettyToString(true);
 
     google::SetVLOGLevel("xcluster*", 4);
+    google::SetVLOGLevel("add_table*", 4);
+    google::SetVLOGLevel("xrepl*", 4);
     google::SetVLOGLevel("cdc*", 4);
     YBTest::SetUp();
 
@@ -180,7 +182,7 @@ class XClusterTestBase : public YBTest {
       const std::vector<xrepl::StreamId>& bootstrap_ids = {},
       SetupReplicationOptions opts = SetupReplicationOptions());
 
-  Status SetupUniverseReplication(
+  virtual Status SetupUniverseReplication(
       MiniCluster* producer_cluster, MiniCluster* consumer_cluster, YBClient* consumer_client,
       const xcluster::ReplicationGroupId& replication_group_id,
       const std::vector<TableId>& producer_table_ids,
@@ -208,7 +210,7 @@ class XClusterTestBase : public YBTest {
       MiniCluster* consumer_cluster, YBClient* consumer_client,
       const xcluster::ReplicationGroupId& replication_group_id, int num_expected_table);
 
-  Status ChangeXClusterRole(const cdc::XClusterRole role, Cluster* cluster = nullptr);
+  virtual Status ChangeXClusterRole(const cdc::XClusterRole role, Cluster* cluster = nullptr);
 
   Status ToggleUniverseReplication(
       MiniCluster* consumer_cluster, YBClient* consumer_client,
@@ -313,8 +315,12 @@ class XClusterTestBase : public YBTest {
     return result;
   }
 
+  // Wait for the xcluster safe time to advance to the given time on all TServers.
   Status WaitForSafeTime(const NamespaceId& namespace_id, const HybridTime& min_safe_time);
 
+  // Wait for the xcluster safe time to advance to Now on all TServers.
+  virtual Status WaitForSafeTimeToAdvanceToNow();
+
   Status VerifyReplicationError(
       const std::string& consumer_table_id, const xrepl::StreamId& stream_id,
       const std::optional<ReplicationErrorPb> expected_replication_error);
@@ -326,6 +332,8 @@ class XClusterTestBase : public YBTest {
 
   Result<TableId> GetColocatedDatabaseParentTableId();
 
+  Result<master::MasterReplicationProxy> GetProducerMasterProxy();
+
  protected:
   CoarseTimePoint PropagationDeadline() const {
     return CoarseMonoClock::Now() + propagation_timeout_;
diff --git a/src/yb/integration-tests/xcluster/xcluster_ysql_index-test.cc b/src/yb/integration-tests/xcluster/xcluster_ysql_index-test.cc
index cb89e174f0..05a5121137 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ysql_index-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ysql_index-test.cc
@@ -29,6 +29,7 @@ DECLARE_string(vmodule);
 DECLARE_bool(TEST_disable_apply_committed_transactions);
 DECLARE_bool(TEST_xcluster_fail_table_create_during_bootstrap);
 DECLARE_int32(TEST_user_ddl_operation_timeout_sec);
+DECLARE_bool(TEST_enable_xcluster_api_v2);
 
 using std::string;
 using namespace std::chrono_literals;
@@ -53,7 +54,6 @@ class XClusterYsqlIndexTest : public XClusterYsqlTestBase {
     google::SetVLOGLevel("xcluster*", 4);
     google::SetVLOGLevel("add_table*", 4);
     google::SetVLOGLevel("catalog*", 4);
-    google::SetVLOGLevel("table_creation_task*", 4);
 
     ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_user_ddl_operation_timeout_sec) = NonTsanVsTsan(60, 90);
 
@@ -126,23 +126,35 @@ class XClusterYsqlIndexTest : public XClusterYsqlTestBase {
     return conn.Execute(Format("CREATE INDEX $0 ON $1 (id2 ASC)", kIndexName, kTableName));
   }
 
-  virtual Status WaitForSafeTimeToAdvanceToNow() {
-    HybridTime now = producer_master_->clock()->Now();
-    for (auto ts : producer_cluster()->mini_tablet_servers()) {
-      now.MakeAtLeast(ts->server()->clock()->Now());
-    }
-    return WaitForSafeTime(namespace_id_, now);
-  }
-
   auto GetAllRows(pgwrapper::PGConn* conn) {
     return conn->FetchRows<int32_t, int32_t>(kSelectAllId12Stmt);
   }
 
   Status ValidateRows() {
+    // With should be less than or equal to row_count_ since some inserts may fail due to
+    // transactions aborted by the DDLs.
+    const auto all_prod_rows = VERIFY_RESULT(GetAllRows(producer_conn_.get()));
+    SCHECK_LE(all_prod_rows.size(), row_count_, IllegalState, "Producer row count mismatch.");
+    const auto actual_count = all_prod_rows.size();
+
+    const auto all_cons_rows = VERIFY_RESULT(GetAllRows(consumer_conn_.get()));
     SCHECK_EQ(
-        VERIFY_RESULT(GetAllRows(producer_conn_.get())),
-        VERIFY_RESULT(GetAllRows(consumer_conn_.get())), IllegalState,
-        "Producer and consumer have different rows.");
+        all_prod_rows, all_cons_rows, IllegalState, "Producer and consumer have different rows.");
+
+    const auto producer_count1 =
+        VERIFY_RESULT(producer_conn_->FetchRow<pgwrapper::PGUint64>(kId1CountStmt));
+    SCHECK_EQ(producer_count1, actual_count, IllegalState, "Id1 count mismatch in producer");
+    const auto producer_count2 =
+        VERIFY_RESULT(producer_conn_->FetchRow<pgwrapper::PGUint64>(kId2CountStmt));
+    SCHECK_EQ(producer_count2, actual_count, IllegalState, "Id2 count mismatch in producer");
+
+    const auto consumer_count1 =
+        VERIFY_RESULT(consumer_conn_->FetchRow<pgwrapper::PGUint64>(kId1CountStmt));
+    SCHECK_EQ(consumer_count1, actual_count, IllegalState, "Id1 count mismatch in consumer");
+    const auto consumer_count2 =
+        VERIFY_RESULT(consumer_conn_->FetchRow<pgwrapper::PGUint64>(kId2CountStmt));
+    SCHECK_EQ(consumer_count2, actual_count, IllegalState, "Id2 count mismatch in consumer");
+
     return Status::OK();
   }
 
@@ -216,6 +228,9 @@ class XClusterYsqlIndexTest : public XClusterYsqlTestBase {
       SleepFor(3s * kTimeMultiplier);
 
       RETURN_NOT_OK(CreateIndex(*consumer_conn_));
+
+      // Keep running for a while with the index.
+      SleepFor(3s * kTimeMultiplier);
     }
 
     SCHECK(
@@ -223,6 +238,7 @@ class XClusterYsqlIndexTest : public XClusterYsqlTestBase {
         "Index scan should be present on Consumer col id2.");
 
     RETURN_NOT_OK(WaitForSafeTimeToAdvanceToNow());
+
     RETURN_NOT_OK(ValidateRows());
 
     for (int i = 0; i < 20; row_count_++, i++) {
@@ -237,7 +253,7 @@ class XClusterYsqlIndexTest : public XClusterYsqlTestBase {
   client::YBTableName yb_table_name_;
   NamespaceId namespace_id_;
   std::unique_ptr<pgwrapper::PGConn> producer_conn_, consumer_conn_;
-  int row_count_ = 0;
+  uint row_count_ = 0;
 };
 
 TEST_F(XClusterYsqlIndexTest, CreateIndex) {
@@ -438,4 +454,47 @@ TEST_F(XClusterColocatedNonTransactionalIndexTest, CreateIndexWithWorkload) {
   ASSERT_EQ(resp.entry().table_streams_size(), 1);
 }
 
+class XClusterDbScopedYsqlIndexTest : public XClusterYsqlIndexTest {
+  Status SetupUniverseReplication(
+      MiniCluster* producer_cluster, MiniCluster* consumer_cluster, YBClient* consumer_client,
+      const xcluster::ReplicationGroupId& replication_group_id,
+      const std::vector<TableId>& producer_table_ids,
+      const std::vector<xrepl::StreamId>& bootstrap_ids, SetupReplicationOptions opts) override {
+    ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_enable_xcluster_api_v2) = true;
+    RETURN_NOT_OK(CheckpointReplicationGroup());
+    RETURN_NOT_OK(CreateReplicationFromCheckpoint());
+    return Status::OK();
+  }
+  Status ChangeXClusterRole(const cdc::XClusterRole role, Cluster* cluster) override {
+    // No-op for Db scoped repl groups.
+    return Status::OK();
+  }
+};
+
+TEST_F(XClusterDbScopedYsqlIndexTest, CreateIndex) {
+  ASSERT_OK(CreateIndex(*producer_conn_));
+  ASSERT_FALSE(ASSERT_RESULT(producer_conn_->HasIndexScan(kId1CountStmt)));
+  ASSERT_TRUE(ASSERT_RESULT(producer_conn_->HasIndexScan(kId2CountStmt)));
+
+  ASSERT_OK(ValidateRows());
+
+  ASSERT_OK(CreateIndex(*consumer_conn_));
+  ASSERT_FALSE(ASSERT_RESULT(consumer_conn_->HasIndexScan(kId1CountStmt)));
+  ASSERT_TRUE(ASSERT_RESULT(consumer_conn_->HasIndexScan(kId2CountStmt)));
+
+  ASSERT_OK(ValidateRows());
+
+  // Insert more rows and validate.
+  for (int i = 0; i < 10; i++, row_count_++) {
+    ASSERT_OK(producer_conn_->ExecuteFormat(kInsertStmtFormat, row_count_));
+  }
+
+  ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+  ASSERT_OK(ValidateRows());
+}
+
+TEST_F(XClusterDbScopedYsqlIndexTest, CreateIndexWithWorkload) {
+  ASSERT_OK(TestCreateIndexConcurrentWorkload());
+}
+
 }  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.cc b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.cc
index 26b2c63998..416d655fad 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.cc
@@ -19,6 +19,7 @@
 #include "yb/master/master_cluster.proxy.h"
 #include "yb/master/master_ddl.pb.h"
 #include "yb/master/master_ddl.proxy.h"
+#include "yb/master/master_replication.proxy.h"
 #include "yb/master/mini_master.h"
 #include "yb/master/sys_catalog_initialization.h"
 #include "yb/server/server_base.h"
@@ -248,7 +249,7 @@ Result<YBTableName> XClusterYsqlTestBase::CreateYsqlTable(
     colocation_id_string = Format("colocation_id = $0", colocation_id);
   }
   if (!schema_name.empty()) {
-    EXPECT_OK(conn.Execute(Format("CREATE SCHEMA IF NOT EXISTS $0;", schema_name)));
+    RETURN_NOT_OK(conn.Execute(Format("CREATE SCHEMA IF NOT EXISTS $0;", schema_name)));
   }
   std::string full_table_name =
       schema_name.empty() ? table_name : Format("$0.$1", schema_name, table_name);
@@ -283,7 +284,7 @@ Result<YBTableName> XClusterYsqlTestBase::CreateYsqlTable(
       }
     }
   }
-  EXPECT_OK(conn.Execute(query));
+  RETURN_NOT_OK(conn.Execute(query));
 
   // Only check the schema name if it is set AND we created the table with a valid pgschema_name.
   bool verify_schema_name =
@@ -800,4 +801,77 @@ Status XClusterYsqlTestBase::SetUpWithParams(
   return PostSetUp();
 }
 
+Status XClusterYsqlTestBase::CheckpointReplicationGroup() {
+  auto producer_namespace_id = VERIFY_RESULT(GetNamespaceId(producer_client()));
+  auto namespace_id_out = VERIFY_RESULT(producer_client()->XClusterCreateOutboundReplicationGroup(
+      kReplicationGroupId, {namespace_name}));
+  SCHECK_EQ(namespace_id_out.size(), 1, IllegalState, "Namespace count does not match");
+  SCHECK_EQ(namespace_id_out[0], producer_namespace_id, IllegalState, "NamespaceId does not match");
+
+  std::promise<Result<bool>> promise;
+  auto future = promise.get_future();
+  RETURN_NOT_OK(producer_client()->IsXClusterBootstrapRequired(
+      CoarseMonoClock::now() + MonoDelta::FromSeconds(kRpcTimeout), kReplicationGroupId,
+      producer_namespace_id, [&promise](Result<bool> res) { promise.set_value(res); }));
+  auto bootstrap_required = VERIFY_RESULT(future.get());
+  SCHECK(!bootstrap_required, IllegalState, "Bootstrap should not be required");
+
+  return Status::OK();
+}
+
+Result<bool> XClusterYsqlTestBase::IsCreateXClusterReplicationDone() {
+  master::IsCreateXClusterReplicationDoneRequestPB req;
+  master::IsCreateXClusterReplicationDoneResponsePB resp;
+  req.set_replication_group_id(kReplicationGroupId.ToString());
+  auto master_addr = consumer_cluster()->GetMasterAddresses();
+  auto hp_vec = VERIFY_RESULT(HostPort::ParseStrings(master_addr, 0));
+  HostPortsToPBs(hp_vec, req.mutable_target_master_addresses());
+
+  auto master_proxy = VERIFY_RESULT(GetProducerMasterProxy());
+
+  rpc::RpcController rpc;
+  rpc.set_timeout(MonoDelta::FromSeconds(kRpcTimeout));
+
+  RETURN_NOT_OK(master_proxy.IsCreateXClusterReplicationDone(req, &resp, &rpc));
+
+  if (resp.has_error()) {
+    return StatusFromPB(resp.error().status());
+  }
+
+  return resp.done();
+}
+
+Status XClusterYsqlTestBase::WaitForCreateReplicationToFinish() {
+  RETURN_NOT_OK(LoggedWaitFor(
+      [this]() { return IsCreateXClusterReplicationDone(); }, MonoDelta::FromSeconds(kRpcTimeout),
+      __func__));
+
+  // Wait for the xcluster safe time to propagate to the tserver nodes.
+  return WaitForSafeTimeToAdvanceToNow();
+}
+
+Status XClusterYsqlTestBase::CreateReplicationFromCheckpoint() {
+  RETURN_NOT_OK(SetupCertificates(kReplicationGroupId));
+
+  master::CreateXClusterReplicationRequestPB req;
+  master::CreateXClusterReplicationResponsePB resp;
+  req.set_replication_group_id(kReplicationGroupId.ToString());
+  auto master_addr = consumer_cluster()->GetMasterAddresses();
+  auto hp_vec = VERIFY_RESULT(HostPort::ParseStrings(master_addr, 0));
+  HostPortsToPBs(hp_vec, req.mutable_target_master_addresses());
+
+  auto master_proxy = VERIFY_RESULT(GetProducerMasterProxy());
+
+  rpc::RpcController rpc;
+  rpc.set_timeout(MonoDelta::FromSeconds(kRpcTimeout));
+
+  RETURN_NOT_OK(master_proxy.CreateXClusterReplication(req, &resp, &rpc));
+
+  if (resp.has_error()) {
+    return StatusFromPB(resp.error().status());
+  }
+
+  return WaitForCreateReplicationToFinish();
+}
+
 }  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
index c8442415b9..bce36afcc1 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
+++ b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
@@ -116,6 +116,11 @@ class XClusterYsqlTestBase : public XClusterTestBase {
       uint32_t start, uint32_t end, Cluster* cluster, const client::YBTableName& table,
       bool delete_op = false, bool use_transaction = false);
 
+  Status CheckpointReplicationGroup();
+  Status CreateReplicationFromCheckpoint();
+  Result<bool> IsCreateXClusterReplicationDone();
+  Status WaitForCreateReplicationToFinish();
+
  protected:
   void TestReplicationWithSchemaChanges(TableId producer_table_id, bool bootstrap);
 
diff --git a/src/yb/master/catalog_manager.h b/src/yb/master/catalog_manager.h
index 65ab9d56f1..fb1e60114f 100644
--- a/src/yb/master/catalog_manager.h
+++ b/src/yb/master/catalog_manager.h
@@ -1399,6 +1399,8 @@ class CatalogManager : public tserver::TabletPeerLookupIf,
   scoped_refptr<UniverseReplicationInfo> GetUniverseReplication(
       const xcluster::ReplicationGroupId& replication_group_id);
 
+  std::vector<scoped_refptr<UniverseReplicationInfo>> GetAllUniverseReplications() const;
+
   // Checks if the universe is in an active state or has failed during setup.
   Status IsSetupUniverseReplicationDone(
       const IsSetupUniverseReplicationDoneRequestPB* req,
@@ -1568,6 +1570,9 @@ class CatalogManager : public tserver::TabletPeerLookupIf,
 
   auto GetTasksTracker() { return tasks_tracker_; }
 
+  void MarkUniverseForCleanup(const xcluster::ReplicationGroupId& replication_group_id)
+      EXCLUDES(mutex_);
+
  protected:
   // TODO Get rid of these friend classes and introduce formal interface.
   friend class TableLoader;
@@ -3055,12 +3060,6 @@ class CatalogManager : public tserver::TabletPeerLookupIf,
 
   void SchedulePostTabletCreationTasksForPendingTables(const LeaderEpoch& epoch) EXCLUDES(mutex_);
 
-  Result<xcluster::ReplicationGroupId> GetIndexesTableReplicationGroup(const TableInfo& index_info);
-
-  Status BootstrapTable(
-      const xcluster::ReplicationGroupId& replication_group_id, const TableInfo& index_info,
-      client::BootstrapProducerCallback callback);
-
   // Checks if the table is a consumer in an xCluster replication universe.
   bool IsTableXClusterConsumer(const TableInfo& table_info) const EXCLUDES(mutex_);
 
diff --git a/src/yb/master/xcluster/add_table_to_xcluster_target_task.cc b/src/yb/master/xcluster/add_table_to_xcluster_target_task.cc
index ea6a38f368..72c15eae1c 100644
--- a/src/yb/master/xcluster/add_table_to_xcluster_target_task.cc
+++ b/src/yb/master/xcluster/add_table_to_xcluster_target_task.cc
@@ -13,8 +13,11 @@
 
 #include "yb/master/xcluster/add_table_to_xcluster_target_task.h"
 
+#include "yb/client/xcluster_client.h"
 #include "yb/master/catalog_manager.h"
 #include "yb/master/xcluster/xcluster_manager_if.h"
+#include "yb/master/xcluster/xcluster_replication_group.h"
+#include "yb/master/xcluster_rpc_tasks.h"
 #include "yb/rpc/messenger.h"
 #include "yb/util/logging.h"
 #include "yb/util/sync_point.h"
@@ -39,21 +42,28 @@ const MonoDelta kScheduleDelay = MonoDelta::FromMilliseconds(200);
 }
 
 AddTableToXClusterTargetTask::AddTableToXClusterTargetTask(
-    CatalogManager& catalog_manager, rpc::Messenger& messenger, TableInfoPtr table_info,
-    const LeaderEpoch& epoch)
+    scoped_refptr<UniverseReplicationInfo> universe, CatalogManager& catalog_manager,
+    rpc::Messenger& messenger, TableInfoPtr table_info, const LeaderEpoch& epoch)
     : PostTabletCreateTaskBase(
           catalog_manager, *catalog_manager.AsyncTaskPool(), messenger, std::move(table_info),
-          std::move(epoch)) {}
+          std::move(epoch)),
+      universe_(universe) {
+  is_db_scoped_ = universe_->LockForRead()->pb.has_db_scoped_info();
+}
 
 std::string AddTableToXClusterTargetTask::description() const {
   return Format("AddTableToXClusterTargetTask [$0]", table_info_->id());
 }
 
 Status AddTableToXClusterTargetTask::FirstStep() {
-  auto stream_ids = catalog_manager_.GetXClusterConsumerStreamIdsForTable(table_info_->id());
-  if (!stream_ids.empty()) {
-    LOG_WITH_PREFIX(INFO) << "Table is already part of xcluster replication "
-                          << yb::ToString(stream_ids);
+  auto universe_l = universe_->LockForRead();
+  auto& universe_pb = universe_l->pb;
+
+  auto table_l = table_info_->LockForRead();
+
+  if (!ShouldAddTableToReplicationGroup(*universe_, *table_info_, catalog_manager_)) {
+    LOG_WITH_PREFIX(INFO) << "Table " << table_info_->ToString()
+                          << " does not need to be added to xCluster universe replication";
     Complete();
     return Status::OK();
   }
@@ -71,13 +81,25 @@ Status AddTableToXClusterTargetTask::FirstStep() {
     return Status::OK();
   }
 
-  replication_group_id_ =
-      VERIFY_RESULT(catalog_manager_.GetIndexesTableReplicationGroup(*table_info_));
-  DCHECK(!replication_group_id_.empty());
+  auto callback =
+      std::bind(&AddTableToXClusterTargetTask::BootstrapTableCallback, shared_from(this), _1);
+
+  if (!is_db_scoped_) {
+    auto xcluster_rpc = VERIFY_RESULT(
+        universe_->GetOrCreateXClusterRpcTasks(universe_pb.producer_master_addresses()));
+    return xcluster_rpc->client()->BootstrapProducer(
+        YQLDatabase::YQL_DATABASE_PGSQL, table_info_->namespace_name(),
+        {table_info_->pgschema_name()}, {table_info_->name()}, std::move(callback));
+  }
+
+  const auto producer_namespace_id =
+      VERIFY_RESULT(GetProducerNamespaceId(*universe_, table_info_->namespace_id()));
 
-  return catalog_manager_.BootstrapTable(
-      replication_group_id_, *table_info_,
-      std::bind(&AddTableToXClusterTargetTask::BootstrapTableCallback, shared_from(this), _1));
+  // We need to keep the client alive until the callback is invoked.
+  remote_client_ = VERIFY_RESULT(GetXClusterRemoteClient(*universe_));
+  return remote_client_->GetXClusterTableCheckpointInfos(
+      universe_->ReplicationGroupId(), producer_namespace_id, {table_info_->name()},
+      {table_info_->pgschema_name()}, std::move(callback));
 }
 
 Status AddTableToXClusterTargetTask::BootstrapTableCallback(
@@ -86,7 +108,34 @@ Status AddTableToXClusterTargetTask::BootstrapTableCallback(
       VERIFY_RESULT(std::move(bootstrap_result));
   CHECK_EQ(producer_table_ids.size(), 1);
   CHECK_EQ(bootstrap_ids.size(), 1);
-  SCHECK(!bootstrap_time.is_special(), IllegalState, "Failed to get a valid bootstrap time");
+  if (is_db_scoped_) {
+    // With Db scoped replication we do not require the bootstrap time.
+    // xCluster streams do not replicate data produced by index backfill. So, both source and
+    // target universe have to run their own backfill jobs.
+    //
+    // In non Db scoped replication we checkpoint the source index at an arbitrary time when the
+    // create index DDL is executed on the target by the user. Only data after this time will be
+    // replicated by xcluster stream and the target side backfill job will populate the data written
+    // before it. We need to for xCluster safe time (which includes the base table) to advance to
+    // the bootstrap time to ensure the base table has all the data before we start the backfill
+    // job.
+    //
+    // In Db scoped replication we checkpoint the index when it is created on the source at OpId 0.
+    // We still need to run the backfill job on the target since we still do not get the data
+    // produced by the source backfill job. The DDL handler which issues the create index DDL waits
+    // for the xCluster safe time to advance upto the DDL commit time before executing it. This time
+    // is guaranteed to be higher than the backfill time of the source universe since index creation
+    // waits for the backfill job to finish.
+    //
+    // We set to coarse time now (and dont worry about clock skews) to have some valid time to
+    // compare against.
+    bootstrap_time = HybridTime::FromMicros(GetCurrentTimeMicros());
+  } else {
+    SCHECK(
+        !bootstrap_time.is_special(), IllegalState, "xCluster Bootstrap time is not valid $0",
+        bootstrap_time.ToString());
+  }
+
   bootstrap_time_ = bootstrap_time;
 
   SCHEDULE(AddTableToReplicationGroup, producer_table_ids[0], bootstrap_ids[0]);
@@ -95,64 +144,44 @@ Status AddTableToXClusterTargetTask::BootstrapTableCallback(
 
 Status AddTableToXClusterTargetTask::AddTableToReplicationGroup(
     TableId producer_table_id, std::string bootstrap_id) {
+  const auto& replication_group_id = universe_->ReplicationGroupId();
   LOG_WITH_PREFIX_AND_FUNC(INFO) << "Adding table to xcluster universe replication "
-                                 << replication_group_id_ << " with bootstrap_id:" << bootstrap_id
+                                 << replication_group_id << " with bootstrap_id:" << bootstrap_id
                                  << ", bootstrap_time:" << bootstrap_time_
                                  << " and producer_table_id:" << producer_table_id;
-  AlterUniverseReplicationRequestPB alter_universe_req;
-  AlterUniverseReplicationResponsePB alter_universe_resp;
-  alter_universe_req.set_replication_group_id(replication_group_id_.ToString());
-  alter_universe_req.add_producer_table_ids_to_add(producer_table_id);
-  alter_universe_req.add_producer_bootstrap_ids_to_add(bootstrap_id);
-  RETURN_NOT_OK(catalog_manager_.AlterUniverseReplication(
-      &alter_universe_req, &alter_universe_resp, nullptr /* rpc */));
-
-  if (alter_universe_resp.has_error()) {
-    return StatusFromPB(alter_universe_resp.error().status());
+  AlterUniverseReplicationRequestPB req;
+  AlterUniverseReplicationResponsePB resp;
+  req.set_replication_group_id(replication_group_id.ToString());
+  req.add_producer_table_ids_to_add(producer_table_id);
+  req.add_producer_bootstrap_ids_to_add(bootstrap_id);
+  RETURN_NOT_OK(catalog_manager_.AlterUniverseReplication(&req, &resp, nullptr /* rpc */));
+
+  if (resp.has_error()) {
+    return StatusFromPB(resp.error().status());
   }
 
-  VLOG_WITH_PREFIX(1) << "Waiting for xcluster safe time of namespace "
-                      << table_info_->namespace_id() << " to get past bootstrap_time "
-                      << bootstrap_time_;
-
   SCHEDULE_WITH_DELAY(WaitForSetupUniverseReplicationToFinish);
   return Status::OK();
 }
 
 Status AddTableToXClusterTargetTask::WaitForSetupUniverseReplicationToFinish() {
-  IsSetupUniverseReplicationDoneRequestPB check_req;
-  IsSetupUniverseReplicationDoneResponsePB check_resp;
-  check_req.set_replication_group_id(replication_group_id_.ToString());
-  auto status = catalog_manager_.IsSetupUniverseReplicationDone(
-      &check_req, &check_resp, /* RpcContext */ nullptr);
-  if (status.ok() && check_resp.has_error()) {
-    status = StatusFromPB(check_resp.error().status());
-  }
+  auto operation_result = VERIFY_RESULT(
+      IsSetupUniverseReplicationDone(universe_->ReplicationGroupId(), catalog_manager_));
 
-  if (!status.ok()) {
-    YB_LOG_EVERY_N_SECS(WARNING, 10)
-        << LogPrefix() << "Failed to check if setup universe replication is done: " << status;
-    SCHEDULE_WITH_DELAY(WaitForSetupUniverseReplicationToFinish);
-    return Status::OK();
-  }
-
-  if (!check_resp.done()) {
+  if (!operation_result.done) {
     VLOG_WITH_PREFIX(2) << "Waiting for setup universe replication to finish";
     // If this takes too long the table creation will timeout and abort the task.
     SCHEDULE_WITH_DELAY(WaitForSetupUniverseReplicationToFinish);
     return Status::OK();
   }
 
-  if (check_resp.has_replication_error()) {
-    RETURN_NOT_OK(StatusFromPB(check_resp.replication_error()));
-  }
+  RETURN_NOT_OK(operation_result.status);
 
   SCHEDULE(RefreshAndGetXClusterSafeTime);
   return Status::OK();
 }
 
 Status AddTableToXClusterTargetTask::RefreshAndGetXClusterSafeTime() {
-  CHECK(bootstrap_time_.is_valid());
   // Force a refresh of the xCluster safe time map so that it accounts for all tables under
   // replication.
   auto namespace_id = table_info_->namespace_id();
@@ -168,6 +197,9 @@ Status AddTableToXClusterTargetTask::RefreshAndGetXClusterSafeTime() {
 
   initial_xcluster_safe_time_ = initial_safe_time[namespace_id];
   initial_xcluster_safe_time_.MakeAtLeast(bootstrap_time_);
+  SCHECK(
+      !initial_xcluster_safe_time_.is_special(), IllegalState, "Invalid initial safe time $0",
+      initial_xcluster_safe_time_);
 
   // Wait for the xCluster safe time to advance beyond the initial value. This ensures all tables
   // under replication are part of the safe time computation.
@@ -176,19 +208,16 @@ Status AddTableToXClusterTargetTask::RefreshAndGetXClusterSafeTime() {
 }
 
 Status AddTableToXClusterTargetTask::WaitForXClusterSafeTimeCaughtUp() {
-  if (initial_xcluster_safe_time_.is_valid()) {
-    // TODO: Handle the case when replication was dropped.
-    auto ht = VERIFY_RESULT(
-        catalog_manager_.GetXClusterManager()->GetXClusterSafeTime(table_info_->namespace_id()));
-
-    auto caught_up = ht > initial_xcluster_safe_time_;
-    if (!caught_up) {
-      YB_LOG_EVERY_N_SECS(WARNING, 10) << LogPrefix() << "Waiting for xCluster safe time " << ht
-                                       << " to advance beyond " << initial_xcluster_safe_time_;
-      // If this takes too long the table creation will timeout and abort the task.
-      SCHEDULE_WITH_DELAY(WaitForXClusterSafeTimeCaughtUp);
-      return Status::OK();
-    }
+  // TODO: Handle the case when replication was dropped.
+  auto ht = VERIFY_RESULT(
+      catalog_manager_.GetXClusterManager()->GetXClusterSafeTime(table_info_->namespace_id()));
+
+  if (ht <= initial_xcluster_safe_time_) {
+    YB_LOG_EVERY_N_SECS(WARNING, 10) << LogPrefix() << "Waiting for xCluster safe time " << ht
+                                     << " to advance beyond " << initial_xcluster_safe_time_;
+    // If this takes too long the table creation will timeout and abort the task.
+    SCHEDULE_WITH_DELAY(WaitForXClusterSafeTimeCaughtUp);
+    return Status::OK();
   }
 
   LOG(INFO) << "Table " << table_info_->ToString()
diff --git a/src/yb/master/xcluster/add_table_to_xcluster_target_task.h b/src/yb/master/xcluster/add_table_to_xcluster_target_task.h
index 0c7c52b5d8..f7f42770fc 100644
--- a/src/yb/master/xcluster/add_table_to_xcluster_target_task.h
+++ b/src/yb/master/xcluster/add_table_to_xcluster_target_task.h
@@ -21,7 +21,15 @@
 #include "yb/master/leader_epoch.h"
 #include "yb/master/post_tablet_create_task_base.h"
 
-namespace yb::master {
+namespace yb {
+
+namespace client {
+class XClusterRemoteClient;
+}  // namespace client
+
+namespace master {
+
+class UniverseReplicationInfo;
 
 // This task adds a newly created table in the consumer xCluster universe to transactional
 // replication group. The table must be in PREPARING state with all tablets created at the start of
@@ -31,8 +39,8 @@ namespace yb::master {
 class AddTableToXClusterTargetTask : public PostTabletCreateTaskBase {
  public:
   AddTableToXClusterTargetTask(
-      CatalogManager& catalog_manager, rpc::Messenger& messenger, TableInfoPtr table_info,
-      const LeaderEpoch& epoch);
+      scoped_refptr<UniverseReplicationInfo> universe, CatalogManager& catalog_manager,
+      rpc::Messenger& messenger, TableInfoPtr table_info, const LeaderEpoch& epoch);
 
   server::MonitoredTaskType type() const override {
     return server::MonitoredTaskType::kAddTableToXClusterTarget;
@@ -52,7 +60,10 @@ class AddTableToXClusterTargetTask : public PostTabletCreateTaskBase {
 
   HybridTime bootstrap_time_ = HybridTime::kInvalid;
   HybridTime initial_xcluster_safe_time_ = HybridTime::kInvalid;
-  xcluster::ReplicationGroupId replication_group_id_;
+  scoped_refptr<UniverseReplicationInfo> universe_;
+  std::shared_ptr<client::XClusterRemoteClient> remote_client_;
+  bool is_db_scoped_ = false;
 };
 
-}  // namespace yb::master
+}  // namespace master
+}  // namespace yb
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
index 5fd8282840..1c28ab2b0a 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
@@ -36,18 +36,18 @@ class XClusterRemoteClientMocked : public client::XClusterRemoteClient {
     return Status::OK();
   }
 
-  Result<UniverseUuid> SetupUniverseReplication(
+  Result<UniverseUuid> SetupDbScopedUniverseReplication(
       const xcluster::ReplicationGroupId& replication_group_id,
       const std::vector<HostPort>& source_master_addresses,
       const std::vector<NamespaceName>& namespace_names,
-      const std::vector<TableId>& source_table_ids,
-      const std::vector<xrepl::StreamId>& bootstrap_ids, Transactional transactional) override {
+      const std::vector<NamespaceId>& namespace_ids, const std::vector<TableId>& source_table_ids,
+      const std::vector<xrepl::StreamId>& bootstrap_ids) override {
     replication_group_id_ = replication_group_id;
     source_master_addresses_ = source_master_addresses;
     namespace_names_ = namespace_names;
+    namespace_ids_ = namespace_ids;
     source_table_ids_ = source_table_ids;
     bootstrap_ids_ = bootstrap_ids;
-    transactional_ = transactional;
 
     return kTargetUniverseUuid;
   }
@@ -60,9 +60,9 @@ class XClusterRemoteClientMocked : public client::XClusterRemoteClient {
   xcluster::ReplicationGroupId replication_group_id_;
   std::vector<HostPort> source_master_addresses_;
   std::vector<NamespaceName> namespace_names_;
+  std::vector<NamespaceId> namespace_ids_;
   std::vector<TableId> source_table_ids_;
   std::vector<xrepl::StreamId> bootstrap_ids_;
-  bool transactional_;
 
   Result<IsOperationDoneResult> is_setup_universe_replication_done_ =
       IsOperationDoneResult(true, Status::OK());
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
index 18ad70f8ee..ec48fdc03b 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
@@ -336,6 +336,7 @@ Status XClusterOutboundReplicationGroup::CreateXClusterReplication(
   }
 
   std::vector<NamespaceName> namespace_names;
+  std::vector<NamespaceId> namespace_ids;
   std::vector<TableId> source_table_ids;
   std::vector<xrepl::StreamId> bootstrap_ids;
   for (const auto& [ns_id, ns_info] : outbound_group.namespace_infos()) {
@@ -343,6 +344,7 @@ Status XClusterOutboundReplicationGroup::CreateXClusterReplication(
         ns_info.state(), SysXClusterOutboundReplicationGroupEntryPB::NamespaceInfoPB::READY,
         TryAgain, Format("Namespace $0 is not yet ready to start replicating", ns_id));
 
+    namespace_ids.push_back(ns_id);
     namespace_names.push_back(VERIFY_RESULT(helper_functions_.get_namespace_name_func(ns_id)));
 
     auto all_tables = VERIFY_RESULT(helper_functions_.get_tables_func(ns_id));
@@ -364,9 +366,9 @@ Status XClusterOutboundReplicationGroup::CreateXClusterReplication(
 
   auto remote_client = VERIFY_RESULT(GetRemoteClient(target_master_addresses));
 
-  auto target_uuid = VERIFY_RESULT(remote_client->SetupUniverseReplication(
-      Id(), source_master_addresses, namespace_names, source_table_ids, bootstrap_ids,
-      client::XClusterRemoteClient::Transactional::kTrue));
+  auto target_uuid = VERIFY_RESULT(remote_client->SetupDbScopedUniverseReplication(
+      Id(), source_master_addresses, namespace_names, namespace_ids, source_table_ids,
+      bootstrap_ids));
 
   auto* target_universe_info = l.mutable_data()->pb.mutable_target_universe_info();
 
diff --git a/src/yb/master/xcluster/xcluster_replication_group.cc b/src/yb/master/xcluster/xcluster_replication_group.cc
index 2527d39ccb..a0b0c4e3fb 100644
--- a/src/yb/master/xcluster/xcluster_replication_group.cc
+++ b/src/yb/master/xcluster/xcluster_replication_group.cc
@@ -14,13 +14,21 @@
 #include "yb/master/xcluster/xcluster_replication_group.h"
 
 #include "yb/client/client.h"
+#include "yb/client/xcluster_client.h"
 #include "yb/common/wire_protocol.pb.h"
 #include "yb/master/catalog_entity_info.h"
+#include "yb/master/catalog_manager.h"
+#include "yb/master/catalog_manager_util.h"
 #include "yb/master/xcluster_rpc_tasks.h"
+#include "yb/master/xcluster/xcluster_manager_if.h"
+#include "yb/cdc/xcluster_util.h"
 #include "yb/master/sys_catalog.h"
 #include "yb/util/flags/auto_flags_util.h"
 #include "yb/util/result.h"
 
+DECLARE_int32(cdc_read_rpc_timeout_ms);
+DECLARE_string(certs_for_cdc_dir);
+
 namespace yb::master {
 
 namespace {
@@ -235,4 +243,197 @@ Status HandleLocalAutoFlagsConfigChange(
 
   return Status::OK();
 }
+
+std::optional<NamespaceId> GetProducerNamespaceIdInternal(
+    const SysUniverseReplicationEntryPB& universe_pb, const NamespaceId& consumer_namespace_id) {
+  const auto& namespace_infos = universe_pb.db_scoped_info().namespace_infos();
+  auto it = std::find_if(
+      namespace_infos.begin(), namespace_infos.end(),
+      [&consumer_namespace_id](const auto& namespace_info) {
+        return namespace_info.consumer_namespace_id() == consumer_namespace_id;
+      });
+
+  if (it == namespace_infos.end()) {
+    return std::nullopt;
+  }
+
+  return it->producer_namespace_id();
+}
+
+bool ShouldAddTableToReplicationGroup(
+    UniverseReplicationInfo& universe, const TableInfo& table_info,
+    CatalogManager& catalog_manager) {
+  const auto& table_pb = table_info.old_pb();
+
+  // Only user created YSQL tables should be automatically added to xCluster replication.
+  if (table_pb.colocated() || table_pb.table_type() != PGSQL_TABLE_TYPE ||
+      !catalog_manager.IsUserCreatedTable(table_info)) {
+    return false;
+  }
+
+  auto l = universe.LockForRead();
+  const auto& universe_pb = l->pb;
+  if (l->is_deleted_or_failed()) {
+    VLOG(1) << "Skip adding table " << table_info.ToString()
+            << " to xCluster replication as the universe " << universe.ReplicationGroupId()
+            << " is in a deleted or failed state";
+    return false;
+  }
+
+  // Handle v1 API, transactional xcluster replication for indexes. If the indexed table is under
+  // replication then we need to add the index to replication as well.
+  if (!universe_pb.has_db_scoped_info() && !(universe_pb.transactional() && IsIndex(table_pb))) {
+    return false;
+  }
+
+  if (universe_pb.has_db_scoped_info()) {
+    if (!IncludesConsumerNamespace(universe, table_info.namespace_id())) {
+      return false;
+    }
+  } else {
+    const auto& indexed_table_id = GetIndexedTableId(table_pb);
+    auto indexed_table_stream_ids =
+        catalog_manager.GetXClusterConsumerStreamIdsForTable(indexed_table_id);
+    if (indexed_table_stream_ids.empty()) {
+      return false;
+    }
+  }
+
+  // Check if the table has already been added to this replication group.
+  auto cluster_config = catalog_manager.ClusterConfig();
+  {
+    auto l = cluster_config->LockForRead();
+    const auto& consumer_registry = l->pb.consumer_registry();
+    // Only add if we are in a transactional replication with STANDBY mode.
+    if (consumer_registry.role() != cdc::XClusterRole::STANDBY ||
+        !consumer_registry.transactional()) {
+      return false;
+    }
+
+    auto producer_entry =
+        FindOrNull(consumer_registry.producer_map(), universe.ReplicationGroupId().ToString());
+    if (producer_entry) {
+      for (auto& [stream_id, stream_info] : producer_entry->stream_map()) {
+        if (stream_info.consumer_table_id() == table_info.id()) {
+          VLOG(1) << "Table " << table_info.ToString()
+                  << " is already part of xcluster replication " << stream_id;
+
+          return false;
+        }
+      }
+    }
+  }
+
+  return true;
+}
+
+Result<NamespaceId> GetProducerNamespaceId(
+    UniverseReplicationInfo& universe, const NamespaceId& consumer_namespace_id) {
+  auto l = universe.LockForRead();
+  SCHECK(
+      l->pb.has_db_scoped_info(), IllegalState, "Replication group $0 is not db-scoped",
+      universe.ToString());
+
+  auto opt_namespace_id = GetProducerNamespaceIdInternal(l->pb, consumer_namespace_id);
+  SCHECK_FORMAT(
+      opt_namespace_id, NotFound, "Namespace $0 not found in replication group $1",
+      consumer_namespace_id, universe.ToString());
+
+  return *opt_namespace_id;
+}
+
+bool IncludesConsumerNamespace(
+    UniverseReplicationInfo& universe, const NamespaceId& consumer_namespace_id) {
+  auto l = universe.LockForRead();
+  if (!l->pb.has_db_scoped_info()) {
+    return false;
+  }
+
+  auto opt_namespace_id = GetProducerNamespaceIdInternal(l->pb, consumer_namespace_id);
+  return opt_namespace_id.has_value();
+}
+
+Result<std::shared_ptr<client::XClusterRemoteClient>> GetXClusterRemoteClient(
+    UniverseReplicationInfo& universe) {
+  auto master_addresses = universe.LockForRead()->pb.producer_master_addresses();
+  std::vector<HostPort> hp;
+  HostPortsFromPBs(master_addresses, &hp);
+  auto xcluster_client = std::make_shared<client::XClusterRemoteClient>(
+      FLAGS_certs_for_cdc_dir, MonoDelta::FromMilliseconds(FLAGS_cdc_read_rpc_timeout_ms));
+  RETURN_NOT_OK(xcluster_client->Init(universe.ReplicationGroupId(), hp));
+
+  return xcluster_client;
+}
+
+Result<bool> IsSafeTimeReady(
+    const SysUniverseReplicationEntryPB& universe_pb, const XClusterManagerIf& xcluster_manager) {
+  if (!universe_pb.has_db_scoped_info()) {
+    // Only valid in Db scoped replication.
+    return true;
+  }
+
+  const auto safe_time_map = VERIFY_RESULT(xcluster_manager.GetXClusterNamespaceToSafeTimeMap());
+  for (const auto& namespace_info : universe_pb.db_scoped_info().namespace_infos()) {
+    const auto& namespace_id = namespace_info.consumer_namespace_id();
+    auto* it = FindOrNull(safe_time_map, namespace_id);
+    if (!it || it->is_special()) {
+      VLOG_WITH_FUNC(1) << "Safe time for namespace " << namespace_id
+                        << " is not yet ready: " << (it ? it->ToString() : "NA");
+      return false;
+    }
+  }
+
+  return true;
+}
+
+Result<IsOperationDoneResult> IsSetupUniverseReplicationDone(
+    const xcluster::ReplicationGroupId& replication_group_id, CatalogManager& catalog_manager) {
+  // Cases for completion:
+  //  - For AlterUniverseReplication, we need to wait until the .ALTER universe gets merged with
+  //    the main universe - at which point the .ALTER universe is deleted.
+  //  - For regular SetupUniverseReplication, we want to wait for the universe to become ACTIVE.
+  //      - If this is a brand new Db scoped replication group then we also have to wait for the
+  //        xcluster safe time to be ready.
+
+  const auto is_alter_request = xcluster::IsAlterReplicationGroupId(replication_group_id);
+  auto universe = catalog_manager.GetUniverseReplication(replication_group_id);
+
+  auto state = SysUniverseReplicationEntryPB::DELETED;
+  if (universe) {
+    state = universe->LockForRead()->pb.state();
+  }
+  if (state == SysUniverseReplicationEntryPB::DELETED) {
+    Status status;
+    if (!is_alter_request) {
+      status = STATUS(NotFound, "Could not find xCluster replication group");
+    }
+    return IsOperationDoneResult(true, status);
+  }
+
+  CHECK(universe);
+
+  if (state == SysUniverseReplicationEntryPB::DELETED_ERROR ||
+      state == SysUniverseReplicationEntryPB::FAILED) {
+    auto setup_error = universe->GetSetupUniverseReplicationErrorStatus();
+    if (setup_error.ok()) {
+      LOG(WARNING) << "Did not find setup error status for universe " << replication_group_id
+                   << " in state " << SysUniverseReplicationEntryPB::State_Name(state);
+      setup_error = STATUS(InternalError, "unknown error");
+    }
+
+    // Add failed universe to GC now that we've responded to the user.
+    catalog_manager.MarkUniverseForCleanup(replication_group_id);
+
+    return IsOperationDoneResult(true, setup_error);
+  }
+
+  bool is_done = false;
+  if (!is_alter_request && state == SysUniverseReplicationEntryPB::ACTIVE) {
+    auto l = universe->LockForRead();
+    is_done = VERIFY_RESULT(IsSafeTimeReady(l->pb, *catalog_manager.GetXClusterManager()));
+  }
+
+  return IsOperationDoneResult(is_done, Status::OK());
+}
+
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_replication_group.h b/src/yb/master/xcluster/xcluster_replication_group.h
index c0f5bb5066..5ad8695fcb 100644
--- a/src/yb/master/xcluster/xcluster_replication_group.h
+++ b/src/yb/master/xcluster/xcluster_replication_group.h
@@ -20,8 +20,14 @@
 namespace yb {
 class SysCatalogTable;
 
+namespace client {
+class XClusterRemoteClient;
+}  // namespace client
+
 namespace master {
 
+struct IsOperationDoneResult;
+
 // TODO: #19714 Create XClusterReplicationGroup, a wrapper over UniverseReplicationInfo, that will
 // manage the ReplicationGroup and its ProducerEntryPB in ClusterConfigInfo.
 
@@ -54,5 +60,26 @@ Status HandleLocalAutoFlagsConfigChange(
     ClusterConfigInfo& cluster_config, const AutoFlagsConfigPB& local_auto_flags_config,
     const LeaderEpoch& epoch);
 
+// Check if the table should be added to the replication group. Returns false if the table is
+// already part of the group.
+bool ShouldAddTableToReplicationGroup(
+    UniverseReplicationInfo& universe, const TableInfo& table_info,
+    CatalogManager& catalog_manager);
+
+Result<NamespaceId> GetProducerNamespaceId(
+    UniverseReplicationInfo& universe, const NamespaceId& consumer_namespace_id);
+
+bool IncludesConsumerNamespace(
+    UniverseReplicationInfo& universe, const NamespaceId& consumer_namespace_id);
+
+Result<std::shared_ptr<client::XClusterRemoteClient>> GetXClusterRemoteClient(
+    UniverseReplicationInfo& universe);
+
+// Returns (false, Status::OK()) if the universe setup is still in progress.
+// Returns (true, status) if the setup completed. status is set to OK if it completed successfully,
+// or the error that caused it to fail.
+Result<IsOperationDoneResult> IsSetupUniverseReplicationDone(
+    const xcluster::ReplicationGroupId& replication_group_id, CatalogManager& catalog_manager);
+
 }  // namespace master
 }  // namespace yb
diff --git a/src/yb/master/xcluster/xcluster_source_manager.cc b/src/yb/master/xcluster/xcluster_source_manager.cc
index 7cf509d07b..7829d61dbc 100644
--- a/src/yb/master/xcluster/xcluster_source_manager.cc
+++ b/src/yb/master/xcluster/xcluster_source_manager.cc
@@ -13,6 +13,8 @@
 
 #include "yb/master/xcluster/xcluster_source_manager.h"
 
+#include "yb/cdc/cdc_service.h"
+
 #include "yb/cdc/cdc_service.proxy.h"
 #include "yb/master/catalog_manager.h"
 #include "yb/master/master.h"
@@ -211,6 +213,14 @@ Result<std::vector<xrepl::StreamId>> XClusterSourceManager::BootstrapTables(
       master::CreateCDCStreamResponsePB create_stream_resp;
       create_stream_req.set_table_id(table_info->id());
 
+      std::unordered_map<std::string, std::string> options;
+      auto record_type_option = create_stream_req.add_options();
+      record_type_option->set_key(cdc::kRecordType);
+      record_type_option->set_value(CDCRecordType_Name(cdc::CDCRecordType::CHANGE));
+      auto record_format_option = create_stream_req.add_options();
+      record_format_option->set_key(cdc::kRecordFormat);
+      record_format_option->set_value(CDCRecordFormat_Name(cdc::CDCRecordFormat::WAL));
+
       RETURN_NOT_OK(catalog_manager_.CreateNewXReplStream(
           create_stream_req, CreateNewCDCStreamMode::kXClusterTableIds, {table_id},
           /*namespace_id=*/std::nullopt, &create_stream_resp, epoch, /*rpc=*/nullptr));
diff --git a/src/yb/master/xcluster/xcluster_target_manager.cc b/src/yb/master/xcluster/xcluster_target_manager.cc
index dc788835ce..67ebc99418 100644
--- a/src/yb/master/xcluster/xcluster_target_manager.cc
+++ b/src/yb/master/xcluster/xcluster_target_manager.cc
@@ -19,15 +19,12 @@
 #include "yb/master/catalog_manager_util.h"
 #include "yb/master/master.h"
 #include "yb/master/xcluster/add_table_to_xcluster_target_task.h"
+#include "yb/master/xcluster/xcluster_replication_group.h"
 #include "yb/master/xcluster/xcluster_safe_time_service.h"
 
 #include "yb/util/flags.h"
 #include "yb/util/status.h"
 
-DEFINE_RUNTIME_bool(
-    disable_auto_add_index_to_xcluster, false,
-    "Disables the automatic addition of indexes to transactional xCluster replication.");
-
 namespace yb::master {
 
 XClusterTargetManager::XClusterTargetManager(
@@ -167,103 +164,19 @@ Status XClusterTargetManager::FillHeartbeatResponse(
   return Status::OK();
 }
 
-bool XClusterTargetManager::ShouldAddTableToXClusterTarget(const TableInfo& table) const {
-  if (FLAGS_disable_auto_add_index_to_xcluster) {
-    return false;
-  }
-
-  const auto& pb = table.metadata().dirty().pb;
-
-  // Only user created YSQL Indexes should be automatically added to xCluster replication.
-  // For Colocated tables, this function will return false since it is only called on the parent
-  // colocated table, which cannot be an index.
-  if (pb.colocated() || pb.table_type() != PGSQL_TABLE_TYPE || !IsIndex(pb) ||
-      !catalog_manager_.IsUserCreatedTable(table)) {
-    return false;
-  }
-
-  auto indexed_table_stream_ids = catalog_manager_.GetXClusterConsumerStreamIdsForTable(table.id());
-  if (!indexed_table_stream_ids.empty()) {
-    VLOG(1) << "Index " << table.ToString() << " is already part of xcluster replication "
-            << yb::ToString(indexed_table_stream_ids);
-    return false;
-  }
-
-  auto indexed_table = catalog_manager_.GetTableInfo(GetIndexedTableId(pb));
-  if (!indexed_table) {
-    LOG(WARNING) << "Indexed table for " << table.id() << " not found";
-    return false;
-  }
-
-  auto stream_ids = catalog_manager_.GetXClusterConsumerStreamIdsForTable(indexed_table->id());
-  if (stream_ids.empty()) {
-    return false;
-  }
-
-  if (stream_ids.size() > 1) {
-    LOG(WARNING) << "Skipping adding index " << table.ToString()
-                 << " to xCluster replication as the base table" << indexed_table->ToString()
-                 << " is part of multiple replication streams " << yb::ToString(stream_ids);
-    return false;
-  }
-
-  const auto& replication_group_id = stream_ids.begin()->first;
-  auto cluster_config = catalog_manager_.ClusterConfig();
-  {
-    auto l = cluster_config->LockForRead();
-    const auto& consumer_registry = l.data().pb.consumer_registry();
-    // Only add if we are in a transactional replication with STANDBY mode.
-    if (consumer_registry.role() != cdc::XClusterRole::STANDBY ||
-        !consumer_registry.transactional()) {
-      return false;
-    }
-
-    auto producer_entry =
-        FindOrNull(consumer_registry.producer_map(), replication_group_id.ToString());
-    if (producer_entry) {
-      // Check if the table is already part of replication.
-      // This is needed despite the check for GetXClusterConsumerStreamIdsForTable as the in-memory
-      // list is not atomically updated.
-      for (auto& stream_info : producer_entry->stream_map()) {
-        if (stream_info.second.consumer_table_id() == table.id()) {
-          VLOG(1) << "Index " << table.ToString() << " is already part of xcluster replication "
-                  << stream_info.first;
-          return false;
-        }
-      }
-    }
-  }
-
-  scoped_refptr<UniverseReplicationInfo> universe;
-  {
-    auto universe = catalog_manager_.GetUniverseReplication(replication_group_id);
-    if (universe == nullptr) {
-      LOG(WARNING) << "Skip adding index " << table.ToString()
-                   << " to xCluster replication as the universe " << replication_group_id
-                   << " was not found";
-      return false;
-    }
-
-    if (universe->LockForRead()->is_deleted_or_failed()) {
-      LOG(WARNING) << "Skip adding index " << table.ToString()
-                   << " to xCluster replication as the universe " << replication_group_id
-                   << " is in a deleted or failed state";
-      return false;
-    }
-  }
-
-  return true;
-}
-
 std::vector<std::shared_ptr<PostTabletCreateTaskBase>>
 XClusterTargetManager::GetPostTabletCreateTasks(
     const TableInfoPtr& table_info, const LeaderEpoch& epoch) {
-  if (!ShouldAddTableToXClusterTarget(*table_info)) {
-    return {};
+  std::vector<std::shared_ptr<PostTabletCreateTaskBase>> tasks;
+
+  for (const auto& universe : catalog_manager_.GetAllUniverseReplications()) {
+    if (ShouldAddTableToReplicationGroup(*universe, *table_info, catalog_manager_)) {
+      tasks.emplace_back(std::make_shared<AddTableToXClusterTargetTask>(
+          universe, catalog_manager_, *master_.messenger(), table_info, epoch));
+    }
   }
 
-  return {std::make_shared<AddTableToXClusterTargetTask>(
-      catalog_manager_, *master_.messenger(), table_info, epoch)};
+  return tasks;
 }
 
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_target_manager.h b/src/yb/master/xcluster/xcluster_target_manager.h
index b9389b056f..9d7a226e99 100644
--- a/src/yb/master/xcluster/xcluster_target_manager.h
+++ b/src/yb/master/xcluster/xcluster_target_manager.h
@@ -74,8 +74,6 @@ class XClusterTargetManager {
 
   Status FillHeartbeatResponse(const TSHeartbeatRequestPB& req, TSHeartbeatResponsePB* resp) const;
 
-  bool ShouldAddTableToXClusterTarget(const TableInfo& table_info) const;
-
   std::vector<std::shared_ptr<PostTabletCreateTaskBase>> GetPostTabletCreateTasks(
       const TableInfoPtr& table_info, const LeaderEpoch& epoch);
 
diff --git a/src/yb/master/xrepl_catalog_manager.cc b/src/yb/master/xrepl_catalog_manager.cc
index b4065ad6f6..522ddcbb0b 100644
--- a/src/yb/master/xrepl_catalog_manager.cc
+++ b/src/yb/master/xrepl_catalog_manager.cc
@@ -2582,6 +2582,15 @@ CatalogManager::CreateUniverseReplicationInfoForProducer(
       return STATUS(
           AlreadyPresent, "Replication group already present", replication_group_id.ToString());
     }
+
+    for (const auto& [universe_rg_id, universe] : universe_replication_map_) {
+      for (const auto& consumer_namespace_id : consumer_namespace_ids) {
+        SCHECK_FORMAT(
+            !IncludesConsumerNamespace(*universe, consumer_namespace_id), AlreadyPresent,
+            "Namespace $0 already included in replication group $1", consumer_namespace_id,
+            universe_rg_id);
+      }
+    }
   }
 
   // Create an entry in the system catalog DocDB for this new universe replication.
@@ -3106,6 +3115,9 @@ Status CatalogManager::SetupUniverseReplication(
   SCHECK_EQ(
       req->namespace_names_size(), req->producer_namespace_ids_size(), InvalidArgument,
       "Incorrect number of namespace names and producer namespace ids");
+  SCHECK(
+      req->namespace_names_size() == 0 || req->transactional(), InvalidArgument,
+      "Transactional flag must be set for Db scoped replication groups");
 
   std::vector<NamespaceId> producer_namespace_ids, consumer_namespace_ids;
   for (int i = 0; i < req->namespace_names_size(); ++i) {
@@ -4135,8 +4147,13 @@ Status CatalogManager::InitXClusterConsumer(
   auto* consumer_registry = l.mutable_data()->pb.mutable_consumer_registry();
   auto transactional = universe_l->pb.transactional();
   if (!xcluster::IsAlterReplicationGroupId(replication_info.ReplicationGroupId())) {
+    if (universe_l->pb.has_db_scoped_info()) {
+      consumer_registry->set_role(cdc::XClusterRole::STANDBY);
+      DCHECK(transactional);
+    }
     consumer_registry->set_transactional(transactional);
   }
+
   for (const auto& stream_info : consumer_info) {
     auto consumer_tablet_keys = VERIFY_RESULT(GetTableKeyRanges(stream_info.consumer_table_id));
     auto schema_version = VERIFY_RESULT(GetTableSchemaVersion(stream_info.consumer_table_id));
@@ -4195,6 +4212,7 @@ Status CatalogManager::InitXClusterConsumer(
 
   // TServers will use the ClusterConfig to create CDC Consumers for applicable local tablets.
   (*replication_group_map)[replication_info.id()] = std::move(producer_entry);
+
   l.mutable_data()->pb.set_version(l.mutable_data()->pb.version() + 1);
   RETURN_NOT_OK(CheckStatus(
       sys_catalog_->Upsert(leader_ready_term(), cluster_config.get()),
@@ -4289,10 +4307,7 @@ void CatalogManager::MergeUniverseReplication(
   }
 
   // Add alter temp universe to GC.
-  {
-    LockGuard lock(mutex_);
-    universes_to_clear_.push_back(universe->ReplicationGroupId());
-  }
+  MarkUniverseForCleanup(universe->ReplicationGroupId());
 
   LOG(INFO) << "Done with Merging " << universe->id() << " into " << original_universe->id();
 
@@ -4333,11 +4348,15 @@ Status CatalogManager::DeleteUniverseReplication(
   {
     auto cluster_config = ClusterConfig();
     auto cl = cluster_config->LockForWrite();
-    auto replication_group_map =
-        cl.mutable_data()->pb.mutable_consumer_registry()->mutable_producer_map();
+    auto* consumer_registry = cl.mutable_data()->pb.mutable_consumer_registry();
+    auto replication_group_map = consumer_registry->mutable_producer_map();
     auto it = replication_group_map->find(replication_group_id.ToString());
     if (it != replication_group_map->end()) {
       replication_group_map->erase(it);
+      if (l->pb.has_db_scoped_info()) {
+        consumer_registry->set_role(cdc::XClusterRole::ACTIVE);
+        consumer_registry->clear_transactional();
+      }
       cl.mutable_data()->pb.set_version(cl.mutable_data()->pb.version() + 1);
       RETURN_NOT_OK(CheckStatus(
           sys_catalog_->Upsert(leader_ready_term(), cluster_config.get()),
@@ -5094,8 +5113,7 @@ Status CatalogManager::RenameUniverseReplication(
 }
 
 Status CatalogManager::GetUniverseReplication(
-    const GetUniverseReplicationRequestPB* req,
-    GetUniverseReplicationResponsePB* resp,
+    const GetUniverseReplicationRequestPB* req, GetUniverseReplicationResponsePB* resp,
     rpc::RpcContext* rpc) {
   LOG(INFO) << "GetUniverseReplication from " << RequestorString(rpc) << ": " << req->DebugString();
 
@@ -5135,81 +5153,13 @@ Status CatalogManager::IsSetupUniverseReplicationDone(
   LOG(INFO) << "IsSetupUniverseReplicationDone from " << RequestorString(rpc) << ": "
             << req->DebugString();
 
-  if (!req->has_replication_group_id()) {
-    return STATUS(
-        InvalidArgument, "Producer universe ID must be provided", req->ShortDebugString(),
-        MasterError(MasterErrorPB::INVALID_REQUEST));
-  }
-  const xcluster::ReplicationGroupId replication_group_id(req->replication_group_id());
-  bool is_alter_request = xcluster::IsAlterReplicationGroupId(replication_group_id);
-
-  GetUniverseReplicationRequestPB universe_req;
-  GetUniverseReplicationResponsePB universe_resp;
-  universe_req.set_replication_group_id(replication_group_id.ToString());
-
-  auto s = GetUniverseReplication(&universe_req, &universe_resp, /* RpcContext */ nullptr);
-  // If the universe was deleted, we're done.  This is normal with ALTER tmp files.
-  if (s.IsNotFound()) {
-    resp->set_done(true);
-    if (is_alter_request) {
-      s = Status::OK();
-      StatusToPB(s, resp->mutable_replication_error());
-    }
-    return s;
-  }
-  RETURN_NOT_OK(s);
-  if (universe_resp.has_error()) {
-    RETURN_NOT_OK(StatusFromPB(universe_resp.error().status()));
-  }
-
-  // Two cases for completion:
-  //  - For a regular SetupUniverseReplication, we want to wait for the universe to become ACTIVE.
-  //  - For an AlterUniverseReplication, we need to wait until the .ALTER universe gets merged with
-  //    the main universe - at which point the .ALTER universe is deleted.
-  auto terminal_state = is_alter_request ? SysUniverseReplicationEntryPB::DELETED
-                                         : SysUniverseReplicationEntryPB::ACTIVE;
-  if (universe_resp.entry().state() == terminal_state) {
-    resp->set_done(true);
-    StatusToPB(Status::OK(), resp->mutable_replication_error());
-    return Status::OK();
-  }
-
-  // Otherwise we have either failed (see MarkUniverseReplicationFailed), or are still working.
-  if (universe_resp.entry().state() == SysUniverseReplicationEntryPB::DELETED_ERROR ||
-      universe_resp.entry().state() == SysUniverseReplicationEntryPB::FAILED) {
-    resp->set_done(true);
-
-    // Get the more detailed error.
-    scoped_refptr<UniverseReplicationInfo> universe;
-    {
-      SharedLock lock(mutex_);
-      universe = FindPtrOrNull(universe_replication_map_, replication_group_id);
-      if (universe == nullptr) {
-        StatusToPB(
-            STATUS(InternalError, "Could not find CDC producer universe after having failed."),
-            resp->mutable_replication_error());
-        return Status::OK();
-      }
-    }
-    if (!universe->GetSetupUniverseReplicationErrorStatus().ok()) {
-      StatusToPB(
-          universe->GetSetupUniverseReplicationErrorStatus(), resp->mutable_replication_error());
-    } else {
-      LOG(WARNING) << "Did not find setup universe replication error status.";
-      StatusToPB(STATUS(InternalError, "unknown error"), resp->mutable_replication_error());
-    }
-
-    // Add failed universe to GC now that we've responded to the user.
-    {
-      LockGuard lock(mutex_);
-      universes_to_clear_.push_back(universe->ReplicationGroupId());
-    }
+  SCHECK_PB_FIELDS_ARE_SET(*req, replication_group_id);
 
-    return Status::OK();
-  }
+  auto is_operation_done = VERIFY_RESULT(master::IsSetupUniverseReplicationDone(
+      xcluster::ReplicationGroupId(req->replication_group_id()), *this));
 
-  // Not done yet.
-  resp->set_done(false);
+  resp->set_done(is_operation_done.done);
+  StatusToPB(is_operation_done.status, resp->mutable_replication_error());
   return Status::OK();
 }
 
@@ -7168,47 +7118,6 @@ Status CatalogManager::BumpVersionAndStoreClusterConfig(
   return Status::OK();
 }
 
-Result<xcluster::ReplicationGroupId> CatalogManager::GetIndexesTableReplicationGroup(
-    const TableInfo& index_info) {
-  const auto indexed_table_id = GetIndexedTableId(index_info.LockForRead()->pb);
-  SCHECK(!indexed_table_id.empty(), IllegalState, "Indexed table id is empty");
-
-  XClusterConsumerTableStreamIds indexed_table_stream_ids =
-      GetXClusterConsumerStreamIdsForTable(indexed_table_id);
-
-  SCHECK_EQ(
-      indexed_table_stream_ids.size(), 1, IllegalState,
-      Format("Expected table $0 to be part of only one replication", indexed_table_id));
-
-  return indexed_table_stream_ids.begin()->first;
-}
-
-Status CatalogManager::BootstrapTable(
-    const xcluster::ReplicationGroupId& replication_group_id, const TableInfo& table_info,
-    client::BootstrapProducerCallback callback) {
-  VLOG_WITH_FUNC(1) << "Bootstrapping table " << table_info.ToString();
-
-  scoped_refptr<UniverseReplicationInfo> universe;
-  google::protobuf::RepeatedPtrField<HostPortPB> master_addresses;
-  {
-    TRACE("Acquired catalog manager lock");
-    SharedLock lock(mutex_);
-    universe = FindPtrOrNull(universe_replication_map_, replication_group_id);
-    SCHECK(universe != nullptr, NotFound, Format("Universe $0 not found", replication_group_id));
-    master_addresses = universe->LockForRead()->pb.producer_master_addresses();
-  }
-
-  auto xcluster_rpc = VERIFY_RESULT(universe->GetOrCreateXClusterRpcTasks(master_addresses));
-
-  std::vector<PgSchemaName> pg_schema_names;
-  if (!table_info.pgschema_name().empty()) {
-    pg_schema_names.emplace_back(table_info.pgschema_name());
-  }
-  return xcluster_rpc->client()->BootstrapProducer(
-      YQLDatabase::YQL_DATABASE_PGSQL, table_info.namespace_name(), pg_schema_names,
-      {table_info.name()}, std::move(callback));
-}
-
 Status CatalogManager::RemoveTableFromXcluster(const vector<TabletId>& table_ids) {
   std::map<xcluster::ReplicationGroupId, std::unordered_set<TableId>> replication_group_tables_map;
   {
@@ -7491,5 +7400,21 @@ scoped_refptr<UniverseReplicationInfo> CatalogManager::GetUniverseReplication(
   return FindPtrOrNull(universe_replication_map_, replication_group_id);
 }
 
+std::vector<scoped_refptr<UniverseReplicationInfo>> CatalogManager::GetAllUniverseReplications()
+    const {
+  std::vector<scoped_refptr<UniverseReplicationInfo>> result;
+  SharedLock lock(mutex_);
+  for (const auto& [_, universe] : universe_replication_map_) {
+    result.emplace_back(universe);
+  }
+  return result;
+}
+
+void CatalogManager::MarkUniverseForCleanup(
+    const xcluster::ReplicationGroupId& replication_group_id) {
+  LockGuard lock(mutex_);
+  universes_to_clear_.push_back(replication_group_id);
+}
+
 }  // namespace master
 }  // namespace yb
diff --git a/src/yb/util/pb_util.h b/src/yb/util/pb_util.h
index e9ff498eee..d0ccb36785 100644
--- a/src/yb/util/pb_util.h
+++ b/src/yb/util/pb_util.h
@@ -56,7 +56,7 @@
   do { \
     std::vector<std::string> _missing_fields; \
     BOOST_PP_SEQ_FOR_EACH( \
-        INTERNAL_SCHECK_PB_FIELD_IS_SET, pb, BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__)) \
+        INTERNAL_SCHECK_PB_FIELD_IS_SET, (pb), BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__)) \
     SCHECK_FORMAT( \
         _missing_fields.empty(), InvalidArgument, "Missing required arguments: $0", \
         _missing_fields); \
