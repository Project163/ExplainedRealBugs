diff --git a/java/yb-pgsql/src/test/java/org/yb/pgsql/TestPgRegressThirdPartyExtensionsPgCron.java b/java/yb-pgsql/src/test/java/org/yb/pgsql/TestPgRegressThirdPartyExtensionsPgCron.java
index 6ec7d353d1..bf6cc9c06f 100644
--- a/java/yb-pgsql/src/test/java/org/yb/pgsql/TestPgRegressThirdPartyExtensionsPgCron.java
+++ b/java/yb-pgsql/src/test/java/org/yb/pgsql/TestPgRegressThirdPartyExtensionsPgCron.java
@@ -27,10 +27,19 @@ public class TestPgRegressThirdPartyExtensionsPgCron extends BasePgSQLTest {
     return 1800;
   }
 
+  @Override
+  protected Map<String, String> getMasterFlags() {
+    Map<String, String> flagMap = super.getMasterFlags();
+    flagMap.put("allowed_preview_flags_csv", "enable_pg_cron");
+    flagMap.put("enable_pg_cron", "true");
+    return flagMap;
+  }
+
   @Override
   protected Map<String, String> getTServerFlags() {
     Map<String, String> flagMap = super.getTServerFlags();
-    flagMap.put("TEST_enable_pg_cron", "true");
+    flagMap.put("allowed_preview_flags_csv", "enable_pg_cron");
+    flagMap.put("enable_pg_cron", "true");
     return flagMap;
   }
 
diff --git a/src/postgres/third-party-extensions/pg_cron/pg_cron.sql b/src/postgres/third-party-extensions/pg_cron/pg_cron.sql
index 2de23f4462..979b0098f1 100644
--- a/src/postgres/third-party-extensions/pg_cron/pg_cron.sql
+++ b/src/postgres/third-party-extensions/pg_cron/pg_cron.sql
@@ -4,9 +4,9 @@ BEGIN
       RAISE EXCEPTION 'can only create extension in database %',
                       pg_catalog.current_setting('cron.database_name')
       USING DETAIL = 'Jobs must be scheduled from the database configured in 'OPERATOR(pg_catalog.||)
-                     'cron.database_name, since the pg_cron background worker 'OPERATOR(pg_catalog.||)
+                     'ysql_cron_database_name, since the pg_cron background worker 'OPERATOR(pg_catalog.||)
                      'reads job descriptions from this database.',
-            HINT = pg_catalog.format('Add cron.database_name = ''%s'' in postgresql.conf 'OPERATOR(pg_catalog.||)
+            HINT = pg_catalog.format('Set the flag ysql_cron_database_name to ''%s'' on yb-tservers 'OPERATOR(pg_catalog.||)
                           'to use the current database.', pg_catalog.current_database());
    END IF;
 END;
diff --git a/src/postgres/third-party-extensions/pg_cron/src/pg_cron.c b/src/postgres/third-party-extensions/pg_cron/src/pg_cron.c
index f08cc2b512..c0539e3060 100644
--- a/src/postgres/third-party-extensions/pg_cron/src/pg_cron.c
+++ b/src/postgres/third-party-extensions/pg_cron/src/pg_cron.c
@@ -95,6 +95,7 @@
 
 /* YB includes */
 #include "pg_yb_utils.h"
+#include "catalog/yb_catalog_version.h"
 
 PG_MODULE_MAGIC;
 
@@ -236,7 +237,7 @@ _PG_init(void)
 		gettext_noop("Log all cron statements prior to execution."),
 		NULL,
 		&CronLogStatement,
-		true, /* TODO(hari): false? */
+		true,
 		PGC_POSTMASTER,
 		GUC_SUPERUSER_ONLY,
 		NULL, NULL, NULL);
@@ -308,7 +309,7 @@ _PG_init(void)
 			"cron.max_running_jobs",
 			gettext_noop("Maximum number of jobs that can run concurrently."),
 			NULL,
-			&MaxRunningTasks, /* TODO(Hari): We need local and global limits */
+			&MaxRunningTasks,
 			(max_worker_processes - 1 < 5) ? max_worker_processes - 1 : 5,
 			0,
 			max_worker_processes - 1,
@@ -663,6 +664,8 @@ PgCronLauncherMain(Datum arg)
 		List *taskList = NIL;
 		TimestampTz currentTime = 0;
 
+		CHECK_FOR_INTERRUPTS();
+
 		AcceptInvalidationMessages();
 
 		if (CronReloadConfig)
@@ -2163,6 +2166,12 @@ CronBackgroundWorker(Datum main_arg)
 #endif
 
 	/* Prepare to execute the query. */
+	/* YB Note: Always read the latest entries in the catalog */
+	if (IsYugaByteEnabled())
+	{
+		YBCPgResetCatalogReadTime();
+		YbUpdateCatalogCacheVersion(YbGetMasterCatalogVersion());
+	}
 	SetCurrentStatementStartTimestamp();
 	debug_query_string = command;
 	pgstat_report_activity(STATE_RUNNING, command);
diff --git a/src/yb/common/common_flags.cc b/src/yb/common/common_flags.cc
index abd153a390..4156cc1f56 100644
--- a/src/yb/common/common_flags.cc
+++ b/src/yb/common/common_flags.cc
@@ -189,6 +189,13 @@ DEFINE_RUNTIME_AUTO_bool(enable_xcluster_auto_flag_validation, kLocalPersisted,
 DEFINE_RUNTIME_AUTO_PG_FLAG(bool, yb_enable_ddl_atomicity_infra, kLocalPersisted, false, true,
     "Enables YSQL DDL atomicity");
 
+// NOTE: This flag guards proto changes and it is not safe to enable during an upgrade, or rollback
+// once enabled. If you want to change the default to true then you will have to make it a
+// kLocalPersisted AutoFlag.
+DEFINE_NON_RUNTIME_PREVIEW_bool(enable_pg_cron, false,
+    "Enables the pg_cron extension. Jobs will be run on a single tserver node. The node should be "
+    "assumed to be selected randomly.");
+
 namespace yb {
 
 void InitCommonFlags() {
diff --git a/src/yb/common/common_types.proto b/src/yb/common/common_types.proto
index a50a5b44fe..4e30961b84 100644
--- a/src/yb/common/common_types.proto
+++ b/src/yb/common/common_types.proto
@@ -166,6 +166,7 @@ enum StatefulServiceKind {
   // Test service.
   TEST_ECHO = 0;
   PG_AUTO_ANALYZE = 1;
+  PG_CRON_LEADER = 2;
 }
 
 // CDC SDK Consistent Snapshot Options
diff --git a/src/yb/integration-tests/external_mini_cluster.cc b/src/yb/integration-tests/external_mini_cluster.cc
index 61b8fd4b30..20fd6fda1a 100644
--- a/src/yb/integration-tests/external_mini_cluster.cc
+++ b/src/yb/integration-tests/external_mini_cluster.cc
@@ -2103,6 +2103,7 @@ Result<pgwrapper::PGConn> ExternalMiniCluster::ConnectToDB(
   if (!node_index) {
     node_index = RandomUniformInt<size_t>(0, num_tablet_servers() - 1);
   }
+  LOG(INFO) << "Connecting to PG database " << db_name << " on tserver " << *node_index;
 
   auto* ts = tablet_server(*node_index);
   return pgwrapper::PGConnBuilder(
@@ -2110,6 +2111,47 @@ Result<pgwrapper::PGConn> ExternalMiniCluster::ConnectToDB(
       .Connect(simple_query_protocol);
 }
 
+namespace {
+Result<itest::TabletServerMap> CreateTabletServerMap(ExternalMiniCluster& cluster) {
+  auto master = cluster.GetLeaderMaster();
+  SCHECK_NOTNULL(master);
+  return itest::CreateTabletServerMap(
+      cluster.GetProxy<master::MasterClusterProxy>(master), &cluster.proxy_cache());
+}
+}  // namespace
+
+Status ExternalMiniCluster::MoveTabletLeader(
+    const TabletId& tablet_id, std::optional<size_t> new_leader_idx, MonoDelta timeout) {
+  if (timeout == MonoDelta::kMin) {
+    timeout = MonoDelta::FromSeconds(10 * kTimeMultiplier);
+  }
+
+  const auto ts_map = VERIFY_RESULT(CreateTabletServerMap(*this));
+
+  itest::TServerDetails* leader_ts;
+  RETURN_NOT_OK(itest::FindTabletLeader(ts_map, tablet_id, timeout, &leader_ts));
+
+  itest::TServerDetails* new_leader_ts = nullptr;
+  if (new_leader_idx) {
+    new_leader_ts = ts_map.at(tablet_server(*new_leader_idx)->uuid()).get();
+  } else {
+    for (const auto& [ts_id, ts_details] : ts_map) {
+      if (ts_id != leader_ts->uuid()) {
+        new_leader_ts = ts_details.get();
+      }
+    }
+  }
+  SCHECK_NOTNULL(new_leader_ts);
+
+  // Step down the leader onto the second follower.
+  RETURN_NOT_OK(
+      (itest::WaitForAllPeersToCatchup(tablet_id, TServerDetailsVector(ts_map), timeout)));
+  RETURN_NOT_OK(
+      itest::LeaderStepDown(leader_ts, tablet_id, new_leader_ts, timeout, false, nullptr));
+
+  return itest::WaitUntilLeader(new_leader_ts, tablet_id, timeout);
+}
+
 //------------------------------------------------------------
 // ExternalDaemon
 //------------------------------------------------------------
diff --git a/src/yb/integration-tests/external_mini_cluster.h b/src/yb/integration-tests/external_mini_cluster.h
index 575ab02751..404ee6226a 100644
--- a/src/yb/integration-tests/external_mini_cluster.h
+++ b/src/yb/integration-tests/external_mini_cluster.h
@@ -556,6 +556,10 @@ class ExternalMiniCluster : public MiniClusterBase {
       const std::string& db_name = "yugabyte", std::optional<size_t> node_index = std::nullopt,
       bool simple_query_protocol = false);
 
+  Status MoveTabletLeader(
+      const TabletId& tablet_id, std::optional<size_t> new_leader_idx = std::nullopt,
+      MonoDelta timeout = MonoDelta::kMin);
+
  protected:
   FRIEND_TEST(MasterFailoverTest, TestKillAnyMaster);
 
@@ -594,12 +598,6 @@ class ExternalMiniCluster : public MiniClusterBase {
       std::vector<OpIdPB>* op_ids,
       const std::vector<ExternalMaster*>& masters);
 
-  // Ensure that the leader server is allowed to process a config change (by having at least one
-  // commit in the current term as leader).
-  Status WaitForLeaderToAllowChangeConfig(
-      const std::string& uuid,
-      consensus::ConsensusServiceProxy* leader_proxy);
-
   // Return master address for specified port.
   std::string MasterAddressForPort(uint16_t port) const;
 
diff --git a/src/yb/integration-tests/pg_cron-test.cc b/src/yb/integration-tests/pg_cron-test.cc
index c591360c10..783c80a732 100644
--- a/src/yb/integration-tests/pg_cron-test.cc
+++ b/src/yb/integration-tests/pg_cron-test.cc
@@ -14,8 +14,11 @@
 #include <chrono>
 
 #include "yb/integration-tests/external_mini_cluster.h"
-#include "yb/tserver/tablet_server.h"
-#include "yb/yql/pgwrapper/pg_mini_test_base.h"
+#include "yb/integration-tests/yb_mini_cluster_test_base.h"
+#include "yb/master/master_client.pb.h"
+#include "yb/tserver/stateful_services/stateful_service_base.h"
+#include "yb/util/backoff_waiter.h"
+#include "yb/yql/pgwrapper/libpq_utils.h"
 
 using namespace std::chrono_literals;
 
@@ -24,12 +27,19 @@ namespace yb {
 constexpr auto kTableName = "tbl1";
 constexpr auto kDefaultJobName = "Job1";
 constexpr auto kobListRefreshInterval = 10;
+const client::YBTableName service_table_name =
+    stateful_service::GetStatefulServiceTableName(StatefulServiceKind::PG_CRON_LEADER);
+const auto kTimeout = 60s * kTimeMultiplier;
 
 class PgCronTest : public MiniClusterTestWithClient<ExternalMiniCluster> {
  public:
   PgCronTest() = default;
 
   void SetUp() override {
+    // #22462. Skip in TSAN as starting the pg_cron background worker gets into a deadlock with
+    // LLVMSymbolizer.
+    YB_SKIP_TEST_IN_TSAN();
+
     YBMiniClusterTestBase<ExternalMiniCluster>::SetUp();
     ExternalMiniClusterOptions opts;
     opts.num_tablet_servers = 3;
@@ -37,61 +47,95 @@ class PgCronTest : public MiniClusterTestWithClient<ExternalMiniCluster> {
     opts.num_masters = 1;
     opts.enable_ysql = true;
 
+    opts.extra_master_flags.push_back("--allowed_preview_flags_csv=enable_pg_cron");
+    opts.extra_master_flags.push_back("--enable_pg_cron=true");
+
     opts.extra_tserver_flags.push_back("--vmodule=pg_cron*=4");
-    opts.extra_tserver_flags.push_back("--TEST_enable_pg_cron=true");
+    opts.extra_tserver_flags.push_back("--allowed_preview_flags_csv=enable_pg_cron");
+    opts.extra_tserver_flags.push_back("--enable_pg_cron=true");
     opts.extra_tserver_flags.push_back(
         Format("--ysql_pg_conf_csv=cron.yb_job_list_refresh_interval=$0", kobListRefreshInterval));
+    opts.extra_tserver_flags.push_back(
+        Format("--pg_cron_leader_lease_sec=$0", kobListRefreshInterval));
+    opts.extra_tserver_flags.push_back("--pg_cron_leadership_refresh_sec=1");
 
     cluster_.reset(new ExternalMiniCluster(opts));
     ASSERT_OK(cluster_->Start());
     ASSERT_OK(MiniClusterTestWithClient<ExternalMiniCluster>::CreateClient());
 
-    conn_ = std::make_unique<pgwrapper::PGConn>(ASSERT_RESULT(Connect()));
+    conn_ = std::make_unique<pgwrapper::PGConn>(ASSERT_RESULT(cluster_->ConnectToDB()));
 
     ASSERT_OK(CreateTable());
     ASSERT_OK(CreateCronExtension());
 
-    // Make the first tserver the cron leader. #22360 will make this unnecessary.
-    ASSERT_OK(cluster_->SetFlag(cluster_->tablet_server(0), "TEST_is_ysql_cron_leader", "true"));
+    ASSERT_OK(client_->WaitForCreateTableToFinish(service_table_name));
+    std::vector<TabletId> tablet_ids;
+    ASSERT_OK(client_->GetTablets(service_table_name, 0 /* max_tablets */, &tablet_ids, NULL));
+    ASSERT_EQ(tablet_ids.size(), 1);
+    tablet_id_ = tablet_ids.front();
+    ASSERT_OK(cluster_->WaitForLoadBalancerToBecomeIdle(client_, kTimeout));
   }
 
-  Result<pgwrapper::PGConn> Connect() { return cluster_->ConnectToDB(); }
+  pgwrapper::PGConn* UseDefaultConnIfNull(pgwrapper::PGConn* conn) {
+    return conn == nullptr ? conn_.get() : conn;
+  }
 
-  Status CreateTable(const std::string& table_name = kTableName) {
-    return conn_->Execute(Format(
+  Status CreateTable(
+      pgwrapper::PGConn* conn = nullptr, const std::string& table_name = kTableName) {
+    conn = UseDefaultConnIfNull(conn);
+    return conn->Execute(Format(
         "CREATE TABLE $0 (a INT, node TEXT, insert_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP)",
         table_name));
   }
 
-  Status CreateCronExtension() { return conn_->Execute("CREATE EXTENSION pg_cron"); }
+  Status CreateCronExtension(pgwrapper::PGConn* conn = nullptr) {
+    conn = UseDefaultConnIfNull(conn);
+    return conn->Execute("CREATE EXTENSION pg_cron");
+  }
 
-  Result<int64_t> Schedule1SecInsertJob(const std::string& job_name = kDefaultJobName) {
+  Result<int64_t> Schedule1SecInsertJob(
+      pgwrapper::PGConn* conn = nullptr, const std::string& job_name = kDefaultJobName) {
     auto insert_query =
         Format("INSERT INTO $0(a, node) VALUES (1, host(inet_server_addr()))", kTableName);
-    return ScheduleJob(job_name, "1 second", insert_query);
+    return ScheduleJob(job_name, "1 second", insert_query, conn);
   }
 
   // Returns the JobId
   Result<int64_t> ScheduleJob(
-      const std::string& job_name, const std::string& schedule, const std::string& query) {
+      const std::string& job_name, const std::string& schedule, const std::string& query,
+      pgwrapper::PGConn* conn = nullptr) {
+    conn = UseDefaultConnIfNull(conn);
     LOG(INFO) << Format(
         "Scheduling job $0 with schedule $1 and query $2", job_name, schedule, query);
-    return conn_->FetchRow<int64_t>(
+    return conn->FetchRow<pgwrapper::PGUint64>(
         Format("SELECT cron.schedule('$0', '$1', '$2')", job_name, schedule, query));
   }
 
-  Status UnscheduleJob(const int64_t& job_id) {
+  // Returns the JobId
+  Result<int64_t> ScheduleJobInDatabase(
+      const std::string& job_name, const std::string& schedule, const std::string& query,
+      const std::string& db_name) {
+    LOG(INFO) << Format(
+        "Scheduling job $0 with schedule $1 and query $2", job_name, schedule, query);
+    return conn_->FetchRow<pgwrapper::PGUint64>(Format(
+        "SELECT cron.schedule_in_database('$0', '$1', '$2', '$3')", job_name, schedule, query,
+        db_name));
+  }
+
+  Status UnscheduleJob(const int64_t& job_id, pgwrapper::PGConn* conn = nullptr) {
+    conn = UseDefaultConnIfNull(conn);
     LOG(INFO) << Format("Unscheduling job $0", job_id);
 
     // Returns a bool indicating if the job was unscheduled.
-    auto result =
-        VERIFY_RESULT(conn_->FetchRow<bool>(Format("SELECT cron.unschedule($0)", job_id)));
+    auto result = VERIFY_RESULT(conn->FetchRow<bool>(Format("SELECT cron.unschedule($0)", job_id)));
     SCHECK(result, IllegalState, "Failed to unschedule job");
     return Status::OK();
   }
 
-  Result<int64_t> GetRowCount(const std::string& table_name = kTableName) {
-    return conn_->FetchRow<int64_t>(Format("SELECT COUNT(*) FROM $0", table_name));
+  Result<int64_t> GetRowCount(
+      pgwrapper::PGConn* conn = nullptr, const std::string& table_name = kTableName) {
+    conn = UseDefaultConnIfNull(conn);
+    return conn->FetchRow<pgwrapper::PGUint64>(Format("SELECT COUNT(*) FROM $0", table_name));
   }
 
   std::unique_ptr<pgwrapper::PGConn> conn_;
@@ -119,17 +163,18 @@ TEST_F(PgCronTest, AtMostOnceTest) {
   // Max rows is the total amount of time we slept.
   ASSERT_LE(row_count, sleep_time_sec + kobListRefreshInterval);
 
-  // Wait a little bit longer to make sure job is still not running.
+  // Wait a little bit longer to make sure job is not running.
   SleepFor(default_sleep_sec * 1s);
   auto row_count2 = ASSERT_RESULT(GetRowCount());
   ASSERT_EQ(row_count, row_count2);
 
   // Make sure it was cron that inserted all the rows.
-  auto job_run_count =
-      ASSERT_RESULT(conn_->FetchRow<int64_t>("SELECT COUNT(*) FROM cron.job_run_details"));
+  auto job_run_count = ASSERT_RESULT(
+      conn_->FetchRow<pgwrapper::PGUint64>("SELECT COUNT(*) FROM cron.job_run_details"));
   ASSERT_EQ(row_count, job_run_count);
 }
 
+// Run a job every minute and make sure it runs at most once.
 TEST_F(PgCronTest, PerMinuteTask) {
   auto insert_query =
       Format("INSERT INTO $0(a, node) VALUES (1, host(inet_server_addr()))", kTableName);
@@ -147,6 +192,203 @@ TEST_F(PgCronTest, PerMinuteTask) {
   ASSERT_LE(row_count, default_sleep_min + 1);
 }
 
-TEST_F(PgCronTest, RecreatejobWithSameName) {}
+// Schedule a job an a database other than the cron database and make sure it runs.
+TEST_F(PgCronTest, JobOnDifferentDB) {
+  constexpr auto kDropTablesFunc = R"(
+    CREATE OR REPLACE FUNCTION drop_all_tables() RETURNS VOID AS $$
+    DECLARE
+        table_name text;
+    BEGIN
+        FOR table_name IN (
+            SELECT tablename
+            FROM pg_tables
+            WHERE schemaname = 'public'
+        )
+        LOOP
+            EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(table_name);
+        END LOOP;
+    END;
+    $$ LANGUAGE plpgsql;
+  )";
+
+  constexpr auto db_name = "db1";
+  ASSERT_OK(conn_->ExecuteFormat("CREATE DATABASE $0", db_name));
+
+  auto new_db_conn = ASSERT_RESULT(cluster_->ConnectToDB(db_name));
+  // Multi line query.
+  ASSERT_OK(new_db_conn.Execute(kDropTablesFunc));
+
+  ASSERT_OK(ScheduleJobInDatabase("drop tables", "1 second", "SELECT drop_all_tables()", db_name));
+
+  // Wait 2 minutes.
+  const auto default_sleep_min = 2;
+  const auto sleep_time = MonoDelta::FromSeconds(kobListRefreshInterval + (60 * default_sleep_min));
+  const auto start = MonoTime::Now();
+
+  for (int i = 0; MonoTime::Now() - start < sleep_time; i++) {
+    LOG(INFO) << Format("Creating table $0", i);
+    ASSERT_OK(new_db_conn.ExecuteFormat("CREATE TABLE tbl$0(a INT)", i));
+    SleepFor(1s);
+  }
+
+  // Wait for the job to get to all the tables.
+  SleepFor(3s * kTimeMultiplier);
+
+  // We should have (default_sleep_min, default_sleep_min+1) rows.
+  auto table_count = ASSERT_RESULT(new_db_conn.FetchRow<pgwrapper::PGUint64>(
+      "SELECT COUNT(*) FROM pg_tables WHERE schemaname = 'public'"));
+  ASSERT_EQ(table_count, 0);
+}
+
+// Make sure pg_cron can survive the crash of the leader tserver/postgres process.
+TEST_F(PgCronTest, LeaderCrash) {
+  // Schedule a 1sec job.
+  const auto job_id = ASSERT_RESULT(Schedule1SecInsertJob());
+
+  // Wait for the job to get picked up and run for a while.
+  const auto default_sleep_sec = 10;
+  const auto kSleepBuffer = 3s;
+  const auto sleep_time = (kobListRefreshInterval + default_sleep_sec) * 1s + kSleepBuffer;
+  SleepFor(sleep_time);
+
+  // Verify GetStatefulServiceLocation returns the correct location.
+  auto initial_leader_idx = ASSERT_RESULT(cluster_->GetTabletLeaderIndex(tablet_id_));
+  auto location =
+      ASSERT_RESULT(client_->GetStatefulServiceLocation(StatefulServiceKind::PG_CRON_LEADER));
+  ASSERT_EQ(location.permanent_uuid(), cluster_->tablet_server(initial_leader_idx)->uuid());
+
+  cluster_->tablet_server(initial_leader_idx)->Shutdown();
+
+  // Connect to some other node.
+  conn_ = std::make_unique<pgwrapper::PGConn>(ASSERT_RESULT(cluster_->ConnectToDB(
+      /*db_name=*/"yugabyte",
+      /*node_index=*/(initial_leader_idx + 1) % cluster_->num_tablet_servers())));
+
+  ASSERT_OK(WaitFor(
+      [&]() -> Result<bool> {
+        auto leader = cluster_->GetTabletLeaderIndex(tablet_id_);
+        return leader.ok();
+      },
+      kTimeout, "Wait for new leader"));
+
+  auto final_leader_idx = ASSERT_RESULT(cluster_->GetTabletLeaderIndex(tablet_id_));
+  ASSERT_NE(final_leader_idx, initial_leader_idx);
+
+  // Make sure new leader is running jobs.
+  auto row_count = ASSERT_RESULT(GetRowCount());
+  SleepFor(sleep_time);
+  auto row_count2 = ASSERT_RESULT(GetRowCount());
+  ASSERT_GT(row_count2, row_count);
+
+  // Stop the job.
+  ASSERT_OK(UnscheduleJob(job_id));
+  SleepFor(kobListRefreshInterval * 1s);
+
+  // Make sure we inserted the minumum number of rows.
+  auto row_count3 = ASSERT_RESULT(GetRowCount());
+  ASSERT_GE(row_count3, 2 * default_sleep_sec);
+
+  // Wait a little bit longer to make sure job is not running.
+  SleepFor(default_sleep_sec * 1s);
+  auto row_count4 = ASSERT_RESULT(GetRowCount());
+  ASSERT_EQ(row_count3, row_count4);
+
+  // Make it was cron that inserted all the rows inserted rows.
+  auto job_run_count = ASSERT_RESULT(
+      conn_->FetchRow<pgwrapper::PGUint64>("SELECT COUNT(*) FROM cron.job_run_details"));
+  // May not be equal as some run might have failed midway.
+  ASSERT_LE(row_count3, job_run_count);
+
+  // YBMiniClusterTestBase test-end verification will fail if the cluster is up with stopped nodes.
+  cluster_->Shutdown();
+}
+
+// Make sure pg_cron handles graceful leader movement of the Stateful service.
+TEST_F(PgCronTest, GracefulLeaderMove) {
+  // Schedule a 1sec job.
+  const auto job_id = ASSERT_RESULT(Schedule1SecInsertJob());
+
+  // Wait for the job to get picked up and run for a while.
+  const auto default_sleep_sec = 10;
+  const auto kSleepBuffer = 3s;
+  const auto sleep_time = (kobListRefreshInterval + default_sleep_sec) * 1s + kSleepBuffer;
+  SleepFor(sleep_time);
+
+  ASSERT_OK(cluster_->MoveTabletLeader(tablet_id_));
+  ASSERT_OK(cluster_->WaitForLoadBalancerToBecomeIdle(client_, kTimeout));
+
+  // Make sure new leader is running jobs.
+  auto row_count = ASSERT_RESULT(GetRowCount());
+  SleepFor(sleep_time);
+  auto row_count2 = ASSERT_RESULT(GetRowCount());
+  ASSERT_GT(row_count2, row_count);
+
+  // Stop the job.
+  ASSERT_OK(UnscheduleJob(job_id));
+  SleepFor(kobListRefreshInterval * 1s);
+
+  // Make sure we inserted the minumum number of rows.
+  auto row_count3 = ASSERT_RESULT(GetRowCount());
+  ASSERT_GE(row_count3, 2 * default_sleep_sec);
+
+  // Wait a little bit longer to make sure job is not running.
+  SleepFor(default_sleep_sec * 1s);
+  auto row_count4 = ASSERT_RESULT(GetRowCount());
+  ASSERT_EQ(row_count3, row_count4);
+
+  // Make it was cron that inserted all the rows inserted rows.
+  auto job_run_count = ASSERT_RESULT(
+      conn_->FetchRow<pgwrapper::PGUint64>("SELECT COUNT(*) FROM cron.job_run_details"));
+  // May not be equal as some run might have failed midway.
+  ASSERT_LE(row_count3, job_run_count);
+}
+
+// Verify the ysql_cron_database_name flag works as expected.
+TEST_F(PgCronTest, ChangeCronDB) {
+  constexpr auto db_name = "db1";
+  ASSERT_OK(conn_->ExecuteFormat("CREATE DATABASE $0", db_name));
+
+  // Schedule a 1sec job.
+  ASSERT_OK(Schedule1SecInsertJob());
+
+  // Wait for the job to get picked up and run for a while.
+  const auto default_sleep_sec = 10;
+  const auto kSleepBuffer = 3s;
+  const auto sleep_time = (kobListRefreshInterval + default_sleep_sec) * 1s + kSleepBuffer;
+  SleepFor(sleep_time);
+
+  // Change the cron database with a restart.
+  cluster_->AddExtraFlagOnTServers("ysql_cron_database_name", db_name);
+  cluster_->Shutdown(ExternalMiniCluster::NodeSelectionMode::TS_ONLY);
+  ASSERT_OK(cluster_->Restart());
+  conn_ = std::make_unique<pgwrapper::PGConn>(ASSERT_RESULT(cluster_->ConnectToDB()));
+  auto new_db_conn = ASSERT_RESULT(cluster_->ConnectToDB(db_name));
+
+  auto old_db_row_count = ASSERT_RESULT(GetRowCount());
+
+  ASSERT_OK(CreateCronExtension(&new_db_conn));
+  ASSERT_OK(CreateTable(&new_db_conn));
+  auto job_id = ASSERT_RESULT(Schedule1SecInsertJob(&new_db_conn));
+
+  SleepFor(sleep_time);
+  auto new_db_row_count1 = ASSERT_RESULT(GetRowCount(&new_db_conn));
+  ASSERT_GT(new_db_row_count1, 0);
+
+  // Make sure no new jobs are run on the old db.
+  auto old_db_row_count2 = ASSERT_RESULT(GetRowCount());
+  ASSERT_EQ(old_db_row_count2, old_db_row_count);
+
+  ASSERT_OK(UnscheduleJob(job_id, &new_db_conn));
+
+  // Wait a little bit longer to make sure job is not running.
+  SleepFor(sleep_time);
+  auto new_db_row_count2 = ASSERT_RESULT(GetRowCount(&new_db_conn));
+
+  // Make sure it was cron from the new DB that inserted all the rows.
+  auto new_db_job_run_count = ASSERT_RESULT(
+      new_db_conn.FetchRow<pgwrapper::PGUint64>("SELECT COUNT(*) FROM cron.job_run_details"));
+  // May not be equal as some run might have failed midway.
+  ASSERT_LE(new_db_row_count2, new_db_job_run_count);
+}
 
 }  // namespace yb
diff --git a/src/yb/master/catalog_manager.cc b/src/yb/master/catalog_manager.cc
index 7b7dd01b9a..9d754fc560 100644
--- a/src/yb/master/catalog_manager.cc
+++ b/src/yb/master/catalog_manager.cc
@@ -604,6 +604,8 @@ TAG_FLAG(initial_tserver_registration_duration_secs, advanced);
 
 DECLARE_bool(ysql_yb_enable_replica_identity);
 
+DECLARE_bool(enable_pg_cron);
+
 namespace yb {
 namespace master {
 
@@ -879,6 +881,11 @@ IndexStatusPB::BackfillStatus GetBackfillStatus(const IndexInfoPB& index) {
                                        : IndexStatusPB::BACKFILL_UNKNOWN;
 }
 
+bool IsPgCronJobTable(const CreateTableRequestPB& req) {
+  return req.has_schema() && req.schema().has_pgschema_name() &&
+         req.schema().pgschema_name() == "cron" && req.name() == "job";
+}
+
 }  // anonymous namespace
 
 ////////////////////////////////////////////////////////////
@@ -4256,6 +4263,10 @@ Status CatalogManager::CreateTable(const CreateTableRequestPB* orig_req,
     }
   }
 
+  if (FLAGS_enable_pg_cron && IsPgCronJobTable(req)) {
+    RETURN_NOT_OK(CreatePgCronService(epoch));
+  }
+
   s = sys_catalog_->Upsert(epoch, table, tablets);
   if (PREDICT_FALSE(!s.ok())) {
     return AbortTableCreation(
@@ -5091,6 +5102,30 @@ Status CatalogManager::CreatePgAutoAnalyzeService(const LeaderEpoch& epoch) {
   return Status::OK();
 }
 
+Status CatalogManager::CreatePgCronService(const LeaderEpoch& epoch) {
+  if (pg_cron_service_created_) {
+    return Status::OK();
+  }
+
+  // Use a generic schema that can be extended later on.
+  client::YBSchemaBuilder schema_builder;
+  schema_builder.AddColumn("id")->HashPrimaryKey()->Type(DataType::INT64);
+  schema_builder.AddColumn("data")->Type(DataType::JSONB);
+
+  client::YBSchema yb_schema;
+  CHECK_OK(schema_builder.Build(&yb_schema));
+
+  auto s = CreateStatefulService(StatefulServiceKind::PG_CRON_LEADER, yb_schema, epoch);
+  // It is possible that the table was already created. If so, there is nothing to do so we just
+  // ignore the "AlreadyPresent" error.
+  if (!s.ok() && !s.IsAlreadyPresent()) {
+    return s;
+  }
+
+  pg_cron_service_created_ = true;
+  return Status::OK();
+}
+
 namespace {
 
 TableIdentifierPB GetTransactionStatusTableId() {
diff --git a/src/yb/master/catalog_manager.h b/src/yb/master/catalog_manager.h
index d0ee044f18..30b5510776 100644
--- a/src/yb/master/catalog_manager.h
+++ b/src/yb/master/catalog_manager.h
@@ -332,6 +332,8 @@ class CatalogManager : public tserver::TabletPeerLookupIf,
 
   Status CreatePgAutoAnalyzeService(const LeaderEpoch& epoch);
 
+  Status CreatePgCronService(const LeaderEpoch& epoch);
+
   // Get the information about an in-progress create operation.
   Status IsCreateTableDone(const IsCreateTableDoneRequestPB* req,
                            IsCreateTableDoneResponsePB* resp) override;
@@ -3273,6 +3275,7 @@ class CatalogManager : public tserver::TabletPeerLookupIf,
           GUARDED_BY(xcluster_consumer_replication_error_map_mutex_);
 
   std::atomic<bool> xcluster_auto_flags_revalidation_needed_{true};
+  std::atomic<bool> pg_cron_service_created_{false};
 
   DISALLOW_COPY_AND_ASSIGN(CatalogManager);
 };
diff --git a/src/yb/tserver/CMakeLists.txt b/src/yb/tserver/CMakeLists.txt
index 4efa24b594..12ebafb4f4 100644
--- a/src/yb/tserver/CMakeLists.txt
+++ b/src/yb/tserver/CMakeLists.txt
@@ -245,6 +245,7 @@ set(TSERVER_SRCS
   tserver_metrics_heartbeat_data_provider.cc
   server_main_util.cc
   stateful_services/pg_auto_analyze_service.cc
+  stateful_services/pg_cron_leader_service.cc
   stateful_services/stateful_service_base.cc
   stateful_services/test_echo_service.cc
   xcluster_async_executor.cc
diff --git a/src/yb/tserver/stateful_services/pg_cron_leader_service.cc b/src/yb/tserver/stateful_services/pg_cron_leader_service.cc
new file mode 100644
index 0000000000..4b75303c5a
--- /dev/null
+++ b/src/yb/tserver/stateful_services/pg_cron_leader_service.cc
@@ -0,0 +1,128 @@
+// Copyright (c) YugaByte, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
+// in compliance with the License.  You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software distributed under the License
+// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+// or implied.  See the License for the specific language governing permissions and limitations
+// under the License.
+//
+
+#include "yb/tserver/stateful_services/pg_cron_leader_service.h"
+
+DECLARE_bool(enable_pg_cron);
+
+DEFINE_RUNTIME_uint32(pg_cron_leader_lease_sec, 60,
+    "The time in seconds to hold the pg_cron leader lease.");
+
+DEFINE_RUNTIME_uint32(pg_cron_leadership_refresh_sec, 10,
+    "Frequency at which the leadership is revalidated. This should be less than "
+    "pg_cron_leader_lease_sec");
+
+DECLARE_uint64(max_clock_skew_usec);
+
+namespace {
+void ValidateLeadershipRefreshSec() {
+  LOG_IF(FATAL, FLAGS_pg_cron_leadership_refresh_sec >= FLAGS_pg_cron_leader_lease_sec)
+      << "Invalid value " << FLAGS_pg_cron_leadership_refresh_sec
+      << " for 'pg_cron_leadership_refresh_sec'. Value should be less than "
+         "pg_cron_leader_lease_sec "
+      << FLAGS_pg_cron_leader_lease_sec;
+}
+}  // namespace
+
+REGISTER_CALLBACK(pg_cron_leadership_refresh_sec, "pg_cron_leadership_refresh_sec",
+    ValidateLeadershipRefreshSec)
+
+namespace yb {
+namespace stateful_service {
+
+PgCronLeaderService::PgCronLeaderService(
+    std::function<void(MonoTime)> set_cron_leader_lease_fn,
+    const std::shared_future<client::YBClient*>& client_future)
+    : StatefulServiceBase(StatefulServiceKind::PG_CRON_LEADER, client_future),
+      set_cron_leader_lease_fn_(std::move(set_cron_leader_lease_fn)) {}
+
+void PgCronLeaderService::Activate() {
+  if (!FLAGS_enable_pg_cron) {
+    return;
+  }
+
+  LOG_WITH_FUNC(INFO) << "Activated";
+
+  auto leader_term = GetLeaderTerm();
+
+  std::lock_guard lock(mutex_);
+  DCHECK(!leader_activate_time_.Initialized());
+
+  if (leader_term.ok()) {
+    if (*leader_term == 1) {
+      VLOG_WITH_FUNC(1) << "Leader for term 1. Activating immediately";
+      leader_activate_time_ = MonoTime::Min();
+    } else {
+      leader_activate_time_ =
+          MonoTime::Now() + MonoDelta::FromMicroseconds(
+                                FLAGS_pg_cron_leader_lease_sec + 2 * FLAGS_max_clock_skew_usec);
+      LOG_WITH_FUNC(INFO) << "Waiting until " << leader_activate_time_.ToFormattedString()
+                          << " for lease of the old leader to expire";
+    }
+  } else {
+    LOG_WITH_FUNC(INFO) << "Lost leadership before activation " << leader_term.status();
+  }
+}
+
+void PgCronLeaderService::Deactivate() {
+  std::lock_guard lock(mutex_);
+  // Break the lease immediately. This is best effort but still safe since new leader will not
+  // activate until the old leader lease has fully expired.
+  set_cron_leader_lease_fn_(MonoTime::kUninitialized);
+  leader_activate_time_ = MonoTime::kUninitialized;
+
+  LOG_WITH_FUNC(INFO) << "Deactivated";
+}
+
+uint32 PgCronLeaderService::PeriodicTaskIntervalMs() const {
+  return FLAGS_pg_cron_leadership_refresh_sec * MonoTime::kMillisecondsPerSecond;
+}
+
+Result<bool> PgCronLeaderService::RunPeriodicTask() {
+  RefreshLeaderLease();
+  return true;
+}
+
+void PgCronLeaderService::RefreshLeaderLease() {
+  // We could can lose the leadership at any time, so the sequence is important here.
+  // Get the time, and then check if we are still the leader. If we are, then use the fetched time
+  // to refresh the lease.
+  const auto now = MonoTime::Now();
+
+  auto leader_term = GetLeaderTerm();
+  if (!leader_term.ok()) {
+    LOG_WITH_FUNC(INFO) << "Not refreshing the lease since we failed to get a valid leader term: "
+                        << leader_term.status();
+    // If we really lost leadership, then Deactivate will get called.
+    return;
+  }
+
+  SharedLock lock(mutex_);
+  if (!leader_activate_time_.Initialized()) {
+    LOG(DFATAL) << "Leader activate time not initialized.";
+    return;
+  }
+
+  if (now < leader_activate_time_) {
+    // Not yet time to set the lease.
+    return;
+  }
+
+  // We are the leader. Renew the lease.
+  const auto lease_end = now + MonoDelta::FromSeconds(FLAGS_pg_cron_leader_lease_sec);
+  VLOG_WITH_FUNC(1) << "Setting leader lease to " << lease_end.ToFormattedString();
+  set_cron_leader_lease_fn_(lease_end);
+}
+
+}  // namespace stateful_service
+}  // namespace yb
diff --git a/src/yb/tserver/stateful_services/pg_cron_leader_service.h b/src/yb/tserver/stateful_services/pg_cron_leader_service.h
new file mode 100644
index 0000000000..72bd58cc6c
--- /dev/null
+++ b/src/yb/tserver/stateful_services/pg_cron_leader_service.h
@@ -0,0 +1,46 @@
+// Copyright (c) YugaByte, Inc.
+//
+// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except
+// in compliance with the License.  You may obtain a copy of the License at
+//
+// http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software distributed under the License
+// is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
+// or implied.  See the License for the specific language governing permissions and limitations
+// under the License.
+//
+
+#pragma once
+
+#include <shared_mutex>
+
+#include "yb/tserver/stateful_services/stateful_service_base.h"
+
+namespace yb {
+namespace stateful_service {
+class PgCronLeaderService : public StatefulServiceBase {
+ public:
+  PgCronLeaderService(
+      std::function<void(MonoTime)> set_cron_leader_lease_fn,
+      const std::shared_future<client::YBClient*>& client_future);
+
+ protected:
+  void Activate() override;
+  void Deactivate() override;
+  uint32 PeriodicTaskIntervalMs() const override;
+  Result<bool> RunPeriodicTask() override EXCLUDES(mutex_);
+  void DrainForDeactivation() override {}
+
+ private:
+  void RefreshLeaderLease() EXCLUDES(mutex_);
+
+  std::function<void(MonoTime)> set_cron_leader_lease_fn_;
+
+  std::shared_mutex mutex_;
+  // The time from which the leader can be active.
+  MonoTime leader_activate_time_ GUARDED_BY(mutex_) = MonoTime::kUninitialized;
+};
+
+}  // namespace stateful_service
+}  // namespace yb
diff --git a/src/yb/tserver/tablet_server.cc b/src/yb/tserver/tablet_server.cc
index 7a3ad66fa8..8e5143048e 100644
--- a/src/yb/tserver/tablet_server.cc
+++ b/src/yb/tserver/tablet_server.cc
@@ -82,6 +82,7 @@
 #include "yb/tserver/metrics_snapshotter.h"
 #include "yb/tserver/pg_client_service.h"
 #include "yb/tserver/remote_bootstrap_service.h"
+#include "yb/tserver/stateful_services/pg_cron_leader_service.h"
 #include "yb/tserver/tablet_service.h"
 #include "yb/tserver/pg_table_mutation_count_sender.h"
 #include "yb/tserver/ts_tablet_manager.h"
@@ -230,8 +231,7 @@ DEFINE_RUNTIME_uint32(ysql_min_new_version_ignored_count, 10,
     "Minimum consecutive number of times that a tserver is allowed to ignore an older catalog "
     "version that is retrieved from a tserver-master heartbeat response.");
 
-DEFINE_test_flag(
-    bool, is_ysql_cron_leader, false, "Make the current node run as the pg_cron leader");
+DECLARE_bool(enable_pg_cron);
 
 namespace yb::tserver {
 
@@ -516,12 +516,6 @@ Status TabletServer::Init() {
 
   shared_object().SetTserverUuid(fs_manager()->uuid());
 
-  TEST_is_cron_leader_callback_ = VERIFY_RESULT(
-      RegisterFlagUpdateCallback(&FLAGS_TEST_is_ysql_cron_leader, "is_ysql_cron_leader", [this] {
-        LOG(INFO) << "Setting the current node as the pg_cron leader";
-        TEST_SetIsCronLeader(FLAGS_TEST_is_ysql_cron_leader);
-      }));
-
   return Status::OK();
 }
 
@@ -644,6 +638,14 @@ Status TabletServer::RegisterServices() {
   RETURN_NOT_OK(RegisterService(
       FLAGS_TEST_echo_svc_queue_length, std::move(pg_auto_analyze_service)));
 
+  if (FLAGS_enable_pg_cron) {
+    pg_cron_leader_service_ = std::make_unique<stateful_service::PgCronLeaderService>(
+        std::bind(&TabletServer::SetCronLeaderLease, this, _1), client_future());
+    LOG(INFO) << "yb::tserver::stateful_service::PgCronLeaderService created at "
+              << pg_cron_leader_service_.get();
+    RETURN_NOT_OK(pg_cron_leader_service_->Init(tablet_manager_.get()));
+  }
+
   return Status::OK();
 }
 
@@ -679,7 +681,9 @@ void TabletServer::Shutdown() {
 
   bool expected = true;
   if (initted_.compare_exchange_strong(expected, false, std::memory_order_acq_rel)) {
-    TEST_is_cron_leader_callback_.Deregister();
+    if (pg_cron_leader_service_) {
+      pg_cron_leader_service_->Shutdown();
+    }
 
     auto xcluster_consumer = GetXClusterConsumer();
     if (xcluster_consumer) {
@@ -1461,8 +1465,8 @@ Result<std::vector<tablet::TabletStatusPB>> TabletServer::GetLocalTabletsMetadat
   return result;
 }
 
-void TabletServer::TEST_SetIsCronLeader(bool is_cron_leader) {
-  SharedObject().SetIsCronLeader(is_cron_leader);
+void TabletServer::SetCronLeaderLease(MonoTime cron_leader_lease_end) {
+  SharedObject().SetCronLeaderLease(cron_leader_lease_end);
 }
 
 }  // namespace yb::tserver
diff --git a/src/yb/tserver/tablet_server.h b/src/yb/tserver/tablet_server.h
index bcc7908ce5..3d869f242e 100644
--- a/src/yb/tserver/tablet_server.h
+++ b/src/yb/tserver/tablet_server.h
@@ -90,6 +90,10 @@ class CDCServiceImpl;
 
 }
 
+namespace stateful_service {
+class PgCronLeaderService;
+}  // namespace stateful_service
+
 namespace tserver {
 
 class TserverAutoFlagsManager;
@@ -378,6 +382,8 @@ class TabletServer : public DbServerBase, public TabletServerIf {
 
   Result<std::unordered_set<std::string>> GetAvailableAutoFlagsForServer() const override;
 
+  void SetCronLeaderLease(MonoTime cron_leader_lease_end);
+
   std::atomic<bool> initted_{false};
 
   // If true, all heartbeats will be seen as failed.
@@ -503,7 +509,7 @@ class TabletServer : public DbServerBase, public TabletServerIf {
   std::atomic<yb::server::RpcAndWebServerBase*> cql_server_{nullptr};
   std::atomic<yb::server::YCQLStatementStatsProvider*> cql_stmt_provider_{nullptr};
 
-  FlagCallbackRegistration TEST_is_cron_leader_callback_;
+  std::unique_ptr<stateful_service::PgCronLeaderService> pg_cron_leader_service_;
 
   DISALLOW_COPY_AND_ASSIGN(TabletServer);
 };
diff --git a/src/yb/tserver/tserver_shared_mem.cc b/src/yb/tserver/tserver_shared_mem.cc
index 043db95325..4bbd1677df 100644
--- a/src/yb/tserver/tserver_shared_mem.cc
+++ b/src/yb/tserver/tserver_shared_mem.cc
@@ -449,4 +449,9 @@ SharedExchangeThread::~SharedExchangeThread() {
   thread_->Join();
 }
 
+bool TServerSharedData::IsCronLeader() const {
+  // We are the leader if we have a valid lease time that has not expired.
+  auto lease_end = cron_leader_lease_.load();
+  return lease_end.Initialized() && lease_end > MonoTime::Now();
+}
 } // namespace yb::tserver
diff --git a/src/yb/tserver/tserver_shared_mem.h b/src/yb/tserver/tserver_shared_mem.h
index ab7bf17495..cc81a8de6c 100644
--- a/src/yb/tserver/tserver_shared_mem.h
+++ b/src/yb/tserver/tserver_shared_mem.h
@@ -110,9 +110,11 @@ class TServerSharedData {
     return tserver_uuid_;
   }
 
-  void SetIsCronLeader(bool is_leader) { is_cron_leader_ = is_leader; }
+  void SetCronLeaderLease(MonoTime cron_leader_lease_end) {
+    cron_leader_lease_ = cron_leader_lease_end;
+  }
 
-  bool IsCronLeader() const { return is_cron_leader_; }
+  bool IsCronLeader() const;
 
  private:
   // Endpoint that should be used by local processes to access this tserver.
@@ -127,7 +129,7 @@ class TServerSharedData {
   // See same variable comments in CatalogManager.
   std::atomic<std::optional<bool>> catalog_version_table_in_perdb_mode_{std::nullopt};
 
-  bool is_cron_leader_ = false;
+  std::atomic<MonoTime> cron_leader_lease_{MonoTime::kUninitialized};
 };
 
 YB_STRONGLY_TYPED_BOOL(Create);
diff --git a/src/yb/yql/pgwrapper/pg_wrapper.cc b/src/yb/yql/pgwrapper/pg_wrapper.cc
index a5b0a88f18..efd5ba9f28 100644
--- a/src/yb/yql/pgwrapper/pg_wrapper.cc
+++ b/src/yb/yql/pgwrapper/pg_wrapper.cc
@@ -291,7 +291,10 @@ DEPRECATE_FLAG(int32, ysql_yb_ash_sampling_interval, "2024_03");
 DEFINE_RUNTIME_PG_FLAG(int32, yb_ash_sample_size, 500,
     "Number of samples captured from each component per sampling event");
 
-DEFINE_test_flag(bool, enable_pg_cron, false, "Enables the pg_cron extension");
+DEFINE_NON_RUNTIME_string(ysql_cron_database_name, "yugabyte",
+    "Database in which pg_cron metadata is kept.");
+
+DECLARE_bool(enable_pg_cron);
 
 using gflags::CommandLineFlagInfo;
 using std::string;
@@ -457,7 +460,7 @@ Result<string> WritePostgresConfig(const PgProcessConf& conf) {
   metricsLibs.push_back("pgaudit");
   metricsLibs.push_back("pg_hint_plan");
 
-  if (FLAGS_TEST_enable_pg_cron) {
+  if (FLAGS_enable_pg_cron) {
     metricsLibs.push_back("pg_cron");
   }
 
@@ -498,6 +501,9 @@ Result<string> WritePostgresConfig(const PgProcessConf& conf) {
     lines.push_back(Format("ssl_ca_file='$0/ca.crt'", conf.certs_for_client_dir));
   }
 
+  // Add cron.database_name
+  lines.push_back(Format("cron.database_name='$0'", FLAGS_ysql_cron_database_name));
+
   // Finally add gFlags.
   // If the file contains multiple entries for the same parameter, all but the last one are
   // ignored. If there are duplicates in FLAGS_ysql_pg_conf_csv then we want the values specified
