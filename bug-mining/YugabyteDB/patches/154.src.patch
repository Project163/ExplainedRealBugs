diff --git a/src/yb/integration-tests/snapshot-test.cc b/src/yb/integration-tests/snapshot-test.cc
index fe637580f2..5bf11b7f9d 100644
--- a/src/yb/integration-tests/snapshot-test.cc
+++ b/src/yb/integration-tests/snapshot-test.cc
@@ -33,6 +33,7 @@
 #include "yb/master/master_backup.proxy.h"
 #include "yb/master/master_cluster.proxy.h"
 #include "yb/master/master_ddl.proxy.h"
+#include "yb/master/master_snapshot_coordinator.h"
 #include "yb/master/master_types.pb.h"
 #include "yb/master/mini_master.h"
 
diff --git a/src/yb/integration-tests/xcluster/xcluster_db_scoped-test.cc b/src/yb/integration-tests/xcluster/xcluster_db_scoped-test.cc
index 4b0f703637..6506c28e7e 100644
--- a/src/yb/integration-tests/xcluster/xcluster_db_scoped-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_db_scoped-test.cc
@@ -72,19 +72,7 @@ class XClusterDBScopedTest : public XClusterYsqlTestBase {
   }
 };
 
-class XClusterDBScopedParameterized
-    : public XClusterDBScopedTest,
-      public ::testing::WithParamInterface<bool> {
- public:
-  bool UseAutomaticMode() override { return GetParam(); }
-};
-
-INSTANTIATE_TEST_CASE_P(
-    AutoMode, XClusterDBScopedParameterized, ::testing::Values(true));
-INSTANTIATE_TEST_CASE_P(
-    SemiMode, XClusterDBScopedParameterized, ::testing::Values(false));
-
-TEST_P(XClusterDBScopedParameterized, TestCreateWithCheckpoint) {
+TEST_F(XClusterDBScopedTest, TestCreateWithCheckpoint) {
   SetupParams param;
   param.num_producer_tablets = {};
   param.num_consumer_tablets = {};
@@ -254,7 +242,7 @@ TEST_F(XClusterDBScopedTest, DropTableOnProducerThenConsumer) {
 }
 
 // Test dropping all tables and then creating new tables.
-TEST_P(XClusterDBScopedParameterized, DropAllTables) {
+TEST_F(XClusterDBScopedTest, DropAllTables) {
   // Drop bg task timer to speed up test.
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_cdc_parent_tablet_deletion_task_retry_secs) = 1;
   // Setup replication with one table
@@ -474,26 +462,16 @@ class XClusterDBScopedTestWithTwoDBs : public XClusterDBScopedTest {
     return Status::OK();
   }
 
+  void TestAddRemoveNamespace();
+
   const NamespaceName namespace_name2_ = "db2";
   const TableName namespace2_table_name_ = "test_table";
   NamespaceId source_namespace2_id_, target_namespace2_id_;
   std::shared_ptr<client::YBTable> source_namespace2_table_, target_namespace2_table_;
 };
 
-class XClusterDBScopedTestWithTwoDBsParameterized
-    : public XClusterDBScopedTestWithTwoDBs,
-      public ::testing::WithParamInterface<bool> {
- public:
-  bool UseAutomaticMode() override { return GetParam(); }
-};
-
-INSTANTIATE_TEST_CASE_P(
-    AutoMode, XClusterDBScopedTestWithTwoDBsParameterized, ::testing::Values(true));
-INSTANTIATE_TEST_CASE_P(
-    SemiMode, XClusterDBScopedTestWithTwoDBsParameterized, ::testing::Values(false));
-
 // Testing adding and removing namespaces to replication.
-TEST_P(XClusterDBScopedTestWithTwoDBsParameterized, AddRemoveNamespace) {
+void XClusterDBScopedTestWithTwoDBs::TestAddRemoveNamespace() {
   ASSERT_OK(SetUpClusters());
   ASSERT_OK(CheckpointReplicationGroup());
   ASSERT_OK(CreateReplicationFromCheckpoint());
@@ -570,6 +548,19 @@ TEST_P(XClusterDBScopedTestWithTwoDBsParameterized, AddRemoveNamespace) {
   ASSERT_TRUE(bootstrap_required) << "Bootstrap should be required";
 }
 
+TEST_F(XClusterDBScopedTestWithTwoDBs, AddRemoveNamespace) {
+  ASSERT_NO_FATALS(TestAddRemoveNamespace());
+}
+
+class XClusterDBScopedTestWithTwoDBsAutomaticDDLMode : public XClusterDBScopedTestWithTwoDBs {
+ public:
+  bool UseAutomaticMode() override { return true; }
+};
+
+TEST_F(XClusterDBScopedTestWithTwoDBsAutomaticDDLMode, AddRemoveNamespace) {
+  ASSERT_NO_FATALS(TestAddRemoveNamespace());
+}
+
 // Remove a namespaces from replication when the target side is down.
 TEST_F_EX(XClusterDBScopedTest, RemoveNamespaceWhenTargetIsDown, XClusterDBScopedTestWithTwoDBs) {
   // Setup replication with both databases.
@@ -789,128 +780,130 @@ TEST_F(XClusterDBScopedTest, DeleteWhenSourceIsDown) {
   ASSERT_NOK_STR_CONTAINS(GetAllXClusterStreams(source_namespace_id), "Not found");
 }
 
-// Validate that we can only have one inbound replication group per database.
-TEST_F(XClusterDBScopedTest, MultipleInboundReplications) {
-  ASSERT_OK(SetUpClusters());
-  ASSERT_OK(CheckpointReplicationGroup());
-  ASSERT_OK(CreateReplicationFromCheckpoint());
+  // Validate that we can only have one inbound replication group per database.
+  TEST_F(XClusterDBScopedTest, MultipleInboundReplications) {
+    ASSERT_OK(SetUpClusters());
+    ASSERT_OK(CheckpointReplicationGroup());
+    ASSERT_OK(CreateReplicationFromCheckpoint());
 
-  auto group2 = xcluster::ReplicationGroupId("group2");
+    auto group2 = xcluster::ReplicationGroupId("group2");
 
-  ASSERT_OK(CheckpointReplicationGroup(group2));
-  ASSERT_NOK_STR_CONTAINS(
-      CreateReplicationFromCheckpoint(/*target_master_addresses=*/"", group2),
-      "already included in replication group");
-}
-
-TEST_F_EX(XClusterDBScopedTest, TestYbAdmin, XClusterDBScopedTestWithTwoDBs) {
-  // TODO: replace this once there is a way to use automatic mode with ybadmin.
-  ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_force_automatic_ddl_replication_mode) = UseAutomaticMode();
-
-  ASSERT_OK(SetUpClusters());
-
-  // Create replication with 1 db.
-  auto result = ASSERT_RESULT(CallAdmin(
-      producer_cluster(), "create_xcluster_checkpoint", kReplicationGroupId, namespace_name));
-  ASSERT_STR_CONTAINS(result, "Bootstrap is not required");
-
-  result = ASSERT_RESULT(CallAdmin(
-      producer_cluster(), "is_xcluster_bootstrap_required", kReplicationGroupId, namespace_name));
-  ASSERT_STR_CONTAINS(result, "Bootstrap is not required");
-
-  const auto target_master_address = consumer_cluster()->GetMasterAddresses();
-  ASSERT_OK(CallAdmin(
-      producer_cluster(), "setup_xcluster_replication", kReplicationGroupId,
-      target_master_address));
-
-  result =
-      ASSERT_RESULT(CallAdmin(producer_cluster(), "list_xcluster_outbound_replication_groups"));
-  ASSERT_STR_CONTAINS(result, kReplicationGroupId.ToString());
-  const auto source_namespace_id = producer_table_->name().namespace_id();
-  result = ASSERT_RESULT(CallAdmin(
-      producer_cluster(), "list_xcluster_outbound_replication_groups", source_namespace_id));
-  ASSERT_STR_CONTAINS(result, kReplicationGroupId.ToString());
-  result = ASSERT_RESULT(CallAdmin(
-      producer_cluster(), "get_xcluster_outbound_replication_group_info",
-      kReplicationGroupId.ToString()));
-  ASSERT_STR_CONTAINS(result, source_namespace_id);
-  ASSERT_STR_CONTAINS(result, producer_table_->id());
-  ASSERT_STR_NOT_CONTAINS(result, source_namespace2_id_);
-  ASSERT_STR_NOT_CONTAINS(result, source_namespace2_table_->id());
-
-  // Test target side commands.
-  const auto target_namespace_id = consumer_table_->name().namespace_id();
-  result = ASSERT_RESULT(CallAdmin(consumer_cluster(), "list_universe_replications", "na"));
-  ASSERT_STR_NOT_CONTAINS(result, kReplicationGroupId.ToString());
-  result = ASSERT_RESULT(
-      CallAdmin(consumer_cluster(), "list_universe_replications", target_namespace2_id_));
-  ASSERT_STR_NOT_CONTAINS(result, kReplicationGroupId.ToString());
-  result = ASSERT_RESULT(
-      CallAdmin(consumer_cluster(), "list_universe_replications", target_namespace_id));
-  ASSERT_STR_CONTAINS(result, kReplicationGroupId.ToString());
-  result = ASSERT_RESULT(CallAdmin(
-      consumer_cluster(), "get_universe_replication_info", kReplicationGroupId.ToString()));
-  ASSERT_STR_CONTAINS(result, xcluster::ShortReplicationType(XCLUSTER_YSQL_DB_SCOPED));
-  ASSERT_STR_CONTAINS(result, namespace_name);
-  ASSERT_STR_CONTAINS(result, target_namespace_id);
-  ASSERT_STR_CONTAINS(result, source_namespace_id);
-  ASSERT_STR_NOT_CONTAINS(result, target_namespace2_id_);
-
-  ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
-
-  ASSERT_OK(InsertRowsInProducer(0, 10));
-  ASSERT_OK(VerifyWrittenRecords());
-
-  // Add second db to replication.
-  result = ASSERT_RESULT(CallAdmin(
-      producer_cluster(), "add_namespace_to_xcluster_checkpoint", kReplicationGroupId,
-      namespace_name2_));
-  ASSERT_STR_CONTAINS(result, "Bootstrap is not required");
-
-  ASSERT_OK(CallAdmin(
-      producer_cluster(), "add_namespace_to_xcluster_replication", kReplicationGroupId,
-      namespace_name2_, target_master_address));
-
-  result = ASSERT_RESULT(CallAdmin(
-      producer_cluster(), "get_xcluster_outbound_replication_group_info",
-      kReplicationGroupId.ToString()));
-  ASSERT_STR_CONTAINS(result, namespace_name);
-  ASSERT_STR_CONTAINS(result, producer_table_->id());
-  ASSERT_STR_CONTAINS(result, namespace_name2_);
-  ASSERT_STR_CONTAINS(result, source_namespace2_table_->id());
-
-  // Remove database from both sides with one command.
-  ASSERT_OK(CallAdmin(
-      producer_cluster(), "remove_namespace_from_xcluster_replication", kReplicationGroupId,
-      namespace_name2_, target_master_address));
-
-  // Remove database from replication from each cluster individually.
-  ASSERT_OK(CallAdmin(
-      producer_cluster(), "add_namespace_to_xcluster_checkpoint", kReplicationGroupId,
-      namespace_name2_));
-  ASSERT_OK(CallAdmin(
-      producer_cluster(), "add_namespace_to_xcluster_replication", kReplicationGroupId,
-      namespace_name2_, target_master_address));
-  ASSERT_OK(CallAdmin(
-      consumer_cluster(), "alter_universe_replication", kReplicationGroupId, "remove_namespace",
-      namespace_name2_));
-  ASSERT_OK(CallAdmin(
-      producer_cluster(), "remove_namespace_from_xcluster_replication", kReplicationGroupId,
-      namespace_name2_));
-
-  // Drop replication on both sides.
-  ASSERT_OK(CallAdmin(
-      producer_cluster(), "drop_xcluster_replication", kReplicationGroupId, target_master_address));
-
-  master::GetUniverseReplicationResponsePB resp;
-  ASSERT_NOK_STR_CONTAINS(
-      VerifyUniverseReplication(&resp), "Could not find xCluster replication group");
-
-  ASSERT_NOK_STR_CONTAINS(GetAllXClusterStreams(source_namespace_id), "Not found");
+    ASSERT_OK(CheckpointReplicationGroup(group2));
+    ASSERT_NOK_STR_CONTAINS(
+        CreateReplicationFromCheckpoint(/*target_master_addresses=*/"", group2),
+        "already included in replication group");
+  }
 
-  result = ASSERT_RESULT(CallAdmin(
-      producer_cluster(), "create_xcluster_checkpoint", kReplicationGroupId, namespace_name));
-  ASSERT_STR_CONTAINS(result, "Bootstrap is required");
-}
+  TEST_F_EX(XClusterDBScopedTest, TestYbAdmin, XClusterDBScopedTestWithTwoDBs) {
+    // TODO: replace this once there is a way to use automatic mode with ybadmin.
+    ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_force_automatic_ddl_replication_mode) =
+        UseAutomaticMode();
+
+    ASSERT_OK(SetUpClusters());
+
+    // Create replication with 1 db.
+    auto result = ASSERT_RESULT(CallAdmin(
+        producer_cluster(), "create_xcluster_checkpoint", kReplicationGroupId, namespace_name));
+    ASSERT_STR_CONTAINS(result, "Bootstrap is not required");
+
+    result = ASSERT_RESULT(CallAdmin(
+        producer_cluster(), "is_xcluster_bootstrap_required", kReplicationGroupId, namespace_name));
+    ASSERT_STR_CONTAINS(result, "Bootstrap is not required");
+
+    const auto target_master_address = consumer_cluster()->GetMasterAddresses();
+    ASSERT_OK(CallAdmin(
+        producer_cluster(), "setup_xcluster_replication", kReplicationGroupId,
+        target_master_address));
+
+    result =
+        ASSERT_RESULT(CallAdmin(producer_cluster(), "list_xcluster_outbound_replication_groups"));
+    ASSERT_STR_CONTAINS(result, kReplicationGroupId.ToString());
+    const auto source_namespace_id = producer_table_->name().namespace_id();
+    result = ASSERT_RESULT(CallAdmin(
+        producer_cluster(), "list_xcluster_outbound_replication_groups", source_namespace_id));
+    ASSERT_STR_CONTAINS(result, kReplicationGroupId.ToString());
+    result = ASSERT_RESULT(CallAdmin(
+        producer_cluster(), "get_xcluster_outbound_replication_group_info",
+        kReplicationGroupId.ToString()));
+    ASSERT_STR_CONTAINS(result, source_namespace_id);
+    ASSERT_STR_CONTAINS(result, producer_table_->id());
+    ASSERT_STR_NOT_CONTAINS(result, source_namespace2_id_);
+    ASSERT_STR_NOT_CONTAINS(result, source_namespace2_table_->id());
+
+    // Test target side commands.
+    const auto target_namespace_id = consumer_table_->name().namespace_id();
+    result = ASSERT_RESULT(CallAdmin(consumer_cluster(), "list_universe_replications", "na"));
+    ASSERT_STR_NOT_CONTAINS(result, kReplicationGroupId.ToString());
+    result = ASSERT_RESULT(
+        CallAdmin(consumer_cluster(), "list_universe_replications", target_namespace2_id_));
+    ASSERT_STR_NOT_CONTAINS(result, kReplicationGroupId.ToString());
+    result = ASSERT_RESULT(
+        CallAdmin(consumer_cluster(), "list_universe_replications", target_namespace_id));
+    ASSERT_STR_CONTAINS(result, kReplicationGroupId.ToString());
+    result = ASSERT_RESULT(CallAdmin(
+        consumer_cluster(), "get_universe_replication_info", kReplicationGroupId.ToString()));
+    ASSERT_STR_CONTAINS(result, xcluster::ShortReplicationType(XCLUSTER_YSQL_DB_SCOPED));
+    ASSERT_STR_CONTAINS(result, namespace_name);
+    ASSERT_STR_CONTAINS(result, target_namespace_id);
+    ASSERT_STR_CONTAINS(result, source_namespace_id);
+    ASSERT_STR_NOT_CONTAINS(result, target_namespace2_id_);
+
+    ASSERT_OK(WaitForSafeTimeToAdvanceToNow());
+
+    ASSERT_OK(InsertRowsInProducer(0, 10));
+    ASSERT_OK(VerifyWrittenRecords());
+
+    // Add second db to replication.
+    result = ASSERT_RESULT(CallAdmin(
+        producer_cluster(), "add_namespace_to_xcluster_checkpoint", kReplicationGroupId,
+        namespace_name2_));
+    ASSERT_STR_CONTAINS(result, "Bootstrap is not required");
+
+    ASSERT_OK(CallAdmin(
+        producer_cluster(), "add_namespace_to_xcluster_replication", kReplicationGroupId,
+        namespace_name2_, target_master_address));
+
+    result = ASSERT_RESULT(CallAdmin(
+        producer_cluster(), "get_xcluster_outbound_replication_group_info",
+        kReplicationGroupId.ToString()));
+    ASSERT_STR_CONTAINS(result, namespace_name);
+    ASSERT_STR_CONTAINS(result, producer_table_->id());
+    ASSERT_STR_CONTAINS(result, namespace_name2_);
+    ASSERT_STR_CONTAINS(result, source_namespace2_table_->id());
+
+    // Remove database from both sides with one command.
+    ASSERT_OK(CallAdmin(
+        producer_cluster(), "remove_namespace_from_xcluster_replication", kReplicationGroupId,
+        namespace_name2_, target_master_address));
+
+    // Remove database from replication from each cluster individually.
+    ASSERT_OK(CallAdmin(
+        producer_cluster(), "add_namespace_to_xcluster_checkpoint", kReplicationGroupId,
+        namespace_name2_));
+    ASSERT_OK(CallAdmin(
+        producer_cluster(), "add_namespace_to_xcluster_replication", kReplicationGroupId,
+        namespace_name2_, target_master_address));
+    ASSERT_OK(CallAdmin(
+        consumer_cluster(), "alter_universe_replication", kReplicationGroupId, "remove_namespace",
+        namespace_name2_));
+    ASSERT_OK(CallAdmin(
+        producer_cluster(), "remove_namespace_from_xcluster_replication", kReplicationGroupId,
+        namespace_name2_));
+
+    // Drop replication on both sides.
+    ASSERT_OK(CallAdmin(
+        producer_cluster(), "drop_xcluster_replication", kReplicationGroupId,
+        target_master_address));
+
+    master::GetUniverseReplicationResponsePB resp;
+    ASSERT_NOK_STR_CONTAINS(
+        VerifyUniverseReplication(&resp), "Could not find xCluster replication group");
+
+    ASSERT_NOK_STR_CONTAINS(GetAllXClusterStreams(source_namespace_id), "Not found");
+
+    result = ASSERT_RESULT(CallAdmin(
+        producer_cluster(), "create_xcluster_checkpoint", kReplicationGroupId, namespace_name));
+    ASSERT_STR_CONTAINS(result, "Bootstrap is required");
+  }
 
 }  // namespace yb
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
index 856185999e..08b4eeb5aa 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication-test.cc
@@ -12,11 +12,13 @@
 //
 
 #include "yb/cdc/xcluster_types.h"
+#include "yb/client/table.h"
 #include "yb/client/yb_table_name.h"
 #include "yb/common/colocated_util.h"
 #include "yb/common/common_types.pb.h"
 #include "yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.h"
 #include "yb/integration-tests/xcluster/xcluster_test_base.h"
+#include "yb/master/catalog_manager.h"
 #include "yb/master/mini_master.h"
 #include "yb/util/tsan_util.h"
 
@@ -33,10 +35,46 @@ const MonoDelta kTimeout = 60s * kTimeMultiplier;
 
 class XClusterDDLReplicationTest : public XClusterDDLReplicationTestBase {};
 
+// In automatic mode, sequences_data should have been created on both universe.
+TEST_F(XClusterDDLReplicationTest, CheckSequenceDataTable) {
+  ASSERT_OK(SetUpClusters());
+  ASSERT_OK(CheckpointReplicationGroup());
+  ASSERT_OK(CreateReplicationFromCheckpoint());
+
+  ASSERT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
+    auto table_info = VERIFY_RESULT(cluster->mini_cluster_->GetLeaderMiniMaster())
+                          ->catalog_manager_impl()
+                          .GetTableInfo(kPgSequencesDataTableId);
+    SCHECK_NOTNULL(table_info);
+    return Status::OK();
+  }));
+}
+
+TEST_F(XClusterDDLReplicationTest, CheckExtensionTableTabletCount) {
+  ASSERT_OK(SetUpClusters());
+  ASSERT_OK(CheckpointReplicationGroup());
+  ASSERT_OK(CreateReplicationFromCheckpoint());
+
+  // Ensure that tables are properly created with only one tablet each.
+  ASSERT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
+    for (const auto& table_name :
+         {xcluster::kDDLQueueTableName, xcluster::kDDLReplicatedTableName}) {
+      auto yb_table_name = VERIFY_RESULT(
+          GetYsqlTable(cluster, namespace_name, xcluster::kDDLQueuePgSchemaName, table_name));
+      std::shared_ptr<client::YBTable> table;
+      RETURN_NOT_OK(cluster->client_->OpenTable(yb_table_name, &table));
+      SCHECK_EQ(table->GetPartitionCount(), 1, IllegalState, "Expected 1 tablet");
+    }
+    return Status::OK();
+  }));
+}
+
 TEST_F(XClusterDDLReplicationTest, DisableSplitting) {
   // Ensure that splitting of xCluster DDL Replication tables is disabled on both sides.
   ASSERT_OK(SetUpClusters());
-  ASSERT_OK(EnableDDLReplicationExtension());
+
+  ASSERT_OK(CheckpointReplicationGroup());
+  ASSERT_OK(CreateReplicationFromCheckpoint());
 
   for (auto* cluster : {&producer_cluster_, &consumer_cluster_}) {
     for (const auto& table : {xcluster::kDDLQueueTableName, xcluster::kDDLReplicatedTableName}) {
@@ -56,8 +94,17 @@ TEST_F(XClusterDDLReplicationTest, DisableSplitting) {
 
 TEST_F(XClusterDDLReplicationTest, DDLReplicationTablesNotColocated) {
   // Ensure that xCluster DDL Replication system tables are not colocated.
+
   ASSERT_OK(SetUpClusters(/* is_colocated */ true));
-  ASSERT_OK(EnableDDLReplicationExtension());
+  // Create a colocated table so that we can run xCluster setup.
+  ASSERT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
+    RETURN_NOT_OK(CreateYsqlTable(
+        /*idx=*/1, /*num_tablets=*/1, cluster, /*tablegroup_name=*/{}, /*colocated=*/true));
+    return Status::OK();
+  }));
+
+  ASSERT_OK(CheckpointReplicationGroup());
+  ASSERT_OK(CreateReplicationFromCheckpoint());
 
   for (auto* cluster : {&producer_cluster_, &consumer_cluster_}) {
     for (const auto& table : {xcluster::kDDLQueueTableName, xcluster::kDDLReplicatedTableName}) {
@@ -75,7 +122,6 @@ TEST_F(XClusterDDLReplicationTest, DDLReplicationTablesNotColocated) {
 
 TEST_F(XClusterDDLReplicationTest, CreateTable) {
   ASSERT_OK(SetUpClusters());
-  ASSERT_OK(EnableDDLReplicationExtension());
   ASSERT_OK(CheckpointReplicationGroup());
   ASSERT_OK(CreateReplicationFromCheckpoint());
 
@@ -132,7 +178,6 @@ TEST_F(XClusterDDLReplicationTest, CreateTable) {
 
 TEST_F(XClusterDDLReplicationTest, BlockMultistatementQuery) {
   ASSERT_OK(SetUpClusters());
-  ASSERT_OK(EnableDDLReplicationExtension());
   ASSERT_OK(CheckpointReplicationGroup());
   ASSERT_OK(CreateReplicationFromCheckpoint());
 
@@ -171,7 +216,6 @@ TEST_F(XClusterDDLReplicationTest, BlockMultistatementQuery) {
 
 TEST_F(XClusterDDLReplicationTest, CreateIndex) {
   ASSERT_OK(SetUpClusters());
-  ASSERT_OK(EnableDDLReplicationExtension());
   ASSERT_OK(CheckpointReplicationGroup());
   ASSERT_OK(CreateReplicationFromCheckpoint());
 
@@ -234,7 +278,6 @@ TEST_F(XClusterDDLReplicationTest, ExactlyOnceReplication) {
   const int kNumTablets = 3;
 
   ASSERT_OK(SetUpClusters());
-  ASSERT_OK(EnableDDLReplicationExtension());
   ASSERT_OK(CheckpointReplicationGroup());
   ASSERT_OK(CreateReplicationFromCheckpoint());
 
@@ -279,7 +322,6 @@ TEST_F(XClusterDDLReplicationTest, DuplicateTableNames) {
 
   const int kNumTablets = 3;
   ASSERT_OK(SetUpClusters());
-  ASSERT_OK(EnableDDLReplicationExtension());
   ASSERT_OK(CheckpointReplicationGroup());
   ASSERT_OK(CreateReplicationFromCheckpoint());
 
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
index 635b43a34a..8406265143 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_pgregress-test.cc
@@ -77,7 +77,6 @@ class XClusterPgRegressDDLReplicationTest : public XClusterDDLReplicationTestBas
 
     // Setup xCluster.
     RETURN_NOT_OK(SetUpClusters());
-    RETURN_NOT_OK(EnableDDLReplicationExtension());
     RETURN_NOT_OK(CheckpointReplicationGroup());
     RETURN_NOT_OK(CreateReplicationFromCheckpoint());
 
diff --git a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.cc b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.cc
index 85d5771180..d36a24bf4b 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_ddl_replication_test_base.cc
@@ -52,34 +52,6 @@ Status XClusterDDLReplicationTestBase::SetUpClusters(bool is_colocated) {
   return XClusterYsqlTestBase::SetUpClusters(kDefaultParams);
 }
 
-Status XClusterDDLReplicationTestBase::EnableDDLReplicationExtension() {
-  // TODO(#19184): This will be done as part of creating the replication groups.
-  auto p_conn = VERIFY_RESULT(producer_cluster_.ConnectToDB(namespace_name));
-  RETURN_NOT_OK(p_conn.ExecuteFormat("CREATE EXTENSION $0", xcluster::kDDLQueuePgSchemaName));
-  RETURN_NOT_OK(p_conn.ExecuteFormat(
-      "ALTER DATABASE $0 SET $1.replication_role = SOURCE", namespace_name,
-      xcluster::kDDLQueuePgSchemaName));
-  auto c_conn = VERIFY_RESULT(consumer_cluster_.ConnectToDB(namespace_name));
-  RETURN_NOT_OK(c_conn.ExecuteFormat("CREATE EXTENSION $0", xcluster::kDDLQueuePgSchemaName));
-  RETURN_NOT_OK(c_conn.ExecuteFormat(
-      "ALTER DATABASE $0 SET $1.replication_role = TARGET", namespace_name,
-      xcluster::kDDLQueuePgSchemaName));
-
-  // Ensure that tables are properly created with only one tablet each.
-  RETURN_NOT_OK(RunOnBothClusters([&](Cluster* cluster) -> Status {
-    for (const auto& table_name :
-         {xcluster::kDDLQueueTableName, xcluster::kDDLReplicatedTableName}) {
-      auto yb_table_name = VERIFY_RESULT(
-          GetYsqlTable(cluster, namespace_name, xcluster::kDDLQueuePgSchemaName, table_name));
-      std::shared_ptr<client::YBTable> table;
-      RETURN_NOT_OK(cluster->client_->OpenTable(yb_table_name, &table));
-      SCHECK_EQ(table->GetPartitionCount(), 1, IllegalState, "Expected 1 tablet");
-    }
-    return Status::OK();
-  }));
-  return Status::OK();
-}
-
 Result<std::shared_ptr<client::YBTable>> XClusterDDLReplicationTestBase::GetProducerTable(
     const client::YBTableName& producer_table_name) {
   std::shared_ptr<client::YBTable> producer_table;
diff --git a/src/yb/integration-tests/xcluster/xcluster_outbound_replication_group-itest.cc b/src/yb/integration-tests/xcluster/xcluster_outbound_replication_group-itest.cc
index 8cad3ad691..e17ba63b81 100644
--- a/src/yb/integration-tests/xcluster/xcluster_outbound_replication_group-itest.cc
+++ b/src/yb/integration-tests/xcluster/xcluster_outbound_replication_group-itest.cc
@@ -84,10 +84,10 @@ class XClusterOutboundReplicationGroupTest : public XClusterYsqlTestBase {
 
   void VerifyNamespaceCheckpointInfo(
       const TableId& table_id1, const TableId& table_id2, size_t all_xcluster_streams_count,
-      const master::GetXClusterStreamsResponsePB& resp, bool sequences_data_included,
-      bool skip_schema_name_check = false) {
+      const master::GetXClusterStreamsResponsePB& resp, bool all_tables_included = true,
+      const PgSchemaName& table2_schema_name = kPgSchemaName) {
     ASSERT_FALSE(resp.initial_bootstrap_required());
-    ASSERT_EQ(resp.table_infos_size(), sequences_data_included ? 3 : 2);
+    ASSERT_EQ(resp.table_infos_size(), 2 + (all_tables_included ? OverheadStreamsCount() : 0));
 
     auto all_xcluster_streams = CleanupAndGetAllXClusterStreams();
     ASSERT_EQ(all_xcluster_streams.size(), all_xcluster_streams_count);
@@ -97,23 +97,22 @@ class XClusterOutboundReplicationGroupTest : public XClusterYsqlTestBase {
       SCOPED_TRACE("table name: " + table_info.table_name());
       if (table_info.table_name() == kTableName1) {
         ASSERT_EQ(table_info.table_id(), table_id1);
+        ASSERT_EQ(table_info.pg_schema_name(), kPgSchemaName);
+
       } else if (table_info.table_name() == kTableName2) {
         ASSERT_EQ(table_info.table_id(), table_id2);
+        ASSERT_EQ(table_info.pg_schema_name(), table2_schema_name);
       } else if (table_info.table_name() == "sequences_data") {
+        ASSERT_TRUE(all_tables_included);
         ASSERT_TRUE(xcluster::IsSequencesDataAlias(table_info.table_id()));
+        EXPECT_TRUE(table_info.pg_schema_name().empty());
+      } else if (
+          table_info.table_name() == xcluster::kDDLQueueTableName &&
+          table_info.pg_schema_name() == xcluster::kDDLQueuePgSchemaName) {
+        ASSERT_TRUE(all_tables_included);
       } else {
         FAIL() << "Unexpected table name: " << table_info.table_name();
       }
-      if (!xcluster::IsSequencesDataAlias(table_info.table_id())) {
-        if (skip_schema_name_check) {
-          // Make sure it is not empty.
-          ASSERT_FALSE(table_info.pg_schema_name().empty());
-        } else {
-          ASSERT_EQ(table_info.pg_schema_name(), kPgSchemaName);
-        }
-      } else {
-        EXPECT_TRUE(table_info.pg_schema_name().empty());
-      }
 
       ASSERT_FALSE(table_info.xrepl_stream_id().empty());
       auto stream_id = ASSERT_RESULT(xrepl::StreamId::FromString(table_info.xrepl_stream_id()));
@@ -224,29 +223,14 @@ TEST_P(XClusterOutboundReplicationGroupParameterized, TestMultipleTable) {
   // We should have 2 normal streams now.
   size_t stream_count = 2 + OverheadStreamsCount();
   ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      table_id_1, table_id_2, stream_count, resp, /*sequences_data_included=*/UseAutomaticMode(),
-      /*skip_schema_name_check=*/true));
-
-  for (const auto& table_info : resp.table_infos()) {
-    // Order is not deterministic so search with the table name.
-    if (table_info.table_name() == kTableName1) {
-      ASSERT_EQ(table_info.pg_schema_name(), kPgSchemaName);
-    } else if (table_info.table_name() == kTableName2) {
-      ASSERT_EQ(table_info.pg_schema_name(), pg_schema_name2);
-    } else if (table_info.table_name() == "sequences_data") {
-      EXPECT_EQ(table_info.pg_schema_name(), "");
-    } else {
-      FAIL() << "unknown tablename " << table_info.table_name();
-    }
-  }
+      table_id_1, table_id_2, stream_count, resp, /*all_tables_included=*/true, pg_schema_name2));
 
   // Get the table info in a custom order.
   resp = ASSERT_RESULT(GetXClusterStreams(
       kReplicationGroupId, namespace_id_, {kTableName2, kTableName1},
       {pg_schema_name2, kPgSchemaName}));
   ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      table_id_1, table_id_2, stream_count, resp, /*sequences_data_included=*/false,
-      /*skip_schema_name_check=*/true));
+      table_id_1, table_id_2, stream_count, resp, /*all_tables_included=*/false, pg_schema_name2));
   ASSERT_EQ(resp.table_infos(0).pg_schema_name(), pg_schema_name2);
   ASSERT_EQ(resp.table_infos(1).pg_schema_name(), kPgSchemaName);
   ASSERT_EQ(resp.table_infos(0).table_name(), kTableName2);
@@ -293,9 +277,8 @@ TEST_P(XClusterOutboundReplicationGroupParameterized, AddDeleteNamespaces) {
   // Make sure only the namespace that was added is returned.
   ASSERT_NOK(GetXClusterStreams(kReplicationGroupId, namespace_id_2));
 
-  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      ns1_table_id_1, ns1_table_id_2, stream_count, ns1_info,
-      /*sequences_data_included=*/UseAutomaticMode()));
+  ASSERT_NO_FATALS(
+      VerifyNamespaceCheckpointInfo(ns1_table_id_1, ns1_table_id_2, stream_count, ns1_info));
 
   // Add the second namespace.
   ASSERT_OK(client::XClusterClient(*client_).AddNamespaceToOutboundReplicationGroup(
@@ -310,9 +293,8 @@ TEST_P(XClusterOutboundReplicationGroupParameterized, AddDeleteNamespaces) {
 
   // Validate the seconds namespace.
   auto ns2_info = ASSERT_RESULT(GetXClusterStreams(kReplicationGroupId, namespace_id_2));
-  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      ns2_table_id_1, ns2_table_id_2, stream_count, ns2_info,
-      /*sequences_data_included=*/UseAutomaticMode()));
+  ASSERT_NO_FATALS(
+      VerifyNamespaceCheckpointInfo(ns2_table_id_1, ns2_table_id_2, stream_count, ns2_info));
 
   ASSERT_OK(XClusterClient().RemoveNamespaceFromOutboundReplicationGroup(
       kReplicationGroupId, namespace_id_, /*target_master_addresses=*/{}));
@@ -358,9 +340,7 @@ TEST_P(XClusterOutboundReplicationGroupParameterized, AddTable) {
   auto ns1_info = ASSERT_RESULT(GetXClusterStreams(kReplicationGroupId, namespace_id_));
 
   size_t stream_count = 2 + OverheadStreamsCount();
-  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      table_id_1, table_id_2, stream_count, ns1_info,
-      /*sequences_data_included=*/UseAutomaticMode()));
+  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(table_id_1, table_id_2, stream_count, ns1_info));
 
   ASSERT_OK(VerifyWalRetentionOfTable(table_id_2));
 }
@@ -459,8 +439,7 @@ TEST_P(XClusterOutboundReplicationGroupParameterized, MasterRestartDuringCheckpo
 
   auto resp = ASSERT_RESULT(future.get());
   size_t stream_count = 2 + OverheadStreamsCount();
-  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      table_id_1, table_id_2, stream_count, resp, /*sequences_data_included=*/UseAutomaticMode()));
+  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(table_id_1, table_id_2, stream_count, resp));
 
   auto all_xcluster_streams_initial = CleanupAndGetAllXClusterStreams();
   ASSERT_EQ(all_xcluster_streams_initial.size(), stream_count);
@@ -743,6 +722,9 @@ TEST_P(XClusterOutboundReplicationGroupParameterized, TestGetStreamByTableId) {
   ASSERT_OK(XClusterClient().CreateOutboundReplicationGroup(
       kReplicationGroupId, {namespace_id_}, UseAutomaticMode()));
 
+  // Wait for the namespace to be ready.
+  ASSERT_OK(GetXClusterStreams(kReplicationGroupId, namespace_id_));
+
   // Delete the table to put it into HIDDEN state.
   ASSERT_OK(DropYsqlTable(&producer_cluster_, kNamespaceName, kPgSchemaName, kTableName1));
 
@@ -774,7 +756,7 @@ TEST_P(XClusterOutboundReplicationGroupParameterized, TestGetStreamByTableId) {
     ASSERT_EQ(ns_info.table_infos(0).table_id(), sequence_table_alias_id);
   }
 
-  // Verify that we can request a table that does not exist.
+  // Verify that we cannot request a table that does not exist.
   ASSERT_NOK_STR_CONTAINS(
       GetXClusterStreamsByTableId(kReplicationGroupId, namespace_id_, {"bad_table_id"}),
       "Table bad_table_id not found");
diff --git a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
index 72b6be8449..b3dd1571f1 100644
--- a/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
+++ b/src/yb/integration-tests/xcluster/xcluster_ysql_test_base.h
@@ -41,9 +41,9 @@ class XClusterYsqlTestBase : public XClusterTestBase {
     if (!UseAutomaticMode()) {
       return 0;
     }
-    // So far automatic mode has one extra stream for each namespace: sequences_data.
-    // TODO(jhe): increment this when you add the DDL queue table
-    return 1;
+    // Automatic DDL mode involves 2 extra tables: sequences_data and
+    // yb_xcluster_ddl_replication.dd_queue.
+    return 2;
   }
 
   Status InitClusters(const MiniClusterOptions& opts) override;
diff --git a/src/yb/master/catalog_manager.cc b/src/yb/master/catalog_manager.cc
index e32f1e86f0..47f752ec94 100644
--- a/src/yb/master/catalog_manager.cc
+++ b/src/yb/master/catalog_manager.cc
@@ -13023,5 +13023,52 @@ Result<TablegroupId> CatalogManager::GetTablegroupId(const TableId& table_id) {
   return tablegroup->id();
 }
 
+Result<TSDescriptorPtr> CatalogManager::GetClosestLiveTserver() const {
+  ServerRegistrationPB local_registration;
+  RETURN_NOT_OK(master_->GetMasterRegistration(&local_registration));
+
+  std::unordered_set<std::string> local_hosts;
+  for (const auto& addr : local_registration.private_rpc_addresses()) {
+    local_hosts.insert(addr.host());
+  }
+
+  const auto& local_cloud_info = local_registration.cloud_info();
+
+  TSDescriptorVector descs;
+  master_->ts_manager()->GetAllLiveDescriptorsInCluster(&descs, VERIFY_RESULT(placement_uuid()));
+
+  auto best_score = CatalogManagerUtil::CloudInfoSimilarity::NO_MATCH;
+  TSDescriptorPtr best_tserver;
+  for (const auto& desc : descs) {
+    const auto& ts_info = desc->GetTSInformationPB();
+    DCHECK(ts_info.has_registration());
+    if (!ts_info.has_registration()) {
+      continue;
+    }
+
+    const auto& ts_cloud_info = ts_info.registration().common().cloud_info();
+    auto ts_score = CatalogManagerUtil::ComputeCloudInfoSimilarity(ts_cloud_info, local_cloud_info);
+    if (ts_score < best_score) {
+      continue;
+    }
+
+    if (ts_score == CatalogManagerUtil::CloudInfoSimilarity::ZONE_MATCH) {
+      // If this tserver is on the same node as master pick it.
+      for (const auto& addr : ts_info.registration().common().private_rpc_addresses()) {
+        if (local_hosts.contains(addr.host())) {
+          return desc;
+        }
+      }
+    }
+
+    best_score = ts_score;
+    best_tserver = desc;
+  }
+
+  SCHECK(best_tserver, NotFound, "Couldn't find a live tablet server to connect to");
+
+  return best_tserver;
+}
+
 }  // namespace master
 }  // namespace yb
diff --git a/src/yb/master/catalog_manager.h b/src/yb/master/catalog_manager.h
index 8cc1a10cce..9469cc47cc 100644
--- a/src/yb/master/catalog_manager.h
+++ b/src/yb/master/catalog_manager.h
@@ -1667,6 +1667,8 @@ class CatalogManager : public tserver::TabletPeerLookupIf,
       SysRowEntryType type, const std::string& item_id, const std::string& debug_string,
       QLWriteRequestPB::QLStmtType op_type);
 
+  Result<TSDescriptorPtr> GetClosestLiveTserver() const override;
+
  protected:
   // TODO Get rid of these friend classes and introduce formal interface.
   friend class TableLoader;
diff --git a/src/yb/master/catalog_manager_if.h b/src/yb/master/catalog_manager_if.h
index baf26b1b1d..672009591d 100644
--- a/src/yb/master/catalog_manager_if.h
+++ b/src/yb/master/catalog_manager_if.h
@@ -343,6 +343,8 @@ class CatalogManagerIf {
   virtual Status CanSupportAdditionalTablet(
       const TableInfoPtr& table, const ReplicationInfoPB& replication_info) const = 0;
 
+  virtual Result<TSDescriptorPtr> GetClosestLiveTserver() const = 0;
+
   virtual ~CatalogManagerIf() = default;
 };
 
diff --git a/src/yb/master/catalog_manager_util.cc b/src/yb/master/catalog_manager_util.cc
index 98e3f652c2..22c1a5f821 100644
--- a/src/yb/master/catalog_manager_util.cc
+++ b/src/yb/master/catalog_manager_util.cc
@@ -10,15 +10,22 @@
 // or implied.  See the License for the specific language governing permissions and limitations
 // under the License.
 //
-#include "yb/dockv/partition.h"
-#include "yb/common/schema_pbutil.h"
 
 #include "yb/master/catalog_manager_util.h"
 
-#include "yb/master/catalog_entity_info.h"
+#include "yb/common/schema_pbutil.h"
+#include "yb/common/wire_protocol.h"
+
+#include "yb/dockv/partition.h"
 
+#include "yb/master/catalog_entity_info.h"
+#include "yb/master/catalog_manager_if.h"
 #include "yb/master/master_cluster.pb.h"
 #include "yb/master/ysql_tablespace_manager.h"
+
+#include "yb/tserver/tserver_service.pb.h"
+#include "yb/tserver/tserver_service.proxy.h"
+
 #include "yb/util/flags.h"
 #include "yb/util/math_util.h"
 #include "yb/util/string_util.h"
@@ -581,5 +588,39 @@ const BlacklistPB& GetBlacklist(const SysClusterConfigEntryPB& pb, bool blacklis
   return blacklist_leader ? pb.leader_blacklist() : pb.server_blacklist();
 }
 
+Status ExecutePgsqlStatements(
+    const std::string& database_name, const std::vector<std::string>& statements,
+    CatalogManagerIf& catalog_manager, CoarseTimePoint deadline, StdStatusCallback callback) {
+  SCHECK(!database_name.empty(), InvalidArgument, "Database name is empty");
+  if (statements.empty()) {
+    return Status::OK();
+  }
+
+  auto closest_tserver = VERIFY_RESULT(catalog_manager.GetClosestLiveTserver());
+  std::shared_ptr<tserver::TabletServerServiceProxy> proxy;
+  RETURN_NOT_OK(closest_tserver->GetProxy(&proxy));
+
+  tserver::AdminExecutePgsqlRequestPB req;
+  req.set_database_name(database_name);
+  for (const auto& statement : statements) {
+    req.add_pgsql_statements(statement);
+  }
+
+  auto resp = std::make_shared<tserver::AdminExecutePgsqlResponsePB>();
+  auto controller = std::make_shared<rpc::RpcController>();
+  controller->set_deadline(deadline);
+
+  proxy->AdminExecutePgsqlAsync(
+      req, resp.get(), controller.get(), [controller, resp, cb = std::move(callback)]() {
+        Status status = controller->status();
+        if (status.ok() && resp->has_error()) {
+          status = StatusFromPB(resp->error().status());
+        }
+        cb(status);
+      });
+
+  return Status::OK();
+}
+
 } // namespace master
 } // namespace yb
diff --git a/src/yb/master/catalog_manager_util.h b/src/yb/master/catalog_manager_util.h
index a4218ea737..72683e79e4 100644
--- a/src/yb/master/catalog_manager_util.h
+++ b/src/yb/master/catalog_manager_util.h
@@ -16,16 +16,15 @@
 #include <unordered_map>
 #include <vector>
 
-#include "yb/util/logging.h"
+#include "yb/common/entity_ids.h"
 
-#include "yb/consensus/consensus_fwd.h"
 #include "yb/master/catalog_entity_info.h"
 #include "yb/master/master_error.h"
 #include "yb/master/master_fwd.h"
-#include "yb/master/master_snapshot_coordinator.h"
-#include "yb/master/snapshot_coordinator_context.h"
 #include "yb/master/ts_descriptor.h"
 
+#include "yb/util/status_callback.h"
+
 // Utility functions that can be shared between test and code for catalog manager.
 namespace yb {
 namespace master {
@@ -256,5 +255,9 @@ int32_t GetNumReplicasOrGlobalReplicationFactor(const PlacementInfoPB& placement
 
 const BlacklistPB& GetBlacklist(const SysClusterConfigEntryPB& pb, bool blacklist_leader);
 
+Status ExecutePgsqlStatements(
+    const std::string& database_name, const std::vector<std::string>& statements,
+    CatalogManagerIf& catalog_manager, CoarseTimePoint deadline, StdStatusCallback callback);
+
 } // namespace master
 } // namespace yb
diff --git a/src/yb/master/master-test.cc b/src/yb/master/master-test.cc
index ce4cb2bdff..bd0db6bafc 100644
--- a/src/yb/master/master-test.cc
+++ b/src/yb/master/master-test.cc
@@ -2782,5 +2782,75 @@ TEST_F(MasterStartUpTest, JoinExistingClusterUnsetWithoutMasterAddresses) {
   ASSERT_TRUE(mini_master->master()->IsShellMode());
 }
 
+TEST_F(MasterTest, TestGetClosestLiveTserver) {
+  ANNOTATE_UNPROTECTED_WRITE(FLAGS_tserver_unresponsive_timeout_ms) = 5 * 60 * 1000;
+
+  auto& catalog_manager = mini_master_->catalog_manager();
+  auto result = catalog_manager.GetClosestLiveTserver();
+  // No valid tservers.
+  ASSERT_NOK(result);
+
+  uint32 tserver_idx = 1;
+  auto add_tserver = [this, &tserver_idx](
+                         const std::string& uuid, std::string&& cloud, std::string&& region,
+                         std::string&& zone, std::string&& host) -> Status {
+    TSToMasterCommonPB common;
+    TSRegistrationPB registration;
+    common.mutable_ts_instance()->set_permanent_uuid(Format(uuid));
+    common.mutable_ts_instance()->set_instance_seqno(0);
+    const auto address = MakeHostPortPB(std::move(host), 1000 + tserver_idx++);
+    *registration.mutable_common()->add_broadcast_addresses() = address;
+    *registration.mutable_common()->add_private_rpc_addresses() = address;
+    *registration.mutable_common()->mutable_cloud_info() =
+        MakeCloudInfoPB(std::move(cloud), std::move(region), std::move(zone));
+    RETURN_NOT_OK(SendHeartbeat(common, registration));
+    return Status::OK();
+  };
+
+  // Default placement is cloud1, rack1, zone.
+  // Add tserver in different cloud.
+  {
+    const auto tserver1_uuid = "uuid-1";
+    ASSERT_OK(add_tserver(tserver1_uuid, "cloud2", "rack1", "zone", "host1"));
+    auto closest_tserver = ASSERT_RESULT(catalog_manager.GetClosestLiveTserver());
+    ASSERT_EQ(closest_tserver->permanent_uuid(), tserver1_uuid);
+  }
+
+  // Add tserver in same cloud, different region.
+  {
+    const auto tserver2_uuid = "uuid-2";
+    ASSERT_OK(add_tserver(tserver2_uuid, "cloud1", "rack2", "zone", "host1"));
+    auto closest_tserver = ASSERT_RESULT(catalog_manager.GetClosestLiveTserver());
+    ASSERT_EQ(closest_tserver->permanent_uuid(), tserver2_uuid);
+  }
+
+  // Add tserver in same cloud, same region, different zone.
+  {
+    const auto tserver3_uuid = "uuid-3";
+    ASSERT_OK(add_tserver(tserver3_uuid, "cloud1", "rack1", "zone2", "host1"));
+    auto closest_tserver = ASSERT_RESULT(catalog_manager.GetClosestLiveTserver());
+    ASSERT_EQ(closest_tserver->permanent_uuid(), tserver3_uuid);
+  }
+
+  // Add tserver in same cloud, same region, same zone, different host.
+  {
+    const auto tserver4_uuid = "uuid-4";
+    ASSERT_OK(add_tserver(tserver4_uuid, "cloud1", "rack1", "zone", "host1"));
+    auto closest_tserver = ASSERT_RESULT(catalog_manager.GetClosestLiveTserver());
+    ASSERT_EQ(closest_tserver->permanent_uuid(), tserver4_uuid);
+  }
+
+  // Add tserver in same host as master.
+  {
+    ServerRegistrationPB master_registration;
+    ASSERT_OK(mini_master_->master()->GetMasterRegistration(&master_registration));
+    auto master_host = master_registration.private_rpc_addresses().begin()->host();
+    const auto tserver5_uuid = "uuid-5";
+    ASSERT_OK(add_tserver(tserver5_uuid, "cloud1", "rack1", "zone", std::move(master_host)));
+    auto closest_tserver = ASSERT_RESULT(catalog_manager.GetClosestLiveTserver());
+    ASSERT_EQ(closest_tserver->permanent_uuid(), tserver5_uuid);
+  }
+}
+
 } // namespace master
 } // namespace yb
diff --git a/src/yb/master/master.cc b/src/yb/master/master.cc
index 6850a917ca..480567eb5e 100644
--- a/src/yb/master/master.cc
+++ b/src/yb/master/master.cc
@@ -56,6 +56,7 @@
 #include "yb/master/master_cluster_handler.h"
 #include "yb/master/master_fwd.h"
 #include "yb/master/master_service.h"
+#include "yb/master/master_snapshot_coordinator.h"
 #include "yb/master/master_tablet_service.h"
 #include "yb/master/master_util.h"
 #include "yb/master/sys_catalog_constants.h"
diff --git a/src/yb/master/master_tablet_service.cc b/src/yb/master/master_tablet_service.cc
index c6ca984d90..bacfd26cf5 100644
--- a/src/yb/master/master_tablet_service.cc
+++ b/src/yb/master/master_tablet_service.cc
@@ -251,5 +251,11 @@ void MasterTabletServiceImpl::Checksum(const tserver::ChecksumRequestPB* req,
   HandleUnsupportedMethod("Checksum", &context);
 }
 
+void MasterTabletServiceImpl::AdminExecutePgsql(
+    const tserver::AdminExecutePgsqlRequestPB* req, tserver::AdminExecutePgsqlResponsePB* resp,
+    rpc::RpcContext context) {
+  HandleUnsupportedMethod("AdminExecutePgsql", &context);
+}
+
 } // namespace master
 } // namespace yb
diff --git a/src/yb/master/master_tablet_service.h b/src/yb/master/master_tablet_service.h
index 2a9ee42513..436ccda4f0 100644
--- a/src/yb/master/master_tablet_service.h
+++ b/src/yb/master/master_tablet_service.h
@@ -58,6 +58,10 @@ class MasterTabletServiceImpl : public tserver::TabletServiceImpl {
       const tserver::ReleaseObjectLockRequestPB* req, tserver::ReleaseObjectLockResponsePB* resp,
       rpc::RpcContext context) override;
 
+  void AdminExecutePgsql(
+      const tserver::AdminExecutePgsqlRequestPB* req, tserver::AdminExecutePgsqlResponsePB* resp,
+      rpc::RpcContext context) override;
+
  private:
   Result<std::shared_ptr<tablet::AbstractTablet>> GetTabletForRead(
     const TabletId& tablet_id, tablet::TabletPeerPtr tablet_peer,
diff --git a/src/yb/master/master_tserver.cc b/src/yb/master/master_tserver.cc
index 4aa12f147e..5f787266d4 100644
--- a/src/yb/master/master_tserver.cc
+++ b/src/yb/master/master_tserver.cc
@@ -36,6 +36,8 @@
 #include "yb/util/monotime.h"
 #include "yb/util/status_format.h"
 
+#include "yb/yql/pgwrapper/libpq_utils.h"
+
 DECLARE_bool(create_initial_sys_catalog_snapshot);
 
 namespace yb {
@@ -224,5 +226,11 @@ Result<std::vector<TserverMetricsInfoPB>> MasterTabletServer::GetMetrics() const
   return STATUS_FORMAT(InternalError, "Unexpected call of GetMetrics()");
 }
 
+Result<pgwrapper::PGConn> MasterTabletServer::CreateInternalPGConn(
+    const std::string& database_name, const std::optional<CoarseTimePoint>& deadline) {
+  LOG(DFATAL) << "Unexpected call of CreateInternalPGConn()";
+  return STATUS_FORMAT(InternalError, "Unexpected call of CreateInternalPGConn()");
+}
+
 } // namespace master
 } // namespace yb
diff --git a/src/yb/master/master_tserver.h b/src/yb/master/master_tserver.h
index 91b68ab2ad..8d64e59ea4 100644
--- a/src/yb/master/master_tserver.h
+++ b/src/yb/master/master_tserver.h
@@ -110,6 +110,9 @@ class MasterTabletServer : public tserver::TabletServerIf,
   virtual Result<std::vector<TserverMetricsInfoPB>> GetMetrics() const override;
 
  private:
+  Result<pgwrapper::PGConn> CreateInternalPGConn(
+      const std::string& database_name, const std::optional<CoarseTimePoint>& deadline) override;
+
   Master* master_ = nullptr;
   scoped_refptr<MetricEntity> metric_entity_;
 };
diff --git a/src/yb/master/sys_catalog.cc b/src/yb/master/sys_catalog.cc
index 12b8512cca..1e84b5f644 100644
--- a/src/yb/master/sys_catalog.cc
+++ b/src/yb/master/sys_catalog.cc
@@ -78,6 +78,7 @@
 #include "yb/master/catalog_manager_if.h"
 #include "yb/master/catalog_manager.h"
 #include "yb/master/master.h"
+#include "yb/master/master_snapshot_coordinator.h"
 #include "yb/master/master_util.h"
 #include "yb/master/sys_catalog_writer.h"
 
diff --git a/src/yb/master/xcluster/master_xcluster_util.cc b/src/yb/master/xcluster/master_xcluster_util.cc
index 646fa0ae6c..f84108628b 100644
--- a/src/yb/master/xcluster/master_xcluster_util.cc
+++ b/src/yb/master/xcluster/master_xcluster_util.cc
@@ -17,9 +17,12 @@
 #include "yb/common/xcluster_util.h"
 #include "yb/master/catalog_entity_info.h"
 #include "yb/master/catalog_manager.h"
+#include "yb/master/catalog_manager_util.h"
 
 namespace yb::master {
 
+static const auto kXClusterDDLExtensionName = xcluster::kDDLQueuePgSchemaName;
+
 bool IsTableEligibleForXClusterReplication(const master::TableInfo& table) {
   if (table.GetTableType() != PGSQL_TABLE_TYPE || table.is_system()) {
     // DB Scoped replication Limited to ysql databases.
@@ -66,16 +69,28 @@ std::string GetFullTableName(const TableInfo& table_info) {
   return Format("$0.$1", schema_name, table_info.name());
 }
 
-std::string TableDesignator::ToString() const {
-  return strings::Substitute("$0.$1 [id=$2]", pgschema_name, name, id);
+TableDesignator::TableDesignator(TableInfoPtr table_info)
+    : id(table_info->id()), table_info(std::move(table_info)) {
+  DCHECK(!this->table_info->IsSequencesSystemTable());
+}
+
+TableDesignator::TableDesignator(TableInfoPtr sequence_table_info, const NamespaceId& namespace_id)
+    : id(xcluster::GetSequencesDataAliasForNamespace(namespace_id)),
+      table_info(std::move(sequence_table_info)) {
+  DCHECK(table_info->IsSequencesSystemTable());
 }
 
-TableDesignator GetDesignatorFromTableInfo(const TableInfo& table_info) {
-  TableDesignator designator;
-  designator.id = table_info.id();
-  designator.name = table_info.name();
-  designator.pgschema_name = table_info.pgschema_name();
-  return designator;
+TableDesignator TableDesignator::CreateSequenceTableDesignator(
+    TableInfoPtr sequence_table_info, const NamespaceId& namespace_id) {
+  return TableDesignator(sequence_table_info, namespace_id);
+}
+
+std::string TableDesignator::name() const { return table_info->name(); }
+
+std::string TableDesignator::pgschema_name() const { return table_info->pgschema_name(); }
+
+std::string TableDesignator::ToString() const {
+  return strings::Substitute("$0.$1 [id=$2]", pgschema_name(), name(), id);
 }
 
 Result<std::vector<TableDesignator>> GetTablesEligibleForXClusterReplication(
@@ -86,16 +101,15 @@ Result<std::vector<TableDesignator>> GetTablesEligibleForXClusterReplication(
   std::vector<TableDesignator> table_designators{};
   for (const auto& table_info : table_infos) {
     if (IsTableEligibleForXClusterReplication(*table_info)) {
-      table_designators.push_back(GetDesignatorFromTableInfo(*table_info));
+      table_designators.emplace_back(table_info);
     }
   }
 
   if (include_sequences_data) {
     auto sequence_table_info = catalog_manager.GetTableInfo(kPgSequencesDataTableId);
     if (sequence_table_info) {
-      TableDesignator designator = GetDesignatorFromTableInfo(*sequence_table_info);
-      designator.id = xcluster::GetSequencesDataAliasForNamespace(namespace_id);
-      table_designators.push_back(designator);
+      table_designators.emplace_back(
+          TableDesignator::CreateSequenceTableDesignator(sequence_table_info, namespace_id));
     }
   }
   return table_designators;
@@ -111,4 +125,27 @@ bool IsAutomaticDdlMode(const SysUniverseReplicationEntryPB& replication_info) {
          replication_info.db_scoped_info().automatic_ddl_mode();
 }
 
+Status SetupDDLReplicationExtension(
+    CatalogManagerIf& catalog_manager, const std::string& database_name,
+    XClusterDDLReplicationRole role, CoarseTimePoint deadline, StdStatusCallback callback) {
+  std::vector<std::string> statements;
+  if (role == XClusterDDLReplicationRole::kSource) {
+    // In 1:N replication the source universe will already have the extension created.
+    statements.push_back(Format("CREATE EXTENSION IF NOT EXISTS $0", kXClusterDDLExtensionName));
+  } else {
+    // We could have older data in the table due to a backup restore from the source universe.
+    // So, we drop the extension and recreate it so that we start with empty tables.
+    statements.push_back(Format("DROP EXTENSION IF EXISTS $0", kXClusterDDLExtensionName));
+    statements.push_back(Format("CREATE EXTENSION $0", kXClusterDDLExtensionName));
+  }
+
+  statements.push_back(Format(
+      "ALTER DATABASE \"$0\" SET $1.replication_role = $2", database_name,
+      kXClusterDDLExtensionName,
+      role == XClusterDDLReplicationRole::kSource ? "SOURCE" : "TARGET"));
+
+  return ExecutePgsqlStatements(
+      database_name, statements, catalog_manager, deadline, std::move(callback));
+}
+
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/master_xcluster_util.h b/src/yb/master/xcluster/master_xcluster_util.h
index d4f65cd175..e91c37f539 100644
--- a/src/yb/master/xcluster/master_xcluster_util.h
+++ b/src/yb/master/xcluster/master_xcluster_util.h
@@ -17,6 +17,7 @@
 #include <vector>
 
 #include "yb/master/master_fwd.h"
+#include "yb/util/status_callback.h"
 
 namespace yb::master {
 class TableInfo;
@@ -27,15 +28,27 @@ bool IsTableEligibleForXClusterReplication(const master::TableInfo& table);
 // Get the table name along with the YSQL schema name if this is a YSQL table.
 std::string GetFullTableName(const TableInfo& table_info);
 
+// A wrapper over TableInfo that allows us to use an alias TableId. This is useful for
+// sequences_data table for which we use a special TableId in xCluster. Check
+// GetSequencesDataAliasForNamespace.
 struct TableDesignator {
-  TableId id;
-  TableName name;
-  PgSchemaName pgschema_name;
+  // Non-sequences_data table constructor.
+  explicit TableDesignator(TableInfoPtr table_info);
+
+  static TableDesignator CreateSequenceTableDesignator(
+      TableInfoPtr sequence_table_info, const NamespaceId& namespace_id);
+
+  const TableId id;
+  const TableInfoPtr table_info;
+  TableName name() const;
+  PgSchemaName pgschema_name() const;
 
   std::string ToString() const;
-};
 
-TableDesignator GetDesignatorFromTableInfo(const TableInfo& table_info);
+ private:
+  // Constructor for sequences_data table.
+  TableDesignator(TableInfoPtr sequence_table_info, const NamespaceId& namespace_id);
+};
 
 Result<std::vector<TableDesignator>> GetTablesEligibleForXClusterReplication(
     const CatalogManager& catalog_manager, const NamespaceId& namespace_id,
@@ -45,4 +58,10 @@ bool IsDbScoped(const SysUniverseReplicationEntryPB& replication_info);
 
 bool IsAutomaticDdlMode(const SysUniverseReplicationEntryPB& replication_info);
 
+YB_DEFINE_ENUM(XClusterDDLReplicationRole, (kSource)(kTarget));
+
+Status SetupDDLReplicationExtension(
+    CatalogManagerIf& catalog_manager, const std::string& database_name,
+    XClusterDDLReplicationRole role, CoarseTimePoint deadline, StdStatusCallback callback);
+
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_bootstrap_helper.cc b/src/yb/master/xcluster/xcluster_bootstrap_helper.cc
index 14b6793a2d..a9f9bcc45d 100644
--- a/src/yb/master/xcluster/xcluster_bootstrap_helper.cc
+++ b/src/yb/master/xcluster/xcluster_bootstrap_helper.cc
@@ -18,6 +18,7 @@
 #include "yb/master/catalog_manager-internal.h"
 #include "yb/master/catalog_manager.h"
 #include "yb/master/master.h"
+#include "yb/master/master_snapshot_coordinator.h"
 #include "yb/master/snapshot_transfer_manager.h"
 #include "yb/master/xcluster/xcluster_manager.h"
 #include "yb/master/xcluster_rpc_tasks.h"
diff --git a/src/yb/master/xcluster/xcluster_inbound_replication_group_setup_task.cc b/src/yb/master/xcluster/xcluster_inbound_replication_group_setup_task.cc
index b89c6600f7..cb7dcd9126 100644
--- a/src/yb/master/xcluster/xcluster_inbound_replication_group_setup_task.cc
+++ b/src/yb/master/xcluster/xcluster_inbound_replication_group_setup_task.cc
@@ -36,6 +36,7 @@
 
 #include "yb/tserver/pg_create_table.h"
 
+#include "yb/util/async_util.h"
 #include "yb/util/flags/auto_flags_util.h"
 #include "yb/util/status.h"
 #include "yb/util/status_format.h"
@@ -58,7 +59,7 @@ DECLARE_bool(enable_xcluster_auto_flag_validation);
 
 DECLARE_bool(TEST_xcluster_enable_sequence_replication);
 
-DECLARE_int32(master_yb_client_default_timeout_ms);
+DECLARE_uint32(xcluster_ysql_statement_timeout_sec);
 
 using namespace std::placeholders;
 
@@ -290,11 +291,42 @@ Status XClusterInboundReplicationGroupSetupTask::FirstStep() {
     // Ensure sequences_data table has been created.
     auto local_client = master_.client_future();
     RETURN_NOT_OK(tserver::CreateSequencesDataTable(
-        local_client.get(),
-        CoarseMonoClock::now() +
-            MonoDelta::FromMilliseconds(FLAGS_master_yb_client_default_timeout_ms)));
+        local_client.get(), CoarseMonoClock::now() +
+                                MonoDelta::FromSeconds(FLAGS_xcluster_ysql_statement_timeout_sec)));
   }
 
+  ScheduleNextStep(
+      std::bind(
+          &XClusterInboundReplicationGroupSetupTask::SetupDDLReplicationExtension,
+          shared_from(this)),
+      "SetupDDLReplicationExtension");
+
+  return Status::OK();
+}
+
+Status XClusterInboundReplicationGroupSetupTask::SetupDDLReplicationExtension() {
+  if (automatic_ddl_mode_) {
+    for (const auto& namespace_id : target_namespace_ids_) {
+      auto namespace_name = VERIFY_RESULT(catalog_manager_.FindNamespaceById(namespace_id))->name();
+      Synchronizer sync;
+      LOG(INFO) << "Setting up DDL replication extension for namespace " << namespace_id << " ("
+                << namespace_name << ")";
+      RETURN_NOT_OK(master::SetupDDLReplicationExtension(
+          catalog_manager_, namespace_name, XClusterDDLReplicationRole::kTarget,
+          CoarseMonoClock::now() +
+              MonoDelta::FromSeconds(FLAGS_xcluster_ysql_statement_timeout_sec),
+          sync.AsStdStatusCallback()));
+      RETURN_NOT_OK_PREPEND(sync.Wait(), "Failed to setup xCluster DDL replication extension");
+    }
+  }
+
+  ScheduleNextStep(
+      std::bind(&XClusterInboundReplicationGroupSetupTask::CreateTableTasks, shared_from(this)),
+      "CreateTableTasks");
+  return Status::OK();
+}
+
+Status XClusterInboundReplicationGroupSetupTask::CreateTableTasks() {
   LOG_WITH_PREFIX(INFO) << "Started schema validation for " << source_table_ids_.size()
                         << " table(s)";
 
diff --git a/src/yb/master/xcluster/xcluster_inbound_replication_group_setup_task.h b/src/yb/master/xcluster/xcluster_inbound_replication_group_setup_task.h
index 1de187dad3..debe4816df 100644
--- a/src/yb/master/xcluster/xcluster_inbound_replication_group_setup_task.h
+++ b/src/yb/master/xcluster/xcluster_inbound_replication_group_setup_task.h
@@ -204,7 +204,9 @@ class XClusterInboundReplicationGroupSetupTask : public XClusterInboundReplicati
   Status RegisterTask() override;
   void UnregisterTask() override;
 
-  Status FirstStep() override EXCLUDES(mutex_);
+  Status FirstStep() override;
+  Status SetupDDLReplicationExtension();
+  Status CreateTableTasks();
 
   void TaskCompleted(const Status& status) override EXCLUDES(done_result_mutex_);
 
diff --git a/src/yb/master/xcluster/xcluster_manager.cc b/src/yb/master/xcluster/xcluster_manager.cc
index c4ab60b2d7..ae6893fb24 100644
--- a/src/yb/master/xcluster/xcluster_manager.cc
+++ b/src/yb/master/xcluster/xcluster_manager.cc
@@ -42,6 +42,9 @@ DEFINE_RUNTIME_AUTO_bool(enable_tablet_split_of_xcluster_replicated_tables, kExt
     "When set, it enables automatic tablet splitting for tables that are part of an "
     "xCluster replication setup");
 
+DEFINE_RUNTIME_uint32(xcluster_ysql_statement_timeout_sec, 120,
+    "Timeout for YSQL statements executed during xCluster operations.");
+
 // This flag will be converted to a PREVIEW, and then a kExternal Auto flag as the feature matures.
 DEFINE_test_flag(bool, xcluster_enable_ddl_replication, false,
     "Enables xCluster automatic DDL replication.");
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
index 8228e8d810..4a0be49d16 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group-test.cc
@@ -18,6 +18,7 @@
 #include "yb/client/xcluster_client_mock.h"
 #include "yb/common/xcluster_util.h"
 #include "yb/master/catalog_entity_info.h"
+#include "yb/master/xcluster/add_table_to_xcluster_source_task.h"
 #include "yb/master/xcluster/xcluster_outbound_replication_group_tasks.h"
 
 #include "yb/rpc/messenger.h"
@@ -85,19 +86,6 @@ class XClusterOutboundReplicationGroupMocked : public XClusterOutboundReplicatio
            SysXClusterOutboundReplicationGroupEntryPB::DELETED;
   }
 
-  Status AddTable(const TableInfoPtr& table_info, const LeaderEpoch& epoch) {
-    // Same as AddTableToXClusterSourceTask.
-
-    RETURN_NOT_OK(CreateStreamForNewTable(table_info->namespace_id(), table_info->id(), epoch));
-
-    Synchronizer sync;
-    RETURN_NOT_OK(CheckpointNewTable(
-        table_info->namespace_id(), table_info->id(), epoch, sync.AsStdStatusCallback()));
-    RETURN_NOT_OK(sync.Wait());
-
-    return MarkNewTablesAsCheckpointed(table_info->namespace_id(), table_info->id(), epoch);
-  }
-
   Status WaitForCheckpoint(const NamespaceId& namespace_id, MonoDelta delta) {
     return LoggedWaitFor(
         [this, namespace_id]() -> Result<bool> {
@@ -135,17 +123,17 @@ class XClusterOutboundReplicationGroupMocked : public XClusterOutboundReplicatio
   std::shared_ptr<client::MockXClusterRemoteClientHolder> remote_client_;
 };
 
+const UniverseUuid kTargetUniverseUuid = UniverseUuid::GenerateRandom();
+const NamespaceName kNamespaceName = "db1";
+const NamespaceId kNamespaceId = "db1_id";
+const PgSchemaName kPgSchemaName = "public", kPgSchemaName2 = "public2";
+const xcluster::ReplicationGroupId kReplicationGroupId = xcluster::ReplicationGroupId("rg1");
+const TableName kTableName1 = "table1", kTableName2 = "table2";
+const TableId kTableId1 = "table_id_1", kTableId2 = "table_id_2";
+const MonoDelta kTimeout = MonoDelta::FromSeconds(5 * kTimeMultiplier);
+
 class XClusterOutboundReplicationGroupMockedTest : public YBTest {
  public:
-  const UniverseUuid kTargetUniverseUuid = UniverseUuid::GenerateRandom();
-  const NamespaceName kNamespaceName = "db1";
-  const NamespaceId kNamespaceId = "db1_id";
-  const PgSchemaName kPgSchemaName = "public", kPgSchemaName2 = "public2";
-  const xcluster::ReplicationGroupId kReplicationGroupId = xcluster::ReplicationGroupId("rg1");
-  const TableName kTableName1 = "table1", kTableName2 = "table2";
-  const TableId kTableId1 = "table_id_1", kTableId2 = "table_id_2";
-  const MonoDelta kTimeout = MonoDelta::FromSeconds(5* kTimeMultiplier);
-
   XClusterOutboundReplicationGroupMockedTest() {
     google::SetVLOGLevel("*", 4);
 
@@ -176,8 +164,7 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
   void SetUp() {
     YBTest::SetUp();
     LOG(INFO) << "Test uses automatic mode: " << UseAutomaticMode();
-    ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_xcluster_enable_ddl_replication) =
-        UseAutomaticMode();
+    ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_xcluster_enable_ddl_replication) = UseAutomaticMode();
     ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_xcluster_enable_sequence_replication) =
         UseAutomaticMode();
   }
@@ -192,9 +179,9 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
     if (!UseAutomaticMode()) {
       return 0;
     }
-    // So far automatic mode has one extra stream for each namespace: sequences_data.
-    // TODO(jhe): increment this when you add the DDL queue table
-    return 1;
+    // Automatic DDL mode involves 2 extra tables: sequences_data and
+    // yb_xcluster_ddl_replication.dd_queue.
+    return 2;
   }
 
   void CreateNamespace(const NamespaceName& namespace_name, const NamespaceId& namespace_id) {
@@ -207,9 +194,49 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
     namespace_infos[namespace_id] = std::move(ns);
   }
 
-  TableInfoPtr CreateTable(
+  // The actual AddTableToXClusterSourceTask requires a CatalogManager so directly invoke the
+  // required methods.
+  Status AddTableToXClusterSourceTask(const master::TableInfo& table) {
+    for (const auto& outbound_replication_group : outbound_replication_groups_) {
+      if (!outbound_replication_group->HasNamespace(table.namespace_id())) {
+        continue;
+      }
+      RETURN_NOT_OK(outbound_replication_group->CreateStreamForNewTable(
+          table.namespace_id(), table.id(), kEpoch));
+      Synchronizer sync;
+      RETURN_NOT_OK(outbound_replication_group->CheckpointNewTable(
+          table.namespace_id(), table.id(), kEpoch, sync.AsStdStatusCallback()));
+      RETURN_NOT_OK(sync.Wait());
+      RETURN_NOT_OK(outbound_replication_group->MarkNewTablesAsCheckpointed(
+          table.namespace_id(), table.id(), kEpoch));
+    }
+
+    return Status::OK();
+  }
+
+  bool TableExists(const NamespaceId& namespace_id, const TableId& table_id) {
+    std::lock_guard l(mutex_);
+    return std::any_of(
+        namespace_tables[namespace_id].begin(), namespace_tables[namespace_id].end(),
+        [&table_id](const auto& table_info) { return table_info->id() == table_id; });
+  }
+
+  Status CreateTableIfNotExists(
       const NamespaceId& namespace_id, const TableId& table_id, const TableName& table_name,
       const PgSchemaName& pg_schema_name) {
+    if (!TableExists(namespace_id, table_id)) {
+      RETURN_NOT_OK(CreateTable(namespace_id, table_id, table_name, pg_schema_name));
+    }
+    return Status::OK();
+  }
+
+  Result<TableInfoPtr> CreateTable(
+      const NamespaceId& namespace_id, const TableId& table_id, const TableName& table_name,
+      const PgSchemaName& pg_schema_name) {
+    SCHECK_FORMAT(
+        !TableExists(namespace_id, table_id), AlreadyPresent,
+        "Table $0 already exists in namespace $1", table_id, namespace_id);
+
     auto table_info = TableInfoPtr(new TableInfo(table_id, /*colocated=*/false));
     auto l = table_info->LockForWrite();
     auto& pb = l.mutable_data()->pb;
@@ -221,6 +248,11 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
 
     std::lock_guard l2(mutex_);
     namespace_tables[namespace_id].push_back(table_info);
+
+    if (IsTableEligibleForXClusterReplication(*table_info)) {
+      RETURN_NOT_OK(AddTableToXClusterSourceTask(*table_info));
+    }
+
     return table_info;
   }
 
@@ -238,8 +270,10 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
   std::shared_ptr<XClusterOutboundReplicationGroupMocked> CreateReplicationGroup() {
     SysXClusterOutboundReplicationGroupEntryPB outbound_replication_group_pb{};
     outbound_replication_group_pb.set_automatic_ddl_mode(UseAutomaticMode());
-    return std::make_shared<XClusterOutboundReplicationGroupMocked>(
+    auto group = std::make_shared<XClusterOutboundReplicationGroupMocked>(
         kReplicationGroupId, outbound_replication_group_pb, helper_functions, *task_factory);
+    outbound_replication_groups_.push_back(group);
+    return group;
   }
 
   scoped_refptr<CDCStreamInfo> CreateXClusterStream(const TableId& table_id) {
@@ -255,14 +289,16 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
   std::unique_ptr<ThreadPool> thread_pool;
   std::unique_ptr<rpc::Messenger> messenger;
   std::unique_ptr<XClusterOutboundReplicationGroupTaskFactoryMocked> task_factory;
+  std::vector<std::shared_ptr<XClusterOutboundReplicationGroupMocked>> outbound_replication_groups_;
 
   XClusterOutboundReplicationGroup::HelperFunctions helper_functions = {
-      .create_sequences_data_table_func =
-          [this]() {
-            (void)CreateTable(
-                kPgSequencesDataNamespaceId, kPgSequencesDataTableId, "sequences_data", "");
-            return Status::OK();
-          },
+      .create_sequences_data_table_func = [this]() -> Status {
+        EXPECT_TRUE(UseAutomaticMode());
+        RETURN_NOT_OK(CreateTableIfNotExists(
+            kPgSequencesDataNamespaceId, kPgSequencesDataTableId, "sequences_data", ""));
+
+        return Status::OK();
+      },
       .get_namespace_func =
           std::bind(&XClusterOutboundReplicationGroupMockedTest::GetNamespace, this, _1),
       .get_tables_func =
@@ -271,16 +307,15 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
             auto tables = namespace_tables[namespace_id];
             std::vector<TableDesignator> table_designators;
             for (const auto& table_info : tables) {
-              table_designators.push_back(GetDesignatorFromTableInfo(*table_info));
+              if (IsTableEligibleForXClusterReplication(*table_info)) {
+                table_designators.emplace_back(table_info);
+              }
             }
             if (include_sequences_data) {
               auto sequences_tables = namespace_tables[kPgSequencesDataNamespaceId];
               if (sequences_tables.size() > 0) {
-                TableDesignator table_designator;
-                table_designator.id = xcluster::GetSequencesDataAliasForNamespace(namespace_id);
-                table_designator.name = "sequences_data";
-                table_designator.pgschema_name = "";
-                table_designators.push_back(table_designator);
+                table_designators.emplace_back(TableDesignator::CreateSequenceTableDesignator(
+                    sequences_tables.front(), namespace_id));
               }
             }
             return table_designators;
@@ -314,6 +349,18 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
              const std::vector<scoped_refptr<CDCStreamInfo>>&) { return Status::OK(); },
       .delete_from_sys_catalog_func =
           [](const LeaderEpoch&, XClusterOutboundReplicationGroupInfo*) { return Status::OK(); },
+      .setup_ddl_replication_extension_func =
+          [this](const NamespaceId& namespace_id, StdStatusCallback callback) -> Status {
+        EXPECT_TRUE(UseAutomaticMode());
+        for (const auto& table_name :
+             {xcluster::kDDLQueueTableName, xcluster::kDDLReplicatedTableName}) {
+          RETURN_NOT_OK(CreateTableIfNotExists(
+              namespace_id, /*table_id=*/table_name, table_name, xcluster::kDDLQueuePgSchemaName));
+        }
+
+        callback(Status::OK());
+        return Status::OK();
+      },
   };
 
   Result<scoped_refptr<NamespaceInfo>> GetNamespace(const NamespaceIdentifierPB& ns_identifier) {
@@ -335,31 +382,30 @@ class XClusterOutboundReplicationGroupMockedTest : public YBTest {
 
   void VerifyNamespaceCheckpointInfo(
       const TableId& table_id1, const TableId& table_id2, const NamespaceCheckpointInfo& ns_info,
-      bool sequences_data_included, bool skip_schema_name_check = false) {
+      bool all_tables_included = true, const PgSchemaName& table2_schema_name = kPgSchemaName) {
     EXPECT_FALSE(ns_info.initial_bootstrap_required);
-    ASSERT_EQ(ns_info.table_infos.size(), sequences_data_included ? 3 : 2);
+    ASSERT_EQ(ns_info.table_infos.size(), 2 + (all_tables_included ? OverheadStreamsCount() : 0));
     std::set<TableId> table_ids;
     for (const auto& table_info : ns_info.table_infos) {
       SCOPED_TRACE("table name: " + table_info.table_name);
       if (table_info.table_name == kTableName1) {
         ASSERT_EQ(table_info.table_id, table_id1);
+        EXPECT_EQ(table_info.pg_schema_name, kPgSchemaName);
       } else if (table_info.table_name == kTableName2) {
         ASSERT_EQ(table_info.table_id, table_id2);
+        EXPECT_EQ(table_info.pg_schema_name, table2_schema_name);
       } else if (table_info.table_name == "sequences_data") {
+        ASSERT_TRUE(all_tables_included);
         ASSERT_TRUE(xcluster::IsSequencesDataAlias(table_info.table_id));
+        EXPECT_TRUE(table_info.pg_schema_name.empty());
+      } else if (
+          table_info.table_name == xcluster::kDDLQueueTableName &&
+          table_info.pg_schema_name == xcluster::kDDLQueuePgSchemaName) {
+        ASSERT_TRUE(all_tables_included);
       } else {
         FAIL() << "Unexpected table name: " << table_info.table_name;
       }
-      if (!xcluster::IsSequencesDataAlias(table_info.table_id)) {
-        if (skip_schema_name_check) {
-          // Make sure it is not empty.
-          EXPECT_FALSE(table_info.pg_schema_name.empty());
-        } else {
-          EXPECT_EQ(table_info.pg_schema_name, kPgSchemaName);
-        }
-      } else {
-        EXPECT_TRUE(table_info.pg_schema_name.empty());
-      }
+
       EXPECT_FALSE(table_info.stream_id.IsNil());
       EXPECT_TRUE(xcluster_streams.contains(table_info.stream_id));
 
@@ -383,8 +429,8 @@ INSTANTIATE_TEST_CASE_P(
     SemiMode, XClusterOutboundReplicationGroupMockedParameterized, ::testing::Values(false));
 
 TEST_P(XClusterOutboundReplicationGroupMockedParameterized, TestMultipleTable) {
-  CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName);
-  CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2);
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName));
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2));
   auto outbound_rg_ptr = CreateReplicationGroup();
   auto& outbound_rg = *outbound_rg_ptr;
 
@@ -395,30 +441,11 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, TestMultipleTable) {
   auto ns_info_opt = ASSERT_RESULT(outbound_rg.GetNamespaceCheckpointInfo(kNamespaceId));
   ASSERT_TRUE(ns_info_opt.has_value());
 
-  if (UseAutomaticMode()) {
-    std::lock_guard l(mutex_);
-    // In automatic mode, sequences_data should have been created.
-    ASSERT_GT(namespace_tables[kPgSequencesDataNamespaceId].size(), 0);
-  }
-
   // We should have 2 streams for normal tables now.
   ASSERT_EQ(xcluster_streams.size(), 2 + OverheadStreamsCount());
 
   ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      kTableId1, kTableId2, *ns_info_opt, /*sequences_data_included=*/UseAutomaticMode(),
-      /*skip_schema_name_check=*/true));
-  for (const auto& table_info : ns_info_opt->table_infos) {
-    // Order is not deterministic so search with the table name.
-    if (table_info.table_name == kTableName1) {
-      EXPECT_EQ(table_info.pg_schema_name, kPgSchemaName);
-    } else if (table_info.table_name == kTableName2) {
-      EXPECT_EQ(table_info.pg_schema_name, kPgSchemaName2);
-    } else if (table_info.table_name == "sequences_data") {
-      EXPECT_EQ(table_info.pg_schema_name, "");
-    } else {
-      FAIL() << "unknown tablename " << table_info.table_name;
-    }
-  }
+      kTableId1, kTableId2, *ns_info_opt, /*all_tables_included=*/true, kPgSchemaName2));
 
   // Get the table info in a custom order.
   ns_info_opt = ASSERT_RESULT(outbound_rg.GetNamespaceCheckpointInfo(
@@ -426,8 +453,7 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, TestMultipleTable) {
   ASSERT_TRUE(ns_info_opt.has_value());
 
   ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      kTableId1, kTableId2, *ns_info_opt, /*sequences_data_included=*/false,
-      /*skip_schema_name_check=*/true));
+      kTableId1, kTableId2, *ns_info_opt, /*all_tables_included=*/false, kPgSchemaName2));
   ASSERT_EQ(ns_info_opt->table_infos[0].pg_schema_name, kPgSchemaName2);
   ASSERT_EQ(ns_info_opt->table_infos[1].pg_schema_name, kPgSchemaName);
   ASSERT_EQ(ns_info_opt->table_infos[0].table_name, kTableName2);
@@ -445,8 +471,8 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, TestMultipleTable) {
 }
 
 TEST_P(XClusterOutboundReplicationGroupMockedParameterized, AddDeleteNamespaces) {
-  CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName);
-  CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName);
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName));
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName));
 
   ANNOTATE_UNPROTECTED_WRITE(FLAGS_TEST_block_xcluster_checkpoint_namespace_task) = true;
 
@@ -454,8 +480,8 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, AddDeleteNamespaces)
   const NamespaceId namespace_id_2 = "ns_id_2";
   const TableId ns2_table_id_1 = "ns2_table_id_1", ns2_table_id_2 = "ns2_table_id_2";
   CreateNamespace(namespace_name_2, namespace_id_2);
-  CreateTable(namespace_id_2, ns2_table_id_1, kTableName1, kPgSchemaName);
-  CreateTable(namespace_id_2, ns2_table_id_2, kTableName2, kPgSchemaName);
+  ASSERT_OK(CreateTable(namespace_id_2, ns2_table_id_1, kTableName1, kPgSchemaName));
+  ASSERT_OK(CreateTable(namespace_id_2, ns2_table_id_2, kTableName2, kPgSchemaName));
 
   auto outbound_rg_ptr = CreateReplicationGroup();
   auto& outbound_rg = *outbound_rg_ptr;
@@ -490,8 +516,7 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, AddDeleteNamespaces)
 
   auto ns1_info_opt = ASSERT_RESULT(outbound_rg.GetNamespaceCheckpointInfo(kNamespaceId));
   ASSERT_TRUE(ns1_info_opt.has_value());
-  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      kTableId1, kTableId2, *ns1_info_opt, /*sequences_data_included=*/UseAutomaticMode()));
+  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(kTableId1, kTableId2, *ns1_info_opt));
 
   // Add the second namespace.
   ASSERT_OK(outbound_rg.AddNamespaceSync(kEpoch, namespace_id_2, kTimeout));
@@ -507,9 +532,7 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, AddDeleteNamespaces)
   // Validate the seconds namespace.
   auto ns2_info_opt = ASSERT_RESULT(outbound_rg.GetNamespaceCheckpointInfo(namespace_id_2));
   ASSERT_TRUE(ns2_info_opt.has_value());
-  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(
-      ns2_table_id_1, ns2_table_id_2, *ns2_info_opt,
-      /*sequences_data_included=*/UseAutomaticMode()));
+  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(ns2_table_id_1, ns2_table_id_2, *ns2_info_opt));
 
   ASSERT_OK(outbound_rg.RemoveNamespace(kEpoch, kNamespaceId, /*target_master_addresses=*/{}));
   ASSERT_FALSE(outbound_rg.HasNamespace(kNamespaceId));
@@ -536,7 +559,7 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, AddDeleteNamespaces)
 }
 
 TEST_P(XClusterOutboundReplicationGroupMockedParameterized, CreateTargetReplicationGroup) {
-  CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName);
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName));
 
   auto outbound_rg_ptr = CreateReplicationGroup();
   auto& outbound_rg = *outbound_rg_ptr;
@@ -548,6 +571,7 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, CreateTargetReplicat
   std::vector<TableId> expected_tables{kTableId1};
   if (UseAutomaticMode()) {
     expected_tables.push_back(xcluster::GetSequencesDataAliasForNamespace(kNamespaceId));
+    expected_tables.push_back(xcluster::kDDLQueueTableName);
   }
   EXPECT_CALL(
       xcluster_client,
@@ -611,8 +635,9 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, CreateTargetReplicat
 }
 
 TEST_P(XClusterOutboundReplicationGroupMockedParameterized, AddTable) {
-  auto table_info1 = CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName);
-  CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2);
+  auto table_info1 =
+      ASSERT_RESULT(CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName));
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2));
 
   auto outbound_rg = CreateReplicationGroup();
 
@@ -623,16 +648,13 @@ TEST_P(XClusterOutboundReplicationGroupMockedParameterized, AddTable) {
   auto ns_info = ASSERT_RESULT(outbound_rg->GetNamespaceCheckpointInfo(kNamespaceId));
   EXPECT_EQ(ns_info->table_infos.size(), 2 + OverheadStreamsCount());
 
-  // Same table should not get added twice.
-  ASSERT_OK(outbound_rg->AddTable(table_info1, kEpoch));
-
+  // Make sure AddTableToXClusterSourceTask is idempotent.
+  ASSERT_OK(AddTableToXClusterSourceTask(*table_info1));
   ASSERT_EQ(ns_info->table_infos.size(), 2 + OverheadStreamsCount());
 
   const TableName table_3 = "table3";
   const TableId table_id_3 = "table_id_3";
-  auto table_info3 = CreateTable(kNamespaceId, table_id_3, table_3, kPgSchemaName);
-
-  ASSERT_OK(outbound_rg->AddTable(table_info3, kEpoch));
+  auto table_info3 = ASSERT_RESULT(CreateTable(kNamespaceId, table_id_3, table_3, kPgSchemaName));
 
   ASSERT_EQ(xcluster_streams.size(), 3 + OverheadStreamsCount());
   ns_info = ASSERT_RESULT(outbound_rg->GetNamespaceCheckpointInfo(kNamespaceId));
@@ -650,12 +672,12 @@ TEST_F(XClusterOutboundReplicationGroupMockedTest, AddTableDuringCheckpoint) {
         "XClusterOutboundReplicationGroup::CreateStreamsForInitialBootstrap"}});
   sync_point_instance->EnableProcessing();
 
-  CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName);
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName));
 
   auto outbound_rg = CreateReplicationGroup();
   ASSERT_OK(outbound_rg->AddNamespace(kEpoch, kNamespaceId));
 
-  CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2);
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2));
   TEST_SYNC_POINT("TESTAddTableDuringCheckpoint::TableCreated");
 
   auto status = outbound_rg->WaitForCheckpoint(kNamespaceId, kTimeout);
@@ -678,8 +700,8 @@ TEST_F(XClusterOutboundReplicationGroupMockedTest, DropTableDuringCheckpoint) {
         "XClusterOutboundReplicationGroup::CreateStreamsForInitialBootstrap"}});
   sync_point_instance->EnableProcessing();
 
-  CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName);
-  CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2);
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName));
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName2));
 
   auto outbound_rg = CreateReplicationGroup();
   ASSERT_OK(outbound_rg->AddNamespace(kEpoch, kNamespaceId));
@@ -697,4 +719,38 @@ TEST_F(XClusterOutboundReplicationGroupMockedTest, DropTableDuringCheckpoint) {
   sync_point_instance->DisableProcessing();
 }
 
+// Make newly created tables are automatically checkpointed.
+TEST_P(XClusterOutboundReplicationGroupMockedParameterized, AutomaticCheckpointOfNewTables) {
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId1, kTableName1, kPgSchemaName));
+  auto outbound_rg = CreateReplicationGroup();
+
+  ASSERT_OK(outbound_rg->AddNamespaceSync(kEpoch, kNamespaceId, kTimeout));
+  ASSERT_TRUE(outbound_rg->HasNamespace(kNamespaceId));
+
+  auto ns_info_opt = ASSERT_RESULT(outbound_rg->GetNamespaceCheckpointInfo(kNamespaceId));
+  ASSERT_TRUE(ns_info_opt.has_value());
+  ASSERT_EQ(ns_info_opt->table_infos.size(), 1 + OverheadStreamsCount());
+
+  ASSERT_OK(CreateTable(kNamespaceId, kTableId2, kTableName2, kPgSchemaName));
+
+  ns_info_opt = ASSERT_RESULT(outbound_rg->GetNamespaceCheckpointInfo(kNamespaceId));
+  ASSERT_TRUE(ns_info_opt.has_value());
+  ASSERT_NO_FATALS(VerifyNamespaceCheckpointInfo(kTableId1, kTableId2, *ns_info_opt));
+}
+
+class XClusterOutboundReplicationGroupMockedAutomaticDDLMode
+    : public XClusterOutboundReplicationGroupMockedTest {
+ public:
+  bool UseAutomaticMode() override { return true; }
+};
+
+TEST_F(XClusterOutboundReplicationGroupMockedAutomaticDDLMode, AutoCreateSysTables) {
+  auto outbound_rg = CreateReplicationGroup();
+  ASSERT_OK(outbound_rg->AddNamespaceSync(kEpoch, kNamespaceId, kTimeout));
+
+  ASSERT_TRUE(TableExists(kPgSequencesDataNamespaceId, kPgSequencesDataTableId));
+  ASSERT_TRUE(TableExists(kNamespaceId, /*table_id=*/xcluster::kDDLQueueTableName));
+  ASSERT_TRUE(TableExists(kNamespaceId, /*table_id=*/xcluster::kDDLReplicatedTableName));
+}
+
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
index a1e1adbf62..4f6e734411 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group.cc
@@ -79,8 +79,8 @@ XClusterOutboundReplicationGroup::XClusterOutboundReplicationGroup(
     XClusterOutboundReplicationGroupTaskFactory& task_factory)
     : CatalogEntityWithTasks(std::move(tasks_tracker)),
       helper_functions_(std::move(helper_functions)),
+      automatic_ddl_mode_(outbound_replication_group_pb.automatic_ddl_mode()),
       task_factory_(task_factory) {
-  automatic_ddl_mode_ = outbound_replication_group_pb.automatic_ddl_mode();
   outbound_rg_info_ = std::make_unique<XClusterOutboundReplicationGroupInfo>(replication_group_id);
   outbound_rg_info_->Load(outbound_replication_group_pb);
 }
@@ -275,13 +275,13 @@ Result<bool> XClusterOutboundReplicationGroup::MarkBootstrapTablesAsCheckpointed
         table_designators.begin(), table_designators.end(), std::inserter(tables, tables.begin()),
         [](const auto& table_designator) { return table_designator.id; });
 
-    std::set<TableId> checkpointed_tables;
-    std::transform(
-        ns_info->table_infos().begin(), ns_info->table_infos().end(),
-        std::inserter(checkpointed_tables, checkpointed_tables.begin()),
-        [](const auto& table_info) { return table_info.first; });
-
-    auto diff = STLSetSymmetricDifference(tables, checkpointed_tables);
+    std::set<TableId> initial_tables;
+    for (const auto& [table_id, table_info] : ns_info->table_infos()) {
+      if (table_info.is_part_of_initial_bootstrap()) {
+        initial_tables.insert(table_id);
+      }
+    }
+    auto diff = STLSetSymmetricDifference(tables, initial_tables);
     SCHECK_FORMAT(
         diff.empty(), IllegalState,
         "List of tables changed during xCluster checkpoint of replication group $0: $1", ToString(),
@@ -353,8 +353,9 @@ XClusterOutboundReplicationGroup::CreateNamespaceInfo(
           AutomaticDDLMode() && FLAGS_TEST_xcluster_enable_sequence_replication)));
   VLOG_WITH_PREFIX_AND_FUNC(1) << "Tables: " << yb::ToString(table_designators);
 
+  // In automatic DDL mode the DDL queue table and sequences tables will be created automatically.
   SCHECK(
-      !table_designators.empty(), InvalidArgument,
+      AutomaticDDLMode() || !table_designators.empty(), InvalidArgument,
       "Database should have at least one table in order to be part of xCluster replication");
 
   auto yb_ns_info = VERIFY_RESULT(GetYbNamespaceInfo(namespace_id));
@@ -404,6 +405,36 @@ Status XClusterOutboundReplicationGroup::AddTableToInitialBootstrapMapping(
   return Upsert(l, epoch);
 }
 
+Status XClusterOutboundReplicationGroup::SetDDLQueueTableIsPartOfInitialBootstrap(
+    const NamespaceId& namespace_id, const LeaderEpoch& epoch) {
+  auto table_designators = VERIFY_RESULT(
+      helper_functions_.get_tables_func(namespace_id, /*include_sequences_data=*/false));
+
+  std::lock_guard mutex_lock(mutex_);
+  auto l = VERIFY_RESULT(LockForWrite());
+
+  auto* ns_info = VERIFY_RESULT(GetNamespaceInfo(namespace_id));
+  bool table_found = false;
+  for (const auto& table_designator : table_designators) {
+    if (!table_designator.table_info->IsXClusterDDLReplicationDDLQueueTable()) {
+      continue;
+    }
+    table_found = true;
+    const auto& table_id = table_designator.id;
+    auto namespace_table_info = FindOrNull(*ns_info->mutable_table_infos(), table_id);
+    SCHECK_FORMAT(
+        namespace_table_info, IllegalState,
+        "Table $0 not found in namespace info of replication group $1", table_id, ToString());
+    namespace_table_info->set_is_part_of_initial_bootstrap(true);
+    break;
+  }
+  SCHECK(
+      table_found, IllegalState, "xCluster DDL queue table not found in namespace $0 of $1",
+      namespace_id, ToString());
+
+  return Upsert(l, epoch);
+}
+
 Result<bool> XClusterOutboundReplicationGroup::AddNamespaceInternal(
     const NamespaceId& namespace_id, XClusterOutboundReplicationGroupInfo::WriteLock& l,
     const LeaderEpoch& epoch) {
@@ -611,8 +642,8 @@ XClusterOutboundReplicationGroup::GetNamespaceCheckpointInfo(
     std::unordered_map<TableSchemaNamePair, TableDesignator, TableSchemaNamePairHash>
         table_names_map;
     for (auto& table_descriptor : all_tables) {
-      table_names_map[{table_descriptor.name, table_descriptor.pgschema_name}] =
-          table_descriptor;
+      table_names_map.insert(
+          {{table_descriptor.name(), table_descriptor.pgschema_name()}, table_descriptor});
     }
 
     for (auto& table : table_names) {
@@ -621,7 +652,7 @@ XClusterOutboundReplicationGroup::GetNamespaceCheckpointInfo(
           Format("Table $0.$1 not found in namespace $2", table.second, table.first, namespace_id));
 
       // Order of elements in table_infos should match the order in input table_names.
-      table_descriptors.push_back(table_names_map[table]);
+      table_descriptors.emplace_back(table_names_map.at(table));
     }
   } else {
     table_descriptors = std::move(all_tables);
@@ -653,8 +684,8 @@ XClusterOutboundReplicationGroup::GetNamespaceCheckpointInfo(
     NamespaceCheckpointInfo::TableInfo ns_table_info{
         .table_id = table_id,
         .stream_id = std::move(stream_id),
-        .table_name = table_descriptor.name,
-        .pg_schema_name = table_descriptor.pgschema_name};
+        .table_name = table_descriptor.name(),
+        .pg_schema_name = table_descriptor.pgschema_name()};
 
     ns_info.table_infos.emplace_back(std::move(ns_table_info));
   }
@@ -757,7 +788,7 @@ Status XClusterOutboundReplicationGroup::CreateXClusterReplication(
   auto target_uuid =
       VERIFY_RESULT(remote_client->GetXClusterClient().SetupDbScopedUniverseReplication(
           Id(), source_master_addresses, namespace_names, namespace_ids, source_table_ids,
-          bootstrap_ids, outbound_group.automatic_ddl_mode()));
+          bootstrap_ids, AutomaticDDLMode()));
 
   auto* target_universe_info = outbound_group.mutable_target_universe_info();
 
@@ -1176,8 +1207,9 @@ Result<std::string> XClusterOutboundReplicationGroup::GetStreamId(
   return table_info->stream_id();
 }
 
-bool XClusterOutboundReplicationGroup::AutomaticDDLMode() const {
-  return automatic_ddl_mode_;
+Status XClusterOutboundReplicationGroup::SetupDDLReplicationExtension(
+    const NamespaceId& namespace_id, StdStatusCallback callback) const {
+  return helper_functions_.setup_ddl_replication_extension_func(namespace_id, std::move(callback));
 }
 
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group.h b/src/yb/master/xcluster/xcluster_outbound_replication_group.h
index d9d4fd0914..f28691da93 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group.h
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group.h
@@ -62,6 +62,8 @@ class XClusterOutboundReplicationGroup
         upsert_to_sys_catalog_func;
     const std::function<Status(const LeaderEpoch& epoch, XClusterOutboundReplicationGroupInfo*)>
         delete_from_sys_catalog_func;
+    const std::function<Status(const NamespaceId&, StdStatusCallback)>
+        setup_ddl_replication_extension_func;
   };
 
   explicit XClusterOutboundReplicationGroup(
@@ -131,6 +133,9 @@ class XClusterOutboundReplicationGroup
 
   void StartPostLoadTasks(const LeaderEpoch& epoch) EXCLUDES(mutex_);
 
+  Status SetDDLQueueTableIsPartOfInitialBootstrap(
+      const NamespaceId& namespace_id, const LeaderEpoch& epoch) EXCLUDES(mutex_);
+
   Status RepairAddTable(
       const NamespaceId& namespace_id, const TableId& table_id, const xrepl::StreamId& stream_id,
       const LeaderEpoch& epoch) EXCLUDES(mutex_);
@@ -142,10 +147,14 @@ class XClusterOutboundReplicationGroup
   Result<std::string> GetStreamId(const NamespaceId& namespace_id, const TableId& table_id) const
       EXCLUDES(mutex_);
 
-  bool AutomaticDDLMode() const;
+  bool AutomaticDDLMode() const { return automatic_ddl_mode_; }
+
+  Status SetupDDLReplicationExtension(
+      const NamespaceId& namespace_id, StdStatusCallback callback) const;
 
  private:
   friend class XClusterOutboundReplicationGroupMocked;
+  friend class XClusterOutboundReplicationGroupMockedTest;
   friend class AddTableToXClusterSourceTask;
   friend class XClusterCheckpointNamespaceTask;
 
@@ -193,6 +202,9 @@ class XClusterOutboundReplicationGroup
       const NamespaceId& namespace_id, const TableId& table_id, const LeaderEpoch& epoch)
       EXCLUDES(mutex_);
 
+  Status PopulateTablesForInitalBootstrap(const NamespaceId& namespace_id, const LeaderEpoch& epoch)
+      EXCLUDES(mutex_);
+
   // Returns the NamespaceInfoPB for the given namespace_id. If its not found returns a NotFound
   // status. Caller must hold the WriteLock.
   Result<NamespaceInfoPB*> GetNamespaceInfo(const NamespaceId& namespace_id) REQUIRES(mutex_);
@@ -257,9 +269,9 @@ class XClusterOutboundReplicationGroup
   mutable std::shared_mutex mutex_;
   std::unique_ptr<XClusterOutboundReplicationGroupInfo> outbound_rg_info_;
 
-  XClusterOutboundReplicationGroupTaskFactory& task_factory_;
+  const bool automatic_ddl_mode_;
 
-  bool automatic_ddl_mode_;
+  XClusterOutboundReplicationGroupTaskFactory& task_factory_;
 
   DISALLOW_COPY_AND_ASSIGN(XClusterOutboundReplicationGroup);
 };
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.cc b/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.cc
index e31d5d6c4b..c9af8faacf 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.cc
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.cc
@@ -76,6 +76,39 @@ Status XClusterCheckpointNamespaceTask::FirstStep() {
         namespace_id_, sequence_table_alias_id, epoch_));
   }
 
+  return SetupDDLReplicationExtension();
+}
+
+Status XClusterCheckpointNamespaceTask::SetupDDLReplicationExtension() {
+  if (outbound_replication_group_.AutomaticDDLMode()) {
+    return outbound_replication_group_.SetupDDLReplicationExtension(
+        namespace_id_,
+        std::bind(
+            &XClusterCheckpointNamespaceTask::SetupDDLReplicationExtensionCallback, this, _1));
+  }
+
+  ScheduleNextStep(
+      std::bind(&XClusterCheckpointNamespaceTask::CreateStreams, this), "CreateStreams");
+
+  return Status::OK();
+}
+
+void XClusterCheckpointNamespaceTask::SetupDDLReplicationExtensionCallback(Status status) {
+  ScheduleNextStep(
+      std::bind(&XClusterCheckpointNamespaceTask::PrepareDDLQueueTable, this, std::move(status)),
+      "PrepareDDLQueueTable");
+}
+
+Status XClusterCheckpointNamespaceTask::PrepareDDLQueueTable(Status status) {
+  RETURN_NOT_OK_PREPEND(status, "Failed to setup xCluster DDL replication extension");
+
+  // If the DDL queue table was freshly created in the previous step, then we would have
+  // automatically created a stream for it and added it to the namespace map. However this table
+  // must be marked as part of the initial bootstrap so that it gets included in the target as part
+  // of the replication setup.
+  RETURN_NOT_OK(
+      outbound_replication_group_.SetDDLQueueTableIsPartOfInitialBootstrap(namespace_id_, epoch_));
+
   ScheduleNextStep(
       std::bind(&XClusterCheckpointNamespaceTask::CreateStreams, this), "CreateStreams");
   return Status::OK();
diff --git a/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.h b/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.h
index 9ced3b6efc..ba72520fd9 100644
--- a/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.h
+++ b/src/yb/master/xcluster/xcluster_outbound_replication_group_tasks.h
@@ -46,6 +46,10 @@ class XClusterCheckpointNamespaceTask : public MultiStepCatalogEntityTask {
 
  private:
   Status CreateStreams();
+  Status SetupDDLReplicationExtension();
+  void SetupDDLReplicationExtensionCallback(Status status);
+  Status PrepareDDLQueueTable(Status status);
+
   Status CheckpointStreams();
   void CheckpointStreamsCallback(XClusterCheckpointStreamsResult result);
   Status MarkTablesAsCheckpointed(XClusterCheckpointStreamsResult result);
diff --git a/src/yb/master/xcluster/xcluster_source_manager.cc b/src/yb/master/xcluster/xcluster_source_manager.cc
index 5b822822a2..61828f43f2 100644
--- a/src/yb/master/xcluster/xcluster_source_manager.cc
+++ b/src/yb/master/xcluster/xcluster_source_manager.cc
@@ -42,6 +42,7 @@ DEFINE_RUNTIME_bool(enable_tablet_split_of_xcluster_bootstrapping_tables, false,
 DECLARE_int32(master_yb_client_default_timeout_ms);
 DECLARE_uint32(cdc_wal_retention_time_secs);
 DECLARE_bool(TEST_disable_cdc_state_insert_on_setup);
+DECLARE_uint32(xcluster_ysql_statement_timeout_sec);
 
 using namespace std::placeholders;
 
@@ -195,7 +196,7 @@ XClusterSourceManager::InitOutboundReplicationGroup(
             return tserver::CreateSequencesDataTable(
                 client.get(),
                 CoarseMonoClock::now() +
-                    MonoDelta::FromMilliseconds(FLAGS_master_yb_client_default_timeout_ms));
+                    MonoDelta::FromSeconds(FLAGS_xcluster_ysql_statement_timeout_sec));
           },
       .get_namespace_func =
           [&catalog_manager = catalog_manager_](const NamespaceIdentifierPB& ns_identifier) {
@@ -229,6 +230,8 @@ XClusterSourceManager::InitOutboundReplicationGroup(
               const LeaderEpoch& epoch, XClusterOutboundReplicationGroupInfo* info) {
             return sys_catalog.Delete(epoch.leader_term, info);
           },
+      .setup_ddl_replication_extension_func =
+          std::bind(&XClusterSourceManager::SetupDDLReplicationExtension, this, _1, _2),
   };
 
   return std::make_shared<XClusterOutboundReplicationGroup>(
@@ -1198,4 +1201,14 @@ Status XClusterSourceManager::ValidateSplitCandidateTable(const TableId& table_i
   return Status::OK();
 }
 
+Status XClusterSourceManager::SetupDDLReplicationExtension(
+    const NamespaceId& namespace_id, StdStatusCallback callback) const {
+  auto namespace_name = VERIFY_RESULT(catalog_manager_.FindNamespaceById(namespace_id))->name();
+
+  return master::SetupDDLReplicationExtension(
+      catalog_manager_, namespace_name, XClusterDDLReplicationRole::kSource,
+      CoarseMonoClock::now() + MonoDelta::FromSeconds(FLAGS_xcluster_ysql_statement_timeout_sec),
+      std::move(callback));
+}
+
 }  // namespace yb::master
diff --git a/src/yb/master/xcluster/xcluster_source_manager.h b/src/yb/master/xcluster/xcluster_source_manager.h
index 0edac3a23b..88c5046c3b 100644
--- a/src/yb/master/xcluster/xcluster_source_manager.h
+++ b/src/yb/master/xcluster/xcluster_source_manager.h
@@ -242,6 +242,9 @@ class XClusterSourceManager {
   bool DoesTableHaveAnyBootstrappingStream(const TableId& table_id) const
       EXCLUDES(tables_to_stream_map_mutex_);
 
+  Status SetupDDLReplicationExtension(
+      const NamespaceId& namespace_id, StdStatusCallback callback) const;
+
   Master& master_;
   CatalogManager& catalog_manager_;
   SysCatalogTable& sys_catalog_;
diff --git a/src/yb/master/xrepl_catalog_manager.cc b/src/yb/master/xrepl_catalog_manager.cc
index 6276a74eb1..9c268d3a86 100644
--- a/src/yb/master/xrepl_catalog_manager.cc
+++ b/src/yb/master/xrepl_catalog_manager.cc
@@ -40,6 +40,7 @@
 #include "yb/master/master_ddl.pb.h"
 #include "yb/master/master_heartbeat.pb.h"
 #include "yb/master/master_replication.pb.h"
+#include "yb/master/master_snapshot_coordinator.h"
 #include "yb/master/master_util.h"
 #include "yb/master/snapshot_transfer_manager.h"
 
diff --git a/src/yb/tserver/tablet_server.cc b/src/yb/tserver/tablet_server.cc
index ec41ee58c6..122e9c31f8 100644
--- a/src/yb/tserver/tablet_server.cc
+++ b/src/yb/tserver/tablet_server.cc
@@ -1598,4 +1598,11 @@ void TabletServer::SetCronLeaderLease(MonoTime cron_leader_lease_end) {
   SharedObject().SetCronLeaderLease(cron_leader_lease_end);
 }
 
+Result<pgwrapper::PGConn> TabletServer::CreateInternalPGConn(
+    const std::string& database_name, const std::optional<CoarseTimePoint>& deadline) {
+  return pgwrapper::CreateInternalPGConnBuilder(
+             pgsql_proxy_bind_address(), database_name, GetSharedMemoryPostgresAuthKey(), deadline)
+      .Connect();
+}
+
 }  // namespace yb::tserver
diff --git a/src/yb/tserver/tablet_server.h b/src/yb/tserver/tablet_server.h
index 0a89f3a240..927a3b8783 100644
--- a/src/yb/tserver/tablet_server.h
+++ b/src/yb/tserver/tablet_server.h
@@ -411,6 +411,9 @@ class TabletServer : public DbServerBase, public TabletServerIf {
 
   void SetCronLeaderLease(MonoTime cron_leader_lease_end);
 
+  Result<pgwrapper::PGConn> CreateInternalPGConn(
+      const std::string& database_name, const std::optional<CoarseTimePoint>& deadline) override;
+
   std::atomic<bool> initted_{false};
 
   // If true, all heartbeats will be seen as failed.
diff --git a/src/yb/tserver/tablet_server_interface.h b/src/yb/tserver/tablet_server_interface.h
index c3671efd8e..74c77b7f2b 100644
--- a/src/yb/tserver/tablet_server_interface.h
+++ b/src/yb/tserver/tablet_server_interface.h
@@ -36,6 +36,10 @@ namespace yb {
 
 class MemTracker;
 
+namespace pgwrapper {
+class PGConn;
+}  // namespace pgwrapper
+
 namespace server {
 class RpcAndWebServerBase;
 class YCQLStatementStatsProvider;
@@ -115,6 +119,9 @@ class TabletServerIf : public LocalTabletServer {
 
   virtual Result<std::vector<tablet::TabletStatusPB>> GetLocalTabletsMetadata() const = 0;
   virtual Result<std::vector<TserverMetricsInfoPB>> GetMetrics() const = 0;
+
+  virtual Result<pgwrapper::PGConn> CreateInternalPGConn(
+      const std::string& database_name, const std::optional<CoarseTimePoint>& deadline) = 0;
 };
 
 } // namespace tserver
diff --git a/src/yb/tserver/tablet_service.cc b/src/yb/tserver/tablet_service.cc
index 274746da66..eee6e82450 100644
--- a/src/yb/tserver/tablet_service.cc
+++ b/src/yb/tserver/tablet_service.cc
@@ -3417,6 +3417,28 @@ void TabletServiceImpl::ReleaseObjectLocks(
   }
 }
 
+void TabletServiceImpl::AdminExecutePgsql(
+    const AdminExecutePgsqlRequestPB* req, AdminExecutePgsqlResponsePB* resp,
+    rpc::RpcContext context) {
+  auto execute_pg_sql = [&req, &context, &server = server_]() -> Status {
+    const auto& deadline = context.GetClientDeadline();
+    auto pg_conn = VERIFY_RESULT(server->CreateInternalPGConn(req->database_name(), deadline));
+    for (const auto& stmt : req->pgsql_statements()) {
+      SCHECK_LT(
+          CoarseMonoClock::Now(), deadline, TimedOut, "Timed out while executing Ysql statements");
+      RETURN_NOT_OK(pg_conn.Execute(stmt));
+    }
+    return Status::OK();
+  };
+
+  auto status = execute_pg_sql();
+  if (!status.ok()) {
+    SetupErrorAndRespond(resp->mutable_error(), status, &context);
+  } else {
+    context.RespondSuccess();
+  }
+}
+
 void TabletServiceAdminImpl::TestRetry(
     const TestRetryRequestPB* req, TestRetryResponsePB* resp, rpc::RpcContext context) {
   if (!CheckUuidMatchOrRespond(server_->tablet_manager(), "TestRetry", req, resp, &context)) {
diff --git a/src/yb/tserver/tablet_service.h b/src/yb/tserver/tablet_service.h
index bc1fcf0a75..9fb1c1e996 100644
--- a/src/yb/tserver/tablet_service.h
+++ b/src/yb/tserver/tablet_service.h
@@ -231,6 +231,10 @@ class TabletServiceImpl : public TabletServerServiceIf, public ReadTabletProvide
       const ReleaseObjectLockRequestPB* req, ReleaseObjectLockResponsePB* resp,
       rpc::RpcContext context) override;
 
+  void AdminExecutePgsql(
+      const AdminExecutePgsqlRequestPB* req, AdminExecutePgsqlResponsePB* resp,
+      rpc::RpcContext context) override;
+
   void Shutdown() override;
 
  private:
diff --git a/src/yb/tserver/tserver_service.proto b/src/yb/tserver/tserver_service.proto
index 5b4ca24824..baee84b4f5 100644
--- a/src/yb/tserver/tserver_service.proto
+++ b/src/yb/tserver/tserver_service.proto
@@ -138,6 +138,9 @@ service TabletServerService {
       returns (ReleaseObjectLockResponsePB);
 
   rpc GetMetrics(GetMetricsRequestPB) returns (GetMetricsResponsePB);
+
+  rpc AdminExecutePgsql(AdminExecutePgsqlRequestPB)
+      returns (AdminExecutePgsqlResponsePB);
 }
 
 // Note: Either among transactions_by_tablet or transaction_ids should be set. Both the fields
@@ -552,3 +555,13 @@ message StartRemoteSnapshotTransferRequestPB {
 message StartRemoteSnapshotTransferResponsePB {
   optional TabletServerErrorPB error = 1;
 }
+
+message AdminExecutePgsqlRequestPB {
+  required string database_name = 1;
+  // The list of SQL statements to execute. Execution will stop at the first error.
+  repeated string pgsql_statements = 2;
+}
+
+message AdminExecutePgsqlResponsePB {
+  optional TabletServerErrorPB error = 1;
+}
diff --git a/src/yb/yql/pgwrapper/libpq_utils.cc b/src/yb/yql/pgwrapper/libpq_utils.cc
index 39c0a81a3c..2e9fa46b67 100644
--- a/src/yb/yql/pgwrapper/libpq_utils.cc
+++ b/src/yb/yql/pgwrapper/libpq_utils.cc
@@ -807,7 +807,7 @@ PGConnBuilder CreateInternalPGConnBuilder(
     const HostPort& pgsql_proxy_bind_address, const std::string& database_name,
     uint64_t postgres_auth_key, const std::optional<CoarseTimePoint>& deadline) {
   size_t connect_timeout = 0;
-  if (deadline) {
+  if (deadline && *deadline != CoarseTimePoint::max()) {
     // By default, connect_timeout is 0, meaning infinite. 1 is automatically converted to 2, so set
     // it to at least 2 in the first place. See connectDBComplete.
     connect_timeout = static_cast<size_t>(
