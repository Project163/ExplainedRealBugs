diff --git a/solr/CHANGES.txt b/solr/CHANGES.txt
index 10b795cfa09..79f1d53a38d 100644
--- a/solr/CHANGES.txt
+++ b/solr/CHANGES.txt
@@ -8,6 +8,13 @@ https://github.com/apache/lucene-solr/blob/master/solr/solr-ref-guide/src/solr-u
 
 Consult the LUCENE_CHANGES.txt file for additional, low level, changes in this release.
 
+Upgrade Notes
+---------------------
+
+* SOLR-12847: maxShardsPerNode parameter has been removed because it was broken and
+inconsistent with other replica placement strategies. Other relevant placement strategies
+should be used instead, such as autoscaling policy or rules-based placement.
+
 New Features
 ---------------------
 * SOLR-14440: Introduce new Certificate Authentication Plugin to load Principal from certificate subject. (Mike Drob)
@@ -86,6 +93,8 @@ Other Changes
 * LUCENE-9411: Fail complation on warnings, 9x gradle-only (Erick Erickson, Dawid Weiss)
   Deserves mention here as well as Lucene CHANGES.txt since it affects both.
 
+* SOLR-12847: Remove support for maxShardsPerNode.
+
 Bug Fixes
 ---------------------
 * SOLR-14546: Fix for a relatively hard to hit issue in OverseerTaskProcessor that could lead to out of order execution
diff --git a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestZKPropertiesWriter.java b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestZKPropertiesWriter.java
index c4f3f7a64df..54a5e1225db 100644
--- a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestZKPropertiesWriter.java
+++ b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestZKPropertiesWriter.java
@@ -104,7 +104,6 @@ public class TestZKPropertiesWriter extends SolrCloudTestCase {
   @SuppressWarnings({"unchecked"})
   public void testZKPropertiesWriter() throws Exception {
     CollectionAdminRequest.createCollectionWithImplicitRouter("collection1", "conf", "1", 1)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
 
     // DIH talks core, SolrCloud talks collection.
diff --git a/solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTROnSolrCloud.java b/solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTROnSolrCloud.java
index c8f96d1ca64..21b71c3e5ec 100644
--- a/solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTROnSolrCloud.java
+++ b/solr/contrib/ltr/src/test/org/apache/solr/ltr/TestLTROnSolrCloud.java
@@ -53,11 +53,10 @@ public class TestLTROnSolrCloud extends TestRerankBase {
 
     int numberOfShards = random().nextInt(4)+1;
     int numberOfReplicas = random().nextInt(2)+1;
-    int maxShardsPerNode = random().nextInt(4)+1;
 
-    int numberOfNodes = (numberOfShards*numberOfReplicas + (maxShardsPerNode-1))/maxShardsPerNode;
+    int numberOfNodes = numberOfShards * numberOfReplicas;
 
-    setupSolrCluster(numberOfShards, numberOfReplicas, numberOfNodes, maxShardsPerNode);
+    setupSolrCluster(numberOfShards, numberOfReplicas, numberOfNodes);
 
 
   }
@@ -197,7 +196,7 @@ public class TestLTROnSolrCloud extends TestRerankBase {
         queryResponse.getResults().get(7).get("features").toString());
   }
 
-  private void setupSolrCluster(int numShards, int numReplicas, int numServers, int maxShardsPerNode) throws Exception {
+  private void setupSolrCluster(int numShards, int numReplicas, int numServers) throws Exception {
     JettyConfig jc = buildJettyConfig("/solr");
     jc = JettyConfig.builder(jc).withServlets(extraServlets).build();
     solrCluster = new MiniSolrCloudCluster(numServers, tmpSolrHome.toPath(), jc);
@@ -206,7 +205,7 @@ public class TestLTROnSolrCloud extends TestRerankBase {
 
     solrCluster.getSolrClient().setDefaultCollection(COLLECTION);
 
-    createCollection(COLLECTION, "conf1", numShards, numReplicas, maxShardsPerNode);
+    createCollection(COLLECTION, "conf1", numShards, numReplicas);
     indexDocuments(COLLECTION);
     for (JettySolrRunner solrRunner : solrCluster.getJettySolrRunners()) {
       if (!solrRunner.getCoreContainer().getCores().isEmpty()){
@@ -219,12 +218,11 @@ public class TestLTROnSolrCloud extends TestRerankBase {
   }
 
 
-  private void createCollection(String name, String config, int numShards, int numReplicas, int maxShardsPerNode)
+  private void createCollection(String name, String config, int numShards, int numReplicas)
       throws Exception {
     CollectionAdminResponse response;
     CollectionAdminRequest.Create create =
         CollectionAdminRequest.createCollection(name, config, numShards, numReplicas);
-    create.setMaxShardsPerNode(maxShardsPerNode);
     response = create.process(solrCluster.getSolrClient());
 
     if (response.getStatus() != 0 || response.getErrorMessages() != null) {
diff --git a/solr/contrib/prometheus-exporter/src/test/org/apache/solr/prometheus/PrometheusExporterTestBase.java b/solr/contrib/prometheus-exporter/src/test/org/apache/solr/prometheus/PrometheusExporterTestBase.java
index f0b9d2cdc22..81069d7131f 100644
--- a/solr/contrib/prometheus-exporter/src/test/org/apache/solr/prometheus/PrometheusExporterTestBase.java
+++ b/solr/contrib/prometheus-exporter/src/test/org/apache/solr/prometheus/PrometheusExporterTestBase.java
@@ -31,8 +31,7 @@ public class PrometheusExporterTestBase extends SolrCloudTestCase {
   public static final String CONF_DIR = getFile("solr/" + COLLECTION + "/conf").getAbsolutePath();
   public static final int NUM_SHARDS = 2;
   public static final int NUM_REPLICAS = 2;
-  public static final int MAX_SHARDS_PER_NODE = 1;
-  public static final int NUM_NODES = (NUM_SHARDS * NUM_REPLICAS + (MAX_SHARDS_PER_NODE - 1)) / MAX_SHARDS_PER_NODE;
+  public static final int NUM_NODES = NUM_SHARDS * NUM_REPLICAS;
   public static final int TIMEOUT = 60;
 
   public static final ImmutableMap<String, Double> FACET_VALUES = ImmutableMap.<String, Double>builder()
@@ -66,7 +65,6 @@ public class PrometheusExporterTestBase extends SolrCloudTestCase {
 
     CollectionAdminRequest
         .createCollection(COLLECTION, CONF_NAME, NUM_SHARDS, NUM_REPLICAS)
-        .setMaxShardsPerNode(MAX_SHARDS_PER_NODE)
         .process(cluster.getSolrClient());
 
     AbstractDistribZkTestBase
diff --git a/solr/core/src/java/org/apache/solr/cloud/api/collections/AddReplicaCmd.java b/solr/core/src/java/org/apache/solr/cloud/api/collections/AddReplicaCmd.java
index 95fffa47f37..1c2146bbfb3 100644
--- a/solr/core/src/java/org/apache/solr/cloud/api/collections/AddReplicaCmd.java
+++ b/solr/core/src/java/org/apache/solr/cloud/api/collections/AddReplicaCmd.java
@@ -62,6 +62,7 @@ import org.apache.solr.common.cloud.ReplicaPosition;
 import org.apache.solr.common.cloud.Slice;
 import org.apache.solr.common.cloud.ZkNodeProps;
 import org.apache.solr.common.cloud.ZkStateReader;
+import org.apache.solr.common.params.CollectionAdminParams;
 import org.apache.solr.common.params.CommonAdminParams;
 import org.apache.solr.common.params.CoreAdminParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -76,12 +77,6 @@ import org.slf4j.LoggerFactory;
 public class AddReplicaCmd implements OverseerCollectionMessageHandler.Cmd {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
-  /**
-   * When AddReplica is called with this set to true, then we do not try to find node assignments
-   * for the add replica API. If set to true, a valid "node" should be specified.
-   */
-  public static final String SKIP_NODE_ASSIGNMENT = "skipNodeAssignment";
-
   private final OverseerCollectionMessageHandler ocmh;
 
   public AddReplicaCmd(OverseerCollectionMessageHandler ocmh) {
@@ -233,7 +228,7 @@ public class AddReplicaCmd implements OverseerCollectionMessageHandler.Cmd {
             ZkStateReader.SHARD_ID_PROP, withCollectionShard,
             "node", createReplica.node,
             // since we already computed node assignments (which include assigning a node for this withCollection replica) we want to skip the assignment step
-            SKIP_NODE_ASSIGNMENT, "true",
+            CollectionAdminParams.SKIP_NODE_ASSIGNMENT, "true",
             CommonAdminParams.WAIT_FOR_FINAL_STATE, Boolean.TRUE.toString()); // set to true because we want `withCollection` to be ready after this collection is created
         addReplica(clusterState, props, results, null);
       }
@@ -347,7 +342,7 @@ public class AddReplicaCmd implements OverseerCollectionMessageHandler.Cmd {
                                                             EnumMap<Replica.Type, Integer> replicaTypeVsCount,
                                                             AtomicReference< PolicyHelper.SessionWrapper> sessionWrapper) throws IOException, InterruptedException {
     boolean skipCreateReplicaInClusterState = message.getBool(SKIP_CREATE_REPLICA_IN_CLUSTER_STATE, false);
-    boolean skipNodeAssignment = message.getBool(SKIP_NODE_ASSIGNMENT, false);
+    boolean skipNodeAssignment = message.getBool(CollectionAdminParams.SKIP_NODE_ASSIGNMENT, false);
     String sliceName = message.getStr(SHARD_ID_PROP);
     DocCollection collection = clusterState.getCollection(collectionName);
 
diff --git a/solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java b/solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java
index b577340845e..98a399a79d5 100644
--- a/solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java
+++ b/solr/core/src/java/org/apache/solr/cloud/api/collections/Assign.java
@@ -322,8 +322,8 @@ public class Assign {
 
   // Only called from addReplica (and by extension createShard) (so far).
   //
-  // Gets a list of candidate nodes to put the required replica(s) on. Throws errors if not enough replicas
-  // could be created on live nodes given maxShardsPerNode, Replication factor (if from createShard) etc.
+  // Gets a list of candidate nodes to put the required replica(s) on. Throws errors if the AssignStrategy
+  // can't allocate valid positions.
   @SuppressWarnings({"unchecked"})
   public static List<ReplicaPosition> getNodesForNewReplicas(ClusterState clusterState, String collectionName,
                                                           String shard, int nrtReplicas, int tlogReplicas, int pullReplicas,
@@ -331,8 +331,7 @@ public class Assign {
     log.debug("getNodesForNewReplicas() shard: {} , nrtReplicas : {} , tlogReplicas: {} , pullReplicas: {} , createNodeSet {}"
         , shard, nrtReplicas, tlogReplicas, pullReplicas, createNodeSet);
     DocCollection coll = clusterState.getCollection(collectionName);
-    int maxShardsPerNode = coll.getMaxShardsPerNode() == -1 ? Integer.MAX_VALUE : coll.getMaxShardsPerNode();
-    List<String> createNodeList;
+    List<String> createNodeList = null;
 
     if (createNodeSet instanceof List) {
       createNodeList = (List<String>) createNodeSet;
@@ -346,22 +345,6 @@ public class Assign {
     // be satisfied which then requires study to diagnose the issue.
     checkLiveNodes(createNodeList,clusterState);
 
-    if (createNodeList == null) { // We only care if we haven't been told to put new replicas on specific nodes.
-      HashMap<String, ReplicaCount> nodeNameVsShardCount = getNodeNameVsShardCount(collectionName, clusterState, null);
-      long availableSlots = 0;
-      for (Map.Entry<String, ReplicaCount> ent : nodeNameVsShardCount.entrySet()) {
-        //ADDREPLICA can put more than maxShardsPerNode on an instance, so this test is necessary.
-        if (maxShardsPerNode > ent.getValue().thisCollectionNodes) {
-          availableSlots += (maxShardsPerNode - ent.getValue().thisCollectionNodes);
-        }
-      }
-      if (availableSlots < nrtReplicas + tlogReplicas + pullReplicas) {
-        throw new AssignmentException(
-            String.format(Locale.ROOT, "Cannot create %d new replicas for collection %s given the current number of eligible live nodes %d and a maxShardsPerNode of %d",
-                nrtReplicas, collectionName, nodeNameVsShardCount.size(), maxShardsPerNode));
-      }
-    }
-
     AssignRequest assignRequest = new AssignRequestBuilder()
         .forCollection(collectionName)
         .forShard(Collections.singletonList(shard))
@@ -425,13 +408,12 @@ public class Assign {
     }
 
     // if we were given a list, just use that, don't worry about counts
-    if (createNodeList != null) { // Overrides petty considerations about maxShardsPerNode
+    if (createNodeList != null) {
       return nodeNameVsShardCount;
     }
 
     // if we get here we were not given a createNodeList, build a map with real counts.
     DocCollection coll = clusterState.getCollection(collectionName);
-    int maxShardsPerNode = coll.getMaxShardsPerNode() == -1 ? Integer.MAX_VALUE : coll.getMaxShardsPerNode();
     Map<String, DocCollection> collections = clusterState.getCollectionsMap();
     for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {
       DocCollection c = entry.getValue();
@@ -444,7 +426,6 @@ public class Assign {
             count.totalNodes++; // Used to "weigh" whether this node should be used later.
             if (entry.getKey().equals(collectionName)) {
               count.thisCollectionNodes++;
-              if (count.thisCollectionNodes >= maxShardsPerNode) nodeNameVsShardCount.remove(replica.getNodeName());
             }
           }
         }
diff --git a/solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java b/solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java
index df55920d398..c3e9a3e64fb 100644
--- a/solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java
+++ b/solr/core/src/java/org/apache/solr/cloud/api/collections/CreateCollectionCmd.java
@@ -75,7 +75,6 @@ import org.apache.zookeeper.KeeperException.NoNodeException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.NRT_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.PULL_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
@@ -354,8 +353,6 @@ public class CreateCollectionCmd implements OverseerCollectionMessageHandler.Cmd
     int numPullReplicas = message.getInt(PULL_REPLICAS, 0);
 
     int numSlices = shardNames.size();
-    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, 1);
-    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;
 
     // we need to look at every node and see how many cores it serves
     // add our new cores to existing nodes serving the least number of cores
@@ -378,22 +375,6 @@ public class CreateCollectionCmd implements OverseerCollectionMessageHandler.Cmd
             , "It's unusual to run two replica of the same slice on the same Solr-instance.");
       }
 
-      int maxShardsAllowedToCreate = maxShardsPerNode == Integer.MAX_VALUE ?
-          Integer.MAX_VALUE :
-          maxShardsPerNode * nodeList.size();
-      int requestedShardsToCreate = numSlices * totalNumReplicas;
-      if (maxShardsAllowedToCreate < requestedShardsToCreate) {
-        throw new Assign.AssignmentException("Cannot create collection " + collectionName + ". Value of "
-            + MAX_SHARDS_PER_NODE + " is " + maxShardsPerNode
-            + ", and the number of nodes currently live or live and part of your "+OverseerCollectionMessageHandler.CREATE_NODE_SET+" is " + nodeList.size()
-            + ". This allows a maximum of " + maxShardsAllowedToCreate
-            + " to be created. Value of " + OverseerCollectionMessageHandler.NUM_SLICES + " is " + numSlices
-            + ", value of " + NRT_REPLICAS + " is " + numNrtReplicas
-            + ", value of " + TLOG_REPLICAS + " is " + numTlogReplicas
-            + " and value of " + PULL_REPLICAS + " is " + numPullReplicas
-            + ". This requires " + requestedShardsToCreate
-            + " shards to be created (higher than the allowed number)");
-      }
       Assign.AssignRequest assignRequest = new Assign.AssignRequestBuilder()
           .forCollection(collectionName)
           .forShard(shardNames)
diff --git a/solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java b/solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java
index 5c3b9d48ca9..e1fca930be4 100644
--- a/solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java
+++ b/solr/core/src/java/org/apache/solr/cloud/api/collections/OverseerCollectionMessageHandler.java
@@ -146,7 +146,6 @@ public class OverseerCollectionMessageHandler implements OverseerMessageHandler,
       ZkStateReader.NRT_REPLICAS, "1",
       ZkStateReader.TLOG_REPLICAS, "0",
       ZkStateReader.PULL_REPLICAS, "0",
-      ZkStateReader.MAX_SHARDS_PER_NODE, "1",
       ZkStateReader.AUTO_ADD_REPLICAS, "false",
       DocCollection.RULE, null,
       POLICY, null,
diff --git a/solr/core/src/java/org/apache/solr/cloud/api/collections/ReindexCollectionCmd.java b/solr/core/src/java/org/apache/solr/cloud/api/collections/ReindexCollectionCmd.java
index 8eaf8f8a510..d98d50a3f4d 100644
--- a/solr/core/src/java/org/apache/solr/cloud/api/collections/ReindexCollectionCmd.java
+++ b/solr/core/src/java/org/apache/solr/cloud/api/collections/ReindexCollectionCmd.java
@@ -109,7 +109,6 @@ public class ReindexCollectionCmd implements OverseerCollectionMessageHandler.Cm
       ZkStateReader.PULL_REPLICAS,
       ZkStateReader.TLOG_REPLICAS,
       ZkStateReader.REPLICATION_FACTOR,
-      ZkStateReader.MAX_SHARDS_PER_NODE,
       "shards",
       Policy.POLICY,
       CollectionAdminParams.CREATE_NODE_SET_PARAM,
@@ -242,7 +241,6 @@ public class ReindexCollectionCmd implements OverseerCollectionMessageHandler.Cm
     Integer numTlog = message.getInt(ZkStateReader.TLOG_REPLICAS, coll.getNumTlogReplicas());
     Integer numPull = message.getInt(ZkStateReader.PULL_REPLICAS, coll.getNumPullReplicas());
     int numShards = message.getInt(ZkStateReader.NUM_SHARDS_PROP, coll.getActiveSlices().size());
-    int maxShardsPerNode = message.getInt(ZkStateReader.MAX_SHARDS_PER_NODE, coll.getMaxShardsPerNode());
     DocRouter router = coll.getRouter();
     if (router == null) {
       router = DocRouter.DEFAULT;
@@ -320,7 +318,6 @@ public class ReindexCollectionCmd implements OverseerCollectionMessageHandler.Cm
         }
       }
 
-      propMap.put(ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode);
       propMap.put(CommonAdminParams.WAIT_FOR_FINAL_STATE, true);
       if (rf != null) {
         propMap.put(ZkStateReader.REPLICATION_FACTOR, rf);
diff --git a/solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java b/solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java
index 47797b4f5fd..f80097913dc 100644
--- a/solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java
+++ b/solr/core/src/java/org/apache/solr/cloud/api/collections/RestoreCmd.java
@@ -26,7 +26,6 @@ import java.util.Collections;
 import java.util.HashMap;
 import java.util.LinkedHashMap;
 import java.util.List;
-import java.util.Locale;
 import java.util.Map;
 import java.util.Objects;
 import java.util.Optional;
@@ -65,7 +64,6 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import static org.apache.solr.common.cloud.ZkStateReader.COLLECTION_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.NRT_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.PULL_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
@@ -139,16 +137,6 @@ public class RestoreCmd implements OverseerCollectionMessageHandler.Cmd {
     int totalReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;
     assert totalReplicasPerShard > 0;
     
-    int maxShardsPerNode = message.getInt(MAX_SHARDS_PER_NODE, backupCollectionState.getMaxShardsPerNode());
-    int availableNodeCount = nodeList.size();
-    if (maxShardsPerNode != -1 && (numShards * totalReplicasPerShard) > (availableNodeCount * maxShardsPerNode)) {
-      throw new SolrException(ErrorCode.BAD_REQUEST,
-          String.format(Locale.ROOT, "Solr cloud with available number of nodes:%d is insufficient for"
-              + " restoring a collection with %d shards, total replicas per shard %d and maxShardsPerNode %d."
-              + " Consider increasing maxShardsPerNode value OR number of available nodes.",
-              availableNodeCount, numShards, totalReplicasPerShard, maxShardsPerNode));
-    }
-
     //Upload the configs
     String configName = (String) properties.get(CollectionAdminParams.COLL_CONF);
     String restoreConfigName = message.getStr(CollectionAdminParams.COLL_CONF, configName);
@@ -172,7 +160,6 @@ public class RestoreCmd implements OverseerCollectionMessageHandler.Cmd {
       propMap.put(NRT_REPLICAS, numNrtReplicas);
       propMap.put(TLOG_REPLICAS, numTlogReplicas);
       propMap.put(PULL_REPLICAS, numPullReplicas);
-      properties.put(MAX_SHARDS_PER_NODE, maxShardsPerNode);
 
       // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor
       for (String collProp : OverseerCollectionMessageHandler.COLLECTION_PROPS_AND_DEFAULTS.keySet()) {
diff --git a/solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd.java b/solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd.java
index 4dd2d7021b3..3c1480f720a 100644
--- a/solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd.java
+++ b/solr/core/src/java/org/apache/solr/cloud/api/collections/SplitShardCmd.java
@@ -434,8 +434,6 @@ public class SplitShardCmd implements OverseerCollectionMessageHandler.Cmd {
       List<String> nodeList = new ArrayList<>(nodes.size());
       nodeList.addAll(nodes);
 
-      // TODO: Have maxShardsPerNode param for this operation?
-
       // Remove the node that hosts the parent shard for replica creation.
       nodeList.remove(nodeName);
 
diff --git a/solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java b/solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java
index 6943f2c99aa..46f1beb1386 100644
--- a/solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java
+++ b/solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java
@@ -105,7 +105,6 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import static org.apache.solr.common.cloud.ZkStateReader.COLLECTION_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.NRT_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.PULL_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
@@ -1009,8 +1008,6 @@ public class SimClusterStateProvider implements ClusterStateProvider {
 
     // fail fast if parameters are wrong or incomplete
     List<String> shardNames = CreateCollectionCmd.populateShardNames(props, router);
-    int maxShardsPerNode = props.getInt(MAX_SHARDS_PER_NODE, 1);
-    if (maxShardsPerNode == -1) maxShardsPerNode = Integer.MAX_VALUE;
     CreateCollectionCmd.checkReplicaTypes(props);
 
     // always force getting fresh state
diff --git a/solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimUtils.java b/solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimUtils.java
index 03c1f5b4752..514131756cc 100644
--- a/solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimUtils.java
+++ b/solr/core/src/java/org/apache/solr/cloud/autoscaling/sim/SimUtils.java
@@ -225,7 +225,6 @@ public class SimUtils {
       perColl.put("activeShards", coll.getActiveSlices().size());
       perColl.put("inactiveShards", coll.getSlices().size() - coll.getActiveSlices().size());
       perColl.put("rf", coll.getReplicationFactor());
-      perColl.put("maxShardsPerNode", coll.getMaxShardsPerNode());
       perColl.put("maxActualShardsPerNode", maxActualShardsPerNode);
       perColl.put("minActualShardsPerNode", minActualShardsPerNode);
       perColl.put("maxShardReplicasPerNode", maxShardReplicasPerNode);
diff --git a/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java b/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
index f443832b2dc..9b1cf78cf05 100644
--- a/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
@@ -127,7 +127,6 @@ import static org.apache.solr.common.cloud.DocCollection.RULE;
 import static org.apache.solr.common.cloud.DocCollection.SNITCH;
 import static org.apache.solr.common.cloud.ZkStateReader.AUTO_ADD_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.COLLECTION_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.NRT_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.PROPERTY_PROP;
 import static org.apache.solr.common.cloud.ZkStateReader.PROPERTY_VALUE_PROP;
@@ -144,6 +143,7 @@ import static org.apache.solr.common.params.CollectionAdminParams.COUNT_PROP;
 import static org.apache.solr.common.params.CollectionAdminParams.FOLLOW_ALIASES;
 import static org.apache.solr.common.params.CollectionAdminParams.PROPERTY_NAME;
 import static org.apache.solr.common.params.CollectionAdminParams.PROPERTY_VALUE;
+import static org.apache.solr.common.params.CollectionAdminParams.SKIP_NODE_ASSIGNMENT;
 import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;
 import static org.apache.solr.common.params.CollectionParams.CollectionAction.*;
 import static org.apache.solr.common.params.CommonAdminParams.ASYNC;
@@ -459,7 +459,6 @@ public class CollectionsHandler extends RequestHandlerBase implements Permission
           REPLICATION_FACTOR,
           COLL_CONF,
           NUM_SLICES,
-          MAX_SHARDS_PER_NODE,
           CREATE_NODE_SET,
           CREATE_NODE_SET_SHUFFLE,
           SHARDS_PROP,
@@ -559,7 +558,6 @@ public class CollectionsHandler extends RequestHandlerBase implements Permission
           PULL_REPLICAS,
           TLOG_REPLICAS,
           REPLICATION_FACTOR,
-          MAX_SHARDS_PER_NODE,
           POLICY,
           CREATE_NODE_SET,
           CREATE_NODE_SET_SHUFFLE,
@@ -942,7 +940,8 @@ public class CollectionsHandler extends RequestHandlerBase implements Permission
           TLOG_REPLICAS,
           PULL_REPLICAS,
           CREATE_NODE_SET,
-          FOLLOW_ALIASES);
+          FOLLOW_ALIASES,
+          SKIP_NODE_ASSIGNMENT);
       return copyPropertiesWithPrefix(req.getParams(), props, COLL_PROP_PREFIX);
     }),
     OVERSEERSTATUS_OP(OVERSEERSTATUS, (req, rsp, h) -> new LinkedHashMap<>()),
@@ -1170,7 +1169,7 @@ public class CollectionsHandler extends RequestHandlerBase implements Permission
       }
       // from CREATE_OP:
       copy(req.getParams(), params, COLL_CONF, REPLICATION_FACTOR, NRT_REPLICAS, TLOG_REPLICAS,
-          PULL_REPLICAS, MAX_SHARDS_PER_NODE, AUTO_ADD_REPLICAS, CREATE_NODE_SET, CREATE_NODE_SET_SHUFFLE);
+          PULL_REPLICAS, AUTO_ADD_REPLICAS, CREATE_NODE_SET, CREATE_NODE_SET_SHUFFLE);
       copyPropertiesWithPrefix(req.getParams(), params, COLL_PROP_PREFIX);
       return params;
     }),
diff --git a/solr/core/src/java/org/apache/solr/util/SolrCLI.java b/solr/core/src/java/org/apache/solr/util/SolrCLI.java
index d77bebc97b9..aa68726220b 100755
--- a/solr/core/src/java/org/apache/solr/util/SolrCLI.java
+++ b/solr/core/src/java/org/apache/solr/util/SolrCLI.java
@@ -1726,12 +1726,6 @@ public class SolrCLI implements CLIO {
           .required(false)
           .desc("Number of copies of each document across the collection (replicas per shard); default is 1")
           .build(),
-      Option.builder("maxShardsPerNode")
-          .argName("#")
-          .hasArg()
-          .required(false)
-          .desc("Maximum number of shards per Solr node; default is determined based on the number of shards, replication factor, and live nodes.")
-          .build(),
       Option.builder("confdir")
           .argName("NAME")
           .hasArg()
@@ -1922,11 +1916,6 @@ public class SolrCLI implements CLIO {
       // build a URL to create the collection
       int numShards = optionAsInt(cli, "shards", 1);
       int replicationFactor = optionAsInt(cli, "replicationFactor", 1);
-      int maxShardsPerNode = -1;
-
-      if (cli.hasOption("maxShardsPerNode")) {
-        maxShardsPerNode = Integer.parseInt(cli.getOptionValue("maxShardsPerNode"));
-      }
 
       String confname = cli.getOptionValue("confname");
       String confdir = cli.getOptionValue("confdir");
@@ -1962,12 +1951,11 @@ public class SolrCLI implements CLIO {
       // doesn't seem to exist ... try to create
       String createCollectionUrl =
           String.format(Locale.ROOT,
-              "%s/admin/collections?action=CREATE&name=%s&numShards=%d&replicationFactor=%d&maxShardsPerNode=%d",
+              "%s/admin/collections?action=CREATE&name=%s&numShards=%d&replicationFactor=%d",
               baseUrl,
               collectionName,
               numShards,
-              replicationFactor,
-              maxShardsPerNode);
+              replicationFactor);
       if (confname != null && !"".equals(confname.trim())) {
         createCollectionUrl = createCollectionUrl + String.format(Locale.ROOT, "&collection.configName=%s", confname);
       }
diff --git a/solr/core/src/test-files/solr/simSnapshot/clusterState.json b/solr/core/src/test-files/solr/simSnapshot/clusterState.json
index 004d202cc3d..acaa3409a79 100644
--- a/solr/core/src/test-files/solr/simSnapshot/clusterState.json
+++ b/solr/core/src/test-files/solr/simSnapshot/clusterState.json
@@ -80,7 +80,6 @@
               "type":"NRT",
               "force_set_state":"false"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -114,7 +113,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -148,7 +146,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -182,7 +179,6 @@
               "type":"NRT",
               "force_set_state":"false"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -216,7 +212,6 @@
               "type":"NRT",
               "force_set_state":"false"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -549,7 +544,6 @@
               "force_set_state":"false"}},
           "stateTimestamp":"1562040233681548279"}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -584,7 +578,6 @@
               "type":"NRT",
               "force_set_state":"false"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -2538,7 +2531,6 @@
               "force_set_state":"false"}},
           "stateTimestamp":"1565369006475856752"}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"2",
       "tlogReplicas":"0"},
@@ -2572,7 +2564,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -2606,7 +2597,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -2640,7 +2630,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -2659,7 +2648,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"1",
       "tlogReplicas":"0"},
@@ -2693,7 +2681,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -2727,7 +2714,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -2814,7 +2800,6 @@
               "type":"NRT",
               "force_set_state":"false"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
       "tlogReplicas":"0"},
@@ -2848,7 +2833,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
       "router":{"name":"compositeId"},
-      "maxShardsPerNode":"1",
       "autoAddReplicas":"true",
       "nrtReplicas":"3",
-      "tlogReplicas":"0"}}}
\ No newline at end of file
+      "tlogReplicas":"0"}}}
diff --git a/solr/core/src/test-files/solr/simSnapshot/statistics.json b/solr/core/src/test-files/solr/simSnapshot/statistics.json
index 735c36e14ba..3e10d61f2a4 100644
--- a/solr/core/src/test-files/solr/simSnapshot/statistics.json
+++ b/solr/core/src/test-files/solr/simSnapshot/statistics.json
@@ -1791,7 +1791,6 @@
       "activeShards":72,
       "inactiveShards":0,
       "rf":2,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":6,
       "minActualShardsPerNode":6,
       "maxShardReplicasPerNode":1,
@@ -1807,7 +1806,6 @@
       "activeShards":12,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":4,
       "minActualShardsPerNode":4,
       "maxShardReplicasPerNode":1,
@@ -1823,7 +1821,6 @@
       "activeShards":3,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1839,7 +1836,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1855,7 +1851,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":1,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1871,7 +1866,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1887,7 +1881,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1903,7 +1896,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1919,7 +1911,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1935,7 +1926,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1951,7 +1941,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1967,7 +1956,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1983,7 +1971,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -1999,7 +1986,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -2015,7 +2001,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -2031,7 +2016,6 @@
       "activeShards":1,
       "inactiveShards":0,
       "rf":3,
-      "maxShardsPerNode":1,
       "maxActualShardsPerNode":1,
       "minActualShardsPerNode":1,
       "maxShardReplicasPerNode":1,
@@ -2042,4 +2026,4 @@
       "minCoresPerNode":1,
       "avgShardSize":22.679232054390013,
       "maxShardSize":22.679232054390013,
-      "minShardSize":22.679232054390013}}}
\ No newline at end of file
+      "minShardSize":22.679232054390013}}}
diff --git a/solr/core/src/test/org/apache/solr/HelloWorldSolrCloudTestCase.java b/solr/core/src/test/org/apache/solr/HelloWorldSolrCloudTestCase.java
index 56a813ca095..820640bd283 100644
--- a/solr/core/src/test/org/apache/solr/HelloWorldSolrCloudTestCase.java
+++ b/solr/core/src/test/org/apache/solr/HelloWorldSolrCloudTestCase.java
@@ -41,8 +41,7 @@ public class HelloWorldSolrCloudTestCase extends SolrCloudTestCase {
 
   private static final int numShards = 3;
   private static final int numReplicas = 2;
-  private static final int maxShardsPerNode = 2;
-  private static final int nodeCount = (numShards*numReplicas + (maxShardsPerNode-1))/maxShardsPerNode;
+  private static final int nodeCount = numShards*numReplicas;
 
   private static final String id = "id";
 
@@ -56,7 +55,6 @@ public class HelloWorldSolrCloudTestCase extends SolrCloudTestCase {
 
     // create an empty collection
     CollectionAdminRequest.createCollection(COLLECTION, "conf", numShards, numReplicas)
-        .setMaxShardsPerNode(maxShardsPerNode)
         .process(cluster.getSolrClient());
 
     // add a document
diff --git a/solr/core/src/test/org/apache/solr/cloud/AddReplicaTest.java b/solr/core/src/test/org/apache/solr/cloud/AddReplicaTest.java
index 3bfda389a50..84cdd74a814 100644
--- a/solr/core/src/test/org/apache/solr/cloud/AddReplicaTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/AddReplicaTest.java
@@ -17,7 +17,6 @@
 package org.apache.solr.cloud;
 
 import static org.apache.solr.client.solrj.response.RequestStatusState.COMPLETED;
-import static org.apache.solr.client.solrj.response.RequestStatusState.FAILED;
 
 import java.lang.invoke.MethodHandles;
 import java.util.Collection;
@@ -62,7 +61,6 @@ public class AddReplicaTest extends SolrCloudTestCase {
     CloudSolrClient cloudClient = cluster.getSolrClient();
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collection, "conf1", 1, 1);
-    create.setMaxShardsPerNode(2);
     cloudClient.request(create);
     cluster.waitForActiveCollection(collection, 1, 1);
 
@@ -82,13 +80,6 @@ public class AddReplicaTest extends SolrCloudTestCase {
     assertEquals(1, docCollection.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());
     assertEquals(1, docCollection.getReplicas(EnumSet.of(Replica.Type.PULL)).size());
 
-    // try to add 5 more replicas which should fail because numNodes(4)*maxShardsPerNode(2)=8 and 4 replicas already exist
-    addReplica = CollectionAdminRequest.addReplicaToShard(collection, "shard1")
-        .setNrtReplicas(3)
-        .setTlogReplicas(1)
-        .setPullReplicas(1);
-    status = addReplica.processAndWait(collection + "_xyz1", cloudClient, 120);
-    assertEquals(FAILED, status);
     docCollection = cloudClient.getZkStateReader().getClusterState().getCollectionOrNull(collection);
     assertNotNull(docCollection);
     // sanity check that everything is as before
@@ -97,7 +88,7 @@ public class AddReplicaTest extends SolrCloudTestCase {
     assertEquals(1, docCollection.getReplicas(EnumSet.of(Replica.Type.TLOG)).size());
     assertEquals(1, docCollection.getReplicas(EnumSet.of(Replica.Type.PULL)).size());
 
-    // but adding any number of replicas is supported if an explicit create node set is specified
+    // adding any number of replicas is supported if an explicit create node set is specified
     // so test that as well
     LinkedHashSet<String> createNodeSet = new LinkedHashSet<>(2);
     createNodeSet.add(cluster.getRandomJetty(random()).getNodeName());
@@ -130,7 +121,6 @@ public class AddReplicaTest extends SolrCloudTestCase {
     CloudSolrClient cloudClient = cluster.getSolrClient();
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collection, "conf1", 2, 1);
-    create.setMaxShardsPerNode(2);
     cloudClient.request(create);
     
     cluster.waitForActiveCollection(collection, 2, 2);
diff --git a/solr/core/src/test/org/apache/solr/cloud/AssignBackwardCompatibilityTest.java b/solr/core/src/test/org/apache/solr/cloud/AssignBackwardCompatibilityTest.java
index 54f535bdc07..37062e63927 100644
--- a/solr/core/src/test/org/apache/solr/cloud/AssignBackwardCompatibilityTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/AssignBackwardCompatibilityTest.java
@@ -51,7 +51,6 @@ public class AssignBackwardCompatibilityTest extends SolrCloudTestCase {
         .addConfig("conf1", TEST_PATH().resolve("configsets").resolve("cloud-dynamic").resolve("conf"))
         .configure();
     CollectionAdminRequest.createCollection(COLLECTION, 1, 4)
-        .setMaxShardsPerNode(1000)
         .process(cluster.getSolrClient());
     cluster.waitForActiveCollection(COLLECTION, 1, 4);
   }
diff --git a/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java b/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
index d5db36acf74..227e50e14aa 100644
--- a/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
@@ -776,14 +776,13 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
 
   @Override
   protected CollectionAdminResponse createCollection(Map<String, List<Integer>> collectionInfos,
-                                                     String collectionName, String configSetName, int numShards, int numReplicas, int maxShardsPerNode, SolrClient client, String createNodeSetStr) throws SolrServerException, IOException {
+                                                     String collectionName, String configSetName, int numShards, int numReplicas, SolrClient client, String createNodeSetStr) throws SolrServerException, IOException {
     // TODO: Use CollectionAdminRequest for this test
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("action", CollectionAction.CREATE.toString());
 
     params.set(OverseerCollectionMessageHandler.NUM_SLICES, numShards);
     params.set(ZkStateReader.REPLICATION_FACTOR, numReplicas);
-    params.set(ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode);
     if (createNodeSetStr != null) params.set(OverseerCollectionMessageHandler.CREATE_NODE_SET, createNodeSetStr);
 
     int clientIndex = clients.size() > 1 ? random().nextInt(2) : 0;
@@ -959,7 +958,6 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     log.info("### STARTING testANewCollectionInOneInstanceWithManualShardAssignement");
     assertEquals(0, CollectionAdminRequest.createCollection(oneInstanceCollection2, "conf1", 2, 2)
         .setCreateNodeSet("")
-        .setMaxShardsPerNode(4)
         .process(cloudClient).getStatus());
 
     List<SolrClient> collectionClients = new ArrayList<>();
@@ -1107,7 +1105,6 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     log.info("### STARTING testANewCollectionInOneInstance");
     CollectionAdminResponse response = CollectionAdminRequest.createCollection(oneInstanceCollection, "conf1", 2, 2)
         .setCreateNodeSet(jettys.get(0).getNodeName())
-        .setMaxShardsPerNode(4)
         .process(cloudClient);
     assertEquals(0, response.getStatus());
     List<SolrClient> collectionClients = new ArrayList<>();
diff --git a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeTest.java b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeTest.java
index fbeaad1f49d..a89dfde2d35 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeTest.java
@@ -289,7 +289,7 @@ public class ChaosMonkeyNothingIsSafeTest extends AbstractFullDistribZkTestBase
 
       try (CloudSolrClient client = createCloudClient("collection1", 30000)) {
           createCollection(null, "testcollection",
-              1, 1, 1, client, null, "conf1");
+              1, 1, client, null, "conf1");
 
       }
       List<Integer> numShardsNumReplicas = new ArrayList<>(2);
diff --git a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest.java b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest.java
index 26b0c36a1d8..1e6cc3fcfe7 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeWithPullReplicasTest.java
@@ -308,9 +308,8 @@ public class ChaosMonkeyNothingIsSafeWithPullReplicasTest extends AbstractFullDi
       }
 
       try (CloudSolrClient client = createCloudClient("collection1", 30000)) {
-        // We don't really know how many live nodes we have at this point, so "maxShardsPerNode" needs to be > 1
         createCollection(null, "testcollection",
-              1, 1, 10, client, null, "conf1"); 
+              1, 1, client, null, "conf1");
       }
       List<Integer> numShardsNumReplicas = new ArrayList<>(2);
       numShardsNumReplicas.add(1);
diff --git a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderTest.java b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderTest.java
index 10380c36b75..af9fdbe0ea5 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderTest.java
@@ -176,7 +176,7 @@ public class ChaosMonkeySafeLeaderTest extends AbstractFullDistribZkTestBase {
     }
 
     try (CloudSolrClient client = createCloudClient("collection1")) {
-        createCollection(null, "testcollection", 1, 1, 1, client, null, "conf1");
+        createCollection(null, "testcollection", 1, 1, client, null, "conf1");
 
     }
     List<Integer> numShardsNumReplicas = new ArrayList<>(2);
diff --git a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest.java b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest.java
index e1e9a8705ee..bf359326080 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderWithPullReplicasTest.java
@@ -224,7 +224,7 @@ public class ChaosMonkeySafeLeaderWithPullReplicasTest extends AbstractFullDistr
     }
 
     try (CloudSolrClient client = createCloudClient("collection1")) {
-        createCollection(null, "testcollection", 1, 1, 100, client, null, "conf1");
+        createCollection(null, "testcollection", 1, 1, client, null, "conf1");
 
     }
     List<Integer> numShardsNumReplicas = new ArrayList<>(2);
diff --git a/solr/core/src/test/org/apache/solr/cloud/ClusterStateMockUtil.java b/solr/core/src/test/org/apache/solr/cloud/ClusterStateMockUtil.java
index 87629d2fc0c..9019be70f08 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ClusterStateMockUtil.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ClusterStateMockUtil.java
@@ -35,7 +35,7 @@ import org.apache.solr.common.util.Utils;
 
 /**
  * A utility class that can create mock ZkStateReader objects with custom ClusterState objects created
- * using a simple string based description. See {@link #buildClusterState(String, int, int, String...)} for
+ * using a simple string based description. See {@link #buildClusterState(String, int, String...)} for
  * details on how the cluster state can be created.
  *
  * @lucene.experimental
@@ -48,10 +48,6 @@ public class ClusterStateMockUtil {
     return buildClusterState(clusterDescription, 1, liveNodes);
   }
 
-  public static ZkStateReader buildClusterState(String clusterDescription, int replicationFactor, String ... liveNodes) {
-    return buildClusterState(clusterDescription, replicationFactor, 10, liveNodes);
-  }
-
   /**
    * This method lets you construct a complex ClusterState object by using simple strings of letters.
    *
@@ -76,7 +72,6 @@ public class ClusterStateMockUtil {
    * Result:
    *        {
    *         "collection2":{
-   *           "maxShardsPerNode":"1",
    *           "replicationFactor":"1",
    *           "shards":{"slice1":{
    *               "state":"active",
@@ -85,7 +80,6 @@ public class ClusterStateMockUtil {
    *                   "node_name":"baseUrl1_",
    *                   "base_url":"http://baseUrl1"}}}}},
    *         "collection1":{
-   *           "maxShardsPerNode":"1",
    *           "replicationFactor":"1",
    *           "shards":{
    *             "slice1":{
@@ -112,11 +106,10 @@ public class ClusterStateMockUtil {
    *
    */
   @SuppressWarnings("resource")
-  public static ZkStateReader buildClusterState(String clusterDescription, int replicationFactor, int maxShardsPerNode, String ... liveNodes) {
+  public static ZkStateReader buildClusterState(String clusterDescription, int replicationFactor, String ... liveNodes) {
     Map<String,Slice> slices = null;
     Map<String,Replica> replicas = null;
     Map<String,Object> collectionProps = new HashMap<>();
-    collectionProps.put(ZkStateReader.MAX_SHARDS_PER_NODE, Integer.toString(maxShardsPerNode));
     collectionProps.put(ZkStateReader.REPLICATION_FACTOR, Integer.toString(replicationFactor));
     Map<String,DocCollection> collectionStates = new HashMap<>();
     DocCollection docCollection = null;
diff --git a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPISolrJTest.java b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPISolrJTest.java
index a18fb6034da..35daa446941 100644
--- a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPISolrJTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPISolrJTest.java
@@ -364,7 +364,6 @@ public class CollectionsAPISolrJTest extends SolrCloudTestCase {
     String collectionName = "solrj_implicit";
     CollectionAdminResponse response
         = CollectionAdminRequest.createCollectionWithImplicitRouter(collectionName, "conf", "shardA,shardB", 1, 1, 1)
-        .setMaxShardsPerNode(3)
         .process(cluster.getSolrClient());
 
     assertEquals(0, response.getStatus());
@@ -1072,13 +1071,6 @@ public class CollectionsAPISolrJTest extends SolrCloudTestCase {
     waitForState("Expecting attribute 'replicationFactor' to be 25", collection,
         (n, c) -> 25 == c.getReplicationFactor());
 
-    CollectionAdminRequest.modifyCollection(collection, null)
-        .unsetAttribute("maxShardsPerNode")
-        .process(cluster.getSolrClient());
-
-    waitForState("Expecting attribute 'maxShardsPerNode' to be deleted", collection,
-        (n, c) -> null == c.get("maxShardsPerNode"));
-
     expectThrows(IllegalArgumentException.class,
         "An attempt to set unknown collection attribute should have failed",
         () -> CollectionAdminRequest.modifyCollection(collection, null)
diff --git a/solr/core/src/test/org/apache/solr/cloud/CreateRoutedAliasTest.java b/solr/core/src/test/org/apache/solr/cloud/CreateRoutedAliasTest.java
index afb13b24e06..cd6edd9006f 100644
--- a/solr/core/src/test/org/apache/solr/cloud/CreateRoutedAliasTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/CreateRoutedAliasTest.java
@@ -120,7 +120,6 @@ public class CreateRoutedAliasTest extends SolrCloudTestCase {
         "      \"config\":\"_default\",\n" +
         "      \"tlogReplicas\":1,\n" +
         "      \"pullReplicas\":1,\n" +
-        "      \"maxShardsPerNode\":4,\n" + // note: we also expect the 'policy' to work fine
         "      \"nodeSet\": '" + createNode + "',\n" +
         "      \"properties\" : {\n" +
         "        \"foobar\":\"bazbam\",\n" +
@@ -152,7 +151,6 @@ public class CreateRoutedAliasTest extends SolrCloudTestCase {
     //assertEquals(1, coll.getNumNrtReplicas().intValue()); // TODO seems to be erroneous; I figured 'null'
     assertEquals(1, coll.getNumTlogReplicas().intValue()); // per-shard
     assertEquals(1, coll.getNumPullReplicas().intValue()); // per-shard
-    assertEquals(4, coll.getMaxShardsPerNode());
     assertTrue("nodeSet didn't work?",
         coll.getSlices().stream().flatMap(s -> s.getReplicas().stream())
             .map(Replica::getNodeName).allMatch(createNode::equals));
diff --git a/solr/core/src/test/org/apache/solr/cloud/DeleteInactiveReplicaTest.java b/solr/core/src/test/org/apache/solr/cloud/DeleteInactiveReplicaTest.java
index 0edc7bef322..325c5fbf486 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DeleteInactiveReplicaTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DeleteInactiveReplicaTest.java
@@ -54,10 +54,8 @@ public class DeleteInactiveReplicaTest extends SolrCloudTestCase {
     String collectionName = "delDeadColl";
     int replicationFactor = 2;
     int numShards = 2;
-    int maxShardsPerNode = ((((numShards + 1) * replicationFactor) / cluster.getJettySolrRunners().size())) + 1;
 
     CollectionAdminRequest.createCollection(collectionName, "conf", numShards, replicationFactor)
-        .setMaxShardsPerNode(maxShardsPerNode)
         .process(cluster.getSolrClient());
     waitForState("Expected a cluster of 2 shards and 2 replicas", collectionName, (n, c) -> {
       return DocCollection.isFullyActive(n, c, numShards, replicationFactor);
diff --git a/solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java b/solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java
index c46362e84fb..13d40e1dd6e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java
@@ -37,7 +37,6 @@ public class DeleteLastCustomShardedReplicaTest extends SolrCloudTestCase {
     final String collectionName = "customcollreplicadeletion";
 
     CollectionAdminRequest.createCollectionWithImplicitRouter(collectionName, "conf", "a,b", 1)
-        .setMaxShardsPerNode(5)
         .process(cluster.getSolrClient());
 
     DocCollection collectionState = getCollectionState(collectionName);
diff --git a/solr/core/src/test/org/apache/solr/cloud/DeleteNodeTest.java b/solr/core/src/test/org/apache/solr/cloud/DeleteNodeTest.java
index 5fd339e5915..84a5eced095 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DeleteNodeTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DeleteNodeTest.java
@@ -68,7 +68,7 @@ public class DeleteNodeTest extends SolrCloudTestCase {
         CollectionAdminRequest.createCollection(coll, "conf1", 5, 1, 0, 0),
         CollectionAdminRequest.createCollection(coll, "conf1", 5, 0, 1, 0)
         );
-    create.setCreateNodeSet(StrUtils.join(l, ',')).setMaxShardsPerNode(3);
+    create.setCreateNodeSet(StrUtils.join(l, ','));
     cloudClient.request(create);
     state = cloudClient.getZkStateReader().getClusterState();
     String node2bdecommissioned = l.get(0);
diff --git a/solr/core/src/test/org/apache/solr/cloud/DeleteShardTest.java b/solr/core/src/test/org/apache/solr/cloud/DeleteShardTest.java
index 6f384fbd3e4..9f3f9a4ec16 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DeleteShardTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DeleteShardTest.java
@@ -114,7 +114,6 @@ public class DeleteShardTest extends SolrCloudTestCase {
 
     final String collection = "deleteshard_test";
     CollectionAdminRequest.createCollectionWithImplicitRouter(collection, "conf", "a,b,c", 1)
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(collection, 3, 3);
diff --git a/solr/core/src/test/org/apache/solr/cloud/DocValuesNotIndexedTest.java b/solr/core/src/test/org/apache/solr/cloud/DocValuesNotIndexedTest.java
index 5fa604e03ab..45ccbc98f5c 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DocValuesNotIndexedTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DocValuesNotIndexedTest.java
@@ -86,7 +86,6 @@ public class DocValuesNotIndexedTest extends SolrCloudTestCase {
 
     // Need enough shards that we have some shards that don't have any docs on them.
     CollectionAdminRequest.createCollection(COLLECTION, "conf1", 4, 1)
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(COLLECTION, 4, 4);
diff --git a/solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java b/solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java
index 84b3622d435..68b2b430b09 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ForceLeaderTest.java
@@ -75,7 +75,7 @@ public class ForceLeaderTest extends HttpPartitionTest {
 
 
     String testCollectionName = "forceleader_lower_terms_collection";
-    createCollection(testCollectionName, "conf1", 1, 3, 1);
+    createCollection(testCollectionName, "conf1", 1, 3);
     
 
     try {
diff --git a/solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest.java b/solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest.java
index b5d3638ae5b..2c4ac646276 100644
--- a/solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/HttpPartitionOnCommitTest.java
@@ -73,7 +73,7 @@ public class HttpPartitionOnCommitTest extends BasicDistributedZkTest {
 
     // create a collection that has 2 shard and 2 replicas
     String testCollectionName = "c8n_2x2_commits";
-    createCollection(testCollectionName, "conf1", 2, 2, 1);
+    createCollection(testCollectionName, "conf1", 2, 2);
     cloudClient.setDefaultCollection(testCollectionName);
 
     List<Replica> notLeaders =
@@ -122,7 +122,7 @@ public class HttpPartitionOnCommitTest extends BasicDistributedZkTest {
 
     // create a collection that has 1 shard and 3 replicas
     String testCollectionName = "c8n_1x3_commits";
-    createCollection(testCollectionName, "conf1", 1, 3, 1);
+    createCollection(testCollectionName, "conf1", 1, 3);
     cloudClient.setDefaultCollection(testCollectionName);
 
     List<Replica> notLeaders =
diff --git a/solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest.java b/solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest.java
index fea8a285e10..6ca5533c31b 100644
--- a/solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest.java
@@ -159,7 +159,7 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
 
       TestInjection.prepRecoveryOpPauseForever = "true:100";
       
-      createCollection(testCollectionName, "conf1", 1, 2, 1);
+      createCollection(testCollectionName, "conf1", 1, 2);
       cloudClient.setDefaultCollection(testCollectionName);
 
       sendDoc(1, 2);
@@ -211,7 +211,7 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
   protected void testRf2() throws Exception {
     // create a collection that has 1 shard but 2 replicas
     String testCollectionName = "c8n_1x2";
-    createCollectionRetry(testCollectionName, "conf1", 1, 2, 1);
+    createCollectionRetry(testCollectionName, "conf1", 1, 2);
     cloudClient.setDefaultCollection(testCollectionName);
     
     sendDoc(1);
@@ -330,7 +330,7 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
   protected void testRf3() throws Exception {
     // create a collection that has 1 shard but 2 replicas
     String testCollectionName = "c8n_1x3";
-    createCollectionRetry(testCollectionName, "conf1", 1, 3, 1);
+    createCollectionRetry(testCollectionName, "conf1", 1, 3);
     
     cloudClient.setDefaultCollection(testCollectionName);
     
@@ -385,7 +385,7 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
   protected void testLeaderZkSessionLoss() throws Exception {
 
     String testCollectionName = "c8n_1x2_leader_session_loss";
-    createCollectionRetry(testCollectionName, "conf1", 1, 2, 1);
+    createCollectionRetry(testCollectionName, "conf1", 1, 2);
     cloudClient.setDefaultCollection(testCollectionName);
 
     sendDoc(1);
diff --git a/solr/core/src/test/org/apache/solr/cloud/LeaderElectionContextKeyTest.java b/solr/core/src/test/org/apache/solr/cloud/LeaderElectionContextKeyTest.java
index 6b2ca95c53e..ee74f680ee6 100644
--- a/solr/core/src/test/org/apache/solr/cloud/LeaderElectionContextKeyTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/LeaderElectionContextKeyTest.java
@@ -52,7 +52,6 @@ public class LeaderElectionContextKeyTest extends SolrCloudTestCase {
       // therefore Assign.buildCoreNodeName will create same coreNodeName
       CollectionAdminRequest
           .createCollection("testCollection"+i, "config", 2, 1)
-          .setMaxShardsPerNode(100)
           .setCreateNodeSet("")
           .process(cluster.getSolrClient());
       CollectionAdminRequest
diff --git a/solr/core/src/test/org/apache/solr/cloud/LeaderElectionIntegrationTest.java b/solr/core/src/test/org/apache/solr/cloud/LeaderElectionIntegrationTest.java
index c20a450e86b..a5964d415f9 100644
--- a/solr/core/src/test/org/apache/solr/cloud/LeaderElectionIntegrationTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/LeaderElectionIntegrationTest.java
@@ -51,7 +51,7 @@ public class LeaderElectionIntegrationTest extends SolrCloudTestCase {
   private void createCollection(String collection) throws IOException, SolrServerException {
     assertEquals(0, CollectionAdminRequest.createCollection(collection,
         "conf", 2, 1)
-        .setMaxShardsPerNode(1).process(cluster.getSolrClient()).getStatus());
+        .process(cluster.getSolrClient()).getStatus());
     for (int i = 1; i < NUM_REPLICAS_OF_SHARD1; i++) {
       assertTrue(
           CollectionAdminRequest.addReplicaToShard(collection, "shard1").process(cluster.getSolrClient()).isSuccess()
diff --git a/solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest.java b/solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest.java
index e94783e6a1c..fc340e05f33 100644
--- a/solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest.java
@@ -63,7 +63,7 @@ public class LeaderFailoverAfterPartitionTest extends HttpPartitionTest {
     // kill the leader ... see what happens
     // create a collection that has 1 shard but 3 replicas
     String testCollectionName = "c8n_1x3_lf"; // _lf is leader fails
-    createCollection(testCollectionName, "conf1", 1, 3, 1);
+    createCollection(testCollectionName, "conf1", 1, 3);
     cloudClient.setDefaultCollection(testCollectionName);
     
     sendDoc(1);
diff --git a/solr/core/src/test/org/apache/solr/cloud/MissingSegmentRecoveryTest.java b/solr/core/src/test/org/apache/solr/cloud/MissingSegmentRecoveryTest.java
index 13b5df0fafd..4584ca2b4c0 100644
--- a/solr/core/src/test/org/apache/solr/cloud/MissingSegmentRecoveryTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/MissingSegmentRecoveryTest.java
@@ -57,7 +57,6 @@ public class MissingSegmentRecoveryTest extends SolrCloudTestCase {
   @Before
   public void setup() throws SolrServerException, IOException {
     CollectionAdminRequest.createCollection(collection, "conf", 1, 2)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
     waitForState("Expected a collection with one shard and two replicas", collection, clusterShape(1, 2));
     cluster.getSolrClient().setDefaultCollection(collection);
diff --git a/solr/core/src/test/org/apache/solr/cloud/MoveReplicaTest.java b/solr/core/src/test/org/apache/solr/cloud/MoveReplicaTest.java
index a17cd1a25a1..f4191d8aa5d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/MoveReplicaTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/MoveReplicaTest.java
@@ -105,7 +105,6 @@ public class MoveReplicaTest extends SolrCloudTestCase {
     // random create tlog or pull type replicas with nrt
     boolean isTlog = random().nextBoolean();
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, "conf1", 2, 1, isTlog ? 1 : 0, !isTlog ? 1 : 0);
-    create.setMaxShardsPerNode(2);
     create.setAutoAddReplicas(false);
     cloudClient.request(create);
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/MultiSolrCloudTestCaseTest.java b/solr/core/src/test/org/apache/solr/cloud/MultiSolrCloudTestCaseTest.java
index 2e382f8e247..e4b7551aa64 100644
--- a/solr/core/src/test/org/apache/solr/cloud/MultiSolrCloudTestCaseTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/MultiSolrCloudTestCaseTest.java
@@ -27,7 +27,6 @@ public class MultiSolrCloudTestCaseTest extends MultiSolrCloudTestCase {
 
   private static int numShards;
   private static int numReplicas;
-  private static int maxShardsPerNode;
   private static int nodesPerCluster;
 
   @BeforeClass
@@ -47,8 +46,7 @@ public class MultiSolrCloudTestCaseTest extends MultiSolrCloudTestCase {
 
     numShards = 1+random().nextInt(2);
     numReplicas = 1+random().nextInt(2);
-    maxShardsPerNode = 1+random().nextInt(2);
-    nodesPerCluster = (numShards*numReplicas + (maxShardsPerNode-1))/maxShardsPerNode;
+    nodesPerCluster = numShards*numReplicas;
 
     doSetupClusters(
         clusterIds,
@@ -58,7 +56,7 @@ public class MultiSolrCloudTestCaseTest extends MultiSolrCloudTestCase {
             return nodesPerCluster;
           }
         },
-        new DefaultClusterInitFunction(numShards, numReplicas, maxShardsPerNode) {
+        new DefaultClusterInitFunction(numShards, numReplicas) {
           @Override
           public void accept(String clusterId, MiniSolrCloudCluster cluster) {
             for (final String collection : collections) {
diff --git a/solr/core/src/test/org/apache/solr/cloud/NodeMutatorTest.java b/solr/core/src/test/org/apache/solr/cloud/NodeMutatorTest.java
index a446f29f568..d31d67f5b0a 100644
--- a/solr/core/src/test/org/apache/solr/cloud/NodeMutatorTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/NodeMutatorTest.java
@@ -43,10 +43,9 @@ public class NodeMutatorTest extends SolrTestCaseJ4Test {
   public void downNodeReportsAllImpactedCollectionsAndNothingElse() throws IOException {
     NodeMutator nm = new NodeMutator();
 
-    //We use 2 nodes with maxShardsPerNode as 1
     //Collection1: 2 shards X 1 replica = replica1 on node1 and replica2 on node2
     //Collection2: 1 shard X 1 replica = replica1 on node2
-    ZkStateReader reader = ClusterStateMockUtil.buildClusterState("csrr2rDcsr2", 1, 1, NODE1, NODE2);
+    ZkStateReader reader = ClusterStateMockUtil.buildClusterState("csrr2rDcsr2", 1, NODE1, NODE2);
     ClusterState clusterState = reader.getClusterState();
     assertEquals(clusterState.getCollection("collection1").getReplica("replica1").getBaseUrl(), NODE1_URL);
     assertEquals(clusterState.getCollection("collection1").getReplica("replica2").getBaseUrl(), NODE2_URL);
@@ -60,11 +59,10 @@ public class NodeMutatorTest extends SolrTestCaseJ4Test {
     assertEquals(writes.get(0).collection.getReplica("replica2").getState(), Replica.State.ACTIVE);
     reader.close();
 
-    //We use 3 nodes with maxShardsPerNode as 1
     //Collection1: 2 shards X 1 replica = replica1 on node1 and replica2 on node2
     //Collection2: 1 shard X 1 replica = replica1 on node2
     //Collection3: 1 shard X 3 replica = replica1 on node1 , replica2 on node2, replica3 on node3
-    reader = ClusterStateMockUtil.buildClusterState("csrr2rDcsr2csr1r2r3", 1, 1, NODE1, NODE2, NODE3);
+    reader = ClusterStateMockUtil.buildClusterState("csrr2rDcsr2csr1r2r3", 1, NODE1, NODE2, NODE3);
     clusterState = reader.getClusterState();
     assertEquals(clusterState.getCollection("collection1").getReplica("replica1").getBaseUrl(), NODE1_URL);
     assertEquals(clusterState.getCollection("collection1").getReplica("replica2").getBaseUrl(), NODE2_URL);
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionConfigSetProcessorTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionConfigSetProcessorTest.java
index 2e621bef754..3d4f69137ea 100644
--- a/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionConfigSetProcessorTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/OverseerCollectionConfigSetProcessorTest.java
@@ -539,14 +539,13 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
   }
 
   protected void issueCreateJob(Integer numberOfSlices,
-      Integer replicationFactor, Integer maxShardsPerNode, List<String> createNodeList, boolean sendCreateNodeList, boolean createNodeSetShuffle) {
+      Integer replicationFactor, List<String> createNodeList, boolean sendCreateNodeList, boolean createNodeSetShuffle) {
     Map<String,Object> propMap = Utils.makeMap(
         Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.CREATE.toLower(),
         ZkStateReader.REPLICATION_FACTOR, replicationFactor.toString(),
         "name", COLLECTION_NAME,
         "collection.configName", CONFIG_NAME,
-        OverseerCollectionMessageHandler.NUM_SLICES, numberOfSlices.toString(),
-        ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode.toString()
+        OverseerCollectionMessageHandler.NUM_SLICES, numberOfSlices.toString()
     );
     if (sendCreateNodeList) {
       propMap.put(OverseerCollectionMessageHandler.CREATE_NODE_SET,
@@ -720,7 +719,7 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     SEND_NULL
   }
   protected void testTemplate(Integer numberOfNodes, Integer numberOfNodesToCreateOn, CreateNodeListOptions createNodeListOption, Integer replicationFactor,
-      Integer numberOfSlices, Integer maxShardsPerNode,
+      Integer numberOfSlices,
       boolean collectionExceptedToBeCreated) throws Exception {
     assertTrue("Wrong usage of testTemplate. numberOfNodesToCreateOn " + numberOfNodesToCreateOn + " is not allowed to be higher than numberOfNodes " + numberOfNodes, numberOfNodes.intValue() >= numberOfNodesToCreateOn.intValue());
     assertTrue("Wrong usage of testTemplage. createNodeListOption has to be " + CreateNodeListOptions.SEND + " when numberOfNodes and numberOfNodesToCreateOn are unequal", ((createNodeListOption == CreateNodeListOptions.SEND) || (numberOfNodes.intValue() == numberOfNodesToCreateOn.intValue())));
@@ -750,7 +749,7 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     final List<String> createNodeListToSend = ((createNodeListOption != CreateNodeListOptions.SEND_NULL) ? createNodeList : null);
     final boolean sendCreateNodeList = (createNodeListOption != CreateNodeListOptions.DONT_SEND);
     final boolean dontShuffleCreateNodeSet = (createNodeListToSend != null) && sendCreateNodeList && random().nextBoolean();
-    issueCreateJob(numberOfSlices, replicationFactor, maxShardsPerNode, createNodeListToSend, sendCreateNodeList, !dontShuffleCreateNodeSet);
+    issueCreateJob(numberOfSlices, replicationFactor, createNodeListToSend, sendCreateNodeList, !dontShuffleCreateNodeSet);
     waitForEmptyQueue(10000);
 
     if (collectionExceptedToBeCreated) {
@@ -769,9 +768,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
     Integer replicationFactor = 1;
     Integer numberOfSlices = 8;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
   
   @Test
@@ -781,9 +779,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
     Integer replicationFactor = 2;
     Integer numberOfSlices = 4;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
   
   @Test
@@ -793,9 +790,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
     Integer replicationFactor = 1;
     Integer numberOfSlices = 8;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
   
   @Test
@@ -805,9 +801,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
     Integer replicationFactor = 2;
     Integer numberOfSlices = 4;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
   
   @Test
@@ -817,9 +812,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND_NULL;
     Integer replicationFactor = 1;
     Integer numberOfSlices = 8;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
   
   @Test
@@ -829,9 +823,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND_NULL;
     Integer replicationFactor = 2;
     Integer numberOfSlices = 4;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }  
   
   @Test
@@ -841,9 +834,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
     Integer replicationFactor = 1;
     Integer numberOfSlices = 6;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
   
   @Test
@@ -853,37 +845,10 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
     Integer replicationFactor = 2;
     Integer numberOfSlices = 3;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
   
-  @Test
-  public void testNoReplicationCollectionNotCreatedDueToMaxShardsPerNodeLimit()
-      throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
-    Integer replicationFactor = 1;
-    Integer numberOfSlices = 6;
-    Integer maxShardsPerNode = 1;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, false);
-  }
-  
-  @Test
-  public void testReplicationCollectionNotCreatedDueToMaxShardsPerNodeLimit()
-      throws Exception {
-    Integer numberOfNodes = 4;
-    Integer numberOfNodesToCreateOn = 4;
-    CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.DONT_SEND;
-    Integer replicationFactor = 2;
-    Integer numberOfSlices = 3;
-    Integer maxShardsPerNode = 1;
-    testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, false);
-  }
-
   @Test
   public void testNoReplicationLimitedNodesToCreateOn()
       throws Exception {
@@ -892,9 +857,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
     Integer replicationFactor = 1;
     Integer numberOfSlices = 6;
-    Integer maxShardsPerNode = 3;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
   
   @Test
@@ -905,9 +869,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
     Integer replicationFactor = 2;
     Integer numberOfSlices = 3;
-    Integer maxShardsPerNode = 3;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, true);
+        true);
   }
 
   @Test
@@ -918,9 +881,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
     Integer replicationFactor = 1;
     Integer numberOfSlices = 8;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, false);
+        false);
   }
   
   @Test
@@ -931,9 +893,8 @@ public class OverseerCollectionConfigSetProcessorTest extends SolrTestCaseJ4 {
     CreateNodeListOptions createNodeListOptions = CreateNodeListOptions.SEND;
     Integer replicationFactor = 2;
     Integer numberOfSlices = 4;
-    Integer maxShardsPerNode = 2;
     testTemplate(numberOfNodes, numberOfNodesToCreateOn, createNodeListOptions, replicationFactor, numberOfSlices,
-        maxShardsPerNode, false);
+        false);
   }
 
 }
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerTest.java
index 8be7a2c2332..ebb6c75aa64 100644
--- a/solr/core/src/test/org/apache/solr/cloud/OverseerTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/OverseerTest.java
@@ -1109,8 +1109,7 @@ public class OverseerTest extends SolrTestCaseJ4 {
         ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.CREATE.toLower(),
             "name", "perf" + i,
             ZkStateReader.NUM_SHARDS_PROP, "1",
-            ZkStateReader.REPLICATION_FACTOR, "1",
-            ZkStateReader.MAX_SHARDS_PER_NODE, "1"
+            ZkStateReader.REPLICATION_FACTOR, "1"
             );
         ZkDistributedQueue q = overseers.get(0).getStateUpdateQueue();
         q.offer(Utils.toJSON(m));
@@ -1471,13 +1470,11 @@ public class OverseerTest extends SolrTestCaseJ4 {
 
       // create collection
       {
-        final Integer maxShardsPerNode = numReplicas * numShards;
         zkClient.makePath(ZkStateReader.COLLECTIONS_ZKNODE + "/" + COLLECTION, true);
         ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, CollectionParams.CollectionAction.CREATE.toLower(),
             "name", COLLECTION,
             ZkStateReader.NUM_SHARDS_PROP, numShards.toString(),
-            ZkStateReader.REPLICATION_FACTOR, "1",
-            ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode.toString()
+            ZkStateReader.REPLICATION_FACTOR, "1"
             );
         q.offer(Utils.toJSON(m));
       }
diff --git a/solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest.java b/solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest.java
index 5693330c45a..a5f1e063148 100644
--- a/solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/RecoveryZkTest.java
@@ -68,7 +68,6 @@ public class RecoveryZkTest extends SolrCloudTestCase {
     final String collection = "recoverytest";
 
     CollectionAdminRequest.createCollection(collection, "conf", 1, 2)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
     waitForState("Expected a collection with one shard and two replicas", collection, clusterShape(1, 2));
     cluster.getSolrClient().setDefaultCollection(collection);
diff --git a/solr/core/src/test/org/apache/solr/cloud/ReindexCollectionTest.java b/solr/core/src/test/org/apache/solr/cloud/ReindexCollectionTest.java
index 8bd0c875748..555e040d18a 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ReindexCollectionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ReindexCollectionTest.java
@@ -380,7 +380,6 @@ public class ReindexCollectionTest extends SolrCloudTestCase {
 
   private void createCollection(String name, String config, int numShards, int numReplicas) throws Exception {
     CollectionAdminRequest.createCollection(name, config, numShards, numReplicas)
-        .setMaxShardsPerNode(-1)
         .process(solrClient);
 
     cluster.waitForActiveCollection(name, numShards, numShards * numReplicas);
diff --git a/solr/core/src/test/org/apache/solr/cloud/ReplaceNodeTest.java b/solr/core/src/test/org/apache/solr/cloud/ReplaceNodeTest.java
index b60c8508c2e..4979dd2d8dd 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ReplaceNodeTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ReplaceNodeTest.java
@@ -85,7 +85,7 @@ public class ReplaceNodeTest extends SolrCloudTestCase {
                         CollectionAdminRequest.createCollection(coll, "conf1", 5, 1,0,0)
                         //CollectionAdminRequest.createCollection(coll, "conf1", 5, 0,1,0)
     );
-    create.setCreateNodeSet(StrUtils.join(l, ',')).setMaxShardsPerNode(3);
+    create.setCreateNodeSet(StrUtils.join(l, ','));
     cloudClient.request(create);
     
     cluster.waitForActiveCollection(coll, 5, 5 * (create.getNumNrtReplicas() + create.getNumPullReplicas() + create.getNumTlogReplicas()));
diff --git a/solr/core/src/test/org/apache/solr/cloud/ReplicationFactorTest.java b/solr/core/src/test/org/apache/solr/cloud/ReplicationFactorTest.java
index b4e7e286b83..41d50f3e5c7 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ReplicationFactorTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ReplicationFactorTest.java
@@ -103,11 +103,10 @@ public class ReplicationFactorTest extends AbstractFullDistribZkTestBase {
   protected void testRf2NotUsingDirectUpdates() throws Exception {
     int numShards = 2;
     int replicationFactor = 2;
-    int maxShardsPerNode = 1;
     String testCollectionName = "repfacttest_c8n_2x2";
     String shardId = "shard1";
 
-    createCollectionWithRetry(testCollectionName, "conf1", numShards, replicationFactor, maxShardsPerNode);
+    createCollectionWithRetry(testCollectionName, "conf1", numShards, replicationFactor);
 
     cloudClient.setDefaultCollection(testCollectionName);
     
@@ -276,12 +275,11 @@ public class ReplicationFactorTest extends AbstractFullDistribZkTestBase {
   protected void testRf3() throws Exception {
     final int numShards = 1;
     final int replicationFactor = 3;
-    final int maxShardsPerNode = 1;
     final String testCollectionName = "repfacttest_c8n_1x3";
     final String shardId = "shard1";
     final int minRf = 2;
 
-    createCollectionWithRetry(testCollectionName, "conf1", numShards, replicationFactor, maxShardsPerNode);
+    createCollectionWithRetry(testCollectionName, "conf1", numShards, replicationFactor);
     cloudClient.setDefaultCollection(testCollectionName);
     
     List<Replica> replicas = 
@@ -503,15 +501,15 @@ public class ReplicationFactorTest extends AbstractFullDistribZkTestBase {
     }
   }
 
-  void createCollectionWithRetry(String testCollectionName, String config, int numShards, int replicationFactor, int maxShardsPerNode) throws IOException, SolrServerException, InterruptedException, TimeoutException {
-    CollectionAdminResponse resp = createCollection(testCollectionName, "conf1", numShards, replicationFactor, maxShardsPerNode);
+  void createCollectionWithRetry(String testCollectionName, String config, int numShards, int replicationFactor) throws IOException, SolrServerException, InterruptedException, TimeoutException {
+    CollectionAdminResponse resp = createCollection(testCollectionName, "conf1", numShards, replicationFactor);
 
     if (resp.getResponse().get("failure") != null) {
       Thread.sleep(5000); // let system settle down. This should be very rare.
 
       CollectionAdminRequest.deleteCollection(testCollectionName).process(cloudClient);
 
-      resp = createCollection(testCollectionName, "conf1", numShards, replicationFactor, maxShardsPerNode);
+      resp = createCollection(testCollectionName, "conf1", numShards, replicationFactor);
 
       if (resp.getResponse().get("failure") != null) {
         fail("Could not create " + testCollectionName);
diff --git a/solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java b/solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java
index 2f2217b5f1d..3fe4d7d25f0 100644
--- a/solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java
@@ -156,7 +156,6 @@ public class SharedFSAutoReplicaFailoverTest extends AbstractFullDistribZkTestBa
   private void testBasics() throws Exception {
     String collection1 = "solrj_collection";
     Create createCollectionRequest = CollectionAdminRequest.createCollection(collection1,"conf1",2,2)
-            .setMaxShardsPerNode(2)
             .setRouterField("myOwnField")
             .setAutoAddReplicas(true);
     CollectionAdminResponse response = createCollectionRequest.process(cloudClient);
@@ -167,7 +166,6 @@ public class SharedFSAutoReplicaFailoverTest extends AbstractFullDistribZkTestBa
     
     String collection2 = "solrj_collection2";
     createCollectionRequest = CollectionAdminRequest.createCollection(collection2,"conf1",2,2)
-            .setMaxShardsPerNode(2)
             .setRouterField("myOwnField")
             .setAutoAddReplicas(false);
     CollectionAdminResponse response2 = createCollectionRequest.process(getCommonCloudSolrClient());
@@ -179,7 +177,6 @@ public class SharedFSAutoReplicaFailoverTest extends AbstractFullDistribZkTestBa
     
     String collection3 = "solrj_collection3";
     createCollectionRequest = CollectionAdminRequest.createCollection(collection3,"conf1",5,1)
-            .setMaxShardsPerNode(1)
             .setRouterField("myOwnField")
             .setAutoAddReplicas(true);
     CollectionAdminResponse response3 = createCollectionRequest.process(getCommonCloudSolrClient());
@@ -192,7 +189,6 @@ public class SharedFSAutoReplicaFailoverTest extends AbstractFullDistribZkTestBa
     // a collection has only 1 replica per a shard
     String collection4 = "solrj_collection4";
     createCollectionRequest = CollectionAdminRequest.createCollection(collection4,"conf1",5,1)
-        .setMaxShardsPerNode(5)
         .setRouterField("text")
         .setAutoAddReplicas(true);
     CollectionAdminResponse response4 = createCollectionRequest.process(getCommonCloudSolrClient());
diff --git a/solr/core/src/test/org/apache/solr/cloud/SplitShardTest.java b/solr/core/src/test/org/apache/solr/cloud/SplitShardTest.java
index 98240e6c250..ea1aa2ef641 100644
--- a/solr/core/src/test/org/apache/solr/cloud/SplitShardTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/SplitShardTest.java
@@ -76,7 +76,6 @@ public class SplitShardTest extends SolrCloudTestCase {
   public void doTest() throws IOException, SolrServerException {
     CollectionAdminRequest
         .createCollection(COLLECTION_NAME, "conf", 2, 1)
-        .setMaxShardsPerNode(100)
         .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(COLLECTION_NAME, 2, 2);
@@ -127,7 +126,6 @@ public class SplitShardTest extends SolrCloudTestCase {
     String collectionName = "splitFuzzCollection";
     CollectionAdminRequest
         .createCollection(collectionName, "conf", 2, 1)
-        .setMaxShardsPerNode(100)
         .process(cluster.getSolrClient());
 
     cluster.waitForActiveCollection(collectionName, 2, 2);
@@ -156,7 +154,6 @@ public class SplitShardTest extends SolrCloudTestCase {
 
       CollectionAdminRequest
           .createCollection(collectionName, "conf", 1, repFactor)
-          .setMaxShardsPerNode(100)
           .process(cluster.getSolrClient());
 
     cluster.waitForActiveCollection(collectionName, 1, repFactor);
diff --git a/solr/core/src/test/org/apache/solr/cloud/SystemCollectionCompatTest.java b/solr/core/src/test/org/apache/solr/cloud/SystemCollectionCompatTest.java
index fba4aff67ea..197f0352f2d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/SystemCollectionCompatTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/SystemCollectionCompatTest.java
@@ -90,7 +90,6 @@ public class SystemCollectionCompatTest extends SolrCloudTestCase {
     // put .system replicas on other nodes that the overseer
     CollectionAdminRequest.createCollection(CollectionAdminParams.SYSTEM_COLL, null, 1, 2)
         .setCreateNodeSet(String.join(",", nodes))
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
     cluster.waitForActiveCollection(CollectionAdminParams.SYSTEM_COLL,  1, 2);
     // send a dummy doc to the .system collection
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestAuthenticationFramework.java b/solr/core/src/test/org/apache/solr/cloud/TestAuthenticationFramework.java
index fa19dcc92b2..3f26b7effe5 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestAuthenticationFramework.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestAuthenticationFramework.java
@@ -47,8 +47,7 @@ public class TestAuthenticationFramework extends SolrCloudTestCase {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
   private static final int numShards = 2;
   private static final int numReplicas = 2;
-  private static final int maxShardsPerNode = 2;
-  private static final int nodeCount = (numShards*numReplicas + (maxShardsPerNode-1))/maxShardsPerNode;
+  private static final int nodeCount = numShards*numReplicas;
   private static final String configName = "solrCloudCollectionConfig";
   private static final String collectionName = "testcollection";
 
@@ -97,13 +96,11 @@ public class TestAuthenticationFramework extends SolrCloudTestCase {
       throws Exception {
     if (random().nextBoolean()) {  // process asynchronously
       CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)
-          .setMaxShardsPerNode(maxShardsPerNode)
           .processAndWait(cluster.getSolrClient(), 90);
       cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);
     }
     else {
       CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)
-          .setMaxShardsPerNode(maxShardsPerNode)
           .process(cluster.getSolrClient());
       cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);
     }
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestBaseStatsCacheCloud.java b/solr/core/src/test/org/apache/solr/cloud/TestBaseStatsCacheCloud.java
index 2a200fa2f79..fb8cd79aa70 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestBaseStatsCacheCloud.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestBaseStatsCacheCloud.java
@@ -95,7 +95,6 @@ public abstract class TestBaseStatsCacheCloud extends SolrCloudTestCase {
 
   protected void createTestCollection() throws Exception {
     CollectionAdminRequest.createCollection(collectionName, "conf", 2, numNodes)
-        .setMaxShardsPerNode(2)
         .process(solrClient);
     indexDocs(solrClient, collectionName, NUM_DOCS, 0, generator);
     indexDocs(control, "collection1", NUM_DOCS, 0, generator);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestCloudRecovery.java b/solr/core/src/test/org/apache/solr/cloud/TestCloudRecovery.java
index 2afeea9ade4..ff66e258ac6 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestCloudRecovery.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestCloudRecovery.java
@@ -74,7 +74,6 @@ public class TestCloudRecovery extends SolrCloudTestCase {
                           // TestInjection#waitForInSyncWithLeader is broken
     CollectionAdminRequest
         .createCollection(COLLECTION, "config", 2, nrtReplicas, tlogReplicas, 0)
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
     cluster.waitForActiveCollection(COLLECTION, 2, 2 * (nrtReplicas + tlogReplicas));
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestCloudRecovery2.java b/solr/core/src/test/org/apache/solr/cloud/TestCloudRecovery2.java
index ae5e769d47d..8167f2cc059 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestCloudRecovery2.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestCloudRecovery2.java
@@ -45,7 +45,6 @@ public class TestCloudRecovery2 extends SolrCloudTestCase {
 
     CollectionAdminRequest
         .createCollection(COLLECTION, "config", 1,2)
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
     AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION, cluster.getSolrClient().getZkStateReader(),
         false, true, 30);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestCloudSearcherWarming.java b/solr/core/src/test/org/apache/solr/cloud/TestCloudSearcherWarming.java
index 5e20994e597..247313e5bb4 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestCloudSearcherWarming.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestCloudSearcherWarming.java
@@ -141,7 +141,7 @@ public class TestCloudSearcherWarming extends SolrCloudTestCase {
 
     String collectionName = "testPeersyncFailureReplicationSuccess";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, 1, 1)
-        .setCreateNodeSet(cluster.getJettySolrRunner(0).getNodeName()).setMaxShardsPerNode(2);
+        .setCreateNodeSet(cluster.getJettySolrRunner(0).getNodeName());
     create.process(solrClient);
 
     waitForState("The collection should have 1 shard and 1 replica", collectionName, clusterShape(1, 1));
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestDeleteCollectionOnDownNodes.java b/solr/core/src/test/org/apache/solr/cloud/TestDeleteCollectionOnDownNodes.java
index e6836a32987..f2146be7f19 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestDeleteCollectionOnDownNodes.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestDeleteCollectionOnDownNodes.java
@@ -44,7 +44,6 @@ public class TestDeleteCollectionOnDownNodes extends SolrCloudTestCase {
   public void deleteCollectionWithDownNodes() throws Exception {
 
     CollectionAdminRequest.createCollection("halfdeletedcollection2", "conf", 4, 3)
-        .setMaxShardsPerNode(3)
         .process(cluster.getSolrClient());
 
     cluster.waitForActiveCollection("halfdeletedcollection2", 60, TimeUnit.SECONDS, 4, 12);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestDynamicFieldNamesIndexCorrectly.java b/solr/core/src/test/org/apache/solr/cloud/TestDynamicFieldNamesIndexCorrectly.java
index 207e255e297..f568d21d440 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestDynamicFieldNamesIndexCorrectly.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestDynamicFieldNamesIndexCorrectly.java
@@ -56,7 +56,7 @@ public class TestDynamicFieldNamesIndexCorrectly extends AbstractFullDistribZkTe
   public void test() throws Exception {
     waitForThingsToLevelOut(30, TimeUnit.SECONDS);
 
-    createCollection(COLLECTION, "conf1", 4, 1, 4);
+    createCollection(COLLECTION, "conf1", 4, 1);
     final int numRuns = 10;
     populateIndex(numRuns);
   }
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestOnReconnectListenerSupport.java b/solr/core/src/test/org/apache/solr/cloud/TestOnReconnectListenerSupport.java
index e50c57166e6..a2039cdb331 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestOnReconnectListenerSupport.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestOnReconnectListenerSupport.java
@@ -64,7 +64,7 @@ public class TestOnReconnectListenerSupport extends AbstractFullDistribZkTestBas
 
     String testCollectionName = "c8n_onreconnect_1x1";
     String shardId = "shard1";
-    createCollectionRetry(testCollectionName, "conf1", 1, 1, 1);
+    createCollectionRetry(testCollectionName, "conf1", 1, 1);
     cloudClient.setDefaultCollection(testCollectionName);
 
     Replica leader = getShardLeader(testCollectionName, shardId, 30 /* timeout secs */);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestPullReplica.java b/solr/core/src/test/org/apache/solr/cloud/TestPullReplica.java
index 65a03e8ef0a..5e06c28b5b9 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestPullReplica.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestPullReplica.java
@@ -130,17 +130,15 @@ public class TestPullReplica extends SolrCloudTestCase {
         case 0:
           // Sometimes use SolrJ
           CollectionAdminRequest.createCollection(collectionName, "conf", 2, 1, 0, 3)
-          .setMaxShardsPerNode(100)
           .process(cluster.getSolrClient());
           break;
         case 1:
           // Sometimes use v1 API
-          String url = String.format(Locale.ROOT, "%s/admin/collections?action=CREATE&name=%s&collection.configName=%s&numShards=%s&pullReplicas=%s&maxShardsPerNode=%s",
+          String url = String.format(Locale.ROOT, "%s/admin/collections?action=CREATE&name=%s&collection.configName=%s&numShards=%s&pullReplicas=%s",
               cluster.getRandomJetty(random()).getBaseUrl(),
               collectionName, "conf",
               2,    // numShards
-              3,    // pullReplicas
-              100); // maxShardsPerNode
+              3);   // pullReplicas
           url = url + pickRandom("", "&nrtReplicas=1", "&replicationFactor=1"); // These options should all mean the same
           HttpGet createCollectionGet = new HttpGet(url);
           cluster.getSolrClient().getHttpClient().execute(createCollectionGet);
@@ -148,11 +146,10 @@ public class TestPullReplica extends SolrCloudTestCase {
         case 2:
           // Sometimes use V2 API
           url = cluster.getRandomJetty(random()).getBaseUrl().toString() + "/____v2/c";
-          String requestBody = String.format(Locale.ROOT, "{create:{name:%s, config:%s, numShards:%s, pullReplicas:%s, maxShardsPerNode:%s %s}}",
+          String requestBody = String.format(Locale.ROOT, "{create:{name:%s, config:%s, numShards:%s, pullReplicas:%s, %s}}",
               collectionName, "conf",
               2,    // numShards
               3,    // pullReplicas
-              100, // maxShardsPerNode
               pickRandom("", ", nrtReplicas:1", ", replicationFactor:1")); // These options should all mean the same
           HttpPost createCollectionPost = new HttpPost(url);
           createCollectionPost.setHeader("Content-type", "application/json");
@@ -221,7 +218,6 @@ public class TestPullReplica extends SolrCloudTestCase {
   public void testAddDocs() throws Exception {
     int numPullReplicas = 1 + random().nextInt(3);
     CollectionAdminRequest.createCollection(collectionName, "conf", 1, 1, 0, numPullReplicas)
-    .setMaxShardsPerNode(100)
     .process(cluster.getSolrClient());
     waitForState("Expected collection to be created with 1 shard and " + (numPullReplicas + 1) + " replicas", collectionName, clusterShape(1, numPullReplicas + 1));
     DocCollection docCollection = assertNumberOfReplicas(1, 0, numPullReplicas, false, true);
@@ -279,7 +275,6 @@ public class TestPullReplica extends SolrCloudTestCase {
 
   public void testAddRemovePullReplica() throws Exception {
     CollectionAdminRequest.createCollection(collectionName, "conf", 2, 1, 0, 0)
-      .setMaxShardsPerNode(100)
       .process(cluster.getSolrClient());
     waitForState("Expected collection to be created with 2 shards and 1 replica each", collectionName, clusterShape(2, 2));
     DocCollection docCollection = assertNumberOfReplicas(2, 0, 0, false, true);
@@ -315,7 +310,6 @@ public class TestPullReplica extends SolrCloudTestCase {
   public void testPullReplicaStates() throws Exception {
     // Validate that pull replicas go through the correct states when starting, stopping, reconnecting
     CollectionAdminRequest.createCollection(collectionName, "conf", 1, 1, 0, 0)
-      .setMaxShardsPerNode(100)
       .process(cluster.getSolrClient());
 //    cluster.getSolrClient().getZkStateReader().registerCore(collectionName); //TODO: Is this needed?
     waitForState("Replica not added", collectionName, activeReplicaCount(1, 0, 0));
@@ -349,7 +343,6 @@ public class TestPullReplica extends SolrCloudTestCase {
     // should be redirected to Replica.Type.NRT
     int numReplicas = random().nextBoolean()?1:2;
     CollectionAdminRequest.createCollection(collectionName, "conf", 1, numReplicas, 0, numReplicas)
-      .setMaxShardsPerNode(100)
       .process(cluster.getSolrClient());
     waitForState("Unexpected replica count", collectionName, activeReplicaCount(numReplicas, 0, numReplicas));
     DocCollection docCollection = assertNumberOfReplicas(numReplicas, 0, numReplicas, false, true);
@@ -394,7 +387,6 @@ public class TestPullReplica extends SolrCloudTestCase {
   @SuppressWarnings({"try"})
   private void doTestNoLeader(boolean removeReplica) throws Exception {
     CollectionAdminRequest.createCollection(collectionName, "conf", 1, 1, 0, 1)
-      .setMaxShardsPerNode(100)
       .process(cluster.getSolrClient());
     waitForState("Expected collection to be created with 1 shard and 2 replicas", collectionName, clusterShape(1, 2));
     DocCollection docCollection = assertNumberOfReplicas(1, 0, 1, false, true);
@@ -500,7 +492,6 @@ public class TestPullReplica extends SolrCloudTestCase {
 
   public void testKillPullReplica() throws Exception {
     CollectionAdminRequest.createCollection(collectionName, "conf", 1, 1, 0, 1)
-      .setMaxShardsPerNode(100)
       .process(cluster.getSolrClient());
 //    cluster.getSolrClient().getZkStateReader().registerCore(collectionName); //TODO: Is this needed?
     waitForState("Expected collection to be created with 1 shard and 2 replicas", collectionName, clusterShape(1, 2));
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestPullReplicaErrorHandling.java b/solr/core/src/test/org/apache/solr/cloud/TestPullReplicaErrorHandling.java
index 4ede3ea43fb..72a3246f1a2 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestPullReplicaErrorHandling.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestPullReplicaErrorHandling.java
@@ -129,7 +129,6 @@ public class TestPullReplicaErrorHandling extends SolrCloudTestCase {
 public void testCantConnectToPullReplica() throws Exception {
     int numShards = 2;
     CollectionAdminRequest.createCollection(collectionName, "conf", numShards, 1, 0, 1)
-      .setMaxShardsPerNode(1)
       .process(cluster.getSolrClient());
     cluster.waitForActiveCollection(collectionName, numShards, numShards * 2);
     addDocs(10);
@@ -172,7 +171,6 @@ public void testCantConnectToPullReplica() throws Exception {
   public void testCantConnectToLeader() throws Exception {
     int numShards = 1;
     CollectionAdminRequest.createCollection(collectionName, "conf", numShards, 1, 0, 1)
-      .setMaxShardsPerNode(1)
       .process(cluster.getSolrClient());
     cluster.waitForActiveCollection(collectionName, numShards, numShards * 2);
     addDocs(10);
@@ -208,7 +206,6 @@ public void testCantConnectToPullReplica() throws Exception {
   public void testPullReplicaDisconnectsFromZooKeeper() throws Exception {
     int numShards = 1;
     CollectionAdminRequest.createCollection(collectionName, "conf", numShards, 1, 0, 1)
-      .setMaxShardsPerNode(1)
       .process(cluster.getSolrClient());
     addDocs(10);
     DocCollection docCollection = assertNumberOfReplicas(numShards, 0, numShards, false, true);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java b/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
index e981167b6ac..8a0a874adf6 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
@@ -68,7 +68,6 @@ public class TestRebalanceLeaders extends SolrCloudTestCase {
 
     CollectionAdminResponse resp = CollectionAdminRequest.createCollection(COLLECTION_NAME, COLLECTION_NAME,
         numShards, numReplicas, 0, 0)
-        .setMaxShardsPerNode((numShards * numReplicas) / numNodes + 1)
         .process(cluster.getSolrClient());
     assertEquals("Admin request failed; ", 0, resp.getStatus());
     cluster.waitForActiveCollection(COLLECTION_NAME, numShards, numShards * numReplicas);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestRequestForwarding.java b/solr/core/src/test/org/apache/solr/cloud/TestRequestForwarding.java
index a479e5fde65..45ac57777ec 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestRequestForwarding.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestRequestForwarding.java
@@ -73,7 +73,6 @@ public class TestRequestForwarding extends SolrTestCaseJ4 {
   private void createCollection(String name, String config) throws Exception {
     CollectionAdminResponse response;
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(name,config,2,1);
-    create.setMaxShardsPerNode(1);
     response = create.process(solrCluster.getSolrClient());
     
     if (response.getStatus() != 0 || response.getErrorMessages() != null) {
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestSkipOverseerOperations.java b/solr/core/src/test/org/apache/solr/cloud/TestSkipOverseerOperations.java
index 73bf698df78..ce728002317 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestSkipOverseerOperations.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestSkipOverseerOperations.java
@@ -141,7 +141,6 @@ public class TestSkipOverseerOperations extends SolrCloudTestCase {
             .map(JettySolrRunner::getNodeName)
             .collect(Collectors.joining(","))
         )
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(collection, 2, 4);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt.java b/solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt.java
index 2923211109c..671e2bd3664 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithKerberosAlt.java
@@ -50,8 +50,7 @@ public class TestSolrCloudWithKerberosAlt extends SolrCloudTestCase {
 
   private static final int numShards = 1;
   private static final int numReplicas = 1;
-  private static final int maxShardsPerNode = 1;
-  private static final int nodeCount = (numShards*numReplicas + (maxShardsPerNode-1))/maxShardsPerNode;
+  private static final int nodeCount = numShards*numReplicas;
   private static final String configName = "solrCloudCollectionConfig";
   private static final String collectionName = "testkerberoscollection";
   
@@ -122,7 +121,6 @@ public class TestSolrCloudWithKerberosAlt extends SolrCloudTestCase {
   private void testCollectionCreateSearchDelete() throws Exception {
     CloudSolrClient client = cluster.getSolrClient();
     CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)
-        .setMaxShardsPerNode(maxShardsPerNode)
         .process(client);
 
     cluster.waitForActiveCollection(collectionName, numShards, numShards * numReplicas);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithSecureImpersonation.java b/solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithSecureImpersonation.java
index ee1515f01c0..bc18ddf6810 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithSecureImpersonation.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestSolrCloudWithSecureImpersonation.java
@@ -183,7 +183,6 @@ public class TestSolrCloudWithSecureImpersonation extends SolrTestCaseJ4 {
         return msp;
       }
     };
-    create.setMaxShardsPerNode(1);
     response = create.process(solrCluster.getSolrClient());
 
     miniCluster.waitForActiveCollection(name, 1, 1);
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestTlogReplica.java b/solr/core/src/test/org/apache/solr/cloud/TestTlogReplica.java
index 060ff61bc28..d68f46b632f 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestTlogReplica.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestTlogReplica.java
@@ -147,18 +147,16 @@ public class TestTlogReplica extends SolrCloudTestCase {
     switch (random().nextInt(3)) {
       case 0:
         CollectionAdminRequest.createCollection(collectionName, "conf", 2, 0, 4, 0)
-        .setMaxShardsPerNode(100)
         .process(cluster.getSolrClient());
         cluster.waitForActiveCollection(collectionName, 2, 8);
         break;
       case 1:
         // Sometimes don't use SolrJ
-        String url = String.format(Locale.ROOT, "%s/admin/collections?action=CREATE&name=%s&collection.configName=%s&numShards=%s&tlogReplicas=%s&maxShardsPerNode=%s",
+        String url = String.format(Locale.ROOT, "%s/admin/collections?action=CREATE&name=%s&collection.configName=%s&numShards=%s&tlogReplicas=%s",
             cluster.getRandomJetty(random()).getBaseUrl(),
             collectionName, "conf",
             2,    // numShards
-            4,    // tlogReplicas
-            100); // maxShardsPerNode
+            4);   // tlogReplicas
         HttpGet createCollectionGet = new HttpGet(url);
         HttpResponse httpResponse = cluster.getSolrClient().getHttpClient().execute(createCollectionGet);
         assertEquals(200, httpResponse.getStatusLine().getStatusCode());
@@ -167,11 +165,11 @@ public class TestTlogReplica extends SolrCloudTestCase {
       case 2:
         // Sometimes use V2 API
         url = cluster.getRandomJetty(random()).getBaseUrl().toString() + "/____v2/c";
-        String requestBody = String.format(Locale.ROOT, "{create:{name:%s, config:%s, numShards:%s, tlogReplicas:%s, maxShardsPerNode:%s}}",
+        String requestBody = String.format(Locale.ROOT, "{create:{name:%s, config:%s, numShards:%s, tlogReplicas:%s}}",
             collectionName, "conf",
             2,    // numShards
-            4,    // tlogReplicas
-            100); // maxShardsPerNode
+            4);   // tlogReplicas
+
         HttpPost createCollectionPost = new HttpPost(url);
         createCollectionPost.setHeader("Content-type", "application/json");
         createCollectionPost.setEntity(new StringEntity(requestBody));
@@ -323,7 +321,6 @@ public class TestTlogReplica extends SolrCloudTestCase {
     int numReplicas = random().nextBoolean()?1:2;
     int numNrtReplicas = random().nextBoolean()?0:2;
     CollectionAdminRequest.createCollection(collectionName, "conf", 1, numNrtReplicas, numReplicas, 0)
-      .setMaxShardsPerNode(100)
       .process(cluster.getSolrClient());
     waitForState("Unexpected replica count", collectionName, activeReplicaCount(numNrtReplicas, numReplicas, 0));
     DocCollection docCollection = assertNumberOfReplicas(numNrtReplicas, numReplicas, 0, false, true);
@@ -748,7 +745,6 @@ public class TestTlogReplica extends SolrCloudTestCase {
 
   private DocCollection createAndWaitForCollection(int numShards, int numNrtReplicas, int numTlogReplicas, int numPullReplicas) throws SolrServerException, IOException, KeeperException, InterruptedException {
     CollectionAdminRequest.createCollection(collectionName, "conf", numShards, numNrtReplicas, numTlogReplicas, numPullReplicas)
-    .setMaxShardsPerNode(100)
     .process(cluster.getSolrClient());
     int numReplicasPerShard = numNrtReplicas + numTlogReplicas + numPullReplicas;
     waitForState("Expected collection to be created with " + numShards + " shards and  " + numReplicasPerShard + " replicas",
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestUtilizeNode.java b/solr/core/src/test/org/apache/solr/cloud/TestUtilizeNode.java
index cac7f76a074..68e1e882a1e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestUtilizeNode.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestUtilizeNode.java
@@ -77,8 +77,7 @@ public class TestUtilizeNode extends SolrCloudTestCase {
     CloudSolrClient cloudClient = cluster.getSolrClient();
     
     log.info("Creating Collection...");
-    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, "conf1", 2, 2)
-        .setMaxShardsPerNode(2);
+    CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(coll, "conf1", 2, 2);
     cloudClient.request(create);
 
     log.info("Spinning up additional jettyX...");
diff --git a/solr/core/src/test/org/apache/solr/cloud/ZkShardTermsTest.java b/solr/core/src/test/org/apache/solr/cloud/ZkShardTermsTest.java
index 56ed8ae7cb4..f648eb23639 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ZkShardTermsTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ZkShardTermsTest.java
@@ -65,7 +65,6 @@ public class ZkShardTermsTest extends SolrCloudTestCase {
     // When new collection is created, the old term nodes will be removed
     CollectionAdminRequest.createCollection(collection, 2, 2)
         .setCreateNodeSet(cluster.getJettySolrRunner(0).getNodeName())
-        .setMaxShardsPerNode(1000)
         .process(cluster.getSolrClient());
     try (ZkShardTerms zkShardTerms = new ZkShardTerms(collection, "shard1", cluster.getZkClient())) {
       waitFor(2, () -> zkShardTerms.getTerms().size());
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/AbstractCloudBackupRestoreTestCase.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/AbstractCloudBackupRestoreTestCase.java
index 1b813515ead..74bcd753aaa 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/AbstractCloudBackupRestoreTestCase.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/AbstractCloudBackupRestoreTestCase.java
@@ -121,14 +121,6 @@ public abstract class AbstractCloudBackupRestoreTestCase extends SolrCloudTestCa
         CollectionAdminRequest.createCollectionWithImplicitRouter(getCollectionName(), "conf1", "shard1,shard2", replFactor, numTlogReplicas, numPullReplicas) :
         CollectionAdminRequest.createCollection(getCollectionName(), "conf1", NUM_SHARDS, replFactor, numTlogReplicas, numPullReplicas);
 
-    if (random().nextBoolean()) {
-      create.setMaxShardsPerNode(-1);
-    } else if (doSplitShardOperation) {
-      create.setMaxShardsPerNode((int) Math.ceil(NUM_SPLIT_SHARDS * backupReplFactor / (double) cluster.getJettySolrRunners().size()));
-    } else if (NUM_SHARDS * (backupReplFactor) > cluster.getJettySolrRunners().size() || random().nextBoolean()) {
-      create.setMaxShardsPerNode((int) Math.ceil(NUM_SHARDS * backupReplFactor / (double) cluster.getJettySolrRunners().size()));//just to assert it survives the restoration
-    }
-
     if (random().nextBoolean()) {
       create.setAutoAddReplicas(true);//just to assert it survives the restoration
     }
@@ -178,10 +170,6 @@ public abstract class AbstractCloudBackupRestoreTestCase extends SolrCloudTestCa
     CollectionAdminRequest.Create create =
         CollectionAdminRequest.createCollection(getCollectionName(), "conf1", NUM_SHARDS, replFactor, numTlogReplicas, numPullReplicas);
 
-    if (NUM_SHARDS * (replFactor + numTlogReplicas + numPullReplicas) > cluster.getJettySolrRunners().size()) {
-      create.setMaxShardsPerNode((int)Math.ceil(NUM_SHARDS * (replFactor + numTlogReplicas + numPullReplicas) / cluster.getJettySolrRunners().size())); //just to assert it survives the restoration
-    }
-
     CloudSolrClient solrClient = cluster.getSolrClient();
     create.process(solrClient);
 
@@ -208,10 +196,6 @@ public abstract class AbstractCloudBackupRestoreTestCase extends SolrCloudTestCa
     {
       CollectionAdminRequest.Restore restore = CollectionAdminRequest.restoreCollection(restoreCollectionName, backupName)
           .setLocation(backupLocation).setRepositoryName(getBackupRepoName());
-      if (backupCollection.getReplicas().size() > cluster.getJettySolrRunners().size()) {
-        // may need to increase maxShardsPerNode (e.g. if it was shard split, then now we need more)
-        restore.setMaxShardsPerNode((int)Math.ceil(backupCollection.getReplicas().size()/cluster.getJettySolrRunners().size()));
-      }
 
       restore.setConfigName("confFaulty");
       assertEquals(RequestStatusState.FAILED, restore.processAndWait(solrClient, 30));
@@ -339,8 +323,6 @@ public abstract class AbstractCloudBackupRestoreTestCase extends SolrCloudTestCa
 
     int restoreReplFactor = restoreReplcationFactor + restoreTlogReplicas + restorePullReplicas;
 
-    boolean isMaxShardsPerNodeExternal = false;
-    boolean isMaxShardsUnlimited = false;
     CollectionAdminRequest.Restore restore = CollectionAdminRequest.restoreCollection(restoreCollectionName, backupName)
         .setLocation(backupLocation).setRepositoryName(getBackupRepoName());
 
@@ -352,28 +334,9 @@ public abstract class AbstractCloudBackupRestoreTestCase extends SolrCloudTestCa
     }
     int computeRestoreMaxShardsPerNode = (int) Math.ceil((restoreReplFactor * numShards/(double) cluster.getJettySolrRunners().size()));
 
-    if (restoreReplFactor > backupReplFactor) { //else the backup maxShardsPerNode should be enough
-      if (log.isInfoEnabled()) {
-        log.info("numShards={} restoreReplFactor={} maxShardsPerNode={} totalNodes={}",
-            numShards, restoreReplFactor, computeRestoreMaxShardsPerNode, cluster.getJettySolrRunners().size());
-      }
-
-      if (random().nextBoolean()) { //set it to -1
-        isMaxShardsUnlimited = true;
-        restore.setMaxShardsPerNode(-1);
-      } else {
-        isMaxShardsPerNodeExternal = true;
-        restore.setMaxShardsPerNode(computeRestoreMaxShardsPerNode);
-      }
-    }
-
     if (rarely()) { // Try with createNodeSet configuration
       //Always 1 as cluster.getJettySolrRunners().size()=NUM_SHARDS=2
       restore.setCreateNodeSet(cluster.getJettySolrRunners().get(0).getNodeName());
-      // we need to double maxShardsPerNode value since we reduced number of available nodes by half.
-      isMaxShardsPerNodeExternal = true;
-      computeRestoreMaxShardsPerNode = origShardToDocCount.size() * restoreReplFactor;
-      restore.setMaxShardsPerNode(computeRestoreMaxShardsPerNode);
     }
 
     final int restoreMaxShardsPerNode = computeRestoreMaxShardsPerNode;
@@ -420,13 +383,6 @@ public abstract class AbstractCloudBackupRestoreTestCase extends SolrCloudTestCa
     assertEquals(restoreCollection.toString(), restoreReplcationFactor, restoreCollection.getNumNrtReplicas().intValue());
     assertEquals(restoreCollection.toString(), restorePullReplicas, restoreCollection.getNumPullReplicas().intValue());
     assertEquals(restoreCollection.toString(), restoreTlogReplicas, restoreCollection.getNumTlogReplicas().intValue());
-    if (isMaxShardsPerNodeExternal) {
-      assertEquals(restoreCollectionName, restoreMaxShardsPerNode, restoreCollection.getMaxShardsPerNode());
-    } else if (isMaxShardsUnlimited){
-      assertEquals(restoreCollectionName, -1, restoreCollection.getMaxShardsPerNode());
-    } else {
-      assertEquals(restoreCollectionName, backupCollection.getMaxShardsPerNode(), restoreCollection.getMaxShardsPerNode());
-    }
 
     //SOLR-12605: Add more docs after restore is complete to see if they are getting added fine
     //explicitly querying the leaders. If we use CloudSolrClient there is no guarantee that we'll hit a nrtReplica
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/AsyncCallRequestStatusResponseTest.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/AsyncCallRequestStatusResponseTest.java
index d00dd679f5d..45220d83a6d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/AsyncCallRequestStatusResponseTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/AsyncCallRequestStatusResponseTest.java
@@ -53,7 +53,6 @@ public class AsyncCallRequestStatusResponseTest extends SolrCloudTestCase {
     int numShards = 4;
     int numReplicas = 1;
     Create createCollection = CollectionAdminRequest.createCollection("asynccall", "conf", numShards, numReplicas);
-    createCollection.setMaxShardsPerNode(100);
     String asyncId =
         createCollection.processAsync(cluster.getSolrClient());
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/CollectionTooManyReplicasTest.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/CollectionTooManyReplicasTest.java
index 25aaf4ecb8c..6489f1c3fc5 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/CollectionTooManyReplicasTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/CollectionTooManyReplicasTest.java
@@ -21,8 +21,10 @@ import java.util.Map;
 import java.util.stream.Collectors;
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
+import org.apache.solr.cloud.CloudTestUtils;
 import org.apache.solr.cloud.SolrCloudTestCase;
 import org.apache.solr.common.cloud.DocCollection;
 import org.apache.solr.common.cloud.Replica;
@@ -49,53 +51,49 @@ public class CollectionTooManyReplicasTest extends SolrCloudTestCase {
 
   @Test
   public void testAddTooManyReplicas() throws Exception {
+
     final String collectionName = "TooManyReplicasInSeveralFlavors";
     CollectionAdminRequest.createCollection(collectionName, "conf", 2, 1)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
 
     // I have two replicas, one for each shard
 
-    // Curiously, I should be able to add a bunch of replicas if I specify the node, even more than maxShardsPerNode
     // Just get the first node any way we can.
     // Get a node to use for the "node" parameter.
     String nodeName = getAllNodeNames(collectionName).get(0);
 
-    // Add a replica using the "node" parameter (no "too many replicas check")
+    // Add a replica using the "node" parameter
     // this node should have 2 replicas on it
     CollectionAdminRequest.addReplicaToShard(collectionName, "shard1")
         .setNode(nodeName)
+        .withProperty("name", "bogus2")
         .process(cluster.getSolrClient());
 
-    // Three replicas so far, should be able to create another one "normally"
-    CollectionAdminRequest.addReplicaToShard(collectionName, "shard1")
-        .process(cluster.getSolrClient());
+    // equivalent to maxShardsPerNode=1
+    String commands =  "{ set-cluster-policy: [ {replica: '<2', shard: '#ANY', node: '#ANY', strict: true} ] }";
+    cluster.getSolrClient().request(CloudTestUtils.AutoScalingRequest.create(SolrRequest.METHOD.POST, commands));
 
-    // This one should fail though, no "node" parameter specified
+    // this should fail because the policy prevents it
     Exception e = expectThrows(Exception.class, () -> {
       CollectionAdminRequest.addReplicaToShard(collectionName, "shard1")
+          .setNode(nodeName)
           .process(cluster.getSolrClient());
     });
+    assertTrue(e.toString(), e.toString().contains("No node can satisfy"));
 
-    assertTrue("Should have gotten the right error message back",
-          e.getMessage().contains("given the current number of eligible live nodes"));
-
-
-    // Oddly, we should succeed next just because setting property.name will not check for nodes being "full up"
-    // TODO: Isn't this a bug?
+    // this should succeed because it places the replica on a different node
     CollectionAdminRequest.addReplicaToShard(collectionName, "shard1")
-        .withProperty("name", "bogus2")
-        .setNode(nodeName)
         .process(cluster.getSolrClient());
 
+
     DocCollection collectionState = getCollectionState(collectionName);
     Slice slice = collectionState.getSlice("shard1");
     Replica replica = getRandomReplica(slice, r -> r.getCoreName().equals("bogus2"));
     assertNotNull("Should have found a replica named 'bogus2'", replica);
-    assertEquals("Replica should have been put on correct core", nodeName, replica.getNodeName());
+    assertEquals("Replica should have been put on correct node", nodeName, replica.getNodeName());
 
-    // Shard1 should have 4 replicas
-    assertEquals("There should be 4 replicas for shard 1", 4, slice.getReplicas().size());
+    // Shard1 should have 2 replicas
+    assertEquals("There should be 3 replicas for shard 1", 3, slice.getReplicas().size());
 
     // And let's fail one more time because to ensure that the math doesn't do weird stuff it we have more replicas
     // than simple calcs would indicate.
@@ -105,7 +103,7 @@ public class CollectionTooManyReplicasTest extends SolrCloudTestCase {
     });
 
     assertTrue("Should have gotten the right error message back",
-        e2.getMessage().contains("given the current number of eligible live nodes"));
+        e2.getMessage().contains("No node can satisfy"));
 
     // wait for recoveries to finish, for a clean shutdown - see SOLR-9645
     waitForState("Expected to see all replicas active", collectionName, (n, c) -> {
@@ -119,10 +117,12 @@ public class CollectionTooManyReplicasTest extends SolrCloudTestCase {
 
   @Test
   public void testAddShard() throws Exception {
+    // equivalent to maxShardsPerNode=2
+    String commands =  "{ set-cluster-policy: [ {replica: '<3', shard: '#ANY', node: '#ANY', strict: true} ] }";
+    cluster.getSolrClient().request(CloudTestUtils.AutoScalingRequest.create(SolrRequest.METHOD.POST, commands));
 
     String collectionName = "TooManyReplicasWhenAddingShards";
     CollectionAdminRequest.createCollectionWithImplicitRouter(collectionName, "conf", "shardstart", 2)
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
 
     // We have two nodes, maxShardsPerNode is set to 2. Therefore, we should be able to add 2 shards each with
@@ -140,38 +140,40 @@ public class CollectionTooManyReplicasTest extends SolrCloudTestCase {
           .process(cluster.getSolrClient());
     });
     assertTrue("Should have gotten the right error message back",
-        e.getMessage().contains("given the current number of eligible live nodes"));
+        e.getMessage().contains("No node can satisfy the rules"));
 
     // Hmmm, providing a nodeset also overrides the checks for max replicas, so prove it.
     List<String> nodes = getAllNodeNames(collectionName);
 
-    CollectionAdminRequest.createShard(collectionName, "shard4")
-        .setNodeSet(String.join(",", nodes))
-        .process(cluster.getSolrClient());
-
-    // And just for yucks, insure we fail the "regular" one again.
     Exception e2 = expectThrows(Exception.class, () -> {
+      CollectionAdminRequest.createShard(collectionName, "shard4")
+          .setNodeSet(String.join(",", nodes))
+          .process(cluster.getSolrClient());
+    });
+    assertTrue("Should have gotten the right error message back",
+        e2.getMessage().contains("No node can satisfy the rules"));
+
+//    // And just for yucks, insure we fail the "regular" one again.
+    Exception e3 = expectThrows(Exception.class, () -> {
       CollectionAdminRequest.createShard(collectionName, "shard5")
           .process(cluster.getSolrClient());
     });
     assertTrue("Should have gotten the right error message back",
-        e2.getMessage().contains("given the current number of eligible live nodes"));
+        e3.getMessage().contains("No node can satisfy the rules"));
 
     // And finally, ensure that there are all the replicas we expect. We should have shards 1, 2 and 4 and each
     // should have exactly two replicas
-    waitForState("Expected shards shardstart, 1, 2 and 4, each with two active replicas", collectionName, (n, c) -> {
-      return DocCollection.isFullyActive(n, c, 4, 2);
+    waitForState("Expected shards shardstart, 1, 2, each with two active replicas", collectionName, (n, c) -> {
+      return DocCollection.isFullyActive(n, c, 3, 2);
     });
     Map<String, Slice> slices = getCollectionState(collectionName).getSlicesMap();
-    assertEquals("There should be exaclty four slices", slices.size(), 4);
+    assertEquals("There should be exaclty three slices", slices.size(), 3);
     assertNotNull("shardstart should exist", slices.get("shardstart"));
     assertNotNull("shard1 should exist", slices.get("shard1"));
     assertNotNull("shard2 should exist", slices.get("shard2"));
-    assertNotNull("shard4 should exist", slices.get("shard4"));
     assertEquals("Shardstart should have exactly 2 replicas", 2, slices.get("shardstart").getReplicas().size());
     assertEquals("Shard1 should have exactly 2 replicas", 2, slices.get("shard1").getReplicas().size());
     assertEquals("Shard2 should have exactly 2 replicas", 2, slices.get("shard2").getReplicas().size());
-    assertEquals("Shard4 should have exactly 2 replicas", 2, slices.get("shard4").getReplicas().size());
 
   }
 
@@ -179,7 +181,6 @@ public class CollectionTooManyReplicasTest extends SolrCloudTestCase {
   public void testDownedShards() throws Exception {
     String collectionName = "TooManyReplicasWhenAddingDownedNode";
     CollectionAdminRequest.createCollectionWithImplicitRouter(collectionName, "conf", "shardstart", 1)
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
 
     // Shut down a Jetty, I really don't care which
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/CollectionsAPIDistributedZkTest.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/CollectionsAPIDistributedZkTest.java
index ad02ab1e0b4..8d4f4413a41 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/CollectionsAPIDistributedZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/CollectionsAPIDistributedZkTest.java
@@ -224,16 +224,6 @@ public class CollectionsAPIDistributedZkTest extends SolrCloudTestCase {
     });
   }
 
-  @Test
-  public void testTooManyReplicas() {
-    @SuppressWarnings({"rawtypes"})
-    CollectionAdminRequest req = CollectionAdminRequest.createCollection("collection", "conf", 2, 10);
-
-    expectThrows(Exception.class, () -> {
-      cluster.getSolrClient().request(req);
-    });
-  }
-
   @Test
   public void testMissingNumShards() {
     // No numShards should fail
@@ -353,18 +343,6 @@ public class CollectionsAPIDistributedZkTest extends SolrCloudTestCase {
     assertEquals("conf2", configName);
   }
 
-  @Test
-  public void testMaxNodesPerShard() {
-    int numLiveNodes = cluster.getJettySolrRunners().size();
-    int numShards = (numLiveNodes/2) + 1;
-    int replicationFactor = 2;
-
-    expectThrows(SolrException.class, () -> {
-      CollectionAdminRequest.createCollection("oversharded", "conf", numShards, replicationFactor)
-          .process(cluster.getSolrClient());
-    });
-  }
-
   @Test
   public void testCreateNodeSet() throws Exception {
     JettySolrRunner jetty1 = cluster.getRandomJetty(random());
@@ -413,11 +391,9 @@ public class CollectionsAPIDistributedZkTest extends SolrCloudTestCase {
 
       int numShards = TestUtil.nextInt(random(), 0, cluster.getJettySolrRunners().size()) + 1;
       int replicationFactor = TestUtil.nextInt(random(), 0, 3) + 1;
-      int maxShardsPerNode = (((numShards * replicationFactor) / cluster.getJettySolrRunners().size())) + 1;
 
       createRequests[i]
-          = CollectionAdminRequest.createCollection("awhollynewcollection_" + i, "conf2", numShards, replicationFactor)
-          .setMaxShardsPerNode(maxShardsPerNode);
+          = CollectionAdminRequest.createCollection("awhollynewcollection_" + i, "conf2", numShards, replicationFactor);
       createRequests[i].processAsync(cluster.getSolrClient());
       
       Coll coll = new Coll();
@@ -613,7 +589,6 @@ public class CollectionsAPIDistributedZkTest extends SolrCloudTestCase {
     String collectionName = "addReplicaColl";
 
     CollectionAdminRequest.createCollection(collectionName, "conf", 2, 2)
-        .setMaxShardsPerNode(4)
         .process(cluster.getSolrClient());
     cluster.waitForActiveCollection(collectionName, 2, 4);
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/ConcurrentCreateCollectionTest.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/ConcurrentCreateCollectionTest.java
index d9fb8b19eaa..cc3bbd6d0dd 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/ConcurrentCreateCollectionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/ConcurrentCreateCollectionTest.java
@@ -71,8 +71,7 @@ public class ConcurrentCreateCollectionTest extends SolrCloudTestCase {
   private CollectionAdminRequest.Create createCollectionRequest(String cname, int numShards, int numReplicas) throws Exception {
     CollectionAdminRequest.Create creq = CollectionAdminRequest
         //  .createCollection(cname, "conf", NODES - 1, NODES - 1)
-        .createCollection(cname, "conf", numShards, numReplicas)
-        .setMaxShardsPerNode(100);
+        .createCollection(cname, "conf", numShards, numReplicas);
     creq.setWaitForFinalState(true);
     creq.setAutoAddReplicas(true);
     return creq;
@@ -135,8 +134,7 @@ public class ConcurrentCreateCollectionTest extends SolrCloudTestCase {
       String cname = "STARTCOLLECTION";
       CollectionAdminRequest.Create creq = CollectionAdminRequest
           //  .createCollection(cname, "conf", NODES - 1, NODES - 1)
-          .createCollection(cname, "conf", unbalancedSize, 1)
-          .setMaxShardsPerNode(100);
+          .createCollection(cname, "conf", unbalancedSize, 1);
       creq.setWaitForFinalState(true);
       // creq.setAutoAddReplicas(true);
       if (useCollectionPolicy) { creq.setPolicy("policy1"); }
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/CustomCollectionTest.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/CustomCollectionTest.java
index d556271304e..69187a071ac 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/CustomCollectionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/CustomCollectionTest.java
@@ -31,7 +31,6 @@ import org.junit.BeforeClass;
 import org.junit.Test;
 
 import static org.apache.solr.common.cloud.DocCollection.DOC_ROUTER;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
 import static org.apache.solr.common.params.ShardParams._ROUTE_;
 
@@ -61,16 +60,13 @@ public class CustomCollectionTest extends SolrCloudTestCase {
     final String collection = "implicitcoll";
     int replicationFactor = TestUtil.nextInt(random(), 0, 3) + 2;
     int numShards = 3;
-    int maxShardsPerNode = (((numShards + 1) * replicationFactor) / NODE_COUNT) + 1;
 
     CollectionAdminRequest.createCollectionWithImplicitRouter(collection, "conf", "a,b,c", replicationFactor)
-        .setMaxShardsPerNode(maxShardsPerNode)
         .process(cluster.getSolrClient());
 
     DocCollection coll = getCollectionState(collection);
     assertEquals("implicit", ((Map) coll.get(DOC_ROUTER)).get("name"));
     assertNotNull(coll.getStr(REPLICATION_FACTOR));
-    assertNotNull(coll.getStr(MAX_SHARDS_PER_NODE));
     assertNull("A shard of a Collection configured with implicit router must have null range",
         coll.getSlice("a").getRange());
 
@@ -126,13 +122,11 @@ public class CustomCollectionTest extends SolrCloudTestCase {
 
     int numShards = 4;
     int replicationFactor = TestUtil.nextInt(random(), 0, 3) + 2;
-    int maxShardsPerNode = ((numShards * replicationFactor) / NODE_COUNT) + 1;
     String shard_fld = "shard_s";
 
     final String collection = "withShardField";
 
     CollectionAdminRequest.createCollectionWithImplicitRouter(collection, "conf", "a,b,c,d", replicationFactor)
-        .setMaxShardsPerNode(maxShardsPerNode)
         .setRouterField(shard_fld)
         .process(cluster.getSolrClient());
 
@@ -154,11 +148,9 @@ public class CustomCollectionTest extends SolrCloudTestCase {
     String collectionName = "routeFieldColl";
     int numShards = 4;
     int replicationFactor = 2;
-    int maxShardsPerNode = ((numShards * replicationFactor) / NODE_COUNT) + 1;
     String shard_fld = "shard_s";
 
     CollectionAdminRequest.createCollection(collectionName, "conf", numShards, replicationFactor)
-        .setMaxShardsPerNode(maxShardsPerNode)
         .setRouterField(shard_fld)
         .process(cluster.getSolrClient());
     
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest.java
index 1dd3f8f1c95..aa99bf8ed38 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/ShardSplitTest.java
@@ -75,7 +75,6 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import static org.apache.solr.common.cloud.ZkStateReader.BASE_URL_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
 
 @Slow
@@ -137,7 +136,6 @@ public class ShardSplitTest extends BasicDistributedZkTest {
 
     String collectionName = "testSplitStaticIndexReplication_" + splitMethod.toLower();
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, "conf1", 1, 1);
-    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance
     create.setCreateNodeSet(nodeName); // we want to create the leader on a fixed node so that we know which one to restart later
     create.process(cloudClient);
     
@@ -356,7 +354,6 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     waitForThingsToLevelOut(15, TimeUnit.SECONDS);
     String collectionName = "testSplitMixedReplicaTypes_" + splitMethod.toLower();
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, "conf1", 1, 2, 0, 2); // TODO tlog replicas disabled right now.
-    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance
     create.process(cloudClient);
     
     cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 4));
@@ -567,7 +564,6 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     waitForThingsToLevelOut(15, TimeUnit.SECONDS);
     String collectionName = "testSplitLocking";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName, "conf1", 1, 2);
-    create.setMaxShardsPerNode(5); // some high number so we can create replicas without hindrance
     create.process(cloudClient);
     
     cloudClient.waitForState(collectionName, 30, TimeUnit.SECONDS, SolrCloudTestCase.activeClusterShape(1, 2));
@@ -796,15 +792,12 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     String collectionName = "routeFieldColl";
     int numShards = 4;
     int replicationFactor = 2;
-    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()
-        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     HashMap<String, List<Integer>> collectionInfos = new HashMap<>();
     String shard_fld = "shard_s";
     try (CloudSolrClient client = createCloudClient(null)) {
       Map<String, Object> props = Utils.makeMap(
           REPLICATION_FACTOR, replicationFactor,
-          MAX_SHARDS_PER_NODE, maxShardsPerNode,
           OverseerCollectionMessageHandler.NUM_SLICES, numShards,
           "router.field", shard_fld);
 
@@ -858,15 +851,12 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     String collectionName = "splitByRouteKeyTest";
     int numShards = 4;
     int replicationFactor = 2;
-    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()
-        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     HashMap<String, List<Integer>> collectionInfos = new HashMap<>();
 
     try (CloudSolrClient client = createCloudClient(null)) {
       Map<String, Object> props = Utils.makeMap(
           REPLICATION_FACTOR, replicationFactor,
-          MAX_SHARDS_PER_NODE, maxShardsPerNode,
           OverseerCollectionMessageHandler.NUM_SLICES, numShards);
 
       createCollection(collectionInfos, collectionName,props,client);
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/SplitByPrefixTest.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/SplitByPrefixTest.java
index c0d15959811..cd548793e97 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/SplitByPrefixTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/SplitByPrefixTest.java
@@ -154,7 +154,6 @@ public class SplitByPrefixTest extends SolrCloudTestCase {
 
     CollectionAdminRequest
         .createCollection(COLLECTION_NAME, "conf", 1, 1)
-        .setMaxShardsPerNode(100)
         .process(cluster.getSolrClient());
 
     cluster.waitForActiveCollection(COLLECTION_NAME, 1, 1);
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/TestCollectionAPI.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/TestCollectionAPI.java
index b0a96913af2..ef718e00bf3 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/TestCollectionAPI.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/TestCollectionAPI.java
@@ -69,11 +69,10 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
       } else {
         req = CollectionAdminRequest.createCollection(COLLECTION_NAME, "conf1",2, 1, 0, 1);
       }
-      req.setMaxShardsPerNode(2);
       setV2(req);
       client.request(req);
       assertV2CallsCount();
-      createCollection(null, COLLECTION_NAME1, 1, 1, 1, client, null, "conf1");
+      createCollection(null, COLLECTION_NAME1, 1, 1, client, null, "conf1");
     }
 
     waitForCollection(cloudClient.getZkStateReader(), COLLECTION_NAME, 2);
@@ -93,7 +92,6 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
     replicaPropTest();
     clusterStatusZNodeVersion();
     testCollectionCreationCollectionNameValidation();
-    testCollectionCreationTooManyShards();
     testReplicationFactorValidaton();
     testCollectionCreationShardNameValidation();
     testAliasCreationNameValidation();
@@ -102,31 +100,6 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
     testModifyCollection(); // deletes replicationFactor property from collections, be careful adding new tests after this one!
   }
 
-  private void testCollectionCreationTooManyShards() throws Exception {
-    try (CloudSolrClient client = createCloudClient(null)) {
-      ModifiableSolrParams params = new ModifiableSolrParams();
-      params.set("action", CollectionParams.CollectionAction.CREATE.toString());
-      params.set("name", "collection_too_many");
-      params.set("router.name", "implicit");
-      params.set("numShards", "10");
-      params.set("maxShardsPerNode", 1);
-      params.set("shards", "b0,b1,b2,b3,b4,b5,b6,b7,b8,b9");
-      @SuppressWarnings({"rawtypes"})
-      SolrRequest request = new QueryRequest(params);
-      request.setPath("/admin/collections");
-
-      try {
-        client.request(request);
-        fail("A collection creation request with too many shards than allowed by maxShardsPerNode should not have succeeded");
-      } catch (BaseHttpSolrClient.RemoteSolrException e) {
-        final String errorMessage = e.getMessage();
-        assertTrue(errorMessage.contains("Cannot create collection"));
-        assertTrue(errorMessage.contains("This requires 10 shards to be created (higher than the allowed number)"));
-        assertMissingCollection(client, "collection_too_many");
-      }
-    }
-  }
-
   private void assertMissingCollection(CloudSolrClient client, String collectionName) throws Exception {
     ClusterState clusterState = client.getZkStateReader().getClusterState();
     assertNull(clusterState.getCollectionOrNull(collectionName));
@@ -441,7 +414,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
   private void clusterStatusZNodeVersion() throws Exception {
     String cname = "clusterStatusZNodeVersion";
     try (CloudSolrClient client = createCloudClient(null)) {
-      setV2(CollectionAdminRequest.createCollection(cname, "conf1", 1, 1).setMaxShardsPerNode(1)).process(client);
+      setV2(CollectionAdminRequest.createCollection(cname, "conf1", 1, 1)).process(client);
       assertV2CallsCount();
       waitForRecoveriesToFinish(cname, true);
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/TestCollectionsAPIViaSolrCloudCluster.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/TestCollectionsAPIViaSolrCloudCluster.java
index eed4c644427..3d5e28d1a6e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/TestCollectionsAPIViaSolrCloudCluster.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/TestCollectionsAPIViaSolrCloudCluster.java
@@ -56,7 +56,6 @@ public class TestCollectionsAPIViaSolrCloudCluster extends SolrCloudTestCase {
 
   private static final int numShards = 2;
   private static final int numReplicas = 2;
-  private static final int maxShardsPerNode = 1;
   private static final int nodeCount = 5;
   private static final String configName = "solrCloudCollectionConfig";
   private static final Map<String,String> collectionProperties  // ensure indexes survive core shutdown
@@ -77,14 +76,12 @@ public class TestCollectionsAPIViaSolrCloudCluster extends SolrCloudTestCase {
   private void createCollection(String collectionName, String createNodeSet) throws Exception {
     if (random().nextBoolean()) { // process asynchronously
       CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)
-          .setMaxShardsPerNode(maxShardsPerNode)
           .setCreateNodeSet(createNodeSet)
           .setProperties(collectionProperties)
           .processAndWait(cluster.getSolrClient(), 30);
     }
     else {
       CollectionAdminRequest.createCollection(collectionName, configName, numShards, numReplicas)
-          .setMaxShardsPerNode(maxShardsPerNode)
           .setCreateNodeSet(createNodeSet)
           .setProperties(collectionProperties)
           .process(cluster.getSolrClient());
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/TestReplicaProperties.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/TestReplicaProperties.java
index f80edabd74c..016892997da 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/TestReplicaProperties.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/TestReplicaProperties.java
@@ -52,12 +52,12 @@ public class TestReplicaProperties extends ReplicaPropertiesBase {
 
     try (CloudSolrClient client = createCloudClient(null)) {
       // Mix up a bunch of different combinations of shards and replicas in order to exercise boundary cases.
-      // shards, replicationfactor, maxreplicaspernode
+      // shards, replicationfactor
       int shards = random().nextInt(7);
       if (shards < 2) shards = 2;
       int rFactor = random().nextInt(4);
       if (rFactor < 2) rFactor = 2;
-      createCollection(null, COLLECTION_NAME, shards, rFactor, shards * rFactor + 1, client, null, "conf1");
+      createCollection(null, COLLECTION_NAME, shards, rFactor, client, null, "conf1");
     }
 
     waitForCollection(cloudClient.getZkStateReader(), COLLECTION_NAME, 2);
diff --git a/solr/core/src/test/org/apache/solr/cloud/api/collections/TestRequestStatusCollectionAPI.java b/solr/core/src/test/org/apache/solr/cloud/api/collections/TestRequestStatusCollectionAPI.java
index 58c4686443f..3c21200cb7e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/api/collections/TestRequestStatusCollectionAPI.java
+++ b/solr/core/src/test/org/apache/solr/cloud/api/collections/TestRequestStatusCollectionAPI.java
@@ -49,7 +49,6 @@ public class TestRequestStatusCollectionAPI extends BasicDistributedZkTest {
     params.set("numShards", numShards);
     int replicationFactor = 1;
     params.set("replicationFactor", replicationFactor);
-    params.set("maxShardsPerNode", 100);
     params.set("collection.configName", "conf1");
     params.set(CommonAdminParams.ASYNC, "1000");
     try {
@@ -130,7 +129,6 @@ public class TestRequestStatusCollectionAPI extends BasicDistributedZkTest {
     params.set("name", "collection2");
     params.set("numShards", 2);
     params.set("replicationFactor", 1);
-    params.set("maxShardsPerNode", 100);
     params.set("collection.configName", "conf1");
     params.set(CommonAdminParams.ASYNC, "1002");
     try {
@@ -158,7 +156,6 @@ public class TestRequestStatusCollectionAPI extends BasicDistributedZkTest {
     params.set("name", "collection3");
     params.set("numShards", 1);
     params.set("replicationFactor", 1);
-    params.set("maxShardsPerNode", 100);
     params.set("collection.configName", "conf1");
     params.set(CommonAdminParams.ASYNC, "1002");
     try {
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoAddReplicasIntegrationTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoAddReplicasIntegrationTest.java
index b03ebc20d46..b744ac19105 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoAddReplicasIntegrationTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoAddReplicasIntegrationTest.java
@@ -108,7 +108,6 @@ public class AutoAddReplicasIntegrationTest extends SolrCloudTestCase {
     CollectionAdminRequest.createCollection(COLLECTION, "conf", 2, 2)
       .setCreateNodeSet(jetty1.getNodeName()+","+jetty2.getNodeName())
       .setAutoAddReplicas(true)
-      .setMaxShardsPerNode(2)
       .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(COLLECTION, 2, 4);
@@ -162,7 +161,6 @@ public class AutoAddReplicasIntegrationTest extends SolrCloudTestCase {
     CollectionAdminRequest.createCollection(COLLECTION, "conf", 2, 2)
       .setCreateNodeSet(jetty1.getNodeName()+","+jetty2.getNodeName())
       .setAutoAddReplicas(true)
-      .setMaxShardsPerNode(2)
       .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(COLLECTION, 2, 4);
@@ -221,7 +219,6 @@ public class AutoAddReplicasIntegrationTest extends SolrCloudTestCase {
     CollectionAdminRequest.createCollection(COLLECTION, "conf", 2, 2)
       .setCreateNodeSet(jetty1.getNodeName()+","+jetty2.getNodeName())
       .setAutoAddReplicas(false) // NOTE: false
-      .setMaxShardsPerNode(2)
       .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(COLLECTION, 2, 4);
@@ -298,7 +295,6 @@ public class AutoAddReplicasIntegrationTest extends SolrCloudTestCase {
     CollectionAdminRequest.createCollection(COLLECTION, "conf", 2, 2)
       .setCreateNodeSet(jetty1.getNodeName()+","+jetty2.getNodeName())
       .setAutoAddReplicas(false) // NOTE: false
-      .setMaxShardsPerNode(2)
       .process(cluster.getSolrClient());
 
     if (log.isInfoEnabled()) {
@@ -310,7 +306,6 @@ public class AutoAddReplicasIntegrationTest extends SolrCloudTestCase {
     CollectionAdminRequest.createCollection(ALT_COLLECTION, "conf", 2, 2)
       .setCreateNodeSet(jetty1.getNodeName()+","+jetty2.getNodeName())
       .setAutoAddReplicas(true) // NOTE: true
-      .setMaxShardsPerNode(2)
       .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(COLLECTION, 2, 4);
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoAddReplicasPlanActionTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoAddReplicasPlanActionTest.java
index 8fca98da48d..081b89e8e47 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoAddReplicasPlanActionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoAddReplicasPlanActionTest.java
@@ -88,18 +88,15 @@ public class AutoAddReplicasPlanActionTest extends SolrCloudTestCase{
     CollectionAdminRequest.createCollection(collection1, "conf", 2, 2)
         .setCreateNodeSet(jetty1.getNodeName()+","+jetty2.getNodeName())
         .setAutoAddReplicas(true)
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
     CollectionAdminRequest.createCollection(collection2, "conf", 1, 2)
         .setCreateNodeSet(jetty2.getNodeName()+","+jetty3.getNodeName())
         .setAutoAddReplicas(false)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
     // the number of cores in jetty1 (6) will be larger than jetty3 (1)
     CollectionAdminRequest.createCollection(collection3, "conf", 3, 1)
         .setCreateNodeSet(jetty1.getNodeName())
         .setAutoAddReplicas(false)
-        .setMaxShardsPerNode(3)
         .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(collection1, 2, 4);
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoScalingHandlerTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoScalingHandlerTest.java
index 2a8c9c11673..6d83fe26001 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoScalingHandlerTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/AutoScalingHandlerTest.java
@@ -109,7 +109,6 @@ public class AutoScalingHandlerTest extends SolrCloudTestCase {
     CloudSolrClient solrClient = cluster.getSolrClient();
     String COLLNAME = "testSuggestionsWithPayload.COLL";
     CollectionAdminResponse adminResponse = CollectionAdminRequest.createCollection(COLLNAME, CONFIGSET_NAME, 1, 2)
-        .setMaxShardsPerNode(4)
         .process(solrClient);
     cluster.waitForActiveCollection(COLLNAME, 1, 2);
     DocCollection collection = solrClient.getClusterStateProvider().getCollection(COLLNAME);
@@ -143,7 +142,6 @@ public class AutoScalingHandlerTest extends SolrCloudTestCase {
     CloudSolrClient solrClient = cluster.getSolrClient();
     String COLLNAME = "testDiagnosticsWithPayload.COLL";
     CollectionAdminResponse adminResponse = CollectionAdminRequest.createCollection(COLLNAME, CONFIGSET_NAME, 1, 2)
-        .setMaxShardsPerNode(4)
         .process(solrClient);
     cluster.waitForActiveCollection(COLLNAME, 1, 2);
     DocCollection collection = solrClient.getClusterStateProvider().getCollection(COLLNAME);
@@ -863,8 +861,7 @@ public class AutoScalingHandlerTest extends SolrCloudTestCase {
     assertEquals(response.get("result").toString(), "success");
 
     // lets create a collection which violates the rule replicas < 2
-    CollectionAdminRequest.Create create = CollectionAdminRequest.Create.createCollection("readApiTestViolations", CONFIGSET_NAME, 1, 6)
-        .setMaxShardsPerNode(3);
+    CollectionAdminRequest.Create create = CollectionAdminRequest.Create.createCollection("readApiTestViolations", CONFIGSET_NAME, 1, 6);
     CollectionAdminResponse adminResponse = create.process(solrClient);
     cluster.waitForActiveCollection("readApiTestViolations", 1, 6);
     assertTrue(adminResponse.isSuccess());
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/ComputePlanActionTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/ComputePlanActionTest.java
index eab52d5f30c..44e4c73ac23 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/ComputePlanActionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/ComputePlanActionTest.java
@@ -287,7 +287,6 @@ public class ComputePlanActionTest extends SolrCloudTestCase {
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection("testNodeWithMultipleReplicasLost",
         "conf", 2, 3);
-    create.setMaxShardsPerNode(2);
     create.process(solrClient);
     
     cluster.waitForActiveCollection("testNodeWithMultipleReplicasLost", 2, 6);
@@ -372,7 +371,7 @@ public class ComputePlanActionTest extends SolrCloudTestCase {
     assertEquals(response.get("result").toString(), "success");
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection("testNodeAdded",
-        "conf",1, 2).setMaxShardsPerNode(2);
+        "conf",1, 2);
     create.process(solrClient);
 
     waitForState("Timed out waiting for replicas of new collection to be active",
@@ -666,7 +665,7 @@ public class ComputePlanActionTest extends SolrCloudTestCase {
 
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionNamePrefix + "_0",
-        "conf", numShards, nNrtReplicas, nTlogReplicas, nPullReplicas).setMaxShardsPerNode(2);
+        "conf", numShards, nNrtReplicas, nTlogReplicas, nPullReplicas);
     create.process(solrClient);
 
     waitForState("Timed out waiting for replicas of new collection to be active",
@@ -695,7 +694,7 @@ public class ComputePlanActionTest extends SolrCloudTestCase {
 
     for (int i = 1; i < numCollections; i++) {
       create = CollectionAdminRequest.createCollection(collectionNamePrefix + "_" + i,
-          "conf", numShards, 2).setMaxShardsPerNode(numShards * 2);
+          "conf", numShards, 2);
       create.process(solrClient);
 
       waitForState("Timed out waiting for replicas of new collection to be active",
@@ -767,7 +766,7 @@ public class ComputePlanActionTest extends SolrCloudTestCase {
     String newNodeName = newNode.getNodeName();
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionNamePrefix + "_0",
-        "conf", numShards, 2).setMaxShardsPerNode(numShards * 2);
+        "conf", numShards, 2);
     create.process(solrClient);
 
     waitForState("Timed out waiting for replicas of new collection to be active",
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/ExecutePlanActionTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/ExecutePlanActionTest.java
index 25a7616eb2c..83aa3ff15c7 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/ExecutePlanActionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/ExecutePlanActionTest.java
@@ -128,7 +128,6 @@ public class ExecutePlanActionTest extends SolrCloudTestCase {
     String collectionName = "testExecute";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", 1, 2);
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
     
     cluster.waitForActiveCollection(collectionName, 1, 2);
@@ -225,7 +224,6 @@ public class ExecutePlanActionTest extends SolrCloudTestCase {
     String collectionName = "testIntegration";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", 1, 2);
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
     
     cluster.waitForActiveCollection(collectionName, 1, 2);
@@ -292,7 +290,6 @@ public class ExecutePlanActionTest extends SolrCloudTestCase {
     String collectionName = "testTaskTimeout";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", 1, 2);
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
 
     cluster.waitForActiveCollection(collectionName, 1, 2);
@@ -351,7 +348,6 @@ public class ExecutePlanActionTest extends SolrCloudTestCase {
     String collectionName = "testTaskFail";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", 1, 2);
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
 
     cluster.waitForActiveCollection(collectionName, 1, 2);
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest.java
index 2075fea0645..22bd537e4cf 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerMixedBoundsTest.java
@@ -124,7 +124,7 @@ public class IndexSizeTriggerMixedBoundsTest extends SolrCloudTestCase {
   public void testMixedBounds() throws Exception {
     String collectionName = "testMixedBounds_collection";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 2, 2).setMaxShardsPerNode(2);
+        "conf", 2, 2);
     create.process(solrClient);
     CloudUtil.waitForState(cloudManager, "failed to create " + collectionName, collectionName,
         CloudUtil.clusterShape(2, 2, false, true));
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerSizeEstimationTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerSizeEstimationTest.java
index 150a67f00bd..528dd556d65 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerSizeEstimationTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerSizeEstimationTest.java
@@ -136,7 +136,7 @@ public class IndexSizeTriggerSizeEstimationTest extends SolrCloudTestCase {
   public void testEstimatedIndexSize() throws Exception {
     String collectionName = "testEstimatedIndexSize_collection";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 2, 2).setMaxShardsPerNode(2);
+        "conf", 2, 2);
     create.process(solrClient);
 
     CloudUtil.waitForState(cloudManager, "failed to create " + collectionName, collectionName,
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest.java
index b937668f0fb..705c0e51939 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/IndexSizeTriggerTest.java
@@ -149,7 +149,7 @@ public class IndexSizeTriggerTest extends SolrCloudTestCase {
   public void testTrigger() throws Exception {
     String collectionName = "testTrigger_collection";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 2, 2).setMaxShardsPerNode(2);
+        "conf", 2, 2);
     create.process(solrClient);
     
     if (SPEED == 1) {
@@ -261,7 +261,7 @@ public class IndexSizeTriggerTest extends SolrCloudTestCase {
   public void testSplitIntegration() throws Exception {
     String collectionName = "testSplitIntegration_collection";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 2, 2).setMaxShardsPerNode(2);
+        "conf", 2, 2);
     create.process(solrClient);
     
     if (SPEED == 1) {
@@ -387,7 +387,7 @@ public class IndexSizeTriggerTest extends SolrCloudTestCase {
   public void testMergeIntegration() throws Exception {
     String collectionName = "testMergeIntegration_collection";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 2, 2).setMaxShardsPerNode(2);
+        "conf", 2, 2);
     create.process(solrClient);
     
     if (SPEED == 1) {
@@ -506,7 +506,7 @@ public class IndexSizeTriggerTest extends SolrCloudTestCase {
   public void testMaxOps() throws Exception {
     String collectionName = "testMaxOps_collection";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 5, 2).setMaxShardsPerNode(10);
+        "conf", 5, 2);
     create.process(solrClient);
     
     CloudUtil.waitForState(cloudManager, "failed to create " + collectionName, collectionName,
@@ -650,7 +650,7 @@ public class IndexSizeTriggerTest extends SolrCloudTestCase {
   public void testSplitConfig() throws Exception {
     String collectionName = "testSplitConfig_collection";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 2, 2).setMaxShardsPerNode(2);
+        "conf", 2, 2);
     create.process(solrClient);
     CloudUtil.waitForState(cloudManager, "failed to create " + collectionName, collectionName,
         CloudUtil.clusterShape(2, 2, false, true));
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/MetricTriggerIntegrationTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/MetricTriggerIntegrationTest.java
index bba3096d105..e35a23052e1 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/MetricTriggerIntegrationTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/MetricTriggerIntegrationTest.java
@@ -84,7 +84,7 @@ public class MetricTriggerIntegrationTest extends SolrCloudTestCase {
     String collectionName = "testMetricTrigger";
     CloudSolrClient solrClient = cluster.getSolrClient();
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 2, 2).setMaxShardsPerNode(2);
+        "conf", 2, 2);
     create.process(solrClient);
     solrClient.setDefaultCollection(collectionName);
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/MetricTriggerTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/MetricTriggerTest.java
index 74ebca5da98..ce00d393848 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/MetricTriggerTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/MetricTriggerTest.java
@@ -51,7 +51,6 @@ public class MetricTriggerTest extends SolrCloudTestCase {
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(DEFAULT_TEST_COLLECTION_NAME,
         "conf", 1, 1);
     CloudSolrClient solrClient = cluster.getSolrClient();
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
     cluster.waitForActiveCollection(DEFAULT_TEST_COLLECTION_NAME, 1, 1);
   }
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/ScheduledTriggerIntegrationTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/ScheduledTriggerIntegrationTest.java
index 63c0e70d7c8..0b812c2a1cc 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/ScheduledTriggerIntegrationTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/ScheduledTriggerIntegrationTest.java
@@ -84,7 +84,7 @@ public class ScheduledTriggerIntegrationTest extends SolrCloudTestCase {
     // this collection will place 2 cores on 1st node and 1 core on 2nd node
     String collectionName = "testScheduledTrigger";
     CollectionAdminRequest.createCollection(collectionName, 1, 3)
-        .setMaxShardsPerNode(5).process(solrClient);
+        .process(solrClient);
     
     cluster.waitForActiveCollection(collectionName, 1, 3);
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/SearchRateTriggerTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/SearchRateTriggerTest.java
index 41bbd8bb79b..6e3f15de30f 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/SearchRateTriggerTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/SearchRateTriggerTest.java
@@ -100,11 +100,9 @@ public class SearchRateTriggerTest extends SolrCloudTestCase {
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(COLL1,
         "conf", 2, 2);
     CloudSolrClient solrClient = cluster.getSolrClient();
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
     create = CollectionAdminRequest.createCollection(COLL2,
         "conf", 2, 2);
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
 
     CloudUtil.waitForState(cloudManager, COLL1, 60, TimeUnit.SECONDS, clusterShape(2, 2));
@@ -238,7 +236,6 @@ public class SearchRateTriggerTest extends SolrCloudTestCase {
     TimeSource timeSource = cloudManager.getTimeSource();
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(COLL1,
         "conf", 2, 2);
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
     CloudUtil.waitForState(cloudManager, COLL1, 60, TimeUnit.SECONDS, clusterShape(2, 4));
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/SystemLogListenerTest.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/SystemLogListenerTest.java
index d2f7c238b6c..714bc3403fd 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/SystemLogListenerTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/SystemLogListenerTest.java
@@ -129,7 +129,6 @@ public class SystemLogListenerTest extends SolrCloudTestCase {
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection("test",
         "conf",3, 2);
-    create.setMaxShardsPerNode(3);
     create.process(solrClient);
 
     waitForState("Timed out waiting for replicas of new collection to be active",
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud.java
index 9899e946616..e715d85804d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/TestPolicyCloud.java
@@ -424,7 +424,6 @@ public class TestPolicyCloud extends SolrCloudTestCase {
 
     final String collectionName = "addshard_with_reptype_using_policy";
     CollectionAdminRequest.createCollectionWithImplicitRouter(collectionName, "conf", "s1", 1, 1, 1)
-        .setMaxShardsPerNode(-1)
         .process(cluster.getSolrClient());
     
     cluster.waitForActiveCollection(collectionName, 1, 3);
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimComputePlanAction.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimComputePlanAction.java
index 9cc3e1a27ab..40a43d566bb 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimComputePlanAction.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimComputePlanAction.java
@@ -224,7 +224,6 @@ public class TestSimComputePlanAction extends SimSolrCloudTestCase {
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection("testNodeWithMultipleReplicasLost",
         "conf",2, 3);
-    create.setMaxShardsPerNode(2);
     create.process(solrClient);
 
     CloudUtil.waitForState(cluster, "Timed out waiting for replicas of new collection to be active",
@@ -314,7 +313,7 @@ public class TestSimComputePlanAction extends SimSolrCloudTestCase {
     assertAutoscalingUpdateComplete();
 
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection("testNodeAdded",
-        "conf",1, 4).setMaxShardsPerNode(-1);
+        "conf",1, 4);
     create.process(solrClient);
 
     CloudUtil.waitForState(cluster, "Timed out waiting for replicas of new collection to be active",
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExecutePlanAction.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExecutePlanAction.java
index 5919c1cffae..138ce8daa21 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExecutePlanAction.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExecutePlanAction.java
@@ -94,7 +94,6 @@ public class TestSimExecutePlanAction extends SimSolrCloudTestCase {
     String collectionName = "testExecute";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", 1, 2);
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
 
     if (log.isInfoEnabled()) {
@@ -192,7 +191,6 @@ public class TestSimExecutePlanAction extends SimSolrCloudTestCase {
     String collectionName = "testIntegration";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", 1, 2);
-    create.setMaxShardsPerNode(1);
     create.process(solrClient);
 
     CloudUtil.waitForState(cluster, "Timed out waiting for replicas of new collection to be active",
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing.java
index 13fb8b4766a..937b4fa9000 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimExtremeIndexing.java
@@ -96,7 +96,7 @@ public class TestSimExtremeIndexing extends SimSolrCloudTestCase {
   public void testScaleUp() throws Exception {
     String collectionName = "testScaleUp_collection";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
-        "conf", 2, 2).setMaxShardsPerNode(10);
+        "conf", 2, 2);
     create.process(solrClient);
 
     CloudUtil.waitForState(cluster, collectionName, 90, TimeUnit.SECONDS,
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster.java
index 01336ef40e1..edf2349c1a5 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimLargeCluster.java
@@ -204,7 +204,6 @@ public class TestSimLargeCluster extends SimSolrCloudTestCase {
     String collectionName = "testBasic";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", 5, 5, 5, 5);
-    create.setMaxShardsPerNode(1);
     create.setAutoAddReplicas(false);
     create.setCreateNodeSet(String.join(",", nodes));
     create.process(solrClient);
@@ -283,12 +282,10 @@ public class TestSimLargeCluster extends SimSolrCloudTestCase {
       final int pReps = TestUtil.nextInt(random(), 2, 25 - numShards);
       final int repsPerShard = (nReps + tReps + pReps);
       final int totalCores = repsPerShard * numShards;
-      final int maxShardsPerNode = atLeast(2) + (totalCores / NUM_NODES);
       final String name = "large_sim_collection" + i;
       
       final CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection
         (name, "conf", numShards, nReps, tReps, pReps);
-      create.setMaxShardsPerNode(maxShardsPerNode);
       create.setAutoAddReplicas(false);
       
       log.info("CREATE: {}", create);
@@ -332,7 +329,6 @@ public class TestSimLargeCluster extends SimSolrCloudTestCase {
     String collectionName = "testNodeAdded";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", NUM_NODES / 10, NUM_NODES / 8, NUM_NODES / 8, NUM_NODES / 8);
-    create.setMaxShardsPerNode(5);
     create.setAutoAddReplicas(false);
     create.process(solrClient);
 
@@ -549,7 +545,6 @@ public class TestSimLargeCluster extends SimSolrCloudTestCase {
     String collectionName = "testNodeLost";
     CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(collectionName,
         "conf", NUM_NODES / 5, NUM_NODES / 10);
-    create.setMaxShardsPerNode(5);
     create.setAutoAddReplicas(false);
     create.process(solrClient);
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimPolicyCloud.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimPolicyCloud.java
index 915aa3fba7e..11c388c47b9 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimPolicyCloud.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimPolicyCloud.java
@@ -269,7 +269,6 @@ public class TestSimPolicyCloud extends SimSolrCloudTestCase {
         Utils.getObjectByPath(json, true, "cluster-policy[2]/port"));
 
     CollectionAdminRequest.createCollectionWithImplicitRouter("policiesTest", "conf", "s1", 1, 1, 1)
-        .setMaxShardsPerNode(-1)
         .process(solrClient);
     CloudUtil.waitForState(cluster, "Timeout waiting for collection to become active", "policiesTest",
         CloudUtil.clusterShape(1, 3, false, true));
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimScenario.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimScenario.java
index f2460627100..38e921aac4d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimScenario.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimScenario.java
@@ -42,7 +42,7 @@ public class TestSimScenario extends SimSolrCloudTestCase {
       "// java comment\n" +
       "create_cluster numNodes=2 // inline comment\n" +
       "load_autoscaling json={'cluster-policy'+:+[{'replica'+:+'<3',+'shard'+:+'#EACH',+'collection'+:+'testCollection','node':'#ANY'}]}&defaultWaitFor=10\n" +
-      "solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2&maxShardsPerNode=2\n" +
+      "solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2\n" +
       "wait_collection collection=testCollection&shards=2&replicas=2\n" +
       "event_listener trigger=.auto_add_replicas&stage=SUCCEEDED\n" +
       "kill_nodes node=${_random_node_}\n" +
@@ -65,7 +65,7 @@ public class TestSimScenario extends SimSolrCloudTestCase {
   String testSuggestionsScenario =
       "create_cluster numNodes=2\n" +
       "load_autoscaling json={'cluster-policy':[]}\n" +
-      "solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2&maxShardsPerNode=2\n" +
+      "solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2\n" +
       "wait_collection collection=testCollection&shards=2&replicas=2\n" +
       "ctx_set key=myNode&value=${_random_node_}\n" +
       "solr_request /admin/collections?action=ADDREPLICA&collection=testCollection&shard=shard1&node=${myNode}\n" +
@@ -124,7 +124,7 @@ public class TestSimScenario extends SimSolrCloudTestCase {
   String indexingScenario =
       "create_cluster numNodes=100\n" +
       "load_autoscaling json={'cluster-policy':[]}\n" +
-      "solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2&maxShardsPerNode=2\n" +
+      "solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2\n" +
       "wait_collection collection=testCollection&shards=2&replicas=2\n" +
       "solr_request /admin/autoscaling?httpMethod=POST&stream.body=" +
           "{'set-trigger':{'name':'indexSizeTrigger','event':'indexSize','waitFor':'10s','aboveDocs':1000,'enabled':true,"+
@@ -148,7 +148,7 @@ public class TestSimScenario extends SimSolrCloudTestCase {
   String splitShardScenario =
       "create_cluster numNodes=2\n" +
           "load_autoscaling json={'cluster-policy':[]}\n" +
-          "solr_request /admin/collections?action=CREATE&name=testCollection&numShards=2&replicationFactor=2&maxShardsPerNode=5\n" +
+          "solr_request /admin/collections?action=CREATE&name=testCollection&numShards=2&replicationFactor=2\n" +
           "wait_collection collection=testCollection&shards=2&replicas=2\n" +
           "set_shard_metrics collection=testCollection&shard=shard1&INDEX.sizeInBytes=1000000000\n" +
           "set_node_metrics nodeset=#ANY&freedisk=1.5\n" +
diff --git a/solr/core/src/test/org/apache/solr/cloud/cdcr/BaseCdcrDistributedZkTest.java b/solr/core/src/test/org/apache/solr/cloud/cdcr/BaseCdcrDistributedZkTest.java
index a6256aea407..aa35de1ada0 100644
--- a/solr/core/src/test/org/apache/solr/cloud/cdcr/BaseCdcrDistributedZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/cdcr/BaseCdcrDistributedZkTest.java
@@ -75,7 +75,6 @@ import org.slf4j.LoggerFactory;
 import static org.apache.solr.cloud.api.collections.OverseerCollectionMessageHandler.CREATE_NODE_SET;
 import static org.apache.solr.cloud.api.collections.OverseerCollectionMessageHandler.NUM_SLICES;
 import static org.apache.solr.common.cloud.ZkStateReader.CLUSTER_PROPS;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
 import static org.apache.solr.handler.admin.CoreAdminHandler.COMPLETED;
 import static org.apache.solr.handler.admin.CoreAdminHandler.RESPONSE_STATUS;
@@ -408,7 +407,6 @@ public class BaseCdcrDistributedZkTest extends AbstractDistribZkTestBase {
     try {
       // Create the target collection
       Map<String, List<Integer>> collectionInfos = new HashMap<>();
-      int maxShardsPerNode = 1;
 
       StringBuilder sb = new StringBuilder();
       for (String nodeName : collectionToNodeNames.get(name)) {
@@ -417,7 +415,7 @@ public class BaseCdcrDistributedZkTest extends AbstractDistribZkTestBase {
       }
       sb.deleteCharAt(sb.length() - 1);
 
-      createCollection(collectionInfos, name, shardCount, replicationFactor, maxShardsPerNode, client, sb.toString());
+      createCollection(collectionInfos, name, shardCount, replicationFactor, client, sb.toString());
     } finally {
       client.close();
     }
@@ -425,14 +423,13 @@ public class BaseCdcrDistributedZkTest extends AbstractDistribZkTestBase {
 
   private CollectionAdminResponse createCollection(Map<String, List<Integer>> collectionInfos,
                                                    String collectionName, int numShards, int replicationFactor,
-                                                   int maxShardsPerNode, SolrClient client, String createNodeSetStr)
+                                                   SolrClient client, String createNodeSetStr)
       throws SolrServerException, IOException {
     return createCollection(collectionInfos, collectionName,
         Utils.makeMap(
             NUM_SLICES, numShards,
             REPLICATION_FACTOR, replicationFactor,
-            CREATE_NODE_SET, createNodeSetStr,
-            MAX_SHARDS_PER_NODE, maxShardsPerNode),
+            CREATE_NODE_SET, createNodeSetStr),
         client, "conf1");
   }
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrBidirectionalTest.java b/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrBidirectionalTest.java
index fdd5317edf6..7f1db84b04d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrBidirectionalTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrBidirectionalTest.java
@@ -63,7 +63,6 @@ public class CdcrBidirectionalTest extends SolrTestCaseJ4 {
       cluster1.uploadConfigSet(configset("cdcr-cluster1"), "cdcr-cluster1");
       CollectionAdminRequest.createCollection("cdcr-cluster1", "cdcr-cluster1", 2, 1)
           .withProperty("solr.directoryFactory", "solr.StandardDirectoryFactory")
-          .setMaxShardsPerNode(2)
           .process(cluster1.getSolrClient());
       CloudSolrClient cluster1SolrClient = cluster1.getSolrClient();
       cluster1SolrClient.setDefaultCollection("cdcr-cluster1");
@@ -71,7 +70,6 @@ public class CdcrBidirectionalTest extends SolrTestCaseJ4 {
       cluster2.uploadConfigSet(configset("cdcr-cluster2"), "cdcr-cluster2");
       CollectionAdminRequest.createCollection("cdcr-cluster2", "cdcr-cluster2", 2, 1)
           .withProperty("solr.directoryFactory", "solr.StandardDirectoryFactory")
-          .setMaxShardsPerNode(2)
           .process(cluster2.getSolrClient());
       CloudSolrClient cluster2SolrClient = cluster2.getSolrClient();
       cluster2SolrClient.setDefaultCollection("cdcr-cluster2");
diff --git a/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrBootstrapTest.java b/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrBootstrapTest.java
index af4b0a618ce..34d8287f5ba 100644
--- a/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrBootstrapTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrBootstrapTest.java
@@ -111,7 +111,6 @@ public class CdcrBootstrapTest extends SolrTestCaseJ4 {
         // setup the target cluster
         target.uploadConfigSet(configset("cdcr-target"), "cdcr-target");
         CollectionAdminRequest.createCollection("cdcr-target", "cdcr-target", 1, 2)
-            .setMaxShardsPerNode(2)
             .process(target.getSolrClient());
         target.waitForActiveCollection("cdcr-target", 1, 2);
         CloudSolrClient targetSolrClient = target.getSolrClient();
diff --git a/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsNNFailoverTest.java b/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsNNFailoverTest.java
index d793852aab1..e41af60d2be 100644
--- a/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsNNFailoverTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsNNFailoverTest.java
@@ -67,7 +67,7 @@ public class HdfsNNFailoverTest extends BasicDistributedZkTest {
 
   @Test
   public void test() throws Exception {
-    createCollection(COLLECTION, "conf1", 1, 1, 1);
+    createCollection(COLLECTION, "conf1", 1, 1);
     
     waitForRecoveriesToFinish(COLLECTION, false);
     
diff --git a/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsWriteToMultipleCollectionsTest.java b/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsWriteToMultipleCollectionsTest.java
index 13531a4c364..c51a156b3bd 100644
--- a/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsWriteToMultipleCollectionsTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsWriteToMultipleCollectionsTest.java
@@ -97,7 +97,7 @@ public class HdfsWriteToMultipleCollectionsTest extends BasicDistributedZkTest {
     int docCount = random().nextInt(1313) + 1;
     int cnt = random().nextInt(4) + 1;
     for (int i = 0; i < cnt; i++) {
-      createCollection(ACOLLECTION + i, "conf1", 2, 2, 9);
+      createCollection(ACOLLECTION + i, "conf1", 2, 2);
     }
     for (int i = 0; i < cnt; i++) {
       waitForRecoveriesToFinish(ACOLLECTION + i, false);
diff --git a/solr/core/src/test/org/apache/solr/cloud/hdfs/StressHdfsTest.java b/solr/core/src/test/org/apache/solr/cloud/hdfs/StressHdfsTest.java
index 2cf16242331..16ff63c8772 100644
--- a/solr/core/src/test/org/apache/solr/cloud/hdfs/StressHdfsTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/hdfs/StressHdfsTest.java
@@ -107,7 +107,7 @@ public class StressHdfsTest extends BasicDistributedZkTest {
       Timer timer = new Timer();
       
       try {
-        createCollection(DELETE_DATA_DIR_COLLECTION, "conf1", 1, 1, 1);
+        createCollection(DELETE_DATA_DIR_COLLECTION, "conf1", 1, 1);
         
         waitForRecoveriesToFinish(DELETE_DATA_DIR_COLLECTION, false);
 
@@ -139,19 +139,16 @@ public class StressHdfsTest extends BasicDistributedZkTest {
     boolean overshard = random().nextBoolean();
     int rep;
     int nShards;
-    int maxReplicasPerNode;
     if (overshard) {
       nShards = getShardCount() * 2;
-      maxReplicasPerNode = 8;
       rep = 1;
     } else {
       nShards = getShardCount() / 2;
-      maxReplicasPerNode = 1;
       rep = 2;
       if (nShards == 0) nShards = 1;
     }
     
-    createCollection(DELETE_DATA_DIR_COLLECTION, "conf1", nShards, rep, maxReplicasPerNode);
+    createCollection(DELETE_DATA_DIR_COLLECTION, "conf1", nShards, rep);
 
     waitForRecoveriesToFinish(DELETE_DATA_DIR_COLLECTION, false);
     
diff --git a/solr/core/src/test/org/apache/solr/cloud/overseer/TestClusterStateMutator.java b/solr/core/src/test/org/apache/solr/cloud/overseer/TestClusterStateMutator.java
index 0be579cf4f3..988ac2509c3 100644
--- a/solr/core/src/test/org/apache/solr/cloud/overseer/TestClusterStateMutator.java
+++ b/solr/core/src/test/org/apache/solr/cloud/overseer/TestClusterStateMutator.java
@@ -53,7 +53,6 @@ public class TestClusterStateMutator extends SolrTestCaseJ4 {
     DocCollection collection = cmd.collection;
     assertEquals("xyz", collection.getName());
     assertEquals(1, collection.getSlicesMap().size());
-    assertEquals(1, collection.getMaxShardsPerNode());
 
     ClusterState state = new ClusterState(Collections.<String>emptySet(), Collections.singletonMap("xyz", collection));
     message = new ZkNodeProps(Utils.makeMap(
@@ -61,8 +60,7 @@ public class TestClusterStateMutator extends SolrTestCaseJ4 {
         "numShards", "2",
         "router.name", "implicit",
         "shards", "x,y",
-        "replicationFactor", "3",
-        "maxShardsPerNode", "4"
+        "replicationFactor", "3"
     ));
     cmd = mutator.createCollection(state, message);
     collection = cmd.collection;
@@ -74,7 +72,6 @@ public class TestClusterStateMutator extends SolrTestCaseJ4 {
     assertNull(collection.getSlicesMap().get("y").getRange());
     assertSame(Slice.State.ACTIVE, collection.getSlicesMap().get("x").getState());
     assertSame(Slice.State.ACTIVE, collection.getSlicesMap().get("y").getState());
-    assertEquals(4, collection.getMaxShardsPerNode());
     assertEquals(ImplicitDocRouter.class, collection.getRouter().getClass());
     assertNotNull(state.getCollectionOrNull("xyz")); // we still have the old collection
   }
diff --git a/solr/core/src/test/org/apache/solr/cloud/rule/RulesTest.java b/solr/core/src/test/org/apache/solr/cloud/rule/RulesTest.java
index d9677932575..7401c8567b8 100644
--- a/solr/core/src/test/org/apache/solr/cloud/rule/RulesTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/rule/RulesTest.java
@@ -154,7 +154,7 @@ public class RulesTest extends SolrCloudTestCase {
     // adding an additional replica should fail since our rule says at most one replica
     // per node, and we know every node already has one replica
     expectedException.expect(BaseHttpSolrClient.RemoteSolrException.class);
-    expectedException.expectMessage(containsString("current number of eligible live nodes 0"));
+    expectedException.expectMessage(containsString("Could not identify nodes matching the rules"));
     CollectionAdminRequest.addReplicaToShard(rulesColl, "shard2").process(cluster.getSolrClient());
     
   }
diff --git a/solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCloudSnapshots.java b/solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCloudSnapshots.java
index 2a6d05dec9f..081fe64ca49 100644
--- a/solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCloudSnapshots.java
+++ b/solr/core/src/test/org/apache/solr/core/snapshots/TestSolrCloudSnapshots.java
@@ -188,11 +188,11 @@ public class TestSolrCloudSnapshots extends SolrCloudTestCase {
     {
       CollectionAdminRequest.Restore restore = CollectionAdminRequest.restoreCollection(restoreCollectionName, backupName)
           .setLocation(backupLocation);
-      if (replicaFailures) {
-        // In this case one of the Solr servers would be down. Hence we need to increase
-        // max_shards_per_node property for restore command to succeed.
-        restore.setMaxShardsPerNode(2);
-      }
+//      if (replicaFailures) {
+//        // In this case one of the Solr servers would be down. Hence we need to increase
+//        // max_shards_per_node property for restore command to succeed.
+//        restore.setMaxShardsPerNode(2);
+//      }
       if (random().nextBoolean()) {
         assertEquals(0, restore.process(solrClient).getStatus());
       } else {
diff --git a/solr/core/src/test/org/apache/solr/handler/admin/AutoscalingHistoryHandlerTest.java b/solr/core/src/test/org/apache/solr/handler/admin/AutoscalingHistoryHandlerTest.java
index 962bd933b02..9886e8927e1 100644
--- a/solr/core/src/test/org/apache/solr/handler/admin/AutoscalingHistoryHandlerTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/admin/AutoscalingHistoryHandlerTest.java
@@ -93,7 +93,6 @@ public class AutoscalingHistoryHandlerTest extends SolrCloudTestCase {
     otherNodes.remove(systemCollNode);
     CollectionAdminRequest.createCollection(COLL_NAME, null, 1, 3)
         .setCreateNodeSet(String.join(",", otherNodes))
-        .setMaxShardsPerNode(3)
         .process(solrClient);
     cluster.waitForActiveCollection(COLL_NAME, 1, 3);
   }
diff --git a/solr/core/src/test/org/apache/solr/handler/admin/DaemonStreamApiTest.java b/solr/core/src/test/org/apache/solr/handler/admin/DaemonStreamApiTest.java
index 480282ed986..34227aea19d 100644
--- a/solr/core/src/test/org/apache/solr/handler/admin/DaemonStreamApiTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/admin/DaemonStreamApiTest.java
@@ -74,15 +74,12 @@ public class DaemonStreamApiTest extends SolrTestCaseJ4 {
     // create a single shard, single replica collection. This is necessary until SOLR-13245 since the commands
     // don't look in all replicas.
     CollectionAdminRequest.createCollection(SOURCE_COLL, CONF_NAME, 1, 1)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
 
     CollectionAdminRequest.createCollection(TARGET_COLL, CONF_NAME, 1, 1)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
 
     CollectionAdminRequest.createCollection(CHECKPOINT_COLL, CONF_NAME, 1, 1)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
 
     for (int idx = 0; idx < numDaemons; ++idx) {
diff --git a/solr/core/src/test/org/apache/solr/handler/admin/HealthCheckHandlerTest.java b/solr/core/src/test/org/apache/solr/handler/admin/HealthCheckHandlerTest.java
index d7a03ab8082..f6252dbed82 100644
--- a/solr/core/src/test/org/apache/solr/handler/admin/HealthCheckHandlerTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/admin/HealthCheckHandlerTest.java
@@ -196,7 +196,7 @@ public class HealthCheckHandlerTest extends SolrCloudTestCase {
     //  node2: collection1 -> shard1: [ replica2 (active), replica4 (down) ]
     //         collection2 -> shard1: [ replica1 (active) ]
     try (ZkStateReader reader = ClusterStateMockUtil.buildClusterState(
-        "csrr2rDr2Dcsr2FrR", 1, 1, "node1", "node2")) {
+        "csrr2rDr2Dcsr2FrR", 1, "node1", "node2")) {
       ClusterState clusterState = reader.getClusterState();
 
       // Node 1
diff --git a/solr/core/src/test/org/apache/solr/handler/admin/IndexSizeEstimatorTest.java b/solr/core/src/test/org/apache/solr/handler/admin/IndexSizeEstimatorTest.java
index b092be19342..ec7ed292e36 100644
--- a/solr/core/src/test/org/apache/solr/handler/admin/IndexSizeEstimatorTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/admin/IndexSizeEstimatorTest.java
@@ -75,7 +75,7 @@ public class IndexSizeEstimatorTest extends SolrCloudTestCase {
         .configure();
     solrClient = cluster.getSolrClient();
     CollectionAdminRequest.createCollection(collection, "conf", 2, 2)
-        .setMaxShardsPerNode(2).process(solrClient);
+        .process(solrClient);
     cluster.waitForActiveCollection(collection, 2, 4);
     SolrInputDocument lastDoc = addDocs(collection, NUM_DOCS);
     HashSet<String> docFields = new HashSet<>(lastDoc.keySet());
diff --git a/solr/core/src/test/org/apache/solr/handler/component/CustomHighlightComponentTest.java b/solr/core/src/test/org/apache/solr/handler/component/CustomHighlightComponentTest.java
index 84dd45accbd..3c4f5619650 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/CustomHighlightComponentTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/CustomHighlightComponentTest.java
@@ -117,8 +117,7 @@ public class CustomHighlightComponentTest extends SolrCloudTestCase {
     // ... and shard/replica/node numbers
     final int numShards = 3;
     final int numReplicas = 2;
-    final int maxShardsPerNode = 2;
-    final int nodeCount = (numShards*numReplicas + (maxShardsPerNode-1))/maxShardsPerNode;
+    final int nodeCount = numShards*numReplicas;
 
     // create and configure cluster
     configureCluster(nodeCount)
@@ -128,7 +127,6 @@ public class CustomHighlightComponentTest extends SolrCloudTestCase {
     // create an empty collection
     CollectionAdminRequest
     .createCollection(COLLECTION, "conf", numShards, numReplicas)
-    .setMaxShardsPerNode(maxShardsPerNode)
     .processAndWait(cluster.getSolrClient(), DEFAULT_TIMEOUT);
     AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION, cluster.getSolrClient().getZkStateReader(), false, true, DEFAULT_TIMEOUT);
   }
diff --git a/solr/core/src/test/org/apache/solr/handler/component/DistributedQueryComponentOptimizationTest.java b/solr/core/src/test/org/apache/solr/handler/component/DistributedQueryComponentOptimizationTest.java
index 8572ae4ae0c..9b583167345 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/DistributedQueryComponentOptimizationTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/DistributedQueryComponentOptimizationTest.java
@@ -62,7 +62,6 @@ public class DistributedQueryComponentOptimizationTest extends SolrCloudTestCase
         .configure();
 
     CollectionAdminRequest.createCollection(COLLECTION, "conf", 3, 1)
-        .setMaxShardsPerNode(1)
         .processAndWait(cluster.getSolrClient(), DEFAULT_TIMEOUT);
     cluster.getSolrClient().waitForState(COLLECTION, DEFAULT_TIMEOUT, TimeUnit.SECONDS,
         (n, c) -> DocCollection.isFullyActive(n, c, sliceCount, 1));
diff --git a/solr/core/src/test/org/apache/solr/handler/component/ShardsWhitelistTest.java b/solr/core/src/test/org/apache/solr/handler/component/ShardsWhitelistTest.java
index 8aea6ebda87..b464f258217 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/ShardsWhitelistTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/ShardsWhitelistTest.java
@@ -55,7 +55,6 @@ public class ShardsWhitelistTest extends MultiSolrCloudTestCase {
 
   private static int numShards;
   private static int numReplicas;
-  private static int maxShardsPerNode;
   private static int nodesPerCluster;
 
   private static void appendClusterNodes(final StringBuilder sb, final String delimiter,
@@ -70,8 +69,7 @@ public class ShardsWhitelistTest extends MultiSolrCloudTestCase {
 
     numShards = 2; // +random().nextInt(2);
     numReplicas = 1; // +random().nextInt(2);
-    maxShardsPerNode = 1; // +random().nextInt(2);
-    nodesPerCluster = (numShards * numReplicas + (maxShardsPerNode - 1)) / maxShardsPerNode;
+    nodesPerCluster = numShards * numReplicas;
 
     final StringBuilder sb = new StringBuilder();
 
@@ -98,7 +96,7 @@ public class ShardsWhitelistTest extends MultiSolrCloudTestCase {
             return nodesPerCluster;
           }
         },
-        new DefaultClusterInitFunction(numShards, numReplicas, maxShardsPerNode) {
+        new DefaultClusterInitFunction(numShards, numReplicas) {
           @Override
           public void accept(String clusterId, MiniSolrCloudCluster cluster) {
             appendClusterNodes(sb, ",", cluster);
diff --git a/solr/core/src/test/org/apache/solr/handler/component/TestTrackingShardHandlerFactory.java b/solr/core/src/test/org/apache/solr/handler/component/TestTrackingShardHandlerFactory.java
index 613696910fa..e72a62cbeda 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/TestTrackingShardHandlerFactory.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/TestTrackingShardHandlerFactory.java
@@ -66,7 +66,7 @@ public class TestTrackingShardHandlerFactory extends AbstractFullDistribZkTestBa
       assertSame(trackingQueue, trackingShardHandlerFactory.getTrackingQueue());
     }
 
-    createCollection(collectionName, "conf1", 2, 1, 1);
+    createCollection(collectionName, "conf1", 2, 1);
 
     waitForRecoveriesToFinish(collectionName, true);
 
diff --git a/solr/core/src/test/org/apache/solr/metrics/reporters/SolrJmxReporterCloudTest.java b/solr/core/src/test/org/apache/solr/metrics/reporters/SolrJmxReporterCloudTest.java
index 94205b2eb75..5cff7737ceb 100644
--- a/solr/core/src/test/org/apache/solr/metrics/reporters/SolrJmxReporterCloudTest.java
+++ b/solr/core/src/test/org/apache/solr/metrics/reporters/SolrJmxReporterCloudTest.java
@@ -58,7 +58,6 @@ public class SolrJmxReporterCloudTest extends SolrCloudTestCase {
         .addConfig("conf", configset("cloud-minimal"))
         .configure();
     CollectionAdminRequest.createCollection(COLLECTION, "conf", 2, 1)
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
   }
   @AfterClass
diff --git a/solr/core/src/test/org/apache/solr/metrics/reporters/solr/SolrCloudReportersTest.java b/solr/core/src/test/org/apache/solr/metrics/reporters/solr/SolrCloudReportersTest.java
index 132c91e4d6d..c272439a7c1 100644
--- a/solr/core/src/test/org/apache/solr/metrics/reporters/solr/SolrCloudReportersTest.java
+++ b/solr/core/src/test/org/apache/solr/metrics/reporters/solr/SolrCloudReportersTest.java
@@ -67,7 +67,6 @@ public class SolrCloudReportersTest extends SolrCloudTestCase {
     cluster.uploadConfigSet(Paths.get(TEST_PATH().toString(), "configsets", "minimal", "conf"), "test");
 
     CollectionAdminRequest.createCollection("test_collection", "test", 2, 2)
-        .setMaxShardsPerNode(4)
         .process(cluster.getSolrClient());
     cluster.waitForActiveCollection("test_collection", 2, 4);
     
@@ -169,7 +168,6 @@ public class SolrCloudReportersTest extends SolrCloudTestCase {
     cluster.uploadConfigSet(Paths.get(TEST_PATH().toString(), "configsets", "minimal", "conf"), "test");
 
     CollectionAdminRequest.createCollection("test_collection", "test", 2, 2)
-        .setMaxShardsPerNode(4)
         .process(cluster.getSolrClient());
     cluster.waitForActiveCollection("test_collection", 2, 4);
     waitForState("Expected test_collection with 2 shards and 2 replicas", "test_collection", clusterShape(2, 4));
diff --git a/solr/core/src/test/org/apache/solr/pkg/TestPackages.java b/solr/core/src/test/org/apache/solr/pkg/TestPackages.java
index d2ddca30563..d20efca7dcf 100644
--- a/solr/core/src/test/org/apache/solr/pkg/TestPackages.java
+++ b/solr/core/src/test/org/apache/solr/pkg/TestPackages.java
@@ -137,7 +137,6 @@ public class TestPackages extends SolrCloudTestCase {
 
       CollectionAdminRequest
           .createCollection(COLLECTION_NAME, "conf", 2, 2)
-          .setMaxShardsPerNode(100)
           .process(cluster.getSolrClient());
       cluster.waitForActiveCollection(COLLECTION_NAME, 2, 4);
 
diff --git a/solr/core/src/test/org/apache/solr/schema/ManagedSchemaRoundRobinCloudTest.java b/solr/core/src/test/org/apache/solr/schema/ManagedSchemaRoundRobinCloudTest.java
index 883ebfdb5e6..fcee288f611 100644
--- a/solr/core/src/test/org/apache/solr/schema/ManagedSchemaRoundRobinCloudTest.java
+++ b/solr/core/src/test/org/apache/solr/schema/ManagedSchemaRoundRobinCloudTest.java
@@ -46,7 +46,6 @@ public class ManagedSchemaRoundRobinCloudTest extends SolrCloudTestCase {
     System.setProperty("managed.schema.mutable", "true");
     configureCluster(NUM_SHARDS).addConfig(CONFIG, configset(CONFIG)).configure();
     CollectionAdminRequest.createCollection(COLLECTION, CONFIG, NUM_SHARDS, 1)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
     cluster.getSolrClient().waitForState(COLLECTION, DEFAULT_TIMEOUT, TimeUnit.SECONDS,
         (n, c) -> DocCollection.isFullyActive(n, c, NUM_SHARDS, 1));
diff --git a/solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldManagedSchemaCloudTest.java b/solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldManagedSchemaCloudTest.java
index 04e1be0d04b..b350883e31f 100644
--- a/solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldManagedSchemaCloudTest.java
+++ b/solr/core/src/test/org/apache/solr/schema/PreAnalyzedFieldManagedSchemaCloudTest.java
@@ -40,7 +40,6 @@ public class PreAnalyzedFieldManagedSchemaCloudTest extends SolrCloudTestCase {
   public static void setupCluster() throws Exception {
     configureCluster(2).addConfig(CONFIG, configset(CONFIG)).configure();
     CollectionAdminRequest.createCollection(COLLECTION, CONFIG, 2, 1)
-        .setMaxShardsPerNode(1)
         .process(cluster.getSolrClient());
     cluster.getSolrClient().waitForState(COLLECTION, DEFAULT_TIMEOUT, TimeUnit.SECONDS,
         (n, c) -> DocCollection.isFullyActive(n, c, 2, 1));
diff --git a/solr/core/src/test/org/apache/solr/schema/SchemaApiFailureTest.java b/solr/core/src/test/org/apache/solr/schema/SchemaApiFailureTest.java
index 7cc15011ed9..b4c21296560 100644
--- a/solr/core/src/test/org/apache/solr/schema/SchemaApiFailureTest.java
+++ b/solr/core/src/test/org/apache/solr/schema/SchemaApiFailureTest.java
@@ -38,7 +38,6 @@ public class SchemaApiFailureTest extends SolrCloudTestCase {
   public static void setupCluster() throws Exception {
     configureCluster(1).configure();
     CollectionAdminRequest.createCollection(COLLECTION, 2, 1) // _default configset
-        .setMaxShardsPerNode(2)
         .process(cluster.getSolrClient());
     cluster.getSolrClient().waitForState(COLLECTION, DEFAULT_TIMEOUT, TimeUnit.SECONDS,
         (n, c) -> DocCollection.isFullyActive(n, c, 2, 1));
diff --git a/solr/core/src/test/org/apache/solr/search/CurrencyRangeFacetCloudTest.java b/solr/core/src/test/org/apache/solr/search/CurrencyRangeFacetCloudTest.java
index b0c824b9aaa..c54c7f12f5d 100644
--- a/solr/core/src/test/org/apache/solr/search/CurrencyRangeFacetCloudTest.java
+++ b/solr/core/src/test/org/apache/solr/search/CurrencyRangeFacetCloudTest.java
@@ -66,7 +66,6 @@ public class CurrencyRangeFacetCloudTest extends SolrCloudTestCase {
     
     final int numShards = TestUtil.nextInt(random(),1,5);
     final int numReplicas = 1;
-    final int maxShardsPerNode = 1;
     final int nodeCount = numShards * numReplicas;
 
     configureCluster(nodeCount)
@@ -74,7 +73,6 @@ public class CurrencyRangeFacetCloudTest extends SolrCloudTestCase {
       .configure();
 
     assertEquals(0, (CollectionAdminRequest.createCollection(COLLECTION, CONF, numShards, numReplicas)
-                     .setMaxShardsPerNode(maxShardsPerNode)
                      .setProperties(Collections.singletonMap(CoreAdminParams.CONFIG, "solrconfig-minimal.xml"))
                      .process(cluster.getSolrClient())).getStatus());
     
diff --git a/solr/core/src/test/org/apache/solr/search/facet/RangeFacetCloudTest.java b/solr/core/src/test/org/apache/solr/search/facet/RangeFacetCloudTest.java
index f5c75c51df9..009b864a144 100644
--- a/solr/core/src/test/org/apache/solr/search/facet/RangeFacetCloudTest.java
+++ b/solr/core/src/test/org/apache/solr/search/facet/RangeFacetCloudTest.java
@@ -85,7 +85,6 @@ public class RangeFacetCloudTest extends SolrCloudTestCase {
   public static void setupCluster() throws Exception {
     final int numShards = TestUtil.nextInt(random(),1,5);
     final int numReplicas = 1;
-    final int maxShardsPerNode = 1;
     final int nodeCount = numShards * numReplicas;
 
     configureCluster(nodeCount)
@@ -93,7 +92,6 @@ public class RangeFacetCloudTest extends SolrCloudTestCase {
       .configure();
 
     assertEquals(0, (CollectionAdminRequest.createCollection(COLLECTION, CONF, numShards, numReplicas)
-                     .setMaxShardsPerNode(maxShardsPerNode)
                      .setProperties(Collections.singletonMap(CoreAdminParams.CONFIG, "solrconfig-minimal.xml"))
                      .process(cluster.getSolrClient())).getStatus());
     
diff --git a/solr/core/src/test/org/apache/solr/search/stats/TestDistribIDF.java b/solr/core/src/test/org/apache/solr/search/stats/TestDistribIDF.java
index 205b30b700f..4fc1f3a7476 100644
--- a/solr/core/src/test/org/apache/solr/search/stats/TestDistribIDF.java
+++ b/solr/core/src/test/org/apache/solr/search/stats/TestDistribIDF.java
@@ -197,12 +197,10 @@ public class TestDistribIDF extends SolrTestCaseJ4 {
     CollectionAdminResponse response;
     if (router.equals(ImplicitDocRouter.NAME)) {
       CollectionAdminRequest.Create create = CollectionAdminRequest.createCollectionWithImplicitRouter(name,config,"a,b,c",1);
-      create.setMaxShardsPerNode(1);
       response = create.process(solrCluster.getSolrClient());
       solrCluster.waitForActiveCollection(name, 3, 3);
     } else {
       CollectionAdminRequest.Create create = CollectionAdminRequest.createCollection(name,config,2,1);
-      create.setMaxShardsPerNode(1);
       response = create.process(solrCluster.getSolrClient());
       solrCluster.waitForActiveCollection(name, 2, 2);
     }
diff --git a/solr/core/src/test/org/apache/solr/security/BasicAuthOnSingleNodeTest.java b/solr/core/src/test/org/apache/solr/security/BasicAuthOnSingleNodeTest.java
index 766e0926804..dfff0581513 100644
--- a/solr/core/src/test/org/apache/solr/security/BasicAuthOnSingleNodeTest.java
+++ b/solr/core/src/test/org/apache/solr/security/BasicAuthOnSingleNodeTest.java
@@ -41,7 +41,6 @@ public class BasicAuthOnSingleNodeTest extends SolrCloudAuthTestCase {
         .withSecurityJson(STD_CONF)
         .configure();
     CollectionAdminRequest.createCollection(COLLECTION, "conf", 4, 1)
-        .setMaxShardsPerNode(100)
         .setBasicAuthCredentials("solr", "solr")
         .process(cluster.getSolrClient());
     cluster.waitForActiveCollection(COLLECTION, 4, 4);
diff --git a/solr/core/src/test/org/apache/solr/servlet/HttpSolrCallGetCoreTest.java b/solr/core/src/test/org/apache/solr/servlet/HttpSolrCallGetCoreTest.java
index 4f9438899fc..34eb34471fc 100644
--- a/solr/core/src/test/org/apache/solr/servlet/HttpSolrCallGetCoreTest.java
+++ b/solr/core/src/test/org/apache/solr/servlet/HttpSolrCallGetCoreTest.java
@@ -48,7 +48,6 @@ public class HttpSolrCallGetCoreTest extends SolrCloudTestCase {
 
     CollectionAdminRequest
         .createCollection(COLLECTION, "config", NUM_SHARD, REPLICA_FACTOR)
-        .setMaxShardsPerNode(NUM_SHARD * REPLICA_FACTOR)
         .process(cluster.getSolrClient());
     AbstractDistribZkTestBase.waitForRecoveriesToFinish(COLLECTION, cluster.getSolrClient().getZkStateReader(),
         false, true, 30);
diff --git a/solr/core/src/test/org/apache/solr/update/TestInPlaceUpdateWithRouteField.java b/solr/core/src/test/org/apache/solr/update/TestInPlaceUpdateWithRouteField.java
index fc85fadfcd9..5c154b48132 100644
--- a/solr/core/src/test/org/apache/solr/update/TestInPlaceUpdateWithRouteField.java
+++ b/solr/core/src/test/org/apache/solr/update/TestInPlaceUpdateWithRouteField.java
@@ -73,7 +73,6 @@ public class TestInPlaceUpdateWithRouteField extends SolrCloudTestCase {
     boolean implicit = random().nextBoolean();
     String routerName = implicit ? "implicit":"compositeId";
     Create createCmd = CollectionAdminRequest.createCollection(COLLECTION, configName, shards.length, replicas)
-        .setMaxShardsPerNode(shards.length * replicas)
         .setProperties(collectionProperties)
         .setRouterName(routerName)
         .setRouterField("shardName");
diff --git a/solr/core/src/test/org/apache/solr/update/processor/AtomicUpdateRemovalJavabinTest.java b/solr/core/src/test/org/apache/solr/update/processor/AtomicUpdateRemovalJavabinTest.java
index 61a94f5f11b..c028051f644 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/AtomicUpdateRemovalJavabinTest.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/AtomicUpdateRemovalJavabinTest.java
@@ -45,7 +45,6 @@ public class AtomicUpdateRemovalJavabinTest extends SolrCloudTestCase {
   private static final String COLLECTION = "collection1";
   private static final int NUM_SHARDS = 1;
   private static final int NUM_REPLICAS = 1;
-  private static final int MAX_SHARDS_PER_NODE = 1;
   private static final Date DATE_1 = new Date();
   private static final Date DATE_2 = Date.from(Instant.ofEpochSecond(1554243909));
 
@@ -56,7 +55,6 @@ public class AtomicUpdateRemovalJavabinTest extends SolrCloudTestCase {
         .configure();
 
     CollectionAdminRequest.createCollection(COLLECTION, "conf", NUM_SHARDS, NUM_REPLICAS)
-        .setMaxShardsPerNode(MAX_SHARDS_PER_NODE)
         .process(cluster.getSolrClient());
 
     cluster.waitForActiveCollection(COLLECTION, 1, 1);
diff --git a/solr/core/src/test/org/apache/solr/update/processor/CategoryRoutedAliasUpdateProcessorTest.java b/solr/core/src/test/org/apache/solr/update/processor/CategoryRoutedAliasUpdateProcessorTest.java
index 56f6ed06b76..618013ec7cc 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/CategoryRoutedAliasUpdateProcessorTest.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/CategoryRoutedAliasUpdateProcessorTest.java
@@ -137,8 +137,7 @@ public class CategoryRoutedAliasUpdateProcessorTest extends RoutedAliasUpdatePro
     assertTrue("ConfigNames should include :" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));
 
     CollectionAdminRequest.createCategoryRoutedAlias(getAlias(), categoryField, 20,
-        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1)
-            .setMaxShardsPerNode(12))
+        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1))
         .process(solrClient);
     addDocsAndCommit(true,
         newDoc(somethingInChinese),
@@ -192,8 +191,7 @@ public class CategoryRoutedAliasUpdateProcessorTest extends RoutedAliasUpdatePro
     assertTrue("ConfigNames should include :" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));
 
     CollectionAdminRequest.createCategoryRoutedAlias(getAlias(), categoryField, 20,
-        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1)
-            .setMaxShardsPerNode(2))
+        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1))
         .process(solrClient);
 
     // now we index a document
@@ -258,8 +256,7 @@ public class CategoryRoutedAliasUpdateProcessorTest extends RoutedAliasUpdatePro
     assertTrue("ConfigNames should include :" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));
 
     CollectionAdminRequest.createCategoryRoutedAlias(getAlias(), categoryField, maxCardinality,
-        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1)
-            .setMaxShardsPerNode(2))
+        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1))
         .setMustMatch(mustMatchRegex)
         .process(solrClient);
 
@@ -298,8 +295,7 @@ public class CategoryRoutedAliasUpdateProcessorTest extends RoutedAliasUpdatePro
     assertTrue("ConfigNames should include :" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));
 
     SolrException e = expectThrows(SolrException.class, () -> CollectionAdminRequest.createCategoryRoutedAlias(getAlias(), categoryField, maxCardinality,
-        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1)
-            .setMaxShardsPerNode(2))
+        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1))
         .setMustMatch(mustMatchRegex)
         .process(solrClient)
     );
@@ -332,8 +328,7 @@ public class CategoryRoutedAliasUpdateProcessorTest extends RoutedAliasUpdatePro
     assertTrue("ConfigNames should include :" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));
 
     CollectionAdminRequest.createCategoryRoutedAlias(getAlias(), categoryField, maxCardinality,
-        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1)
-            .setMaxShardsPerNode(2))
+        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1))
         .process(solrClient);
 
     // now we index a document
@@ -371,8 +366,7 @@ public class CategoryRoutedAliasUpdateProcessorTest extends RoutedAliasUpdatePro
     final int numShards = 1 + random().nextInt(4);
     final int numReplicas = 1 + random().nextInt(3);
     CollectionAdminRequest.createCategoryRoutedAlias(getAlias(), categoryField, 20,
-        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas)
-            .setMaxShardsPerNode(numReplicas*numShards))
+        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas))
         .process(solrClient);
 
     // cause some collections to be created
diff --git a/solr/core/src/test/org/apache/solr/update/processor/DimensionalRoutedAliasUpdateProcessorTest.java b/solr/core/src/test/org/apache/solr/update/processor/DimensionalRoutedAliasUpdateProcessorTest.java
index f69745da04e..59aced6f5bc 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/DimensionalRoutedAliasUpdateProcessorTest.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/DimensionalRoutedAliasUpdateProcessorTest.java
@@ -99,8 +99,7 @@ public class DimensionalRoutedAliasUpdateProcessorTest extends RoutedAliasUpdate
     CreateCategoryRoutedAlias CRA_Dim = createCategoryRoutedAlias(null, getCatField(), 20, null);
 
     CollectionAdminRequest.DimensionalRoutedAlias dra = CollectionAdminRequest.createDimensionalRoutedAlias(getAlias(),
-        CollectionAdminRequest.createCollection("_unused_", configName, 2, 2)
-            .setMaxShardsPerNode(2), TRA_Dim,  CRA_Dim);
+        CollectionAdminRequest.createCollection("_unused_", configName, 2, 2), TRA_Dim,  CRA_Dim);
 
     SolrParams params = dra.getParams();
     assertEquals("Dimensional[TIME,CATEGORY]", params.get(CollectionAdminRequest.RoutedAliasAdminRequest.ROUTER_TYPE_NAME));
@@ -360,8 +359,7 @@ public class DimensionalRoutedAliasUpdateProcessorTest extends RoutedAliasUpdate
     CreateCategoryRoutedAlias CRA_Dim = createCategoryRoutedAlias(null, getCatField(), 20, null);
 
     CollectionAdminRequest.DimensionalRoutedAlias dra = CollectionAdminRequest.createDimensionalRoutedAlias(getAlias(),
-        CollectionAdminRequest.createCollection("_unused_", configName, 2, 2)
-            .setMaxShardsPerNode(2), CRA_Dim, TRA_Dim);
+        CollectionAdminRequest.createCollection("_unused_", configName, 2, 2), CRA_Dim, TRA_Dim);
 
     SolrParams params = dra.getParams();
     assertEquals("Dimensional[CATEGORY,TIME]", params.get(CollectionAdminRequest.RoutedAliasAdminRequest.ROUTER_TYPE_NAME));
diff --git a/solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest.java b/solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest.java
index cba15f88765..c3214f40f4d 100644
--- a/solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest.java
+++ b/solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest.java
@@ -115,7 +115,6 @@ public class TimeRoutedAliasUpdateProcessorTest extends RoutedAliasUpdateProcess
     //  This tests we may pre-create the collection and it's acceptable.
     final String col23rd = alias + TRA + "2017-10-23";
     CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)
-        .setMaxShardsPerNode(2)
         .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)
         .process(solrClient);
 
@@ -130,8 +129,7 @@ public class TimeRoutedAliasUpdateProcessorTest extends RoutedAliasUpdateProcess
     assertTrue("ConfigNames should include :" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));
 
     CollectionAdminRequest.createTimeRoutedAlias(alias, "2017-10-23T00:00:00Z", "+1DAY", getTimeField(),
-        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1)
-            .setMaxShardsPerNode(2))
+        CollectionAdminRequest.createCollection("_unused_", configName, 1, 1))
         .process(solrClient);
 
     // now we index a document
@@ -241,8 +239,7 @@ public class TimeRoutedAliasUpdateProcessorTest extends RoutedAliasUpdateProcess
     final int numShards = 1 + random().nextInt(4);
     final int numReplicas = 1 + random().nextInt(3);
     CollectionAdminRequest.createTimeRoutedAlias(alias, "2017-10-23T00:00:00Z", "+1DAY", getTimeField(),
-        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas)
-            .setMaxShardsPerNode(numReplicas))
+        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas))
         .process(solrClient);
 
     // cause some collections to be created
@@ -288,14 +285,14 @@ public class TimeRoutedAliasUpdateProcessorTest extends RoutedAliasUpdateProcess
     final int numShards = 1 ;
     final int numReplicas = 1 ;
     CollectionAdminRequest.createTimeRoutedAlias(alias, "2017-10-23T00:00:00Z", "+1DAY", getTimeField(),
-        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas)
-            .setMaxShardsPerNode(numReplicas)).setPreemptiveCreateWindow("3HOUR")
+        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas))
+        .setPreemptiveCreateWindow("3HOUR")
         .process(solrClient);
 
     // needed to verify that preemptive creation in one alias doesn't inhibit preemptive creation in another
     CollectionAdminRequest.createTimeRoutedAlias(alias2, "2017-10-23T00:00:00Z", "+1DAY", getTimeField(),
-        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas)
-            .setMaxShardsPerNode(numReplicas)).setPreemptiveCreateWindow("3HOUR")
+        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas))
+        .setPreemptiveCreateWindow("3HOUR")
         .process(solrClient);
 
     addOneDocSynchCreation(numShards, alias);
@@ -376,8 +373,8 @@ public class TimeRoutedAliasUpdateProcessorTest extends RoutedAliasUpdateProcess
     // Start and stop some cores that have TRA's... 2x2 used to ensure every jetty gets at least one
 
     CollectionAdminRequest.createTimeRoutedAlias(getSaferTestName() + "foo", "2017-10-23T00:00:00Z", "+1DAY", getTimeField(),
-        CollectionAdminRequest.createCollection("_unused_", configName, 2, 2)
-            .setMaxShardsPerNode(numReplicas)).setPreemptiveCreateWindow("3HOUR")
+        CollectionAdminRequest.createCollection("_unused_", configName, 2, 2))
+        .setPreemptiveCreateWindow("3HOUR")
         .process(solrClient);
 
     waitColAndAlias(getSaferTestName() + "foo", TRA, "2017-10-23",2);
@@ -735,8 +732,7 @@ public class TimeRoutedAliasUpdateProcessorTest extends RoutedAliasUpdateProcess
     final int numShards = 1 + random().nextInt(4);
     final int numReplicas = 1 + random().nextInt(3);
     CollectionAdminRequest.createTimeRoutedAlias(alias, "2019-09-14T03:00:00Z/DAY", "+1DAY", getTimeField(),
-        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas)
-            .setMaxShardsPerNode(numReplicas))
+        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas))
         .process(solrClient);
 
     aliasUpdate.await();
@@ -927,8 +923,8 @@ public class TimeRoutedAliasUpdateProcessorTest extends RoutedAliasUpdateProcess
     final int numShards = 1 ;
     final int numReplicas = 1 ;
     CollectionAdminRequest.createTimeRoutedAlias(alias, "2017-10-23T00:00:00Z", "+1DAY", getTimeField(),
-        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas)
-            .setMaxShardsPerNode(numReplicas)).setPreemptiveCreateWindow("3HOUR").setAutoDeleteAge("/DAY-3DAYS")
+        CollectionAdminRequest.createCollection("_unused_", configName, numShards, numReplicas))
+        .setPreemptiveCreateWindow("3HOUR").setAutoDeleteAge("/DAY-3DAYS")
         .process(solrClient);
 
     // now create collections that look like the legacy (pre __TRA__) names...
diff --git a/solr/core/src/test/org/apache/solr/util/TestExportTool.java b/solr/core/src/test/org/apache/solr/util/TestExportTool.java
index 7b34958e468..a69d733cb68 100644
--- a/solr/core/src/test/org/apache/solr/util/TestExportTool.java
+++ b/solr/core/src/test/org/apache/solr/util/TestExportTool.java
@@ -56,7 +56,6 @@ public class TestExportTool extends SolrCloudTestCase {
     try {
       CollectionAdminRequest
           .createCollection(COLLECTION_NAME, "conf", 2, 1)
-          .setMaxShardsPerNode(100)
           .process(cluster.getSolrClient());
       cluster.waitForActiveCollection(COLLECTION_NAME, 2, 2);
 
@@ -131,7 +130,6 @@ public class TestExportTool extends SolrCloudTestCase {
     try {
       CollectionAdminRequest
           .createCollection(COLLECTION_NAME, "conf", 8, 1)
-          .setMaxShardsPerNode(10)
           .process(cluster.getSolrClient());
       cluster.waitForActiveCollection(COLLECTION_NAME, 8, 8);
 
diff --git a/solr/server/solr/configsets/sample_techproducts_configs/conf/solrconfig.xml b/solr/server/solr/configsets/sample_techproducts_configs/conf/solrconfig.xml
index ce885f9174a..26141b88f6f 100644
--- a/solr/server/solr/configsets/sample_techproducts_configs/conf/solrconfig.xml
+++ b/solr/server/solr/configsets/sample_techproducts_configs/conf/solrconfig.xml
@@ -774,7 +774,7 @@
          -->
        <!-- Controls the distribution of a query to shards other than itself.
             Consider making 'preferLocalShards' true when:
-              1) maxShardsPerNode > 1
+              1) more than 1 replica may be located on a node
               2) Number of shards > 1
               3) CloudSolrClient or LbHttpSolrServer is used by clients.
             Without this option, every core broadcasts the distributed query to
diff --git a/solr/solr-ref-guide/src/cluster-node-management.adoc b/solr/solr-ref-guide/src/cluster-node-management.adoc
index 4a3099e4a78..3b3de30a23a 100644
--- a/solr/solr-ref-guide/src/cluster-node-management.adoc
+++ b/solr/solr-ref-guide/src/cluster-node-management.adoc
@@ -94,7 +94,6 @@ http://localhost:8983/solr/admin/collections?action=CLUSTERSTATUS
                 "core":"collection1",
                 "node_name":"127.0.1.1:7500_solr",
                 "base_url":"http://127.0.1.1:7500/solr"}}}},
-        "maxShardsPerNode":"1",
         "router":{"name":"compositeId"},
         "replicationFactor":"1",
         "znodeVersion": 11,
diff --git a/solr/solr-ref-guide/src/collection-aliasing.adoc b/solr/solr-ref-guide/src/collection-aliasing.adoc
index 0fa2e4e2d68..80ab5b909a4 100644
--- a/solr/solr-ref-guide/src/collection-aliasing.adoc
+++ b/solr/solr-ref-guide/src/collection-aliasing.adoc
@@ -302,7 +302,6 @@ POST /api/c
       "numShards": 3,
       "tlogReplicas":1,
       "pullReplicas":1,
-      "maxShardsPerNode":2,
       "properties" : {
         "foobar":"bazbam"
       }
@@ -346,7 +345,6 @@ http://localhost:8983/solr/admin/collections?action=CREATEALIAS
     &create-collection.shards=foo,bar,baz
     &create-collection.tlogReplicas=1
     &create-collection.pullReplicas=1
-    &create-collection.maxShardsPerNode=2
     &create-collection.property.foobar=bazbam
 ----
 
diff --git a/solr/solr-ref-guide/src/collection-management.adoc b/solr/solr-ref-guide/src/collection-management.adoc
index 6d2b2a9c62c..aa22dc3f253 100644
--- a/solr/solr-ref-guide/src/collection-management.adoc
+++ b/solr/solr-ref-guide/src/collection-management.adoc
@@ -62,13 +62,6 @@ The number of TLOG replicas to create for this collection. This type of replica
 `pullReplicas`::
 The number of PULL replicas to create for this collection. This type of replica does not maintain a transaction log and only updates its index via replication from a leader. This type is not eligible to become a leader and should not be the only type of replicas in the collection. See the section <<shards-and-indexing-data-in-solrcloud.adoc#types-of-replicas,Types of Replicas>> for more information about replica types.
 
-`maxShardsPerNode`::
-When creating collections, the shards and/or replicas are spread across all available (i.e., live) nodes, and two replicas of the same shard will never be on the same node.
-+
-If a node is not live when the CREATE action is called, it will not get any parts of the new collection, which could lead to too many replicas being created on a single live node. Defining `maxShardsPerNode` sets a limit on the number of replicas the CREATE action will spread to each node.
-+
-If the entire collection can not be fit into the live nodes, no collection will be created at all. The default `maxShardsPerNode` value is `1`. A value of `-1` means unlimited. If a `policy` is also specified then the stricter of `maxShardsPerNode` and policy rules apply.
-
 `createNodeSet`::
 Allows defining the nodes to spread the new collection across. The format is a comma-separated list of node_names, such as `localhost:8983_solr,localhost:8984_solr,localhost:8985_solr`.
 +
@@ -241,7 +234,6 @@ At least one `_attribute_` parameter is required.
 
 The attributes that can be modified are:
 
-* maxShardsPerNode
 * replicationFactor
 * autoAddReplicas
 * collection.configName
@@ -721,7 +713,7 @@ source collection.
 There's a number of optional parameters that determine the target collection layout. If they
 are not specified in the request then their values are copied from the source collection.
 The following parameters are currently supported (described in details in the <<create,CREATE collection>> section):
-`numShards`, `replicationFactor`, `nrtReplicas`, `tlogReplicas`, `pullReplicas`, `maxShardsPerNode`,
+`numShards`, `replicationFactor`, `nrtReplicas`, `tlogReplicas`, `pullReplicas`,
 `autoAddReplicas`, `shards`, `policy`, `createNodeSet`, `createNodeSet.shuffle`, `router.*`.
 
 `removeSource`::
@@ -906,7 +898,6 @@ http://localhost:8983/solr/admin/collections?action=COLSTATUS&collection=getting
         "znodeVersion": 16,
         "properties": {
             "autoAddReplicas": "false",
-            "maxShardsPerNode": "-1",
             "nrtReplicas": "2",
             "pullReplicas": "0",
             "replicationFactor": "2",
@@ -1051,7 +1042,6 @@ http://localhost:8983/solr/admin/collections?action=COLSTATUS&collection=getting
         "znodeVersion": 33,
         "properties": {
             "autoAddReplicas": "false",
-            "maxShardsPerNode": "-1",
             "nrtReplicas": "2",
             "pullReplicas": "0",
             "replicationFactor": "2",
@@ -1299,11 +1289,6 @@ The number of TLOG replicas to create for this collection. This type of replica
 `pullReplicas`::
 The number of PULL replicas to create for this collection. This type of replica does not maintain a transaction log and only updates its index via replication from a leader. This type is not eligible to become a leader and should not be the only type of replicas in the collection. See the section <<shards-and-indexing-data-in-solrcloud.adoc#types-of-replicas,Types of Replicas>> for more information about replica types.
 
-`maxShardsPerNode`::
-When creating collections, the shards and/or replicas are spread across all available (i.e., live) nodes, and two replicas of the same shard will never be on the same node.
-+
-If a node is not live when the CREATE operation is called, it will not get any parts of the new collection, which could lead to too many replicas being created on a single live node. Defining `maxShardsPerNode` sets a limit on the number of replicas CREATE will spread to each node. If the entire collection can not be fit into the live nodes, no collection will be created at all.
-
 `autoAddReplicas`::
 When set to `true`, enables auto addition of replicas on shared file systems. See the section <<running-solr-on-hdfs.adoc#automatically-add-replicas-in-solrcloud,Automatically Add Replicas in SolrCloud>> for more details on settings and overrides.
 
diff --git a/solr/solr-ref-guide/src/enabling-ssl.adoc b/solr/solr-ref-guide/src/enabling-ssl.adoc
index 6d1be3ba5b3..4a3db6a2cbd 100644
--- a/solr/solr-ref-guide/src/enabling-ssl.adoc
+++ b/solr/solr-ref-guide/src/enabling-ssl.adoc
@@ -368,7 +368,6 @@ You should get a response that looks like this:
                 "core":"mycollection_shard2_replica1",
                 "node_name":"127.0.0.1:7574_solr",
                 "leader":"true"}}}},
-        "maxShardsPerNode":"1",
         "router":{"name":"compositeId"},
         "replicationFactor":"1"}},
     "properties":{"urlScheme":"https"}}}
diff --git a/solr/solr-ref-guide/src/replica-management.adoc b/solr/solr-ref-guide/src/replica-management.adoc
index 6dd03cc2da5..5d110ae4fb0 100644
--- a/solr/solr-ref-guide/src/replica-management.adoc
+++ b/solr/solr-ref-guide/src/replica-management.adoc
@@ -26,8 +26,6 @@ Add one or more replicas to a shard in a collection. The node name can be specif
 
 The API uses the Autoscaling framework to find nodes that can satisfy the disk requirements for the new replica(s) but only when an Autoscaling preferences or policy is configured. Refer to <<solrcloud-autoscaling-policy-preferences.adoc#solrcloud-autoscaling-policy-preferences,Autoscaling Policy and Preferences>> section for more details.
 
-WARNING: If the destination node is specified, this command will ignore the maxShardsPerNode property.
-
 `/admin/collections?action=ADDREPLICA&collection=_collection_&shard=_shard_&node=_nodeName_`
 
 === ADDREPLICA Parameters
@@ -164,8 +162,6 @@ This command moves a replica from one node to another node by executing ADDREPLI
 
 If this command is used on a collection where more than one replica from the same shard exists on the same node, and the `shard` and `sourceNode` parameters match more than one replica, the replica selected is not deterministic (currently it's random).
 
-WARNING: MOVERREPLICA does not check the maxShardsPerNode setting, and may produce a collection that is in violation of the maxShardsPerNode.
-
 === MOVEREPLICA Parameters
 
 `collection`::
diff --git a/solr/solr-ref-guide/src/solr-tutorial.adoc b/solr/solr-ref-guide/src/solr-tutorial.adoc
index 8f53f05155d..0eb1a8a5f05 100644
--- a/solr/solr-ref-guide/src/solr-tutorial.adoc
+++ b/solr/solr-ref-guide/src/solr-tutorial.adoc
@@ -161,7 +161,7 @@ INFO  - 2017-07-27 12:48:59.289; org.apache.solr.client.solrj.impl.ZkClientClust
 Uploading /solr-{solr-docs-version}.0/server/solr/configsets/sample_techproducts_configs/conf for config techproducts to ZooKeeper at localhost:9983
 
 Creating new collection 'techproducts' using command:
-http://localhost:8983/solr/admin/collections?action=CREATE&name=techproducts&numShards=2&replicationFactor=2&maxShardsPerNode=2&collection.configName=techproducts
+http://localhost:8983/solr/admin/collections?action=CREATE&name=techproducts&numShards=2&replicationFactor=2&collection.configName=techproducts
 
 {
   "responseHeader":{
@@ -553,7 +553,7 @@ INFO  - 2017-07-27 15:07:46.191; org.apache.solr.client.solrj.impl.ZkClientClust
 Uploading /{solr-docs-version}.0/server/solr/configsets/_default/conf for config films to ZooKeeper at localhost:9983
 
 Creating new collection 'films' using command:
-http://localhost:7574/solr/admin/collections?action=CREATE&name=films&numShards=2&replicationFactor=2&maxShardsPerNode=2&collection.configName=films
+http://localhost:7574/solr/admin/collections?action=CREATE&name=films&numShards=2&replicationFactor=2&collection.configName=films
 
 {
   "responseHeader":{
diff --git a/solr/solr-ref-guide/src/solrcloud-autoscaling-policy-preferences.adoc b/solr/solr-ref-guide/src/solrcloud-autoscaling-policy-preferences.adoc
index 65ca480712b..38d5821737a 100644
--- a/solr/solr-ref-guide/src/solrcloud-autoscaling-policy-preferences.adoc
+++ b/solr/solr-ref-guide/src/solrcloud-autoscaling-policy-preferences.adoc
@@ -430,8 +430,6 @@ When a collection-specific policy is used, the rules in that policy are *appende
 
 It is possible to override rules specified in the cluster policy using collection-specific policy. For example, if a rule `{replica:'<3', node:'#ANY'}` is present in the cluster policy and the collection-specific policy has a rule `{replica:'<4', node:'#ANY'}`, the cluster policy is ignored in favor of the collection policy.
 
-Also, if `maxShardsPerNode` is specified during the time of collection creation, then both `maxShardsPerNode` and the policy rules must be satisfied.
-
 Some attributes such as `cores` can only be used in the cluster policy. See the section <<Policy Rule Attributes>> for details.
 
 To create a new named policy, use the <<solrcloud-autoscaling-api.adoc#create-and-modify-collection-specific-policy,`set-policy` API>>.  Once you have a named policy, you can specify the `policy=<policy_name>` parameter to the CREATE command of the Collection API:
@@ -577,7 +575,7 @@ Example scenario testing the behavior of `.autoAddReplicas` trigger:
 create_cluster numNodes=2 // inline comment
 // load autoscaling config from a JSON string. Notice that the value must be URL-encoded
 load_autoscaling json={'cluster-policy'+:+[{'replica'+:+'<3',+'shard'+:+'#EACH',+'collection'+:+'testCollection','node':'#ANY'}]}&defaultWaitFor=10
-solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2&maxShardsPerNode=2
+solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2
 wait_collection collection=testCollection&shards=2&replicas=2
 // prepare a listener for trigger events and the processing state SUCCEEDED
 event_listener trigger=.auto_add_replicas&stage=SUCCEEDED
@@ -596,7 +594,7 @@ Example scenario testing the behavior of `indexSize` trigger. Notice the use of
 [source,text]
 ----
 create_cluster numNodes=100
-solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2&maxShardsPerNode=2
+solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2
 wait_collection collection=testCollection&shards=2&replicas=2
 // example of defining a trigger config
 solr_request /admin/autoscaling?httpMethod=POST&stream.body={'set-trigger':{'name':'indexSizeTrigger','event':'indexSize','waitFor':'10s','aboveDocs':1000,'enabled':true,'actions':[{'name':'compute_plan','class':'solr.ComputePlanAction'},{'name':'execute_plan','class':'solr.ExecutePlanAction'}]}}
@@ -622,7 +620,7 @@ a random node to consistently add replicas to it.
 [source,text]
 ----
 create_cluster numNodes=2
-solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2&maxShardsPerNode=10
+solr_request /admin/collections?action=CREATE&autoAddReplicas=true&name=testCollection&numShards=2&replicationFactor=2
 wait_collection collection=testCollection&shards=2&replicas=2
 ctx_set key=myNode&value=${_random_node_}
 solr_request /admin/collections?action=ADDREPLICA&collection=testCollection&shard=shard1&node=${myNode}
diff --git a/solr/solr-ref-guide/src/v2-api.adoc b/solr/solr-ref-guide/src/v2-api.adoc
index 5ca9459ae4a..8d895fe6933 100644
--- a/solr/solr-ref-guide/src/v2-api.adoc
+++ b/solr/solr-ref-guide/src/v2-api.adoc
@@ -131,10 +131,7 @@ Example of introspect for a POST API: `\http://localhost:8983/api/c/gettingstart
               "description":"When set to true, enables auto addition of replicas on shared file systems (such as HDFS). See https://lucene.apache.org/solr/guide/running-solr-on-hdfs.html for more details on settings and overrides."},
             "replicationFactor":{
               "type":"string",
-              "description":"The number of replicas to be created for each shard. Replicas are physical copies of each shard, acting as failover for the shard. Note that changing this value on an existing collection does not automatically add more replicas to the collection. However, it will allow add-replica commands to succeed."},
-            "maxShardsPerNode":{
-              "type":"integer",
-              "description":"When creating collections, the shards and/or replicas are spread across all available, live, nodes, and two replicas of the same shard will never be on the same node. If a node is not live when the collection is created, it will not get any parts of the new collection, which could lead to too many replicas being created on a single live node. Defining maxShardsPerNode sets a limit on the number of replicas can be spread to each node. If the entire collection can not be fit into the live nodes, no collection will be created at all."}}}}}],
+              "description":"The number of replicas to be created for each shard. Replicas are physical copies of each shard, acting as failover for the shard. Note that changing this value on an existing collection does not automatically add more replicas to the collection. However, it will allow add-replica commands to succeed."}}}}}],
   "WARNING":"This response format is experimental.  It is likely to change in the future.",
   "availableSubPaths":{
     "/c/gettingstarted/select":["POST", "GET"],
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
index 2ec73a73fba..bbfe4747707 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
@@ -59,7 +59,6 @@ import static org.apache.solr.client.solrj.cloud.autoscaling.Policy.POLICY;
 import static org.apache.solr.common.cloud.DocCollection.RULE;
 import static org.apache.solr.common.cloud.DocCollection.SNITCH;
 import static org.apache.solr.common.cloud.ZkStateReader.AUTO_ADD_REPLICAS;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.NRT_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.PULL_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.READ_ONLY;
@@ -72,6 +71,7 @@ import static org.apache.solr.common.params.CollectionAdminParams.COUNT_PROP;
 import static org.apache.solr.common.params.CollectionAdminParams.CREATE_NODE_SET_PARAM;
 import static org.apache.solr.common.params.CollectionAdminParams.CREATE_NODE_SET_SHUFFLE_PARAM;
 import static org.apache.solr.common.params.CollectionAdminParams.ROUTER_PREFIX;
+import static org.apache.solr.common.params.CollectionAdminParams.SKIP_NODE_ASSIGNMENT;
 import static org.apache.solr.common.params.CollectionAdminParams.WITH_COLLECTION;
 
 /**
@@ -88,7 +88,6 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
       RULE,
       SNITCH,
       REPLICATION_FACTOR,
-      MAX_SHARDS_PER_NODE,
       AUTO_ADD_REPLICAS,
       POLICY,
       COLL_CONF,
@@ -439,7 +438,6 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
     protected String shards;
     protected String routerField;
     protected Integer numShards;
-    protected Integer maxShardsPerNode;
     protected Integer nrtReplicas;
     protected Integer pullReplicas;
     protected Integer tlogReplicas;
@@ -478,7 +476,6 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
     public Create setCreateNodeSet(String nodeSet) { this.createNodeSet = nodeSet; return this; }
     public Create setRouterName(String routerName) { this.routerName = routerName; return this; }
     public Create setRouterField(String routerField) { this.routerField = routerField; return this; }
-    public Create setMaxShardsPerNode(Integer numShards) { this.maxShardsPerNode = numShards; return this; }
     public Create setAutoAddReplicas(boolean autoAddReplicas) { this.autoAddReplicas = autoAddReplicas; return this; }
     public Create setNrtReplicas(Integer nrtReplicas) { this.nrtReplicas = nrtReplicas; return this;}
     public Create setTlogReplicas(Integer tlogReplicas) { this.tlogReplicas = tlogReplicas; return this;}
@@ -498,7 +495,6 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
     public String getRouterName() { return  routerName; }
     public String getShards() { return  shards; }
     public Integer getNumShards() { return numShards; }
-    public Integer getMaxShardsPerNode() { return maxShardsPerNode; }
 
     public Integer getReplicationFactor() { return getNumNrtReplicas(); }
     public Integer getNumNrtReplicas() { return nrtReplicas; }
@@ -556,9 +552,6 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
       if (numShards != null) {
         params.set( ZkStateReader.NUM_SHARDS_PROP, numShards);
       }
-      if (maxShardsPerNode != null) {
-        params.set( ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode);
-      }
       if (routerName != null)
         params.set( "router.name", routerName);
       if (shards != null)
@@ -1082,7 +1075,6 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
 
     // in common with collection creation:
     protected String configName;
-    protected Integer maxShardsPerNode;
     protected Integer replicationFactor;
     protected Integer nrtReplicas;
     protected Integer tlogReplicas;
@@ -1135,9 +1127,6 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
     public Restore setConfigName(String config) { this.configName = config; return this; }
     public String getConfigName()  { return configName; }
 
-    public Integer getMaxShardsPerNode() { return maxShardsPerNode; }
-    public Restore setMaxShardsPerNode(int maxShardsPerNode) { this.maxShardsPerNode = maxShardsPerNode; return this; }
-
     public Integer getReplicationFactor() { return replicationFactor; }
     public Restore setReplicationFactor(Integer replicationFactor) { this.replicationFactor = replicationFactor; return this; }
 
@@ -1167,9 +1156,6 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
       params.set(CoreAdminParams.NAME, backupName);
       params.set(CoreAdminParams.BACKUP_LOCATION, location); //note: optional
       params.set("collection.configName", configName); //note: optional
-      if (maxShardsPerNode != null) {
-        params.set( ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode);
-      }
       if (replicationFactor != null && nrtReplicas != null) {
         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,
             "Cannot set both replicationFactor and nrtReplicas as they mean the same thing");
@@ -2106,6 +2092,7 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
     protected Properties properties;
     protected Replica.Type type;
     protected Integer nrtReplicas, tlogReplicas, pullReplicas;
+    protected Boolean skipNodeAssignment;
     protected String createNodeSet;
 
     private AddReplica(String collection, String shard, String routeKey, Replica.Type type) {
@@ -2141,6 +2128,11 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
       return this;
     }
 
+    public AddReplica setSkipNodeAssignment(Boolean skipNodeAssignment) {
+      this.skipNodeAssignment = skipNodeAssignment;
+      return this;
+    }
+
     public String getRouteKey() {
       return routeKey;
     }
@@ -2236,6 +2228,9 @@ public abstract class CollectionAdminRequest<T extends CollectionAdminResponse>
       if (node != null) {
         params.add(CoreAdminParams.NODE, node);
       }
+      if (skipNodeAssignment != null) {
+        params.add(SKIP_NODE_ASSIGNMENT, String.valueOf(skipNodeAssignment));
+      }
       if (instanceDir != null)  {
         params.add(CoreAdminParams.INSTANCE_DIR, instanceDir);
       }
diff --git a/solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java b/solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java
index aa45f2dabcc..3a4a28a8fb9 100644
--- a/solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java
+++ b/solr/solrj/src/java/org/apache/solr/common/cloud/DocCollection.java
@@ -30,12 +30,9 @@ import java.util.function.BiConsumer;
 import java.util.function.BiPredicate;
 
 import org.apache.solr.client.solrj.cloud.autoscaling.Policy;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
 import org.noggit.JSONWriter;
 
 import static org.apache.solr.common.cloud.ZkStateReader.AUTO_ADD_REPLICAS;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
 import static org.apache.solr.common.cloud.ZkStateReader.NRT_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.PULL_REPLICAS;
 import static org.apache.solr.common.cloud.ZkStateReader.READ_ONLY;
@@ -67,7 +64,6 @@ public class DocCollection extends ZkNodeProps implements Iterable<Slice> {
   private final Integer numNrtReplicas;
   private final Integer numTlogReplicas;
   private final Integer numPullReplicas;
-  private final Integer maxShardsPerNode;
   private final Boolean autoAddReplicas;
   private final String policy;
   private final Boolean readOnly;
@@ -96,7 +92,6 @@ public class DocCollection extends ZkNodeProps implements Iterable<Slice> {
     this.numNrtReplicas = (Integer) verifyProp(props, NRT_REPLICAS, 0);
     this.numTlogReplicas = (Integer) verifyProp(props, TLOG_REPLICAS, 0);
     this.numPullReplicas = (Integer) verifyProp(props, PULL_REPLICAS, 0);
-    this.maxShardsPerNode = (Integer) verifyProp(props, MAX_SHARDS_PER_NODE);
     Boolean autoAddReplicas = (Boolean) verifyProp(props, AUTO_ADD_REPLICAS);
     this.policy = (String) props.get(Policy.POLICY);
     this.autoAddReplicas = autoAddReplicas == null ? Boolean.FALSE : autoAddReplicas;
@@ -147,7 +142,6 @@ public class DocCollection extends ZkNodeProps implements Iterable<Slice> {
     Object o = props.get(propName);
     if (o == null) return def;
     switch (propName) {
-      case MAX_SHARDS_PER_NODE:
       case REPLICATION_FACTOR:
       case NRT_REPLICAS:
       case PULL_REPLICAS:
@@ -257,14 +251,6 @@ public class DocCollection extends ZkNodeProps implements Iterable<Slice> {
     return autoAddReplicas;
   }
   
-  public int getMaxShardsPerNode() {
-    if (maxShardsPerNode == null) {
-      throw new SolrException(ErrorCode.BAD_REQUEST, MAX_SHARDS_PER_NODE + " is not in the cluster state.");
-    }
-    //maxShardsPerNode=0 when policy is used. This variable is not important then
-    return maxShardsPerNode == 0 ? Integer.MAX_VALUE : maxShardsPerNode;
-  }
-
   public DocRouter getRouter() {
     return router;
   }
diff --git a/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java b/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java
index a87e421e1c9..51392592b43 100644
--- a/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java
+++ b/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java
@@ -125,7 +125,6 @@ public class ZkStateReader implements SolrCloseable {
 
   public static final String DEFAULT_SHARD_PREFERENCES = "defaultShardPreferences";
   public static final String REPLICATION_FACTOR = "replicationFactor";
-  public static final String MAX_SHARDS_PER_NODE = "maxShardsPerNode";
   public static final String AUTO_ADD_REPLICAS = "autoAddReplicas";
   public static final String MAX_CORES_PER_NODE = "maxCoresPerNode";
   public static final String PULL_REPLICAS = "pullReplicas";
diff --git a/solr/solrj/src/java/org/apache/solr/common/params/CollectionAdminParams.java b/solr/solrj/src/java/org/apache/solr/common/params/CollectionAdminParams.java
index 5af2345356f..5b6af2e3074 100644
--- a/solr/solrj/src/java/org/apache/solr/common/params/CollectionAdminParams.java
+++ b/solr/solrj/src/java/org/apache/solr/common/params/CollectionAdminParams.java
@@ -127,4 +127,9 @@ public interface CollectionAdminParams {
 
   /** Option to follow aliases when deciding the target of a collection admin command. */
   String FOLLOW_ALIASES = "followAliases";
+  /**
+   * When AddReplica is called with this set to true, then we do not try to find node assignments
+   * for the add replica API. If set to true, a valid "node" should be specified.
+   */
+  String SKIP_NODE_ASSIGNMENT = "skipNodeAssignment";
 }
diff --git a/solr/solrj/src/resources/apispec/collections.Commands.json b/solr/solrj/src/resources/apispec/collections.Commands.json
index 5fc7f76561d..2eb700f4c42 100644
--- a/solr/solrj/src/resources/apispec/collections.Commands.json
+++ b/solr/solrj/src/resources/apispec/collections.Commands.json
@@ -76,10 +76,6 @@
           "type": "boolean",
           "description": "Controls whether or not the shard-replicas created for this collection will be assigned to the nodes specified by the nodeSet property in a sequential manner, or if the list of nodes should be shuffled prior to creating individual replicas. A 'false' value makes the results of a collection creation predictable and gives more exact control over the location of the individual shard-replicas, but 'true' can be a better choice for ensuring replicas are distributed evenly across nodes. This property is ignored if nodeSet is not also specified."
         },
-        "maxShardsPerNode": {
-          "type": "integer",
-          "description": "When creating collections, the shards and/or replicas are spread across all available, live, nodes, and two replicas of the same shard will never be on the same node. If a node is not live when the collection is created, it will not get any parts of the new collection, which could lead to too many replicas being created on a single live node. Defining maxShardsPerNode sets a limit on the number of replicas can be spread to each node. If the entire collection can not be fit into the live nodes, no collection will be created at all."
-        },
         "autoAddReplicas": {
           "type": "boolean",
           "description": "When set to true, enables auto addition of replicas when the number of active replicas falls below the value set for replicationFactor.",
diff --git a/solr/solrj/src/resources/apispec/collections.collection.Commands.modify.json b/solr/solrj/src/resources/apispec/collections.collection.Commands.modify.json
index 7a12eb18a1b..4206b332e3b 100644
--- a/solr/solrj/src/resources/apispec/collections.collection.Commands.modify.json
+++ b/solr/solrj/src/resources/apispec/collections.collection.Commands.modify.json
@@ -33,10 +33,6 @@
     "replicationFactor": {
       "type": "integer",
       "description": "The number of replicas to be created for each shard. Replicas are physical copies of each shard, acting as failover for the shard. Note that changing this value on an existing collection does not automatically add more replicas to the collection. However, it will allow add-replica commands to succeed."
-    },
-    "maxShardsPerNode": {
-      "type": "integer",
-      "description": "When creating collections, the shards and/or replicas are spread across all available, live, nodes, and two replicas of the same shard will never be on the same node. If a node is not live when the collection is created, it will not get any parts of the new collection, which could lead to too many replicas being created on a single live node. Defining maxShardsPerNode sets a limit on the number of replicas can be spread to each node. If the entire collection can not be fit into the live nodes, no collection will be created at all."
     }
 
   }
diff --git a/solr/solrj/src/test-files/solrj/solr/autoscaling/testAddMissingReplica.json b/solr/solrj/src/test-files/solrj/solr/autoscaling/testAddMissingReplica.json
index 60469454e9a..6c202a51d89 100644
--- a/solr/solrj/src/test-files/solrj/solr/autoscaling/testAddMissingReplica.json
+++ b/solr/solrj/src/test-files/solrj/solr/autoscaling/testAddMissingReplica.json
@@ -112,7 +112,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"-1",
         "autoAddReplicas":"false",
         "nrtReplicas":"2",
         "tlogReplicas":"0",
diff --git a/solr/solrj/src/test-files/solrj/solr/autoscaling/testAutoscalingPreferencesUsedWithNoPolicy.json b/solr/solrj/src/test-files/solrj/solr/autoscaling/testAutoscalingPreferencesUsedWithNoPolicy.json
index a4c39d404b6..4974eefc1e5 100644
--- a/solr/solrj/src/test-files/solrj/solr/autoscaling/testAutoscalingPreferencesUsedWithNoPolicy.json
+++ b/solr/solrj/src/test-files/solrj/solr/autoscaling/testAutoscalingPreferencesUsedWithNoPolicy.json
@@ -29,7 +29,6 @@
       "port":8985}},
 "clusterstate":{"c1":{
   "router":{"name":"compositeId"},
-  "maxShardsPerNode":-1,
   "shards":{
     "s1":{"replicas":{
       "r1":{
diff --git a/solr/solrj/src/test-files/solrj/solr/autoscaling/testEmptyCollection.json b/solr/solrj/src/test-files/solrj/solr/autoscaling/testEmptyCollection.json
index 7dd4295802c..0da18b4bd63 100644
--- a/solr/solrj/src/test-files/solrj/solr/autoscaling/testEmptyCollection.json
+++ b/solr/solrj/src/test-files/solrj/solr/autoscaling/testEmptyCollection.json
@@ -19,9 +19,8 @@
   "router":{
     "name":"compositeId",
     "field":"shard_s"},
-  "maxShardsPerNode":"-1",
   "autoAddReplicas":"false",
   "nrtReplicas":1,
   "tlogReplicas":0}},
 
-  "replicaInfo":{}}
\ No newline at end of file
+  "replicaInfo":{}}
diff --git a/solr/solrj/src/test-files/solrj/solr/autoscaling/testInfiniteLoop.json b/solr/solrj/src/test-files/solrj/solr/autoscaling/testInfiniteLoop.json
index ff1bf2a60cf..dbc425d5f66 100644
--- a/solr/solrj/src/test-files/solrj/solr/autoscaling/testInfiniteLoop.json
+++ b/solr/solrj/src/test-files/solrj/solr/autoscaling/testInfiniteLoop.json
@@ -9699,7 +9699,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -10073,7 +10072,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -10183,7 +10181,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -10232,7 +10229,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -10474,7 +10470,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -10827,7 +10822,6 @@
                 "type":"NRT",
                 "force_set_state":"false"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"4",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -10952,7 +10946,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"2",
         "tlogReplicas":"0",
@@ -11001,7 +10994,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -11111,7 +11103,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -11806,7 +11797,6 @@
                 "type":"NRT",
                 "force_set_state":"false"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -11855,7 +11845,6 @@
                 "type":"NRT",
                 "force_set_state":"false"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -11965,7 +11954,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12014,7 +12002,6 @@
                 "type":"NRT",
                 "force_set_state":"false"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12050,7 +12037,6 @@
               "type":"NRT",
               "force_set_state":"false"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12099,7 +12085,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12148,7 +12133,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12258,7 +12242,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12566,7 +12549,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12615,7 +12597,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12664,7 +12645,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12713,7 +12693,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
@@ -12781,7 +12760,6 @@
                 "force_set_state":"false",
                 "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"2",
         "tlogReplicas":"0",
@@ -13155,7 +13133,6 @@
               "force_set_state":"false",
               "leader":"true"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"1",
         "autoAddReplicas":"false",
         "nrtReplicas":"1",
         "tlogReplicas":"0",
diff --git a/solr/solrj/src/test-files/solrj/solr/autoscaling/testMoveReplicasInMultipleCollections.json b/solr/solrj/src/test-files/solrj/solr/autoscaling/testMoveReplicasInMultipleCollections.json
index 16ba1a77ec3..b515050d19e 100644
--- a/solr/solrj/src/test-files/solrj/solr/autoscaling/testMoveReplicasInMultipleCollections.json
+++ b/solr/solrj/src/test-files/solrj/solr/autoscaling/testMoveReplicasInMultipleCollections.json
@@ -38,7 +38,6 @@
             "type":"NRT"}}}},
     "router":{
       "name":"compositeId"},
-    "maxShardsPerNode":"2",
     "autoAddReplicas":"true",
     "nrtReplicas":"2",
     "tlogReplicas":"0"},
@@ -82,7 +81,6 @@
             "leader":"true"}}}},
     "router":{
       "name":"compositeId"},
-    "maxShardsPerNode":"2",
     "autoAddReplicas":"true",
     "nrtReplicas":"2",
-    "tlogReplicas":"0"}}
\ No newline at end of file
+    "tlogReplicas":"0"}}
diff --git a/solr/solrj/src/test-files/solrj/solr/autoscaling/testUnresolvedSuggestion.json b/solr/solrj/src/test-files/solrj/solr/autoscaling/testUnresolvedSuggestion.json
index 19401de06d8..e22b65262c2 100644
--- a/solr/solrj/src/test-files/solrj/solr/autoscaling/testUnresolvedSuggestion.json
+++ b/solr/solrj/src/test-files/solrj/solr/autoscaling/testUnresolvedSuggestion.json
@@ -200,7 +200,6 @@
                 "type":"NRT",
                 "force_set_state":"false"}}}},
         "router":{"name":"compositeId"},
-        "maxShardsPerNode":"-1",
         "autoAddReplicas":"false",
         "nrtReplicas":"2",
         "tlogReplicas":"0",
@@ -209,4 +208,4 @@
     "live_nodes":["10.0.0.80:8983_solr",
       "10.0.0.80:7574_solr",
       "10.0.0.80:8984_solr"]}
-}
\ No newline at end of file
+}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudHttp2SolrClientTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudHttp2SolrClientTest.java
index df76cb83739..83073d9caac 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudHttp2SolrClientTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudHttp2SolrClientTest.java
@@ -427,7 +427,6 @@ public class CloudHttp2SolrClientTest extends SolrCloudTestCase {
     // all its cores on the same node.
     // Hence the below configuration for our collection
     CollectionAdminRequest.createCollection(collectionName, "conf", liveNodes, liveNodes)
-        .setMaxShardsPerNode(liveNodes * liveNodes)
         .processAndWait(cluster.getSolrClient(), TIMEOUT);
     cluster.waitForActiveCollection(collectionName, liveNodes, liveNodes * liveNodes);
     // Add some new documents
@@ -509,7 +508,6 @@ public class CloudHttp2SolrClientTest extends SolrCloudTestCase {
 
     // For testing replica.type, we want to have all replica types available for the collection
     CollectionAdminRequest.createCollection(collectionName, "conf", 1, liveNodes/3, liveNodes/3, liveNodes/3)
-        .setMaxShardsPerNode(liveNodes)
         .processAndWait(cluster.getSolrClient(), TIMEOUT);
     cluster.waitForActiveCollection(collectionName, 1, liveNodes);
 
@@ -975,7 +973,6 @@ public class CloudHttp2SolrClientTest extends SolrCloudTestCase {
     // Hence the below configuration for our collection
     int pullReplicas = Math.max(1, liveNodes - 2);
     CollectionAdminRequest.createCollection(collectionName, "conf", liveNodes, 1, 1, pullReplicas)
-        .setMaxShardsPerNode(liveNodes)
         .processAndWait(cluster.getSolrClient(), TIMEOUT);
     cluster.waitForActiveCollection(collectionName, liveNodes, liveNodes * (2 + pullReplicas));
     
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientCacheTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientCacheTest.java
index 1a671a8e9f6..d35f4d928ed 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientCacheTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientCacheTest.java
@@ -157,7 +157,6 @@ public class CloudSolrClientCacheTest extends SolrTestCaseJ4 {
   private String coll1State = "{'gettingstarted':{\n" +
       "    'replicationFactor':'2',\n" +
       "    'router':{'name':'compositeId'},\n" +
-      "    'maxShardsPerNode':'2',\n" +
       "    'autoAddReplicas':'false',\n" +
       "    'shards':{\n" +
       "      'shard1':{\n" +
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java
index fb363589300..cdf606a739e 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java
@@ -413,7 +413,6 @@ public class CloudSolrClientTest extends SolrCloudTestCase {
     // all its cores on the same node.
     // Hence the below configuration for our collection
     CollectionAdminRequest.createCollection(collectionName, "conf", liveNodes, liveNodes)
-        .setMaxShardsPerNode(liveNodes * liveNodes)
         .processAndWait(cluster.getSolrClient(), TIMEOUT);
     cluster.waitForActiveCollection(collectionName, liveNodes, liveNodes * liveNodes);
     // Add some new documents
@@ -493,7 +492,6 @@ public class CloudSolrClientTest extends SolrCloudTestCase {
 
     // For testing replica.type, we want to have all replica types available for the collection
     CollectionAdminRequest.createCollection(collectionName, "conf", 1, liveNodes/3, liveNodes/3, liveNodes/3)
-        .setMaxShardsPerNode(liveNodes)
         .processAndWait(cluster.getSolrClient(), TIMEOUT);
     cluster.waitForActiveCollection(collectionName, 1, liveNodes);
 
@@ -943,7 +941,6 @@ public class CloudSolrClientTest extends SolrCloudTestCase {
     // Hence the below configuration for our collection
     int pullReplicas = Math.max(1, liveNodes - 2);
     CollectionAdminRequest.createCollection(collectionName, "conf", liveNodes, 1, 1, pullReplicas)
-        .setMaxShardsPerNode(liveNodes)
         .processAndWait(cluster.getSolrClient(), TIMEOUT);
     cluster.waitForActiveCollection(collectionName, liveNodes, liveNodes * (2 + pullReplicas));
     
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamingTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamingTest.java
index 0c3c6093e7b..5afee281509 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamingTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamingTest.java
@@ -123,7 +123,6 @@ public static void configureCluster() throws Exception {
     collection = MULTI_REPLICA_COLLECTIONORALIAS;
   }
   CollectionAdminRequest.createCollection(collection, "conf", numShards, 1, 1, 1)
-      .setMaxShardsPerNode(numShards * 3)
       .process(cluster.getSolrClient());
   cluster.waitForActiveCollection(collection, numShards, numShards * 3);
   if (useAlias) {
diff --git a/solr/solrj/src/test/org/apache/solr/common/cloud/SolrZkClientTest.java b/solr/solrj/src/test/org/apache/solr/common/cloud/SolrZkClientTest.java
index 50bac4986d8..a96c2caa1d2 100644
--- a/solr/solrj/src/test/org/apache/solr/common/cloud/SolrZkClientTest.java
+++ b/solr/solrj/src/test/org/apache/solr/common/cloud/SolrZkClientTest.java
@@ -171,7 +171,6 @@ public class SolrZkClientTest extends SolrCloudTestCase {
     assertEquals(wrapped1A.hashCode(), wrapped2A.hashCode());
 
     CollectionAdminRequest.createCollection(getSaferTestName(), "_default", 1, 1)
-        .setMaxShardsPerNode(2)
         .process(solrClient);
 
     CollectionAdminRequest.setCollectionProperty(getSaferTestName(),"foo", "bar")
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/AbstractFullDistribZkTestBase.java b/solr/test-framework/src/java/org/apache/solr/cloud/AbstractFullDistribZkTestBase.java
index 053586d6c70..5c01018aa26 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/AbstractFullDistribZkTestBase.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/AbstractFullDistribZkTestBase.java
@@ -1751,8 +1751,8 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     cloudClient.commit();
   }
 
-  protected CollectionAdminResponse createCollection(String collectionName, String configSetName, int numShards, int replicationFactor, int maxShardsPerNode) throws SolrServerException, IOException, InterruptedException, TimeoutException {
-    return createCollection(null, collectionName, configSetName, numShards, replicationFactor, maxShardsPerNode, null, null);
+  protected CollectionAdminResponse createCollection(String collectionName, String configSetName, int numShards, int replicationFactor) throws SolrServerException, IOException, InterruptedException, TimeoutException {
+    return createCollection(null, collectionName, configSetName, numShards, replicationFactor, null, null);
   }
 
   protected CollectionAdminResponse createCollection(Map<String,List<Integer>> collectionInfos, String collectionName, Map<String,Object> collectionProps, SolrClient client)  throws SolrServerException, IOException, InterruptedException, TimeoutException{
@@ -1828,7 +1828,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
 
 
   protected CollectionAdminResponse createCollection(Map<String,List<Integer>> collectionInfos,
-      String collectionName, String configSetName, int numShards, int replicationFactor, int maxShardsPerNode, SolrClient client, String createNodeSetStr) throws SolrServerException, IOException, InterruptedException, TimeoutException {
+      String collectionName, String configSetName, int numShards, int replicationFactor, SolrClient client, String createNodeSetStr) throws SolrServerException, IOException, InterruptedException, TimeoutException {
 
     int numNrtReplicas = useTlogReplicas()?0:replicationFactor;
     int numTlogReplicas = useTlogReplicas()?replicationFactor:0;
@@ -1838,13 +1838,12 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
             ZkStateReader.NRT_REPLICAS, numNrtReplicas,
             ZkStateReader.TLOG_REPLICAS, numTlogReplicas,
             ZkStateReader.PULL_REPLICAS, getPullReplicaCount(),
-            OverseerCollectionMessageHandler.CREATE_NODE_SET, createNodeSetStr,
-            ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode),
+            OverseerCollectionMessageHandler.CREATE_NODE_SET, createNodeSetStr),
         client, configSetName);
   }
 
   protected CollectionAdminResponse createCollection(Map<String, List<Integer>> collectionInfos,
-                                                     String collectionName, int numShards, int replicationFactor, int maxShardsPerNode, SolrClient client, String createNodeSetStr, String configName) throws SolrServerException, IOException, InterruptedException, TimeoutException {
+                                                     String collectionName, int numShards, int replicationFactor, SolrClient client, String createNodeSetStr, String configName) throws SolrServerException, IOException, InterruptedException, TimeoutException {
 
     int numNrtReplicas = useTlogReplicas()?0:replicationFactor;
     int numTlogReplicas = useTlogReplicas()?replicationFactor:0;
@@ -1854,8 +1853,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
             ZkStateReader.NRT_REPLICAS, numNrtReplicas,
             ZkStateReader.TLOG_REPLICAS, numTlogReplicas,
             ZkStateReader.PULL_REPLICAS, getPullReplicaCount(),
-            OverseerCollectionMessageHandler.CREATE_NODE_SET, createNodeSetStr,
-            ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode),
+            OverseerCollectionMessageHandler.CREATE_NODE_SET, createNodeSetStr),
         client, configName);
   }
 
@@ -2041,12 +2039,9 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
                                   CloudSolrClient client,
                                   int replicationFactor ,
                                   int numShards ) throws Exception {
-    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrClient()
-        .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
     int numNrtReplicas = useTlogReplicas()?0:replicationFactor;
     int numTlogReplicas = useTlogReplicas()?replicationFactor:0;
     Map<String, Object> props = makeMap(
-        ZkStateReader.MAX_SHARDS_PER_NODE, maxShardsPerNode,
         ZkStateReader.NRT_REPLICAS, numNrtReplicas,
         ZkStateReader.TLOG_REPLICAS, numTlogReplicas,
         ZkStateReader.PULL_REPLICAS, getPullReplicaCount(),
@@ -2055,14 +2050,14 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     createCollection(collectionInfos, collName, props, client);
   }
 
-  protected void createCollectionRetry(String testCollectionName, String configSetName, int numShards, int replicationFactor, int maxShardsPerNode)
+  protected void createCollectionRetry(String testCollectionName, String configSetName, int numShards, int replicationFactor)
       throws SolrServerException, IOException, InterruptedException, TimeoutException {
-    CollectionAdminResponse resp = createCollection(testCollectionName, configSetName, numShards, replicationFactor, maxShardsPerNode);
+    CollectionAdminResponse resp = createCollection(testCollectionName, configSetName, numShards, replicationFactor);
     if (resp.getResponse().get("failure") != null) {
       CollectionAdminRequest.Delete req = CollectionAdminRequest.deleteCollection(testCollectionName);
       req.process(cloudClient);
 
-      resp = createCollection(testCollectionName, configSetName, numShards, replicationFactor, maxShardsPerNode);
+      resp = createCollection(testCollectionName, configSetName, numShards, replicationFactor);
 
       if (resp.getResponse().get("failure") != null) {
         fail("Could not create " + testCollectionName);
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/MultiSolrCloudTestCase.java b/solr/test-framework/src/java/org/apache/solr/cloud/MultiSolrCloudTestCase.java
index eb0a677890e..b7e6bb649f5 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/MultiSolrCloudTestCase.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/MultiSolrCloudTestCase.java
@@ -62,19 +62,16 @@ public abstract class MultiSolrCloudTestCase extends SolrTestCaseJ4 {
 
     final private int numShards;
     final private int numReplicas;
-    final private int maxShardsPerNode;
 
-    public DefaultClusterInitFunction(int numShards, int numReplicas, int maxShardsPerNode) {
+    public DefaultClusterInitFunction(int numShards, int numReplicas) {
       this.numShards = numShards;
       this.numReplicas = numReplicas;
-      this.maxShardsPerNode = maxShardsPerNode;
     }
 
     protected void doAccept(String collection, MiniSolrCloudCluster cluster) {
       try {
         CollectionAdminRequest
         .createCollection(collection, "conf", numShards, numReplicas)
-        .setMaxShardsPerNode(maxShardsPerNode)
         .processAndWait(cluster.getSolrClient(), SolrCloudTestCase.DEFAULT_TIMEOUT);
 
         AbstractDistribZkTestBase.waitForRecoveriesToFinish(collection, cluster.getSolrClient().getZkStateReader(), false, true, SolrCloudTestCase.DEFAULT_TIMEOUT);
diff --git a/solr/webapp/web/js/angular/controllers/cloud.js b/solr/webapp/web/js/angular/controllers/cloud.js
index 27be1ad3100..1327c6e0760 100644
--- a/solr/webapp/web/js/angular/controllers/cloud.js
+++ b/solr/webapp/web/js/angular/controllers/cloud.js
@@ -753,7 +753,6 @@ var graphSubController = function ($scope, Zookeeper) {
                                 pullReplicas: state[c].pullReplicas,
                                 replicationFactor: state[c].replicationFactor,
                                 router: state[c].router.name,
-                                maxShardsPerNode: state[c].maxShardsPerNode,
                                 autoAddReplicas: state[c].autoAddReplicas,
                                 nrtReplicas: state[c].nrtReplicas,
                                 tlogReplicas: state[c].tlogReplicas,
@@ -872,7 +871,6 @@ solrAdminApp.directive('graph', function(Constants) {
                 if (d.data.type == 'collection') {
                   tooltip = d.name + " {<br/> ";
                   tooltip += "numShards: [" + d.data.numShards + "],<br/>";
-                  tooltip += "maxShardsPerNode: [" + d.data.maxShardsPerNode + "],<br/>";
                   tooltip += "router: [" + d.data.router + "],<br/>";
                   tooltip += "autoAddReplicas: [" + d.data.autoAddReplicas + "],<br/>";
                   tooltip += "replicationFactor: [" + d.data.replicationFactor + "],<br/>";
diff --git a/solr/webapp/web/js/angular/controllers/collections.js b/solr/webapp/web/js/angular/controllers/collections.js
index 660baa0abf0..733922843c4 100644
--- a/solr/webapp/web/js/angular/controllers/collections.js
+++ b/solr/webapp/web/js/angular/controllers/collections.js
@@ -102,7 +102,6 @@ solrAdminApp.controller('CollectionsController',
           numShards: 1,
           configName: "",
           replicationFactor: 1,
-          maxShardsPerNode: 1,
           autoAddReplicas: 'false'
         };
       };
@@ -153,7 +152,6 @@ solrAdminApp.controller('CollectionsController',
                 numShards: coll.numShards,
                 "collection.configName": coll.configName,
                 replicationFactor: coll.replicationFactor,
-                maxShardsPerNode: coll.maxShardsPerNode,
                 autoAddReplicas: coll.autoAddReplicas
             };
             if (coll.shards) params.shards = coll.shards;
diff --git a/solr/webapp/web/partials/collection_overview.html b/solr/webapp/web/partials/collection_overview.html
index cf1c18c3146..75287d8320d 100644
--- a/solr/webapp/web/partials/collection_overview.html
+++ b/solr/webapp/web/partials/collection_overview.html
@@ -29,9 +29,6 @@ limitations under the License.
           <dt>Config name:</dt>
             <dd class="value">{{selectedCollection.configName}}</dd>
 
-          <dt>Max shards per node:</dt>
-            <dd class="value">{{selectedCollection.maxShardsPerNode}}</dd>
-
           <dt>Replication factor:</dt>
             <dd class="value">{{selectedCollection.replicationFactor}}</dd>
 
diff --git a/solr/webapp/web/partials/collections.html b/solr/webapp/web/partials/collections.html
index 198030c744f..eb962f1411b 100644
--- a/solr/webapp/web/partials/collections.html
+++ b/solr/webapp/web/partials/collections.html
@@ -49,9 +49,6 @@ limitations under the License.
             </select>
           </p>
 
-          <p class="clearfix"><label for="add_maxShardsPerNode">maxShardsPerNode:</label>
-            <input type="text" name="replicationFactor" id="add_maxShardsPerNode" ng-model="newCollection.maxShardsPerNode"></p>
-
           <p class="clearfix"><label for="add_shards">shards:</label>
             <input type="text" name="shards" id="add_shards" ng-model="newCollection.shards"></p>
 
@@ -214,11 +211,6 @@ limitations under the License.
                 <dd>{{collection.replicationFactor}}</dd>
             </dl></li>
 
-            <li><dl class="clearfix">
-              <dt><span>maxShardsPerNode:</span></dt>
-                <dd>{{collection.maxShardsPerNode}}</dd>
-            </dl></li>
-
             <li><dl class="clearfix">
               <dt><span>router:</span></dt>
                 <dd>{{collection.router.name}}</dd>
