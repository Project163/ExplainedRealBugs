diff --git a/solr/core/src/java/org/apache/solr/cloud/autoscaling/ComputePlanAction.java b/solr/core/src/java/org/apache/solr/cloud/autoscaling/ComputePlanAction.java
index 4a9c7442774..22e3ef5e77e 100644
--- a/solr/core/src/java/org/apache/solr/cloud/autoscaling/ComputePlanAction.java
+++ b/solr/core/src/java/org/apache/solr/cloud/autoscaling/ComputePlanAction.java
@@ -168,7 +168,13 @@ public class ComputePlanAction extends TriggerActionBase {
     // estimate a maximum default limit that should be sufficient for most purposes:
     // number of nodes * total number of replicas * 3
     AtomicInteger totalRF = new AtomicInteger();
-    clusterState.forEachCollection(coll -> totalRF.addAndGet(coll.getReplicationFactor() * coll.getSlices().size()));
+    clusterState.forEachCollection(coll -> {
+      Integer rf = coll.getReplicationFactor();
+      if (rf == null) {
+        rf = coll.getReplicas().size() / coll.getSlices().size();
+      }
+      totalRF.addAndGet(rf * coll.getSlices().size());
+    });
     int totalMax = clusterState.getLiveNodes().size() * totalRF.get() * 3;
     int maxOp = (Integer) autoScalingConfig.getProperties().getOrDefault(AutoScalingParams.MAX_COMPUTE_OPERATIONS, totalMax);
     Object o = event.getProperty(AutoScalingParams.MAX_COMPUTE_OPERATIONS, maxOp);
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimCloudManager.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimCloudManager.java
index c09d4a48c35..234eaea29a1 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimCloudManager.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimCloudManager.java
@@ -392,8 +392,8 @@ public class SimCloudManager implements SolrCloudManager {
   public String simAddNode() throws Exception {
     Map<String, Object> values = createNodeValues(null);
     String nodeId = (String)values.get(ImplicitSnitch.NODE);
-    clusterStateProvider.simAddNode(nodeId);
     nodeStateProvider.simSetNodeValues(nodeId, values);
+    clusterStateProvider.simAddNode(nodeId);
     LOG.trace("-- added node " + nodeId);
     // initialize history handler if this is the first node
     if (historyHandler == null && liveNodesSet.size() == 1) {
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java
index ca2dd48858d..20ffca92fe3 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimClusterStateProvider.java
@@ -111,11 +111,11 @@ import static org.apache.solr.common.params.CommonParams.NAME;
 public class SimClusterStateProvider implements ClusterStateProvider {
   private static final Logger LOG = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
-  private final Map<String, List<ReplicaInfo>> nodeReplicaMap = new ConcurrentHashMap<>();
   private final LiveNodesSet liveNodes;
   private final SimDistribStateManager stateManager;
   private final SimCloudManager cloudManager;
 
+  private final Map<String, List<ReplicaInfo>> nodeReplicaMap = new ConcurrentHashMap<>();
   private final Map<String, Object> clusterProperties = new ConcurrentHashMap<>();
   private final Map<String, Map<String, Object>> collProperties = new ConcurrentHashMap<>();
   private final Map<String, Map<String, Map<String, Object>>> sliceProperties = new ConcurrentHashMap<>();
@@ -257,8 +257,8 @@ public class SimClusterStateProvider implements ClusterStateProvider {
     try {
       Set<String> collections = new HashSet<>();
       // mark every replica on that node as down
-      setReplicaStates(nodeId, Replica.State.DOWN, collections);
       boolean res = liveNodes.remove(nodeId);
+      setReplicaStates(nodeId, Replica.State.DOWN, collections);
       if (!collections.isEmpty()) {
         collectionsStatesRef.set(null);
       }
@@ -279,6 +279,20 @@ public class SimClusterStateProvider implements ClusterStateProvider {
     }
   }
 
+  /**
+   * Remove all replica information related to dead nodes.
+   */
+  public void simRemoveDeadNodes() throws Exception {
+    lock.lockInterruptibly();
+    try {
+      Set<String> myNodes = new HashSet<>(nodeReplicaMap.keySet());
+      myNodes.removeAll(liveNodes.get());
+      collectionsStatesRef.set(null);
+    } finally {
+      lock.unlock();
+    }
+  }
+
   private synchronized void updateOverseerLeader() throws Exception {
     if (overseerLeader != null && liveNodes.contains(overseerLeader)) {
       return;
@@ -436,6 +450,8 @@ public class SimClusterStateProvider implements ClusterStateProvider {
 
       opDelay(replicaInfo.getCollection(), CollectionParams.CollectionAction.ADDREPLICA.name());
 
+      // at this point nuke our cached DocCollection state
+      collectionsStatesRef.set(null);
       List<ReplicaInfo> replicas = nodeReplicaMap.computeIfAbsent(nodeId, n -> new ArrayList<>());
       // mark replica as active
       replicaInfo.getVariables().put(ZkStateReader.STATE_PROP, Replica.State.ACTIVE.toString());
@@ -445,8 +461,6 @@ public class SimClusterStateProvider implements ClusterStateProvider {
       replicaInfo.getVariables().put(Suggestion.coreidxsize, 1);
 
       replicas.add(replicaInfo);
-      // at this point nuke our cached DocCollection state
-      collectionsStatesRef.set(null);
       LOG.trace("-- simAddReplica {}", replicaInfo);
 
       Map<String, Object> values = cloudManager.getSimNodeStateProvider().simGetAllNodeValues()
@@ -483,8 +497,8 @@ public class SimClusterStateProvider implements ClusterStateProvider {
    * @param coreNodeName coreNodeName
    */
   public void simRemoveReplica(String nodeId, String coreNodeName) throws Exception {
-    List<ReplicaInfo> replicas = nodeReplicaMap.computeIfAbsent(nodeId, n -> new ArrayList<>());
     lock.lockInterruptibly();
+    List<ReplicaInfo> replicas = nodeReplicaMap.computeIfAbsent(nodeId, n -> new ArrayList<>());
     try {
       for (int i = 0; i < replicas.size(); i++) {
         if (coreNodeName.equals(replicas.get(i).getName())) {
@@ -572,7 +586,7 @@ public class SimClusterStateProvider implements ClusterStateProvider {
     });
   }
 
-  private void simRunLeaderElection(String collection, Slice s, boolean saveClusterState) throws Exception {
+  private void simRunLeaderElection(String collection, Slice s, boolean saveState) throws Exception {
     AtomicBoolean stateChanged = new AtomicBoolean(Boolean.FALSE);
     Replica leader = s.getLeader();
     if (leader == null || !liveNodes.contains(leader.getNodeName())) {
@@ -636,8 +650,9 @@ public class SimClusterStateProvider implements ClusterStateProvider {
     } else {
       LOG.trace("-- already has leader for {} / {}", collection, s.getName());
     }
-    if (stateChanged.get()) {
+    if (stateChanged.get() || saveState) {
       collectionsStatesRef.set(null);
+      saveClusterState.set(true);
     }
   }
 
@@ -654,6 +669,8 @@ public class SimClusterStateProvider implements ClusterStateProvider {
     List<String> nodeList = new ArrayList<>();
     List<String> shardNames = new ArrayList<>();
     final String collectionName = props.getStr(NAME);
+    // always force getting fresh state
+    collectionsStatesRef.set(null);
     ClusterState clusterState = getClusterState();
     ZkWriteCommand cmd = new ClusterStateMutator(cloudManager).createCollection(clusterState, props);
     if (cmd.noop) {
@@ -758,12 +775,18 @@ public class SimClusterStateProvider implements ClusterStateProvider {
               if (cores == 0) {
                 throw new RuntimeException("Unexpected value of 'cores' (" + cores + ") on node: " + n);
               }
-              cloudManager.getSimNodeStateProvider().simSetNodeValue(n, "cores", cores - 1);
+              try {
+                cloudManager.getSimNodeStateProvider().simSetNodeValue(n, "cores", cores - 1);
+              } catch (InterruptedException e) {
+                Thread.currentThread().interrupt();
+                throw new RuntimeException("interrupted");
+              }
             }
           }
         }
       });
       collectionsStatesRef.set(null);
+      saveClusterState.set(true);
       results.add("success", "");
     } catch (Exception e) {
       LOG.warn("Exception", e);
@@ -787,6 +810,7 @@ public class SimClusterStateProvider implements ClusterStateProvider {
         values.put(ImplicitSnitch.DISK, 1000);
       });
       collectionsStatesRef.set(null);
+      saveClusterState.set(true);
     } finally {
       lock.unlock();
     }
@@ -1057,7 +1081,7 @@ public class SimClusterStateProvider implements ClusterStateProvider {
     }
   }
 
-  public synchronized void createSystemCollection() throws IOException {
+  public void createSystemCollection() throws IOException {
     try {
       if (simListCollections().contains(CollectionAdminParams.SYSTEM_COLL)) {
         return;
@@ -1065,7 +1089,8 @@ public class SimClusterStateProvider implements ClusterStateProvider {
       ZkNodeProps props = new ZkNodeProps(
           NAME, CollectionAdminParams.SYSTEM_COLL,
           REPLICATION_FACTOR, "1",
-          OverseerCollectionMessageHandler.NUM_SLICES, "1"
+          OverseerCollectionMessageHandler.NUM_SLICES, "1",
+          CommonAdminParams.WAIT_FOR_FINAL_STATE, "true"
       );
       simCreateCollection(props, new NamedList());
     } catch (Exception e) {
@@ -1389,7 +1414,7 @@ public class SimClusterStateProvider implements ClusterStateProvider {
       });
     });
     if (infos.isEmpty()) {
-      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Collection " + collection + " doesn't exist.");
+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Collection " + collection + " doesn't exist (shard=" + shard + ").");
     }
     if (divide && value != null && (value instanceof Number)) {
       if ((value instanceof Long) || (value instanceof Integer)) {
@@ -1455,6 +1480,9 @@ public class SimClusterStateProvider implements ClusterStateProvider {
       nodeReplicaMap.forEach((n, replicas) -> {
         replicas.forEach(ri -> collections.add(ri.getCollection()));
       });
+      // check collProps and sliceProps too
+      collProperties.forEach((coll, props) -> collections.add(coll));
+      sliceProperties.forEach((coll, slices) -> collections.add(coll));
       return new ArrayList<>(collections);
     } finally {
       lock.unlock();
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimNodeStateProvider.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimNodeStateProvider.java
index b9169eb2263..cb8640c155e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimNodeStateProvider.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimNodeStateProvider.java
@@ -29,6 +29,7 @@ import java.util.Set;
 import java.util.TreeSet;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.locks.ReentrantLock;
 import java.util.stream.Collectors;
 
 import org.apache.solr.client.solrj.cloud.NodeStateProvider;
@@ -50,6 +51,7 @@ public class SimNodeStateProvider implements NodeStateProvider {
   private final SimClusterStateProvider clusterStateProvider;
   private final SimDistribStateManager stateManager;
   private final LiveNodesSet liveNodesSet;
+  private final ReentrantLock lock = new ReentrantLock();
 
   public SimNodeStateProvider(LiveNodesSet liveNodesSet, SimDistribStateManager stateManager,
                               SimClusterStateProvider clusterStateProvider,
@@ -84,14 +86,19 @@ public class SimNodeStateProvider implements NodeStateProvider {
    * @param node node id
    * @param values values.
    */
-  public void simSetNodeValues(String node, Map<String, Object> values) {
-    Map<String, Object> existing = nodeValues.computeIfAbsent(node, n -> new ConcurrentHashMap<>());
-    existing.clear();
-    if (values != null) {
-      existing.putAll(values);
-    }
-    if (values == null || values.isEmpty() || values.containsKey("nodeRole")) {
-      saveRoles();
+  public void simSetNodeValues(String node, Map<String, Object> values) throws InterruptedException {
+    lock.lockInterruptibly();
+    try {
+      Map<String, Object> existing = nodeValues.computeIfAbsent(node, n -> new ConcurrentHashMap<>());
+      existing.clear();
+      if (values != null) {
+        existing.putAll(values);
+      }
+      if (values == null || values.isEmpty() || values.containsKey("nodeRole")) {
+        saveRoles();
+      }
+    } finally {
+      lock.unlock();
     }
   }
 
@@ -102,15 +109,20 @@ public class SimNodeStateProvider implements NodeStateProvider {
    * @param key property name
    * @param value property value
    */
-  public void simSetNodeValue(String node, String key, Object value) {
-    Map<String, Object> existing = nodeValues.computeIfAbsent(node, n -> new ConcurrentHashMap<>());
-    if (value == null) {
-      existing.remove(key);
-    } else {
-      existing.put(key, value);
-    }
-    if (key.equals("nodeRole")) {
-      saveRoles();
+  public void simSetNodeValue(String node, String key, Object value) throws InterruptedException {
+    lock.lockInterruptibly();
+    try {
+      Map<String, Object> existing = nodeValues.computeIfAbsent(node, n -> new ConcurrentHashMap<>());
+      if (value == null) {
+        existing.remove(key);
+      } else {
+        existing.put(key, value);
+      }
+      if (key.equals("nodeRole")) {
+        saveRoles();
+      }
+    } finally {
+      lock.unlock();
     }
   }
 
@@ -121,21 +133,26 @@ public class SimNodeStateProvider implements NodeStateProvider {
    * @param key property name
    * @param value property value.
    */
-  public void simAddNodeValue(String node, String key, Object value) {
-    Map<String, Object> values = nodeValues.computeIfAbsent(node, n -> new ConcurrentHashMap<>());
-    Object existing = values.get(key);
-    if (existing == null) {
-      values.put(key, value);
-    } else if (existing instanceof Set) {
-      ((Set)existing).add(value);
-    } else {
-      Set<Object> vals = new HashSet<>();
-      vals.add(existing);
-      vals.add(value);
-      values.put(key, vals);
-    }
-    if (key.equals("nodeRole")) {
-      saveRoles();
+  public void simAddNodeValue(String node, String key, Object value) throws InterruptedException {
+    lock.lockInterruptibly();
+    try {
+      Map<String, Object> values = nodeValues.computeIfAbsent(node, n -> new ConcurrentHashMap<>());
+      Object existing = values.get(key);
+      if (existing == null) {
+        values.put(key, value);
+      } else if (existing instanceof Set) {
+        ((Set)existing).add(value);
+      } else {
+        Set<Object> vals = new HashSet<>();
+        vals.add(existing);
+        vals.add(value);
+        values.put(key, vals);
+      }
+      if (key.equals("nodeRole")) {
+        saveRoles();
+      }
+    } finally {
+      lock.unlock();
     }
   }
 
@@ -144,10 +161,16 @@ public class SimNodeStateProvider implements NodeStateProvider {
    * /roles.json is updated.
    * @param node node id
    */
-  public void simRemoveNodeValues(String node) {
-    Map<String, Object> values = nodeValues.remove(node);
-    if (values != null && values.containsKey("nodeRole")) {
-      saveRoles();
+  public void simRemoveNodeValues(String node) throws InterruptedException {
+    LOG.debug("--removing value for " + node);
+    lock.lockInterruptibly();
+    try {
+      Map<String, Object> values = nodeValues.remove(node);
+      if (values != null && values.containsKey("nodeRole")) {
+        saveRoles();
+      }
+    } finally {
+      lock.unlock();
     }
   }
 
@@ -155,19 +178,24 @@ public class SimNodeStateProvider implements NodeStateProvider {
    * Remove values that correspond to dead nodes. If values contained a 'nodeRole'
    * key then /roles.json is updated.
    */
-  public void simRemoveDeadNodes() {
+  public void simRemoveDeadNodes() throws InterruptedException {
     Set<String> myNodes = new HashSet<>(nodeValues.keySet());
     myNodes.removeAll(liveNodesSet.get());
-    AtomicBoolean updateRoles = new AtomicBoolean(false);
-    myNodes.forEach(n -> {
-      LOG.debug("- removing dead node values: " + n);
-      Map<String, Object> vals = nodeValues.remove(n);
-      if (vals.containsKey("nodeRole")) {
-        updateRoles.set(true);
+    lock.lockInterruptibly();
+    try {
+      AtomicBoolean updateRoles = new AtomicBoolean(false);
+      myNodes.forEach(n -> {
+        LOG.debug("- removing dead node values: " + n);
+        Map<String, Object> vals = nodeValues.remove(n);
+        if (vals.containsKey("nodeRole")) {
+          updateRoles.set(true);
+        }
+      });
+      if (updateRoles.get()) {
+        saveRoles();
       }
-    });
-    if (updateRoles.get()) {
-      saveRoles();
+    } finally {
+      lock.unlock();
     }
   }
 
@@ -187,7 +215,7 @@ public class SimNodeStateProvider implements NodeStateProvider {
     return nodeValues;
   }
 
-  private synchronized void saveRoles() {
+  private void saveRoles() {
     final Map<String, Set<String>> roles = new HashMap<>();
     nodeValues.forEach((n, values) -> {
       String nodeRole = (String)values.get("nodeRole");
@@ -211,6 +239,9 @@ public class SimNodeStateProvider implements NodeStateProvider {
    * @return map of metrics names / values
    */
   public Map<String, Object> getReplicaMetricsValues(String node, Collection<String> tags) {
+    if (!liveNodesSet.contains(node)) {
+      throw new RuntimeException("non-live node " + node);
+    }
     List<ReplicaInfo> replicas = clusterStateProvider.simGetReplicaInfos(node);
     if (replicas == null || replicas.isEmpty()) {
       return Collections.emptyMap();
@@ -258,8 +289,7 @@ public class SimNodeStateProvider implements NodeStateProvider {
   public Map<String, Object> getNodeValues(String node, Collection<String> tags) {
     LOG.trace("-- requested values for " + node + ": " + tags);
     if (!liveNodesSet.contains(node)) {
-      nodeValues.remove(node);
-      return Collections.emptyMap();
+      throw new RuntimeException("non-live node " + node);
     }
     if (tags.isEmpty()) {
       return Collections.emptyMap();
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimSolrCloudTestCase.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimSolrCloudTestCase.java
index 757e2975cd9..e83f72f5712 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimSolrCloudTestCase.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/SimSolrCloudTestCase.java
@@ -84,6 +84,10 @@ public class SimSolrCloudTestCase extends SolrTestCaseJ4 {
       // clear any persisted configuration
       cluster.getDistribStateManager().setData(SOLR_AUTOSCALING_CONF_PATH, Utils.toJSON(new ZkNodeProps()), -1);
       cluster.getDistribStateManager().setData(ZkStateReader.ROLES, Utils.toJSON(new HashMap<>()), -1);
+      cluster.getSimClusterStateProvider().simDeleteAllCollections();
+      cluster.simClearSystemCollection();
+      cluster.getSimNodeStateProvider().simRemoveDeadNodes();
+      cluster.getSimClusterStateProvider().simRemoveDeadNodes();
       // restore the expected number of nodes
       int currentSize = cluster.getLiveNodesSet().size();
       if (currentSize < clusterNodeCount) {
@@ -99,10 +103,6 @@ public class SimSolrCloudTestCase extends SolrTestCaseJ4 {
       removeChildren(ZkStateReader.SOLR_AUTOSCALING_TRIGGER_STATE_PATH);
       removeChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH);
       removeChildren(ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH);
-      cluster.getSimClusterStateProvider().simDeleteAllCollections();
-      cluster.simClearSystemCollection();
-      // clear any dead nodes
-      cluster.getSimNodeStateProvider().simRemoveDeadNodes();
       cluster.getSimClusterStateProvider().simResetLeaderThrottles();
       cluster.simRestartOverseer(null);
       cluster.getTimeSource().sleep(5000);
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestClusterStateProvider.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestClusterStateProvider.java
index 71106452ffb..e395985d027 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestClusterStateProvider.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestClusterStateProvider.java
@@ -109,7 +109,11 @@ public class TestClusterStateProvider extends SolrCloudTestCase {
       simCloudManager.getSimClusterStateProvider().simSetClusterProperties(clusterProperties);
       simCloudManager.getSimDistribStateManager().simSetAutoScalingConfig(autoScalingConfig);
       nodeValues.forEach((n, values) -> {
-        simCloudManager.getSimNodeStateProvider().simSetNodeValues(n, values);
+        try {
+          simCloudManager.getSimNodeStateProvider().simSetNodeValues(n, values);
+        } catch (InterruptedException e) {
+          fail("Interrupted:" + e);
+        }
       });
       simCloudManager.getSimClusterStateProvider().simSetClusterState(realState);
       ClusterState simState = simCloudManager.getClusterStateProvider().getClusterState();
diff --git a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster.java b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster.java
index 6d53363a078..6e6b4aa3bd8 100644
--- a/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster.java
+++ b/solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestLargeCluster.java
@@ -33,7 +33,6 @@ import java.util.concurrent.atomic.AtomicInteger;
 import com.carrotsearch.randomizedtesting.annotations.ThreadLeakLingering;
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
 import org.apache.commons.math3.stat.descriptive.SummaryStatistics;
-import org.apache.lucene.util.LuceneTestCase;
 import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.cloud.autoscaling.AutoScalingConfig;
@@ -54,6 +53,7 @@ import org.apache.solr.cloud.autoscaling.CapturedEvent;
 import org.apache.solr.cloud.autoscaling.TriggerValidationException;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.cloud.Replica;
+import org.apache.solr.common.params.CollectionAdminParams;
 import org.apache.solr.common.params.CollectionParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.util.Pair;
@@ -74,7 +74,7 @@ import static org.apache.solr.cloud.autoscaling.AutoScalingHandlerTest.createAut
 @TimeoutSuite(millis = 4 * 3600 * 1000)
 @LogLevel("org.apache.solr.cloud.autoscaling=DEBUG")
 @ThreadLeakLingering(linger = 20000) // ComputePlanAction may take significant time to complete
-@LuceneTestCase.BadApple(bugUrl = "https://issues.apache.org/jira/browse/SOLR-12075")
+//@LuceneTestCase.BadApple(bugUrl = "https://issues.apache.org/jira/browse/SOLR-12075")
 public class TestLargeCluster extends SimSolrCloudTestCase {
   private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
 
@@ -94,7 +94,6 @@ public class TestLargeCluster extends SimSolrCloudTestCase {
 
   @Before
   public void setupTest() throws Exception {
-
     waitForSeconds = 5;
     triggerFiredCount.set(0);
     triggerFiredLatch = new CountDownLatch(1);
@@ -107,6 +106,13 @@ public class TestLargeCluster extends SimSolrCloudTestCase {
     SolrClient solrClient = cluster.simGetSolrClient();
     NamedList<Object> response = solrClient.request(req);
     assertEquals(response.get("result").toString(), "success");
+
+    // do this in advance if missing
+    if (!cluster.getSimClusterStateProvider().simListCollections().contains(CollectionAdminParams.SYSTEM_COLL)) {
+      cluster.getSimClusterStateProvider().createSystemCollection();
+      CloudTestUtils.waitForState(cluster, CollectionAdminParams.SYSTEM_COLL, 120, TimeUnit.SECONDS,
+          CloudTestUtils.clusterShape(1, 1));
+    }
   }
 
   public static class TestTriggerListener extends TriggerListenerBase {
@@ -520,8 +526,7 @@ public class TestLargeCluster extends SimSolrCloudTestCase {
   }
 
   @Test
-  // JIRA closed 24-Feb-2018. Still apparently a problem.
-  @BadApple(bugUrl = "https://issues.apache.org/jira/browse/SOLR-11714")
+  //@BadApple(bugUrl = "https://issues.apache.org/jira/browse/SOLR-11714")
   public void testSearchRate() throws Exception {
     SolrClient solrClient = cluster.simGetSolrClient();
     String collectionName = "testSearchRate";
@@ -575,7 +580,7 @@ public class TestLargeCluster extends SimSolrCloudTestCase {
     assertEquals(response.get("result").toString(), "success");
 
 
-    boolean await = triggerFiredLatch.await(40000 / SPEED, TimeUnit.MILLISECONDS);
+    boolean await = triggerFiredLatch.await(waitForSeconds * 20000 / SPEED, TimeUnit.MILLISECONDS);
     assertTrue("The trigger did not fire at all", await);
     // wait for listener to capture the SUCCEEDED stage
     cluster.getTimeSource().sleep(2000);
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Policy.java b/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Policy.java
index fb01cc5e962..60ff0c929be 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Policy.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/cloud/autoscaling/Policy.java
@@ -383,11 +383,10 @@ public class Policy implements MapWriter {
             return p.compare(r1, r2, false);
           });
         } catch (Exception e) {
-          LOG.error("Exception! prefs = {}, recent r1 = {}, r2 = {}, compare : {} matrix = {}",
+          LOG.error("Exception! prefs = {}, recent r1 = {}, r2 = {}, matrix = {}",
               clusterPreferences,
-              lastComparison[0].node,
-              lastComparison[1].node,
-              p.compare(lastComparison[0],lastComparison[1], false ),
+              lastComparison[0],
+              lastComparison[1],
               Utils.toJSONString(Utils.getDeepCopy(tmpMatrix, 6, false)));
           throw e;
         }
