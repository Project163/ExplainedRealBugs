<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 04:19:44 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SOLR-10141] Caffeine cache causes BlockCache corruption </title>
                <link>https://issues.apache.org/jira/browse/SOLR-10141</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;After fixing the race conditions in the BlockCache itself (&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10121&quot; title=&quot;BlockCache corruption with high concurrency&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10121&quot;&gt;&lt;del&gt;SOLR-10121&lt;/del&gt;&lt;/a&gt;), the concurrency test passes with the previous implementation using ConcurrentLinkedHashMap and fail with Caffeine.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13043296">SOLR-10141</key>
            <summary>Caffeine cache causes BlockCache corruption </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="yseeley@gmail.com">Yonik Seeley</assignee>
                                    <reporter username="yseeley@gmail.com">Yonik Seeley</reporter>
                        <labels>
                    </labels>
                <created>Wed, 15 Feb 2017 15:57:38 +0000</created>
                <updated>Sat, 8 Jun 2019 15:29:16 +0000</updated>
                            <resolved>Tue, 21 Feb 2017 22:31:22 +0000</resolved>
                                    <version>6.0</version>
                                    <fixVersion>6.5</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="15868099" author="yseeley@gmail.com" created="Wed, 15 Feb 2017 16:06:50 +0000"  >&lt;p&gt;OK, so I finally tracked down the corruption failures with Caffeine to the removal listener being called more than once with the same value.&lt;br/&gt;
The first time, the underlying block is released and then presumably reused for a different key.  The next time (which should never happen), the underlying block is unlocked again and can hence be reused by an additional key and we get into a situation where multiple &quot;live&quot; keys point to the same underlying memory block (and corruption results).&lt;/p&gt;

&lt;p&gt;I&apos;m going to come up with a simple unit test that directly tests the underlying Caffeine cache the same way we use it.&lt;/p&gt;</comment>
                            <comment id="15868110" author="ben.manes" created="Wed, 15 Feb 2017 16:15:52 +0000"  >&lt;p&gt;It may be FJP retrying a task if it is slow to complete. If so, we might need to put a guard to ignore multiple attempts. I can help when you have a test case to investigate with.&lt;/p&gt;</comment>
                            <comment id="15868125" author="yseeley@gmail.com" created="Wed, 15 Feb 2017 16:28:02 +0000"  >&lt;p&gt;OK, here&apos;s a rather self-contained test that shows the issue.&lt;/p&gt;</comment>
                            <comment id="15868132" author="yseeley@gmail.com" created="Wed, 15 Feb 2017 16:33:06 +0000"  >&lt;p&gt;Adding a guard in the test code is easy enough (just check if &quot;live&quot; has already been set to false), but that then uncovers an additional problem: a memory leak since size() != (adds-removes) at the end (i.e. the removal listener is not called for all items).&lt;/p&gt;

&lt;p&gt;It looks like the removal listener is called the correct number of times, but not always with the correct value.  My guess is that it&apos;s somehow related to concurrent use of equal keys with different values.&lt;/p&gt;</comment>
                            <comment id="15868161" author="ben.manes" created="Wed, 15 Feb 2017 16:54:44 +0000"  >&lt;p&gt;I plan on porting the test to Caffeine&apos;s suite and checking against 2.x. Just waiting for my train to start.&lt;/p&gt;</comment>
                            <comment id="15868168" author="ben.manes" created="Wed, 15 Feb 2017 16:57:28 +0000"  >&lt;p&gt;Oh, also older jdk8 versions had a bug in fjp causing it to drop tasks. That&apos;s also a possibility at play.&lt;/p&gt;</comment>
                            <comment id="15868205" author="ben.manes" created="Wed, 15 Feb 2017 17:21:18 +0000"  >&lt;p&gt;Running your test against master and it doesn&apos;t fail. Can you please try Caffeine 2.3.5? The only change needed is that the RemovalListener is now lambda friendly.&lt;/p&gt;</comment>
                            <comment id="15868307" author="ben.manes" created="Wed, 15 Feb 2017 18:28:40 +0000"  >&lt;p&gt;I updated the test to use Awaitility to avoid race conditions when asserting the counts. This allowed me to enable the FJP executor so that the listener and eviction occur asynchronously. The test passes against master and I have not tested against the 1.0.1 which Solr still uses (please upgrade!).&lt;/p&gt;</comment>
                            <comment id="15872211" author="jira-bot" created="Fri, 17 Feb 2017 17:50:54 +0000"  >&lt;p&gt;Commit 6804f3694210ac34728dd6f1a74736681dae2837 in lucene-solr&apos;s branch refs/heads/master from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yonik%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;yonik@apache.org&quot;&gt;yonik@apache.org&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=6804f36&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=6804f36&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10141&quot; title=&quot;Caffeine cache causes BlockCache corruption &quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10141&quot;&gt;&lt;del&gt;SOLR-10141&lt;/del&gt;&lt;/a&gt;: Upgrade to Caffeine 2.3.5 to fix issues with removal listener&lt;/p&gt;</comment>
                            <comment id="15872221" author="ben.manes" created="Fri, 17 Feb 2017 18:06:43 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yseeley%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;yseeley@gmail.com&quot;&gt;yseeley@gmail.com&lt;/a&gt;. Sorry about any frustrations this caused.&lt;/p&gt;</comment>
                            <comment id="15872344" author="jira-bot" created="Fri, 17 Feb 2017 19:16:07 +0000"  >&lt;p&gt;Commit be61c6634872435614ea4d59fd14df3426398116 in lucene-solr&apos;s branch refs/heads/branch_6x from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yonik%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;yonik@apache.org&quot;&gt;yonik@apache.org&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=be61c66&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=be61c66&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10141&quot; title=&quot;Caffeine cache causes BlockCache corruption &quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10141&quot;&gt;&lt;del&gt;SOLR-10141&lt;/del&gt;&lt;/a&gt;: Upgrade to Caffeine 2.3.5 to fix issues with removal listener&lt;/p&gt;</comment>
                            <comment id="15872905" author="jira-bot" created="Sat, 18 Feb 2017 02:21:23 +0000"  >&lt;p&gt;Commit 33e398c02115c57ea54bda5f6f612f1b06c1e771 in lucene-solr&apos;s branch refs/heads/master from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yonik%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;yonik@apache.org&quot;&gt;yonik@apache.org&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=33e398c&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=33e398c&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10141&quot; title=&quot;Caffeine cache causes BlockCache corruption &quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10141&quot;&gt;&lt;del&gt;SOLR-10141&lt;/del&gt;&lt;/a&gt;: add test for underlying cache&lt;/p&gt;</comment>
                            <comment id="15872906" author="jira-bot" created="Sat, 18 Feb 2017 02:21:42 +0000"  >&lt;p&gt;Commit d810edf5e900bef32b10928d275a02c093d359b6 in lucene-solr&apos;s branch refs/heads/branch_6x from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yonik%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;yonik@apache.org&quot;&gt;yonik@apache.org&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d810edf&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d810edf&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10141&quot; title=&quot;Caffeine cache causes BlockCache corruption &quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10141&quot;&gt;&lt;del&gt;SOLR-10141&lt;/del&gt;&lt;/a&gt;: add test for underlying cache&lt;/p&gt;</comment>
                            <comment id="15872937" author="yseeley@gmail.com" created="Sat, 18 Feb 2017 02:54:24 +0000"  >&lt;p&gt;Well darn... it looked like things were fixed by the upgrade to 2.3.5, but then I looked a little closer.&lt;br/&gt;
I happened to notice that the hit rate was super high, when I designed the test to be closer to 50% (maxEntries = maxBlocks/2)&lt;/p&gt;

&lt;p&gt;When I set these parameters in the test:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; readLastBlockOdds=0; &lt;span class=&quot;code-comment&quot;&gt;// odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; updateAnyway = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; &lt;span class=&quot;code-comment&quot;&gt;// sometimes insert a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; entry &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the key even &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; one was found&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Results in something like this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Done! # of Elements = 200 inserts=17234 removals=17034 hits=9982766 maxObservedSize=401
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;So for 10M multi-threaded reads, our hit rate was 99.8%, which artificially lowers the rate at which we insert new entries, and hence doesn&apos;t exercise the concurrency as well, leading to a passing test most of the time.&lt;/p&gt;

&lt;p&gt;When I modified the test to increase the write concurrency again, accounting for a cache that is apparently too big:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; readLastBlockOdds=10; &lt;span class=&quot;code-comment&quot;&gt;// odds (1 in N) of the next block operation being on the same block as the previous operation... helps flush concurrency issues
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; updateAnyway = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;; &lt;span class=&quot;code-comment&quot;&gt;// sometimes insert a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; entry &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; the key even &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; one was found&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The removal listener issues reappear:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;WARNING: Exception thrown by removal listener
java.lang.RuntimeException: listener called more than once! k=103 v=org.apache.solr.store.blockcache.BlockCacheTest$Val@49dbc210 removalCause=SIZE
	at org.apache.solr.store.blockcache.BlockCacheTest.lambda$testCacheConcurrent$0(BlockCacheTest.java:250)
	at org.apache.solr.store.blockcache.BlockCacheTest$$Lambda$5/498475569.onRemoval(Unknown Source)
	at com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$notifyRemoval$1(BoundedLocalCache.java:286)
	at com.github.benmanes.caffeine.cache.BoundedLocalCache$$Lambda$12/1297599052.run(Unknown Source)
	at org.apache.solr.store.blockcache.BlockCacheTest$$Lambda$7/957914685.execute(Unknown Source)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Guarding against the removal listener being called more than once with the same entry also doesn&apos;t seem to work (same as before) since it then becomes apparent that some entries never get passed to the removal listener.&lt;/p&gt;

&lt;p&gt;Even if the removal listener issues are fixed, the fact that the cache can be bigger than the configured size is a problem for us.  The map itself is not storing the data, only controlling access to direct memory, so timely removal (and a timely call to the removal listener) under heavy concurrency is critical.  Without that, the cache will cease to function as a LRU cache under load because we won&apos;t be able to find a free block int he direct memory to actually use.&lt;/p&gt;

&lt;p&gt;Even with only 2 threads, I see the cache going to at least double the configured maxEntries.  Is there a way to configure the size checking to be more strict?&lt;/p&gt;</comment>
                            <comment id="15872943" author="ben.manes" created="Sat, 18 Feb 2017 02:59:07 +0000"  >&lt;p&gt;Can you provide me with the latest version of a self-contained test? If I can reproduce and debug it, I&apos;ll have a fix over the weekend.&lt;/p&gt;

&lt;p&gt;v2 introduced a new eviction policy to take into account the frequency. The eviction should be rapid, so these issues remaining are surprising. I&apos;ve tried to be diligent about testing, so will investigate.&lt;/p&gt;</comment>
                            <comment id="15872965" author="yseeley@gmail.com" created="Sat, 18 Feb 2017 03:36:27 +0000"  >&lt;p&gt;I checked in the test (test method testCacheConcurrent) : &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;a=blob;f=solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest.java&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;a=blob;f=solr/core/src/test/org/apache/solr/store/blockcache/BlockCacheTest.java&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15872969" author="ben.manes" created="Sat, 18 Feb 2017 03:41:58 +0000"  >&lt;p&gt;Thanks! I&apos;m resolving some issues with the latest error-prone (static analyzer) and dig into it.&lt;/p&gt;</comment>
                            <comment id="15872983" author="ben.manes" created="Sat, 18 Feb 2017 04:42:00 +0000"  >&lt;p&gt;Thanks!!! I think I found the bug. It now passes your test case.&lt;/p&gt;

&lt;p&gt;The problem was due to put() stampeding over the value during the eviction. The &lt;a href=&quot;https://github.com/ben-manes/caffeine/blob/65e3efd4b50613c27567ff594877d0f63acfbce2/caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java#L725&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;eviction routine&lt;/a&gt; performed the following:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Read the key, value, etc&lt;/li&gt;
	&lt;li&gt;Conditionally removed in a computeIfPresent() block
	&lt;ul&gt;
		&lt;li&gt;resurrected if a race occurred (e.g. was thought expired, but newly accessed)&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Mark the entry as &quot;dead&quot; (using a synchronized (entry) block)&lt;/li&gt;
	&lt;li&gt;Notify the listener&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;This failed because &lt;a href=&quot;https://github.com/ben-manes/caffeine/blob/65e3efd4b50613c27567ff594877d0f63acfbce2/caffeine/src/main/java/com/github/benmanes/caffeine/cache/BoundedLocalCache.java#L1521&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;putFast&lt;/a&gt; can perform its update outside of a hash table lock (e.g. a computation). It synchronizes on the entry to update, checking first if it was still alive. This resulted in a race where the entry was removed from the hash table, the value updated, and entry marked as dead. When the listener was notified, it received the wrong value.&lt;/p&gt;

&lt;p&gt;The solution I have now is to expand the synchronized block on eviction. This passes your test and should be cheap. I&apos;d like to review it a little more and incorporate your test into my suite.&lt;/p&gt;

&lt;p&gt;This is an excellent find. I&apos;ve stared at the code many times and the race seems obvious in hindsight.&lt;/p&gt;</comment>
                            <comment id="15873011" author="ben.manes" created="Sat, 18 Feb 2017 05:51:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/ben-manes/caffeine/pull/144&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Pull Request&lt;/a&gt; with the fix and your test case.&lt;/p&gt;</comment>
                            <comment id="15873210" author="yseeley@gmail.com" created="Sat, 18 Feb 2017 15:21:12 +0000"  >&lt;p&gt;Thanks Ben, I confirmed that this fixes the removalListener issue.&lt;/p&gt;

&lt;p&gt;As far as the cache size issue, I&apos;ve found that calling cache.cleanUp() after a put() seems to keep things under control.  Is there any other method I should look at?&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;            &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (cache.estimatedSize() &amp;gt; maxEntries) {
              &lt;span class=&quot;code-comment&quot;&gt;// BlockCache *really* relies on having enough removalListeners called to get back down to the configured maxEntries (otherwise the
&lt;/span&gt;              &lt;span class=&quot;code-comment&quot;&gt;// underlying direct memory will be exhausted and the BlockCache.store will have to fail).
&lt;/span&gt;              cache.cleanUp();
            }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15873334" author="ben.manes" created="Sat, 18 Feb 2017 20:47:49 +0000"  >&lt;p&gt;If you wish to ensure a very strict bounding by throttling writers, that would do the job. I&apos;m not sure if its needed except in your tests, as in practice the assumption is its cleaned up in a timely enough manner.&lt;/p&gt;

&lt;p&gt;The cache uses a bounded write buffer to provide some slack, minimize the response latencies for writers, and defers the cleanup to the executor (scheduled as immediate). This allows the cache to temporarily exceed the high water mark, but catch up quickly. In general a high write rate on a cache is actually 2-3 inserts/sec, there&apos;s memory headroom for GC, and the server isn&apos;t cpu bounded. If instead we ensured a strict bound then we&apos;d need a global lock to throttle writers on which limits concurrency. So its a trade-off that works for most usages.&lt;/p&gt;

&lt;p&gt;CLHM uses the same design, so I wonder if only your tests are affected but it is okay in practice. CLHM uses an unbounded write buffer, whereas in Caffeine its bounded to provide some back pressure if full. Being full is very rare, so this is mostly to replace linked lists with a growable ring buffer. The slack is probably excessive as I didn&apos;t have a good sizing parameter (max ~= 128 x ncpu). The cleanUp() call forces the caller to block and do the maintenance itself, rather than relying on the async processing (which may be in-flight or triggered on a subsequent operation). You can get a sense of this write-ahead log design from this &lt;a href=&quot;https://docs.google.com/presentation/d/1NlDxyXsUG1qlVHMl4vsUUBQfAJ2c2NsFPNPr2qymIBs&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;slide deck&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&apos;m not sure what, or if, I can do anything regarding your size concern. But I&apos;ll wait for releasing 2.4 until you&apos;re satisfied that we&apos;ve resolved all the issues.&lt;/p&gt;</comment>
                            <comment id="15873357" author="yseeley@gmail.com" created="Sat, 18 Feb 2017 23:02:13 +0000"  >&lt;p&gt;The size issue is only an issue for the BlockCache specifically (not for any other Solr caches).&lt;br/&gt;
Actually, the way the BlockCache is written, we are guaranteed to never have more than maxEntries... writers have to wait for an open slot (which opens up once the removal listener is called).  The writer spins a bit trying to find an open slot and fails if it can&apos;t.  Doing extra work via cache.cleanUp() if we don&apos;t see an empty slot is definitely better than failing to cache the entry.&lt;/p&gt;

&lt;p&gt;I imagine the issue existed when CLHM was used as well.  The metric of store failures isn&apos;t currently tracked, and it only leads to a lower cache hit rate.  I plan on starting to track it, and then to see how often it happens when we&apos;re actually caching real HDFS blocks.  That&apos;s a separate issue though.&lt;/p&gt;</comment>
                            <comment id="15873361" author="ben.manes" created="Sat, 18 Feb 2017 23:15:40 +0000"  >&lt;p&gt;That makes sense. If its a fallback when an empty slot can&apos;t be acquired, it may be preferable to calling cleanUp() always. But a stress test would be necessary to verify that, as the spin time might be too small so that it didn&apos;t help.&lt;/p&gt;

&lt;p&gt;In most traces frequency dominates over recency, so most insertions are pollutants. The impact of a failed insertion might not have had a negative result, as a popular item would make its way in. Then the failing one-hit wonders wouldn&apos;t have disrupted the LRU as much. That&apos;s less meaningful with Caffeine, since we switched to TinyLFU.&lt;/p&gt;

&lt;p&gt;As an aside, I&apos;d appreciate help in moving &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8241&quot; title=&quot;Evaluate W-TinyLfu cache&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8241&quot;&gt;&lt;del&gt;SOLR-8241&lt;/del&gt;&lt;/a&gt; forward. Its been approved but backlogged as the committer has not had the time to actively participate in Solr. But if that&apos;s crossing territories or you feel uncomfortable due to this bug, I understand.&lt;/p&gt;</comment>
                            <comment id="15873511" author="ben.manes" created="Sun, 19 Feb 2017 06:59:47 +0000"  >&lt;p&gt;Released 2.4.0&lt;/p&gt;</comment>
                            <comment id="15876847" author="jira-bot" created="Tue, 21 Feb 2017 22:15:19 +0000"  >&lt;p&gt;Commit e9e02a2313518682690ca2933efd0b4db0b54b7c in lucene-solr&apos;s branch refs/heads/master from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yonik%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;yonik@apache.org&quot;&gt;yonik@apache.org&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e9e02a2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e9e02a2&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10141&quot; title=&quot;Caffeine cache causes BlockCache corruption &quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10141&quot;&gt;&lt;del&gt;SOLR-10141&lt;/del&gt;&lt;/a&gt;: Upgrade to Caffeine 2.4.0 to fix issues with removal listener&lt;/p&gt;</comment>
                            <comment id="15876872" author="jira-bot" created="Tue, 21 Feb 2017 22:26:29 +0000"  >&lt;p&gt;Commit d8799bc475ca5d384ec49ecf2726aec58e37447b in lucene-solr&apos;s branch refs/heads/branch_6x from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yonik%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;yonik@apache.org&quot;&gt;yonik@apache.org&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d8799bc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d8799bc&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10141&quot; title=&quot;Caffeine cache causes BlockCache corruption &quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10141&quot;&gt;&lt;del&gt;SOLR-10141&lt;/del&gt;&lt;/a&gt;: Upgrade to Caffeine 2.4.0 to fix issues with removal listener&lt;/p&gt;</comment>
                            <comment id="15876880" author="yseeley@gmail.com" created="Tue, 21 Feb 2017 22:31:22 +0000"  >&lt;p&gt;Everything is looking good w/ Caffeine 2.4.0, thanks for the help Ben!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310010">
                    <name>Incorporates</name>
                                                                <inwardlinks description="is part of">
                                        <issuelink>
            <issuekey id="13042123">SOLR-10121</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13041915">SOLR-10115</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12818866">SOLR-7355</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12852847" name="SOLR-10141.patch" size="3855" author="yseeley@gmail.com" created="Wed, 15 Feb 2017 16:28:02 +0000"/>
                            <attachment id="12852875" name="Solr10141Test.java" size="4033" author="ben.manes" created="Wed, 15 Feb 2017 18:28:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 39 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3a4br:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313321" key="com.atlassian.jira.toolkit:message">
                        <customfieldname>Solr Mailing List Info</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>