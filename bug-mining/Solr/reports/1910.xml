<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 03:51:00 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SOLR-5495] Recovery strategy for leader partitioned from replica case.</title>
                <link>https://issues.apache.org/jira/browse/SOLR-5495</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;We need to work out a strategy for the case of:&lt;/p&gt;

&lt;p&gt;Leader and replicas can still talk to ZooKeeper, Leader cannot talk to replica.&lt;/p&gt;

&lt;p&gt;We punted on this in initial design, but I&apos;d like to get something in.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12680886">SOLR-5495</key>
            <summary>Recovery strategy for leader partitioned from replica case.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="thelabdude">Timothy Potter</assignee>
                                    <reporter username="markrmiller@gmail.com">Mark Miller</reporter>
                        <labels>
                    </labels>
                <created>Sat, 23 Nov 2013 17:27:31 +0000</created>
                <updated>Fri, 11 Jul 2014 15:18:48 +0000</updated>
                            <resolved>Tue, 24 Jun 2014 16:58:20 +0000</resolved>
                                                    <fixVersion>4.9</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>14</watches>
                                                                                                                <comments>
                            <comment id="13830709" author="markrmiller@gmail.com" created="Sat, 23 Nov 2013 17:34:06 +0000"  >&lt;p&gt;In this case, the only real communication path is through zookeeper.&lt;/p&gt;

&lt;p&gt;Couple ideas I have thought about - seems tricky in general though:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;have the leader publish the replica as down - this is tricky because the replica may be publishing it&apos;s own states - perhaps we publish it with a special marker, and the overseer will not write a new state for that replica until one is published acking that it has seen the marker and acted accordingly?&lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;have a zk queue that leaders can publish to, asking for a recovery - replicas monitor the queue and check it at startup - if they are in it, they enter recovery and remove the queue entry - Overseer could also periodically clear the queue&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Just a quick 30 sec dump of some initial thoughts...looking for other ideas and may offer some more myself.&lt;/p&gt;</comment>
                            <comment id="13958938" author="tim.potter" created="Thu, 3 Apr 2014 16:30:03 +0000"  >&lt;p&gt;Hi Mark,&lt;/p&gt;

&lt;p&gt;I&apos;m finally starting work on this ... I like both of your ideas above; of the two, I like the latter a little more so will start there and see what shakes out.&lt;/p&gt;</comment>
                            <comment id="13974430" author="tim.potter" created="Fri, 18 Apr 2014 20:11:33 +0000"  >&lt;p&gt;Here is a first patch that shows the direction I&apos;m heading with this. A few things to note about this patch that are worth discussing (sorry it&apos;s a bit long winded but want to be sure we&apos;re all on the same page about this solution):&lt;/p&gt;

&lt;p&gt;1) I found a handy class named SocketProxy in the ActiveMQ project and &quot;borrowed&quot; it here to help simulate network partitions, such as between the leader and replica, while keeping the ZooKeeper connection alive. I&apos;m aware of the IpTables class (from &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5482&quot; title=&quot;We should add an option to the ChaosMonkey&amp;#39;s to do more complicated partition failures on Linux, as well as simulate hard fails of Jetty.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5482&quot;&gt;SOLR-5482&lt;/a&gt;) but the advantage of SocketProxy is it is just native Java so runs w/o sudo and on any platforms that don&apos;t have iptables. This of course requires a little trickery when setting up your test as you need to insert the proxy in-front of the Jetty nodes, which is being accomplished by setting a proxyPort on the JettySolrRunner, see HttpPartitionTest.createJetty. I&apos;m guessing we can build this into a test base class if we like this approach and think it will be useful for other tests.&lt;/p&gt;

&lt;p&gt;2) I ended up going with Mark&apos;s idea #1 except I don&apos;t see where / why we need to worry about the replica publishing it&apos;s own state? In other words, what really matters, is that the leader cannot send a request to the replica, so to me, the leader&apos;s view of the replica is what matters. In my patch, the leader will publish the state of the replica as &quot;down&quot; when it encounters a communication error when trying to send a request to a replica. See ZkController.ensureReplicaInLeaderInitiatedRecovery() method, which is called from the DistributedUpdateProcessor.doFinish() method.&lt;/p&gt;

&lt;p&gt;So I&apos;ve thought about this in some detail and I think it will work itself out without us having to coordinate state changes. So let&apos;s just say the leader set the state to &quot;down&quot; and for some weird reason (which I can&apos;t really see how it would happen), the replica reset it&apos;s state to &quot;active&quot;. This would make the replica a candidate for receiving requests again, which would just lead to another error, leading to the leader re-setting the state to &quot;down&quot;. In a nutshell, if the leader can&apos;t talk to the replica over http, it&apos;s state gets set to &quot;down&quot;.&lt;/p&gt;

&lt;p&gt;One idea I did have for this is to have the leader pass the ClusterState.zkClusterStateVersion along in every request, thus allowing the replica to compare the version it is working with and if they are different, then have the replica force a state update from ZK and act accordingly. It shouldn&apos;t be too bad to implement this if we think it will be useful? Version would be passed along like the distrib.update param is today.&lt;/p&gt;

&lt;p&gt;3) Even if more coordination is needed for #2 ^ at some point the replica gets marked as being in the down state. This ensures the leader stops trying to send requests to that replica (via the DOWN filter in the call to getReplicaProps to determine the set of Nodes to forward requests to). The leader also needs to determine if it should send the CoreAdminAction.REQUESTRECOVERY command to the downed replica&apos;s core. This occurs over HTTP, which I think is correct because if the leader can&apos;t send the recover command to the replica, then sending docs is futile as well. What I&apos;ve done here is to build upon the existing code in DistributedUpdateProcessor&apos;s doFinish method to attempt sending that command every 5 secs for up to 10 minutes so long as the node is still listed as a /live_nodes in ZK. If that changes, I stop trying to hit that node from the leader since a node that is no longer live will do full recovery when it comes back.&lt;/p&gt;

&lt;p&gt;I like this leader-initiated recovery approach because the leader&apos;s view of the replica is what matters, so I felt creating a self-initiating recovery process by which the replica realizes its state got changed by the leader doesn&apos;t do much if the HTTP connection between the leader and replica is still down.&lt;/p&gt;

&lt;p&gt;4) Of course, there&apos;s no guarantee that connectivity will be restored within 10 minutes, so the re-try loop described in #3 ^ will timeout and the leader will stop trying to tell the replica to recover. At this point, the replica should be marked down so at least the leader is no longer trying to send requests to it, so I think the shard is in a safe state wrt consistency but after the 10 minutes, there&apos;s nothing to tell the replica to recover from the down state. Do we want the leader to just try forever? Seems like not ... Maybe this is where an ops alert could be inserted to have someone go investigate why the partition is longer than 10 minutes. Appreciate any advice on how to handle this better.&lt;/p&gt;

&lt;p&gt;5) You&apos;ll notice that I&apos;m using a HashSet containing replicaUrl&apos;s in ZkController to keep track of replicas that are in the &quot;leader-initiated&quot; recovery process, see: ZkController.replicasInLeaderInitiatedRecoveryHandling. This approach is needed because there are many DistributedUpdateProcessor&apos;s that may be receiving a flood of errors concurrently when connectivity to a replica is lost. I didn&apos;t want the leader trying to set the state to DOWN more than once when it sees a bunch of errors or to have more than one thread per replica trying to send the recovery command. There might be a better location for this code than the ZkController (maybe ZkStateReader).&lt;/p&gt;

&lt;p&gt;As for testing, I think the unit test (HttpPartitionTest) is pretty close to the scenario we&apos;re trying to capture in this ticket.&lt;/p&gt;

&lt;p&gt;Specifically, it tests the following process:&lt;/p&gt;

&lt;p&gt;a. setup proxies in-front of all Jetty servers (3 in this test) by overriding the createJetty method.&lt;br/&gt;
b. create a collection with 1 shard and rf=2&lt;br/&gt;
c. send doc 1 to leader, which gets forwarded to replica successfully&lt;br/&gt;
d. partition occurs (using SocketProxy); however the ZK connection between the replica remains in tact (which is the crux of this issue); the leader remains the same throughout this test&lt;br/&gt;
e. send doc 2 to leader&lt;br/&gt;
f. leader send doc 2 to replica fails due to comm error, asynchronous call to doFinish starts the leader-initiated recovery process&lt;br/&gt;
g. leader marks replica as being down, which means it will stop trying to send requests to the replica until the situation improves as the ZkStateReader.getReplicaProps() filters out &quot;downed&quot; nodes. At this point, the leader is also trying to tell the replica to recover from a background thread.&lt;br/&gt;
h. partition is restored&lt;br/&gt;
i. send doc 3&lt;br/&gt;
j. replica recovery succeeds asynchronously, test waits until it sees the replica in the &quot;active&quot; state&lt;br/&gt;
k. test verifies both the leader and the replica have docs 1,2,3 using requests to the /get handler&lt;/p&gt;

&lt;p&gt;Next, the test performs the same basic process but for 1000 docs while dropping and restoring the connectivity between the leader and replica every 100 docs.&lt;/p&gt;

&lt;p&gt;I should mention that without the code in this patch, the replica will most certainly be out of sync and not know it, which of course is a no-no for a CP system (btw: I used real test-driven development methodology here by writing the test first and then implementing until the test passes).&lt;/p&gt;

&lt;p&gt;The one minor concern I have with this test right now is the Thread.sleep(2000) before restoring connectivity with the proxy. I had to introduce this because the test was progressing too fast for the recovery process to kick-in, thus leading to test failures. I think this is OK to wait a little bit because that is more reflective of a running cluster and things do take a little time to propagate around the cluster. Just wanted to draw attention to this so you&apos;re clear it was intentional to give things time to work.&lt;/p&gt;</comment>
                            <comment id="13975362" author="markrmiller@gmail.com" created="Mon, 21 Apr 2014 03:21:02 +0000"  >&lt;blockquote&gt;&lt;p&gt;which I can&apos;t really see how it would happen&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Consider that we might have other states in the future as well - and / or, there can be backed up requests. Or what about races with the replica doing it&apos;s own recovery and having a down tossed in there by the leader. It&apos;s tricky to promise anything.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This would make the replica a candidate for receiving requests again, which would just lead to another error&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Is that guaranteed though? What if a connection recovers and it doesn&apos;t lead to another error?&lt;/p&gt;

&lt;p&gt;If it all bears out in testing though, perhaps that&apos;s all fine.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I found a handy class named SocketProxy&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 - it&apos;s great to be able to do this as part of the standard tests in Java.&lt;/p&gt;</comment>
                            <comment id="13975363" author="markrmiller@gmail.com" created="Mon, 21 Apr 2014 03:22:59 +0000"  >&lt;p&gt;I&apos;ll try and do a code review soon by the way.&lt;/p&gt;</comment>
                            <comment id="13975366" author="markrmiller@gmail.com" created="Mon, 21 Apr 2014 03:26:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;Or what about races &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;To expand, I guess my main worry is around a leader telling a replica it&apos;s down right before it publishes it&apos;s active, so the down is basically ignored. I have not thought it thorough fully, but that is the type of thing I&apos;m worried about. We don&apos;t want any races around a replica realizing it&apos;s been marked as down - we have to make sure it receives that message and doesn&apos;t ever think it properly recovered when it&apos;s missing a doc it would have buffered or something.&lt;/p&gt;</comment>
                            <comment id="13975460" author="anshumg" created="Mon, 21 Apr 2014 07:26:33 +0000"  >&lt;p&gt;Just to be sure, I&apos;d want to add that &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5991&quot; title=&quot;SolrCloud: Add API to move leader off a Solr instance&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5991&quot;&gt;&lt;del&gt;SOLR-5991&lt;/del&gt;&lt;/a&gt; might intersect (not overlap) with the work on this one. I&apos;ll put a note in there (as well) about this one so whoever plans to work on that knows about changes happening as a part of this issue.&lt;/p&gt;</comment>
                            <comment id="13975641" author="thelabdude" created="Mon, 21 Apr 2014 15:35:51 +0000"  >&lt;p&gt;Thanks for the feedback! Mainly I just wanted clarification on that issue and if your intuition tells you it may be an issue, then that&apos;s sufficient for me to think harder and come up with something more robust around the leader marking the replica as &quot;down&quot;.&lt;/p&gt;</comment>
                            <comment id="13981661" author="thelabdude" created="Fri, 25 Apr 2014 21:41:42 +0000"  >&lt;p&gt;Here&apos;s an updated patch that builds upon the previous one, same basic approach of leader-initiated recovery but with some added coordination between the leader and partitioned replica using a znode: /collections/&amp;lt;collection&amp;gt;/leader_initiated_recovery/&amp;lt;shard&amp;gt;/&amp;lt;replicaCoreName&amp;gt; (see ZkController.getLeaderInitiatedRecoveryZnodePath).&lt;/p&gt;

&lt;p&gt;The basic idea here is in addition to the leader marking the replica down, a separate znode is used to track the replica&apos;s transition from down -&amp;gt; recovering -&amp;gt; active. So the leader marks the replica as down (which removes it from participating in queries and update requests) and also creates this special znode. When the replica finally gets the &quot;you need to recover&quot; command from the leader, it changes the value of this znode to &quot;recovering&quot;. When recovery succeeds, the replica deletes the znode as it&apos;s no longer needed. If the leader, while trying to send the recovery command (see LeaderInitiatedRecoveryThread), sees the replica as being &quot;active&quot; but the znode wasn&apos;t ack&apos;d, then the leader can set the state to down again. As stated before, I don&apos;t see where the replica would do this, but if it happens, we now have a better way to handle it. Bottom line is with this special znode, the replica cannot stay in the &quot;active&quot; state until it acks the leader&apos;s command to recover by transitioning the znode appropriately.&lt;/p&gt;

&lt;p&gt;The special znode is also useful if the nagging leader fails before the bad replica receives the message. The idea here is that the new leader can query ZK for any of these &quot;leader-initiated-recovery&quot; znodes for its shard and if there are any in the &quot;down&quot; state, then it can start up the nag loop for each bad replica; a znode in the down state means the replica hasn&apos;t received the recovery command yet (see: ElectionContext$ShardLeaderElectionContext.startLeaderInitiatedRecoveryOnReplicas).&lt;/p&gt;

&lt;p&gt;There is a unit test that covers the leader failing over to a new leader and resuming the &quot;nag&quot; loop on the downed replica. There&apos;s one area where I&apos;m not 100% sure if it is correct yet ... in the shouldIBeLeader method in ShardLeaderElectionContext, I check to see if a previous leader marked this core &quot;down&quot; and if so, return false to indicate this node should not be the leader. I think this works OK for RF=3 but I&apos;m worried about RF=2 situations where this check prevents a leader from being elected. The main idea behind this check is that if the leader forces the shard state to &quot;down&quot;, the core.getCoreDescriptor().getCloudDescriptor().getLastPublished() method can still return active so I needed this additional check on the znode. I suppose we could try to update the lastPublished state when it changes but didn&apos;t see how to go about that? (or if that was even a good idea).&lt;/p&gt;

&lt;p&gt;Another area where I&apos;m not 100% sold on is the 10-minute max wait and then timeout loop in the LeaderInitiatedRecoveryThread. 10 mins is arbitrary but it seems like it shouldn&apos;t just run forever. One idea I had was to use JMX to raise some event / notification to allow monitoring tools to alert ops team of this issue. Curious if there&apos;s anything else in SolrCloud related to notifying of issues that need ops attention?&lt;/p&gt;

&lt;p&gt;Lastly, I did give some thought to a self-initiating recovery approach where the &quot;trying to recover&quot; loop runs on the replica itself as that is more immune to leader changes and there&apos;s already a recover retry loop in place via the RecoveryStrategy thread. As I understand it, a self-initiating approach would work something like:&lt;/p&gt;

&lt;p&gt;1) leader receives error when trying to forward update request to replica&lt;br/&gt;
2) leader marks replica as down in ZK&lt;br/&gt;
3) replica receives state change notification (at some point), replica must iterate over all cores hosted on that node looking for cores marked as down&lt;br/&gt;
4) for each &quot;down&quot; core on the node found in step 3, try recovering in a loop&lt;/p&gt;

&lt;p&gt;This is all straight-forward to implement. However, the main problem with this approach is in step 4, when starting recovery, the replica updates its state to &quot;recovering&quot; in ZK immediately. When a replica is &quot;recovering&quot; the leader still tries to forward updates to it (the updates get stashed in the tlog until recovery is complete). This works in normal circumstances because the replica assumes there is no partition between it and the leader so it&apos;s OK to go into the recovering state and continue receiving updates. The problem here though is the network may still be partitioned, so the leader keeps trying to forward docs and receiving errors. From the leader&apos;s perspective, we&apos;re right back at step 1 above.&lt;/p&gt;

&lt;p&gt;Of course, it would be possible to introduce a new state that would prevent the leader from sending updates while the replica sorted itself out, but I&apos;m hesitant to introduce a new state as that has broader repercussions in the code base. I&apos;m mentioning this here in case someone else has some better ideas around this self-initiating approach.&lt;/p&gt;</comment>
                            <comment id="13981762" author="markrmiller@gmail.com" created="Fri, 25 Apr 2014 23:23:55 +0000"  >&lt;p&gt;Awesome! Hope to read that closely this weekend. &lt;/p&gt;</comment>
                            <comment id="13981852" author="otis" created="Sat, 26 Apr 2014 02:26:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;One idea I had was to use JMX to raise some event / notification to allow monitoring tools to alert ops team of this issue. Curious if there&apos;s anything else in SolrCloud related to notifying of issues that need ops attention?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;+1 for bringing this up - not that I&apos;m aware of, but I also didn&apos;t look very closely.  This may deserve a standalone JIRA!  Perhaps relying on ZK for notifications would work?&lt;/p&gt;</comment>
                            <comment id="13986829" author="thelabdude" created="Thu, 1 May 2014 18:17:36 +0000"  >&lt;p&gt;Updated patch to fix compilation error after backing out &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5473&quot; title=&quot;Split clusterstate.json per collection and watch states selectively &quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5473&quot;&gt;&lt;del&gt;SOLR-5473&lt;/del&gt;&lt;/a&gt; and tighten up the unit test, such as reducing the amount of time it waits before healing a partition. Also cleaned up a few minor issues in the LeaderInitiatedRecoveryThread loop.&lt;/p&gt;</comment>
                            <comment id="13990836" author="markrmiller@gmail.com" created="Tue, 6 May 2014 17:11:47 +0000"  >&lt;p&gt;I&apos;d like to dig into this more, but on a glance this morning, this looks like great stuff - thanks Tim!&lt;/p&gt;</comment>
                            <comment id="13991498" author="thelabdude" created="Wed, 7 May 2014 02:54:56 +0000"  >&lt;p&gt;Thanks for the review Mark! I think there are still some weird interactions going on with this code and the waitForLeaderToSeeDownState stuff as I&apos;m seeing some exceptions like the following in a good sized cluster when I knock over replicas during heavy indexing. Leader doesn&apos;t see down state, it sees the &quot;recovering&quot; state.&lt;/p&gt;

&lt;p&gt;2014-05-07 02:34:03,112 &lt;span class=&quot;error&quot;&gt;&amp;#91;Thread-3531&amp;#93;&lt;/span&gt; ERROR solr.cloud.ZkController  - There was a problem making a request to the leader:org.apache.solr.client.solrj.SolrServerException: Timeout occured while waiting response from server at: &lt;a href=&quot;http://host:8985/solr&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://host:8985/solr&lt;/a&gt;&lt;br/&gt;
        at org.apache.solr.client.solrj.impl.HttpSolrServer.executeMethod(HttpSolrServer.java:562)&lt;br/&gt;
        at org.apache.solr.client.solrj.impl.HttpSolrServer.request(HttpSolrServer.java:210)&lt;br/&gt;
        at org.apache.solr.client.solrj.impl.HttpSolrServer.request(HttpSolrServer.java:206)&lt;br/&gt;
        at org.apache.solr.cloud.ZkController.waitForLeaderToSeeDownState(ZkController.java:1528)&lt;br/&gt;
        at org.apache.solr.cloud.ZkController.registerAllCoresAsDown(ZkController.java:372)&lt;br/&gt;
        at org.apache.solr.cloud.ZkController.access$000(ZkController.java:87)&lt;br/&gt;
        at org.apache.solr.cloud.ZkController$1.command(ZkController.java:229)&lt;br/&gt;
        at org.apache.solr.common.cloud.ConnectionManager$1$1.run(ConnectionManager.java:166)&lt;/p&gt;

&lt;p&gt;In short, I there are still a few little issues that didn&apos;t show up in unit testing. So I&apos;m going to flog this area of the code a bit more tomorrow morning!&lt;/p&gt;</comment>
                            <comment id="13992858" author="jira-bot" created="Thu, 8 May 2014 15:48:27 +0000"  >&lt;p&gt;Commit 1593312 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thelabdude&quot; class=&quot;user-hover&quot; rel=&quot;thelabdude&quot;&gt;thelabdude&lt;/a&gt; in branch &apos;dev/trunk&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1593312&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1593312&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5495&quot; title=&quot;Recovery strategy for leader partitioned from replica case.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5495&quot;&gt;&lt;del&gt;SOLR-5495&lt;/del&gt;&lt;/a&gt;: Hardening recovery scenarios after the leader receives an error trying to forward an update request to a replica.&lt;/p&gt;</comment>
                            <comment id="13994552" author="jira-bot" created="Sun, 11 May 2014 13:51:09 +0000"  >&lt;p&gt;Commit 1593791 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thelabdude&quot; class=&quot;user-hover&quot; rel=&quot;thelabdude&quot;&gt;thelabdude&lt;/a&gt; in branch &apos;dev/trunk&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1593791&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1593791&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5495&quot; title=&quot;Recovery strategy for leader partitioned from replica case.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5495&quot;&gt;&lt;del&gt;SOLR-5495&lt;/del&gt;&lt;/a&gt;: Fix HttpPartitionTest to dynamically select the port the Jetty and the SocketProxy binds to, was causing Jenkins failures.&lt;/p&gt;</comment>
                            <comment id="14002710" author="jira-bot" created="Tue, 20 May 2014 02:07:28 +0000"  >&lt;p&gt;Commit 1596103 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thelabdude&quot; class=&quot;user-hover&quot; rel=&quot;thelabdude&quot;&gt;thelabdude&lt;/a&gt; in branch &apos;dev/trunk&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1596103&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1596103&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5495&quot; title=&quot;Recovery strategy for leader partitioned from replica case.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5495&quot;&gt;&lt;del&gt;SOLR-5495&lt;/del&gt;&lt;/a&gt;: Raise the amount of time the test waits for replicas to become active after partitions are healed (to address intermittent Jenkins failures)&lt;/p&gt;</comment>
                            <comment id="14002746" author="jira-bot" created="Tue, 20 May 2014 03:38:44 +0000"  >&lt;p&gt;Commit 1596107 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thelabdude&quot; class=&quot;user-hover&quot; rel=&quot;thelabdude&quot;&gt;thelabdude&lt;/a&gt; in branch &apos;dev/branches/branch_4x&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1596107&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1596107&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5495&quot; title=&quot;Recovery strategy for leader partitioned from replica case.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5495&quot;&gt;&lt;del&gt;SOLR-5495&lt;/del&gt;&lt;/a&gt;: Port over from trunk.&lt;/p&gt;</comment>
                            <comment id="14003626" author="anshumg" created="Tue, 20 May 2014 16:56:28 +0000"  >&lt;p&gt;The CHANGES.txt entry for trunk and 4x are in different sections.&lt;br/&gt;
trunk: 5.0 section&lt;br/&gt;
4x: 4.9 section&lt;/p&gt;</comment>
                            <comment id="14003638" author="jira-bot" created="Tue, 20 May 2014 17:04:21 +0000"  >&lt;p&gt;Commit 1596315 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thelabdude&quot; class=&quot;user-hover&quot; rel=&quot;thelabdude&quot;&gt;thelabdude&lt;/a&gt; in branch &apos;dev/trunk&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1596315&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1596315&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5495&quot; title=&quot;Recovery strategy for leader partitioned from replica case.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5495&quot;&gt;&lt;del&gt;SOLR-5495&lt;/del&gt;&lt;/a&gt;: Re-arrange location of &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5495&quot; title=&quot;Recovery strategy for leader partitioned from replica case.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5495&quot;&gt;&lt;del&gt;SOLR-5495&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5468&quot; title=&quot;Option to notify client when desired replication factor not achieved for an update request.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5468&quot;&gt;&lt;del&gt;SOLR-5468&lt;/del&gt;&lt;/a&gt; in CHANGES.txt&lt;/p&gt;</comment>
                            <comment id="14004999" author="jira-bot" created="Wed, 21 May 2014 18:05:54 +0000"  >&lt;p&gt;Commit 1596636 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thelabdude&quot; class=&quot;user-hover&quot; rel=&quot;thelabdude&quot;&gt;thelabdude&lt;/a&gt; in branch &apos;dev/trunk&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1596636&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1596636&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5495&quot; title=&quot;Recovery strategy for leader partitioned from replica case.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5495&quot;&gt;&lt;del&gt;SOLR-5495&lt;/del&gt;&lt;/a&gt;: Print cluster state in assertion failure messages if a leader cannot be found to determine root cause of HttpPartitionTest failures in Jenkins.&lt;/p&gt;</comment>
                            <comment id="14005009" author="jira-bot" created="Wed, 21 May 2014 18:11:27 +0000"  >&lt;p&gt;Commit 1596637 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thelabdude&quot; class=&quot;user-hover&quot; rel=&quot;thelabdude&quot;&gt;thelabdude&lt;/a&gt; in branch &apos;dev/branches/branch_4x&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1596637&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1596637&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-5495&quot; title=&quot;Recovery strategy for leader partitioned from replica case.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-5495&quot;&gt;&lt;del&gt;SOLR-5495&lt;/del&gt;&lt;/a&gt;: Print cluster state in assertion failure messages if a leader cannot be found to determine root cause of HttpPartitionTest failures in Jenkins&lt;/p&gt;</comment>
                            <comment id="14037941" author="markrmiller@gmail.com" created="Thu, 19 Jun 2014 21:45:06 +0000"  >&lt;p&gt;What&apos;s the current status of this? I see a lot of commits, but still in progress. I actually still hope to review it, but who knows. I have not touched anything in like a month or more now so I expect a huge backlog of crap will stand before me.&lt;/p&gt;</comment>
                            <comment id="14038015" author="thelabdude" created="Thu, 19 Jun 2014 22:28:20 +0000"  >&lt;p&gt;Hi Mark,&lt;/p&gt;

&lt;p&gt;I think it is ready to go, but was hoping for a review from you before closing. It&apos;s been committed to trunk and branch_4x. Tests seem to be passing on Jenkins and I&apos;ve seen it work in some large clusters. If you can give it a quick once-over, I&apos;d appreciate it.&lt;/p&gt;

&lt;p&gt;Tim&lt;/p&gt;</comment>
                            <comment id="14042362" author="thelabdude" created="Tue, 24 Jun 2014 16:58:20 +0000"  >&lt;p&gt;Marking this as resolved as it&apos;s included in the 4.9 release. Would definitely appreciate a review from Mark and others when convenient ... can open a new JIRA for any issues found with this implementation going forward.&lt;/p&gt;</comment>
                            <comment id="14058879" author="markrmiller@gmail.com" created="Fri, 11 Jul 2014 15:11:49 +0000"  >&lt;p&gt;I did a quick review of the code and read your comments above more thoroughly. I did not do a low level review. From that mid level though, this looks like a great change and even if there are any issues, the changes look like good improvements and we should just work through anything that comes up as a result of them.&lt;/p&gt;

&lt;p&gt;As I work on anything in that area, I&apos;ll look at some parts more closely.&lt;/p&gt;</comment>
                            <comment id="14058888" author="thelabdude" created="Fri, 11 Jul 2014 15:18:48 +0000"  >&lt;p&gt;Hi Mark,&lt;/p&gt;

&lt;p&gt;Awesome, thanks for the review ... there&apos;s one area in the CoreAdminHandler waitForState that could use your review.&lt;/p&gt;

&lt;p&gt;              // TODO: This is funky but I&apos;ve seen this in testing where the replica asks the&lt;br/&gt;
              // leader to be in recovery? Need to track down how that happens ... in the meantime,&lt;br/&gt;
              // this is a safeguard &lt;br/&gt;
              boolean leaderDoesNotNeedRecovery = (onlyIfLeader != null &amp;amp;&amp;amp; &lt;br/&gt;
                  onlyIfLeader &amp;amp;&amp;amp; &lt;br/&gt;
                  core.getName().equals(nodeProps.getStr(&quot;core&quot;)) &amp;amp;&amp;amp;&lt;br/&gt;
                  ZkStateReader.RECOVERING.equals(waitForState) &amp;amp;&amp;amp; &lt;br/&gt;
                  ZkStateReader.ACTIVE.equals(localState) &amp;amp;&amp;amp; &lt;br/&gt;
                  ZkStateReader.ACTIVE.equals(state));&lt;/p&gt;


&lt;p&gt;Basically, at some point, I was seeing replicas ask active leaders to recover, which I didn&apos;t think was a valid thing to do. I actually haven&apos;t seen this occur in any of my testing so maybe I was just confused. We can definitely remove that code if it&apos;s not valid, but wanted to make you aware that I had it in there &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12680408">SOLR-5482</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12723133">SOLR-6189</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12642872" name="SOLR-5495.patch" size="76296" author="thelabdude" created="Thu, 1 May 2014 18:17:36 +0000"/>
                            <attachment id="12642025" name="SOLR-5495.patch" size="76662" author="thelabdude" created="Fri, 25 Apr 2014 21:41:42 +0000"/>
                            <attachment id="12640880" name="SOLR-5495.patch" size="47966" author="tim.potter" created="Fri, 18 Apr 2014 20:11:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>360151</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 19 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1q32v:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>360450</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313321" key="com.atlassian.jira.toolkit:message">
                        <customfieldname>Solr Mailing List Info</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>