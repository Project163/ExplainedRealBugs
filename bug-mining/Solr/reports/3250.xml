<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 04:19:29 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SOLR-10130] Serious performance degradation in Solr 6.4.1 due to the new metrics collection</title>
                <link>https://issues.apache.org/jira/browse/SOLR-10130</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;We&apos;ve stumbled on serious performance issues after upgrading to Solr 6.4.1. Looks like the new metrics collection system in MetricsDirectoryFactory is causing a major slowdown. This happens with an index configuration that, as far as I can see, has no metrics specific configuration and uses luceneMatchVersion 5.5.0. In practice a moderate load will completely bog down the server with Solr threads constantly using up all CPU (600% on 6 core machine) capacity with a load that normally  where we normally see an average load of &amp;lt; 50%.&lt;/p&gt;

&lt;p&gt;I took stack traces (I&apos;ll attach them) and noticed that the threads are spending time in com.codahale.metrics.Meter.mark. I tested building Solr 6.4.1 with the metrics collection disabled in MetricsDirectoryFactory getByte and getBytes methods and was unable to reproduce the issue.&lt;/p&gt;

&lt;p&gt;As far as I can see there are several issues:&lt;br/&gt;
1. Collecting metrics on every single byte read is slow.&lt;br/&gt;
2. Having it enabled by default is not a good idea.&lt;br/&gt;
3. The comment &quot;enable coarse-grained metrics by default&quot; at &lt;a href=&quot;https://github.com/apache/lucene-solr/blob/branch_6x/solr/core/src/java/org/apache/solr/update/SolrIndexConfig.java#L104&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/lucene-solr/blob/branch_6x/solr/core/src/java/org/apache/solr/update/SolrIndexConfig.java#L104&lt;/a&gt; implies that only coarse-grained metrics should be enabled by default, and this contradicts with collecting metrics on every single byte read.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Centos 7, OpenJDK 1.8.0 update 111&lt;/p&gt;</environment>
        <key id="13042552">SOLR-10130</key>
            <summary>Serious performance degradation in Solr 6.4.1 due to the new metrics collection</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="ab">Andrzej Bialecki</assignee>
                                    <reporter username="emaijala">Ere Maijala</reporter>
                        <labels>
                            <label>perfomance</label>
                    </labels>
                <created>Mon, 13 Feb 2017 11:58:02 +0000</created>
                <updated>Sat, 8 Jun 2019 15:30:04 +0000</updated>
                            <resolved>Wed, 15 Feb 2017 13:58:39 +0000</resolved>
                                    <version>6.4</version>
                    <version>6.4.1</version>
                                    <fixVersion>6.4.2</fixVersion>
                    <fixVersion>7.0</fixVersion>
                                    <component>metrics</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>31</watches>
                                                                                                                <comments>
                            <comment id="15863948" author="wunder" created="Mon, 13 Feb 2017 16:35:04 +0000"  >&lt;p&gt;I&#8217;m seeing similar problems here. With 6.4.0, we were handling 6000 requests/minute. With 6.4.1 it is 1000 rpm with median response times around 2.5 seconds. I also switched to the G1 collector. I&#8217;m going to back that out and retest today to see if the performance comes back.&lt;/p&gt;

&lt;p&gt;Does disabling metrics fix it or we we need to go back to 6.4.0?&lt;/p&gt;

&lt;p&gt;wunder&lt;/p&gt;</comment>
                            <comment id="15864585" author="ab" created="Mon, 13 Feb 2017 22:25:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;Does disabling metrics fix it or we we need to go back to 6.4.0?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Unfortunately no, these metrics are always turned on both in 6.4.0 and in 6.4.1. I&apos;ll upload a patch that disables this by default and allows turning it on via a solrconfig.xml knob.&lt;/p&gt;</comment>
                            <comment id="15864751" author="ab" created="Tue, 14 Feb 2017 00:27:31 +0000"  >&lt;p&gt;This patch turns off Directory and Index metrics by default, and adds config knobs to selectively turn them on in &lt;tt&gt;solrconfig.xml&lt;/tt&gt; (default are all false now, so this section is optional):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&amp;lt;config&amp;gt;
...
  &amp;lt;indexConfig&amp;gt;
    &amp;lt;mergeFactor&amp;gt;...
    ...
    &amp;lt;metrics&amp;gt;
      &amp;lt;bool name=&lt;span class=&quot;code-quote&quot;&gt;&quot;directory&quot;&lt;/span&gt;&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;lt;/bool&amp;gt;
      &amp;lt;bool name=&lt;span class=&quot;code-quote&quot;&gt;&quot;directoryDetails&quot;&lt;/span&gt;&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;lt;/bool&amp;gt;
      &amp;lt;bool name=&lt;span class=&quot;code-quote&quot;&gt;&quot;merge&quot;&lt;/span&gt;&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;lt;/bool&amp;gt;
      &amp;lt;bool name=&lt;span class=&quot;code-quote&quot;&gt;&quot;mergeDetails&quot;&lt;/span&gt;&amp;gt;&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;lt;/bool&amp;gt;
    &amp;lt;/metrics&amp;gt;  
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15865470" author="ichattopadhyaya" created="Tue, 14 Feb 2017 09:38:51 +0000"  >&lt;p&gt;I ran some benchmarks, with and without this patch.&lt;/p&gt;

&lt;p&gt;Benchmarking suite: &lt;a href=&quot;https://github.com/chatman/solr-upgrade-tests/blob/master/BENCHMARKS.md&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/chatman/solr-upgrade-tests/blob/master/BENCHMARKS.md&lt;/a&gt;&lt;br/&gt;
Environment: packet.net, Type 0 server (&lt;a href=&quot;https://www.packet.net/bare-metal/servers/type-0/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.packet.net/bare-metal/servers/type-0/&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;6.4.1 Without patch
------------------------
java -cp target/org.apache.solr.tests.upgradetests-0.0.1-SNAPSHOT-jar-with-dependencies.jar:. org.apache.solr.tests.upgradetests.SimpleBenchmarks -v 72f75b2503fa0aa4f0aff76d439874feb923bb0e -Nodes 1 -Shards 1 -Replicas 1 -numDocs 100000 -threads 6 -benchmarkType generalIndexing

Indexing times: 188,190

6.4.1 With patch
--------------------
java -cp target/org.apache.solr.tests.upgradetests-0.0.1-SNAPSHOT-jar-with-dependencies.jar:. org.apache.solr.tests.upgradetests.SimpleBenchmarks -v 72f75b2503fa0aa4f0aff76d439874feb923bb0e -patchUrl https:&lt;span class=&quot;code-comment&quot;&gt;//issues.apache.org/jira/secure/attachment/12852444/SOLR-10130.patch -Nodes 1 -Shards 1 -Replicas 1 -numDocs 100000 -threads 6 -benchmarkType generalIndexing
&lt;/span&gt;
Indexing times: 171,165
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15865492" author="ab" created="Tue, 14 Feb 2017 09:54:10 +0000"  >&lt;p&gt;I would&apos;ve expected a much larger difference with this patch, if this indeed was the cause of the slowdown - the patch completely turns off metrics collection at directory and index level.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;With 6.4.0, we were handling 6000 requests/minute. With 6.4.1 it is 1000 rpm&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wunder&quot; class=&quot;user-hover&quot; rel=&quot;wunder&quot;&gt;wunder&lt;/a&gt; This is odd, too - the same metrics code is present in both 6.4.1 and 6.4.0, with the same defaults, so I would expect that both versions should show similar performance. Could you please collect some stacktraces (or sample / profile) to verify that you see the same hotspots as &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=emaijala&quot; class=&quot;user-hover&quot; rel=&quot;emaijala&quot;&gt;emaijala&lt;/a&gt; ?&lt;/p&gt;</comment>
                            <comment id="15865510" author="ichattopadhyaya" created="Tue, 14 Feb 2017 10:05:09 +0000"  >&lt;p&gt;6.4.0 shows very similar numbers as compared to 6.4.1&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;6.4.0 Without patch
--------------------
java -cp target/org.apache.solr.tests.upgradetests-0.0.1-SNAPSHOT-jar-with-dependencies.jar:. org.apache.solr.tests.upgradetests.SimpleBenchmarks -v 680153de29c5b01d4a8afad88d4a7b84ab01e145 -Nodes 1 -Shards 1 -Replicas 1 -numDocs 100000 -threads 6 -benchmarkType generalIndexing

Indexing times: 191,184
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15865584" author="ichattopadhyaya" created="Tue, 14 Feb 2017 10:57:53 +0000"  >&lt;p&gt;6.3.0 was faster (same as 6.4.1 with patch).&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java -cp target/org.apache.solr.tests.upgradetests-0.0.1-SNAPSHOT-jar-with-dependencies.jar:. org.apache.solr.tests.upgradetests.SimpleBenchmarks -v 6fa26fe8553b7b65dee96da741f2c1adf4cb6216 -patchUrl http:&lt;span class=&quot;code-comment&quot;&gt;//147.75.108.131/LUCENE-7651.patch -Nodes 1 -Shards 1 -Replicas 1 -numDocs 100000 -threads 6 -benchmarkType generalIndexing
&lt;/span&gt;Indexing times: 168,167
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15865912" author="ab" created="Tue, 14 Feb 2017 15:08:37 +0000"  >&lt;p&gt;I haven&apos;t been able to reproduce such drastic slowdown using simple benchmarks - example results from indexing using &lt;tt&gt;post&lt;/tt&gt; tool, fairly representative from several runs on each branch:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;* branch_6_3
real    4m14.804s
user    0m0.883s
sys     0m2.279s

* branch_6_4
real    5m0.987s
user    0m0.910s
sys     0m2.276s

* jira/solr-10130
real    4m38.097s
user    0m0.881s
sys     0m2.287s
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Profiler indeed shows that one of the hotspots on branch_6_4 is the &lt;tt&gt;Meter.mark&lt;/tt&gt; code that is called in &lt;tt&gt;org.apache.solr.core.MetricsDirectoryFactory$MetricsInput.readByte&lt;/tt&gt;. In my test the profiler showed that this consumes ~ 3% CPU, which is indeed something that we should avoid and turn off by default.&lt;/p&gt;

&lt;p&gt;However, this still doesn&apos;t explain the order of magnitude slowdown reported above.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=emaijala&quot; class=&quot;user-hover&quot; rel=&quot;emaijala&quot;&gt;emaijala&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wunder&quot; class=&quot;user-hover&quot; rel=&quot;wunder&quot;&gt;wunder&lt;/a&gt; - please apply the above patch in your environment and see what is the impact. It makes sense to make this change anyway, so I&apos;m going to apply this or similar version to all affected branches, but maybe there&apos;s more we can do here.&lt;/p&gt;</comment>
                            <comment id="15865945" author="monti" created="Tue, 14 Feb 2017 15:20:37 +0000"  >&lt;p&gt;We&apos;ve also seen performance degradation with SolrCloud on 6.4.1, as I&apos;ve posted on solr-user ( &lt;a href=&quot;http://lucene.472066.n3.nabble.com/Performance-degradation-after-upgrading-from-6-2-1-to-6-4-1-td4320226.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://lucene.472066.n3.nabble.com/Performance-degradation-after-upgrading-from-6-2-1-to-6-4-1-td4320226.html&lt;/a&gt; ):&lt;/p&gt;

&lt;p&gt;Here are a couple of graphs.  As you can see, 6.4.1 was introduced 2/10 &lt;br/&gt;
12:00: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.dropbox.com/s/qrc0wodain50azz/solr1.png?dl=0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.dropbox.com/s/qrc0wodain50azz/solr1.png?dl=0&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://www.dropbox.com/s/sdk30imm8jlomz2/solr2.png?dl=0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.dropbox.com/s/sdk30imm8jlomz2/solr2.png?dl=0&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://www.dropbox.com/s/rgd8bq86i3c5mga/solr2b.png?dl=0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.dropbox.com/s/rgd8bq86i3c5mga/solr2b.png?dl=0&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;These are two very different usage scenarios: &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Solr1 has constant updates and very volatile data (30 minutes TTL, 20&lt;br/&gt;
shards with no replicas, across 8 servers).  Requests in the 99 percentile &lt;br/&gt;
went from ~400ms to 1000-1500ms. (Hystrix cutoff at 1.5s) &lt;/li&gt;
&lt;/ul&gt;


&lt;ul&gt;
	&lt;li&gt;Solr2 is a more traditional instance with long-lived data (updated once a&lt;br/&gt;
day, 24 shards with 2 replicas, across 8 servers).  Requests in the 99 &lt;br/&gt;
percentile went from ~400ms to at least 1s. (Hystrix cutoff at 1s) &lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15865980" author="wunder" created="Tue, 14 Feb 2017 15:42:35 +0000"  >&lt;p&gt;Sorry, the 6000 rpm was with 6.2.1, not 6.4.0.&lt;/p&gt;

&lt;p&gt;I&apos;ve backrev&apos;ed the cluster to 6.3.0 and I&apos;ll be running load benchmarks today.&lt;/p&gt;</comment>
                            <comment id="15866067" author="yseeley@gmail.com" created="Tue, 14 Feb 2017 16:27:33 +0000"  >&lt;p&gt;Just a matter of how many little IOs are involved in your request.&lt;br/&gt;
I was easily able to reproduce a 5x slowdown with a prefix query that matches many terms.&lt;/p&gt;</comment>
                            <comment id="15866077" author="ichattopadhyaya" created="Tue, 14 Feb 2017 16:33:50 +0000"  >&lt;p&gt;Thanks Yonik. I&apos;m working on query performance benchmarks for this.&lt;/p&gt;</comment>
                            <comment id="15866092" author="wunder" created="Tue, 14 Feb 2017 16:43:16 +0000"  >&lt;p&gt;I have a JMeter-based load script I can share. It replays access logs. I reload the collection to clear caches, run warming queries, then run queries at a controlled rate. After, it calculates percentiles.&lt;/p&gt;

&lt;p&gt;This was a test of 6.4.1. Really slow. The errors are usually log lines with queries so long that they are truncated and end up with bad syntax. There is one column per request handler, so these results are for /auto, /mobile, /select, and /srp.&lt;/p&gt;

&lt;p&gt;Mon Feb 13 12:01:29 PST 2017 ; INFO testing solr-cloud.test.cheggnet.com:8983&lt;br/&gt;
Mon Feb 13 12:01:29 PST 2017 ; INFO testing with 2000 requests/min&lt;br/&gt;
Mon Feb 13 12:01:29 PST 2017 ; INFO testing with 240000 requests&lt;br/&gt;
Mon Feb 13 12:01:29 PST 2017 : splitting log into cache warming (first 2000 lines) and benchmark for /home/wunder/2016-12-12-peak-questions-traffic-clean.log&lt;br/&gt;
Mon Feb 13 12:01:36 PST 2017 : starting cache warming to solr-cloud.test.cheggnet.com:8983&lt;br/&gt;
Mon Feb 13 12:24:29 PST 2017 : starting benchmarking to solr-cloud.test.cheggnet.com:8983&lt;br/&gt;
Mon Feb 13 12:24:29 PST 2017 : benchmark should run for 120 minutes&lt;br/&gt;
Mon Feb 13 12:24:29 PST 2017 : to get a count of requests sent so far, use &quot;wc -l out-32688.jtl&quot;&lt;br/&gt;
Mon Feb 13 14:55:01 PST 2017 : WARNING 207 error responses from solr-cloud.test.cheggnet.com&lt;br/&gt;
Mon Feb 13 14:55:01 PST 2017 : INFO Removing 207 error responses from JMeter output file before analysis&lt;br/&gt;
Mon Feb 13 14:55:01 PST 2017 : analyzing results&lt;br/&gt;
/home/wunder/search-test/load-test&lt;br/&gt;
Mon Feb 13 14:55:04 PST 2017 : 25th percentiles are 3151.0,3389.0,9329.0,5647.0&lt;br/&gt;
Mon Feb 13 14:55:04 PST 2017 : medians are 6101.0,10579.0,18692.0,8780.0&lt;br/&gt;
Mon Feb 13 14:55:04 PST 2017 : 75th percentiles are 6871.0,12499.0,25000.0,12580.0&lt;br/&gt;
Mon Feb 13 14:55:04 PST 2017 : 90th percentiles are 7593.0,13481.0,27623.0,14068.0&lt;br/&gt;
Mon Feb 13 14:55:04 PST 2017 : 95th percentiles are 8079.0,14039.0,28566.0,16606.0&lt;br/&gt;
Mon Feb 13 14:55:04 PST 2017 : full results are in test.csv&lt;/p&gt;</comment>
                            <comment id="15866806" author="ichattopadhyaya" created="Tue, 14 Feb 2017 22:10:43 +0000"  >&lt;p&gt;I could reproduce a 1.6x slowdown for prefix queries.&lt;/p&gt;

&lt;p&gt;Benchmarking suite: &lt;a href=&quot;https://github.com/chatman/solr-upgrade-tests/blob/master/BENCHMARKS.md&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/chatman/solr-upgrade-tests/blob/master/BENCHMARKS.md&lt;/a&gt;&lt;br/&gt;
Environment: packet.net, Type 0 server (&lt;a href=&quot;https://www.packet.net/bare-metal/servers/type-0/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.packet.net/bare-metal/servers/type-0/&lt;/a&gt;)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Prefix query times &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 6.4.1
----------------------------
java -cp target/org.apache.solr.tests.upgradetests-0.0.1-SNAPSHOT-jar-with-dependencies.jar:. org.apache.solr.tests.upgradetests.SimpleBenchmarks -v 72f75b2503fa0aa4f0aff76d439874feb923bb0e -Nodes 1 -Shards 1 -Replicas 1 -numDocs 10000 -threads 4 -benchmarkType generalQuerying

Got results &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; prefix queries: 10000
Max time (prefix queries): 2156ms
Total time (prefix queries): 1324856ms

Prefix query times &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 6.3.0
----------------------------
java -cp target/org.apache.solr.tests.upgradetests-0.0.1-SNAPSHOT-jar-with-dependencies.jar:. org.apache.solr.tests.upgradetests.SimpleBenchmarks -v 6fa26fe8553b7b65dee96da741f2c1adf4cb6216 -patchUrl http:&lt;span class=&quot;code-comment&quot;&gt;//147.75.108.131/LUCENE-7651.patch -Nodes 1 -Shards 1 -Replicas 1 -numDocs 10000 -threads 4 -benchmarkType generalQuerying
&lt;/span&gt;
Got results &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; prefix queries: 10000
Max time (prefix queries): 1358ms
Total time (prefix queries): 839534ms
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Notes:&lt;br/&gt;
1. The -threads parameter here is for no. of indexing threads, and number of querying threads is 4 times that, i.e. 16 in this case.&lt;br/&gt;
2. Total time is the sum of all times, as reported in the response header&apos;s &quot;QTime&quot;. Max time is the QTime for the worst performing query.&lt;/p&gt;</comment>
                            <comment id="15866888" author="ichattopadhyaya" created="Tue, 14 Feb 2017 23:01:34 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Prefix query times &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 6.4.1 with SOLR-10130 patch
-----------------------------------------------------------------
java -cp target/org.apache.solr.tests.upgradetests-0.0.1-SNAPSHOT-jar-with-dependencies.jar:. org.apache.solr.tests.upgradetests.SimpleBenchmarks -v 72f75b2503fa0aa4f0aff76d439874feb923bb0e -patchUrl https:&lt;span class=&quot;code-comment&quot;&gt;//issues.apache.org/jira/secure/attachment/12852444/SOLR-10130.patch -Nodes 1 -Shards 1 -Replicas 1 -numDocs 10000 -threads 4 -benchmarkType generalQuerying
&lt;/span&gt;
Got results &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; prefix queries: 10000
Max time (prefix queries): 1716
Total time (prefix queries): 852266
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15867402" author="emaijala" created="Wed, 15 Feb 2017 07:48:40 +0000"  >&lt;p&gt;I don&apos;t have proper benchmarks at hand, but I can support others&apos; findings about the serious query performance degradation. I suppose it&apos;s easily overlooked when testing with light concurrency, but with enough concurrent queries being served it gets CPU-heavy. We use queries with a lot of filters so that may play a role too. I&apos;ll see if I came come up with a reproducible-enough test results from our actual queries.&lt;/p&gt;</comment>
                            <comment id="15867647" author="tech@bidorbuy.co.za" created="Wed, 15 Feb 2017 11:07:02 +0000"  >&lt;p&gt;Same issue here. Worked perfectly fine on Solr 6.2.0 and CPU is trashing on Solr 6.4.1. I didn&apos;t see this bug report and logged a duplicate - &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10140&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SOLR-10140&lt;/a&gt; showing slowdown in comparison.&lt;/p&gt;

&lt;p&gt;In our case, Solr 6.4.1 works perfectly fine under production load for about 1 hour and then CPU starts trashing. From the New Relic reports you will see  that Solr 6.4.1 is flaring CPU substantially more than prior versions.&lt;/p&gt;</comment>
                            <comment id="15867701" author="ab" created="Wed, 15 Feb 2017 11:59:03 +0000"  >&lt;p&gt;Patch with some cleanup and CHANGES.txt entry. I&apos;ll commit this shortly.&lt;/p&gt;</comment>
                            <comment id="15867744" author="jira-bot" created="Wed, 15 Feb 2017 12:33:43 +0000"  >&lt;p&gt;Commit a9eb001f44ca846b64d4ed6e46af316fe12ce3d0 in lucene-solr&apos;s branch refs/heads/branch_6_4 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ab&quot; class=&quot;user-hover&quot; rel=&quot;ab&quot;&gt;ab&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=a9eb001&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=a9eb001&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10130&quot; title=&quot;Serious performance degradation in Solr 6.4.1 due to the new metrics collection&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10130&quot;&gt;&lt;del&gt;SOLR-10130&lt;/del&gt;&lt;/a&gt; Serious performance degradation in Solr 6.4.1 due to the&lt;br/&gt;
new metrics collection.&lt;/p&gt;</comment>
                            <comment id="15867817" author="jira-bot" created="Wed, 15 Feb 2017 13:19:25 +0000"  >&lt;p&gt;Commit 835c96ba97a01c61978535c0e8fe34708755dc28 in lucene-solr&apos;s branch refs/heads/branch_6x from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ab&quot; class=&quot;user-hover&quot; rel=&quot;ab&quot;&gt;ab&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=835c96b&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=835c96b&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10130&quot; title=&quot;Serious performance degradation in Solr 6.4.1 due to the new metrics collection&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10130&quot;&gt;&lt;del&gt;SOLR-10130&lt;/del&gt;&lt;/a&gt; Serious performance degradation in Solr 6.4.1 due to the&lt;br/&gt;
new metrics collection.&lt;/p&gt;</comment>
                            <comment id="15867867" author="jira-bot" created="Wed, 15 Feb 2017 13:56:42 +0000"  >&lt;p&gt;Commit b6f49dc1fb4ad6ef890ae1d09f6d4c0584bb6f64 in lucene-solr&apos;s branch refs/heads/master from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ab&quot; class=&quot;user-hover&quot; rel=&quot;ab&quot;&gt;ab&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b6f49dc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b6f49dc&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10130&quot; title=&quot;Serious performance degradation in Solr 6.4.1 due to the new metrics collection&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10130&quot;&gt;&lt;del&gt;SOLR-10130&lt;/del&gt;&lt;/a&gt; Serious performance degradation in Solr 6.4.1 due to the&lt;br/&gt;
new metrics collection.&lt;/p&gt;</comment>
                            <comment id="15867870" author="ab" created="Wed, 15 Feb 2017 13:58:39 +0000"  >&lt;p&gt;Fixed in branch_6_4, branch_6x and master.&lt;/p&gt;</comment>
                            <comment id="15867900" author="tech@bidorbuy.co.za" created="Wed, 15 Feb 2017 14:15:46 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ab&quot; class=&quot;user-hover&quot; rel=&quot;ab&quot;&gt;ab&lt;/a&gt; would I have to do a Solr build myself to get the patch in or should I rather wait for 6.4.2 (if so, any indication of when it would be released)?&lt;/p&gt;</comment>
                            <comment id="15867912" author="ab" created="Wed, 15 Feb 2017 14:22:06 +0000"  >&lt;p&gt;You can of course build Solr yourself from &lt;tt&gt;branch_6_4&lt;/tt&gt; that contains the patch. I don&apos;t know of any specific timeline for 6.4.2, but this is a pretty serious issue so I think we should do it soon - let&apos;s discuss this on mailing lists.&lt;/p&gt;</comment>
                            <comment id="15868222" author="monti" created="Wed, 15 Feb 2017 17:38:54 +0000"  >&lt;p&gt;We just deployed the latest from branch_6_4 (a9eb001f44) and our systems are performing normally again.  Thanks for your work on this &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ab&quot; class=&quot;user-hover&quot; rel=&quot;ab&quot;&gt;ab&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="15868973" author="wunder" created="Thu, 16 Feb 2017 01:55:56 +0000"  >&lt;p&gt;I don&apos;t have hard numbers, but core recovery after a restart with 6.4.0 was taking a really long time. Maybe 30 minutes. Back-reved to 6.3.0, it is maybe five minutes.&lt;/p&gt;</comment>
                            <comment id="15869625" author="alessandro.benedetti" created="Thu, 16 Feb 2017 09:41:15 +0000"  >&lt;p&gt;What was causing the Query time slowdown for prefix queries ?&lt;br/&gt;
Has this been discovered ?&lt;/p&gt;</comment>
                            <comment id="15869702" author="ab" created="Thu, 16 Feb 2017 10:34:17 +0000"  >&lt;p&gt;Prefix query that matches many terms causes many seek &amp;amp; read ops, which meant that the instrumentation in &lt;tt&gt;org.apache.solr.core.MetricsDirectoryFactory$MetricsInput.readByte&lt;/tt&gt; was called for every small read. This normally wouldn&apos;t matter for regular Directory implementations because they use caching extensively, precisely to avoid the overhead of reading single bytes, but &lt;tt&gt;MetricsDirectory&lt;/tt&gt; being a wrapper on top of any Directory implementation couldn&apos;t benefit from this caching and still maintain the read/write counters. The overhead of individual &lt;tt&gt;Meter.mark&lt;/tt&gt; call is in the order of microseconds, but invoking it a few million times resulted in significant slowdown. &lt;/p&gt;</comment>
                            <comment id="15869753" author="alessandro.benedetti" created="Thu, 16 Feb 2017 11:17:17 +0000"  >&lt;p&gt;Thanks, for the clear explanation!&lt;br/&gt;
Good spot !&lt;/p&gt;</comment>
                            <comment id="15870165" author="wunder" created="Thu, 16 Feb 2017 15:54:36 +0000"  >&lt;p&gt;The slowdown is impressive under heavy query load. Here are two load benchmarks with a 16 node cluster, c4.8xlarge instances (36 CPUs, 60 GB RAM), 15.7 million docs, 4 shards, replication factor 4 using production query logs. These are very long text queries, up to 40 words. Benchmark runs for two or three hours, depending on my patience. Java 8u121, G1 collector.&lt;/p&gt;

&lt;p&gt;6.4.0 with 1000 requests/minute is running out of CPU. Median and 95th percentile response times for an ngram/prefix match are 7.5 and 9.8 seconds. For a word match, they are 11 and 25.4 seconds.&lt;/p&gt;

&lt;p&gt;6.3.0 with 6000 rpm, the times are 0.4 and 2.7 seconds, and 0.7 and 4.3 seconds, respectively. CPU usage is under 50%.&lt;/p&gt;

&lt;p&gt;Short version, 6.4 is 10X slower than 6.3 handling 1/6 the load. &lt;/p&gt;</comment>
                            <comment id="15870198" author="wunder" created="Thu, 16 Feb 2017 16:14:08 +0000"  >&lt;p&gt;Also, recovery is much, much slower in 6.4. Each core is about 8 GB. After a server process restart, the core is recovering for a few minutes in 6.3, but for about a half hour in 6.4.&lt;/p&gt;</comment>
                            <comment id="15870379" author="erickerickson" created="Thu, 16 Feb 2017 17:58:04 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wunder&quot; class=&quot;user-hover&quot; rel=&quot;wunder&quot;&gt;wunder&lt;/a&gt;: If it&apos;s easy, could you try a manual fetchindex? Which you can even do in cloud mode. See: &lt;a href=&quot;https://cwiki.apache.org/confluence/display/solr/Index+Replication#IndexReplication-HTTPAPICommandsfortheReplicationHandler&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cwiki.apache.org/confluence/display/solr/Index+Replication#IndexReplication-HTTPAPICommandsfortheReplicationHandler&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Or maybe just see if the logs show that this very long recovery happens when you have a full recovery, i.e. you&apos;re copying the full index down from the leader/master...&lt;/p&gt;


</comment>
                            <comment id="15870429" author="wunder" created="Thu, 16 Feb 2017 18:12:27 +0000"  >&lt;p&gt;I&apos;m looking at how long the core is marked &quot;recovering&quot; in the cloud view of the admin UI.&lt;/p&gt;

&lt;p&gt;There shouldn&apos;t be any recovery. The server process is restarted hours after the most recent update. I think this is how long it takes to get the core loaded and ready for search. Startup time, really.&lt;/p&gt;</comment>
                            <comment id="15870444" author="erickerickson" created="Thu, 16 Feb 2017 18:20:26 +0000"  >&lt;p&gt;Ah, ok. I take it this is a replica with a bunch of data in it? Although this doesn&apos;t make sense, there shouldn&apos;t be that much work do fire up a core absent tlog replay and the like but it sounds like you&apos;re far beyond that so I&apos;m missing something.&lt;/p&gt;

&lt;p&gt;Is there any way you could pull/build a new version of Solr 6.4 (or apply the patch on this JIRA locally) and try? I&apos;d hate to have the 6.4.2 release get out (coming soon, due to this) and not have fixed a different issue.&lt;/p&gt;</comment>
                            <comment id="15870734" author="ab" created="Thu, 16 Feb 2017 21:38:28 +0000"  >&lt;blockquote&gt;&lt;p&gt;Is there any way you could pull/build a new version of Solr 6.4 (or apply the patch on this JIRA locally) and try? I&apos;d hate to have the 6.4.2 release get out (coming soon, due to this) and not have fixed a different issue.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I concur. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=wunder&quot; class=&quot;user-hover&quot; rel=&quot;wunder&quot;&gt;wunder&lt;/a&gt; - we are not sure if your situation is caused by the issue fixed here or by some other bug, it would be very helpful if you could try a build that contains this patch to see if it solves the problem in your environment.&lt;/p&gt;</comment>
                            <comment id="15870751" author="wunder" created="Thu, 16 Feb 2017 21:49:37 +0000"  >&lt;p&gt;This might be part of it:&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;wunder@new-solr-c01.test3&amp;#93;&lt;/span&gt;# ls -lh /solr/data/questions_shard2_replica1/data/tlog/&lt;br/&gt;
total 4.7G&lt;br/&gt;
&lt;del&gt;rw-r&lt;/del&gt;&lt;del&gt;r&lt;/del&gt;- 1 bin bin 4.7G Feb 13 11:04 tlog.0000000000000000000&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;wunder@new-solr-c01.test3&amp;#93;&lt;/span&gt;# du -sh /solr/data/questions_shard2_replica1/data/*&lt;br/&gt;
8.4G	/solr/data/questions_shard2_replica1/data/index&lt;br/&gt;
4.0K	/solr/data/questions_shard2_replica1/data/snapshot_metadata&lt;br/&gt;
4.7G	/solr/data/questions_shard2_replica1/data/tlog&lt;/p&gt;


&lt;p&gt;Last Modified: 3 days ago&lt;br/&gt;
Num Docs: 3683075&lt;br/&gt;
Max Doc: 3683075&lt;br/&gt;
Heap Memory Usage: -1&lt;br/&gt;
Deleted Docs: 0&lt;br/&gt;
Version: 2737&lt;br/&gt;
Segment Count: 26&lt;br/&gt;
Optimized: yes&lt;br/&gt;
Current: yes&lt;/p&gt;
</comment>
                            <comment id="15870760" author="erickerickson" created="Thu, 16 Feb 2017 21:58:10 +0000"  >&lt;p&gt;How on earth did you get a 4.7G tlog? It looks like you somehow didn&apos;t commit, shut the node down are replaying a ton of docs (well, how much does 4.7G weigh anyway?) from the tlog.&lt;/p&gt;

&lt;p&gt;So, simple test:&lt;br/&gt;
1&amp;gt; wait for the node to come up.&lt;br/&gt;
2&amp;gt; insure you&apos;ve issued a hard commit&lt;br/&gt;
3&amp;gt; try restarting.&lt;/p&gt;

&lt;p&gt;My claim is that the restart will be reasonable and the slowness you&apos;re seeing is a result of somehow shutting down without doing a commit. Of course depending on your autocommit interval you may not need to do the hard commit before restarting...&lt;/p&gt;

&lt;p&gt;Best,&lt;br/&gt;
Erick&lt;/p&gt;</comment>
                            <comment id="15871772" author="emaijala" created="Fri, 17 Feb 2017 12:23:01 +0000"  >&lt;p&gt;I still don&apos;t have proper benchmarks, but I&apos;ve tested enough to say with fair confidence that this is fixed for us.&lt;/p&gt;</comment>
                            <comment id="15881006" author="ichattopadhyaya" created="Thu, 23 Feb 2017 18:47:46 +0000"  >&lt;p&gt;Adding a link to &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10182&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SOLR-10182&lt;/a&gt; for backing out the changes that caused these perf degradations.&lt;/p&gt;</comment>
                            <comment id="15926179" author="elyograg" created="Wed, 15 Mar 2017 13:31:50 +0000"  >&lt;p&gt;The reassignment was accidental, fixed.  I hate the fact that Jira responds with real actions to just typing on the keyboard.  I sometimes forget which window has the focus, assume that an SSH session I can clearly see is active, and find that I&apos;m giving unknown commands to something that accepts keypresses as commands, like Thunderbird or Jira.&lt;/p&gt;</comment>
                            <comment id="15986859" author="elyograg" created="Thu, 27 Apr 2017 15:53:08 +0000"  >&lt;p&gt;Have a question related to this issue.  Somebody on the IRC channel running 6.4.2 is seeing continued performance degradation compared to 4.x.  They were running an earlier 6.4.x release, until they were advised about this issue.&lt;/p&gt;

&lt;p&gt;Looking at the utilization for threads, the top threads on 6.4.2 are all named starting with qtp, which I believe means they are Jetty threads.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/msporleder-work/7313ebedbdab2e178ca0aa2e889d006b&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gist.github.com/msporleder-work/7313ebedbdab2e178ca0aa2e889d006b&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If I&apos;m not mistaken, we enabled container-level metrics with the changes that went into 6.4.0.  If that&apos;s true, do we perhaps have those metrics dialed up to 11?&lt;/p&gt;</comment>
                            <comment id="15986913" author="ab" created="Thu, 27 Apr 2017 16:12:09 +0000"  >&lt;p&gt;I don&apos;t think this should make much of a difference - &lt;tt&gt;InstrumentedQueuedThreadPool&lt;/tt&gt; only exposes gauges, which basically don&apos;t add CPU overhead unless accessed, and &lt;tt&gt;InstrumentedHandler&lt;/tt&gt; collects only a few specific metrics, so the overhead should also be minimal, in the order of microseconds / request.&lt;/p&gt;

&lt;p&gt;A drill-down into these threads to find their hot-spots would be useful.&lt;/p&gt;</comment>
                            <comment id="15987079" author="msporleder" created="Thu, 27 Apr 2017 17:22:46 +0000"  >&lt;p&gt;Not sure I have the tooling right now for a full drill down, but here are some examples of a thread dump:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-quote&quot;&gt;&quot;qtp968514068-37953&quot;&lt;/span&gt; - &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; t@37953
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: RUNNABLE
    at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
    at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)
    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
    - locked &amp;lt;2e101d2c&amp;gt; (a sun.nio.ch.Util$2)
    - locked &amp;lt;59c1f901&amp;gt; (a java.util.Collections$UnmodifiableSet)
    - locked &amp;lt;54c6a926&amp;gt; (a sun.nio.ch.EPollSelectorImpl)
    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:243)
    at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:191)
    at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:249)
    at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
    at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
    at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)

   Locked ownable synchronizers:
    - None

&lt;span class=&quot;code-quote&quot;&gt;&quot;qtp968514068-37952&quot;&lt;/span&gt; - &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; t@37952
   java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.State: TIMED_WAITING
    at sun.misc.Unsafe.park(Native Method)
    - parking to wait &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; &amp;lt;2d78e562&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
    at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:392)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.idleJobPoll(QueuedThreadPool.java:563)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.access$800(QueuedThreadPool.java:48)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:626)
    at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Most are in that TIMED_WAITING and most CPU time is spend on org.eclipse.jetty.util.BlockingArrayQueue.poll according to visualvm&lt;/p&gt;</comment>
                            <comment id="15987160" author="ab" created="Thu, 27 Apr 2017 17:57:39 +0000"  >&lt;p&gt;Did you change JDK version between these two installs? I found an old issue (but still open!) that may indicate it&apos;s a JDK bug: &lt;a href=&quot;https://github.com/netty/netty/issues/327&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/netty/netty/issues/327&lt;/a&gt; . There are other similar reports for Jetty, but for older versions ... can&apos;t say whether that&apos;s relevant here.&lt;/p&gt;

&lt;p&gt;However, what these stacktraces do NOT show is anything related to metrics.&lt;/p&gt;</comment>
                            <comment id="15987240" author="msporleder" created="Thu, 27 Apr 2017 18:35:25 +0000"  >&lt;p&gt;Both are running java version &quot;1.8.0_45&quot; sun jdk&lt;/p&gt;</comment>
                            <comment id="15987488" author="elyograg" created="Thu, 27 Apr 2017 19:57:34 +0000"  >&lt;p&gt;Metrics was just a theory, sounds like that&apos;s not it.  Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ab&quot; class=&quot;user-hover&quot; rel=&quot;ab&quot;&gt;ab&lt;/a&gt; for the assist.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13044543">SOLR-10172</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13043699">SOLR-10150</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="13043219">SOLR-10140</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13044939">SOLR-10182</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="13027512">SOLR-9854</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12852801" name="SOLR-10130.patch" size="24860" author="ab" created="Wed, 15 Feb 2017 11:59:03 +0000"/>
                            <attachment id="12852444" name="SOLR-10130.patch" size="23697" author="ab" created="Tue, 14 Feb 2017 00:27:31 +0000"/>
                            <attachment id="12852336" name="solr-8983-console-f1.log" size="240031" author="emaijala" created="Mon, 13 Feb 2017 11:58:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 29 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i39zqn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313321" key="com.atlassian.jira.toolkit:message">
                        <customfieldname>Solr Mailing List Info</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>