<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 04:17:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SOLR-9284] The HDFS BlockDirectoryCache should not let it&apos;s keysToRelease or names maps grow indefinitely.</title>
                <link>https://issues.apache.org/jira/browse/SOLR-9284</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9284&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/SOLR-9284&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="12987185">SOLR-9284</key>
            <summary>The HDFS BlockDirectoryCache should not let it&apos;s keysToRelease or names maps grow indefinitely.</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="markrmiller@gmail.com">Mark Miller</assignee>
                                    <reporter username="markrmiller@gmail.com">Mark Miller</reporter>
                        <labels>
                    </labels>
                <created>Wed, 6 Jul 2016 15:09:03 +0000</created>
                <updated>Sat, 8 Jun 2019 15:37:06 +0000</updated>
                            <resolved>Tue, 15 Nov 2016 21:03:57 +0000</resolved>
                                                    <fixVersion>6.4</fixVersion>
                    <fixVersion>7.0</fixVersion>
                                    <component>hdfs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                                                                                <comments>
                            <comment id="15364435" author="markrmiller@gmail.com" created="Wed, 6 Jul 2016 15:10:10 +0000"  >&lt;p&gt;A fix for keysToRelease is relatively straightforward, but names is a little tougher. We may just need to have a configurable max names to track size that defaults to something fairly healthy for a normal index.&lt;/p&gt;</comment>
                            <comment id="15370728" author="markrmiller@gmail.com" created="Mon, 11 Jul 2016 13:16:13 +0000"  >&lt;p&gt;Just a quick patch, needs a bit of review and polish, but this is along the lines I was thinking of for a fix.&lt;/p&gt;

&lt;p&gt;Not super satisfied with the &apos;names&apos; issue, but not sure what we should do at the moment. We might want a higher upper limit and/or to make it configurable. Or perhaps there should be some kind of cleaner thread that prunes occasionally?&lt;/p&gt;</comment>
                            <comment id="15431842" author="michael.sun" created="Tue, 23 Aug 2016 00:12:35 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markrmiller%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;markrmiller@gmail.com&quot;&gt;markrmiller@gmail.com&lt;/a&gt; for patch. Here is some of my thoughts.&lt;/p&gt;

&lt;p&gt;1. In BlockDirectoryCache, the map between name and integer is changed to use Caffeine cache without setting up removal listener. I am not sure if it&apos;s correct. If Caffeine cache removes a name in cache, underlying Block Cache needs to delete all blocks related to that name. &lt;br/&gt;
2. There are a few occurrences of System.out.println() in BlockDirectoryCache. It&apos;s better to use log.&lt;/p&gt;

</comment>
                            <comment id="15436868" author="markrmiller@gmail.com" created="Thu, 25 Aug 2016 13:35:31 +0000"  >&lt;ul&gt;
	&lt;li&gt;1. In BlockDirectoryCache, the map between name and integer is changed to use Caffeine cache without setting up removal listener...&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;It never had a removal listener. This is the names map mentioned above. We can&apos;t easily remove names, that is the point of just setting an upper size on it.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;2. There are a few occurrences of System.out.println() in BlockDirectoryCache. It&apos;s better to use log.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is just debug statements for development, no need to log, they just need to be removed before commit.&lt;/p&gt;</comment>
                            <comment id="15436869" author="markrmiller@gmail.com" created="Thu, 25 Aug 2016 13:36:06 +0000"  >&lt;p&gt;Updated patch attached.&lt;/p&gt;</comment>
                            <comment id="15437301" author="michael.sun" created="Thu, 25 Aug 2016 17:40:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;It never had a removal listener. This is the names map mentioned above. We can&apos;t easily remove names, that is the point of just setting an upper size on it.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I understand this patch doesn&apos;t want to remove names. However the Caffeine cache may decide to remove a name on his own. It&apos;s the case even the map didn&apos;t reach the max size. Therefore removing can happen under the hood anytime. A removal listener is necessary if Caffeine cache is used. Here is the doc of maximumSize() which explains the behavior &lt;a href=&quot;https://github.com/ben-manes/caffeine/blob/master/caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java#L277&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/ben-manes/caffeine/blob/master/caffeine/src/main/java/com/github/benmanes/caffeine/cache/Caffeine.java#L277&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If names are not intended to be removed, it&apos;s probably better to use ConcurrentHashMap. I think the growth of name map is less critical compared to the growth of BlockKey. There seems no evidence in test so far that name map grows significantly to be on the radar either.&lt;/p&gt;</comment>
                            <comment id="15437364" author="markrmiller@gmail.com" created="Thu, 25 Aug 2016 18:08:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;A removal listener is necessary if Caffeine cache is used.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Why though? The underlying data will just be reused as the cache is LRU - do we really need to explicitly free anything here?&lt;/p&gt;</comment>
                            <comment id="15437374" author="michael.sun" created="Thu, 25 Aug 2016 18:14:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why though (A removal listener is necessary if Caffeine cache is used.)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As long as the name can be removed (in this case, implicitly by Caffeine cache), the block cache items related to that name needs to be removed as well. That&apos;s the reason a removal listener is necessary.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;do we really need to explicitly free anything here&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;We don&apos;t explicitly free anything. The point is that names can be freed implicitly by Caffeine cache. The doc of this behavior is mentioned in previous comment.&lt;/p&gt;</comment>
                            <comment id="15437826" author="ben.manes" created="Thu, 25 Aug 2016 22:16:41 +0000"  >&lt;p&gt;Hopefully I didn&apos;t break this behavior when upgrading from ConcurrentLinkedHashMap (Caffeine&apos;s predecessor). That code used an eviction listener, so I think it was a direct translation. Can you take a look and see if the prior version was more correct?&lt;/p&gt;

&lt;p&gt;Note that the cache, in its current form, will only evict after the maximum size threshold is crossed. However, Guava does evict prior due to being split into multiple segments that are operated on exclusively during a write. I kept that wording in the JavaDoc to provide flexibility, just in case.&lt;/p&gt;</comment>
                            <comment id="15438466" author="michael.sun" created="Fri, 26 Aug 2016 04:56:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;Can you take a look and see if the prior version was more correct?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;For the name map (BlockDirectoryCache.names) mentioned in my previous comments, it&apos;s currently ConcurrentHashMap, not ConcurrentLinkedHashMap. ConcurrentHashMap doesn&apos;t evict items implicitly. Therefore there was no need to setup eviction listener and prior version is ok.&lt;/p&gt;

&lt;p&gt;The patch changes the name map from ConcurrentHashMap to Caffeine which can evict items implicitly. Therefore it&apos;s necessary to setup a removal listener. Or keep ConcurrentHashMap since the name map usually doesn&apos;t grow much from test results.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ben.manes&quot; class=&quot;user-hover&quot; rel=&quot;ben.manes&quot;&gt;ben.manes&lt;/a&gt; I guess you are talking about the BlockCache.cache, which was using ConcurrentLinkedHashMap, and now Caffeine. There is a removal listener setup in the code and it looks ok. Feel free to open a JIRA if you have any specific concern about it.&lt;/p&gt;

</comment>
                            <comment id="15441243" author="markrmiller@gmail.com" created="Sat, 27 Aug 2016 10:48:58 +0000"  >&lt;blockquote&gt;&lt;p&gt;As long as the name can be removed (in this case, implicitly by Caffeine cache), the block cache items related to that name needs to be removed as well. That&apos;s the reason a removal listener is necessary.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But that does not address &quot;why&quot;. It just restates what you said: &lt;/p&gt;

&lt;p&gt;&quot;the block cache items related to that name needs to be removed as well.&quot; &lt;/p&gt;

&lt;p&gt;I have the same questions though. Even if the name is removed, why do we care if the data remains in the cache?&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Why&lt;/b&gt; does the underlying data in the cache need to be removed? The underlying cache locations should simply be reclaimed by the LRU cache replacement policy.&lt;/p&gt;

&lt;p&gt;Do we gain much by working to explicitly free anything early in this case?&lt;/p&gt;


</comment>
                            <comment id="15447558" author="michael.sun" created="Tue, 30 Aug 2016 00:34:49 +0000"  >&lt;blockquote&gt;&lt;p&gt;Why does the underlying data in the cache need to be removed? The underlying cache locations should simply be reclaimed by the LRU cache replacement policy.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Ah, I see your question. I agree that inaccessible data can be removed by the LRU logic of block cache eventually. The main gain of my suggestion to help cache efficiency. For example, if cached data related to the name removed is newly cached, instead of pushing out them, the LRU cache may decide to push out some older cached data which may be still useful.&lt;/p&gt;

&lt;p&gt;And releasing unused memory early is in general a good practice.&lt;/p&gt;

&lt;p&gt;With that said, the name map implementation in patch is better than current implementation (using ConcurrentHashMap). I was hoping to make max use of memory by removing related items once a name is deleted. But if it&apos;s hard to achieve, the current patch is good to go IMO.&lt;/p&gt;

</comment>
                            <comment id="15447579" author="ben.manes" created="Tue, 30 Aug 2016 00:44:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=michael.sun&quot; class=&quot;user-hover&quot; rel=&quot;michael.sun&quot;&gt;michael.sun&lt;/a&gt;: If you upgrade to Caffeine 2.x then it will take &lt;a href=&quot;https://github.com/ben-manes/caffeine/wiki/Efficiency&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;advantage&lt;/a&gt; of frequency in addition to recency. A path is available in &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8241&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;SOLR-8241&lt;/a&gt;, but its been stalled due to Shawn not having the bandwidth to drive the changes forward.&lt;/p&gt;</comment>
                            <comment id="15666417" author="markrmiller@gmail.com" created="Tue, 15 Nov 2016 07:45:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;But if it&apos;s hard to achieve&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s not exactly simple - that is why the current delete methods take a file name, but also do not release any of the block keys. I think if we wanted to that, we either have to do long scans of cache keys, or start storing cache key list maps keyed by file name.&lt;/p&gt;</comment>
                            <comment id="15666509" author="markrmiller@gmail.com" created="Tue, 15 Nov 2016 08:33:52 +0000"  >&lt;p&gt;Let&apos;s spin that off into a new issue if you want to tackle it. I&apos;ll commit the progress we have now.&lt;/p&gt;</comment>
                            <comment id="15666765" author="jira-bot" created="Tue, 15 Nov 2016 10:18:48 +0000"  >&lt;p&gt;Commit 0325722e675c336ba71f5d47b19133753c2a42e5 in lucene-solr&apos;s branch refs/heads/master from markrmiller&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=0325722&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=0325722&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9284&quot; title=&quot;The HDFS BlockDirectoryCache should not let it&amp;#39;s keysToRelease or names maps grow indefinitely.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9284&quot;&gt;&lt;del&gt;SOLR-9284&lt;/del&gt;&lt;/a&gt;: The HDFS BlockDirectoryCache should not let it&apos;s keysToRelease or names maps grow indefinitely.&lt;/p&gt;</comment>
                            <comment id="15666767" author="jira-bot" created="Tue, 15 Nov 2016 10:19:26 +0000"  >&lt;p&gt;Commit 3d9101601448f0a69b91de2151e64f1f48895fab in lucene-solr&apos;s branch refs/heads/branch_6x from markrmiller&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=3d91016&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=3d91016&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9284&quot; title=&quot;The HDFS BlockDirectoryCache should not let it&amp;#39;s keysToRelease or names maps grow indefinitely.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9284&quot;&gt;&lt;del&gt;SOLR-9284&lt;/del&gt;&lt;/a&gt;: The HDFS BlockDirectoryCache should not let it&apos;s keysToRelease or names maps grow indefinitely.&lt;/p&gt;</comment>
                            <comment id="15667176" author="steve_rowe" created="Tue, 15 Nov 2016 13:46:55 +0000"  >&lt;p&gt;OOM issues likely caused by commit here: &lt;a href=&quot;https://jenkins.thetaphi.de/job/Lucene-Solr-master-Linux/18288/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://jenkins.thetaphi.de/job/Lucene-Solr-master-Linux/18288/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also reproducible, from my Jenkins:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  [junit4]   2&amp;gt; NOTE: reproduce with: ant test  -Dtestcase=BlockDirectoryTest -Dtests.method=testEOF -Dtests.seed=81253F7E7D614B6C -Dtests.slow=true -Dtests.locale=bg -Dtests.timezone=Etc/UCT -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1
   [junit4] ERROR   1.41s | BlockDirectoryTest.testEOF &amp;lt;&amp;lt;&amp;lt;
   [junit4]    &amp;gt; Throwable #1: java.lang.OutOfMemoryError: Direct buffer memory
   [junit4]    &amp;gt;        at java.nio.Bits.reserveMemory(Bits.java:693)
   [junit4]    &amp;gt;        at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:123)
   [junit4]    &amp;gt;        at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
   [junit4]    &amp;gt;        at org.apache.solr.store.blockcache.BlockCache.&amp;lt;init&amp;gt;(BlockCache.java:68)
   [junit4]    &amp;gt;        at org.apache.solr.store.blockcache.BlockDirectoryTest.setUp(BlockDirectoryTest.java:119)
   [junit4]    &amp;gt;        at java.lang.Thread.run(Thread.java:745)Throwable #2: java.lang.NullPointerException
   [junit4]    &amp;gt;        at org.apache.solr.store.blockcache.BlockDirectoryTest.tearDown(BlockDirectoryTest.java:131)
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15667521" author="jira-bot" created="Tue, 15 Nov 2016 16:06:02 +0000"  >&lt;p&gt;Commit 358c164620f774820bd22278fcf425c599a254b2 in lucene-solr&apos;s branch refs/heads/master from markrmiller&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=358c164&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=358c164&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9284&quot; title=&quot;The HDFS BlockDirectoryCache should not let it&amp;#39;s keysToRelease or names maps grow indefinitely.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9284&quot;&gt;&lt;del&gt;SOLR-9284&lt;/del&gt;&lt;/a&gt;: Reduce off heap cache size and fix test asserts.&lt;/p&gt;</comment>
                            <comment id="15667522" author="jira-bot" created="Tue, 15 Nov 2016 16:06:20 +0000"  >&lt;p&gt;Commit b90b4dc694edb9b31c5afd69b477e6d90f24adfd in lucene-solr&apos;s branch refs/heads/branch_6x from markrmiller&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b90b4dc&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b90b4dc&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9284&quot; title=&quot;The HDFS BlockDirectoryCache should not let it&amp;#39;s keysToRelease or names maps grow indefinitely.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9284&quot;&gt;&lt;del&gt;SOLR-9284&lt;/del&gt;&lt;/a&gt;: Reduce off heap cache size and fix test asserts.&lt;/p&gt;</comment>
                            <comment id="15669208" author="steve_rowe" created="Wed, 16 Nov 2016 03:06:04 +0000"  >&lt;p&gt;My Jenkins found a reproducing seed half an hour ago (after the commits above) - note that I had to run the test without &lt;tt&gt;-Dtests.method=ensureCacheConfigurable&lt;/tt&gt; to get it to reproduce: &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  [junit4]   2&amp;gt; NOTE: reproduce with: ant test  -Dtestcase=BlockDirectoryTest -Dtests.method=ensureCacheConfigurable -Dtests.seed=281E6C2B5FD2D4E1 -Dtests.slow=true -Dtests.locale=tr-TR -Dtests.timezone=PST8PDT -Dtests.asserts=true -Dtests.file.encoding=UTF-8
  [junit4] ERROR   1.39s J3  | BlockDirectoryTest.ensureCacheConfigurable &amp;lt;&amp;lt;&amp;lt;
  [junit4]    &amp;gt; Throwable #1: java.lang.OutOfMemoryError: Direct buffer memory
  [junit4]    &amp;gt; 	at java.nio.Bits.reserveMemory(Bits.java:693)
  [junit4]    &amp;gt; 	at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:123)
  [junit4]    &amp;gt; 	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockCache.&amp;lt;init&amp;gt;(BlockCache.java:68)
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.setUp(BlockDirectoryTest.java:119)
  [junit4]    &amp;gt; 	at java.lang.Thread.run(Thread.java:745)Throwable #2: java.lang.NullPointerException
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.tearDown(BlockDirectoryTest.java:131)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15670479" author="steve_rowe" created="Wed, 16 Nov 2016 14:03:31 +0000"  >&lt;p&gt;Three more seeds, but none reproduce for me - note that all three include an NPE as a second Throwable, which I just noticed in the trace in my previous comment here:&lt;/p&gt;

&lt;p&gt;From &lt;a href=&quot;https://builds.apache.org/job/Lucene-Solr-SmokeRelease-6.x/182&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Lucene-Solr-SmokeRelease-6.x/182&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  [smoker]    [junit4]   2&amp;gt; NOTE: reproduce with: ant test  -Dtestcase=BlockDirectoryTest -Dtests.method=testEOF -Dtests.seed=9A2D36FC5487E440 -Dtests.multiplier=2 -Dtests.locale=hi -Dtests.timezone=America/North_Dakota/Beulah -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1
   [smoker]    [junit4] ERROR   1.66s J1 | BlockDirectoryTest.testEOF &amp;lt;&amp;lt;&amp;lt;
   [smoker]    [junit4]    &amp;gt; Throwable #1: java.lang.OutOfMemoryError: Direct buffer memory
   [smoker]    [junit4]    &amp;gt; 	at java.nio.Bits.reserveMemory(Bits.java:693)
   [smoker]    [junit4]    &amp;gt; 	at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:123)
   [smoker]    [junit4]    &amp;gt; 	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
   [smoker]    [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockCache.&amp;lt;init&amp;gt;(BlockCache.java:68)
   [smoker]    [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.setUp(BlockDirectoryTest.java:119)
   [smoker]    [junit4]    &amp;gt; 	at java.lang.Thread.run(Thread.java:745)Throwable #2: java.lang.NullPointerException
   [smoker]    [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.tearDown(BlockDirectoryTest.java:131)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From my Jenkins on branch_6.x:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  [junit4]   2&amp;gt; NOTE: reproduce with: ant test  -Dtestcase=BlockDirectoryTest -Dtests.method=testRandomAccessWritesLargeCache -Dtests.seed=79BD96B775734799 -Dtests.slow=true -Dtests.locale=ar-TN -Dtests.timezone=Europe/Lisbon -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1
  [junit4] ERROR   1.95s J7  | BlockDirectoryTest.testRandomAccessWritesLargeCache &amp;lt;&amp;lt;&amp;lt;
  [junit4]    &amp;gt; Throwable #1: java.lang.OutOfMemoryError: Direct buffer memory
  [junit4]    &amp;gt; 	at java.nio.Bits.reserveMemory(Bits.java:693)
  [junit4]    &amp;gt; 	at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:123)
  [junit4]    &amp;gt; 	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockCache.&amp;lt;init&amp;gt;(BlockCache.java:68)
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.setUp(BlockDirectoryTest.java:119)
  [junit4]    &amp;gt; 	at java.lang.Thread.run(Thread.java:745)Throwable #2: java.lang.NullPointerException
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.tearDown(BlockDirectoryTest.java:131)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And from my Jenkins on master:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  [junit4]   2&amp;gt; NOTE: reproduce with: ant test  -Dtestcase=BlockDirectoryTest -Dtests.method=testRandomAccessWrites -Dtests.seed=39545A949FB2DD31 -Dtests.slow=true -Dtests.locale=sr-ME -Dtests.timezone=America/Indiana/Vevay -Dtests.asserts=true -Dtests.file.encoding=UTF-8
  [junit4] ERROR   0.86s J7  | BlockDirectoryTest.testRandomAccessWrites &amp;lt;&amp;lt;&amp;lt;
  [junit4]    &amp;gt; Throwable #1: java.lang.OutOfMemoryError: Direct buffer memory
  [junit4]    &amp;gt; 	at java.nio.Bits.reserveMemory(Bits.java:693)
  [junit4]    &amp;gt; 	at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:123)
  [junit4]    &amp;gt; 	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockCache.&amp;lt;init&amp;gt;(BlockCache.java:68)
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.setUp(BlockDirectoryTest.java:119)
  [junit4]    &amp;gt; 	at java.lang.Thread.run(Thread.java:745)Throwable #2: java.lang.NullPointerException
  [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.tearDown(BlockDirectoryTest.java:131)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15670646" author="markrmiller@gmail.com" created="Wed, 16 Nov 2016 15:07:26 +0000"  >&lt;p&gt;It probably just matters what is running in parallel and also eating away at the artificial direct memory governor.&lt;/p&gt;</comment>
                            <comment id="15670659" author="jira-bot" created="Wed, 16 Nov 2016 15:11:57 +0000"  >&lt;p&gt;Commit 53a0748f4345b540da598c25500f4fc402dbbf38 in lucene-solr&apos;s branch refs/heads/master from markrmiller&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=53a0748&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=53a0748&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9284&quot; title=&quot;The HDFS BlockDirectoryCache should not let it&amp;#39;s keysToRelease or names maps grow indefinitely.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9284&quot;&gt;&lt;del&gt;SOLR-9284&lt;/del&gt;&lt;/a&gt;: Reduce off heap cache size.&lt;/p&gt;</comment>
                            <comment id="15670660" author="jira-bot" created="Wed, 16 Nov 2016 15:12:18 +0000"  >&lt;p&gt;Commit 6962381180c7c9d26f22fb09b3b673f2a9f8ef7b in lucene-solr&apos;s branch refs/heads/branch_6x from markrmiller&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=6962381&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=6962381&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9284&quot; title=&quot;The HDFS BlockDirectoryCache should not let it&amp;#39;s keysToRelease or names maps grow indefinitely.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9284&quot;&gt;&lt;del&gt;SOLR-9284&lt;/del&gt;&lt;/a&gt;: Reduce off heap cache size.&lt;/p&gt;</comment>
                            <comment id="15670664" author="markrmiller@gmail.com" created="Wed, 16 Nov 2016 15:14:10 +0000"  >&lt;blockquote&gt;&lt;p&gt;It probably just matters what is running in parallel and also eating away at the artificial direct memory governor.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Although I suppose anything in parallel is in it&apos;s own JVM and should have it&apos;s own limit. Perhaps a lack of releasing direct memory somewhere then.&lt;/p&gt;</comment>
                            <comment id="15688398" author="steve_rowe" created="Wed, 23 Nov 2016 00:22:41 +0000"  >&lt;p&gt;Looks like the NPE in &lt;tt&gt;HdfsDirectoryTest.testEOF()&lt;/tt&gt; is still happening: this reproducing master seed is from my Jenkins:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;   [junit4]   2&amp;gt; NOTE: reproduce with: ant test  -Dtestcase=HdfsDirectoryTest -Dtests.method=testEOF -Dtests.seed=FA1024A704DD72C3 -Dtests.slow=true -Dtests.locale=en-GB -Dtests.timezone=Africa/Johannesburg -Dtests.asserts=true -Dtests.file.encoding=UTF-8
   [junit4] ERROR   0.11s J11 | HdfsDirectoryTest.testEOF &amp;lt;&amp;lt;&amp;lt;
   [junit4]    &amp;gt; Throwable #1: java.lang.NullPointerException
   [junit4]    &amp;gt; 	at __randomizedtesting.SeedInfo.seed([FA1024A704DD72C3:6B7B66AF46F9D4BF]:0)
   [junit4]    &amp;gt; 	at org.apache.lucene.store.RAMInputStream.readByte(RAMInputStream.java:69)
   [junit4]    &amp;gt; 	at org.apache.solr.store.hdfs.HdfsDirectoryTest.testEof(HdfsDirectoryTest.java:158)
   [junit4]    &amp;gt; 	at org.apache.solr.store.hdfs.HdfsDirectoryTest.testEOF(HdfsDirectoryTest.java:150)
[...]
   [junit4]   2&amp;gt; 429308 ERROR (SUITE-HdfsDirectoryTest-seed#[FA1024A704DD72C3]-worker) [    ] o.a.h.m.l.MethodMetric Error invoking method getBlocksTotal
   [junit4]   2&amp;gt; java.lang.reflect.InvocationTargetException
   [junit4]   2&amp;gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
   [junit4]   2&amp;gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
   [junit4]   2&amp;gt; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
   [junit4]   2&amp;gt; 	at java.lang.reflect.Method.invoke(Method.java:498)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.MethodMetric$2.snapshot(MethodMetric.java:111)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.MethodMetric.snapshot(MethodMetric.java:144)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.MetricsRegistry.snapshot(MetricsRegistry.java:401)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.MetricsSourceBuilder$1.getMetrics(MetricsSourceBuilder.java:79)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMetrics(MetricsSourceAdapter.java:194)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.updateJmxCache(MetricsSourceAdapter.java:172)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMBeanInfo(MetricsSourceAdapter.java:151)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getClassName(DefaultMBeanServerInterceptor.java:1804)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.safeGetClassName(DefaultMBeanServerInterceptor.java:1595)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanPermission(DefaultMBeanServerInterceptor.java:1813)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:430)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
   [junit4]   2&amp;gt; 	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:81)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.stopMBeans(MetricsSourceAdapter.java:226)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.stop(MetricsSourceAdapter.java:211)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stopSources(MetricsSystemImpl.java:463)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stop(MetricsSystemImpl.java:213)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.shutdown(MetricsSystemImpl.java:594)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.shutdownInstance(DefaultMetricsSystem.java:72)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.shutdown(DefaultMetricsSystem.java:68)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.shutdown(NameNodeMetrics.java:171)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.namenode.NameNode.stop(NameNode.java:872)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1726)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1705)
   [junit4]   2&amp;gt; 	at org.apache.solr.cloud.hdfs.HdfsTestUtil.teardownClass(HdfsTestUtil.java:198)
   [junit4]   2&amp;gt; 	at org.apache.solr.store.hdfs.HdfsDirectoryTest.afterClass(HdfsDirectoryTest.java:65)
   [junit4]   2&amp;gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
   [junit4]   2&amp;gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
   [junit4]   2&amp;gt; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
   [junit4]   2&amp;gt; 	at java.lang.reflect.Method.invoke(Method.java:498)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1713)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:870)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule$1.evaluate(SystemPropertiesRestoreRule.java:57)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:41)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:53)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:47)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:64)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:54)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)
   [junit4]   2&amp;gt; 	at java.lang.Thread.run(Thread.java:745)
   [junit4]   2&amp;gt; Caused by: java.lang.NullPointerException
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.blockmanagement.BlocksMap.size(BlocksMap.java:203)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.getTotalBlocks(BlockManager.java:3370)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlocksTotal(FSNamesystem.java:5729)
   [junit4]   2&amp;gt; 	... 54 more
   [junit4]   2&amp;gt; 429312 INFO  (SUITE-HdfsDirectoryTest-seed#[FA1024A704DD72C3]-worker) [    ] o.a.s.SolrTestCaseJ4 ###deleteCore
   [junit4]   2&amp;gt; NOTE: leaving temporary files on disk at: /var/lib/jenkins/jobs/Lucene-Solr-tests-6.x/workspace/solr/build/solr-core/test/J11/temp/solr.store.hdfs.HdfsDirectoryTest_FA1024A704DD72C3-001
   [junit4]   2&amp;gt; Nov 22, 2016 11:23:44 AM com.carrotsearch.randomizedtesting.ThreadLeakControl checkThreadLeaks
   [junit4]   2&amp;gt; WARNING: Will linger awaiting termination of 130 leaked thread(s).
   [junit4]   2&amp;gt; NOTE: test params are: codec=Asserting(Lucene62), sim=RandomSimilarity(queryNorm=true,coord=yes): {}, locale=en-GB, timezone=Africa/Johannesburg
   [junit4]   2&amp;gt; NOTE: Linux 4.1.0-custom2-amd64 amd64/Oracle Corporation 1.8.0_77 (64-bit)/cpus=16,threads=2,free=193596736,total=526385152
   [junit4]   2&amp;gt; NOTE: All tests run in this JVM: [TestReversedWildcardFilterFactory, TestTestInjection, TestGraphMLResponseWriter, ReplicaListTransformerTest, UpdateRequestProcessorFactoryTest, TestMissingGroups, CursorPagingTest, LukeRequestHandlerTest, TestDistributedStatsComponentCardinality, TestRangeQuery, TestHdfsBackupRestoreCore, AtomicUpdatesTest, TestRealTimeGet, TestNumericTerms64, TestRandomFlRTGCloud, TestSolrCoreProperties, OverseerModifyCollectionTest, TestExpandComponent, DocValuesMissingTest, ReplaceNodeTest, DistribCursorPagingTest, TestClassicSimilarityFactory, MoreLikeThisHandlerTest, TestSystemIdResolver, TestLegacyFieldCache, TestRTGBase, WordBreakSolrSpellCheckerTest, CheckHdfsIndexTest, HdfsDirectoryTest]
   [junit4] Completed [339/655 (1!)] on J11 in 44.08s, 4 tests, 1 error &amp;lt;&amp;lt;&amp;lt; FAILURES!
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15688601" author="steve_rowe" created="Wed, 23 Nov 2016 02:01:23 +0000"  >&lt;p&gt;A couple more &quot;OOM: Direct buffer memory&quot; failures today on Apache Jenkins:&lt;/p&gt;

&lt;p&gt;From &lt;a href=&quot;https://builds.apache.org/job/Lucene-Solr-NightlyTests-master/1160/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Lucene-Solr-NightlyTests-master/1160/&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  [junit4]   2&amp;gt; NOTE: reproduce with: ant test  -Dtestcase=HdfsDirectoryFactoryTest -Dtests.method=testInitArgsOrSysPropConfig -Dtests.seed=200C6D6D2F8C2C5F -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/home/jenkins/jenkins-slave/workspace/Lucene-Solr-NightlyTests-master/test-data/enwiki.random.lines.txt -Dtests.locale=zh-TW -Dtests.timezone=America/Argentina/Buenos_Aires -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1
   [junit4] ERROR   1.30s J0 | HdfsDirectoryFactoryTest.testInitArgsOrSysPropConfig &amp;lt;&amp;lt;&amp;lt;
   [junit4]    &amp;gt; Throwable #1: java.lang.RuntimeException: The max direct memory is likely too low.  Either increase it (by adding -XX:MaxDirectMemorySize=&amp;lt;size&amp;gt;g -XX:+UseLargePages to your containers startup args) or disable direct allocation using solr.hdfs.blockcache.direct.memory.allocation=false in solrconfig.xml. If you are putting the block cache on the heap, your java heap size might not be large enough. Failed allocating ~134.217728 MB.
   [junit4]    &amp;gt; 	at __randomizedtesting.SeedInfo.seed([200C6D6D2F8C2C5F:D7A3A446D205C674]:0)
   [junit4]    &amp;gt; 	at org.apache.solr.core.HdfsDirectoryFactory.createBlockCache(HdfsDirectoryFactory.java:304)
   [junit4]    &amp;gt; 	at org.apache.solr.core.HdfsDirectoryFactory.getBlockDirectoryCache(HdfsDirectoryFactory.java:280)
   [junit4]    &amp;gt; 	at org.apache.solr.core.HdfsDirectoryFactory.create(HdfsDirectoryFactory.java:220)
   [junit4]    &amp;gt; 	at org.apache.solr.core.HdfsDirectoryFactoryTest.testInitArgsOrSysPropConfig(HdfsDirectoryFactoryTest.java:108)
   [junit4]    &amp;gt; 	at java.lang.Thread.run(Thread.java:745)
   [junit4]    &amp;gt; Caused by: java.lang.OutOfMemoryError: Direct buffer memory
   [junit4]    &amp;gt; 	at java.nio.Bits.reserveMemory(Bits.java:693)
   [junit4]    &amp;gt; 	at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:123)
   [junit4]    &amp;gt; 	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
   [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockCache.&amp;lt;init&amp;gt;(BlockCache.java:68)
   [junit4]    &amp;gt; 	at org.apache.solr.core.HdfsDirectoryFactory.createBlockCache(HdfsDirectoryFactory.java:302)
   [junit4]    &amp;gt; 	... 42 more
[...]
   [junit4]   2&amp;gt; 415746 ERROR (SUITE-HdfsDirectoryFactoryTest-seed#[200C6D6D2F8C2C5F]-worker) [    ] o.a.h.m.l.MethodMetric Error invoking method getBlocksTotal
   [junit4]   2&amp;gt; java.lang.reflect.InvocationTargetException
   [junit4]   2&amp;gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
   [junit4]   2&amp;gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
   [junit4]   2&amp;gt; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
   [junit4]   2&amp;gt; 	at java.lang.reflect.Method.invoke(Method.java:498)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.MethodMetric$2.snapshot(MethodMetric.java:111)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.MethodMetric.snapshot(MethodMetric.java:144)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.MetricsRegistry.snapshot(MetricsRegistry.java:401)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.MetricsSourceBuilder$1.getMetrics(MetricsSourceBuilder.java:79)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMetrics(MetricsSourceAdapter.java:194)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.updateJmxCache(MetricsSourceAdapter.java:172)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMBeanInfo(MetricsSourceAdapter.java:151)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getClassName(DefaultMBeanServerInterceptor.java:1804)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.safeGetClassName(DefaultMBeanServerInterceptor.java:1595)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.checkMBeanPermission(DefaultMBeanServerInterceptor.java:1813)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:430)
   [junit4]   2&amp;gt; 	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
   [junit4]   2&amp;gt; 	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:81)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.stopMBeans(MetricsSourceAdapter.java:226)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.stop(MetricsSourceAdapter.java:211)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stopSources(MetricsSystemImpl.java:463)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stop(MetricsSystemImpl.java:213)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.shutdown(MetricsSystemImpl.java:594)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.shutdownInstance(DefaultMetricsSystem.java:72)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.shutdown(DefaultMetricsSystem.java:68)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.namenode.metrics.NameNodeMetrics.shutdown(NameNodeMetrics.java:171)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.namenode.NameNode.stop(NameNode.java:872)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1726)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:1705)
   [junit4]   2&amp;gt; 	at org.apache.solr.cloud.hdfs.HdfsTestUtil.teardownClass(HdfsTestUtil.java:198)
   [junit4]   2&amp;gt; 	at org.apache.solr.core.HdfsDirectoryFactoryTest.teardownClass(HdfsDirectoryFactoryTest.java:61)
   [junit4]   2&amp;gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
   [junit4]   2&amp;gt; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
   [junit4]   2&amp;gt; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
   [junit4]   2&amp;gt; 	at java.lang.reflect.Method.invoke(Method.java:498)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1713)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:870)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule$1.evaluate(SystemPropertiesRestoreRule.java:57)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:41)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:53)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:47)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:64)
   [junit4]   2&amp;gt; 	at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:54)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36)
   [junit4]   2&amp;gt; 	at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367)
   [junit4]   2&amp;gt; 	at java.lang.Thread.run(Thread.java:745)
   [junit4]   2&amp;gt; Caused by: java.lang.NullPointerException
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.blockmanagement.BlocksMap.size(BlocksMap.java:203)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.getTotalBlocks(BlockManager.java:3370)
   [junit4]   2&amp;gt; 	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlocksTotal(FSNamesystem.java:5729)
   [junit4]   2&amp;gt; 	... 54 more
[...]
   [junit4]   2&amp;gt; NOTE: test params are: codec=Asserting(Lucene70): {}, docValues:{}, maxPointsInLeafNode=174, maxMBSortInHeap=6.915978870333232, sim=RandomSimilarity(queryNorm=false): {}, locale=zh-TW, timezone=America/Argentina/Buenos_Aires
   [junit4]   2&amp;gt; NOTE: Linux 3.13.0-85-generic amd64/Oracle Corporation 1.8.0_102 (64-bit)/cpus=4,threads=2,free=364870536,total=525860864
   [junit4]   2&amp;gt; NOTE: All tests run in this JVM: [TestFileDictionaryLookup, HdfsChaosMonkeySafeLeaderTest, DistributedDebugComponentTest, TestExactSharedStatsCache, TestLFUCache, TestFieldCacheSort, HdfsUnloadDistributedZkTest, TestLockTree, TestHighlightDedupGrouping, TestDFISimilarityFactory, SolrRequestParserTest, SyncSliceTest, CreateCollectionCleanupTest, HdfsDirectoryFactoryTest]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;From &lt;a href=&quot;https://builds.apache.org/job/Lucene-Solr-NightlyTests-6.x/207&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Lucene-Solr-NightlyTests-6.x/207&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;   [junit4]   2&amp;gt; NOTE: reproduce with: ant test  -Dtestcase=BlockDirectoryTest -Dtests.method=testRandomAccessWritesLargeCache -Dtests.seed=85E88260B81B20E2 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/home/jenkins/jenkins-slave/workspace/Lucene-Solr-NightlyTests-6.x/test-data/enwiki.random.lines.txt -Dtests.locale=id-ID -Dtests.timezone=Africa/Libreville -Dtests.asserts=true -Dtests.file.encoding=US-ASCII
   [junit4] ERROR   1.64s J1 | BlockDirectoryTest.testRandomAccessWritesLargeCache &amp;lt;&amp;lt;&amp;lt;
   [junit4]    &amp;gt; Throwable #1: java.lang.OutOfMemoryError: Direct buffer memory
   [junit4]    &amp;gt; 	at java.nio.Bits.reserveMemory(Bits.java:693)
   [junit4]    &amp;gt; 	at java.nio.DirectByteBuffer.&amp;lt;init&amp;gt;(DirectByteBuffer.java:123)
   [junit4]    &amp;gt; 	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:311)
   [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockCache.&amp;lt;init&amp;gt;(BlockCache.java:68)
   [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.setUp(BlockDirectoryTest.java:119)
   [junit4]    &amp;gt; 	at java.lang.Thread.run(Thread.java:745)Throwable #2: java.lang.NullPointerException
   [junit4]    &amp;gt; 	at org.apache.solr.store.blockcache.BlockDirectoryTest.tearDown(BlockDirectoryTest.java:131)
[...]
   [junit4]   2&amp;gt; NOTE: test params are: codec=Asserting(Lucene62): {}, docValues:{}, maxPointsInLeafNode=1406, maxMBSortInHeap=7.589330986925872, sim=RandomSimilarity(queryNorm=false,coord=yes): {}, locale=id-ID, timezone=Africa/Libreville
   [junit4]   2&amp;gt; NOTE: Linux 3.13.0-85-generic amd64/Oracle Corporation 1.8.0_102 (64-bit)/cpus=4,threads=1,free=317294960,total=496500736
   [junit4]   2&amp;gt; NOTE: All tests run in this JVM: [WordBreakSolrSpellCheckerTest, DocumentBuilderTest, TestHashQParserPlugin, TestDynamicFieldResource, DateMathParserTest, CollectionsAPIDistributedZkTest, HdfsRecoveryZkTest, TestDocBasedVersionConstraints, TestCloudManagedSchema, SpellCheckCollatorTest, HdfsBasicDistributedZkTest, TestLuceneMatchVersion, SpatialFilterTest, CustomCollectionTest, TestUseDocValuesAsStored2, TestCharFilters, BlockDirectoryTest]
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="15858470" author="mdrob" created="Wed, 8 Feb 2017 20:01:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/lucene-solr/blob/5738c293f0c3f346b3e3e52c937183060d59cba1/solr/core/src/java/org/apache/solr/store/blockcache/BlockDirectoryCache.java#L53&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/lucene-solr/blob/5738c293f0c3f346b3e3e52c937183060d59cba1/solr/core/src/java/org/apache/solr/store/blockcache/BlockDirectoryCache.java#L53&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (releaseBlocks) {
      keysToRelease = Collections.newSetFromMap(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ConcurrentHashMap&amp;lt;BlockCacheKey,&lt;span class=&quot;code-object&quot;&gt;Boolean&lt;/span&gt;&amp;gt;(1024, 0.75f, 512));
      blockCache.setOnRelease(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; OnRelease() {
        
        @Override
        &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void release(BlockCacheKey key) {
          keysToRelease.remove(key);
        }
      });
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If we&apos;re using the global block cache option and create multiple directories using the same factory, we will lose the release hook for the first directory. I think we can verify that by creating a server with multiple cores.&lt;/p&gt;

&lt;p&gt;Edit: Filed &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-10104&quot; title=&quot;BlockDirectoryCache release hooks do not work with multiple directories&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-10104&quot;&gt;&lt;del&gt;SOLR-10104&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13041473">SOLR-10104</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12825467" name="SOLR-9284.patch" size="11686" author="markrmiller@gmail.com" created="Thu, 25 Aug 2016 13:36:06 +0000"/>
                            <attachment id="12817167" name="SOLR-9284.patch" size="5787" author="markrmiller@gmail.com" created="Mon, 11 Jul 2016 13:16:13 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 40 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30lnj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313321" key="com.atlassian.jira.toolkit:message">
                        <customfieldname>Solr Mailing List Info</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>