<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 05:00:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SOLR-13396] SolrCloud will delete the core data for any core that is not referenced in the clusterstate</title>
                <link>https://issues.apache.org/jira/browse/SOLR-13396</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-12066&quot; title=&quot;Cleanup deleted core when node start&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-12066&quot;&gt;&lt;del&gt;SOLR-12066&lt;/del&gt;&lt;/a&gt; is an improvement designed to delete core data for replicas that were deleted while the node was down &amp;#8211; better cleanup.&lt;/p&gt;

&lt;p&gt;In practice, that change causes SolrCloud to delete all core data for cores that are not referenced in the ZK clusterstate.  If all the ZK data gets deleted or the Solr instance is pointed at a ZK ensemble with no data, it will proceed to delete all of the cores in the solr home, with no possibility of recovery.&lt;/p&gt;

&lt;p&gt;I do not think that Solr should ever delete core data unless an explicit DELETE action has been made and the node is operational at the time of the request.  If a core exists during startup that cannot be found in the ZK clusterstate, it should be ignored (not started) and a helpful message should be logged.  I think that message should probably be at WARN so that it shows up in the admin UI logging tab with default settings.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13227593">SOLR-13396</key>
            <summary>SolrCloud will delete the core data for any core that is not referenced in the clusterstate</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="elyograg">Shawn Heisey</reporter>
                        <labels>
                    </labels>
                <created>Fri, 12 Apr 2019 01:30:44 +0000</created>
                <updated>Fri, 1 Sep 2023 13:12:28 +0000</updated>
                            <resolved>Fri, 1 Sep 2023 13:09:54 +0000</resolved>
                                    <version>7.3.1</version>
                    <version>8.0</version>
                                    <fixVersion>9.3</fixVersion>
                                    <component>SolrCloud</component>
                        <due></due>
                            <votes>2</votes>
                                    <watches>14</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="5400">1.5h</timespent>
                                <comments>
                            <comment id="16816063" author="koendg" created="Fri, 12 Apr 2019 08:00:58 +0000"  >&lt;p&gt;Just going to add this link to the mail archive where the question was asked: &lt;a href=&quot;https://mail-archives.apache.org/mod_mbox/lucene-solr-user/201904.mbox/%3CCAPPyzbwMr1EN97h-TnsebAgw6pL8i8GNa41zE7Q6ksvqkAnqLA%40mail.gmail.com%3E&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://mail-archives.apache.org/mod_mbox/lucene-solr-user/201904.mbox/%3CCAPPyzbwMr1EN97h-TnsebAgw6pL8i8GNa41zE7Q6ksvqkAnqLA%40mail.gmail.com%3E&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In case someone wants the reference.&lt;/p&gt;</comment>
                            <comment id="16816146" author="janhoy" created="Fri, 12 Apr 2019 10:09:38 +0000"  >&lt;p&gt;Could perhaps this be registered as a AutoScaling suggestion that is not executed, but shows up in the suggestions for manual execution? Or could it be scheduled for the Overseer to delete, say, 7 days after it was discovered, so an Admin will have time to cancel the deletion should it be a mistake? Just thinking aloud here.&lt;/p&gt;</comment>
                            <comment id="16816343" author="erickerickson" created="Fri, 12 Apr 2019 15:15:35 +0000"  >&lt;p&gt;This is a sticky wicket. Let&apos;s claim I have a 200 node cluster hosting 1,000 collections. Keeping track of all the cores that aren&apos;t &lt;em&gt;really&lt;/em&gt; part of a collection and manually cleaning them up is an onerous task.&lt;/p&gt;

&lt;p&gt;Yet it&apos;s pretty horrible to have one mistake (someone edits the startup script and messes up the ZK parameter and pushes it out to all the Solr nodes and restarts the cluster) one could delete everything everywhere.&lt;/p&gt;

&lt;p&gt;More thinking out loud, and I have no clue how it&apos;d interact with autoscaling. It seems odd but we &lt;em&gt;could&lt;/em&gt; use ZooKeeper to keep a list of potential nodes to delete and have&lt;/p&gt;

&lt;p&gt;1&amp;gt; a way to view/list them&lt;/p&gt;

&lt;p&gt;2&amp;gt; a button to push or a collections API command to issue or.. to say &quot;delete them&quot;.&lt;/p&gt;

&lt;p&gt;3&amp;gt; some kind of very visible warning that this list is not empty.&lt;/p&gt;

&lt;p&gt;&quot;But wait!&lt;span class=&quot;error&quot;&gt;Unable to render embedded object: File (&amp;quot;&#160;you cry, The whole problem is that you can&amp;#39;t get to ZooKeeper in the first place) not found.&lt;/span&gt;&quot; Which is perfectly fine, since we&apos;re presupposing a bogus ZK address anyway. That way the nodes to delete would be tied to the proper ZK instance. When the ZK address was corrected, there wouldn&apos;t be anything in the queue. I think I like this a little better than some sort of scheduled-in-the-future event, for people who cared a cron job that issued the collections API call could be done. One could even attach a date to the znode for the potential core to delete with an expiration date.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16816367" author="risdenk" created="Fri, 12 Apr 2019 15:34:49 +0000"  >&lt;p&gt;I agree that arbitrarily deleting data is bad. The other issue is how do you clean up if you JUST have the error/warn. Would be nice to know what you needed to do in addition that it was a problem.&lt;/p&gt;

&lt;p&gt;So I will caveat this by saying I have no idea how this works today, but when I read this I thought it would make sense for each node responsible for a shard/collection would have to &quot;ack&quot; that the operation was complete. If the node was down at the time, when it comes up it should know it needs to do &quot;xyz&quot; and finish the operation.&lt;/p&gt;

&lt;p&gt;Again not sure of the ZK details, but some rough ideas:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Create a znode for each node with list of operations it needs to complete - this would be written to by the leader?&lt;/li&gt;
	&lt;li&gt;Keep track of which operations each node completed on existing list before deleting? - I think this could be hard since leader could change?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Some of the concerns would be added load on ZK for reading/writing operations.&lt;/p&gt;

&lt;p&gt;The above could have already been thought about when building Solr Cloud so it might be a nonstarter.&lt;/p&gt;</comment>
                            <comment id="16816372" author="erickerickson" created="Fri, 12 Apr 2019 15:39:28 +0000"  >&lt;p&gt;Hmmm, actually this seems like it would be an overseer task, look at the queue and delete what&apos;s reasonable. which is really sending a core admin request to each node.&lt;/p&gt;

&lt;p&gt;I don&apos;t think in the normal state there&apos;s really any work here. In the usual case, Solr starts up and each core is found to be part of a collection and no znode is written. Likewise if the list is empty there&apos;s nothing to do as far as the overseer is concerned and nothing to report as potential problems.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Admittedly in my above scenario there&apos;d be a zillion znodes written but who cares in that case? &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16816433" author="elyograg" created="Fri, 12 Apr 2019 16:30:59 +0000"  >&lt;p&gt;If I&apos;m not mistaken, I think that delete operations happen through the overseer.  I&apos;m guessing that we don&apos;t want operations that couldn&apos;t be handled to stick around in the overseer queue ... but maybe we could create a secondary queue for things (like deletes) that were never acknowledged, and the overseer can occasionally revisit those items to see if it&apos;s possible to complete them.&lt;/p&gt;</comment>
                            <comment id="16822603" author="gus_heck" created="Sun, 21 Apr 2019 01:50:06 +0000"  >&lt;p&gt;I think it&apos;s probably sufficient to add a long delay before deletion. On startup and once every hour compare the state and the collections on disk, anything that&apos;s&#160;not had representation in the zookeeper state for 24h can be deleted. (Time period should be configurable) The thing that&apos;s the problem here is that the moment you start it with bad settings your days long&#160;ingest of 50 billion documents goes bye bye. That&apos;s very different than starting it and not noticing that you can&apos;t see any collections for 24 hours... I just had to explain zkchroot to a customer with a&#160;data set of that magnitude... so this issue is kinda scary to me &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16822665" author="koendg" created="Sun, 21 Apr 2019 11:13:29 +0000"  >&lt;p&gt;Just gonna chime in here.&lt;/p&gt;

&lt;p&gt;As already stated in the mailing list: the reason I came upon this issue is either down to iptables or a network issue.&lt;/p&gt;

&lt;p&gt;Here&apos;s what I assume happened: A new zookeeper was added, it could not connect to the other zookeepers, therefore did not sync up. But the auto-deploy only really checks if the zookeeper container is running and not if it&apos;s synced to the others. So the deploy script continues.&lt;/p&gt;

&lt;p&gt;Next step: solr starts, and from all the possible zookeepers it could connect to, it connected to the faulty one. And that caused the deletion.&lt;/p&gt;

&lt;p&gt;That&apos;s a possibility: that there&apos;s a network issue just at the moment you&apos;re deploying. I&apos;d even go as far as to say it&apos;s not a rare occurrence. And in that event, the data should remain safe, so the deploy can happen again after the network issue is fixed.&lt;/p&gt;

&lt;p&gt;The delay before deletion sounds good. Probably want a form of logging attached to that as a WARN and/or ERROR.&lt;br/&gt;
I&apos;d go even further and says: make it an option, default disabled, to shut down the solr in case this happens. Or should that be something detected by the user? My whole train of thought for that option is exactly: what if there&apos;s nobody around to notice? Ideally, that should never be the case, certainly not in a professional environment.&lt;/p&gt;

&lt;p&gt;Still, I feel like automatic deletes should never occur when it comes to data storage. If a data set is retired, for whatever reason, it should be up to the team maintaining it to decide and then manually do the cleanup.&lt;/p&gt;</comment>
                            <comment id="16822748" author="elyograg" created="Sun, 21 Apr 2019 19:07:27 +0000"  >&lt;blockquote&gt;&lt;p&gt;Next step: solr starts, and from all the possible zookeepers it could connect to, it connected to the faulty one. And that caused the deletion.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ZK clients (including Solr) connect to &lt;b&gt;ALL&lt;/b&gt; of the zookeepers that have been configured.  They don&apos;t connect to just one server unless they have only been configured with one server.  ZK should never be placed behind a load balancer.  If Solr has been configured with multiple servers and it can only connect to one, that seems like something we should detect (if we can) and probably refuse to proceed with startup.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;d go even further and says: make it an option, default disabled, to shut down the solr in case this happens.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s an interesting idea.  If we combine it with what I initially proposed, then there&apos;s a hybrid solution that I will describe here:&lt;/p&gt;

&lt;p&gt;We create a new option to prevent Solr startup when there are cores that aren&apos;t referenced in ZK.  Initially, this option will default to disabled, but at some point (probably 9.0) we flip the default to enabled.&lt;/p&gt;

&lt;p&gt;If the new option is enabled, then Solr will not complete startup when that situation is found.  The log will indicate why this has happened.  The &quot;bootstrap&quot; option will take priority over the new option if it is found.&lt;/p&gt;

&lt;p&gt;If the new option is disabled, then here&apos;s what will happen:&lt;/p&gt;

&lt;p&gt;Cores that do not exist in ZK will not start.  Solr will check for a file in the solr home, with a name like allow_auto_core_delete, and if that file exists, it will be deleted and then Solr will proceed as if another new option were enabled, and delete unreferenced cores.  The new option described here will default to false and the default will not change in a later release.&lt;/p&gt;</comment>
                            <comment id="16823091" author="koendg" created="Mon, 22 Apr 2019 13:10:12 +0000"  >&lt;p&gt;Sounds like a great plan. Far as I can tell it covers all eventualities.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Which only leaves me to wonder what happened when this first occured in my case. The whole thing about an ensemble is: it won&apos;t start if there&apos;s not a majority. So if 1 instance out of 3 or 5 isn&apos;t properly connected to the others, it should refuse to service requests, far as I understand.&#160;Unless something went wrong with that setup.&lt;/p&gt;</comment>
                            <comment id="16849860" author="koendg" created="Tue, 28 May 2019 15:46:14 +0000"  >&lt;p&gt;In the mean time, while this is awaiting being picked up or being assigned, I&apos;m working on a script that contacts zkCli.sh, queries it for its directories and checks if the one I want is in there with the underlying tree that I expect it to have.&lt;/p&gt;

&lt;p&gt;I guess that should offer some protection in case not everything is detected, in which case I can stop the deploy before solr starts.&lt;/p&gt;

&lt;p&gt;But I&apos;m wondering about cases where zookeeper crashes and restarts, and the solr reconnects to it and it offers an empty list. What happens then?&lt;/p&gt;

&lt;p&gt;Or will zookeeper first reconnect with all the other zookeepers in its ensemble, sync configs and then open itself up for connections?&lt;/p&gt;

&lt;p&gt;What if it loses its config of being part of an ensemble and just opens itself up, empty?&lt;/p&gt;</comment>
                            <comment id="16855119" author="koendg" created="Mon, 3 Jun 2019 22:38:42 +0000"  >&lt;p&gt;Just did some testing:&lt;/p&gt;

&lt;p&gt;I created a `/solr` directory in zookeeper and put some test data in it.&lt;/p&gt;

&lt;p&gt;If I delete the `version-2` folder, the solr data directories remain in place.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;When restarting the containers, nothing changes. In fact, solr refuses to connect with zookeeper, with messages like this:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;2019-06-03 22:18:08.648 WARN&#160; (qtp574568002-28) &lt;span class=&quot;error&quot;&gt;&amp;#91;&#160;&#160; &amp;#93;&lt;/span&gt; o.e.j.s.HttpChannel /solr/&lt;br/&gt;
javax.servlet.ServletException: javax.servlet.UnavailableException: Error processing the request. CoreContainer is either not initialized or shutting down.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;And&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;2019-06-03 22:04:10.654 ERROR (OverseerCollectionConfigSetProcessor-72057939225149443-localhost:8983_solr-n_0000000001) &lt;span class=&quot;error&quot;&gt;&amp;#91;&#160;&#160; &amp;#93;&lt;/span&gt; o.a.s.c.OverseerTaskProcessor &lt;br/&gt;
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /overseer_elect/leader&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;The problem of data directories being deleted really only occurs when I re-create the /solr chroot... which is then empty. They don&apos;t contain the data of the old ZK. So when I then restart solr, it connects to ZK, finds what it&apos;s looking for, namely `/solr`, sees that it is empty, and proceeds to make it so that the data on disk for solr is identical to what it found. In this case: empty.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I don&apos;t see how that problem can be fixed. Would really like some feedback on that.&lt;/p&gt;

&lt;p&gt;EDIT: Or is this exactly the case that was being described?&lt;/p&gt;</comment>
                            <comment id="16855553" author="koendg" created="Tue, 4 Jun 2019 10:26:21 +0000"  >&lt;p&gt;Just noticed that the assignee of the previous ticket had not been notified yet.&lt;/p&gt;

&lt;p&gt;So just going to ping &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=caomanhdat&quot; class=&quot;user-hover&quot; rel=&quot;caomanhdat&quot;&gt;caomanhdat&lt;/a&gt; in here so they can be aware of this, in case they hadn&apos;t seen it yet.&lt;/p&gt;</comment>
                            <comment id="16855560" author="caomanhdat" created="Tue, 4 Jun 2019 10:34:18 +0000"  >&lt;p&gt;I&apos;m taking a look.&lt;/p&gt;</comment>
                            <comment id="16944481" author="JIRAUSER298947" created="Fri, 4 Oct 2019 13:09:33 +0000"  >&lt;p&gt;Hello, just wondering if there&apos;s been any progress on this? I just accidentally hit it (in dev thankfully), and having my cores be deleted because I made a mistake in my ZK Host address (missing the chroot) is quite terrifying.&lt;/p&gt;</comment>
                            <comment id="16944485" author="caomanhdat" created="Fri, 4 Oct 2019 13:14:21 +0000"  >&lt;p&gt;I wonder should we handle the case for mistaken in ZK Host address by checking well knowns node like &quot;/collections&quot; or so?&lt;/p&gt;</comment>
                            <comment id="16944490" author="JIRAUSER298947" created="Fri, 4 Oct 2019 13:18:36 +0000"  >&lt;p&gt;ZkStateReader in solrj has something similar, checking that the&#160;clusterstate.json exists (&lt;a href=&quot;https://github.com/apache/lucene-solr/blob/b51013a10b5acd603ae934fa56714ffb7eb3641b/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java#L1093&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/lucene-solr/blob/b51013a10b5acd603ae934fa56714ffb7eb3641b/solr/solrj/src/java/org/apache/solr/common/cloud/ZkStateReader.java#L1093&lt;/a&gt;)&lt;/p&gt;</comment>
                            <comment id="16944505" author="caomanhdat" created="Fri, 4 Oct 2019 13:39:31 +0000"  >&lt;p&gt;Yeah I mean rather than coming up with something complicated. Should we just improve the logic here so most of the cases will be solved. I.E: check existence of clusterstate before delete core.&lt;/p&gt;</comment>
                            <comment id="17440882" author="ykonathala" created="Tue, 9 Nov 2021 03:52:10 +0000"  >&lt;p&gt;Sorry if I am missing something here.. but can I know the status of this case? Is this still being worked out or is there a workaround ? I did faced similar issue with solr 8.2 which is quite intermittent and happened twice in production too.. so pls let me know the status of the same.&lt;/p&gt;</comment>
                            <comment id="17479982" author="JIRAUSER298947" created="Fri, 21 Jan 2022 10:29:59 +0000"  >&lt;p&gt;I couldn&apos;t wait for something to be done / agreement to be reached on what to do with this issue, so the workaround I used in my product was to subclass the &lt;tt&gt;org.apache.solr.core.CoreContainer&lt;/tt&gt; and override the &lt;tt&gt;unload(String, boolean, boolean, boolean)&lt;/tt&gt; method so that it doesn&apos;t delete a core in this scenario. (I also subclass &lt;tt&gt;org.apache.solr.servlet.SolrDispatchFilter&lt;/tt&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;which is specified in the web.xml&amp;#93;&lt;/span&gt; and override &lt;tt&gt;createCoreContainer(Path, Properties)&lt;/tt&gt; which is where I call my overridden core container from).&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;It&apos;s almost 3 years since this was raised. If nothing else, could we at least have a flag that can be used to disable this destructive by default behaviour through the solr.in?&lt;/p&gt;</comment>
                            <comment id="17480124" author="koendg" created="Fri, 21 Jan 2022 15:03:53 +0000"  >&lt;p&gt;On my end, we implemented a daily backup of solr.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://solr.apache.org/guide/8_2/making-and-restoring-backups.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://solr.apache.org/guide/8_2/making-and-restoring-backups.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;action=BACKUP and action=RESTORE basically. A cronjob that runs it once per day and a script that can perform the RESTORE.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;As for this code, I wouldn&apos;t know how to properly change anything here.&lt;/p&gt;</comment>
                            <comment id="17682548" author="JIRAUSER298947" created="Tue, 31 Jan 2023 12:43:55 +0000"  >&lt;p&gt;I&apos;ve created a draft PR to add a flag to just disable this behavior, &lt;a href=&quot;https://github.com/apache/solr/pull/1321&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/solr/pull/1321&lt;/a&gt;. It still needs a test and some other things, but hopefully it&apos;s a starting point for discussion and getting this fixed in Solr itself.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=caomanhdat&quot; class=&quot;user-hover&quot; rel=&quot;caomanhdat&quot;&gt;caomanhdat&lt;/a&gt; added a comment - 04/Oct/19 13:39&lt;br/&gt;
Yeah I mean rather than coming up with something complicated. Should we just improve the logic here so most of the cases will be solved. I.E: check existence of clusterstate before delete core.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I think that even with improvements to the logic, I would still prefer to have an override that disables automatic deletion of cores. In fact I would prefer to have to explicitly enable automatic deletion if I want to opt-in to it.&lt;/p&gt;

&lt;p&gt;Personally, I think the only time I want a core to be deleted automatically is if the creation of a new collection/core fails. Otherwise it just makes me very nervous. I can always clean things up manually, but I can&apos;t undelete without a fresh backup (though obviously regular backups are needed as well but that&apos;s not the point for me).&lt;/p&gt;</comment>
                            <comment id="17682640" author="dsmiley" created="Tue, 31 Jan 2023 16:29:13 +0000"  >&lt;p&gt;Just reviewed the description &amp;amp; conversation here. &#160;It seems the scenario to guard against is the wrong ZK being referenced (for whatever reason, to include ZK getting wiped clean). In such a scenario &lt;b&gt;every&lt;/b&gt; core on disk will not be linked to a replica in ZK. &#160;If this happens, I think we can, by default, take no deletion action. &#160;Perhaps even shutdown Solr. &#160;Configuration options to toggle this are okay but it&apos;d be nice to improve the default behavior because people won&apos;t find this configuration option and use it unless they&apos;ve been burned &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="17682660" author="JIRAUSER298947" created="Tue, 31 Jan 2023 17:04:33 +0000"  >&lt;blockquote&gt;&lt;p&gt;It seems the scenario to guard against is the wrong ZK being referenced (for whatever reason, to include ZK getting wiped clean). In such a scenario every core on disk will not be linked to a replica in ZK.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;That does sound fair in general, though I think there&apos;s still other scenarios where that isn&apos;t the case.&lt;/p&gt;

&lt;p&gt;For example, if I have a test system &lt;b&gt;A&lt;/b&gt; and a prod system &lt;b&gt;B&lt;/b&gt;, and system &lt;b&gt;B&lt;/b&gt; has some extra collections in it. I accidentally connect Solr &lt;b&gt;B&lt;/b&gt; to ZooKeeper &lt;b&gt;A&lt;/b&gt;, which has a subset of &lt;b&gt;A&lt;/b&gt;&apos;s collections, then the rest get wiped. (Granted there&apos;s other issues there as I shouldn&apos;t really be able to connect to prod by mistake, but it happens).&lt;br/&gt;
Or perhaps if I fail to properly restore a ZooKeeper backup after some sort of corruption?&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Configuration options to toggle this are okay but it&apos;d be nice to improve the default behavior because people won&apos;t find this configuration option and use it unless they&apos;ve been burned &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I definitely agree. My preference would be to default to not automatically deleting cores, and instead set configuration to enable that. But as that&apos;s a behavior change, I thought I would start with a flag to disable it as being less contentious.&lt;/p&gt;

&lt;p&gt;Making the code itself more sensitive to misconfiguration vs a core that was left behind by accident would be great as well, but I don&apos;t know the code well enough to address that myself. And I would still be inclined to make the deletion optional in any case (ideally with an opt-in), so I think there&apos;s value in having a config option with or without improvements to the logic?&lt;/p&gt;</comment>
                            <comment id="17738470" author="jira-bot" created="Thu, 29 Jun 2023 10:17:51 +0000"  >&lt;p&gt;Commit c8ee862b7a8c39b3ee9f43fbdcee80799d56f3df in solr&apos;s branch refs/heads/main from Colvin Cowie&lt;br/&gt;
[ &lt;a href=&quot;https://gitbox.apache.org/repos/asf?p=solr.git;h=c8ee862b7a8&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gitbox.apache.org/repos/asf?p=solr.git;h=c8ee862b7a8&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-13396&quot; title=&quot;SolrCloud will delete the core data for any core that is not referenced in the clusterstate&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-13396&quot;&gt;&lt;del&gt;SOLR-13396&lt;/del&gt;&lt;/a&gt; - Disable deletion of unknown cores by default (#1321)&lt;/p&gt;

&lt;p&gt;Previous behavior is now disabled by default, set -Dsolr.deleteUnknownCores=true to use the old behavior.&lt;/p&gt;</comment>
                            <comment id="17738515" author="jira-bot" created="Thu, 29 Jun 2023 11:42:36 +0000"  >&lt;p&gt;Commit 894748c7ca67e24d3e817c8bcd18bcb0808de265 in solr&apos;s branch refs/heads/branch_9x from Colvin Cowie&lt;br/&gt;
[ &lt;a href=&quot;https://gitbox.apache.org/repos/asf?p=solr.git;h=894748c7ca6&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gitbox.apache.org/repos/asf?p=solr.git;h=894748c7ca6&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-13396&quot; title=&quot;SolrCloud will delete the core data for any core that is not referenced in the clusterstate&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-13396&quot;&gt;&lt;del&gt;SOLR-13396&lt;/del&gt;&lt;/a&gt; - Disable deletion of unknown cores by default (#1321)&lt;/p&gt;

&lt;p&gt;Previous behavior is now disabled by default, set -Dsolr.deleteUnknownCores=true to use the old behavior.&lt;/p&gt;</comment>
                            <comment id="17738565" author="jira-bot" created="Thu, 29 Jun 2023 13:08:50 +0000"  >&lt;p&gt;Commit a844cbbad68a9816e8ca86be4eafe11e96c4415e in solr&apos;s branch refs/heads/main from Colvin Cowie&lt;br/&gt;
[ &lt;a href=&quot;https://gitbox.apache.org/repos/asf?p=solr.git;h=a844cbbad68&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gitbox.apache.org/repos/asf?p=solr.git;h=a844cbbad68&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-13396&quot; title=&quot;SolrCloud will delete the core data for any core that is not referenced in the clusterstate&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-13396&quot;&gt;&lt;del&gt;SOLR-13396&lt;/del&gt;&lt;/a&gt; - Tidy up the upgade notes&lt;/p&gt;</comment>
                            <comment id="17738567" author="jira-bot" created="Thu, 29 Jun 2023 13:09:08 +0000"  >&lt;p&gt;Commit 1896bf0385ac3a5f917884b6427989750a67510b in solr&apos;s branch refs/heads/branch_9x from Colvin Cowie&lt;br/&gt;
[ &lt;a href=&quot;https://gitbox.apache.org/repos/asf?p=solr.git;h=1896bf0385a&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gitbox.apache.org/repos/asf?p=solr.git;h=1896bf0385a&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-13396&quot; title=&quot;SolrCloud will delete the core data for any core that is not referenced in the clusterstate&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-13396&quot;&gt;&lt;del&gt;SOLR-13396&lt;/del&gt;&lt;/a&gt; - Tidy up the upgade notes&lt;/p&gt;</comment>
                            <comment id="17761310" author="JIRAUSER301703" created="Fri, 1 Sep 2023 13:12:20 +0000"  >&lt;p&gt;From 9.3 onwards this functionality is no longer enabled by default &lt;a href=&quot;https://solr.apache.org/guide/solr/latest/upgrade-notes/major-changes-in-solr-9.html#deletion-of-unknown-cores-is-now-disabled-by-default&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://solr.apache.org/guide/solr/latest/upgrade-notes/major-changes-in-solr-9.html#deletion-of-unknown-cores-is-now-disabled-by-default&lt;/a&gt; if there&apos;s any desire to improve the functionality when it is enabled then raise a new issue.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13143465">SOLR-12066</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 10 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z01pj4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313321" key="com.atlassian.jira.toolkit:message">
                        <customfieldname>Solr Mailing List Info</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>