<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 04:14:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SOLR-9290] TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease</title>
                <link>https://issues.apache.org/jira/browse/SOLR-9290</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;Heavy indexing on Solr with SSL leads to a lot of connections in CLOSE_WAIT state. &lt;/p&gt;

&lt;p&gt;At my workplace, we have seen this issue only with 5.5.1 and could not reproduce it with 5.4.1 but from my conversation with Shalin, he knows of users with 5.3.1 running into this issue too. &lt;/p&gt;

&lt;p&gt;Here&apos;s an excerpt from the email &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shaie&quot; class=&quot;user-hover&quot; rel=&quot;shaie&quot;&gt;shaie&lt;/a&gt; sent to the mailing list  (about what we see:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;1) It consistently reproduces on 5.5.1, but &lt;b&gt;does not&lt;/b&gt; reproduce on 5.4.1&lt;br/&gt;
2) It does not reproduce when SSL is disabled&lt;br/&gt;
3) Restarting the Solr process (sometimes both need to be restarted), the&lt;br/&gt;
count drops to 0, but if indexing continues, they climb up again&lt;/p&gt;

&lt;p&gt;When it does happen, Solr seems stuck. The leader cannot talk to the&lt;br/&gt;
replica, or vice versa, the replica is usually put in DOWN state and&lt;br/&gt;
there&apos;s no way to fix it besides restarting the JVM.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Here&apos;s the mail thread: &lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/lucene-solr-user/201607.mbox/%3C46cc66220a8143dc903fa34e792059c4@vp-exc01.dips.local%3E&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://mail-archives.apache.org/mod_mbox/lucene-solr-user/201607.mbox/%3C46cc66220a8143dc903fa34e792059c4@vp-exc01.dips.local%3E&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Creating this issue so we could track this and have more people comment on what they see. &lt;/p&gt;</description>
                <environment></environment>
        <key id="12987521">SOLR-9290</key>
            <summary>TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="shalin">Shalin Shekhar Mangar</assignee>
                                    <reporter username="anshum">Anshum Gupta</reporter>
                        <labels>
                    </labels>
                <created>Thu, 7 Jul 2016 16:02:17 +0000</created>
                <updated>Thu, 21 Nov 2019 00:41:43 +0000</updated>
                            <resolved>Fri, 15 Jul 2016 19:30:58 +0000</resolved>
                                    <version>5.3.2</version>
                    <version>5.4.1</version>
                    <version>5.5.1</version>
                    <version>5.5.2</version>
                    <version>6.0</version>
                    <version>6.0.1</version>
                    <version>6.1</version>
                                    <fixVersion>5.5.3</fixVersion>
                    <fixVersion>6.2</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>21</watches>
                                                                                                                <comments>
                            <comment id="15367313" author="jsm" created="Fri, 8 Jul 2016 06:54:52 +0000"  >&lt;p&gt;We have the same issue on Solr 6.1.0&lt;/p&gt;</comment>
                            <comment id="15371758" author="hossman" created="Mon, 11 Jul 2016 22:16:19 +0000"  >&lt;p&gt;questions specifically for &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shaie&quot; class=&quot;user-hover&quot; rel=&quot;shaie&quot;&gt;shaie&lt;/a&gt; followng up on comments made in the mailing list thread mentioned in the isue summary...&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When it does happen, the number of CLOSE_WAITS climb very high, to the order of 30K+ entries in &apos;netstat&apos;.&lt;br/&gt;
...&lt;br/&gt;
When I say it does not reproduce on 5.4.1 I really mean the numbers&lt;br/&gt;
don&apos;t go as high as they do in 5.5.1. Meaning, when running without&lt;br/&gt;
SSL, the number of CLOSE_WAITs is smallish, usually less than a 10 (I&lt;br/&gt;
would separately like to understand why we have any in that state at&lt;br/&gt;
all). When running with SSL and 5.4.1, they stay low at the order of&lt;br/&gt;
hundreds the most.&lt;/p&gt;&lt;/blockquote&gt;

&lt;ul&gt;
	&lt;li&gt;Does this only reproduce in your application, with your customized configs of Solr, or can you reproduce it using something trivial like &quot;modify bin/solr.in.sh to point at an SSL cert, then run; &lt;tt&gt;bin/solr -noprompt -cloud&lt;/tt&gt;.&quot; ?&lt;/li&gt;
	&lt;li&gt;Does the problem only manifest solely with indexing, or with queries as well? ie...
	&lt;ul&gt;
		&lt;li&gt;assuming a pre-built collection, and then all nodes restarted, does hammering the cluster with read only queries manifest the problem?&lt;/li&gt;
		&lt;li&gt;assuming a virgin cluster with no docs, does hammering the cluster w/updates but never any queries, manifest the problem?&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Assuming you start by bringing up a virgin cluster and then begin hammering it with whatever sequences of requests are needed to manifest the problem, how long do you have to wait before the number of CLOSE_WAITS spikes high enough that you are reasonably confident the problem has occured?&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;The last question being a pre-req to wondering if we can just git bisect to identify where/when the problem originated.  &lt;/p&gt;

&lt;p&gt;Even if writing a (reliable) bash automation script (to start the cluster, &lt;em&gt;and&lt;/em&gt; triggering requests, &lt;em&gt;and&lt;/em&gt; monitoring the CLOSE_WAITS to see if they go over a specified threshold in under a specified timelimit, &lt;em&gt;and&lt;/em&gt; shut everything down cleanly) is too cumbersome to have faith in running an automated &lt;tt&gt;git bisect run test.sh&lt;/tt&gt;, we could still consider doing some manually driven git bisection to try and track this down, as long as each iteration doesn&apos;t take very long.&lt;/p&gt;

&lt;p&gt;Specifically: &lt;tt&gt;git merge-base&lt;/tt&gt; says ffadf9715c4a511178183fc1411b18c1701b9f1d is the common ancestor for 5.4.1 and 5.5.1, and &lt;tt&gt;git log&lt;/tt&gt; says there are 487 commits between that point and the 5.5.1 tag.  Statistically speaking it should only take &lt;br/&gt;
~10 iterations to do a binary search of those commits to find the first problematic one.&lt;/p&gt;

&lt;p&gt;Assuming there is a manual process someone can run on a clean git checkout of 5.4.1 that takes under 10 minutes to get from &quot;ant clean server&quot; to an obvious splke in CLOSE_WAITS, someone with some CPU cycles to spare who doesn&apos;t mind a lot of context switching while they do their day job could be...&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;running a command to spin up the cluster &amp;amp; client hammering code&lt;/li&gt;
	&lt;li&gt;setting a 10 minute timer&lt;/li&gt;
	&lt;li&gt;when the timer goes off, check the results of another command to count the CLOSE_WAITS&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;git bisect good/bad&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;repeat&lt;br/&gt;
...and within ~2-3 hours should almost certainly have tracked down when/where the problem started.&lt;/li&gt;
&lt;/ol&gt;

</comment>
                            <comment id="15373452" author="shalinmangar" created="Tue, 12 Jul 2016 18:51:38 +0000"  >&lt;p&gt;It is reproducible very easily on stock solr with SSL enabled. My test setup creates two SSL-enabled Solr instances with a 5 shard x 2 replica collection and runs a short indexing program (just 9 update requests with 1 document each and a commit at the end). Keep on running the indexing program repeatedly and the number of connections in the CLOSE_WAIT state gradually increase.&lt;/p&gt;

&lt;p&gt;Interestingly, the number of connections stuck in CLOSE_WAIT decrease during indexing and increase again about 10 or so seconds after the indexing is stopped.&lt;/p&gt;

&lt;p&gt;I can reproduce the problem on 6.1, 6.0, 5.5.1, 5.3.2. I am not able to reproduce this on master although I don&apos;t see anything relevant that has changed since 6.1 &amp;#8211; I tried this only once so it may have just been bad timing?&lt;/p&gt;

&lt;p&gt;When the connections show in CLOSE_WAIT state, the recv-q buffer always has exactly 70 bytes.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;netstat -tonp | grep CLOSE_WAIT | grep java
tcp       70      0 127.0.0.1:56538         127.0.1.1:8983          CLOSE_WAIT  21654/java       off (0.00/0/0)
tcp       70      0 127.0.0.1:47995         127.0.1.1:8984          CLOSE_WAIT  21654/java       off (0.00/0/0)
tcp       70      0 127.0.0.1:47477         127.0.1.1:8984          CLOSE_WAIT  21654/java       off (0.00/0/0)
tcp       70      0 127.0.0.1:47996         127.0.1.1:8984          CLOSE_WAIT  21654/java       off (0.00/0/0)
tcp       70      0 127.0.0.1:56644         127.0.1.1:8983          CLOSE_WAIT  21654/java       off (0.00/0/0)
tcp       70      0 127.0.0.1:56533         127.0.1.1:8983          CLOSE_WAIT  21654/java       off (0.00/0/0)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If I run the same steps with SSL disabled then the connections in CLOSE_WAIT state have just 1 byte in recv-q. I don&apos;t see the number of such connections increasing with indexing over time but I know for a fact (from a client) that eventually more and more connections pile up in this state even without SSL.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;tcp       1      0 127.0.0.1:41723         127.0.1.1:8983          CLOSE_WAIT  2522/java        off (0.00/0/0)
tcp       1      0 127.0.0.1:41780         127.0.1.1:8983          CLOSE_WAIT  2640/java        off (0.00/0/0)
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I enabled debug logging for PoolingHttpClientConnectionManager (used in 6.x) and PoolingClientConnectionManager (used in 5.x.x) and after running the indexing program and verifying that some connections are in CLOSE_WAIT, I grepped the logs for connections leased vs released and I always find the number to be the same which means that the connections are always given back to the pool.&lt;/p&gt;

&lt;p&gt;Now some connections hanging around in CLOSE_WAIT are to be expected because of the following (quoted from the httpclient documentation):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One of the major shortcomings of the classic blocking I/O model is that the network socket can react to I/O events only when blocked in an I/O operation. When a connection is released back to the manager, it can be kept alive however it is unable to monitor the status of the socket and react to any I/O events. If the connection gets closed on the server side, the client side connection is unable to detect the change in the connection state (and react appropriately by closing the socket on its end).&lt;br/&gt;
HttpClient tries to mitigate the problem by testing whether the connection is &apos;stale&apos;, that is no longer valid because it was closed on the server side, prior to using the connection for executing an HTTP request. The stale connection check is not 100% reliable. The only feasible solution that does not involve a one thread per socket model for idle connections is a dedicated monitor thread used to evict connections that are considered expired due to a long period of inactivity. The monitor thread can periodically call ClientConnectionManager#closeExpiredConnections() method to close all expired connections and evict closed connections from the pool. It can also optionally call ClientConnectionManager#closeIdleConnections() method to close all connections that have been idle over a given period of time.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m going to try adding such a monitor thread and see if this is still a problem.&lt;/p&gt;</comment>
                            <comment id="15373469" author="shalinmangar" created="Tue, 12 Jul 2016 18:58:55 +0000"  >&lt;p&gt;The setup-solr.sh is small script that I use to setup different versions with SSL enabled and debug logging enabled for httpclient.&lt;/p&gt;

&lt;p&gt;The debug logging looks like the following:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2016-07-12 13:25:05.692 DEBUG (httpShardExecutor-4-thread-7-processing-x:xyz_shard3_replica1 r:core_node5 https:&lt;span class=&quot;code-comment&quot;&gt;////127.0.1.1:8983//solr//xyz_shard3_replica2// n:127.0.1.1:8984_solr s:shard3 c:xyz [https:////127.0.1.1:8983//solr//xyz_shard3_replica2//]) [c:xyz s:shard3 r:core_node5 x:xyz_shard3_replica1] o.a.h.i.c.PoolingClientConnectionManager Connection leased: [id: 17][route: {s}-&amp;gt;https://127.0.1.1:8983][total kept alive: 0; route allocated: 5 of 100000; total allocated: 5 of 100000]
&lt;/span&gt;...
2016-07-12 13:25:05.791 DEBUG (recoveryExecutor-3-thread-4-processing-n:127.0.1.1:8984_solr x:xyz_shard1_replica1 s:shard1 c:xyz r:core_node2) [c:xyz s:shard1 r:core_node2 x:xyz_shard1_replica1] o.a.h.i.c.PoolingClientConnectionManager Connection released: [id: 17][route: {s}-&amp;gt;https:&lt;span class=&quot;code-comment&quot;&gt;//127.0.1.1:8983][total kept alive: 8; route allocated: 8 of 100000; total allocated: 8 of 100000]&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The attached &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9290&quot; title=&quot;TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9290&quot;&gt;&lt;del&gt;SOLR-9290&lt;/del&gt;&lt;/a&gt;-debug.patch applies to 5.3.x and changes HttpSolrClient to log the connection details including the client port number for each request.&lt;/p&gt;</comment>
                            <comment id="15374478" author="mbjorgan" created="Wed, 13 Jul 2016 07:01:19 +0000"  >&lt;p&gt;I performed a bisect, yielding some commit of 5.4.1 as good, and a commit from 5.5.3 as bad. This gave the following commit: ad9b87a7285e444cd61fffb83c0aee06c8f7cef0, as the first bad commit. However, this commit only increases the limits on how many update connections that can be open. I built Solr on top of the last commit from branch_5_4 (7d52c2523c7a4ff70612742b76b934a12b493331), and implemented the commit that was supposed to be bad, and ended up with the same CLOSE_WAIT-leak. Thus - this problem affects version 5.4.1 aswell - but is harder to see as Solr isn&apos;t allowed to use that many connections when updating.&lt;/p&gt;</comment>
                            <comment id="15374779" author="shaie" created="Wed, 13 Jul 2016 10:15:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;Interestingly, the number of connections stuck in CLOSE_WAIT decrease during indexing and increase again about 10 or so seconds after the indexing is stopped.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve observed that too and it&apos;s not that they decrease, but rather that the connections change their state from CLOSE_WAIT to ESTABLISHED, then when indexing is done to TIME_WAIT and then finally to CLOSE_WAIT again. I believe this aligns with what the HC documentation says &amp;#8211; the connections are not necessarily released, but kept in the pool. When you re-index again, they are reused and go back to the pool.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;However, this commit only increases the limits on how many update connections that can be open&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That&apos;s interesting and might be a temporary workaround for the problem, which I intend to test shortly. In 5.4.1 they were both modified to 100,000:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;-  public static final int DEFAULT_MAXUPDATECONNECTIONS = 10000;
-  public static final int DEFAULT_MAXUPDATECONNECTIONSPERHOST = 100;
+  public static final int DEFAULT_MAXUPDATECONNECTIONS = 100000;
+  public static final int DEFAULT_MAXUPDATECONNECTIONSPERHOST = 100000;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This can explain why we run into trouble with 5.5.1 but not with 5.4.1. Though even in 5.4.1 there are few hundreds of CLOSE_WAIT connections, with 5.5.1 they reach (in our case) the orders of 35-40K, at which point Solr became useless, not being able to talk to the replica or pretty much anything else.&lt;/p&gt;

&lt;p&gt;I see these can be defined in solr.xml, though it&apos;s not documented how, so I&apos;m going to give it a try and will report back here.&lt;/p&gt;</comment>
                            <comment id="15375082" author="shaie" created="Wed, 13 Jul 2016 14:19:29 +0000"  >&lt;p&gt;An update &amp;#8211; I&apos;ve modified our solr.xml (which is basically the vanilla solr.xml) with these added props (under the &lt;tt&gt;solrcloud&lt;/tt&gt; element) and I do not see the connections spike anymore:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    &amp;lt;int name=&quot;maxUpdateConnections&quot;&amp;gt;10000&amp;lt;/int&amp;gt;
    &amp;lt;int name=&quot;maxUpdateConnectionsPerHost&quot;&amp;gt;100&amp;lt;/int&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Those changes were part of &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8533&quot; title=&quot;Raise default maxUpdateConnections and maxUpdateConnectionsPerHost to 100k each.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8533&quot;&gt;&lt;del&gt;SOLR-8533&lt;/del&gt;&lt;/a&gt;. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markrmiller%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;markrmiller@gmail.com&quot;&gt;markrmiller@gmail.com&lt;/a&gt; on that issue you didn&apos;t explain why the defaults need to be set that high. Was there perhaps an email thread you can link to which includes more details? I ask because one thing I&apos;ve noticed is that if I query &lt;tt&gt;solr/admin/info/system&lt;/tt&gt;, the &lt;tt&gt;system.openFileDescriptorCount&lt;/tt&gt; is very high when there are many CLOSE_WAITs. Such a change in Solr default probably need to be accompanied by an OS-level setting too, no?&lt;/p&gt;

&lt;p&gt;I am still running tests with those props set in solr.xml, on top of 5.5.1. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mbjorgan&quot; class=&quot;user-hover&quot; rel=&quot;mbjorgan&quot;&gt;mbjorgan&lt;/a&gt; would you mind testing in your environment too?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=hossman%40fucit.org&quot; class=&quot;user-hover&quot; rel=&quot;hossman@fucit.org&quot;&gt;hossman@fucit.org&lt;/a&gt;, sorry I completely missed your questions. Our solr.xml is the vanilla one, we didn&apos;t modify anything in it. We did uncomment the SSL props in solr.in.sh as the ref guide says, but aside from the key name and password, we didn&apos;t change any settings.&lt;/p&gt;</comment>
                            <comment id="15375117" author="markrmiller@gmail.com" created="Wed, 13 Jul 2016 14:35:44 +0000"  >&lt;p&gt;The defaults need to be very high to avoid distributed deadlock.&lt;/p&gt;</comment>
                            <comment id="15375151" author="shaie" created="Wed, 13 Jul 2016 14:53:36 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markrmiller%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;markrmiller@gmail.com&quot;&gt;markrmiller@gmail.com&lt;/a&gt;. In that case, what&apos;s your take on the issue at hand?&lt;/p&gt;</comment>
                            <comment id="15375184" author="shaie" created="Wed, 13 Jul 2016 15:08:40 +0000"  >&lt;p&gt;Also &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markrmiller%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;markrmiller@gmail.com&quot;&gt;markrmiller@gmail.com&lt;/a&gt;, for education purposes, if you have a link to a discussion about why it may lead to a distributed deadlock, I&apos;d be happy to read it.&lt;/p&gt;</comment>
                            <comment id="15375243" author="yseeley@gmail.com" created="Wed, 13 Jul 2016 15:53:21 +0000"  >&lt;blockquote&gt;&lt;p&gt;if you have a link to a discussion about why it may lead to a distributed deadlock, I&apos;d be happy to read it.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-683&quot; title=&quot;Distributed Search / Shards Deadlock&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-683&quot;&gt;&lt;del&gt;SOLR-683&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Same logic applies to any internal general purpose thread pools or connection pools / connection limits.  Think of acquiring a thread like acquiring a lock.  If there are going to be a limited number of resources, then one needs to be very careful under what circumstances those resources can be acquired.&lt;/p&gt;</comment>
                            <comment id="15375500" author="shaie" created="Wed, 13 Jul 2016 18:31:59 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yonik%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;yonik@apache.org&quot;&gt;yonik@apache.org&lt;/a&gt;, I&apos;ll read the issue.&lt;/p&gt;

&lt;p&gt;I agree with what you write in general, but we do hit an issue with these settings. That that it reproduces easily with SSL enabled suggests that the issue may not be in Solr code at all, but I wonder if we shouldn&apos;t perhaps pick smaller default values if SSL is enabled? (Our guess at the moment is that HC keeps more connections in the pool when SSL is enabled because they are more expensive to initiate, but it&apos;s just a guess).&lt;/p&gt;

&lt;p&gt;And maybe the proper solution would be what &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt; wrote above &amp;#8211; have a bg monitor which closes idle/expired connections. I actually wonder why it can&apos;t be a property of &lt;tt&gt;ClientConnectionManager&lt;/tt&gt; that you can set to auto close idle/expired connections after a period of time. We can potentially have that monitor act only if SSL is enabled (or at least until non-SSL exhibits the same problems too).&lt;/p&gt;</comment>
                            <comment id="15375534" author="anshumg" created="Wed, 13 Jul 2016 18:55:14 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt; mentioned that he&apos;s able to reproduce this in 5.3.2 as well, which was without &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8533&quot; title=&quot;Raise default maxUpdateConnections and maxUpdateConnectionsPerHost to 100k each.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8533&quot;&gt;&lt;del&gt;SOLR-8533&lt;/del&gt;&lt;/a&gt; so we certainly need to look at this more.&lt;/p&gt;

&lt;p&gt;Shalin, can you confirm if you were running your tests in stock Solr ?&lt;/p&gt;</comment>
                            <comment id="15375537" author="shalinmangar" created="Wed, 13 Jul 2016 18:58:05 +0000"  >&lt;p&gt;This patch applies on 5.3.2. This patch adds a monitor thread for the pool created in UpdateShardHandler and with this applied, I cannot reproduce this problem anymore. There are still a few connections in CLOSE_WAIT at steady state but I verified that they belong to a different HttpClient instance in HttpShardHandlerFactory and other places.&lt;/p&gt;

&lt;p&gt;My hypothesis is that: We have a large limit for maxConnections and maxConnectionsPerHost. As long as the limit isn&apos;t met and the servers are decently busy, new connections will continue to be created from the pool. In 5.x and 6.x, we do not have a policy of closing idle connections so httpclient will keep these connections in CLOSE_WAIT for reuse. So we must periodically close such connections once they&apos;re idle to avoid the number of such connections increasing to absurd limits.&lt;/p&gt;

&lt;p&gt;Also, I think the reason this wasn&apos;t reproducible on master is because &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-4509&quot; title=&quot;Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-4509&quot;&gt;&lt;del&gt;SOLR-4509&lt;/del&gt;&lt;/a&gt; enabled eviction of idle connections by calling HttpClientBuilder#evictIdleConnections with a 50 second limit.&lt;/p&gt;</comment>
                            <comment id="15375541" author="shalinmangar" created="Wed, 13 Jul 2016 19:02:02 +0000"  >&lt;blockquote&gt;
&lt;p&gt;Shalin Shekhar Mangar mentioned that he&apos;s able to reproduce this in 5.3.2 as well, which was without &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8533&quot; title=&quot;Raise default maxUpdateConnections and maxUpdateConnectionsPerHost to 100k each.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8533&quot;&gt;&lt;del&gt;SOLR-8533&lt;/del&gt;&lt;/a&gt; so we certainly need to look at this more.&lt;/p&gt;

&lt;p&gt;Shalin, can you confirm if you were running your tests in stock Solr ?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Actually it is 5.3.2 with some kerberos patches but the client which originally reported the issue was using stock 5.3.2. I don&apos;t think the changes are relevant.&lt;/p&gt;

&lt;p&gt;I believe this was a problem all along. It just got amplified with &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8533&quot; title=&quot;Raise default maxUpdateConnections and maxUpdateConnectionsPerHost to 100k each.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8533&quot;&gt;&lt;del&gt;SOLR-8533&lt;/del&gt;&lt;/a&gt; in 5.5.x because now the limit is higher.&lt;/p&gt;</comment>
                            <comment id="15375548" author="shaie" created="Wed, 13 Jul 2016 19:06:18 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt;. Few questions:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Also, I think the reason this wasn&apos;t reproducible on master is because &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-4509&quot; title=&quot;Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-4509&quot;&gt;&lt;del&gt;SOLR-4509&lt;/del&gt;&lt;/a&gt; enabled eviction of idle threads by calling HttpClientBuilder#evictIdleConnections with a 50 second limit.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Is this something we can apply to 5x/6x too?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This patch adds a monitor thread for the pool created in UpdateShardHandler and with this applied&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I didn&apos;t see the monitor in the latest patch, only the log printouts. Did you forget to add it?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;There are still a few connections in CLOSE_WAIT at steady state but I verified that they belong to a different HttpClient instance in HttpShardHandlerFactory and other places.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;(1) Can/Should we have a similar monitor for HttpShardHandlerFactory?&lt;br/&gt;
(2) Any reason why the two don&apos;t share the same HttpClient instance?&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;This patch applies on 5.3.2&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;We have a large limit for maxConnections and maxConnectionsPerHost&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I thought that hypothesis holds only after &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8533&quot; title=&quot;Raise default maxUpdateConnections and maxUpdateConnectionsPerHost to 100k each.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8533&quot;&gt;&lt;del&gt;SOLR-8533&lt;/del&gt;&lt;/a&gt;. Are you saying you also saw it on 5.3.2? If so, what are the values that are set for these properties there? We definitely &lt;b&gt;do not&lt;/b&gt; see the problem with 5.4.1, but we didn&apos;t test prior versions.&lt;/p&gt;</comment>
                            <comment id="15375552" author="shaie" created="Wed, 13 Jul 2016 19:08:25 +0000"  >&lt;blockquote&gt;&lt;p&gt;I thought that hypothesis holds only after &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8533&quot; title=&quot;Raise default maxUpdateConnections and maxUpdateConnectionsPerHost to 100k each.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8533&quot;&gt;&lt;del&gt;SOLR-8533&lt;/del&gt;&lt;/a&gt;. Are you saying you also saw it on 5.3.2? If so, what are the values that are set for these properties there? We definitely do not see the problem with 5.4.1, but we didn&apos;t test prior versions.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We posted at the same time, I read your answer above. I wonder why we don&apos;t see the problem with 5.4.1. I mean, we do see CLOSE_WAITs piling, but stop at ~100 (200 for the leader).&lt;/p&gt;</comment>
                            <comment id="15375560" author="shalinmangar" created="Wed, 13 Jul 2016 19:15:05 +0000"  >&lt;blockquote&gt;&lt;p&gt;I didn&apos;t see the monitor in the latest patch, only the log printouts. Did you forget to add it?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sorry &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shaie&quot; class=&quot;user-hover&quot; rel=&quot;shaie&quot;&gt;shaie&lt;/a&gt;, I noticed that after uploaded. I have uploaded the right patch now. Please review.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;(1) Can/Should we have a similar monitor for HttpShardHandlerFactory?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think so. This patch was only for my tests.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Any reason why the two don&apos;t share the same HttpClient instance?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hmm. I think originally the idea was to keep the pools for indexing and querying separate but now that the limit (for updates) is so high, I wonder if it still makes sense. I mean, yes you can deadlock a distributed search because of high indexing and vice-versa if you share the pool but if you ever reach the high limit of 100,000 connections, you have more serious problems in the cluster anyway.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I wonder why we don&apos;t see the problem with 5.4.1. I mean, we do see CLOSE_WAITs piling, but stop at ~100 (200 for the leader)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Do you have only two replicas? Perhaps the maxConnectionsPerHost limit of 100 is kicking in?&lt;/p&gt;</comment>
                            <comment id="15375571" author="shaie" created="Wed, 13 Jul 2016 19:22:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;Do you have only two replicas? Perhaps the maxConnectionsPerHost limit of 100 is kicking in?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yes, we do have only 2 replicas and I get why the CLOSE_WAITs stop at 100. I was asking about 5.3.2 &amp;#8211; how could CLOSE_WAITs get high in 5.3.2 when maxConnectionsPerHost was the same as in 5.4.1?&lt;/p&gt;</comment>
                            <comment id="15375582" author="shaie" created="Wed, 13 Jul 2016 19:28:09 +0000"  >&lt;p&gt;Regarding the patch, the monitor looks good. Few comments:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I prefer that we name it &lt;tt&gt;IdleConnectionsMonitor&lt;/tt&gt; (w/ &apos;s&apos;, plural connections). It goes for the class, field and thread name.&lt;/li&gt;
	&lt;li&gt;Do you intend to keep all the log statements around?&lt;/li&gt;
	&lt;li&gt;Do you think we should make the polling interval (10s) and idle-connections-time (50s) configurable? Perhaps through system properties?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15375589" author="shalinmangar" created="Wed, 13 Jul 2016 19:31:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;I was asking about 5.3.2 &#8211; how could CLOSE_WAITs get high in 5.3.2 when maxConnectionsPerHost was the same as in 5.4.1?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;5.3.2 has maxConnectionsPerHost=100 for updates and maxConnectionsPerHost=20 for queries. So on a leader you may have 100*replicationFactor+20*numShards*replicationFactor connections. For a large cluster with many shards and replicas, the overall number of such connections can be quite high.&lt;/p&gt;</comment>
                            <comment id="15375601" author="shaie" created="Wed, 13 Jul 2016 19:35:51 +0000"  >&lt;p&gt;Oh I see. So we didn&apos;t experience the problem because we run w/ 2 replicas (and one shard currently) and with 5.4.1&apos;s settings the math for us results in a low number of connections. But someone running a larger Solr deployment could already hit that problem prior to 5.5. Thanks for the clarification!&lt;/p&gt;</comment>
                            <comment id="15375666" author="davidabradley" created="Wed, 13 Jul 2016 20:21:15 +0000"  >&lt;p&gt;I don&apos;t understand why the preferred approach here is to just have a thread that is trying to close connections. Is the problem that these connections would never otherwise be closed? If that is the case, why can&apos;t we solve the problem of them not being closed as a part of their normal usage? It sounds like master doesn&apos;t have this problem because of different client settings? :&lt;br/&gt;
&quot;Also, I think the reason this wasn&apos;t reproducible on master is because &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-4509&quot; title=&quot;Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-4509&quot;&gt;&lt;del&gt;SOLR-4509&lt;/del&gt;&lt;/a&gt; enabled eviction of idle connections by calling HttpClientBuilder#evictIdleConnections with a 50 second limit.&quot;&lt;/p&gt;

&lt;p&gt;Why not backport that and avoid the problem entirely? Is it a different client version in master or something that makes it not that easy?&lt;/p&gt;

&lt;p&gt;&quot;So we must periodically close such connections once they&apos;re idle to avoid the number of such connections increasing to absurd limits.&quot; It seems from the discussion here that the problem is hitting a high number of connections, which is only allowed to be so high because we asked for it. What if this thread lags behind enough that the connections get too high? It sounds like the purpose of this thread is to race to prevent Solr from doing what we asked it to do.&lt;/p&gt;

&lt;p&gt;The idea of having a thread to deal with any connections that end up in a bad state unexpectedly makes sense, but is the cause of all these CLOSE_WAIT connections really from unexpected behavior?&lt;/p&gt;

&lt;p&gt;I feel like I must be missing something.&lt;/p&gt;</comment>
                            <comment id="15375727" author="slindner" created="Wed, 13 Jul 2016 20:46:26 +0000"  >&lt;p&gt;I would like to add something, too.  The problem must stem from some sort of OS-level setting.  In our environment I&apos;ve noticed that when a given IP+PORT combo reaches ~28k connections in a CLOSE_WAIT state that the OS, itself, cannot allow any more connections to that IP+PORT combo (i.e. even curl fails to that combo - but to other combos, including other ports on that same host - it works just fine).  I mention this because the problem seems related here to whatever settings we configure solr to use and you really must change these things in combination for it to ultimately make sense or you risk hitting this problem at some point - though admittedly with the bg thread it wouldn&apos;t be permanent like it is for us today.&lt;/p&gt;</comment>
                            <comment id="15375821" author="hossman" created="Wed, 13 Jul 2016 21:47:07 +0000"  >&lt;p&gt;I&apos;m no expert but...&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t understand why the preferred approach here is to just have a thread that is trying to close connections. Is the problem that these connections would never otherwise be closed? ...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;...my understanding is yes: In a situation where indexing load spikes up, you can get a lot of connections which are never completely closed. (even if they are never needed anymore)&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;...If that is the case, why can&apos;t we solve the problem of them not being closed as a part of their normal usage? ...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;again, IIUC: because they are pooled connections maintained by the HTTP layer.  Per the docs shalin quoted, clients are required to call ClientConnectionManager#closeExpiredConnections() if they (ie: &quot;we&quot;) want to ensure those connections get closed properly.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It sounds like master doesn&apos;t have this problem because of different client settings? ... Why not backport that and avoid the problem entirely? Is it a different client version in master or something that makes it not that easy?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;master &amp;amp; branch_6x (and earlier) use completely diff http client APIs (see &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-4509&quot; title=&quot;Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-4509&quot;&gt;&lt;del&gt;SOLR-4509&lt;/del&gt;&lt;/a&gt;) ... the &lt;tt&gt;HttpClientBuilder.evictIdleConnections&lt;/tt&gt; method shalin refered to being used on master is on a class (&lt;tt&gt;HttpClientBuilder&lt;/tt&gt;) that is not used at all in branch_6x.&lt;/p&gt;

&lt;p&gt;The docs of that method describe it doing virtually the same exact same thing on the (private connection pool for the) HttpClient as what Shalin&apos;s patch does (on the pool in the shared ClientConnectionManager) ...&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Makes this instance of HttpClient proactively evict idle connections from the connection pool using a background thread. 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Which makes me wonder...&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt;: why not just re-use the &lt;tt&gt;IdleConnectionEvictor&lt;/tt&gt; class provided by httpcomponents (getting the exact same underlying impl as what master gets from  &lt;tt&gt;HttpClientBuilder.evictIdleConnections&lt;/tt&gt;) ?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hc.apache.org/httpcomponents-client-4.4.x/httpclient/apidocs/org/apache/http/impl/client/IdleConnectionEvictor.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hc.apache.org/httpcomponents-client-4.4.x/httpclient/apidocs/org/apache/http/impl/client/IdleConnectionEvictor.html&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="15375885" author="hossman" created="Wed, 13 Jul 2016 22:16:53 +0000"  >&lt;p&gt;Somebody sanity check my understanding / summary description of the root issue...&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;Solr&apos;s use of HttpClient for intra-node communication has historically always had the potential to result in connections sitting &quot;idle&quot; (ie: in a CLOSE_WAIT state) for possible re-use later &amp;#8211; but these connections are kept open indefinitely.
	&lt;ul&gt;
		&lt;li&gt;For reasons I don&apos;t understand, &apos;idle&apos; connections are more likely to (exist? | be kept around indefinitely?) when  the intra-node communication is over SSL.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;maxUpdateConnections&lt;/tt&gt; and &lt;tt&gt;maxUpdateConnectionsPerHost&lt;/tt&gt; have always set hard upper limits on the number of connections that could ever be created &amp;#8211; let alone in sitting idle in a CLOSE_WAIT state.&lt;/li&gt;
	&lt;li&gt;Prior to &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8533&quot; title=&quot;Raise default maxUpdateConnections and maxUpdateConnectionsPerHost to 100k each.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8533&quot;&gt;&lt;del&gt;SOLR-8533&lt;/del&gt;&lt;/a&gt;, the default values for these limits was relatively low, making it unlikely that users could ever observe an extreme # of idle / CLOSE_WAIT threads &amp;#8211; you were more likely to have your Solr cluster crash from deadlocks then notice any serious OS level problem with too many idle connections&lt;/li&gt;
	&lt;li&gt;After &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8533&quot; title=&quot;Raise default maxUpdateConnections and maxUpdateConnectionsPerHost to 100k each.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8533&quot;&gt;&lt;del&gt;SOLR-8533&lt;/del&gt;&lt;/a&gt;, the increased default values of these limits made the problem much more noticeable&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-4509&quot; title=&quot;Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-4509&quot;&gt;&lt;del&gt;SOLR-4509&lt;/del&gt;&lt;/a&gt;&apos;s changes included use of a new option which results in a background thread checking for an existing idle connections on the master branch&lt;/li&gt;
	&lt;li&gt;This issue address the problem for branch_6x (and older) branches via a similar background thread&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15376374" author="hossman" created="Thu, 14 Jul 2016 06:05:54 +0000"  >&lt;p&gt;FWIW, I&apos;m attaching a beefed up setup-solr.sh and an index.sh i&apos;ve been testing with...&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;setup-solr.sh
	&lt;ul&gt;
		&lt;li&gt;you must edit 2 variables: the path to your lucene checkout &amp;amp; an absolute path to the SSL keystore for jetty to use (with a password &quot;secret)&lt;/li&gt;
		&lt;li&gt;spins up a 3 node cluster, then creates a collection with has 5 shards an rep factor of 3&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;index.sh
	&lt;ul&gt;
		&lt;li&gt;you must edit one variable to point at the SSL pem file for curl to use&lt;/li&gt;
		&lt;li&gt;loops forever doing a bunch of curl connections indexing the same 9 docs over and over, periodically commiting &amp;amp; sleeping, reporting the # of CLOSE_WAIT java connections at each step&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;On master, index.sh never reports &lt;em&gt;any&lt;/em&gt; CLOSE_WAIT connections for me.&lt;/p&gt;

&lt;p&gt;On branch_6x, I&apos;ll see the CLOSE_WAITS spike up to 40 - even with this (essentially) single threaded indexing, and stay at stead state even after killing the index.sh process&lt;/p&gt;

&lt;p&gt;On branch_6x, with shalin&apos;s patch, CLOSE_WAITS start at 15 (which is suspiciously 5x3) as soon as the collection is created &amp;#8211; even w/o indexing &amp;#8211; and stay steady state at 15 forever.&lt;/p&gt;

&lt;p&gt;Which begs the question: why are there 15 CLOSE_WAIT connections that last forever on branch_6x even with this patch?&lt;/p&gt;</comment>
                            <comment id="15376474" author="shaie" created="Thu, 14 Jul 2016 07:20:14 +0000"  >&lt;blockquote&gt;&lt;p&gt;Which begs the question: why are there 15 CLOSE_WAIT connections that last forever on branch_6x even with this patch?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think Shalin&apos;s patch only adds this monitor thread to &lt;tt&gt;UpdateShardHandler&lt;/tt&gt;, but not to &lt;tt&gt;HttpShardHandlerFactory&lt;/tt&gt; so these 15 could be from it?&lt;/p&gt;</comment>
                            <comment id="15376893" author="shalinmangar" created="Thu, 14 Jul 2016 13:22:07 +0000"  >&lt;p&gt;Hoss has covered most of the things but just a few comments (note that I&apos;m responding to multiple people and comments here):&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Why not backport that and avoid the problem entirely? Is it a different client version in master or something that makes it not that easy?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We could backport &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-4509&quot; title=&quot;Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-4509&quot;&gt;&lt;del&gt;SOLR-4509&lt;/del&gt;&lt;/a&gt; to 6.x and deal with the incompatible changes but I&apos;d certainly not backport it to 5x because it is just a huge change and I am not comfortable releasing that in a minor bug-fix release. I am sure many people running 5.x releases would also like a fix to this issue. Adding an idle eviction thread is trivial and unlikely to cause any regressions.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Shalin Shekhar Mangar: why not just re-use the IdleConnectionEvictor class provided by httpcomponents (getting the exact same underlying impl as what master gets from HttpClientBuilder.evictIdleConnections) ?&lt;br/&gt;
&lt;a href=&quot;https://hc.apache.org/httpcomponents-client-4.4.x/httpclient/apidocs/org/apache/http/impl/client/IdleConnectionEvictor.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hc.apache.org/httpcomponents-client-4.4.x/httpclient/apidocs/org/apache/http/impl/client/IdleConnectionEvictor.html&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I wasn&apos;t aware of this class. But looking deeper, I see that it requires a HttpClientConnectionManager instance but the 6.x and 5.x code uses the deprecated PoolingClientConnectionManager which extends ClientConnectionManager. But now that we know it exists, I can just borrow it from the httpclient project instead of writing my own evictor. It is ASLv2 anyway.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Somebody sanity check my understanding / summary description of the root issue...&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;That sounds about right to me Hoss. Thanks for the summary!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For reasons I don&apos;t understand, &apos;idle&apos; connections are more likely to (exist? | be kept around indefinitely?) when the intra-node communication is over SSL.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Perhaps the SSL setup/teardown overhead adds some latency such that concurrent requests end up opening more connections overall? I am just guessing here.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Which begs the question: why are there 15 CLOSE_WAIT connections that last forever on branch_6x even with this patch?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;As Shai said, this is likely the HttpShardHandler&apos;s pool. The overseer collection processor invokes a core admin create for each replica in parallel so you get 15 connections for 15 replicas that were created by the collection API.&lt;/p&gt;

&lt;p&gt;I&apos;m working on a new patch which applies on branch_6x that incorporates Shai&apos;s comments as well. We can then backport it to 5x.&lt;/p&gt;</comment>
                            <comment id="15376974" author="yseeley@gmail.com" created="Thu, 14 Jul 2016 14:08:01 +0000"  >&lt;p&gt;I haven&apos;t been following this issue, but this caught my eye:&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Solr&apos;s use of HttpClient for intra-node communication has historically always had the potential to result in connections sitting &quot;idle&quot; (ie: in a CLOSE_WAIT state) for possible re-use later&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;It&apos;s been a &lt;b&gt;long&lt;/b&gt; time since I messed around with making sure Solr worked with persistent connections (we&apos;re talking CNET days... 2004,2005 &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;br/&gt;
But CLOSE_WAIT is when one side has closed the connection... there&apos;s no going back to ESTABLISHED from that state (i.e. no reusing that connection).&lt;/p&gt;</comment>
                            <comment id="15377292" author="shalinmangar" created="Thu, 14 Jul 2016 17:11:06 +0000"  >&lt;p&gt;Hmm, you&apos;re right Yonik. But we&apos;ve always had an idle timeout for the http connector in jetty set to 50 seconds (I traced this back to &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-128&quot; title=&quot;Include Newer version of Jetty&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-128&quot;&gt;&lt;del&gt;SOLR-128&lt;/del&gt;&lt;/a&gt;). So after 50 seconds of inactivity, Jetty closes that connection from its end and the client&apos;s socket goes to CLOSE_WAIT state. As you said, this connection cannot be re-used anymore. When httpclient tries to use the connection, it does the stale check, sees the CLOSE_WAIT state and terminates the connection and gives a new one to Solr.&lt;/p&gt;

&lt;p&gt;So all the connections that suddenly do not show up in CLOSE_WAIT and we assumed that they went to ESTABLISHED state were actually terminated.&lt;/p&gt;

&lt;p&gt;So in summary, our assumption that connections in CLOSE_WAIT are kept around because of re-use is wrong but it still doesn&apos;t change the solution that I&apos;ve proposed. We could also think of increasing the value of Jetty&apos;s idle timeout as a separate change but the idle eviction thread would still be necessary.&lt;/p&gt;</comment>
                            <comment id="15377345" author="markrmiller@gmail.com" created="Thu, 14 Jul 2016 17:39:47 +0000"  >&lt;blockquote&gt;&lt;p&gt;why not just re-use the IdleConnectionEvictor class provided by httpcomponents&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;ve gone down this road. It&apos;s not a great solution. This is why we ended up changing to the new API&apos;s instead in &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-4509&quot; title=&quot;Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-4509&quot;&gt;&lt;del&gt;SOLR-4509&lt;/del&gt;&lt;/a&gt;. Just having an evictor thread is not enough - you also then want the ability to check connections before use if they have been sitting in the pool too long and that requires HttpClient changes they made in the new API&apos;s.&lt;/p&gt;
</comment>
                            <comment id="15377355" author="shalinmangar" created="Thu, 14 Jul 2016 17:44:13 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markrmiller%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;markrmiller@gmail.com&quot;&gt;markrmiller@gmail.com&lt;/a&gt; &amp;#8211; But you were trying to remove the stale check and disable Nagle&apos;s algorithm as well which exposed you to the NoHttpResponseExceptions. We aren&apos;t trying to do that here. We just want to close the idle connections so that they don&apos;t keep accumulating in the CLOSE_WAIT state.&lt;/p&gt;</comment>
                            <comment id="15377991" author="markrmiller@gmail.com" created="Thu, 14 Jul 2016 18:20:11 +0000"  >&lt;p&gt;Okay, I didn&apos;t catch you were not removing the stale check.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;For reasons I don&apos;t understand, &apos;idle&apos; connections are more likely to (exist? | be kept around indefinitely?) when the intra-node communication is over SSL.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think I remember reading the SSL handles connection lifecycle differently, based on the SSL spec.&lt;/p&gt;</comment>
                            <comment id="15378327" author="shalinmangar" created="Thu, 14 Jul 2016 20:37:49 +0000"  >&lt;p&gt;Patch which starts the idle connection evictor for both UpdateShardHandler and HttpShardHandlerFactory. I changed the HttpShardHandlerFactory to use an external connection pool ala UpdateShardHandler. The defaults are set to sleep for 5 seconds and expire connections and close idle connections older than 40 seconds. I chose 40 seconds because it is slightly lower than the jetty timeout of 50 seconds. Both of these values are configurable for both updates and queries.&lt;/p&gt;

&lt;p&gt;This patch applies to branch_6x.&lt;/p&gt;</comment>
                            <comment id="15378761" author="shalinmangar" created="Fri, 15 Jul 2016 02:22:41 +0000"  >&lt;p&gt;Patch updated to fix two test failures: TestCoreContainer and OverseerTest. &lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;The TestCoreContainer.testCustomHandlers was calling CoreContainer.load twice leading to leaked threads.&lt;/li&gt;
	&lt;li&gt;The OverseerTest doesn&apos;t call init on HttpShardHandler causing a NPE on close.&lt;/li&gt;
	&lt;li&gt;HttpShardHandlerFactory closed the pool before closing the http client itself. It is fixed to be the other way round.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I think this is ready.&lt;/p&gt;</comment>
                            <comment id="15378846" author="markrmiller@gmail.com" created="Fri, 15 Jul 2016 04:47:10 +0000"  >&lt;p&gt;Patch looks okay to me.&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;+        clientConnectionManager.shutdown();
+        IOUtils.closeQuietly(defaultClient);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Not that it likely matters, but I&apos;d reverse this and shut down the pool after the client.&lt;/p&gt;</comment>
                            <comment id="15378850" author="shalinmangar" created="Fri, 15 Jul 2016 04:51:05 +0000"  >&lt;p&gt;Thanks for reviewing Mark but I already fixed that in the last patch.&lt;/p&gt;

&lt;p&gt;I found a test failure in ZkControllerTest because of a thread leak so I may post another patch soon.&lt;/p&gt;</comment>
                            <comment id="15378893" author="shalinmangar" created="Fri, 15 Jul 2016 06:02:00 +0000"  >&lt;p&gt;Patch which fixes the ZkControllerTest failure. Thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=varun&quot; class=&quot;user-hover&quot; rel=&quot;varun&quot;&gt;varun&lt;/a&gt; for spotting the fix.&lt;/p&gt;

&lt;p&gt;I&apos;ll run precommit + tests again and then commit this patch to 6x and backport to 5x.&lt;/p&gt;</comment>
                            <comment id="15378924" author="jira-bot" created="Fri, 15 Jul 2016 06:54:11 +0000"  >&lt;p&gt;Commit bb7742ebc7f33f5c9f41cc3ad28b30c20a19a380 in lucene-solr&apos;s branch refs/heads/branch_6x from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=bb7742e&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=bb7742e&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9290&quot; title=&quot;TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9290&quot;&gt;&lt;del&gt;SOLR-9290&lt;/del&gt;&lt;/a&gt;: TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&lt;/p&gt;</comment>
                            <comment id="15379102" author="jira-bot" created="Fri, 15 Jul 2016 09:29:06 +0000"  >&lt;p&gt;Commit d00c44de2eab6d01fb1df39a17b17fb769a0f541 in lucene-solr&apos;s branch refs/heads/branch_5x from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d00c44d&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=d00c44d&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9290&quot; title=&quot;TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9290&quot;&gt;&lt;del&gt;SOLR-9290&lt;/del&gt;&lt;/a&gt;: TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&lt;br/&gt;
(cherry picked from commit bb7742e)&lt;/p&gt;</comment>
                            <comment id="15379122" author="jira-bot" created="Fri, 15 Jul 2016 09:41:28 +0000"  >&lt;p&gt;Commit 00ad5efac95f38cb1df9ef33672f17a7167a656f in lucene-solr&apos;s branch refs/heads/branch_5x from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=00ad5ef&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=00ad5ef&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9290&quot; title=&quot;TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9290&quot;&gt;&lt;del&gt;SOLR-9290&lt;/del&gt;&lt;/a&gt;: Adding 5.5.3 section and this issue to CHANGES.txt&lt;/p&gt;</comment>
                            <comment id="15379204" author="jira-bot" created="Fri, 15 Jul 2016 10:33:21 +0000"  >&lt;p&gt;Commit e16fb5aa3073021993595acc061cc62bd575adc2 in lucene-solr&apos;s branch refs/heads/branch_5_5 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e16fb5a&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=e16fb5a&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9290&quot; title=&quot;TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9290&quot;&gt;&lt;del&gt;SOLR-9290&lt;/del&gt;&lt;/a&gt;: TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&lt;br/&gt;
(cherry picked from commit bb7742e)&lt;/p&gt;

&lt;p&gt;(cherry picked from commit d00c44de2eab6d01fb1df39a17b17fb769a0f541)&lt;/p&gt;</comment>
                            <comment id="15379220" author="shalinmangar" created="Fri, 15 Jul 2016 10:47:28 +0000"  >&lt;p&gt;Thanks everyone for the help!&lt;/p&gt;</comment>
                            <comment id="15379940" author="shalinmangar" created="Fri, 15 Jul 2016 19:09:46 +0000"  >&lt;p&gt;Hoss pointed out to me privately that the test fixes for ZkController, TestCoreContainer and OverseerTest should be applied to master as well.&lt;/p&gt;</comment>
                            <comment id="15379964" author="jira-bot" created="Fri, 15 Jul 2016 19:29:48 +0000"  >&lt;p&gt;Commit 833c8ee152fc28b7ec767d0e8f8ecd346229d443 in lucene-solr&apos;s branch refs/heads/master from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shalin&quot; class=&quot;user-hover&quot; rel=&quot;shalin&quot;&gt;shalin&lt;/a&gt;&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=833c8ee&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=833c8ee&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-9290&quot; title=&quot;TCP-connections in CLOSE_WAIT spike during heavy indexing and do not decrease&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-9290&quot;&gt;&lt;del&gt;SOLR-9290&lt;/del&gt;&lt;/a&gt;: MockCoreContainer should call super.shutdown()&lt;/p&gt;</comment>
                            <comment id="15379965" author="shalinmangar" created="Fri, 15 Jul 2016 19:30:58 +0000"  >&lt;p&gt;It looks like all the test fixes that we made here were already fixed by &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-4509&quot; title=&quot;Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-4509&quot;&gt;&lt;del&gt;SOLR-4509&lt;/del&gt;&lt;/a&gt; on master. I only had to add a super.shutdown() call in MockCoreContainer just for the sake of correctness.&lt;/p&gt;</comment>
                            <comment id="15381414" author="elyograg" created="Sun, 17 Jul 2016 16:32:44 +0000"  >&lt;p&gt;I recently joined the jetty-users mailing list for other Solr-related issues.&lt;/p&gt;

&lt;p&gt;Ten days ago (July 7th in my timezone) somebody sent a message to that list about encountering a large number of CLOSE_WAIT connections when using SSL.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We have an ensemble of three jetty-servers running jetty 9.3.8 on CentOS. There is a fairly high rate of communication between the servers. When we run the ensemble without SSL, everything works perfectly, but once SSL is activated, exactly one of the servers start to get a massive amount of connections in CLOSE_WAIT (more than 50 000). This, again, causes the Old Gen-part of the heap memory in the JVM to fill up, and the server becomes unable to communicate with exactly one of the other two, with Couldn&#8217;t resolve address. However, the other machine can still communicate with the one that breaks down, and the 3^rd machine can communicate with both.&lt;br/&gt;
It seems that other people using Jetty (not just Solr) are experiencing a buildup of CLOSE_WAIT connections when using SSL.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;m going to mention this issue on the mailing list thread, and try to find out whether they are having the problem with software &lt;b&gt;other&lt;/b&gt; than Solr.&lt;/p&gt;</comment>
                            <comment id="15439031" author="mikemccand" created="Fri, 26 Aug 2016 14:00:17 +0000"  >&lt;p&gt;Bulk close resolved issues after 6.2.0 release.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12817779" name="SOLR-9290-debug.patch" size="17525" author="shalin" created="Wed, 13 Jul 2016 19:03:28 +0000"/>
                            <attachment id="12817488" name="SOLR-9290-debug.patch" size="15556" author="shalin" created="Tue, 12 Jul 2016 18:58:55 +0000"/>
                            <attachment id="12818100" name="SOLR-9290.patch" size="19752" author="shalin" created="Fri, 15 Jul 2016 06:02:00 +0000"/>
                            <attachment id="12818088" name="SOLR-9290.patch" size="17879" author="shalin" created="Fri, 15 Jul 2016 02:22:41 +0000"/>
                            <attachment id="12818022" name="SOLR-9290.patch" size="16939" author="shalin" created="Thu, 14 Jul 2016 20:37:49 +0000"/>
                            <attachment id="12817885" name="index.sh" size="813" author="hossman" created="Thu, 14 Jul 2016 06:05:54 +0000"/>
                            <attachment id="12817884" name="setup-solr.sh" size="1139" author="hossman" created="Thu, 14 Jul 2016 06:05:54 +0000"/>
                            <attachment id="12817487" name="setup-solr.sh" size="652" author="shalin" created="Tue, 12 Jul 2016 18:58:55 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>8.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            9 years, 12 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i30nqf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313321" key="com.atlassian.jira.toolkit:message">
                        <customfieldname>Solr Mailing List Info</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>