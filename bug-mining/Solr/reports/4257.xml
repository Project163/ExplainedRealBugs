<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 04:39:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SOLR-13599] ReplicationFactorTest high failure rate on Windows jenkins VMs after 2019-06-22 OS/java upgrades</title>
                <link>https://issues.apache.org/jira/browse/SOLR-13599</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;We&apos;ve started seeing some weirdly consistent (but not reliably reproducible) failures from ReplicationFactorTest when running on Uwe&apos;s Windows jenkins machines.&lt;/p&gt;

&lt;p&gt;The failures all seem to have started on June 22 &amp;#8211; when Uwe upgraded his Windows VMs to upgrade the Java version, but happen across all versions of java tested, and on both the master and branch_8x.&lt;/p&gt;

&lt;p&gt;While this test failed a total of 5 times, in different ways, on various jenkins boxes between 2019-01-01 and 2019-06-21, it seems to have failed on all but 1 or 2 of Uwe&apos;s &quot;Windows&quot; jenkins builds since that 2019-06-22, and when it fails the &lt;tt&gt;reproduceJenkinsFailures.py&lt;/tt&gt; logic used in Uwe&apos;s jenkins builds frequently fails anywhere from 1-4 additional times.&lt;/p&gt;

&lt;p&gt;All of these failures occur in the exact same place, with the exact same assertion: that the expected replicationFactor of 2 was not achieved, and an rf=1 (ie: only the master) was returned, when sending a &lt;em&gt;batch&lt;/em&gt; of documents to a collection with 1 shard, 3 replicas; while 1 of the replicas was partitioned off due to a closed proxy.&lt;/p&gt;

&lt;p&gt;In the handful of logs I&apos;ve examined closely, the 2nd &quot;live&quot; replica does in fact log that it recieved &amp;amp; processed the update, but with a QTime of over 30 seconds, and it then it immediately logs an &lt;tt&gt;org.eclipse.jetty.io.EofException: Reset cancel_stream_error&lt;/tt&gt; Exception &amp;#8211; meanwhile, the leader has one (&lt;tt&gt;updateExecutor&lt;/tt&gt; thread logging copious amount of &lt;tt&gt;java.net.ConnectException: Connection refused: no further information&lt;/tt&gt; regarding the replica that was partitioned off, before a second &lt;tt&gt;updateExecutor&lt;/tt&gt; thread ultimately logs &lt;tt&gt;java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException: idle_timeout&lt;/tt&gt; regarding the &quot;live&quot; replica.&lt;/p&gt;


&lt;hr /&gt;

&lt;p&gt;What makes this perplexing is that this is not the first time in the test that documents were added to this collection while one replica was partitioned off, but it is the first time that all 3 of the following are true &lt;em&gt;at the same time&lt;/em&gt;:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;the collection has recovered after some replicas were partitioned and re-connected&lt;/li&gt;
	&lt;li&gt;a batch of multiple documents is being added&lt;/li&gt;
	&lt;li&gt;one replica has been &quot;re&quot; partitioned.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;...prior to the point when this failure happens, only individual document adds were tested while replicas where partitioned.  Batches of adds were only tested when all 3 replicas were &quot;live&quot; after the proxies were re-opened and the collection had fully recovered.  The failure also comes from the first update to happen after a replica&apos;s proxy port has been &quot;closed&quot; for the &lt;em&gt;second&lt;/em&gt; time.&lt;/p&gt;

&lt;p&gt;While this conflagration of events might concievible trigger some weird bug, what makes these failures &lt;em&gt;particularly&lt;/em&gt; perplexing is that:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;the failures only happen on Windows&lt;/li&gt;
	&lt;li&gt;the failures only started after the Windows VM update on June-22.&lt;/li&gt;
&lt;/ul&gt;

</description>
                <environment></environment>
        <key id="13242824">SOLR-13599</key>
            <summary>ReplicationFactorTest high failure rate on Windows jenkins VMs after 2019-06-22 OS/java upgrades</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="5">Cannot Reproduce</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="hossman">Chris M. Hostetter</reporter>
                        <labels>
                    </labels>
                <created>Tue, 2 Jul 2019 18:34:01 +0000</created>
                <updated>Sat, 27 Jul 2019 01:30:18 +0000</updated>
                            <resolved>Sat, 27 Jul 2019 01:30:18 +0000</resolved>
                                                                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                                                                                <comments>
                            <comment id="16877235" author="hossman" created="Tue, 2 Jul 2019 18:36:55 +0000"  >
&lt;p&gt;Details of Uwe&apos;s jenkins updates...&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/lucene-dev/201906.mbox/%3C00b301d52918$d27b2f60$77718e20$@thetaphi.de%3E&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://mail-archives.apache.org/mod_mbox/lucene-dev/201906.mbox/%3C00b301d52918$d27b2f60$77718e20$@thetaphi.de%3E&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/lucene-dev/201907.mbox/%3C01a901d530a7$fac9d2a0$f05d77e0$@thetaphi.de%3E&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://mail-archives.apache.org/mod_mbox/lucene-dev/201907.mbox/%3C01a901d530a7$fac9d2a0$f05d77e0$@thetaphi.de%3E&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;a href=&quot;http://mail-archives.apache.org/mod_mbox/lucene-dev/201907.mbox/raw/%3C01a901d530a7$fac9d2a0$f05d77e0$@thetaphi.de%3E/4&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://mail-archives.apache.org/mod_mbox/lucene-dev/201907.mbox/raw/%3C01a901d530a7$fac9d2a0$f05d77e0$@thetaphi.de%3E/4&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;hr /&gt;

&lt;p&gt;I&apos;m attaching thetaphi_Lucene-Solr-master-Windows_8025.log.txt as an illustrative example of the failure, here are some key snippets and the associated lines from the test class...&lt;/p&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;
# Previously: test individual adds, delById, and delByyQ using...
#  ... rf=3 with all replicas connected,
#  ... rf=2 when one replica&apos;s proxy is closed,
#  ... rf=1 when both replica&apos;s proxies are closed

# Lines # 314-320 - &quot;heal&quot; the cluster (re-enable all proxies)

...
   [junit4]   2&amp;gt; 555732 INFO  (TEST-ReplicationFactorTest.test-seed#[C415B4F186C6C69D]) [     ] o.a.s.c.AbstractFullDistribZkTestBase Found 3 replicas and leader on 127.0.0.1:59004_ for shard1 in repfacttest_c8n_1x3
   [junit4]   2&amp;gt; 555732 INFO  (TEST-ReplicationFactorTest.test-seed#[C415B4F186C6C69D]) [     ] o.a.s.c.AbstractFullDistribZkTestBase Took 7107.0 ms to see all replicas become active.
...


# Lines # 322-326 - checks that (individual) add, delById &amp;amp; delByQ all get rf=3

# Lines # 328-341 - checks that (batched) add, delById &amp;amp; delByQ all get rf=3

# Line #  344 - close a proxy port (59108) again ...

   [junit4]   2&amp;gt; 556060 WARN  (TEST-ReplicationFactorTest.test-seed#[C415B4F186C6C69D]) [     ] o.a.s.c.s.c.SocketProxy Closing 1 connections to: http://127.0.0.1:59108/, target: http://127.0.0.1:59109/
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At this point, the next thing in the test is to add a batch of documents (ids#15-29) while one replica is partitioned &amp;#8211; but I should point out that it&apos;s not immediately obvious to me if the &lt;tt&gt;(updateExecutor-1924-thread-4&lt;/tt&gt; logging from the leader below (complaining about &lt;tt&gt;Connection refused:&lt;/tt&gt; to port 59108 is &lt;b&gt;because&lt;/b&gt; of the update sent my the client, or independently because of the HTTP2 connection management detecting that the proxy was closed...&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;# Lines # 346-355 - send our first &quot;batch&quot; (id#15-29) when cluster isn&apos;t &quot;healed&quot;

   [junit4]   2&amp;gt; 558074 ERROR (updateExecutor-1924-thread-4-processing-x:repfacttest_c8n_1x3_shard1_replica_n2 r:core_node5 null n:127.0.0.1:59004_ c:repfacttest_c8n_1x3 s:shard1) [n:127.0.0.1:59004_ c:repfacttest_c8n_1x3 s:shard1 r:core_node5 x:repfacttest_c8n_1x3_shard1_replica_n2 ] o.a.s.u.ErrorReportingConcurrentUpdateSolrClient Error when calling SolrCmdDistributor$Req: cmd=add{,id=(null)}; node=StdNode: http://127.0.0.1:59108/repfacttest_c8n_1x3_shard1_replica_n3/ to http://127.0.0.1:59108/repfacttest_c8n_1x3_shard1_replica_n3/
   [junit4]   2&amp;gt;           =&amp;gt; java.io.IOException: java.net.ConnectException: Connection refused: no further information
...

# ...there are more details about supressed exceptions
# ...this ERROR repeats many times - evidently as the leader tries to reconnect...

...
   [junit4]   2&amp;gt; 560193 ERROR (updateExecutor-1924-thread-4-processing-x:repfacttest_c8n_1x3_shard1_replica_n2 r:core_node5 null n:127.0.0.1:59004_ c:repfacttest_c8n_1x3 s:shard1) [n:127.0.0.1:59004_ c:repfacttest_c8n_1x3 s:shard1 r:core_node5 x:repfacttest_c8n_1x3_shard1_replica_n2 ] o.a.s.u.ErrorReportingConcurrentUpdateSolrClient Error when calling SolrCmdDistributor$Req: cmd=add{,id=(null)}; node=StdNode: http://127.0.0.1:59108/repfacttest_c8n_1x3_shard1_replica_n3/ to http://127.0.0.1:59108/repfacttest_c8n_1x3_shard1_replica_n3/
   [junit4]   2&amp;gt;           =&amp;gt; java.io.IOException: java.net.ConnectException: Connection refused: no further information
...

# ... brief bit of path=/admin/metrics logging from both n:127.0.0.1:59004_ and n:127.0.0.1:59084_
# ... and some other MetricsHistoryHandler logging (from overseer?) about failing to talk to 127.0.0.1:59108
# ... but mostly lots of logging from the leader about not being able to connect to 127.0.0.1:59108



# live replica (port 59060) logs that it&apos;s added the 15 docs FROMLEADER, ... BUT!!!!...
# ... same thread then logs jetty EofException: Reset cancel_stream_error
# ... so aparently it added the docs but had a problem communicating that back to the leader
# ... evidently because it took 30 seconds (QTime = 30013) and leader gave up (see below)

   [junit4]   2&amp;gt; 591364 INFO  (qtp1520091886-5884) [n:127.0.0.1:59060_ c:repfacttest_c8n_1x3 s:shard1 r:core_node4 x:repfacttest_c8n_1x3_shard1_replica_n1 ] o.a.s.u.p.LogUpdateProcessorFactory [repfacttest_c8n_1x3_shard1_replica_n1]  webapp= path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http://127.0.0.1:59004/repfacttest_c8n_1x3_shard1_replica_n2/&amp;amp;wt=javabin&amp;amp;version=2}{add=[15 (1637713552307388416), 16 (1637713552307388417), 17 (1637713552307388418), 18 (1637713552308436992), 19 (1637713552308436993), 20 (1637713552308436994), 21 (1637713552308436995), 22 (1637713552308436996), 23 (1637713552308436997), 24 (1637713552308436998), ... (15 adds)]} 0 30013
   [junit4]   2&amp;gt; 591367 ERROR (qtp1520091886-5884) [n:127.0.0.1:59060_ c:repfacttest_c8n_1x3 s:shard1 r:core_node4 x:repfacttest_c8n_1x3_shard1_replica_n1 ] o.a.s.h.RequestHandlerBase org.eclipse.jetty.io.EofException: Reset cancel_stream_error
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.server.HTTP2ServerConnectionFactory$HTTPServerSessionListener.onReset(HTTP2ServerConnectionFactory.java:157)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Stream.notifyReset(HTTP2Stream.java:574)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Stream.onReset(HTTP2Stream.java:343)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Stream.process(HTTP2Stream.java:252)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Session.onReset(HTTP2Session.java:294)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.Parser$Listener$Wrapper.onReset(Parser.java:368)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.BodyParser.notifyReset(BodyParser.java:139)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.ResetBodyParser.onReset(ResetBodyParser.java:97)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.ResetBodyParser.parse(ResetBodyParser.java:66)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.Parser.parseBody(Parser.java:194)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.Parser.parse(Parser.java:123)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.ServerParser.parse(ServerParser.java:115)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection$HTTP2Producer.produce(HTTP2Connection.java:248)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:357)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:181)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:132)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection.produce(HTTP2Connection.java:170)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection.onFillable(HTTP2Connection.java:125)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection$FillableCallback.succeeded(HTTP2Connection.java:348)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.Invocable.invokeNonBlocking(Invocable.java:68)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.invokeTask(EatWhatYouKill.java:345)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:300)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:132)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:781)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:917)
   [junit4]   2&amp;gt;        at java.base/java.lang.Thread.run(Thread.java:830)
   [junit4]   2&amp;gt;        Suppressed: java.lang.Throwable: HttpInput failure
   [junit4]   2&amp;gt;                at org.eclipse.jetty.server.HttpInput.failed(HttpInput.java:831)
   [junit4]   2&amp;gt;                at org.eclipse.jetty.http2.server.HttpChannelOverHTTP2.onFailure(HttpChannelOverHTTP2.java:323)
   [junit4]   2&amp;gt;                at org.eclipse.jetty.http2.server.HTTP2ServerConnection.onStreamFailure(HTTP2ServerConnection.java:219)
   [junit4]   2&amp;gt;                ... 30 more
   [junit4]   2&amp;gt; 

# FYI: same request thread on port 59060 also logs same exception from o.a.s.s.HttpSolrCall ...

   [junit4]   2&amp;gt; 591367 ERROR (qtp1520091886-5884) [n:127.0.0.1:59060_ c:repfacttest_c8n_1x3 s:shard1 r:core_node4 x:repfacttest_c8n_1x3_shard1_replica_n1 ] o.a.s.s.HttpSolrCall null:org.eclipse.jetty.io.EofException: Reset cancel_stream_error
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.server.HTTP2ServerConnectionFactory$HTTPServerSessionListener.onReset(HTTP2ServerConnectionFactory.java:157)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Stream.notifyReset(HTTP2Stream.java:574)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Stream.onReset(HTTP2Stream.java:343)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Stream.process(HTTP2Stream.java:252)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Session.onReset(HTTP2Session.java:294)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.Parser$Listener$Wrapper.onReset(Parser.java:368)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.BodyParser.notifyReset(BodyParser.java:139)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.ResetBodyParser.onReset(ResetBodyParser.java:97)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.ResetBodyParser.parse(ResetBodyParser.java:66)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.Parser.parseBody(Parser.java:194)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.Parser.parse(Parser.java:123)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.parser.ServerParser.parse(ServerParser.java:115)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection$HTTP2Producer.produce(HTTP2Connection.java:248)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:357)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:181)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:132)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection.produce(HTTP2Connection.java:170)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection.onFillable(HTTP2Connection.java:125)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection$FillableCallback.succeeded(HTTP2Connection.java:348)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.Invocable.invokeNonBlocking(Invocable.java:68)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.invokeTask(EatWhatYouKill.java:345)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:300)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:168)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:132)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:781)
   [junit4]   2&amp;gt;        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:917)
   [junit4]   2&amp;gt;        at java.base/java.lang.Thread.run(Thread.java:830)
   [junit4]   2&amp;gt;        Suppressed: java.lang.Throwable: HttpInput failure
   [junit4]   2&amp;gt;                at org.eclipse.jetty.server.HttpInput.failed(HttpInput.java:831)
   [junit4]   2&amp;gt;                at org.eclipse.jetty.http2.server.HttpChannelOverHTTP2.onFailure(HttpChannelOverHTTP2.java:323)
   [junit4]   2&amp;gt;                at org.eclipse.jetty.http2.server.HTTP2ServerConnection.onStreamFailure(HTTP2ServerConnection.java:219)
   [junit4]   2&amp;gt;                ... 30 more

# leader&apos;s updateExecutor-1924-thread-4 complains many more times that it isn&apos;t able to update
# (the still down) 127.0.0.1:59108 ...


   [junit4]   2&amp;gt; 591661 ERROR (updateExecutor-1924-thread-4-processing-x:repfacttest_c8n_1x3_shard1_replica_n2 r:core_node5 null n:127.0.0.1:59004_ c:repfacttest_c8n_1x3 s:shard1) [n:127.0.0.1:59004_ c:repfacttest_c8n_1x3 s:shard1 r:core_node5 x:repfacttest_c8n_1x3_shard1_replica_n2 ] o.a.s.u.ErrorReportingConcurrentUpdateSolrClient Error when calling SolrCmdDistributor$Req: cmd=add{,id=(null)}; node=StdNode: http://127.0.0.1:59
108/repfacttest_c8n_1x3_shard1_replica_n3/ to http://127.0.0.1:59108/repfacttest_c8n_1x3_shard1_replica_n3/
   [junit4]   2&amp;gt;           =&amp;gt; java.io.IOException: java.net.ConnectException: Connection refused: no further information
   [junit4]   2&amp;gt;        at org.eclipse.jetty.client.util.DeferredContentProvider.flush(DeferredContentProvider.java:193)
   ...

# Eventually (a different) updateExecutor-1924-thread-2 on the leader also complains it
# couldn&apos;t send the update to port 59060 because of a &quot;TimeoutException: idle_timeout&quot;
# (which is either a cause or effect of 59060&apos;s &quot;EofException: Reset cancel_stream_error&quot; above)


   [junit4]   2&amp;gt; 591661 ERROR (updateExecutor-1924-thread-2-processing-x:repfacttest_c8n_1x3_shard1_replica_n2 r:core_node5 null n:127.0.0.1:59004_ c:repfacttest_c8n_1x3 s:shard1) [n:127.0.0.1:59004_ c:repfacttest_c8n_1x3 s:shard1 r:core_node5 x:repfacttest_c8n_1x3_shard1_replica_n2 ] o.a.s.u.ErrorReportingConcurrentUpdateSolrClient Error when calling SolrCmdDistributor$Req: cmd=add{,id=(null)}; node=StdNode: http://127.0.0.1:59060/repfacttest_c8n_1x3_shard1_replica_n1/ to http://127.0.0.1:59060/repfacttest_c8n_1x3_shard1_replica_n1/
   [junit4]   2&amp;gt;           =&amp;gt; java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException: idle_timeout
   [junit4]   2&amp;gt;        at org.eclipse.jetty.client.util.InputStreamResponseListener.get(InputStreamResponseListener.java:221)
   [junit4]   2&amp;gt; java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException: idle_timeout
   [junit4]   2&amp;gt;        at org.eclipse.jetty.client.util.InputStreamResponseListener.get(InputStreamResponseListener.java:221) ~[jetty-client-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at org.apache.solr.client.solrj.impl.ConcurrentUpdateHttp2SolrClient$Runner.sendUpdateStream(ConcurrentUpdateHttp2SolrClient.java:240) ~[java/:?]
   [junit4]   2&amp;gt;        at org.apache.solr.client.solrj.impl.ConcurrentUpdateHttp2SolrClient$Runner.run(ConcurrentUpdateHttp2SolrClient.java:176) ~[java/:?]
   [junit4]   2&amp;gt;        at com.codahale.metrics.InstrumentedExecutorService$InstrumentedRunnable.run(InstrumentedExecutorService.java:181) ~[metrics-core-4.0.5.jar:4.0.5]
   [junit4]   2&amp;gt;        at org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor.lambda$execute$0(ExecutorUtil.java:209) ~[java/:?]
   [junit4]   2&amp;gt;        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[?:?]
   [junit4]   2&amp;gt;        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[?:?]
   [junit4]   2&amp;gt;        at java.lang.Thread.run(Thread.java:830) [?:?]
   [junit4]   2&amp;gt; Caused by: java.util.concurrent.TimeoutException: idle_timeout
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.client.http.HttpConnectionOverHTTP2.onIdleTimeout(HttpConnectionOverHTTP2.java:137) ~[http2-http-client-transport-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.client.http.HttpClientTransportOverHTTP2$SessionListenerPromise.onIdleTimeout(HttpClientTransportOverHTTP2.java:243) ~[http2-http-client-transport-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Session.notifyIdleTimeout(HTTP2Session.java:1165) ~[http2-common-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Session.onIdleTimeout(HTTP2Session.java:1003) ~[http2-common-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at org.eclipse.jetty.http2.HTTP2Connection.onIdleExpired(HTTP2Connection.java:150) ~[http2-common-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at org.eclipse.jetty.io.AbstractEndPoint.onIdleExpired(AbstractEndPoint.java:401) ~[jetty-io-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at org.eclipse.jetty.io.IdleTimeout.checkIdleTimeout(IdleTimeout.java:171) ~[jetty-io-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at org.eclipse.jetty.io.IdleTimeout.idleCheck(IdleTimeout.java:113) ~[jetty-io-9.4.19.v20190610.jar:9.4.19.v20190610]
   [junit4]   2&amp;gt;        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) ~[?:?]
   [junit4]   2&amp;gt;        at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
   [junit4]   2&amp;gt;        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
   [junit4]   2&amp;gt;        ... 3 more


# lots more logging from the leader about being unable to talk to the (down) 127.0.0.1:59108
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16877320" author="jira-bot" created="Tue, 2 Jul 2019 21:52:22 +0000"  >&lt;p&gt;Commit b4a602f6b24196273adbdb7d47bf42fa8d08d807 in lucene-solr&apos;s branch refs/heads/master from Chris M. Hostetter&lt;br/&gt;
[ &lt;a href=&quot;https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=b4a602f&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=b4a602f&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-13599&quot; title=&quot;ReplicationFactorTest high failure rate on Windows jenkins VMs after 2019-06-22 OS/java upgrades&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-13599&quot;&gt;&lt;del&gt;SOLR-13599&lt;/del&gt;&lt;/a&gt;: additional &apos;checkpoint&apos; logging to try and help diagnose strange failures&lt;/p&gt;</comment>
                            <comment id="16880481" author="hossman" created="Mon, 8 Jul 2019 15:41:28 +0000"  >&lt;p&gt;this is the epitome of a heisenbug ... &lt;/p&gt;

&lt;p&gt;5 days ago i commit a change to master that adds a bit of extra logging to the test, and since then there hasn&apos;t been a single master fail &amp;#8211; but in the same about of time, 7/10 of the 8x builds have failed, and all but one of those reproduced 3x (or more) times.&lt;/p&gt;

&lt;p&gt;not sure what to do here except backport the loging changes to 8x, and hope we get another failure eventaully so we&apos;ll have something to diagnose.&lt;/p&gt;</comment>
                            <comment id="16880493" author="jira-bot" created="Mon, 8 Jul 2019 15:59:52 +0000"  >&lt;p&gt;Commit 4fd1850d2ee2976efe4e1ee5645d32dc394714b1 in lucene-solr&apos;s branch refs/heads/branch_8x from Chris M. Hostetter&lt;br/&gt;
[ &lt;a href=&quot;https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=4fd1850&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://gitbox.apache.org/repos/asf?p=lucene-solr.git;h=4fd1850&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-13599&quot; title=&quot;ReplicationFactorTest high failure rate on Windows jenkins VMs after 2019-06-22 OS/java upgrades&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-13599&quot;&gt;&lt;del&gt;SOLR-13599&lt;/del&gt;&lt;/a&gt;: additional &apos;checkpoint&apos; logging to try and help diagnose strange failures&lt;/p&gt;

&lt;p&gt;(cherry picked from commit b4a602f6b24196273adbdb7d47bf42fa8d08d807)&lt;/p&gt;</comment>
                            <comment id="16894223" author="hossman" created="Sat, 27 Jul 2019 01:30:18 +0000"  >&lt;p&gt;not a single jenkins failure in this test since backporting the logging additions to brach_8x on July8.&lt;/p&gt;

&lt;p&gt;doesn&apos;t seem like there is much more we can do here....&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="13242738">SOLR-13598</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12973470" name="thetaphi_Lucene-Solr-master-Windows_8025.log.txt" size="7271545" author="hossman" created="Tue, 2 Jul 2019 18:36:40 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 16 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z04ba0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313321" key="com.atlassian.jira.toolkit:message">
                        <customfieldname>Solr Mailing List Info</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>