<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Wed Nov 12 04:08:28 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[SOLR-8129] HdfsChaosMonkeyNothingIsSafeTest failures</title>
                <link>https://issues.apache.org/jira/browse/SOLR-8129</link>
                <project id="12310230" key="SOLR">Solr</project>
                    <description>&lt;p&gt;New HDFS chaos test in &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8123&quot; title=&quot;Add HdfsChaosMonkeyNothingIsSafeTest test.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8123&quot;&gt;&lt;del&gt;SOLR-8123&lt;/del&gt;&lt;/a&gt; hits a number of types of failures, including shard inconsistency.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12902452">SOLR-8129</key>
            <summary>HdfsChaosMonkeyNothingIsSafeTest failures</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="markrmiller@gmail.com">Mark Miller</assignee>
                                    <reporter username="yseeley@gmail.com">Yonik Seeley</reporter>
                        <labels>
                    </labels>
                <created>Mon, 5 Oct 2015 16:51:30 +0000</created>
                <updated>Mon, 27 Mar 2017 09:08:50 +0000</updated>
                            <resolved>Wed, 22 Feb 2017 15:20:46 +0000</resolved>
                                                    <fixVersion>6.5</fixVersion>
                    <fixVersion>7.0</fixVersion>
                                    <component>SolrCloud</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="14945248" author="yseeley@gmail.com" created="Tue, 6 Oct 2015 15:59:33 +0000"  >&lt;p&gt;Here&apos;s the smallest log file that I&apos;ve been able to generate with a large number of descrepancies:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;fail.151005_080319:   &amp;gt; Throwable #1: java.lang.AssertionError: shard2 is not consistent.  Got 2076 from http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:43897/collection1 (previous client) and got 2103 from http://127.0.0.1:36605/collection1&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This was without deletes (if I managed to configure that correctly).&lt;/p&gt;</comment>
                            <comment id="14949872" author="yseeley@gmail.com" created="Fri, 9 Oct 2015 04:21:04 +0000"  >&lt;p&gt;This seems to be a case of extreme reordering of updates due to thread scheduling or whatever.&lt;br/&gt;
The leader is selected by the chaos monkey to be killed, and there are a bunch of updates that are sent to one shard but not another (i.e. they may have been waiting to be sent, but didn&apos;t make it before the leader was killed).&lt;br/&gt;
A bunch more updates flood in, and when a leader election is held and peersync is done, everyone thinks they are up-to-date because the most recent updates do match.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;43897 has fewer docs than 36605: missing: {_version_=1514192462261780480, id=ft1-1715} ... {_version_=1514192462057308160, id=ft1-1700} ... {_version_=1514192462056259585, id=ft1-1698}

&lt;span class=&quot;code-comment&quot;&gt;// Port 43897 is recovering and begins buffering updates
&lt;/span&gt;  2&amp;gt; 31048 INFO  (RecoveryThread-collection1) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.c.RecoveryStrategy Starting recovery process. recoveringAfterStartup=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
  2&amp;gt; 31049 INFO  (RecoveryThread-collection1) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.c.RecoveryStrategy ###### startupVersions=[]

&lt;span class=&quot;code-comment&quot;&gt;// going &lt;span class=&quot;code-quote&quot;&gt;&quot;active&quot;&lt;/span&gt;
&lt;/span&gt;  2&amp;gt; 38552 INFO  (RecoveryThread-collection1) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.c.RecoveryStrategy Registering as Active after recovery.

&lt;span class=&quot;code-comment&quot;&gt;// example of a normal add
&lt;/span&gt;  2&amp;gt; 55692 INFO  (qtp1287419856-309) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp= path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:49240/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-48 (1514192447743197184)]} 0 188
&lt;/span&gt;  
&lt;span class=&quot;code-comment&quot;&gt;// The leader is going to be killed
&lt;/span&gt;  2&amp;gt; 68281 INFO  (&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-378) [    ] o.a.s.c.ChaosMonkey monkey: stop shard! 49240
 
&lt;span class=&quot;code-comment&quot;&gt;// This is presumably where 43897 see the leader marked as &lt;span class=&quot;code-quote&quot;&gt;&quot;down&quot;&lt;/span&gt; in the clusterstate
&lt;/span&gt;  2&amp;gt; 68347 INFO  (zkCallback-25-thread-1-processing-n:127.0.0.1:43897_) [n:127.0.0.1:43897_    ] o.a.s.c.c.ZkStateReader A cluster state change: WatchedEvent state:SyncConnected type:NodeDataChanged path:/collections/collection1/state.json &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; collection collection1 has occurred - updating... (live nodes size: 9)

&lt;span class=&quot;code-comment&quot;&gt;// updates are still being processed by the leader
&lt;/span&gt;  2&amp;gt; 68743 DEBUG (qtp139680011-202) [n:127.0.0.1:49240_ c:collection1 s:shard2 r:core_node1 x:collection1] o.a.s.u.p.LogUpdateProcessor PRE_UPDATE add{,id=ft1-1700} {wt=javabin&amp;amp;version=2}

&lt;span class=&quot;code-comment&quot;&gt;// Replica 36605 receives and processes the update, but 43897 never does (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; may be normal as the leader is being killed)
&lt;/span&gt;  2&amp;gt; 69010 DEBUG (qtp33344819-419) [n:127.0.0.1:36605_ c:collection1 s:shard2 r:core_node7 x:collection1] o.a.s.u.p.LogUpdateProcessor PRE_UPDATE add{,id=ft1-1700} {update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:49240/collection1/&amp;amp;wt=javabin&amp;amp;version=2}
&lt;/span&gt;  2&amp;gt; 69015 INFO  (qtp33344819-419) [n:127.0.0.1:36605_ c:collection1 s:shard2 r:core_node7 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp= path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:49240/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-1656 (1514192461610614784), ft1-1670 (1514192462015365120), ft1-1679 (1514192462052065280), ft1-1682 (1514192462053113856), ft1-1688 (1514192462055211008), ft1-1695 (1514192462056259584), ft1-1698 (1514192462056259585), ft1-1700 (1514192462057308160), ft1-1702 (1514192462058356736)]} 0 224
&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;// a ton of more update flood in
&lt;/span&gt;  2&amp;gt; 69710 INFO  (qtp1287419856-654) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp= path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:49240/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-1516 (1514192460689965056), ft1-1518 (1514192460829425664), ft1-1519 (1514192460867174400), ft1-1539 (1514192460868222976), ft1-1540 (1514192460868222977), ft1-1542 (1514192460868222978), ft1-1546 (1514192460869271552), ft1-1552 (1514192460869271553), ft1-1563 (1514192460871368704), ft1-1564 (1514192460871368705), ... (41 adds)]} 0 992
&lt;/span&gt;  2&amp;gt; 70571 INFO  (qtp1287419856-655) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp= path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:49240/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-1790 (1514192462017462272), ft1-1791 (1514192462035288064), ft1-1803 (1514192462036336640), ft1-1810 (1514192462037385216), ft1-1813 (1514192462042628096), ft1-1814 (1514192462043676672), ft1-1815 (1514192462043676673), ft1-1818 (1514192462044725248), ft1-1819 (1514192462044725249), ft1-1820 (1514192462303723520), ... (45 adds)]} 0 856
&lt;/span&gt; 2&amp;gt; 70911 INFO  (qtp1287419856-309) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp= path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:49240/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-1998 (1514192463049261056), ft1-1999 (1514192463084912640), ft1-2001 (1514192463085961216), ft1-2003 (1514192463085961217), ft1-2011 (1514192463087009792), ft1-2012 (1514192463088058368), ft1-2016 (1514192463099592704), ft1-2020 (1514192463101689856), ft1-2022 (1514192463102738432), ft1-2023 (1514192463392145408), ... (35 adds)]} 0 325
&lt;/span&gt;  2&amp;gt; 71386 INFO  (qtp1287419856-653) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp= path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:49240/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-2203 (1514192463788507136), ft1-2206 (1514192464060088320), ft1-2217 (1514192464074768384), ft1-2219 (1514192464074768385), ft1-2224 (1514192464075816960), ft1-2229 (1514192464075816961), ft1-2231 (1514192464075816962), ft1-2239 (1514192464076865536), ft1-2249 (1514192464077914112), ft1-2268 (1514192464077914113), ... (27 adds)]} 0 471
&lt;/span&gt;  

&lt;span class=&quot;code-comment&quot;&gt;// the most 100 recent versions match &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; both replicas
&lt;/span&gt;  2&amp;gt; 76191 DEBUG (zkCallback-25-thread-1-processing-n:127.0.0.1:43897_) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.u.PeerSync PeerSync: core=collection1 url=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:43897  sorted versions from http://127.0.0.1:36605/collection1/ = [1514192465046798337, 1514192465046798336, ... , 1514192463538946050, 1514192463538946049]
&lt;/span&gt;  2&amp;gt; 76241 DEBUG (qtp33344819-419) [n:127.0.0.1:36605_ c:collection1 s:shard2 r:core_node7 x:collection1] o.a.s.u.PeerSync PeerSync: core=collection1 url=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:36605  sorted versions from http://127.0.0.1:43897/collection1/ = [1514192465046798337, 1514192465046798336, ... , 1514192463538946050, 1514192463538946049]
&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;// 43897 becomes the &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; leader
&lt;/span&gt;  2&amp;gt; 76242 INFO  (zkCallback-25-thread-1-processing-n:127.0.0.1:43897_) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.c.ShardLeaderElectionContext I am the &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; leader: http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:43897/collection1/ shard2
&lt;/span&gt;

&lt;span class=&quot;code-comment&quot;&gt;// end of test
&lt;/span&gt;  2&amp;gt; ######shard2 is not consistent.  Got 2076 from http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:43897/collection1 (previous client) and got 2103 from http://127.0.0.1:36605/collection1
&lt;/span&gt;  2&amp;gt; 129545 INFO  (qtp1287419856-653) [n:127.0.0.1:43897_ c:collection1 s:shard2 r:core_node4 x:collection1] o.a.s.c.S.Request [collection1] webapp= path=/select params={q=*:*&amp;amp;distrib=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;amp;tests=checkShardConsistency/showDiff&amp;amp;fl=id,_version_&amp;amp;sort=id+asc&amp;amp;rows=100000&amp;amp;wt=javabin&amp;amp;version=2} hits=2076 status=0 QTime=114 
  2&amp;gt; 129656 INFO  (qtp33344819-422) [n:127.0.0.1:36605_ c:collection1 s:shard2 r:core_node7 x:collection1] o.a.s.c.S.Request [collection1] webapp= path=/select params={q=*:*&amp;amp;distrib=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;amp;tests=checkShardConsistency/showDiff&amp;amp;fl=id,_version_&amp;amp;sort=id+asc&amp;amp;rows=100000&amp;amp;wt=javabin&amp;amp;version=2} hits=2103 status=0 QTime=4 
  2&amp;gt; ######http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:43897/collection1: SolrDocumentList[sz=2076]=[SolrDocument{id=0-0, _version_=1514192448210862080}, SolrDocument{id=0-100, _version_=1514192469996077056}, SolrDocument{id=0-1000, _version_=1514192493627834368}, SolrDocument{id=0-1006, _version_=1514192493742129152}, SolrDocument{id=0-1008, _version_=1514192493795606528}] , [...] , [SolrDocument{id=ft1-984, _version_=1514192458787848193}, SolrDocument{id=ft1-991, _version_=1514192459077255168}, SolrDocument{id=ft1-992, _version_=1514192459148558336}, SolrDocument{id=ft1-994, _version_=1514192459149606912}, SolrDocument{id=ft1-997, _version_=1514192459150655488}]
&lt;/span&gt;  2&amp;gt; ######http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:36605/collection1: SolrDocumentList[sz=2103]=[SolrDocument{id=0-0, _version_=1514192448210862080}, SolrDocument{id=0-100, _version_=1514192469996077056}, SolrDocument{id=0-1000, _version_=1514192493627834368}, SolrDocument{id=0-1006, _version_=1514192493742129152}, SolrDocument{id=0-1008, _version_=1514192493795606528}] , [...] , [SolrDocument{id=ft1-984, _version_=1514192458787848193}, SolrDocument{id=ft1-991, _version_=1514192459077255168}, SolrDocument{id=ft1-992, _version_=1514192459148558336}, SolrDocument{id=ft1-994, _version_=1514192459149606912}, SolrDocument{id=ft1-997, _version_=1514192459150655488}]
&lt;/span&gt;  2&amp;gt; ###### sizes=2076,2103
  2&amp;gt; ###### Only in http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:36605/collection1: [{_version_=1514192462261780480, id=ft1-1715}, {_version_=1514192462260731904, id=ft1-1711}, {_version_=1514192462263877632, id=ft1-1719}, {_version_=1514192462262829056, id=ft1-1718}, {_version_=1514192462264926208, id=ft1-1720}, {_version_=1514192462015365120, id=ft1-1670}, {_version_=1514192462276460544, id=ft1-1722}, {_version_=1514192462415921152, id=ft1-1844}, {_version_=1514192462413824000, id=ft1-1840}, {_version_=1514192462230323200, id=ft1-1709}, {_version_=1514192462414872576, id=ft1-1841}, {_version_=1514192462412775424, id=ft1-1838}, {_version_=1514192462412775425, id=ft1-1839}, {_version_=1514192462411726848, id=ft1-1837}, {_version_=1514192462230323201, id=ft1-1710}, {_version_=1514192462057308160, id=ft1-1700}, {_version_=1514192462058356737, id=ft1-1703}, {_version_=1514192462058356736, id=ft1-1702}, {_version_=1514192462375026688, id=ft1-1796}, {_version_=1514192462400192512, id=ft1-1798}, {_version_=1514192462399143936, id=ft1-1797}, {_version_=1514192462193623040, id=ft1-1707}, {_version_=1514192462052065280, id=ft1-1679}, {_version_=1514192462055211008, id=ft1-1688}, {_version_=1514192462053113856, id=ft1-1682}, {_version_=1514192462056259584, id=ft1-1695}, {_version_=1514192462056259585, id=ft1-1698}]
&lt;/span&gt; &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14971347" author="yseeley@gmail.com" created="Fri, 23 Oct 2015 16:48:45 +0000"  >&lt;p&gt;OK, here&apos;s another failure I&apos;ve been analyzing.&lt;br/&gt;
It comes down to this:&lt;br/&gt;
1) leader is shutdown (CoreContainer.shutdown is called)&lt;br/&gt;
2) a single doc is sent from the leader to one replica successfully, but unsuccessfully to a different replica (rejected task from shutdown executor that the client is using to send)&lt;br/&gt;
3) tons of other updates are still being accepted and sent by the leader&lt;br/&gt;
4) much later, a peersync sees everything as OK since recent versions match up.&lt;/p&gt;

&lt;p&gt;One mystery is why ConcurrentUpdateSolrClient is trying to create a new Runner when there is obviously another runner already running (since it still accepts and sends new updates after that point).&lt;/p&gt;

&lt;p&gt;A general way to fix this is to make sure that shutdown happens much more quickly... we should stop reading and processing updates.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// good-doc comes into leader 53975
&lt;/span&gt;  2&amp;gt; 43204 DEBUG (qtp1536362844-206) [n:127.0.0.1:53975__%2Fzl c:collection1 s:shard2 r:core_node1 x:collection1] o.a.s.u.p.LogUpdateProcessor PRE_UPDATE add{,id=ft1-476} {wt=javabin&amp;amp;version=2}

&lt;span class=&quot;code-comment&quot;&gt;// bad-doc comes into leader 53975
&lt;/span&gt;  2&amp;gt; 43204 DEBUG (qtp1536362844-206) [n:127.0.0.1:53975__%2Fzl c:collection1 s:shard2 r:core_node1 x:collection1] o.a.s.u.p.LogUpdateProcessor PRE_UPDATE add{,id=ft1-477} {wt=javabin&amp;amp;version=2}

&lt;span class=&quot;code-comment&quot;&gt;// good-doc added to shard 57414
&lt;/span&gt;  2&amp;gt; 43273 DEBUG (qtp702407469-354) [n:127.0.0.1:57414__%2Fzl c:collection1 s:shard2 r:core_node5 x:collection1] o.a.s.u.p.LogUpdateProcessor PRE_UPDATE add{,id=ft1-476} {update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:53975/_/zl/collection1/&amp;amp;wt=javabin&amp;amp;version=2}
&lt;/span&gt;  2&amp;gt; 43280 INFO  (qtp702407469-354) [n:127.0.0.1:57414__%2Fzl c:collection1 s:shard2 r:core_node5 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp=/_/zl path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:53975/_/zl/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-467 (1514187847514456064), ft1-470 (1514187847746191360), ft1-473 (1514187847754579968), ft1-476 (1514187847755628544)]} 0 42
&lt;/span&gt;

&lt;span class=&quot;code-comment&quot;&gt;// the leader is going to be stopped in the &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt;
&lt;/span&gt;  2&amp;gt; 43345 INFO  (&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-272) [    ] o.a.s.c.ChaosMonkey monkey: stop shard! 53975
  2&amp;gt; 43345 INFO  (&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-272) [    ] o.a.s.c.CoreContainer Shutting down CoreContainer instance=171681388

&lt;span class=&quot;code-comment&quot;&gt;// overseer gets state:down &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; leader 53975 
&lt;/span&gt;  2&amp;gt; 43378 INFO  (OverseerStateUpdate-94636738141945860-127.0.0.1:49439__%2Fzl-n_0000000000) [n:127.0.0.1:49439__%2Fzl    ] o.a.s.c.Overseer processMessage: queueSize: 1, message = {

&lt;span class=&quot;code-comment&quot;&gt;// BUT... 53975 appears to keep processing updates... there are ~736 more updates like the following, continuing another couple of seconds through to time 45555
&lt;/span&gt;fail.151005_064958:  2&amp;gt; 43381 DEBUG (qtp1536362844-204) [n:127.0.0.1:53975__%2Fzl c:collection1 s:shard2 r:core_node1 x:collection1] o.a.s.u.p.LogUpdateProcessor PRE_UPDATE add{,id=ft1-1165} {wt=javabin&amp;amp;version=2}



&lt;span class=&quot;code-comment&quot;&gt;// good-doc is added to replica 44323
&lt;/span&gt;  2&amp;gt; 43449 DEBUG (qtp1776514246-272) [n:127.0.0.1:44323__%2Fzl c:collection1 s:shard2 r:core_node3 x:collection1] o.a.s.u.p.LogUpdateProcessor PRE_UPDATE add{,id=ft1-476} {update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:53975/_/zl/collection1/&amp;amp;wt=javabin&amp;amp;version=2}
&lt;/span&gt;  2&amp;gt; 43456 INFO  (qtp1776514246-272) [n:127.0.0.1:44323__%2Fzl c:collection1 s:shard2 r:core_node3 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp=/_/zl path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:53975/_/zl/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-473 (1514187847754579968), ft1-476 (1514187847755628544)]} 0 108
&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;// more signs of node being stopped
&lt;/span&gt;  2&amp;gt; 43453 WARN  (qtp1536362844-205) [n:127.0.0.1:53975__%2Fzl c:collection1 s:shard2 r:core_node1 x:collection1] o.e.j.s.ServletHandler /_/zl/collection1/update
  2&amp;gt; org.apache.solr.common.SolrException: Error processing the request. CoreContainer is either not initialized or shutting down.


&lt;span class=&quot;code-comment&quot;&gt;// bad-doc is added to replica 44323
&lt;/span&gt;  2&amp;gt; 43471 DEBUG (qtp1776514246-273) [n:127.0.0.1:44323__%2Fzl c:collection1 s:shard2 r:core_node3 x:collection1] o.a.s.u.p.LogUpdateProcessor PRE_UPDATE add{,id=ft1-477} {update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:53975/_/zl/collection1/&amp;amp;wt=javabin&amp;amp;version=2}
&lt;/span&gt;  2&amp;gt; 43501 INFO  (qtp1776514246-273) [n:127.0.0.1:44323__%2Fzl c:collection1 s:shard2 r:core_node3 x:collection1] o.a.s.u.p.LogUpdateProcessor [collection1] webapp=/_/zl path=/update params={update.distrib=FROMLEADER&amp;amp;distrib.from=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:53975/_/zl/collection1/&amp;amp;wt=javabin&amp;amp;version=2} {add=[ft1-477 (1514187847778697216)]} 0 30
&lt;/span&gt;
&lt;span class=&quot;code-comment&quot;&gt;// This is the same update thread that has our bad-doc on the leader... it can&apos;t send because the update executor has been shut down
&lt;/span&gt;  2&amp;gt; 43472 ERROR (qtp1536362844-206) [n:127.0.0.1:53975__%2Fzl c:collection1 s:shard2 r:core_node1 x:collection1] o.a.s.u.SolrCmdDistributor java.util.concurrent.RejectedExecutionException: Task org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor$1@183e1649 rejected from org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor@7552e28d[Shutting down, pool size = 5, active threads = 5, queued tasks = 0, completed tasks = 62]

&lt;span class=&quot;code-comment&quot;&gt;// Takes a &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; other executors to be shut down
&lt;/span&gt;  2&amp;gt; 45288 ERROR (qtp1536362844-204) [n:127.0.0.1:53975__%2Fzl c:collection1 s:shard2 r:core_node1 x:collection1] o.a.s.u.SolrCmdDistributor java.util.concurrent.RejectedExecutionException: Task org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor$1@4dbd9a35 rejected from org.apache.solr.common.util.ExecutorUtil$MDCAwareThreadPoolExecutor@7552e28d[Shutting down, pool size = 2, active threads = 2, queued tasks = 0, completed tasks = 65]


&lt;span class=&quot;code-comment&quot;&gt;// Peer sync... the versions show that 44323 is ahead by 14 updates, but everything &lt;span class=&quot;code-keyword&quot;&gt;else&lt;/span&gt; matches up after that point.
&lt;/span&gt;&lt;span class=&quot;code-comment&quot;&gt;// Our missing update (1514187848796864512) is older than the oldest update of either list.
&lt;/span&gt;  2&amp;gt; 49313 DEBUG (zkCallback-21-thread-2-processing-n:127.0.0.1:44323__%2Fzl) [n:127.0.0.1:44323__%2Fzl c:collection1 s:shard2 r:core_node3 x:collection1] o.a.s.u.PeerSync PeerSync: core=collection1 url=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:44323/_/zl  sorted versions from http://127.0.0.1:57414/_/zl/collection1/ = [1514187849851731968, ...
&lt;/span&gt;  2&amp;gt; 49313 INFO  (zkCallback-21-thread-2-processing-n:127.0.0.1:44323__%2Fzl) [n:127.0.0.1:44323__%2Fzl c:collection1 s:shard2 r:core_node3 x:collection1] o.a.s.u.PeerSync PeerSync: core=collection1 url=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:44323/_/zl  Our versions are newer. ourLowThreshold=1514187848979316736 otherHigh=1514187849717514240
&lt;/span&gt;

  2&amp;gt; 49567 DEBUG (qtp702407469-351) [n:127.0.0.1:57414__%2Fzl c:collection1 s:shard2 r:core_node5 x:collection1] o.a.s.u.PeerSync PeerSync: core=collection1 url=http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:57414/_/zl  sorted versions from http://127.0.0.1:44323/_/zl/collection1/ = [1514187849932472320, ...
&lt;/span&gt;

  2&amp;gt; 50327 ERROR (qtp1776514246-274) [n:127.0.0.1:44323__%2Fzl c:collection1 s:shard2 r:core_node3 x:collection1] o.a.s.c.SolrCore org.apache.solr.common.SolrException: No registered leader was found after waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; 4000ms , collection: collection1 slice: shard2

&lt;span class=&quot;code-comment&quot;&gt;// the leader is still not all the way shut down... 
&lt;/span&gt;  2&amp;gt; 62700 ERROR (qtp1536362844-206) [n:127.0.0.1:53975__%2Fzl c:collection1 s:shard2 r:core_node1 x:collection1] o.a.s.c.s.i.ConcurrentUpdateSolrClient interrupted





  2&amp;gt; ######shard2 is not consistent.  Got 2456 from http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:44323/_/zl/collection1 (previous client) and got 2455 from http://127.0.0.1:57414/_/zl/collection1
&lt;/span&gt;  2&amp;gt; 110640 INFO  (qtp1776514246-276) [n:127.0.0.1:44323__%2Fzl c:collection1 s:shard2 r:core_node3 x:collection1] o.a.s.c.S.Request [collection1] webapp=/_/zl path=/select params={q=*:*&amp;amp;distrib=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;amp;tests=checkShardConsistency/showDiff&amp;amp;fl=id,_version_&amp;amp;sort=id+asc&amp;amp;rows=100000&amp;amp;wt=javabin&amp;amp;version=2} hits=2456 status=0 QTime=91 
  2&amp;gt; 110762 INFO  (qtp702407469-354) [n:127.0.0.1:57414__%2Fzl c:collection1 s:shard2 r:core_node5 x:collection1] o.a.s.c.S.Request [collection1] webapp=/_/zl path=/select params={q=*:*&amp;amp;distrib=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;&amp;amp;tests=checkShardConsistency/showDiff&amp;amp;fl=id,_version_&amp;amp;sort=id+asc&amp;amp;rows=100000&amp;amp;wt=javabin&amp;amp;version=2} hits=2455 status=0 QTime=9 
  2&amp;gt; ######http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:44323/_/zl/collection1: SolrDocumentList[sz=2456]=[SolrDocument{id=0-100, _version_=1514187858469978112}, SolrDocument{id=0-1000, _version_=1514187879861977089}, SolrDocument{id=0-1005, _version_=1514187879928037376}, SolrDocument{id=0-1009, _version_=1514187879977320448}, SolrDocument{id=0-1011, _version_=1514187880001437696}] , [...] , [SolrDocument{id=ft1-92, _version_=1514187844608851968}, SolrDocument{id=ft1-95, _version_=1514187844616192000}, SolrDocument{id=ft1-96, _version_=1514187844623532032}, SolrDocument{id=ft1-985, _version_=1514187847262797824}, SolrDocument{id=ft1-99, _version_=1514187844641357824}]
&lt;/span&gt;  2&amp;gt; ######http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:57414/_/zl/collection1: SolrDocumentList[sz=2455]=[SolrDocument{id=0-100, _version_=1514187858469978112}, SolrDocument{id=0-1000, _version_=1514187879861977089}, SolrDocument{id=0-1005, _version_=1514187879928037376}, SolrDocument{id=0-1009, _version_=1514187879977320448}, SolrDocument{id=0-1011, _version_=1514187880001437696}] , [...] , [SolrDocument{id=ft1-92, _version_=1514187844608851968}, SolrDocument{id=ft1-95, _version_=1514187844616192000}, SolrDocument{id=ft1-96, _version_=1514187844623532032}, SolrDocument{id=ft1-985, _version_=1514187847262797824}, SolrDocument{id=ft1-99, _version_=1514187844641357824}]
&lt;/span&gt;  2&amp;gt; ###### sizes=2456,2455
  2&amp;gt; ###### Only in http:&lt;span class=&quot;code-comment&quot;&gt;//127.0.0.1:44323/_/zl/collection1: [{_version_=1514187847778697216, id=ft1-477}]&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14971436" author="yseeley@gmail.com" created="Fri, 23 Oct 2015 17:41:00 +0000"  >&lt;blockquote&gt;
&lt;p&gt;One mystery is why ConcurrentUpdateSolrClient is trying to create a new Runner when there is obviously another runner already running (since it still accepts and sends new updates after that point).&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Mark pointed me at this comment in ConcurrentUpdateSolrClient:&lt;br/&gt;
          // see if queue is half full and we can add more runners&lt;br/&gt;
          // special case: if only using a threadCount of 1 and the queue&lt;br/&gt;
          // is filling up, allow 1 add&apos;l runner to help process the queue&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thelabdude&quot; class=&quot;user-hover&quot; rel=&quot;thelabdude&quot;&gt;thelabdude&lt;/a&gt; It looks like you added that comment... but it&apos;s not clear to me how the code implements that special case.  Thoughts?&lt;/p&gt;</comment>
                            <comment id="14971564" author="thelabdude" created="Fri, 23 Oct 2015 18:34:47 +0000"  >&lt;p&gt;heh - yeah, that&apos;s my bad ... I think I had that in there at one point when I was dealing with the perf improvements but it didn&apos;t actually help or at least I had other changes that masked it&apos;s benefit. I&apos;ll revisit that idea ... for now, the comment is misleading and should be removed. Sorry &apos;bout that!&lt;/p&gt;</comment>
                            <comment id="14971697" author="shalinmangar" created="Fri, 23 Oct 2015 19:38:03 +0000"  >&lt;p&gt;Thanks for the details, Yonik.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;A general way to fix this is to make sure that shutdown happens much more quickly... we should stop reading and processing updates.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;maybe HttpSolrCall can return an error immediately if container has been shutdown?&lt;/p&gt;</comment>
                            <comment id="14971917" author="yseeley@gmail.com" created="Fri, 23 Oct 2015 21:38:24 +0000"  >&lt;p&gt;Thanks for clarifying Tim, it had me wondering what I was missing.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;maybe HttpSolrCall can return an error immediately if container has been shutdown?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, I think there are a lot of places we could check if the container has been shut down... not sure yet what is the best place.  I think &lt;b&gt;new&lt;/b&gt; calls would be rejected already... it&apos;s really existing streaming calls that are the issue I think.&lt;/p&gt;

&lt;p&gt;I&apos;m still first trying to find out why one update was rejected and then updates that happened after that were still processed though.  This particular failure would not have happened without that piece as well.&lt;/p&gt;</comment>
                            <comment id="14972038" author="yseeley@gmail.com" created="Fri, 23 Oct 2015 22:57:13 +0000"  >&lt;p&gt;I think the first thing I&apos;ll try to track down is if it&apos;s the same ConcurrentUpdateSolrClient instance or not.  If it is, that points to a race condition somewhere in that class.&lt;/p&gt;</comment>
                            <comment id="14972633" author="yseeley@gmail.com" created="Sat, 24 Oct 2015 14:53:50 +0000"  >&lt;blockquote&gt;&lt;p&gt;I&apos;m still first trying to find out why one update was rejected and then updates that happened after that were still processed though.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK, figured it out... it was my incorrect mental model assuming that there was a single ConcurrentUpdateSolrClient between a leader and a replica.&lt;br/&gt;
I made that leap looking at StreamingSolrClients.getSolrClient called from SolrCmdDistributor.  But there is a different SolrCmdDistributor created per update request to Solr.&lt;/p&gt;

&lt;p&gt;So there is no longer any mystery around the reject followed by many other updates.  Different client objects (and once they have runners going, they can keep going processing updates).&lt;/p&gt;</comment>
                            <comment id="14972652" author="yseeley@gmail.com" created="Sat, 24 Oct 2015 15:31:00 +0000"  >&lt;blockquote&gt;&lt;p&gt;maybe HttpSolrCall can return an error immediately if container has been shutdown?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think somewhere in the dispatch filter path may already reject new requests when things are shutting down.  The issue in this last fail was existing update requests that were streaming via ConcurrentUpdateSolrClient.&lt;/p&gt;

&lt;p&gt;Mark is investigating using a more aggressive shutdown (i.e. interrupt) of the update executor (it&apos;s just used to talk to other nodes).&lt;br/&gt;
We could also check the core container status anywhere in the update path as well and throw an error that would stop processing the update streams.  Thoughts?&lt;/p&gt;</comment>
                            <comment id="14972658" author="markrmiller@gmail.com" created="Sat, 24 Oct 2015 15:44:11 +0000"  >&lt;p&gt;I&apos;ve just finished beasting HdfsChaosMonkeyNothingIsSafeTest for 100 runs. The only change I made was to interrupt the update executor on shutdown. Mostly this was just a test to see if this helped and what else might still pop up.&lt;/p&gt;

&lt;p&gt;In 100 runs, I saw 4 or 5 fails, but no replica inconsistency.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;I saw control off with cloud, by 1 and by more than 1. (There is a known test issue here, but we don&apos;t know it covers all cases)&lt;/li&gt;
	&lt;li&gt;I saw a hang in CUSC#blockUntilFinished - I think I already have an open JIRA issue for something like that.&lt;/li&gt;
	&lt;li&gt;Before this 100 runs I saw a strange fail where the connection pool for the test client is shutdown while we still try and use - I removed the try, finally that wraps the test prints the zklayout on failure - I saw that printout but could not work out the real issue - just hanging threads because we didn&apos;t actually wait for indexing threads to stop. Since removing that, have not seen this, but could just be lucky. It seemed like somehow the true fail reason was being swallowed somehow.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I&apos;ll keep it running for now, while we work out the best way to cut things off faster.&lt;/p&gt;</comment>
                            <comment id="14972668" author="yseeley@gmail.com" created="Sat, 24 Oct 2015 16:13:35 +0000"  >&lt;p&gt;For now, I&apos;m going to try and run with this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Index: solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
===================================================================
--- solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java	(revision 1710343)
+++ solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java	(working copy)
@@ -1443,6 +1443,10 @@
   }
 
   &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void zkCheck() {
+    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (req.getCore().getCoreDescriptor().getCoreContainer().isShutDown()) {
+      &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; SolrException(ErrorCode.SERVICE_UNAVAILABLE, &lt;span class=&quot;code-quote&quot;&gt;&quot;CoreContainer is shutting down.&quot;&lt;/span&gt;);
+    }
+
     &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((updateCommand.getFlags() &amp;amp; (UpdateCommand.REPLAY | UpdateCommand.PEER_SYNC)) != 0) {
       &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; log reply or peer sync, we don&apos;t need to be connected to ZK
&lt;/span&gt;       &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14972695" author="yseeley@gmail.com" created="Sat, 24 Oct 2015 16:46:10 +0000"  >&lt;p&gt;I opened &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8203&quot; title=&quot;Stop processing updates more quickly on shutdown&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8203&quot;&gt;&lt;del&gt;SOLR-8203&lt;/del&gt;&lt;/a&gt; to handle these &quot;let&apos;s shutdown faster&quot; changes.&lt;/p&gt;</comment>
                            <comment id="14972741" author="markrmiller@gmail.com" created="Sat, 24 Oct 2015 17:16:31 +0000"  >&lt;blockquote&gt;&lt;p&gt;I saw a strange fail where the connection pool for the test client is shutdown while we still try and use&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Okay, this looks like it is the result of: Throwable #1: java.lang.AssertionError: The Monkey ran for over 30 seconds and no jetties were stopped - this is worth investigating!&lt;/p&gt;

&lt;p&gt;This causes the test to bail before stopping the indexing threads.&lt;/p&gt;</comment>
                            <comment id="14972759" author="markrmiller@gmail.com" created="Sat, 24 Oct 2015 17:33:15 +0000"  >&lt;p&gt;Seems the above happens because we only have one Solr instance and nothing to kill. The logic to make sure we have at least 2 is is not correct and needs to be fixed.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      &lt;span class=&quot;code-comment&quot;&gt;// we make sure that there&apos;s at least one shard with more than one replica
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// so that the ChaosMonkey has something to kill
&lt;/span&gt;      numShards = sliceCount + random().nextInt(TEST_NIGHTLY ? 12 : 2) + 1;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;should be &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      &lt;span class=&quot;code-comment&quot;&gt;// we make sure that there&apos;s at least one shard with more than one replica
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// so that the ChaosMonkey has something to kill
&lt;/span&gt;      numShards = sliceCount + random().nextInt(TEST_NIGHTLY ? 12 : 2) + 2;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
	&lt;li&gt;That&apos;s actually probably not the right fix it looks - but something like this.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14972773" author="markrmiller@gmail.com" created="Sat, 24 Oct 2015 17:53:17 +0000"  >&lt;p&gt;Actually, it appears to just be really bad luck for the monkey. The fail is reproducible, but it&apos;s actually with numSlices = 2 and numShards = 3.&lt;/p&gt;

&lt;p&gt;I was seeing:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;  [junit4]   2&amp;gt; 55703 INFO  (Thread-219) [    ] o.a.s.c.ChaosMonkey monkey: only one active node in shard - monkey cannot kill :(
   [junit4]   2&amp;gt; 57863 INFO  (Thread-219) [    ] o.a.s.c.ChaosMonkey monkey: only one active node in shard - monkey cannot kill :(
   [junit4]   2&amp;gt; 63113 INFO  (Thread-219) [    ] o.a.s.c.ChaosMonkey monkey: only one active node in shard - monkey cannot kill :(
   [junit4]   2&amp;gt; 69451 INFO  (Thread-219) [    ] o.a.s.c.ChaosMonkey monkey: only one active node in shard - monkey cannot kill :(
   [junit4]   2&amp;gt; 78330 INFO  (Thread-219) [    ] o.a.s.c.ChaosMonkey monkey: only one active node in shard - monkey cannot kill :(
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;But apparently it just keeps randomly picking the shard with only a single replica in it. With the same numShards and slices and a different seed, the test passes.&lt;/p&gt;</comment>
                            <comment id="14972790" author="jira-bot" created="Sat, 24 Oct 2015 18:22:24 +0000"  >&lt;p&gt;Commit 1710371 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markrmiller%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;markrmiller@gmail.com&quot;&gt;markrmiller@gmail.com&lt;/a&gt; in branch &apos;dev/trunk&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1710371&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1710371&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8129&quot; title=&quot;HdfsChaosMonkeyNothingIsSafeTest failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8129&quot;&gt;&lt;del&gt;SOLR-8129&lt;/del&gt;&lt;/a&gt;: Raise no kill by monkey warning from 30 to 45.&lt;/p&gt;</comment>
                            <comment id="14972802" author="jira-bot" created="Sat, 24 Oct 2015 18:33:59 +0000"  >&lt;p&gt;Commit 1710375 from &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markrmiller%40gmail.com&quot; class=&quot;user-hover&quot; rel=&quot;markrmiller@gmail.com&quot;&gt;markrmiller@gmail.com&lt;/a&gt; in branch &apos;dev/branches/branch_5x&apos;&lt;br/&gt;
[ &lt;a href=&quot;https://svn.apache.org/r1710375&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://svn.apache.org/r1710375&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8129&quot; title=&quot;HdfsChaosMonkeyNothingIsSafeTest failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8129&quot;&gt;&lt;del&gt;SOLR-8129&lt;/del&gt;&lt;/a&gt;: Raise no kill by monkey warning from 30 to 45.&lt;/p&gt;</comment>
                            <comment id="14972967" author="markrmiller@gmail.com" created="Sun, 25 Oct 2015 02:55:01 +0000"  >&lt;p&gt;Man, manyy hundreds of runs and I still have not seen a replica out of sync issue.&lt;/p&gt;

&lt;p&gt;Have not seen the above issue since the above commit either.&lt;/p&gt;</comment>
                            <comment id="14973223" author="markrmiller@gmail.com" created="Sun, 25 Oct 2015 12:46:12 +0000"  >&lt;p&gt;I ran another 500 runs overnight. No new fails. Still saw one fail where the monkey did not kill anything even after the new 45 second limit. Should probably try 60 next.&lt;/p&gt;</comment>
                            <comment id="15111065" author="yseeley@gmail.com" created="Thu, 21 Jan 2016 18:39:23 +0000"  >&lt;p&gt;Here&apos;s a visualization of a recent fail:&lt;/p&gt;

&lt;p&gt;Node A starts off as the leader, gets a bunch of updates that it ever sends to node B before it is killed.&lt;br/&gt;
Node B becomes the leader.&lt;br/&gt;
Node A comes up, does a PeerSync and the lists pretty much overlap in time (looking at low threshold / high threshold only), so node A asks node B for the docs it&apos;s missing (and ends up with a lot more docs than node B).&lt;/p&gt;

&lt;p&gt;The list below is ordered from oldest to newest:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;1523440456046739456    B 
1523440456047788032    B 
1523440456049885184    B 
1523440456050933760    B 
1523440456051982336    B 
1523440456053030912    B 
1523440456053030913    B 
1523440456053030914    B 
1523440456054079488    B 
1523440456055128064    B 
1523440456059322368    B 
1523440456314126336    B 
1523440456314126337    B 
1523440456315174912    B 
1523440456316223488    B 
1523440456318320640    B 
1523440456342437888    B 
1523440456343486464    B 
1523440456343486465    B 
1523440456344535040    B 
1523440456362360832    B 
1523440456363409408  A 
1523440456372846592  A B 
1523440456375992320  A B 
1523440456375992321  A B 
1523440456379138048  A 
1523440456381235200  A 
1523440456382283776  A B 
1523440456392769536  A 
1523440456401158144  A 
1523440456403255296  A B 
1523440456437858304  A 
1523440456463024128  A 
1523440456472461312  A 
1523440456480849920  A 
1523440456531181568  A 
1523440456543764480  A 
1523440456544813056  A 
1523440456544813057  A 
1523440456545861632  A 
1523440456550055936  A B 
1523440456552153088  A B 
1523440456552153089  A 
1523440456559493120  A B 
1523440456561590272  A B 
1523440456561590273  A B 
1523440456562638848  A B 
1523440456563687424  A B 
1523440456565784576  A 
1523440456609824768  A 
1523440456610873344  A 
1523440456610873345  A 
1523440456611921920  A 
1523440456669593600  A 
1523440456669593601  A 
1523440456669593602  A 
1523440456670642176  A 
1523440456671690752  A B 
1523440456672739328  A 
1523440456673787904  A 
1523440456674836480  A 
1523440456675885056  A 
1523440456686370816  A 
1523440456690565120  A 
1523440456702099456  A B 
1523440456726216704  A B 
1523440456772354048  A B 
1523440456785985536  A B 
1523440456826880000  A B 
1523440456857288704  A B 
1523440456858337280  A B 
1523440456921251840  A 
1523440456921251841  A 
1523440456922300416  A 
1523440456926494720  A B 
1523440456926494721  A B 
1523440456927543296  A 
1523440456927543297  A 
1523440456929640448  A B 
1523440456929640449  A 
1523440456934883328  A 
1523440456944320512  A 
1523440456950611968  A 
1523440456975777792  A 
1523440456975777793  A 
1523440456975777794  A 
1523440456976826368  A 
1523440456976826369  A 
1523440456976826370  A 
1523440456999895040  A 
1523440457004089344  A 
1523440457008283648  A 
1523440457009332224  A 
1523440457009332225  A 
1523440457010380800  A 
1523440457056518144  A B 
1523440457064906752  A B 
1523440457065955328  A B 
1523440457067003904  A B 
1523440457070149632  A B 
1523440457071198208  A B 
1523440457071198209  A B 
1523440457074343936  A B 
1523440457077489664  A B 
1523440457078538240  A B 
1523440457079586816  A B 
1523440457080635392  A B 
1523440457116286976  A 
1523440457116286977  A 
1523440457117335552  A 
1523440457138307072  A 
1523440457149841408  A 
1523440457170812928  A 
1523440457172910080  A 
1523440457173958656  A 
1523440457173958657  A 
1523440457175007232  A 
1523440457175007233  A 
1523440457180250112  A 
1523440457181298688  A 
1523440457181298689  A 
1523440460638453760    B 
1523440460641599488    B 
1523440460641599489    B 
1523440460653133824    B 
1523440460708708352    B 
1523440460881723392    B 
1523440460915277824    B 
1523440461056835584    B 
1523440461057884160    B 
1523440461145964544    B 
1523440461206781952    B 
1523440461227753472    B 
1523440461237190656    B 
1523440461259210752    B 
1523440461272842240    B 
1523440461370359808    B 
1523440461379796992    B 
1523440461486751744    B 
1523440461550714880    B 
1523440461615726592    B 
1523440461659766784    B 
1523440461713244160    B 
1523440461754138624    B 
1523440461787693056    B 
1523440461817053184    B 
1523440461862141952    B 
1523440461881016320    B 
1523440461917716480    B 
1523440461939736576    B 
1523440461953368064    B 
1523440461987971072    B 
1523440462001602560    B 
1523440462224949248    B 
1523440462292058112    B 
1523440462313029632    B 
1523440462325612544    B 
1523440462379089920    B 
1523440462421032960    B 
1523440462461927424    B 
1523440462486044672    B 
1523440462501773312    B 
1523440462545813504    B 
1523440474431422464    B
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Massive reorders, which PeerSync was not designed for.&lt;br/&gt;
Possible remedies:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;greatly lower the probability of these big reorders&lt;/li&gt;
	&lt;li&gt;where there is overlap in versions, make PeerSync check that it is &quot;dense&quot; (both shards have all docs in the overlap)
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;this seems extremely strict and could cause peersync to fail due to a missing doc right at the end of an overlap... &lt;b&gt;which&lt;/b&gt; end matters a lot.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;expand PeerSync to cover complete index
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;use hashes over &lt;b&gt;all&lt;/b&gt; versions in the index&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="15111068" author="markrmiller@gmail.com" created="Thu, 21 Jan 2016 18:42:26 +0000"  >&lt;blockquote&gt;&lt;p&gt;expand PeerSync to cover complete index&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I think this would be great if we could do it reasonably.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;greatly lower the probability of these big reorders&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Main reason I don&apos;t like this is that it just seems fragile over time, and will constrict things more.&lt;/p&gt;</comment>
                            <comment id="15111192" author="gchanan" created="Thu, 21 Jan 2016 19:53:19 +0000"  >&lt;p&gt;+1 for Mark&apos;s reasoning.&lt;/p&gt;</comment>
                            <comment id="15111261" author="yseeley@gmail.com" created="Thu, 21 Jan 2016 20:45:21 +0000"  >&lt;p&gt;Yep, but reducing the probability of big reorders will still be important, because if we do detect a big reorder (with hashes over the entire index), the only current general remedy we have is to fail peersync and copy the whole index.&lt;/p&gt;</comment>
                            <comment id="15111508" author="markrmiller@gmail.com" created="Thu, 21 Jan 2016 22:29:25 +0000"  >&lt;p&gt;Yeah, but I&apos;d prefer full replication over holes. Better that reducing reorders is an optimization than a bug.&lt;/p&gt;</comment>
                            <comment id="15111805" author="yseeley@gmail.com" created="Fri, 22 Jan 2016 02:26:24 +0000"  >&lt;blockquote&gt;&lt;p&gt;Yeah, but I&apos;d prefer full replication over holes. Better that reducing reorders is an optimization than a bug.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Sure, we&apos;re saying the same thing.  I was just pointing out that the reorders can still be very painful (and thus important) even if we improve/fix everything else.&lt;/p&gt;</comment>
                            <comment id="15111833" author="markrmiller@gmail.com" created="Fri, 22 Jan 2016 02:58:22 +0000"  >&lt;blockquote&gt;&lt;p&gt;we&apos;re saying the same thing. &lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I just get the feeling you have been trying to avoid doing this full hash, but it seems so much more bulletproof than these quick window checks. I&apos;d rather recovery be a lot slower and get it right and worry about speeding that up later. &lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;the only current general remedy we have is to fail peersync and copy the whole index.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;These kind of reorders don&apos;t seem that common? And we have many other reasons you will probably have to replicate the whole index. 100 updates in peer sync means it&apos;s best simply for static indexes or low usage indexes. Sure, I&apos;d rather not replicate a full index, but I think it&apos;s pretty common to have to do already.&lt;/p&gt;

</comment>
                            <comment id="15112775" author="yseeley@gmail.com" created="Fri, 22 Jan 2016 17:50:50 +0000"  >&lt;p&gt;Opened &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8586&quot; title=&quot;Implement hash over all documents to check for shard synchronization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8586&quot;&gt;&lt;del&gt;SOLR-8586&lt;/del&gt;&lt;/a&gt; for hashing all versions.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;These kind of reorders don&apos;t seem that common?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Seems way too common on HDFS (on my linux box at least).  &lt;/p&gt;

&lt;p&gt;Even with &lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8586&quot; title=&quot;Implement hash over all documents to check for shard synchronization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8586&quot;&gt;&lt;del&gt;SOLR-8586&lt;/del&gt;&lt;/a&gt;, big enough reorders can still cause other issues, such as going beyond our delete window.  That would cause shards to get out-of-sync even when all the shards are up and live (and hence we wouldn&apos;t catch it until the next time we did a version-hash for some reason).&lt;/p&gt;</comment>
                            <comment id="15119905" author="jeremie.monsinjon@gmail.com" created="Wed, 27 Jan 2016 18:09:00 +0000"  >&lt;p&gt;I&#8217;m stressing a SolR cluster with Gatling for perf tests. 3 shards, 3 nodes per shard (1 leader, 2 replicas). &lt;br/&gt;
About 300 updates per second using CloudSolrServer (about 100 per shard) and 40 qps.&lt;br/&gt;
Using round robin for select queries on each node.&lt;br/&gt;
After 2 minutes playing the scenario, it seems that the leader of a shard can&#8217;t send an update to a replica.&lt;/p&gt;

&lt;p&gt;REPLICA : 51&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:18:00.252 WARN  (qtp1057941451-128982) [   ] o.e.j.h.HttpParser badMessage: java.lang.IllegalStateException: too much data after closed for HttpChannelOverHttp@428e80f&lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {r=1098,c=false,a=IDLE,uri=-}&lt;/span&gt; &lt;/div&gt;&lt;/blockquote&gt;

&lt;p&gt;LEADER : 33&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:18:00.245 ERROR (updateExecutor-2-thread-3557-processing-&lt;a href=&quot;http:////solrNode051:8983//solr//offers_full_shard3_replica1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http:////solrNode051:8983//solr//offers_full_shard3_replica1&lt;/a&gt; x:offers_full_shard3_replica3 r:core_node10 n:solrNode033:8983_solr s:shard3 c:offers_full) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.u.StreamingSolrClients error&lt;br/&gt;
org.apache.http.NoHttpResponseException: solrNode051:8983 failed to respond&lt;br/&gt;
2016-01-27 15:18:00.267 INFO  (qtp1057941451-45551) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ZkController Put replica core=offers_full_shard3_replica1 coreNodeName=core_node3 on solrNode051:8983_solr into leader-initiated recovery.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;REPLICA : 51&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:18:00.276 INFO  (qtp1057941451-129018) [   ] o.a.s.h.a.CoreAdminHandler It has been requested that we recover: core=offers_full_shard3_replica1&lt;br/&gt;
2016-01-27 15:18:00.277 INFO  (Thread-117036) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node3 x:offers_full_shard3_replica1&amp;#93;&lt;/span&gt; o.a.s.u.DefaultSolrCoreState Running recovery - first canceling any ongoing recovery&lt;/p&gt;

&lt;p&gt;2016-01-27 15:18:08.296 INFO  (updateExecutor-2-thread-4594-processing-n:solrNode051:8983_solr x:offers_full_shard3_replica1 s:shard3 c:offers_full r:core_node3) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node3 x:offers_full_shard3_replica1&amp;#93;&lt;/span&gt; o.a.s.c.RecoveryStrategy Attempting to PeerSync from &lt;a href=&quot;http://solrNode033:8983/solr/offers_full_shard3_replica3/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://solrNode033:8983/solr/offers_full_shard3_replica3/&lt;/a&gt; - recoveringAfterStartup=false&lt;/p&gt;

&lt;p&gt;2016-01-27 15:18:08.296 ERROR (updateExecutor-2-thread-4594-processing-n:solrNode051:8983_solr x:offers_full_shard3_replica1 s:shard3 c:offers_full r:core_node3) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node3 x:offers_full_shard3_replica1&amp;#93;&lt;/span&gt; o.a.s.u.PeerSync PeerSync: core=offers_full_shard3_replica1 url=&lt;a href=&quot;http://solrNode051:8983/solr&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://solrNode051:8983/solr&lt;/a&gt; ERROR, update log not in ACTIVE or REPLAY state. FSUpdateLog{state=BUFFERING, tlog=tlog{file=/var/lib/solr5/data/offers_full_shard3_replica1/data/tlog/tlog.0000000000000004550 refcount=1}}&lt;br/&gt;
2016-01-27 15:18:08.297 WARN  (updateExecutor-2-thread-4594-processing-n:solrNode051:8983_solr x:offers_full_shard3_replica1 s:shard3 c:offers_full r:core_node3) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node3 x:offers_full_shard3_replica1&amp;#93;&lt;/span&gt; o.a.s.u.PeerSync PeerSync: core=offers_full_shard3_replica1 url=&lt;a href=&quot;http://solrNode051:8983/solr&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://solrNode051:8983/solr&lt;/a&gt; too many updates received since start - startingUpdates no longer overlaps with our currentUpdates&lt;/p&gt;

&lt;p&gt;2016-01-27 15:18:15.160 WARN  (updateExecutor-2-thread-4594-processing-n:solrNode051:8983_solr x:offers_full_shard3_replica1 s:shard3 c:offers_full r:core_node3) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node3 x:offers_full_shard3_replica1&amp;#93;&lt;/span&gt; o.a.s.h.IndexFetcher File _d2r_1wk.liv did not match. expected checksum is 3620017595 and actual is checksum 442433238. expected length is 38405 and actual length is 38405&lt;br/&gt;
2016-01-27 15:18:15.160 INFO  (updateExecutor-2-thread-4594-processing-n:solrNode051:8983_solr x:offers_full_shard3_replica1 s:shard3 c:offers_full r:core_node3) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node3 x:offers_full_shard3_replica1&amp;#93;&lt;/span&gt; o.a.s.h.IndexFetcher Starting download (fullCopy=true) to NRTCachingDirectory(MMapDirectory@/var/lib/solr5/data/offers_full_shard3_replica1/data/index.20160127151815143 lockFactory=org.apache.lucene.store.NativeFSLockFactory@721552d5; maxCacheMB=48.0 maxMergeSizeMB=4.0)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;REPLICA : 27&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:20:54.009 INFO  (zkCallback-3-thread-198-processing-n:solrNode027:8983_solr) [   ] o.a.s.c.c.ZkStateReader A live node change: WatchedEvent state:Sync&lt;br/&gt;
Connected type:NodeChildrenChanged path:/live_nodes, has occurred - updating... (live nodes size: 11)&lt;br/&gt;
2016-01-27 15:20:54.016 INFO  (zkCallback-3-thread-198-processing-n:solrNode027:8983_solr) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node7 x:offers_full_shard3_replica2&amp;#93;&lt;/span&gt; o.a.s.c.ShardLeaderElectionContext Running the leader process for shard shard3&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;REPLICA : 51&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:20:54.011 INFO  (zkCallback-3-thread-110-processing-n:solrNode051:8983_solr) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node3 x:offers_full_shard3_replica1&amp;#93;&lt;/span&gt; o.a.s.u.DefaultSolrCoreState Running recovery - first canceling any ongoing recovery&lt;/p&gt;&lt;/blockquote&gt;	

&lt;p&gt;REPLICA : 27&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;BECAME THE LEADER&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:20:56.525 INFO  (zkCallback-3-thread-198-processing-n:solrNode027:8983_solr) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node7 x:offers_full_shard3_replica2&amp;#93;&lt;/span&gt; o.a.s.c.SyncStrategy Sync Success - now sync replicas to me&lt;/p&gt;

&lt;p&gt;2016-01-27 15:21:08.793 ERROR (qtp1057941451-43187) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node7 x:offers_full_shard3_replica2&amp;#93;&lt;/span&gt; o.a.s.u.p.DistributedUpdateProcessor Request says it is coming from leader, but we are the leader: update.distrib=FROMLEADER&amp;amp;distrib.from=&lt;a href=&quot;http://solrNode033:8983/solr/offers_full_shard3_replica3/&amp;amp;wt=javabin&amp;amp;version=2&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://solrNode033:8983/solr/offers_full_shard3_replica3/&amp;amp;wt=javabin&amp;amp;version=2&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;	

&lt;p&gt;(OLD) LEADER : 33&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:21:08.801 ERROR (qtp1057941451-45871) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.u.p.DistributedUpdateProcessor On core_node10, replica &lt;a href=&quot;http://solrNode027:8983/solr/offers_full_shard3_replica2/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://solrNode027:8983/solr/offers_full_shard3_replica2/&lt;/a&gt; now thinks it is the leader! Failing the request to let the client retry! org.apache.solr.common.SolrException:Service Unavailable&lt;/p&gt;

&lt;p&gt;2016-01-27 15:21:09.712 INFO  (zkCallback-3-thread-36-processing-n:solrNode033:8983_solr-EventThread) [   ] o.a.s.c.c.ConnectionManager Our previous ZooKeeper session was expired. Attempting to reconnect to recover relationship with ZooKeeper...&lt;/p&gt;

&lt;p&gt;2016-01-27 15:21:09.747 INFO  (zkCallback-3-thread-36-processing-n:solrNode033:8983_solr-EventThread) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ZkController publishing state=down&lt;br/&gt;
2016-01-27 15:21:09.760 INFO  (zkCallback-3-thread-36-processing-n:solrNode033:8983_solr-EventThread) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ZkController Replica core_node10 NOT in leader-initiated recovery, need to wait for leader to see down state.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;(NEW) LEADER : 27&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:21:10.137 INFO  (zkCallback-3-thread-199-processing-n:solrNode027:8983_solr) [   ] o.a.s.c.c.ZkStateReader A cluster state change: WatchedEvent state:SyncConnected type:NodeDataChanged path:/collections/offers_full/state.json for collection offers_full has occurred - updating... (live nodes size: 10)&lt;br/&gt;
2016-01-27 15:21:10.139 INFO  (zkCallback-3-thread-199-processing-n:solrNode027:8983_solr) [   ] o.a.s.c.c.ZkStateReader Updating data for offers_full from 1344 to 1345&lt;br/&gt;
2016-01-27 15:21:10.215 INFO  (qtp1057941451-43418) [   ] o.a.s.h.a.CoreAdminHandler Going to wait for coreNodeName: core_node10, state: down, checkLive: null, onlyIfLeader: null, onlyIfLeaderActive: null&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;(OLD) LEADER : 33&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:21:10.220 INFO  (zkCallback-3-thread-36-processing-n:solrNode033:8983_solr-EventThread) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ElectionContext cancelElection did not find election node to remove /overseer_elect/election/238989758703863355-solrNode033:8983_solr-n_0000000158&lt;br/&gt;
2016-01-27 15:21:10.221 INFO  (zkCallback-3-thread-36-processing-n:solrNode033:8983_solr-EventThread) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.LeaderElector Joined leadership election with path: /overseer_elect/election/238989758703863364-solrNode033:8983_solr-n_0000000175&lt;br/&gt;
2016-01-27 15:21:10.238 INFO  (zkCallback-3-thread-36-processing-n:solrNode033:8983_solr-EventThread) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ZkController Register node as live in ZooKeeper:/live_nodes/solrNode033:8983_solr&lt;br/&gt;
2016-01-27 15:21:10.290 INFO  (updateExecutor-2-thread-3542-processing-n:solrNode033:8983_solr x:offers_full_shard3_replica3 s:shard3 c:offers_full r:core_node10) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.RecoveryStrategy Sending prep recovery command to &lt;a href=&quot;http://solrNode027:8983/solr&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://solrNode027:8983/solr&lt;/a&gt;; WaitForState: action=PREPRECOVERY&amp;amp;core=offers_full_shard3_replica2&amp;amp;nodeName=solrNode033:8983_solr&amp;amp;coreNodeName=core_node10&amp;amp;state=recovering&amp;amp;checkLive=true&amp;amp;onlyIfLeader=true&amp;amp;onlyIfLeaderActive=true&lt;/p&gt;&lt;/blockquote&gt;	

&lt;p&gt;(NEW) LEADER : 27&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:21:10.329 INFO  (qtp1057941451-43519) [   ] o.a.s.s.HttpSolrCall &lt;span class=&quot;error&quot;&gt;&amp;#91;admin&amp;#93;&lt;/span&gt; webapp=null path=/admin/cores params=&lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {nodeName=solrNode033}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; status=0 QTime=2&lt;/p&gt;&lt;/blockquote&gt;	

&lt;p&gt;(OLD) LEADER : 33&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Process Recovering&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:21:52.007 INFO  (zkCallback-3-thread-211-processing-n:solrNode033:8983_solr) [   ] o.a.s.c.c.ZkStateReader A live node change: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/live_nodes, has occurred - updating... (live nodes size: 11)&lt;br/&gt;
2016-01-27 15:21:52.008 INFO  (zkCallback-3-thread-210-processing-n:solrNode033:8983_solr) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ActionThrottle The last leader attempt started 22366010ms ago.&lt;br/&gt;
2016-01-27 15:21:52.008 INFO  (zkCallback-3-thread-210-processing-n:solrNode033:8983_solr) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ShardLeaderElectionContext Running the leader process for shard shard3&lt;br/&gt;
2016-01-27 15:21:52.007 INFO  (zkCallback-3-thread-211-processing-n:solrNode033:8983_solr) [   ] o.a.s.c.c.ZkStateReader A live node change: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/live_nodes, has occurred - updating... (live nodes size: 11)&lt;br/&gt;
2016-01-27 15:21:52.011 INFO  (zkCallback-3-thread-210-processing-n:solrNode033:8983_solr) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ShardLeaderElectionContext Checking if I should try and be the leader.&lt;br/&gt;
2016-01-27 15:21:52.011 INFO  (zkCallback-3-thread-210-processing-n:solrNode033:8983_solr) &lt;span class=&quot;error&quot;&gt;&amp;#91;c:offers_full s:shard3 r:core_node10 x:offers_full_shard3_replica3&amp;#93;&lt;/span&gt; o.a.s.c.ShardLeaderElectionContext There may be a better leader candidate than us - going back into recovery&lt;/p&gt;&lt;/blockquote&gt;	

&lt;p&gt;(NEW) LEADER : 27&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2016-01-27 15:21:53.211 INFO  (zkCallback-3-thread-73-processing-n:solrNode027:8983_solr-EventThread) [   ] o.a.s.c.c.ConnectionManager Watcher org.apache.solr.common.cloud.ConnectionManager@478ca953 name:ZooKeeperConnection Watcher:solrNode013:2181,solrNode014:2181,solrNode015:2181 got event WatchedEvent state:Disconnected type:None path:null path:null type:None&lt;br/&gt;
2016-01-27 15:21:53.211 INFO  (zkCallback-3-thread-73-processing-n:solrNode027:8983_solr-EventThread) [   ] o.a.s.c.c.ConnectionManager zkClient has disconnected	&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;All this time, the replica 51 can&apos;t catch up and stay in recovering	state.&lt;br/&gt;
The old leader 33 stays in full recovering state because 27 is the new leader. During several minutes, the node 33 tries to download all the segments but fail on every checksum (&quot;expected length is 137136 and actual length is 2096582&quot; for example)&lt;br/&gt;
Because it cannot keep its zookeeper session, the 27 stays down because there are no leader for the shard...&lt;/p&gt;

&lt;p&gt;This behaviour happens every time I send too many QPS... Under 40 qps, we do not have any problems...&lt;/p&gt;

&lt;p&gt;Does it look similar to these ChaosMonkey failures ?&lt;/p&gt;</comment>
                            <comment id="15126091" author="stephlag" created="Mon, 1 Feb 2016 10:44:05 +0000"  >&lt;p&gt;I&apos;m trying to gather all issues related to SolrCloud that affects Solr 5.4. Can you affect SolrCloud component to this issue ?&lt;/p&gt;</comment>
                            <comment id="15873937" author="jira-bot" created="Mon, 20 Feb 2017 01:41:05 +0000"  >&lt;p&gt;Commit 72f71275b28635cc4383fa12923245aaba69d592 in lucene-solr&apos;s branch refs/heads/master from markrmiller&lt;br/&gt;
[ &lt;a href=&quot;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=72f7127&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=72f7127&lt;/a&gt; ]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SOLR-8129&quot; title=&quot;HdfsChaosMonkeyNothingIsSafeTest failures&quot; class=&quot;issue-link&quot; data-issue-key=&quot;SOLR-8129&quot;&gt;&lt;del&gt;SOLR-8129&lt;/del&gt;&lt;/a&gt;: Harden HdfsChaosMonkeyNothingIsSafeTest some&lt;/p&gt;</comment>
                            <comment id="15878458" author="markrmiller@gmail.com" created="Wed, 22 Feb 2017 15:20:23 +0000"  >&lt;p&gt;I&apos;m going to close this and open a new issue for more recent failures.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12736076">SOLR-6406</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12907664">SOLR-8203</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12933397">SOLR-8586</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12768337" name="fail.151005_064958" size="11795076" author="yseeley@gmail.com" created="Fri, 23 Oct 2015 16:48:45 +0000"/>
                            <attachment id="12765192" name="fail.151005_080319" size="14348472" author="yseeley@gmail.com" created="Tue, 6 Oct 2015 15:59:33 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            8 years, 38 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i2mlhz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12313321" key="com.atlassian.jira.toolkit:message">
                        <customfieldname>Solr Mailing List Info</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>