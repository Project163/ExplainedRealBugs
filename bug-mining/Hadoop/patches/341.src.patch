diff --git a/hadoop-assemblies/src/main/resources/assemblies/hadoop-dist.xml b/hadoop-assemblies/src/main/resources/assemblies/hadoop-dist.xml
index 02c104bbfb9..4d4e5377387 100644
--- a/hadoop-assemblies/src/main/resources/assemblies/hadoop-dist.xml
+++ b/hadoop-assemblies/src/main/resources/assemblies/hadoop-dist.xml
@@ -113,7 +113,6 @@
       <useProjectArtifact>false</useProjectArtifact>
       <excludes>
         <exclude>org.apache.ant:*:jar</exclude>
-        <exclude>org.apache.hadoop:hadoop-*:jar</exclude>
         <exclude>jdiff:jdiff:jar</exclude>
       </excludes>
     </dependencySet>
diff --git a/hadoop-common/CHANGES.txt b/hadoop-common/CHANGES.txt
index 2bc86d980d1..5c31200f6e6 100644
--- a/hadoop-common/CHANGES.txt
+++ b/hadoop-common/CHANGES.txt
@@ -522,6 +522,9 @@ Trunk (unreleased changes)
     HADOOP-7567. 'mvn eclipse:eclipse' fails for hadoop-alfredo (auth).
     (Alejandro Abdelnur via tomwhite)
 
+    HADOOP-7563. Setup HADOOP_HDFS_HOME, HADOOP_MAPRED_HOME and classpath
+    correction. (Eric Yang via acmurthy) 
+
 Release 0.22.0 - Unreleased
 
   INCOMPATIBLE CHANGES
diff --git a/hadoop-common/src/main/bin/hadoop b/hadoop-common/src/main/bin/hadoop
index d42644d377b..e17f019d0e7 100755
--- a/hadoop-common/src/main/bin/hadoop
+++ b/hadoop-common/src/main/bin/hadoop
@@ -21,11 +21,7 @@ bin=`which $0`
 bin=`dirname ${bin}`
 bin=`cd "$bin"; pwd`
  
-if [ -e "$bin/../libexec/hadoop-config.sh" ]; then
-  . "$bin"/../libexec/hadoop-config.sh
-else
-  . "$bin"/hadoop-config.sh
-fi
+. "$bin"/../libexec/hadoop-config.sh
 
 function print_usage(){
   echo "Usage: hadoop [--config confdir] COMMAND"
diff --git a/hadoop-common/src/main/bin/hadoop-config.sh b/hadoop-common/src/main/bin/hadoop-config.sh
index 6b5520219b1..0803fe268a3 100644
--- a/hadoop-common/src/main/bin/hadoop-config.sh
+++ b/hadoop-common/src/main/bin/hadoop-config.sh
@@ -139,64 +139,19 @@ fi
 # CLASSPATH initially contains $HADOOP_CONF_DIR
 CLASSPATH="${HADOOP_CONF_DIR}"
 
-# for developers, add Hadoop classes to CLASSPATH
-if [ -d "$HADOOP_PREFIX/build/classes" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/build/classes
-fi
-if [ -d "$HADOOP_PREFIX/build/webapps" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/build
-fi
-if [ -d "$HADOOP_PREFIX/build/test/classes" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/build/test/classes
-fi
-if [ -d "$HADOOP_PREFIX/build/test/core/classes" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/build/test/core/classes
-fi
-
 # so that filenames w/ spaces are handled correctly in loops below
 IFS=
 
 # for releases, add core hadoop jar & webapps to CLASSPATH
-if [ -d "$HADOOP_PREFIX/webapps" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX
+if [ -d "$HADOOP_PREFIX/share/hadoop/common/webapps" ]; then
+  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/share/hadoop/common/webapps
 fi
 
 if [ -d "$HADOOP_PREFIX/share/hadoop/common/lib" ]; then
-  for f in $HADOOP_PREFIX/share/hadoop/common/lib/*.jar; do
-    CLASSPATH=${CLASSPATH}:$f;
-  done
+  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/share/hadoop/common/lib'/*'
 fi
 
-for f in $HADOOP_PREFIX/share/hadoop/common/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-
-# for developers, add libs to CLASSPATH
-for f in $HADOOP_PREFIX/lib/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-
-if [ -d "$HADOOP_PREFIX/build/ivy/lib/Hadoop-Common/common" ]; then
-for f in $HADOOP_PREFIX/build/ivy/lib/Hadoop-Common/common/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-fi
-
-if [ -d "$HADOOP_PREFIX/build/ivy/lib/hadoop-hdfs/hdfs" ]; then
-for f in $HADOOP_PREFIX/build/ivy/lib/hadoop-hdfs/hdfs/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-fi
-
-if [ -d "$HADOOP_PREFIX/build/ivy/lib/Hadoop/mapred" ]; then
-for f in $HADOOP_PREFIX/build/ivy/lib/Hadoop/mapred/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-fi
-
-for f in $HADOOP_PREFIX/lib/jsp-2.1/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
+CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/share/hadoop/common'/*'
 
 # add user-specified CLASSPATH last
 if [ "$HADOOP_CLASSPATH" != "" ]; then
@@ -274,37 +229,20 @@ HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"
 # put hdfs in classpath if present
 if [ "$HADOOP_HDFS_HOME" = "" ]; then
   if [ -d "${HADOOP_PREFIX}/share/hadoop/hdfs" ]; then
-    HADOOP_HDFS_HOME=$HADOOP_PREFIX/share/hadoop/hdfs
-    #echo Found HDFS installed at $HADOOP_HDFS_HOME
+    HADOOP_HDFS_HOME=$HADOOP_PREFIX
   fi
 fi
 
-if [ -d "${HADOOP_HDFS_HOME}" ]; then
+if [ -d "$HADOOP_HDFS_HOME/share/hadoop/hdfs/webapps" ]; then
+  CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME/share/hadoop/hdfs
+fi
 
-  if [ -d "$HADOOP_HDFS_HOME/webapps" ]; then
-    CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME
-  fi
-  
-  if [ ! -d "${HADOOP_CONF_DIR}" ] && [ -d "${HADOOP_HDFS_HOME}/conf" ]; then
-    CLASSPATH=${CLASSPATH}:${HADOOP_HDFS_HOME}/conf
-  fi
-  
-  for f in $HADOOP_HDFS_HOME/hadoop-hdfs-*.jar; do
-    CLASSPATH=${CLASSPATH}:$f;
-  done
-
-  # add libs to CLASSPATH
-  if [ -d "${HADOOP_HDFS_HOME}/lib" ]; then
-    for f in $HADOOP_HDFS_HOME/lib/*.jar; do
-      CLASSPATH=${CLASSPATH}:$f;
-    done
-  fi
-  
-  if [ -d "$HADOOP_HDFS_HOME/build/classes" ]; then
-    CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME/build/classes
-  fi
+if [ -d "$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib" ]; then
+  CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib'/*'
 fi
 
+CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME/share/hadoop/hdfs'/*'
+
 # cygwin path translation
 if $cygwin; then
   HADOOP_HDFS_HOME=`cygpath -w "$HADOOP_HDFS_HOME"`
@@ -313,44 +251,16 @@ fi
 # set mapred home if mapred is present
 if [ "$HADOOP_MAPRED_HOME" = "" ]; then
   if [ -d "${HADOOP_PREFIX}/share/hadoop/mapreduce" ]; then
-    HADOOP_MAPRED_HOME=$HADOOP_PREFIX/share/hadoop/mapreduce
+    HADOOP_MAPRED_HOME=$HADOOP_PREFIX
   fi
 fi
 
-if [ -d "${HADOOP_MAPRED_HOME}" ]; then
-
-  if [ -d "$HADOOP_MAPRED_HOME/webapps" ]; then
-    CLASSPATH=${CLASSPATH}:$HADOOP_MAPRED_HOME
-  fi
-
-  if [ ! -d "${HADOOP_CONF_DIR}" ] && [ -d "${HADOOP_MAPRED_HOME}/conf" ]; then
-    CLASSPATH=${CLASSPATH}:${HADOOP_MAPRED_HOME}/conf
-  fi
-  
-  for f in $HADOOP_MAPRED_HOME/hadoop-mapreduce-*.jar; do
-    CLASSPATH=${CLASSPATH}:$f
-  done
-
-  if [ -d "${HADOOP_MAPRED_HOME}/lib" ]; then
-    for f in $HADOOP_MAPRED_HOME/lib/*.jar; do
-      CLASSPATH=${CLASSPATH}:$f
-    done
-  fi
-
-  if [ -d "$HADOOP_MAPRED_HOME/build/classes" ]; then
-    CLASSPATH=${CLASSPATH}:$HADOOP_MAPRED_HOME/build/classes
-  fi
-
-  if [ -d "$HADOOP_MAPRED_HOME/build/tools" ]; then
-    CLASSPATH=${CLASSPATH}:$HADOOP_MAPRED_HOME/build/tools
-  fi
+if [ -d "$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/webapps" ]; then
+  CLASSPATH=${CLASSPATH}:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/webapps
+fi
 
-  for f in $HADOOP_MAPRED_HOME/hadoop-mapreduce-tools-*.jar; do
-    TOOL_PATH=${TOOL_PATH}:$f;
-  done
-  for f in $HADOOP_MAPRED_HOME/build/hadoop-mapreduce-tools-*.jar; do
-    TOOL_PATH=${TOOL_PATH}:$f;
-  done
+if [ -d "$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib" ]; then
+  CLASSPATH=${CLASSPATH}:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib'/*'
 fi
 
 # cygwin path translation
diff --git a/hadoop-common/src/main/bin/hadoop-daemon.sh b/hadoop-common/src/main/bin/hadoop-daemon.sh
index 93fd1705693..01aaad4298a 100755
--- a/hadoop-common/src/main/bin/hadoop-daemon.sh
+++ b/hadoop-common/src/main/bin/hadoop-daemon.sh
@@ -39,11 +39,7 @@ fi
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hadoop-config.sh" ]; then
-  . "$bin"/../libexec/hadoop-config.sh
-else
-  . "$bin"/hadoop-config.sh
-fi
+. "$bin"/../libexec/hadoop-config.sh
 
 # get arguments
 
diff --git a/hadoop-common/src/main/bin/hadoop-daemons.sh b/hadoop-common/src/main/bin/hadoop-daemons.sh
index e61ad0cca91..08c7e23ac93 100755
--- a/hadoop-common/src/main/bin/hadoop-daemons.sh
+++ b/hadoop-common/src/main/bin/hadoop-daemons.sh
@@ -29,10 +29,6 @@ fi
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hadoop-config.sh" ]; then
-  . "$bin"/../libexec/hadoop-config.sh
-else
-  . "$bin"/hadoop-config.sh
-fi
+. "$bin"/../libexec/hadoop-config.sh
 
 exec "$bin/slaves.sh" --config $HADOOP_CONF_DIR cd "$HADOOP_PREFIX" \; "$bin/hadoop-daemon.sh" --config $HADOOP_CONF_DIR "$@"
diff --git a/hadoop-common/src/main/bin/rcc b/hadoop-common/src/main/bin/rcc
index 9433e98314e..ebeebd0ee25 100755
--- a/hadoop-common/src/main/bin/rcc
+++ b/hadoop-common/src/main/bin/rcc
@@ -50,40 +50,6 @@ fi
 JAVA=$JAVA_HOME/bin/java
 JAVA_HEAP_MAX=-Xmx1000m 
 
-# CLASSPATH initially contains $HADOOP_CONF_DIR
-CLASSPATH="${HADOOP_CONF_DIR}"
-
-# for developers, add Hadoop classes to CLASSPATH
-if [ -d "$HADOOP_PREFIX/build/classes" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/build/classes
-fi
-if [ -d "$HADOOP_PREFIX/build/webapps" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/build
-fi
-if [ -d "$HADOOP_PREFIX/build/test/classes" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/build/test/classes
-fi
-
-# so that filenames w/ spaces are handled correctly in loops below
-IFS=
-
-# for releases, add core hadoop jar & webapps to CLASSPATH
-if [ -d "$HADOOP_PREFIX/webapps" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX
-fi
-for f in $HADOOP_PREFIX/hadoop-*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-
-# add libs to CLASSPATH
-for f in $HADOOP_PREFIX/lib/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-
-for f in $HADOOP_PREFIX/lib/jetty-ext/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-
 # restore ordinary behaviour
 unset IFS
 
diff --git a/hadoop-common/src/main/bin/slaves.sh b/hadoop-common/src/main/bin/slaves.sh
index f31b08a5d14..153f4416f7d 100755
--- a/hadoop-common/src/main/bin/slaves.sh
+++ b/hadoop-common/src/main/bin/slaves.sh
@@ -38,11 +38,7 @@ fi
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hadoop-config.sh" ]; then
-  . "$bin"/../libexec/hadoop-config.sh
-else
-  . "$bin"/hadoop-config.sh
-fi
+. "$bin"/../libexec/hadoop-config.sh
 
 if [ -f "${HADOOP_CONF_DIR}/hadoop-env.sh" ]; then
   . "${HADOOP_CONF_DIR}/hadoop-env.sh"
diff --git a/hadoop-common/src/main/bin/start-all.sh b/hadoop-common/src/main/bin/start-all.sh
index 666cb1b8fd1..646c9b78020 100755
--- a/hadoop-common/src/main/bin/start-all.sh
+++ b/hadoop-common/src/main/bin/start-all.sh
@@ -23,11 +23,7 @@ echo "This script is Deprecated. Instead use start-dfs.sh and start-mapred.sh"
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hadoop-config.sh" ]; then
-  . "$bin"/../libexec/hadoop-config.sh
-else
-  . "$bin"/hadoop-config.sh
-fi
+. "$bin"/../libexec/hadoop-config.sh
 
 # start hdfs daemons if hdfs is present
 if [ -f "${HADOOP_HDFS_HOME}"/bin/start-dfs.sh ]; then
diff --git a/hadoop-common/src/main/bin/stop-all.sh b/hadoop-common/src/main/bin/stop-all.sh
index 37b07f4d7f7..9adb5a4e031 100755
--- a/hadoop-common/src/main/bin/stop-all.sh
+++ b/hadoop-common/src/main/bin/stop-all.sh
@@ -23,11 +23,7 @@ echo "This script is Deprecated. Instead use stop-dfs.sh and stop-mapred.sh"
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hadoop-config.sh" ]; then
-  . "$bin"/../libexec/hadoop-config.sh
-else
-  . "$bin"/hadoop-config.sh
-fi
+. "$bin"/../libexec/hadoop-config.sh
 
 # stop hdfs daemons if hdfs is present
 if [ -f "${HADOOP_HDFS_HOME}"/bin/stop-dfs.sh ]; then
diff --git a/hadoop-hdfs/src/main/bin/distribute-exclude.sh b/hadoop-hdfs/src/main/bin/distribute-exclude.sh
index 2d1f3d50f23..cc538f72d37 100644
--- a/hadoop-hdfs/src/main/bin/distribute-exclude.sh
+++ b/hadoop-hdfs/src/main/bin/distribute-exclude.sh
@@ -36,11 +36,7 @@
 bin=`dirname "$0"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin/../libexec/hdfs-config.sh"
-else
-  . "$bin/hdfs-config.sh" 
-fi
+. "$bin/../libexec/hdfs-config.sh"
 
 if [ "$1" = '' ] ; then
   "Error: please specify local exclude file as a first argument"
diff --git a/hadoop-hdfs/src/main/bin/hdfs b/hadoop-hdfs/src/main/bin/hdfs
index 0d41b21705f..8e8b1cfafc2 100755
--- a/hadoop-hdfs/src/main/bin/hdfs
+++ b/hadoop-hdfs/src/main/bin/hdfs
@@ -19,11 +19,7 @@ bin=`which $0`
 bin=`dirname ${bin}`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin"/../libexec/hdfs-config.sh
-else
-  . "$bin/hdfs-config.sh"
-fi
+. "$bin"/../libexec/hdfs-config.sh
 
 function print_usage(){
   echo "Usage: hdfs [--config confdir] COMMAND"
@@ -109,45 +105,6 @@ else
   CLASS="$COMMAND"
 fi
 
-# for developers, add hdfs classes to CLASSPATH
-if [ -d "$HADOOP_HDFS_HOME/build/classes" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME/build/classes
-fi
-if [ -d "$HADOOP_HDFS_HOME/build/web/webapps" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME/build/web
-fi
-if [ -d "$HADOOP_HDFS_HOME/build/test/classes" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME/build/test/classes
-fi
-if [ -d "$HADOOP_HDFS_HOME/build/tools" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_HDFS_HOME/build/tools
-fi
-
-if [ -d "$HADOOP_HDFS_HOME/build/ivy/lib/hadoop-hdfs/common" ]; then
-  for f in $HADOOP_HDFS_HOME/build/ivy/lib/hadoop-hdfs/common/*.jar; do
-    CLASSPATH=${CLASSPATH}:$f;
-  done
-fi
-
-if [ -d "$HADOOP_HDFS_HOME/build/ivy/lib/hadoop-hdfs/hdfs" ]; then
-  for f in $HADOOP_HDFS_HOME/build/ivy/lib/hadoop-hdfs/hdfs/*.jar; do
-    CLASSPATH=${CLASSPATH}:$f;
-  done
-fi
-
-# for releases, add core hdfs jar & webapps to CLASSPATH
-if [ -d "$HADOOP_PREFIX/share/hadoop/hdfs/webapps" ]; then
-  CLASSPATH=${CLASSPATH}:$HADOOP_PREFIX/share/hadoop/hdfs
-fi
-for f in $HADOOP_PREFIX/share/hadoop-hdfs/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-
-# add libs to CLASSPATH
-for f in $HADOOP_PREFIX/lib/*.jar; do
-  CLASSPATH=${CLASSPATH}:$f;
-done
-
 if $cygwin; then
   CLASSPATH=`cygpath -p -w "$CLASSPATH"`
 fi
@@ -161,7 +118,7 @@ if [ "$starting_secure_dn" = "true" ]; then
    HADOOP_SECURE_DN_PID="$HADOOP_PID_DIR/hadoop_secure_dn.pid"
   fi
 
-  exec "$HADOOP_PREFIX/bin/jsvc" \
+  exec "$HADOOP_HDFS_HOME/bin/jsvc" \
            -Dproc_$COMMAND -outfile "$HADOOP_LOG_DIR/jsvc.out" \
            -errfile "$HADOOP_LOG_DIR/jsvc.err" \
            -pidfile "$HADOOP_SECURE_DN_PID" \
diff --git a/hadoop-hdfs/src/main/bin/hdfs-config.sh b/hadoop-hdfs/src/main/bin/hdfs-config.sh
index 6d44418b0d9..48aa20c94dc 100644
--- a/hadoop-hdfs/src/main/bin/hdfs-config.sh
+++ b/hadoop-hdfs/src/main/bin/hdfs-config.sh
@@ -26,12 +26,10 @@ export HADOOP_PREFIX="${HADOOP_PREFIX:-$bin/..}"
 
 if [ -e "$bin/../libexec/hadoop-config.sh" ]; then
   . $bin/../libexec/hadoop-config.sh
-elif [ -e "${HADOOP_COMMON_HOME}/bin/hadoop-config.sh" ]; then
-  . "$HADOOP_COMMON_HOME"/bin/hadoop-config.sh
-elif [ -e "${HADOOP_HOME}/bin/hadoop-config.sh" ]; then
-  . "$HADOOP_HOME"/bin/hadoop-config.sh
-elif [ -e "${HADOOP_HDFS_HOME}/bin/hadoop-config.sh" ]; then
-  . "$HADOOP_HDFS_HOME"/bin/hadoop-config.sh
+elif [ -e "${HADOOP_COMMON_HOME}/libexec/hadoop-config.sh" ]; then
+  . "$HADOOP_COMMON_HOME"/libexec/hadoop-config.sh
+elif [ -e "${HADOOP_HOME}/libexec/hadoop-config.sh" ]; then
+  . "$HADOOP_HOME"/libexec/hadoop-config.sh
 else
   echo "Hadoop common not found."
   exit
diff --git a/hadoop-hdfs/src/main/bin/refresh-namenodes.sh b/hadoop-hdfs/src/main/bin/refresh-namenodes.sh
index f05b5907fd6..2092764a1dc 100644
--- a/hadoop-hdfs/src/main/bin/refresh-namenodes.sh
+++ b/hadoop-hdfs/src/main/bin/refresh-namenodes.sh
@@ -23,11 +23,7 @@
 bin=`dirname "$0"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin/../libexec/hdfs-config.sh"
-else
-  . "$bin/hdfs-config.sh"
-fi
+. "$bin/../libexec/hdfs-config.sh"
 
 namenodes=$("$HADOOP_PREFIX/bin/hdfs" getconf -nnRpcAddresses)
 if [ "$?" != '0' ] ; then errorFlag='1' ; 
diff --git a/hadoop-hdfs/src/main/bin/start-balancer.sh b/hadoop-hdfs/src/main/bin/start-balancer.sh
index 1fa2afd47a8..b6b3aa7f8bf 100755
--- a/hadoop-hdfs/src/main/bin/start-balancer.sh
+++ b/hadoop-hdfs/src/main/bin/start-balancer.sh
@@ -18,11 +18,7 @@
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin"/../libexec/hdfs-config.sh
-else
-  . "$bin/hdfs-config.sh"
-fi
+. "$bin"/../libexec/hdfs-config.sh
 
 # Start balancer daemon.
 
diff --git a/hadoop-hdfs/src/main/bin/start-dfs.sh b/hadoop-hdfs/src/main/bin/start-dfs.sh
index dc417293dc6..32dcf860cd9 100755
--- a/hadoop-hdfs/src/main/bin/start-dfs.sh
+++ b/hadoop-hdfs/src/main/bin/start-dfs.sh
@@ -25,11 +25,7 @@ usage="Usage: start-dfs.sh [-upgrade|-rollback]"
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin"/../libexec/hdfs-config.sh
-else
-  . "$bin/hdfs-config.sh"
-fi
+. "$bin"/../libexec/hdfs-config.sh
 
 # get arguments
 if [ $# -ge 1 ]; then
diff --git a/hadoop-hdfs/src/main/bin/start-secure-dns.sh b/hadoop-hdfs/src/main/bin/start-secure-dns.sh
index 30532fafc12..c4190dbde0d 100644
--- a/hadoop-hdfs/src/main/bin/start-secure-dns.sh
+++ b/hadoop-hdfs/src/main/bin/start-secure-dns.sh
@@ -22,12 +22,7 @@ usage="Usage (run as root in order to start secure datanodes): start-secure-dns.
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin"/../libexec/hdfs-config.sh
-else
-  . "$bin/hdfs-config.sh"
-fi
-
+. "$bin"/../libexec/hdfs-config.sh
 
 if [ "$EUID" -eq 0 ] && [ -n "$HADOOP_SECURE_DN_USER" ]; then
   "$HADOOP_PREFIX"/bin/hadoop-daemons.sh --config $HADOOP_CONF_DIR --script "$bin"/hdfs start datanode $dataStartOpt
diff --git a/hadoop-hdfs/src/main/bin/stop-balancer.sh b/hadoop-hdfs/src/main/bin/stop-balancer.sh
index c586a7a0887..7edd0bd3119 100755
--- a/hadoop-hdfs/src/main/bin/stop-balancer.sh
+++ b/hadoop-hdfs/src/main/bin/stop-balancer.sh
@@ -18,12 +18,7 @@
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin"/../libexec/hdfs-config.sh
-else
-  . "$bin/hdfs-config.sh"
-fi
-
+. "$bin"/../libexec/hdfs-config.sh
 
 # Stop balancer daemon.
 # Run this on the machine where the balancer is running
diff --git a/hadoop-hdfs/src/main/bin/stop-dfs.sh b/hadoop-hdfs/src/main/bin/stop-dfs.sh
index c39e54c864d..7158ca6bdac 100755
--- a/hadoop-hdfs/src/main/bin/stop-dfs.sh
+++ b/hadoop-hdfs/src/main/bin/stop-dfs.sh
@@ -18,11 +18,7 @@
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin"/../libexec/hdfs-config.sh
-else
-  . "$bin/hdfs-config.sh"
-fi
+. "$bin"/../libexec/hdfs-config.sh
 
 #---------------------------------------------------------
 # namenodes
diff --git a/hadoop-hdfs/src/main/bin/stop-secure-dns.sh b/hadoop-hdfs/src/main/bin/stop-secure-dns.sh
index 53dc6f7d939..63854c44958 100644
--- a/hadoop-hdfs/src/main/bin/stop-secure-dns.sh
+++ b/hadoop-hdfs/src/main/bin/stop-secure-dns.sh
@@ -22,11 +22,7 @@ usage="Usage (run as root in order to stop secure datanodes): stop-secure-dns.sh
 bin=`dirname "${BASH_SOURCE-$0}"`
 bin=`cd "$bin"; pwd`
 
-if [ -e "$bin/../libexec/hdfs-config.sh" ]; then
-  . "$bin"/../libexec/hdfs-config.sh
-else
-  . "$bin/hdfs-config.sh"
-fi
+. "$bin"/../libexec/hdfs-config.sh
 
 if [ "$EUID" -eq 0 ] && [ -n "$HADOOP_SECURE_DN_USER" ]; then
   "$HADOOP_PREFIX"/bin/hadoop-daemons.sh --config $HADOOP_CONF_DIR --script "$bin"/hdfs stop datanode
diff --git a/hadoop-mapreduce/pom.xml b/hadoop-mapreduce/pom.xml
index 133a149532c..f0234e62280 100644
--- a/hadoop-mapreduce/pom.xml
+++ b/hadoop-mapreduce/pom.xml
@@ -82,6 +82,7 @@
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-common</artifactId>
       <version>${hadoop-common.version}</version>
+      <scope>provided</scope>
       <exclusions>
         <exclusion>
           <groupId>commons-el</groupId>
