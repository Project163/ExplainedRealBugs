diff --git a/CHANGES.txt b/CHANGES.txt
index 2a2a3ecdada..4a0f307fe6c 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -229,6 +229,9 @@ Trunk (unreleased changes)
     HADOOP-6667. RPC.waitForProxy should retry through NoRouteToHostException.
     (Todd Lipcon via tomwhite)
 
+    HADOOP-6677. InterfaceAudience.LimitedPrivate should take a string not an
+    enum. (tomwhite)
+
   OPTIMIZATIONS
 
     HADOOP-6467. Improve the performance on HarFileSystem.listStatus(..).
diff --git a/src/java/org/apache/hadoop/classification/InterfaceAudience.java b/src/java/org/apache/hadoop/classification/InterfaceAudience.java
index 96172d3f893..0a6ba31c6cd 100644
--- a/src/java/org/apache/hadoop/classification/InterfaceAudience.java
+++ b/src/java/org/apache/hadoop/classification/InterfaceAudience.java
@@ -29,13 +29,11 @@ public class InterfaceAudience {
   @Documented public @interface Public {};
   
   /**
-   * Intended only for the project(s) specified in the annotation
+   * Intended only for the project(s) specified in the annotation.
+   * For example, "Common", "HDFS", "MapReduce", "ZooKeeper", "HBase".
    */
   @Documented public @interface LimitedPrivate {
-    public enum Project {COMMON, AVRO, CHUKWA, HBASE, HDFS, 
-                         HIVE, MAPREDUCE, PIG, ZOOKEEPER};
-    
-    Project[] value();
+    String[] value();
   };
   
   /**
diff --git a/src/java/org/apache/hadoop/classification/tools/package-info.java b/src/java/org/apache/hadoop/classification/tools/package-info.java
index f18a44a0b50..dc647c583ba 100644
--- a/src/java/org/apache/hadoop/classification/tools/package-info.java
+++ b/src/java/org/apache/hadoop/classification/tools/package-info.java
@@ -15,10 +15,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-@InterfaceAudience.LimitedPrivate({COMMON, AVRO, CHUKWA, HBASE, HDFS, HIVE,
-  MAPREDUCE, PIG, ZOOKEEPER})
+@InterfaceAudience.LimitedPrivate({"Common", "Avro", "Chukwa", "HBase", "HDFS",
+  "Hive", "MapReduce", "Pig", "ZooKeeper"})
 package org.apache.hadoop.classification.tools;
 
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.*;
-
 import org.apache.hadoop.classification.InterfaceAudience;
diff --git a/src/java/org/apache/hadoop/fs/FileContext.java b/src/java/org/apache/hadoop/fs/FileContext.java
index d358ee7e8fb..bb0836fee56 100644
--- a/src/java/org/apache/hadoop/fs/FileContext.java
+++ b/src/java/org/apache/hadoop/fs/FileContext.java
@@ -39,7 +39,6 @@
 import org.apache.hadoop.HadoopIllegalArgumentException;
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.classification.InterfaceStability;
-import org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.*;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.Options.CreateOpts;
 import org.apache.hadoop.fs.Options.Rename;
@@ -1135,7 +1134,7 @@ public Path next(final AbstractFileSystem fs, final Path p)
    * RuntimeExceptions:
    * @throws InvalidPathException If path <code>f</code> is invalid
    */
-  @InterfaceAudience.LimitedPrivate({Project.HDFS, Project.MAPREDUCE})
+  @InterfaceAudience.LimitedPrivate({"HDFS", "MapReduce"})
   @InterfaceStability.Evolving
   public BlockLocation[] getFileBlockLocations(final Path f, final long start,
       final long len) throws AccessControlException, FileNotFoundException,
diff --git a/src/java/org/apache/hadoop/fs/UnresolvedLinkException.java b/src/java/org/apache/hadoop/fs/UnresolvedLinkException.java
index cf86358cdcb..f5fee55abc6 100644
--- a/src/java/org/apache/hadoop/fs/UnresolvedLinkException.java
+++ b/src/java/org/apache/hadoop/fs/UnresolvedLinkException.java
@@ -21,12 +21,11 @@
 import java.io.IOException;
 
 import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.*;
 
 /** 
  * Thrown when a symbolic link is encountered in a path.
  */
-@InterfaceAudience.LimitedPrivate({Project.HDFS})
+@InterfaceAudience.LimitedPrivate({"HDFS"})
 public class UnresolvedLinkException extends IOException {
   private static final long serialVersionUID = 1L;
 
diff --git a/src/java/org/apache/hadoop/security/TokenStorage.java b/src/java/org/apache/hadoop/security/TokenStorage.java
index 7aee6e3433d..b6a56d852ac 100644
--- a/src/java/org/apache/hadoop/security/TokenStorage.java
+++ b/src/java/org/apache/hadoop/security/TokenStorage.java
@@ -18,8 +18,6 @@
 
 package org.apache.hadoop.security;
 
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.MAPREDUCE;
-
 import java.io.DataInput;
 import java.io.DataOutput;
 import java.io.IOException;
@@ -42,7 +40,7 @@
  * A class that provides the facilities of reading and writing 
  * secret keys and Tokens.
  */
-@InterfaceAudience.LimitedPrivate({MAPREDUCE})
+@InterfaceAudience.LimitedPrivate({"MapReduce"})
 public class TokenStorage implements Writable {
 
   private  Map<Text, byte[]> secretKeysMap = new HashMap<Text, byte[]>();
diff --git a/src/java/org/apache/hadoop/security/UserGroupInformation.java b/src/java/org/apache/hadoop/security/UserGroupInformation.java
index 3b717dafc0c..ed1fce42a67 100644
--- a/src/java/org/apache/hadoop/security/UserGroupInformation.java
+++ b/src/java/org/apache/hadoop/security/UserGroupInformation.java
@@ -17,8 +17,6 @@
  */
 package org.apache.hadoop.security;
 
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.HDFS;
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.MAPREDUCE;
 import static org.apache.hadoop.fs.CommonConfigurationKeys.HADOOP_SECURITY_AUTHENTICATION;
 
 import java.io.IOException;
@@ -542,7 +540,7 @@ private void setUserGroups(String user, String[] groups) {
    * @param userGroups the names of the groups that the user belongs to
    * @return a fake user for running unit tests
    */
-  @InterfaceAudience.LimitedPrivate({HDFS, MAPREDUCE})
+  @InterfaceAudience.LimitedPrivate({"HDFS", "MapReduce"})
   public static UserGroupInformation createUserForTesting(String user, 
                                                           String[] userGroups) {
     ensureInitialized();
@@ -568,7 +566,7 @@ public static UserGroupInformation createUserForTesting(String user,
    *          the names of the groups that the user belongs to
    * @return a fake user for running unit tests
    */
-  @InterfaceAudience.LimitedPrivate( { HDFS, MAPREDUCE })
+  @InterfaceAudience.LimitedPrivate( { "HDFS", "MapReduce" })
   public static UserGroupInformation createProxyUserForTesting(String user,
       UserGroupInformation realUser, String[] userGroups) {
     ensureInitialized();
diff --git a/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenIdentifier.java b/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenIdentifier.java
index 0fc4349c78e..a75bfd61f7f 100644
--- a/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenIdentifier.java
+++ b/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenIdentifier.java
@@ -19,8 +19,6 @@
 package org.apache.hadoop.security.token.delegation;
 
 import org.apache.hadoop.classification.InterfaceAudience;
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.HDFS;
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.MAPREDUCE;
 
 import java.io.DataInput;
 import java.io.DataOutput;
@@ -31,7 +29,7 @@
 import org.apache.hadoop.security.UserGroupInformation;
 import org.apache.hadoop.security.token.TokenIdentifier;
 
-@InterfaceAudience.LimitedPrivate({HDFS, MAPREDUCE})
+@InterfaceAudience.LimitedPrivate({"HDFS", "MapReduce"})
 public abstract class AbstractDelegationTokenIdentifier 
 extends TokenIdentifier {
   private static final byte VERSION = 0;
diff --git a/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java b/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java
index 71c7f46ace3..37e298019f7 100644
--- a/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java
+++ b/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSecretManager.java
@@ -21,9 +21,6 @@
 import org.apache.hadoop.classification.InterfaceAudience;
 import org.apache.hadoop.io.Text;
 
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.HDFS;
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.MAPREDUCE;
-
 import java.io.ByteArrayInputStream;
 import java.io.DataInputStream;
 import java.io.IOException;
@@ -42,7 +39,7 @@
 import org.apache.hadoop.util.Daemon;
 import org.apache.hadoop.util.StringUtils;
 
-@InterfaceAudience.LimitedPrivate({HDFS, MAPREDUCE})
+@InterfaceAudience.LimitedPrivate({"HDFS", "MapReduce"})
 public abstract 
 class AbstractDelegationTokenSecretManager<TokenIdent 
 extends AbstractDelegationTokenIdentifier> 
diff --git a/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSelector.java b/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSelector.java
index a85f7c97b35..f9d58b01a7c 100644
--- a/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSelector.java
+++ b/src/java/org/apache/hadoop/security/token/delegation/AbstractDelegationTokenSelector.java
@@ -25,14 +25,12 @@
 import org.apache.hadoop.security.token.Token;
 import org.apache.hadoop.security.token.TokenIdentifier;
 import org.apache.hadoop.security.token.TokenSelector;
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.HDFS;
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.MAPREDUCE;
 
 /**
  * Look through tokens to find the first delegation token that matches the
  * service and return it.
  */
-@InterfaceAudience.LimitedPrivate({HDFS, MAPREDUCE})
+@InterfaceAudience.LimitedPrivate({"HDFS", "MapReduce"})
 public 
 class AbstractDelegationTokenSelector<TokenIdent 
 extends AbstractDelegationTokenIdentifier> 
diff --git a/src/java/org/apache/hadoop/security/token/delegation/DelegationKey.java b/src/java/org/apache/hadoop/security/token/delegation/DelegationKey.java
index 269eb569b41..2edb911b80f 100644
--- a/src/java/org/apache/hadoop/security/token/delegation/DelegationKey.java
+++ b/src/java/org/apache/hadoop/security/token/delegation/DelegationKey.java
@@ -27,13 +27,11 @@
 
 import org.apache.hadoop.io.Writable;
 import org.apache.hadoop.io.WritableUtils;
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.HDFS;
-import static org.apache.hadoop.classification.InterfaceAudience.LimitedPrivate.Project.MAPREDUCE;
 
 /**
  * Key used for generating and verifying delegation tokens
  */
-@InterfaceAudience.LimitedPrivate({HDFS, MAPREDUCE})
+@InterfaceAudience.LimitedPrivate({"HDFS", "MapReduce"})
 public class DelegationKey implements Writable {
   private int keyId;
   private long expiryDate;
