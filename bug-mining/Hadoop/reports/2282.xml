<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:53:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-14919] BZip2 drops records when reading data in splits</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-14919</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;BZip2 can drop records when reading data in splits. This problem was already discussed before in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11445&quot; title=&quot;Bzip2Codec: Data block is skipped when position of newly created stream is equal to start of split&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11445&quot;&gt;&lt;del&gt;HADOOP-11445&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13270&quot; title=&quot;BZip2CompressionInputStream finds the same compression marker twice in corner case, causing duplicate data blocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13270&quot;&gt;&lt;del&gt;HADOOP-13270&lt;/del&gt;&lt;/a&gt;. But we still have a problem in corner case, causing lost data blocks.&lt;/p&gt;

&lt;p&gt;I attached a unit test for this issue. You can reproduce the problem if you run the unit test.&lt;/p&gt;

&lt;p&gt;First, this issue happens when position of newly created stream is equal to start of split. Hadoop has some test cases for this (blockEndingInCR.txt.bz2 file for TestLineRecordReader#testBzip2SplitStartAtBlockMarker, etc). However, the issue I am reporting does not happen when we run these tests because this issue happens only when the start of split byte block includes both block marker and compressed data.&lt;/p&gt;

&lt;p&gt;BZip2 block marker - 0x314159265359 (001100010100000101011001001001100101001101011001)&lt;/p&gt;

&lt;p&gt;blockEndingInCR.txt.bz2 (Start of Split - 136504):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ xxd -l 6 -g 1 -b -seek 136498 ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-classes/blockEndingInCR.txt.bz2
0021532: 00110001 01000001 01011001 00100110 01010011 01011001  1AY&amp;amp;SY
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Test bz2 File (Start of Split - 203426)&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;$ xxd -l 7 -g 1 -b -seek 203419 250000.bz2
0031a9b: 11100110 00101000 00101011 00100100 11001010 01101011  .(+$.k
0031aa1: 00101111                                               /
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;p&gt;Let&apos;s say a job splits this test bz2 file into two splits at the start of split (position 203426).&lt;br/&gt;
The former split does not read records which start position 203426 because BZip2 says the position of these dropped records is 203427. The latter split does not read the records because BZip2CompressionInputStream read the block from position 320955.&lt;br/&gt;
Due to this behavior, records between 203427 and 320955 are lost.&lt;/p&gt;

&lt;p&gt;Also, if we reverted the changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13270&quot; title=&quot;BZip2CompressionInputStream finds the same compression marker twice in corner case, causing duplicate data blocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13270&quot;&gt;&lt;del&gt;HADOOP-13270&lt;/del&gt;&lt;/a&gt;, we will not see this issue. We will see &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13270&quot; title=&quot;BZip2CompressionInputStream finds the same compression marker twice in corner case, causing duplicate data blocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13270&quot;&gt;&lt;del&gt;HADOOP-13270&lt;/del&gt;&lt;/a&gt; issue though.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13106472">HADOOP-14919</key>
            <summary>BZip2 drops records when reading data in splits</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="jlowe">Jason Darrell Lowe</assignee>
                                    <reporter username="tanakahda">Aki Tanaka</reporter>
                        <labels>
                    </labels>
                <created>Mon, 2 Oct 2017 16:28:59 +0000</created>
                <updated>Thu, 1 Feb 2018 20:46:52 +0000</updated>
                            <resolved>Tue, 31 Oct 2017 14:38:44 +0000</resolved>
                                    <version>2.8.0</version>
                    <version>2.7.3</version>
                    <version>3.0.0-alpha1</version>
                                    <fixVersion>2.9.0</fixVersion>
                    <fixVersion>2.8.3</fixVersion>
                    <fixVersion>2.7.5</fixVersion>
                    <fixVersion>3.0.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>15</watches>
                                                                                                                <comments>
                            <comment id="16188397" author="tanakahda" created="Mon, 2 Oct 2017 16:30:14 +0000"  >&lt;p&gt;Add patch for the unit test.&lt;/p&gt;</comment>
                            <comment id="16188403" author="tanakahda" created="Mon, 2 Oct 2017 16:32:11 +0000"  >&lt;p&gt;Adding the test bz2 file (The bz2 file that the attached unit test generates)&lt;/p&gt;</comment>
                            <comment id="16191986" author="jlowe" created="Wed, 4 Oct 2017 20:26:09 +0000"  >&lt;p&gt;Upgrading the priority since this involves silent data loss.&lt;/p&gt;</comment>
                            <comment id="16192154" author="jlowe" created="Wed, 4 Oct 2017 22:16:47 +0000"  >&lt;p&gt;A lot of the troubles with split handling in this codec are related to these issues:&lt;br/&gt;
1) It seeks &lt;em&gt;backwards&lt;/em&gt; from the split start looking for a possible bzip2 block header and sometimes miscomputes where that should start.&lt;br/&gt;
2) It is reporting stream positions that can skip data that has not been processed yet (as in this case).&lt;/p&gt;

&lt;p&gt;So here&apos;s my pitch at fixing this for the Nth time:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;No seeking backwards.  Any block whose start marker appears before the split is not the responsibility of this split&apos;s reader.  Split processing should never require reading data just before the split offset, as that data is entirely the responsibility of the previous split&apos;s reader.&lt;/li&gt;
	&lt;li&gt;Stream position reports the byte where the block start marker begins rather than the byte after it ends.  That way we&apos;re always consistent about who is responsible for &quot;consuming&quot; a block start header and never report byte positions that may have skipped some data bits.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;This is probably going to break &lt;em&gt;something&lt;/em&gt; given how many attempts there have been at fixing this, so I greatly appreciate any and all eyes willing to take a look.  Alternative proposals are also welcome.&lt;/p&gt;

&lt;p&gt;Attaching a patch that implements the approach described above.  Thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tanakahda&quot; class=&quot;user-hover&quot; rel=&quot;tanakahda&quot;&gt;tanakahda&lt;/a&gt; for the unit test.  I extended it to test all the split positions around the block start marker for this test case. Speaking of tests, Jenkins won&apos;t run all the related tests, so I also manually ran the TestLineRecordReader tests in hadoop-mapreduce-client-core and they passed.&lt;/p&gt;</comment>
                            <comment id="16192365" author="hadoopqa" created="Thu, 5 Oct 2017 01:57:39 +0000"  >&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Vote &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Runtime &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Comment &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; reexec &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;  0m 16s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Docker mode activated. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; &lt;font color=&quot;brown&quot;&gt; Prechecks &lt;/font&gt; &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; @author &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  0m  0s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch does not contain any @author tags. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; test4tests &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  0m  0s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch appears to include 1 new or modified test files. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; &lt;font color=&quot;brown&quot;&gt; trunk Compile Tests &lt;/font&gt; &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; mvndep &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;  0m 15s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Maven dependency ordering for branch &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; mvninstall &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 13m 29s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; trunk passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; compile &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 15m 58s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; trunk passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; checkstyle &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  2m 15s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; trunk passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; mvnsite &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  1m 37s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; trunk passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; shadedclient &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 15m 49s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; branch has no errors when building and testing our client artifacts. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; findbugs &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  2m 26s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; trunk passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; javadoc &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  1m 15s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; trunk passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; &lt;font color=&quot;brown&quot;&gt; Patch Compile Tests &lt;/font&gt; &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; mvndep &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;  0m 21s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt; Maven dependency ordering for patch &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; mvninstall &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  1m 13s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; the patch passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; compile &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 13m  6s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; the patch passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; javac &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 13m  6s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; the patch passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;orange&quot;&gt;-0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;orange&quot;&gt; checkstyle &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;orange&quot;&gt;  2m 19s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;orange&quot;&gt; root: The patch generated 2 new + 118 unchanged - 9 fixed = 120 total (was 127) &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; mvnsite &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  1m 54s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; the patch passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; whitespace &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  0m  0s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch has no whitespace issues. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; shadedclient &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; 11m 57s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; patch has no errors when building and testing our client artifacts. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; findbugs &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  2m 37s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; the patch passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; javadoc &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  1m 40s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; the patch passed &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt;&amp;nbsp;&lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; &lt;font color=&quot;brown&quot;&gt; Other Tests &lt;/font&gt; &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; unit &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;  9m 22s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt; hadoop-common in the patch failed. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; unit &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;101m 37s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; hadoop-mapreduce-client-jobclient in the patch passed. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; asflicense &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;  0m 45s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt; The patch does not generate ASF License warnings. &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt;&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; &lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt;216m 49s&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;black&quot;&gt; &lt;/font&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Reason &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Tests &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Failed junit tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; hadoop.security.TestKDiag &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Report/Notes &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Docker &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  Image:yetus/hadoop:71bbb86 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Issue &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-14919&quot; title=&quot;BZip2 drops records when reading data in splits&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-14919&quot;&gt;&lt;del&gt;HADOOP-14919&lt;/del&gt;&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; JIRA Patch URL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12890447/HADOOP-14919.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12890447/HADOOP-14919.001.patch&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Optional Tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; uname &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Linux 081a67763b93 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Build tool &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; maven &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Personality &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; /testptch/hadoop/patchprocess/precommit/personality/provided.sh &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; git revision &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; trunk / cae1c73 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Default Java &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 1.8.0_144 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; findbugs &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; v3.1.0-RC1 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; checkstyle &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/13454/artifact/patchprocess/diff-checkstyle-root.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/13454/artifact/patchprocess/diff-checkstyle-root.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; unit &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/13454/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/13454/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  Test Results &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/13454/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/13454/testReport/&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; modules &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; C: hadoop-common-project/hadoop-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient U: . &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Console output &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/13454/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/13454/console&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Powered by &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Apache Yetus 0.6.0-SNAPSHOT   &lt;a href=&quot;http://yetus.apache.org&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://yetus.apache.org&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;



&lt;p&gt;This message was automatically generated.&lt;/p&gt;
</comment>
                            <comment id="16193075" author="tanakahda" created="Thu, 5 Oct 2017 15:49:25 +0000"  >&lt;p&gt;Thank you for the patch. I tested the patch and confirmed that the patch can fix the issues we saw in our production environment.&lt;br/&gt;
As far as I tested, I did not see any regressions or new issues.&lt;/p&gt;</comment>
                            <comment id="16193088" author="jlowe" created="Thu, 5 Oct 2017 16:01:17 +0000"  >&lt;p&gt;Thanks for taking the patch for a test drive!  Glad to hear it fixes the problem and doesn&apos;t seem to regress anything so far.&lt;/p&gt;</comment>
                            <comment id="16199444" author="subru" created="Tue, 10 Oct 2017 22:06:18 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jlowe&quot; class=&quot;user-hover&quot; rel=&quot;jlowe&quot;&gt;jlowe&lt;/a&gt; for fixing this and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tanakahda&quot; class=&quot;user-hover&quot; rel=&quot;tanakahda&quot;&gt;tanakahda&lt;/a&gt; for validating the fix. I assume since it has been tested, it&apos;ll be committed in time for 2.9?&lt;/p&gt;</comment>
                            <comment id="16199457" author="jlowe" created="Tue, 10 Oct 2017 22:11:13 +0000"  >&lt;p&gt;If it can get a thorough review from someone then yes. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Still looking for a committer who knows a thing or two about splittable codecs and the pitfalls therein to find time to give this a review.&lt;/p&gt;</comment>
                            <comment id="16217177" author="jlowe" created="Tue, 24 Oct 2017 16:22:18 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lewuathe&quot; class=&quot;user-hover&quot; rel=&quot;lewuathe&quot;&gt;lewuathe&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ajisakaa&quot; class=&quot;user-hover&quot; rel=&quot;ajisakaa&quot;&gt;ajisakaa&lt;/a&gt; this is a bug related to the changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-13270&quot; title=&quot;BZip2CompressionInputStream finds the same compression marker twice in corner case, causing duplicate data blocks&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-13270&quot;&gt;&lt;del&gt;HADOOP-13270&lt;/del&gt;&lt;/a&gt;.  Would you have time to take a look?&lt;/p&gt;</comment>
                            <comment id="16218188" author="ajisakaa" created="Wed, 25 Oct 2017 07:01:21 +0000"  >&lt;p&gt;LGTM, +1. I ran all the bzip2-related tests locally and all the tests passed.&lt;/p&gt;</comment>
                            <comment id="16221294" author="chris.douglas" created="Thu, 26 Oct 2017 21:48:25 +0000"  >&lt;p&gt;+1 for removing the seek backward. The text reader also had bugs from that. Ironically, they were discovered/fixed as part of adding splittable codecs.&lt;/p&gt;

&lt;p&gt;Looking at the code, would this support concatenated bzip files? The reader handling the previous block will detect the end of its stream, and a split following it should find the block delimiter after the header of the next file. However, if the text splits are around the concat point, the &lt;tt&gt;BZh9&lt;/tt&gt; bytes may not be unaccounted for. The codec skips these at the beginning of the file and updates &lt;tt&gt;reportedBytesReadFromCompressedStream&lt;/tt&gt;, but I didn&apos;t see handling for this within the stream. Similarly, if splits are arranged like this:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;file.txt.bz2: [BZh93141592659xxxxxxxx3141592659xxxxxxxx0x177245385090BZh93141592659ooooooo3141592659xxxxxxxx...]
               ^split0                                                               ^split1
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Would split0 pick up the &lt;tt&gt;ooooooo&lt;/tt&gt; bytes?&lt;/p&gt;

&lt;p&gt;It doesn&apos;t look like the unit tests cover a combination of multi-byte delimiters and splittable codecs. I don&apos;t know how thoroughly we can test that, without getting too deep into bzip2...&lt;/p&gt;</comment>
                            <comment id="16222840" author="subru" created="Fri, 27 Oct 2017 21:15:12 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jlowe&quot; class=&quot;user-hover&quot; rel=&quot;jlowe&quot;&gt;jlowe&lt;/a&gt;, is this on track for 2.9.0? I see that &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ajisakaa&quot; class=&quot;user-hover&quot; rel=&quot;ajisakaa&quot;&gt;ajisakaa&lt;/a&gt;&apos;s signed off and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chris.douglas&quot; class=&quot;user-hover&quot; rel=&quot;chris.douglas&quot;&gt;chris.douglas&lt;/a&gt; also has reviewed it and has couple of outstanding questions. Thanks.&lt;/p&gt;</comment>
                            <comment id="16222899" author="chris.douglas" created="Fri, 27 Oct 2017 21:49:16 +0000"  >&lt;p&gt;FWIW, I&apos;d be +1 on the patch as-is&lt;/p&gt;</comment>
                            <comment id="16222936" author="jlowe" created="Fri, 27 Oct 2017 22:08:51 +0000"  >&lt;p&gt;Thanks for the reviews, Akira and Chris!&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;is this on track for 2.9.0?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I&apos;d like to dig into the potential issues Chris brought up, and I was hoping to carve out some time early next week to do so.  So if we have time I&apos;d rather wait, but I&apos;m also OK if this goes in and the investigation is done in a followup JIRA.&lt;/p&gt;

&lt;p&gt;Concatenated bzip2 files may already be problematic according to &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6852&quot; title=&quot;apparent bug in concatenated-bzip2 support (decoding)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-6852&quot;&gt;&lt;del&gt;HADOOP-6852&lt;/del&gt;&lt;/a&gt; but I haven&apos;t had a chance to verify yet.&lt;/p&gt;</comment>
                            <comment id="16223051" author="subru" created="Fri, 27 Oct 2017 23:33:11 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jlowe&quot; class=&quot;user-hover&quot; rel=&quot;jlowe&quot;&gt;jlowe&lt;/a&gt; for the clarification. We can wait if it&apos;s early next week. If it gets delayed or you hit complications, we can fall back to committing this and having a followup JIRA.&lt;/p&gt;</comment>
                            <comment id="16225517" author="jlowe" created="Mon, 30 Oct 2017 18:39:27 +0000"  >&lt;p&gt;Had some more time to look into this today.  &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6852&quot; title=&quot;apparent bug in concatenated-bzip2 support (decoding)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-6852&quot;&gt;&lt;del&gt;HADOOP-6852&lt;/del&gt;&lt;/a&gt; is legit.  Concatenated bz2 files don&apos;t work at all in Hadoop:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ echo hey | bzip2 -c &amp;gt; foo.bz2
$ echo there | bzip2 -c &amp;gt;&amp;gt; foo.bz2
$ bzcat foo.bz2
hey
there
$ hadoop fs -put foo.bz2
$ hadoop fs -text foo.bz2     
2017-10-30 13:18:08,083 INFO  [main] compress.CodecPool (CodecPool.java:getDecompressor(184)) - Got brand-new decompressor [.bz2]
hey
text: bad block header
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I don&apos;t think it would be very difficult to add support for concatenation.  IIUC all it needs to do is account for the possibility that &apos;BZh9&apos; could appear before the block marker.  We should &lt;em&gt;not&lt;/em&gt; updated the reported position when skipping just the &apos;BZh9&apos; bytes and only when we move from block mark to block mark.  The existing behavior of skipping at the file offset 0 is benign, but I don&apos;t think we want/need to update reported position when skipping these extra bytes mid-stream.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The reader handling the previous block will detect the end of its stream, and a split following it should find the block delimiter after the header of the next file. However, if the text splits are around the concat point, the BZh9 bytes may not be unaccounted for.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Assuming we add the ability to silently skip &apos;BZh9&apos; we should still be OK.  The compression input stream will only report the position moving when the next block starts to be read.  Whether we have &apos;BZh9&apos; bytes or not doesn&apos;t change that.  We either read the whole block header and marker or none of it.  The upper layer reader will continue reading until the reported position changes, so the upper layer semantics don&apos;t change based on the presence of the extra header bytes.  Therefore I argue we&apos;re either OK or already screwed whether there&apos;s an extra header there or not.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Would split0 pick up the ooooooo bytes?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I had a little trouble following the example and knowing what was a record delimiter.  In general the split reader is responsible for reading until a record ends in the next split because the next reader will always toss away the first record.  &quot;Ends in the next split&quot; means the entire delimiter appears in the next split, since the next split reader will toss all bytes up to and including the first record delimiter found.  There&apos;s some complicated logic in LineRecordReader and SplitLineReader to account for buffering occurring at both the codec and line reader levels along with the games codecs can play with reported byte position in the stream.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;It doesn&apos;t look like the unit tests cover a combination of multi-byte delimiters and splittable codecs.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;See TestLineRecordReader#testBzipWithMultibyteDelimiter and compressedMultibyteDelimiter.txt.bz2.  I doubt it is exhaustive of all the corner cases, but there is at least one test there.&lt;/p&gt;

&lt;p&gt;At this point I think we&apos;re good to go with committing this and addressing concatenated bz2 in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6852&quot; title=&quot;apparent bug in concatenated-bzip2 support (decoding)&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-6852&quot;&gt;&lt;del&gt;HADOOP-6852&lt;/del&gt;&lt;/a&gt;.  As such I&apos;ll commit this tomorrow if there are no objections.&lt;/p&gt;</comment>
                            <comment id="16225643" author="chris.douglas" created="Mon, 30 Oct 2017 19:53:54 +0000"  >&lt;blockquote&gt;&lt;p&gt;We should not updated the reported position when skipping just the &apos;BZh9&apos; bytes and only when we move from block mark to block mark. The existing behavior of skipping at the file offset 0 is benign, but I don&apos;t think we want/need to update reported position when skipping these extra bytes mid-stream.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;+1 I saw this was skipped from the codec, and wanted to be sure (if concatenation is supported) that your fix worked in that case. But as you say, it&apos;s moot if it doesn&apos;t support concatenated bz2 files.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I had a little trouble following the example and knowing what was a record delimiter&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sorry. If split0 stopped at the end of stream and split1 skipped to the next delimiter, then the &lt;tt&gt;oooooo&lt;/tt&gt; bytes would be skipped.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;See TestLineRecordReader#testBzipWithMultibyteDelimiter&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thanks, I&apos;d missed that.&lt;/p&gt;

&lt;p&gt;+1 for committing this. Thanks for the detailed fix and followup, Jason.&lt;/p&gt;</comment>
                            <comment id="16226893" author="jlowe" created="Tue, 31 Oct 2017 14:38:44 +0000"  >&lt;p&gt;Thanks to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chris.douglas&quot; class=&quot;user-hover&quot; rel=&quot;chris.douglas&quot;&gt;chris.douglas&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ajisakaa&quot; class=&quot;user-hover&quot; rel=&quot;ajisakaa&quot;&gt;ajisakaa&lt;/a&gt;, and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tanakahda&quot; class=&quot;user-hover&quot; rel=&quot;tanakahda&quot;&gt;tanakahda&lt;/a&gt; for reviews!  I committed this to trunk, branch-3.0, branch-2, branch-2.8, and branch-2.7.&lt;/p&gt;</comment>
                            <comment id="16226929" author="hudson" created="Tue, 31 Oct 2017 14:51:51 +0000"  >&lt;p&gt;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13166 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/13166/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/13166/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-14919&quot; title=&quot;BZip2 drops records when reading data in splits&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-14919&quot;&gt;&lt;del&gt;HADOOP-14919&lt;/del&gt;&lt;/a&gt;. BZip2 drops records when reading data in splits. (jlowe: rev 2fae63aa60c43b62bd908a9499562fe528603185)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;(edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/BZip2Codec.java&lt;/li&gt;
	&lt;li&gt;(edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/bzip2/CBZip2InputStream.java&lt;/li&gt;
	&lt;li&gt;(edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestTextInputFormat.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="16349239" author="tanakahda" created="Thu, 1 Feb 2018 20:46:52 +0000"  >&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;Regarding this issue, I found another corner case of BZip2 codec/input stream behavior. Created&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-15206&quot; title=&quot;BZip2 drops and duplicates records when input split size is small&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-15206&quot;&gt;&lt;del&gt;HADOOP-15206&lt;/del&gt;&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;I&apos;d like someone in this thread look at&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-15206&quot; title=&quot;BZip2 drops and duplicates records when input split size is small&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-15206&quot;&gt;&lt;del&gt;HADOOP-15206&lt;/del&gt;&lt;/a&gt; too. Thank you.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12941604">HADOOP-13270</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12889981" name="250000.bz2" size="320955" author="tanakahda" created="Mon, 2 Oct 2017 16:31:04 +0000"/>
                            <attachment id="12889980" name="HADOOP-14919-test.patch" size="3570" author="tanakahda" created="Mon, 2 Oct 2017 16:29:54 +0000"/>
                            <attachment id="12890447" name="HADOOP-14919.001.patch" size="11265" author="jlowe" created="Wed, 4 Oct 2017 22:11:52 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 41 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3kscn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12334219">2.9.0</customfieldvalue>
    <customfieldvalue id="12341091">2.8.3</customfieldvalue>
    <customfieldvalue id="12341256">2.7.5</customfieldvalue>
    <customfieldvalue id="12341431">3.0.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>