<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:48:16 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-9891] CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-9891</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;The instruction on how to start up a mini CLI cluster in &lt;tt&gt;CLIMiniCluster.md&lt;/tt&gt; don&apos;t work -it looks like &lt;tt&gt;MiniYarnCluster&lt;/tt&gt; isn&apos;t on the classpath&lt;/p&gt;</description>
                <environment></environment>
        <key id="12664693">HADOOP-9891</key>
            <summary>CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="d4rr3ll">Darrell Taylor</assignee>
                                    <reporter username="stevel@apache.org">Steve Loughran</reporter>
                        <labels>
                            <label>BB2015-05-TBR</label>
                    </labels>
                <created>Tue, 20 Aug 2013 21:06:32 +0000</created>
                <updated>Tue, 30 Aug 2016 01:32:57 +0000</updated>
                            <resolved>Wed, 27 May 2015 23:37:28 +0000</resolved>
                                    <version>2.1.1-beta</version>
                                    <fixVersion>2.8.0</fixVersion>
                    <fixVersion>3.0.0-alpha1</fixVersion>
                                    <component>documentation</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="13745432" author="stevel@apache.org" created="Tue, 20 Aug 2013 21:10:57 +0000"  >&lt;p&gt;(this is on a clean linux box, no env variables for Hadoop set up other than JAVA_HOME)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;hadoop-2.1.1-SNAPSHOT$ bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.1.1-SNAPSHOT-tests.jar minicluster -rmport 8096 -jhsport 8097
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;the JAR file exists&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ls -l share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.1.1-SNAPSHOT-tests.jar
-rw-rw-r-- 1 stevel stevel 1429647 Aug 20 21:49 share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.1.1-SNAPSHOT-tests.jar

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;but the cluster doesn&apos;t come out to play&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
13/08/20 22:03:22 INFO mapreduce.MiniHadoopClusterManager: Updated 0 configuration settings from command line.
13/08/20 22:03:22 WARN util.NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
Formatting using clusterid: testClusterID
13/08/20 22:03:22 INFO namenode.HostFileManager: read includes:
HostSet(
)
13/08/20 22:03:22 INFO namenode.HostFileManager: read excludes:
HostSet(
)
13/08/20 22:03:22 WARN conf.Configuration: hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
13/08/20 22:03:22 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
13/08/20 22:03:22 INFO util.GSet: Computing capacity &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; map BlocksMap
13/08/20 22:03:22 INFO util.GSet: VM type       = 32-bit
13/08/20 22:03:22 INFO util.GSet: 2.0% max memory = 494.9 MB
13/08/20 22:03:22 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/08/20 22:03:22 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:22 INFO blockmanagement.BlockManager: defaultReplication         = 1
13/08/20 22:03:22 INFO blockmanagement.BlockManager: maxReplication             = 512
13/08/20 22:03:22 INFO blockmanagement.BlockManager: minReplication             = 1
13/08/20 22:03:22 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
13/08/20 22:03:22 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:22 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
13/08/20 22:03:22 INFO blockmanagement.BlockManager: encryptDataTransfer        = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:23 INFO namenode.FSNamesystem: fsOwner             = stevel (auth:SIMPLE)
13/08/20 22:03:23 INFO namenode.FSNamesystem: supergroup          = supergroup
13/08/20 22:03:23 INFO namenode.FSNamesystem: isPermissionEnabled = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
13/08/20 22:03:23 INFO namenode.FSNamesystem: HA Enabled: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:23 INFO namenode.FSNamesystem: Append Enabled: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
13/08/20 22:03:23 INFO util.GSet: Computing capacity &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; map INodeMap
13/08/20 22:03:23 INFO util.GSet: VM type       = 32-bit
13/08/20 22:03:23 INFO util.GSet: 1.0% max memory = 494.9 MB
13/08/20 22:03:23 INFO util.GSet: capacity      = 2^20 = 1048576 entries
13/08/20 22:03:23 INFO namenode.NameNode: Caching file names occuring more than 10 times
13/08/20 22:03:23 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
13/08/20 22:03:23 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
13/08/20 22:03:23 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
13/08/20 22:03:23 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
13/08/20 22:03:23 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
13/08/20 22:03:23 INFO util.GSet: Computing capacity &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; map Namenode Retry Cache
13/08/20 22:03:23 INFO util.GSet: VM type       = 32-bit
13/08/20 22:03:23 INFO util.GSet: 0.029999999329447746% max memory = 494.9 MB
13/08/20 22:03:23 INFO util.GSet: capacity      = 2^15 = 32768 entries
13/08/20 22:03:23 INFO common.Storage: Storage directory /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name1 has been successfully formatted.
13/08/20 22:03:23 INFO common.Storage: Storage directory /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name2 has been successfully formatted.
13/08/20 22:03:23 INFO namenode.FSImage: Saving image file /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name2/current/fsimage.ckpt_0000000000000000000 using no compression
13/08/20 22:03:23 INFO namenode.FSImage: Saving image file /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name1/current/fsimage.ckpt_0000000000000000000 using no compression
13/08/20 22:03:23 INFO namenode.FSImage: Image file /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name1/current/fsimage.ckpt_0000000000000000000 of size 198 bytes saved in 0 seconds.
13/08/20 22:03:23 INFO namenode.FSImage: Image file /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name2/current/fsimage.ckpt_0000000000000000000 of size 198 bytes saved in 0 seconds.
13/08/20 22:03:23 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &amp;gt;= 0
13/08/20 22:03:23 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
13/08/20 22:03:23 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
13/08/20 22:03:23 INFO impl.MetricsSystemImpl: NameNode metrics system started
13/08/20 22:03:23 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
13/08/20 22:03:23 INFO http.HttpServer: Added global filter &lt;span class=&quot;code-quote&quot;&gt;&apos;safety&apos;&lt;/span&gt; (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
13/08/20 22:03:23 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
13/08/20 22:03:23 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt;
13/08/20 22:03:23 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
13/08/20 22:03:23 INFO http.HttpServer: dfs.webhdfs.enabled = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:23 INFO http.HttpServer: Jetty bound to port 49811
13/08/20 22:03:23 INFO mortbay.log: jetty-6.1.26
13/08/20 22:03:23 INFO mortbay.log: Started SelectChannelConnector@localhost:49811
13/08/20 22:03:23 INFO namenode.NameNode: Web-server up at: localhost:49811
13/08/20 22:03:23 INFO namenode.HostFileManager: read includes:
HostSet(
)
13/08/20 22:03:23 INFO namenode.HostFileManager: read excludes:
HostSet(
)
13/08/20 22:03:23 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
13/08/20 22:03:23 INFO util.GSet: Computing capacity &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; map BlocksMap
13/08/20 22:03:23 INFO util.GSet: VM type       = 32-bit
13/08/20 22:03:23 INFO util.GSet: 2.0% max memory = 494.9 MB
13/08/20 22:03:23 INFO util.GSet: capacity      = 2^21 = 2097152 entries
13/08/20 22:03:23 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:23 INFO blockmanagement.BlockManager: defaultReplication         = 1
13/08/20 22:03:23 INFO blockmanagement.BlockManager: maxReplication             = 512
13/08/20 22:03:23 INFO blockmanagement.BlockManager: minReplication             = 1
13/08/20 22:03:23 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
13/08/20 22:03:23 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:23 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
13/08/20 22:03:23 INFO blockmanagement.BlockManager: encryptDataTransfer        = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:23 INFO namenode.FSNamesystem: fsOwner             = stevel (auth:SIMPLE)
13/08/20 22:03:23 INFO namenode.FSNamesystem: supergroup          = supergroup
13/08/20 22:03:23 INFO namenode.FSNamesystem: isPermissionEnabled = &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
13/08/20 22:03:23 INFO namenode.FSNamesystem: HA Enabled: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:23 INFO namenode.FSNamesystem: Append Enabled: &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
13/08/20 22:03:23 INFO util.GSet: Computing capacity &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; map INodeMap
13/08/20 22:03:23 INFO util.GSet: VM type       = 32-bit
13/08/20 22:03:23 INFO util.GSet: 1.0% max memory = 494.9 MB
13/08/20 22:03:23 INFO util.GSet: capacity      = 2^20 = 1048576 entries
13/08/20 22:03:23 INFO namenode.NameNode: Caching file names occuring more than 10 times
13/08/20 22:03:23 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
13/08/20 22:03:23 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
13/08/20 22:03:23 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
13/08/20 22:03:23 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
13/08/20 22:03:23 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
13/08/20 22:03:23 INFO util.GSet: Computing capacity &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; map Namenode Retry Cache
13/08/20 22:03:23 INFO util.GSet: VM type       = 32-bit
13/08/20 22:03:23 INFO util.GSet: 0.029999999329447746% max memory = 494.9 MB
13/08/20 22:03:23 INFO util.GSet: capacity      = 2^15 = 32768 entries
13/08/20 22:03:23 INFO common.Storage: Lock on /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name1/in_use.lock acquired by nodename 13794@ubuntu
13/08/20 22:03:23 INFO common.Storage: Lock on /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name2/in_use.lock acquired by nodename 13794@ubuntu
13/08/20 22:03:23 INFO namenode.FileJournalManager: Recovering unfinalized segments in /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name1/current
13/08/20 22:03:23 INFO namenode.FileJournalManager: Recovering unfinalized segments in /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name2/current
13/08/20 22:03:23 INFO namenode.FSImage: No edit log streams selected.
13/08/20 22:03:23 INFO namenode.FSImage: Loading image file /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name1/current/fsimage_0000000000000000000 using no compression
13/08/20 22:03:23 INFO namenode.FSImage: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of files = 1
13/08/20 22:03:23 INFO namenode.FSImage: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of files under construction = 0
13/08/20 22:03:23 INFO namenode.FSImage: Image file /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name1/current/fsimage_0000000000000000000 of size 198 bytes loaded in 0 seconds.
13/08/20 22:03:23 INFO namenode.FSImage: Loaded image &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; txid 0 from /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/name1/current/fsimage_0000000000000000000
13/08/20 22:03:23 INFO namenode.FSEditLog: Starting log segment at 1
13/08/20 22:03:23 INFO namenode.NameCache: initialized with 0 entries 0 lookups
13/08/20 22:03:23 INFO namenode.FSNamesystem: Finished loading FSImage in 99 msecs
13/08/20 22:03:23 INFO ipc.Server: Starting Socket Reader #1 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; port 58332
13/08/20 22:03:24 INFO namenode.FSNamesystem: Registered FSNamesystemState MBean
13/08/20 22:03:24 INFO namenode.FSNamesystem: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of blocks under construction: 0
13/08/20 22:03:24 INFO namenode.FSNamesystem: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of blocks under construction: 0
13/08/20 22:03:24 INFO namenode.FSNamesystem: initializing replication queues
13/08/20 22:03:24 INFO blockmanagement.BlockManager: Total number of blocks            = 0
13/08/20 22:03:24 INFO blockmanagement.BlockManager: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of invalid blocks          = 0
13/08/20 22:03:24 INFO blockmanagement.BlockManager: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of under-replicated blocks = 0
13/08/20 22:03:24 INFO blockmanagement.BlockManager: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of  over-replicated blocks = 0
13/08/20 22:03:24 INFO blockmanagement.BlockManager: &lt;span class=&quot;code-object&quot;&gt;Number&lt;/span&gt; of blocks being written    = 0
13/08/20 22:03:24 INFO hdfs.StateChange: STATE* Replication Queue initialization scan &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; invalid, over- and under-replicated blocks completed in 13 msec
13/08/20 22:03:24 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs
13/08/20 22:03:24 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
13/08/20 22:03:24 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
13/08/20 22:03:24 INFO ipc.Server: IPC Server Responder: starting
13/08/20 22:03:24 INFO ipc.Server: IPC Server listener on 58332: starting
13/08/20 22:03:24 INFO namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:58332
13/08/20 22:03:24 INFO namenode.FSNamesystem: Starting services required &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; active state
13/08/20 22:03:24 INFO hdfs.MiniDFSCluster: Starting DataNode 0 with dfs.datanode.data.dir: file:/home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1,file:/home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2
13/08/20 22:03:24 INFO impl.MetricsSystemImpl: DataNode metrics system started (again)
13/08/20 22:03:24 INFO datanode.DataNode: Configured hostname is 127.0.0.1
13/08/20 22:03:24 INFO datanode.DataNode: Opened streaming server at /127.0.0.1:47429
13/08/20 22:03:24 INFO datanode.DataNode: Balancing bandwith is 1048576 bytes/s
13/08/20 22:03:24 INFO http.HttpServer: Added global filter &lt;span class=&quot;code-quote&quot;&gt;&apos;safety&apos;&lt;/span&gt; (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
13/08/20 22:03:24 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
13/08/20 22:03:24 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt;
13/08/20 22:03:24 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
13/08/20 22:03:24 INFO datanode.DataNode: Opened info server at localhost:0
13/08/20 22:03:24 INFO datanode.DataNode: dfs.webhdfs.enabled = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
13/08/20 22:03:24 INFO http.HttpServer: Jetty bound to port 59754
13/08/20 22:03:24 INFO mortbay.log: jetty-6.1.26
13/08/20 22:03:24 INFO mortbay.log: Started SelectChannelConnector@localhost:59754
13/08/20 22:03:24 INFO datanode.DataNode: Opened IPC server at /127.0.0.1:34353
13/08/20 22:03:24 INFO ipc.Server: Starting Socket Reader #1 &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; port 34353
13/08/20 22:03:24 INFO datanode.DataNode: Refresh request received &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; nameservices: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
13/08/20 22:03:24 INFO datanode.DataNode: Starting BPOfferServices &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; nameservices: &amp;lt;&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;&amp;gt;
13/08/20 22:03:24 INFO datanode.DataNode: Block pool &amp;lt;registering&amp;gt; (storage id unknown) service to localhost/127.0.0.1:58332 starting to offer service
13/08/20 22:03:24 INFO ipc.Server: IPC Server Responder: starting
13/08/20 22:03:24 INFO ipc.Server: IPC Server listener on 34353: starting
13/08/20 22:03:24 INFO common.Storage: Lock on /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1/in_use.lock acquired by nodename 13794@ubuntu
13/08/20 22:03:24 INFO common.Storage: Storage directory /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1 is not formatted
13/08/20 22:03:24 INFO common.Storage: Formatting ...
13/08/20 22:03:24 INFO hdfs.MiniDFSCluster: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; cluster to become active
13/08/20 22:03:24 INFO common.Storage: Lock on /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2/in_use.lock acquired by nodename 13794@ubuntu
13/08/20 22:03:24 INFO common.Storage: Storage directory /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2 is not formatted
13/08/20 22:03:24 INFO common.Storage: Formatting ...
13/08/20 22:03:24 INFO common.Storage: Locking is disabled
13/08/20 22:03:24 INFO common.Storage: Storage directory /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1/current/BP-604112716-192.168.1.132-1377032603159 is not formatted.
13/08/20 22:03:24 INFO common.Storage: Formatting ...
13/08/20 22:03:24 INFO common.Storage: Formatting block pool BP-604112716-192.168.1.132-1377032603159 directory /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1/current/BP-604112716-192.168.1.132-1377032603159/current
13/08/20 22:03:24 INFO common.Storage: Locking is disabled
13/08/20 22:03:24 INFO common.Storage: Storage directory /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2/current/BP-604112716-192.168.1.132-1377032603159 is not formatted.
13/08/20 22:03:24 INFO common.Storage: Formatting ...
13/08/20 22:03:24 INFO common.Storage: Formatting block pool BP-604112716-192.168.1.132-1377032603159 directory /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2/current/BP-604112716-192.168.1.132-1377032603159/current
13/08/20 22:03:24 INFO datanode.DataNode: Setting up storage: nsid=355659070;bpid=BP-604112716-192.168.1.132-1377032603159;lv=-47;nsInfo=lv=-47;cid=testClusterID;nsid=355659070;c=0;bpid=BP-604112716-192.168.1.132-1377032603159
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Added volume - /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1/current
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Added volume - /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2/current
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean
13/08/20 22:03:24 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1377035360956 with interval 21600000
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Adding block pool BP-604112716-192.168.1.132-1377032603159
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Scanning block pool BP-604112716-192.168.1.132-1377032603159 on volume /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1/current...
13/08/20 22:03:24 INFO hdfs.MiniDFSCluster: Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; cluster to become active
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Scanning block pool BP-604112716-192.168.1.132-1377032603159 on volume /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2/current...
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-604112716-192.168.1.132-1377032603159 on /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2/current: 16ms
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-604112716-192.168.1.132-1377032603159 on /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1/current: 22ms
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Total time to scan all replicas &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block pool BP-604112716-192.168.1.132-1377032603159: 22ms
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Adding replicas to map &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block pool BP-604112716-192.168.1.132-1377032603159 on volume /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1/current...
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Time to add replicas to map &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block pool BP-604112716-192.168.1.132-1377032603159 on volume /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data1/current: 0ms
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Adding replicas to map &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block pool BP-604112716-192.168.1.132-1377032603159 on volume /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2/current...
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Time to add replicas to map &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block pool BP-604112716-192.168.1.132-1377032603159 on volume /home/stevel/hadoop-2.1.1-SNAPSHOT/build/test/data/dfs/data/data2/current: 1ms
13/08/20 22:03:24 INFO impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
13/08/20 22:03:24 INFO datanode.DataNode: Block pool BP-604112716-192.168.1.132-1377032603159 (storage id DS-1166679418-192.168.1.132-47429-1377032604876) service to localhost/127.0.0.1:58332 beginning handshake with NN
13/08/20 22:03:24 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1166679418-192.168.1.132-47429-1377032604876, infoPort=59754, ipcPort=34353, storageInfo=lv=-47;cid=testClusterID;nsid=355659070;c=0) storage DS-1166679418-192.168.1.132-47429-1377032604876
13/08/20 22:03:25 INFO net.NetworkTopology: Adding a &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; node: /&lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;-rack/127.0.0.1:47429
13/08/20 22:03:25 INFO datanode.DataNode: Block pool Block pool BP-604112716-192.168.1.132-1377032603159 (storage id DS-1166679418-192.168.1.132-47429-1377032604876) service to localhost/127.0.0.1:58332 successfully registered with NN
13/08/20 22:03:25 INFO datanode.DataNode: For namenode localhost/127.0.0.1:58332 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec Initial delay: 0msec; heartBeatInterval=3000
13/08/20 22:03:25 INFO datanode.DataNode: Namenode Block pool BP-604112716-192.168.1.132-1377032603159 (storage id DS-1166679418-192.168.1.132-47429-1377032604876) service to localhost/127.0.0.1:58332 trying to claim ACTIVE state with txid=1
13/08/20 22:03:25 INFO datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-604112716-192.168.1.132-1377032603159 (storage id DS-1166679418-192.168.1.132-47429-1377032604876) service to localhost/127.0.0.1:58332
13/08/20 22:03:25 INFO blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:47429 after starting up or becoming active. Its block contents are no longer considered stale
13/08/20 22:03:25 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1166679418-192.168.1.132-47429-1377032604876, infoPort=59754, ipcPort=34353, storageInfo=lv=-47;cid=testClusterID;nsid=355659070;c=0), blocks: 0, processing time: 4 msecs
13/08/20 22:03:25 INFO datanode.DataNode: BlockReport of 0 blocks took 1 msec to generate and 9 msecs &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; RPC and NN processing
13/08/20 22:03:25 INFO datanode.DataNode: sent block report, processed command:org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@381a53
13/08/20 22:03:25 INFO util.GSet: Computing capacity &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; map BlockMap
13/08/20 22:03:25 INFO util.GSet: VM type       = 32-bit
13/08/20 22:03:25 INFO util.GSet: 0.5% max memory = 494.9 MB
13/08/20 22:03:25 INFO util.GSet: capacity      = 2^19 = 524288 entries
13/08/20 22:03:25 INFO datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block pool BP-604112716-192.168.1.132-1377032603159
13/08/20 22:03:25 INFO datanode.DataBlockScanner: Added bpid=BP-604112716-192.168.1.132-1377032603159 to blockPoolScannerMap, &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; size=1
13/08/20 22:03:25 INFO hdfs.MiniDFSCluster: Cluster is active
13/08/20 22:03:25 INFO mapreduce.MiniHadoopClusterManager: Started MiniDFSCluster -- namenode on port 58332
java.lang.NoClassDefFoundError: org/apache/hadoop/yarn/server/MiniYARNCluster
	at org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start(MiniHadoopClusterManager.java:170)
	at org.apache.hadoop.mapreduce.MiniHadoopClusterManager.run(MiniHadoopClusterManager.java:129)
	at org.apache.hadoop.mapreduce.MiniHadoopClusterManager.main(MiniHadoopClusterManager.java:314)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:115)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:123)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.yarn.server.MiniYARNCluster
	at java.net.URLClassLoader$1.run(URLClassLoader.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:321)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:294)
	at java.lang.&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.loadClass(&lt;span class=&quot;code-object&quot;&gt;ClassLoader&lt;/span&gt;.java:266)
	... 16 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13745763" author="gopalv" created="Wed, 21 Aug 2013 04:03:48 +0000"  >&lt;p&gt;Just adding the YARN mini cluster into class-path does not give an operational cluster, the AM code is missing from that jar &amp;amp; also has to be added to the classpath.&lt;/p&gt;</comment>
                            <comment id="14509736" author="d4rr3ll" created="Thu, 23 Apr 2015 20:34:51 +0000"  >&lt;p&gt;I&apos;ll have a go a fixing this as I&apos;m trying to use it.  Would anybody be able to give me any pointers towards where I should be looking to get the missing class into the jar?&lt;/p&gt;</comment>
                            <comment id="14509739" author="d4rr3ll" created="Thu, 23 Apr 2015 20:37:36 +0000"  >&lt;p&gt;This seems to be the solution.  If I can make it work I&apos;ll update the docs.&lt;/p&gt;</comment>
                            <comment id="14509741" author="d4rr3ll" created="Thu, 23 Apr 2015 20:38:48 +0000"  >&lt;p&gt;the above comment is about the related Jira I just linked...&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/YARN-683&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/YARN-683&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="14511265" author="hadoopqa" created="Fri, 24 Apr 2015 15:56:35 +0000"  >&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/check.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Vote &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Runtime &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Comment &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; pre-patch &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   2m 48s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Pre-patch trunk compilation is healthy. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; @author &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The patch does not contain any @author tags. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; whitespace &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The patch has no lines that end in whitespace. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; release audit &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 20s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The applied patch does not increase the total number of release audit warnings. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; site &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   2m 53s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Site still builds. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   6m 12s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Report/Notes &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Patch URL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12727940/HADOOP-9891.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12727940/HADOOP-9891.patch&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Optional Tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; site &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; git revision &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; trunk / 91b97c2 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Console output &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6173/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6173/console&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;



&lt;p&gt;This message was automatically generated.&lt;/p&gt;</comment>
                            <comment id="14561993" author="aw" created="Wed, 27 May 2015 23:37:28 +0000"  >&lt;p&gt;+1 committed to trunk.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;</comment>
                            <comment id="14562097" author="hudson" created="Thu, 28 May 2015 00:44:59 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-trunk-Commit #7911 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/7911/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/7911/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9891&quot; title=&quot;CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9891&quot;&gt;&lt;del&gt;HADOOP-9891&lt;/del&gt;&lt;/a&gt;. CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException (Darrell Taylor via aw) (aw: rev 4d8fb8c19c04088cf8f8e9deecb571273adeaab5)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/site/markdown/CLIMiniCluster.md.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14562667" author="hudson" created="Thu, 28 May 2015 10:43:12 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #211 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/211/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/211/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9891&quot; title=&quot;CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9891&quot;&gt;&lt;del&gt;HADOOP-9891&lt;/del&gt;&lt;/a&gt;. CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException (Darrell Taylor via aw) (aw: rev 4d8fb8c19c04088cf8f8e9deecb571273adeaab5)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/site/markdown/CLIMiniCluster.md.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14562749" author="hudson" created="Thu, 28 May 2015 11:59:14 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #941 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/941/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/941/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9891&quot; title=&quot;CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9891&quot;&gt;&lt;del&gt;HADOOP-9891&lt;/del&gt;&lt;/a&gt;. CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException (Darrell Taylor via aw) (aw: rev 4d8fb8c19c04088cf8f8e9deecb571273adeaab5)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/site/markdown/CLIMiniCluster.md.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14562953" author="hudson" created="Thu, 28 May 2015 14:24:21 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #2139 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/2139/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/2139/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9891&quot; title=&quot;CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9891&quot;&gt;&lt;del&gt;HADOOP-9891&lt;/del&gt;&lt;/a&gt;. CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException (Darrell Taylor via aw) (aw: rev 4d8fb8c19c04088cf8f8e9deecb571273adeaab5)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/site/markdown/CLIMiniCluster.md.vm&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14562968" author="hudson" created="Thu, 28 May 2015 14:30:53 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #199 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/199/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/199/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9891&quot; title=&quot;CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9891&quot;&gt;&lt;del&gt;HADOOP-9891&lt;/del&gt;&lt;/a&gt;. CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException (Darrell Taylor via aw) (aw: rev 4d8fb8c19c04088cf8f8e9deecb571273adeaab5)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/site/markdown/CLIMiniCluster.md.vm&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14563074" author="hudson" created="Thu, 28 May 2015 15:29:39 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #209 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/209/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/209/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9891&quot; title=&quot;CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9891&quot;&gt;&lt;del&gt;HADOOP-9891&lt;/del&gt;&lt;/a&gt;. CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException (Darrell Taylor via aw) (aw: rev 4d8fb8c19c04088cf8f8e9deecb571273adeaab5)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/site/markdown/CLIMiniCluster.md.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14563141" author="hudson" created="Thu, 28 May 2015 15:54:24 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2157 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2157/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2157/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9891&quot; title=&quot;CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9891&quot;&gt;&lt;del&gt;HADOOP-9891&lt;/del&gt;&lt;/a&gt;. CLIMiniCluster instructions fail with MiniYarnCluster ClassNotFoundException (Darrell Taylor via aw) (aw: rev 4d8fb8c19c04088cf8f8e9deecb571273adeaab5)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/site/markdown/CLIMiniCluster.md.vm&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14698144" author="jira.shegalov" created="Sat, 15 Aug 2015 06:25:07 +0000"  >&lt;p&gt;Any objections to backporting this to branch-2 as well?&lt;/p&gt;</comment>
                            <comment id="14701522" author="ajisakaa" created="Tue, 18 Aug 2015 16:27:45 +0000"  >&lt;p&gt;+1 for backporting this to branch-2.&lt;/p&gt;</comment>
                            <comment id="14701864" author="jira.shegalov" created="Tue, 18 Aug 2015 19:50:17 +0000"  >&lt;p&gt;Thanks, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ajisakaa&quot; class=&quot;user-hover&quot; rel=&quot;ajisakaa&quot;&gt;ajisakaa&lt;/a&gt;! Committed to branch-2!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12905435">YARN-4272</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12647524">YARN-683</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12727940" name="HADOOP-9891.patch" size="1095" author="d4rr3ll" created="Fri, 24 Apr 2015 15:40:24 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344636</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 14 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1nfjz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>344936</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>