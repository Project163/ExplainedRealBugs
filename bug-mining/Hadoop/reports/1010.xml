<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:43:58 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-9478] Fix race conditions during the initialization of Configuration related to deprecatedKeyMap</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-9478</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;When we lanuch the client appliation which use kerberos security,the FileSystem can&apos;t be create because the exception &apos; java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.SecurityUtil&apos;.&lt;/p&gt;

&lt;p&gt;I check the exception stack trace,it maybe caused by the unsafe get operation of the deprecatedKeyMap which used by the org.apache.hadoop.conf.Configuration.&lt;/p&gt;

&lt;p&gt;So I write a simple test case:&lt;/p&gt;

&lt;p&gt;import org.apache.hadoop.conf.Configuration;&lt;br/&gt;
import org.apache.hadoop.fs.FileSystem;&lt;br/&gt;
import org.apache.hadoop.hdfs.HdfsConfiguration;&lt;/p&gt;

&lt;p&gt;public class HTest {&lt;br/&gt;
    public static void main(String[] args) throws Exception &lt;/p&gt;
{
        Configuration conf = new Configuration();
        conf.addResource(&quot;core-site.xml&quot;);
        conf.addResource(&quot;hdfs-site.xml&quot;);
        FileSystem fileSystem = FileSystem.get(conf);
        System.out.println(fileSystem);
        System.exit(0);
    }
&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;Then I launch this test case many times,the following exception is thrown:&lt;/p&gt;

&lt;p&gt;Exception in thread &quot;TGT Renewer for XXX&quot; java.lang.ExceptionInInitializerError&lt;br/&gt;
     at org.apache.hadoop.security.UserGroupInformation.getTGT(UserGroupInformation.java:719)&lt;br/&gt;
     at org.apache.hadoop.security.UserGroupInformation.access$1100(UserGroupInformation.java:77)&lt;br/&gt;
     at org.apache.hadoop.security.UserGroupInformation$1.run(UserGroupInformation.java:746)&lt;br/&gt;
     at java.lang.Thread.run(Thread.java:662)&lt;br/&gt;
Caused by: java.lang.ArrayIndexOutOfBoundsException: 16&lt;br/&gt;
     at java.util.HashMap.getEntry(HashMap.java:345)&lt;br/&gt;
     at java.util.HashMap.containsKey(HashMap.java:335)&lt;br/&gt;
     at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1989)&lt;br/&gt;
     at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1867)&lt;br/&gt;
     at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1785)&lt;br/&gt;
     at org.apache.hadoop.conf.Configuration.get(Configuration.java:712)&lt;br/&gt;
     at org.apache.hadoop.conf.Configuration.getTrimmed(Configuration.java:731)&lt;br/&gt;
     at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1047)&lt;br/&gt;
     at org.apache.hadoop.security.SecurityUtil.&amp;lt;clinit&amp;gt;(SecurityUtil.java:76)&lt;br/&gt;
     ... 4 more&lt;br/&gt;
Exception in thread &quot;main&quot; java.io.IOException: Couldn&apos;t create proxy provider class org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;br/&gt;
     at org.apache.hadoop.hdfs.NameNodeProxies.createFailoverProxyProvider(NameNodeProxies.java:453)&lt;br/&gt;
     at org.apache.hadoop.hdfs.NameNodeProxies.createProxy(NameNodeProxies.java:133)&lt;br/&gt;
     at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:436)&lt;br/&gt;
     at org.apache.hadoop.hdfs.DFSClient.&amp;lt;init&amp;gt;(DFSClient.java:403)&lt;br/&gt;
     at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:125)&lt;br/&gt;
     at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2262)&lt;br/&gt;
     at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:86)&lt;br/&gt;
     at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2296)&lt;br/&gt;
     at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2278)&lt;br/&gt;
     at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:316)&lt;br/&gt;
     at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:162)&lt;br/&gt;
     at HTest.main(HTest.java:11)&lt;br/&gt;
Caused by: java.lang.reflect.InvocationTargetException&lt;br/&gt;
     at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)&lt;br/&gt;
     at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)&lt;br/&gt;
     at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)&lt;br/&gt;
     at java.lang.reflect.Constructor.newInstance(Constructor.java:513)&lt;br/&gt;
     at org.apache.hadoop.hdfs.NameNodeProxies.createFailoverProxyProvider(NameNodeProxies.java:442)&lt;br/&gt;
     ... 11 more&lt;br/&gt;
Caused by: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.SecurityUtil&lt;br/&gt;
     at org.apache.hadoop.net.NetUtils.createSocketAddrForHost(NetUtils.java:231)&lt;br/&gt;
     at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:211)&lt;br/&gt;
     at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:159)&lt;br/&gt;
     at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)&lt;br/&gt;
     at org.apache.hadoop.hdfs.DFSUtil.getAddressesForNameserviceId(DFSUtil.java:452)&lt;br/&gt;
     at org.apache.hadoop.hdfs.DFSUtil.getAddresses(DFSUtil.java:434)&lt;br/&gt;
     at org.apache.hadoop.hdfs.DFSUtil.getHaNnRpcAddresses(DFSUtil.java:496)&lt;br/&gt;
     at org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.&amp;lt;init&amp;gt;(ConfiguredFailoverProxyProvider.java:88)&lt;br/&gt;
     ... 16 more&lt;/p&gt;


&lt;p&gt;If the HashMap used at multi-thread enviroment,not only the put operation be synchronized,the get operation(eg. containKey) should be synchronzied too.&lt;/p&gt;

&lt;p&gt;The simple solution is trigger the init of SecurityUtil before creating the FileSystem,but I think it&apos;s should be synchronized for get of deprecatedKeyMap.&lt;/p&gt;

&lt;p&gt;Thanks. &lt;/p&gt;</description>
                <environment>&lt;p&gt;OS:&lt;br/&gt;
CentOS release 6.3 (Final)&lt;/p&gt;

&lt;p&gt;JDK:&lt;br/&gt;
java version &quot;1.6.0_27&quot;&lt;br/&gt;
Java(TM) SE Runtime Environment (build 1.6.0_27-b07)&lt;br/&gt;
Java HotSpot(TM) 64-Bit Server VM (build 20.2-b06, mixed mode)&lt;/p&gt;

&lt;p&gt;Hadoop:&lt;br/&gt;
hadoop-2.0.0-cdh4.1.3/hadoop-2.0.0-cdh4.2.0&lt;/p&gt;

&lt;p&gt;Security:&lt;br/&gt;
Kerberos&lt;/p&gt;</environment>
        <key id="12642711">HADOOP-9478</key>
            <summary>Fix race conditions during the initialization of Configuration related to deprecatedKeyMap</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cmccabe">Colin McCabe</assignee>
                                    <reporter username="d0ngw">Dongyong Wang</reporter>
                        <labels>
                    </labels>
                <created>Tue, 16 Apr 2013 12:08:12 +0000</created>
                <updated>Tue, 25 Feb 2014 01:21:55 +0000</updated>
                            <resolved>Tue, 25 Feb 2014 01:21:49 +0000</resolved>
                                    <version>2.0.0-alpha</version>
                                    <fixVersion>2.3.0</fixVersion>
                                    <component>conf</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="13801128" author="andrew.wang" created="Mon, 21 Oct 2013 21:35:11 +0000"  >&lt;p&gt;Here&apos;s a patch for trunk which just swaps out the &lt;tt&gt;HashMap&lt;/tt&gt; for a &lt;tt&gt;ConcurrentHashMap&lt;/tt&gt;. I couldn&apos;t repro this, but I can see the potential for this race condition: &lt;tt&gt;addDeprecation&lt;/tt&gt; is &lt;tt&gt;synchronized&lt;/tt&gt;, but various read operations aren&apos;t, e.g. &lt;tt&gt;loadResource&lt;/tt&gt; via &lt;tt&gt;getProps&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;&lt;tt&gt;Configuration&lt;/tt&gt; will still require external synchronization if your app requires strong consistency while concurrently loading resources and reading config keys, but at least this will hopefully prevent exceptions like the above.&lt;/p&gt;</comment>
                            <comment id="13801398" author="cmccabe" created="Tue, 22 Oct 2013 01:54:10 +0000"  >&lt;p&gt;thinking about this, I think it would be better to use compare-and-swap to swap in a new immutable object containing both forward and backward maps, when updating the Configuration.  Using &lt;tt&gt;AtomicReference&lt;/tt&gt; or something.&lt;/p&gt;

&lt;p&gt;If you want to use ConcurrentHashMap, that&apos;s fine, I guess.  However, you should at least fix the places where we do a bunch of loads in a row, like this:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    DeprecatedKeyInfo keyInfo = deprecatedKeyMap.get(name);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (keyInfo == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      altNames = (reverseDeprecatedKeyMap.get(name) != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt; ) ?
        &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; [] {reverseDeprecatedKeyMap.get(name)} : &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;we don&apos;t want to have the inconsistency here.  Also, we&apos;re taking and releasing the lock an awful lot in this scenario.&lt;/p&gt;</comment>
                            <comment id="13802315" author="andrew.wang" created="Tue, 22 Oct 2013 21:48:12 +0000"  >&lt;p&gt;Good points. I was hoping to escape slapping locks everywhere since the deprecated list is append-only, but we do need consistent multi-key and cross-map operations.&lt;/p&gt;

&lt;p&gt;Unfortunately, I don&apos;t think &lt;tt&gt;AtomicReference&lt;/tt&gt; or &lt;tt&gt;ConcurrentHashMap&lt;/tt&gt; really save us when we need to do multiple operations atomically. I think the only &lt;b&gt;really&lt;/b&gt; safe solution is slapping down class monitor locks everywhere. This is heavyweight, but applications really shouldn&apos;t be accessing Configuration so much that it becomes a problem.&lt;/p&gt;

&lt;p&gt;I did leave a few one-off ops unsynchronized since they should be handled by the &lt;tt&gt;CHM&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="13805955" author="cmccabe" created="Sat, 26 Oct 2013 02:09:25 +0000"  >&lt;p&gt;I figured out a way to do this without any global locking.  Instead, we just have an &lt;tt&gt;AtomicReference&lt;/tt&gt; to an immutable &lt;tt&gt;DeprecationContext&lt;/tt&gt; object.  Every time we mutate the &lt;tt&gt;DeprecationContext&lt;/tt&gt;, we create a new copy of the object.  I also added a batch mutate API for efficiency&apos;s sake.&lt;/p&gt;

&lt;p&gt;This should eliminate the concurrent access exceptions, while not requiring a global lock for all &lt;tt&gt;Configuration&lt;/tt&gt; objects.&lt;/p&gt;

&lt;p&gt;Interestingly enough, I found a lot of places where access to a single &lt;tt&gt;Configuration&lt;/tt&gt; object was single-threaded... like the use of the internally-synchronized &lt;tt&gt;Properties&lt;/tt&gt; class.  It would be nice to get rid of those in the future and use some kind of concurrent map instead.  However, a lot of things would have to change, like the &lt;tt&gt;REGISTRY&lt;/tt&gt; object and so forth, so that would be a bigger change.&lt;/p&gt;</comment>
                            <comment id="13805973" author="hadoopqa" created="Sat, 26 Oct 2013 02:42:21 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12610430/HADOOP-9478.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12610430/HADOOP-9478.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;      &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 1550 javac compiler warnings (more than the trunk&apos;s current 1549 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3251//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3251//testReport/&lt;/a&gt;&lt;br/&gt;
Javac warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3251//artifact/trunk/patchprocess/diffJavacWarnings.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3251//artifact/trunk/patchprocess/diffJavacWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3251//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3251//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13810568" author="cmccabe" created="Thu, 31 Oct 2013 19:10:14 +0000"  >&lt;p&gt;Use the &lt;tt&gt;Configuration#addDeprecations&lt;/tt&gt; API in &lt;tt&gt;HdfsConfiguration&lt;/tt&gt; to avoid a warning about using a deprecated function&lt;/p&gt;</comment>
                            <comment id="13810661" author="cmccabe" created="Thu, 31 Oct 2013 20:31:17 +0000"  >&lt;p&gt;fix some other uses of the deprecated methods&lt;/p&gt;</comment>
                            <comment id="13810736" author="hadoopqa" created="Thu, 31 Oct 2013 21:34:34 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12611455/HADOOP-9478.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12611455/HADOOP-9478.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3257//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3257//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3257//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3257//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13810857" author="hadoopqa" created="Thu, 31 Oct 2013 23:26:19 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12611473/HADOOP-9478.003.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12611473/HADOOP-9478.003.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-tools/hadoop-extras hadoop-tools/hadoop-gridmix.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3259//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3259//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3259//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3259//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13810945" author="andrew.wang" created="Fri, 1 Nov 2013 01:50:46 +0000"  >&lt;p&gt;Hey Colin, thanks for taking this on. I like the overall idea; it&apos;s a pity we can&apos;t use an built-in java class for this, but needs must when synchronizing across two maps. Some review comments:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;testAndSetAccessed: should this be instead named getAndSetAccessed?&lt;/li&gt;
	&lt;li&gt;DeprecationContext#containsKey is never used&lt;/li&gt;
	&lt;li&gt;I prefer using &lt;tt&gt;Preconditions&lt;/tt&gt; checks over throwing a raw IllegalArgumentException, it&apos;ll have a nicer message&lt;/li&gt;
	&lt;li&gt;I&apos;d rather not expose that new &lt;tt&gt;addDeprecations(DeprecationDelta[] delta&lt;/tt&gt; method publicly, users prefer manipulating strings. It seems like some past coder was also trying to move in the direction of simplifying this API to just the &lt;tt&gt;String&lt;/tt&gt; variants by deprecating the &lt;tt&gt;String[]&lt;/tt&gt; versions.&lt;/li&gt;
	&lt;li&gt;The above would also help quash the diff&lt;/li&gt;
	&lt;li&gt;Can we just do &lt;tt&gt;deprecationContext.get()&lt;/tt&gt; in &lt;tt&gt;handleDeprecation(String)&lt;/tt&gt; rather than passing it down in &lt;tt&gt;handleDeprecation&lt;/tt&gt; etc?&lt;/li&gt;
	&lt;li&gt;loadResource, could you move the global deprecation get down to where it&apos;s used for the first time?&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13811625" author="cmccabe" created="Fri, 1 Nov 2013 20:29:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;testAndSetAccessed: should this be instead named getAndSetAccessed?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;yeah&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;DeprecationContext#containsKey is never used&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;removed&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I prefer using Preconditions checks over throwing a raw IllegalArgumentException, it&apos;ll have a nicer message&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I changed the checks to &lt;tt&gt;Preconditions&lt;/tt&gt; and moved them to the &lt;tt&gt;DeprecationDelta&lt;/tt&gt; constructor&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I&apos;d rather not expose that new addDeprecations(DeprecationDelta[] delta method publicly, users prefer manipulating strings. It seems like some past coder was also trying to move in the direction of simplifying this API to just the String variants by deprecating the String[] versions.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This API is far more efficient and expressive.  In many cases we&apos;re adding hundreds of deprecated keys, so this does matter.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can we just do deprecationContext.get() in handleDeprecation(String) rather than passing it down in handleDeprecation etc?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No, because then we&apos;d be doing an atomic get O(num_properties) times.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;loadResource, could you move the global deprecation get down to where it&apos;s used for the first time?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK&lt;/p&gt;

&lt;p&gt;I will also add a test&lt;/p&gt;</comment>
                            <comment id="13811701" author="andrew.wang" created="Fri, 1 Nov 2013 22:05:54 +0000"  >&lt;p&gt;Just nitty things this time, thanks Colin. +1 once addressed:&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;typo: &quot;globals set of&quot; -&amp;gt; &quot;global set of&quot;&lt;/li&gt;
	&lt;li&gt;Can we slap &lt;tt&gt;@Deprecation&lt;/tt&gt; on the &lt;tt&gt;DeprecationDelta&lt;/tt&gt; constructors that take an array of new keys? We still want to discourage this usage.&lt;/li&gt;
	&lt;li&gt;I don&apos;t think we need to deprecate &lt;tt&gt;addDeprecation(String, String)&lt;/tt&gt;&lt;/li&gt;
	&lt;li&gt;Similarly, don&apos;t we need a &lt;tt&gt;DeprecationDelta(String, String, String)&lt;/tt&gt; constructor for parity with the existing non-deprecated methods?&lt;/li&gt;
	&lt;li&gt;I sort of expected the new test to be using the new &lt;tt&gt;DeprecationDelta&lt;/tt&gt; API&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13811750" author="hadoopqa" created="Fri, 1 Nov 2013 23:12:58 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12611680/HADOOP-9478.004.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12611680/HADOOP-9478.004.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-tools/hadoop-extras hadoop-tools/hadoop-gridmix.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3262//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3262//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3262//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3262//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13811897" author="cmccabe" created="Sat, 2 Nov 2013 07:26:16 +0000"  >&lt;blockquote&gt;&lt;p&gt;typo: &quot;globals set of&quot; -&amp;gt; &quot;global set of&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Can we slap @Deprecation on the DeprecationDelta constructors that take an array of new keys? We still want to discourage this usage.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I made it package-private so it won&apos;t be part of the public API at all.  It&apos;s just used to implement some of the deprecated methods elsewhere in &lt;tt&gt;Configuration&lt;/tt&gt;.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I don&apos;t think we need to deprecate addDeprecation(String, String)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Similarly, don&apos;t we need a DeprecationDelta(String, String, String) constructor for parity with the existing non-deprecated methods?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;added&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;I sort of expected the new test to be using the new DeprecationDelta API&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK&lt;/p&gt;

&lt;p&gt;resubmitting, will commit after jenkins.&lt;/p&gt;</comment>
                            <comment id="13811901" author="d0ngw" created="Sat, 2 Nov 2013 08:35:10 +0000"  >&lt;p&gt;Thanks. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="13811926" author="hadoopqa" created="Sat, 2 Nov 2013 10:14:45 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12611748/HADOOP-9478.005.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12611748/HADOOP-9478.005.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-tools/hadoop-extras hadoop-tools/hadoop-gridmix:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.hdfs.server.balancer.TestBalancerWithNodeGroup&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3264//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3264//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3264//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3264//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13812099" author="cmccabe" created="Sat, 2 Nov 2013 18:34:23 +0000"  >&lt;p&gt;TestBalancerWithNodeGroup failure is unrelated.  Thanks for the +1, Andrew-- will commit shortly.&lt;/p&gt;</comment>
                            <comment id="13812114" author="hudson" created="Sat, 2 Nov 2013 18:56:44 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #4691 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/4691/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/4691/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9478&quot; title=&quot;Fix race conditions during the initialization of Configuration related to deprecatedKeyMap&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9478&quot;&gt;&lt;del&gt;HADOOP-9478&lt;/del&gt;&lt;/a&gt;. Fix race conditions during the initialization of Configuration related to deprecatedKeyMap (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1538248&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1538248&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HdfsConfiguration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/util/ConfigUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/Logalyzer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13812331" author="hudson" created="Sun, 3 Nov 2013 11:10:24 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #381 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/381/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/381/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9478&quot; title=&quot;Fix race conditions during the initialization of Configuration related to deprecatedKeyMap&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9478&quot;&gt;&lt;del&gt;HADOOP-9478&lt;/del&gt;&lt;/a&gt;. Fix race conditions during the initialization of Configuration related to deprecatedKeyMap (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1538248&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1538248&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HdfsConfiguration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/util/ConfigUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/Logalyzer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13812353" author="hudson" created="Sun, 3 Nov 2013 13:03:29 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1598 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1598/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1598/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9478&quot; title=&quot;Fix race conditions during the initialization of Configuration related to deprecatedKeyMap&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9478&quot;&gt;&lt;del&gt;HADOOP-9478&lt;/del&gt;&lt;/a&gt;. Fix race conditions during the initialization of Configuration related to deprecatedKeyMap (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1538248&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1538248&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HdfsConfiguration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/util/ConfigUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/Logalyzer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13812365" author="hudson" created="Sun, 3 Nov 2013 13:35:30 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1572 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1572/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1572/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9478&quot; title=&quot;Fix race conditions during the initialization of Configuration related to deprecatedKeyMap&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9478&quot;&gt;&lt;del&gt;HADOOP-9478&lt;/del&gt;&lt;/a&gt;. Fix race conditions during the initialization of Configuration related to deprecatedKeyMap (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1538248&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1538248&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HdfsConfiguration.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/util/ConfigUtil.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-extras/src/main/java/org/apache/hadoop/tools/Logalyzer.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-tools/hadoop-gridmix/src/main/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13817460" author="acmurthy" created="Fri, 8 Nov 2013 17:03:45 +0000"  >&lt;p&gt;I need to debug more, but it looks like this may caused an incompatible change in handling deprecations... in future, MR folks (I volunteer) appreciate a heads up on major configuration changes. Thanks.&lt;/p&gt;</comment>
                            <comment id="13817562" author="cmccabe" created="Fri, 8 Nov 2013 18:43:07 +0000"  >&lt;p&gt;Can you be more specific about what the problem you are encountering is and why you think this is the cause?&lt;/p&gt;</comment>
                            <comment id="13817720" author="acmurthy" created="Fri, 8 Nov 2013 21:42:08 +0000"  >&lt;p&gt;Deprecation isn&apos;t working for MR when client and cluster are on 2.2 v/s 2.3-SNAPSHOT, still debugging.&lt;/p&gt;</comment>
                            <comment id="13818019" author="cmccabe" created="Sat, 9 Nov 2013 05:23:01 +0000"  >&lt;p&gt;Why don&apos;t you file an MR JIRA with a description of the problems you are having and how to reproduce them so that the community can help with this process?  If this JIRA turns out to be the issue we can always link the JIRAs, like we did with so many other Configuration issues.&lt;/p&gt;</comment>
                            <comment id="13828048" author="szetszwo" created="Wed, 20 Nov 2013 19:59:59 +0000"  >&lt;p&gt;After this change, I somehow get &quot;NoClassDefFoundError: org/apache/commons/collections/map/UnmodifiableMap&quot; when I run any test under trunk/hadoop-hdfs-project/hadoop-hdfs.  Running tests under project root (i.e. trunk/) is fine.  I wonder if it is a problem in my local environment.  Do you get the same thing?&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Running org.apache.hadoop.hdfs.TestFileCreation
Tests run: 22, Failures: 0, Errors: 20, Skipped: 2, Time elapsed: 0.161 sec &amp;lt;&amp;lt;&amp;lt; FAILURE! - in org.apache.hadoop.hdfs.TestFileCreation
testServerDefaults(org.apache.hadoop.hdfs.TestFileCreation)  Time elapsed: 0.016 sec  &amp;lt;&amp;lt;&amp;lt; ERROR!
java.lang.NoClassDefFoundError: org/apache/commons/collections/map/UnmodifiableMap
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
	at org.apache.hadoop.conf.Configuration$DeprecationContext.&amp;lt;init&amp;gt;(Configuration.java:394)
	at org.apache.hadoop.conf.Configuration.&amp;lt;clinit&amp;gt;(Configuration.java:432)
	at org.apache.hadoop.hdfs.TestFileCreation.testServerDefaults(TestFileCreation.java:149)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13828113" author="andrew.wang" created="Wed, 20 Nov 2013 21:04:21 +0000"  >&lt;p&gt;Hey Nicholas, I&apos;ve been running trunk tests the last few weeks without seeing this. It might be your local environment like you suspect.&lt;/p&gt;</comment>
                            <comment id="13828164" author="cmccabe" created="Wed, 20 Nov 2013 21:39:52 +0000"  >&lt;p&gt;I have not seen that.  I think it&apos;s your local environment.&lt;/p&gt;

&lt;p&gt;The class you are referring to is part of &lt;tt&gt;org.apache.commons.collections&lt;/tt&gt; and should be provided by &lt;tt&gt;commons-collections-3.2.1.jar&lt;/tt&gt;.  If that jar is not in your &lt;tt&gt;CLASSPATH&lt;/tt&gt;, you need to figure out why.  Note that we also used  &lt;tt&gt;org.apache.commons.collections&lt;/tt&gt; in hadoop-common prior to this change, in &lt;tt&gt;FileUtil&lt;/tt&gt;.&lt;/p&gt;</comment>
                            <comment id="13828247" author="bikassaha" created="Wed, 20 Nov 2013 22:54:52 +0000"  >&lt;p&gt;We noticed that the changes in jira caused client side deployment of Tez to have errors. &lt;br/&gt;
Tez is designed to have a client side install. So we package Tez and its dependencies and upload that onto HDFS and those jars are used to run Tez job. Tez brings in mapreduce-client-core.jar as a dependency for InputFormats etc.&lt;br/&gt;
When we build Tez against trunk then the mapreduce-client-core.jar that we bring in uses DeprecatedDelta added in that jar. However, the Configuration in the cluster comes from the cluster deployed jars for hadoop common and that does not have DeprecationDelta. So the execution fails.&lt;br/&gt;
This basically means that if someone compiles MR from trunk and runs MR against a cluster deployed with 2.2 then MR will not work.&lt;/p&gt;</comment>
                            <comment id="13828313" author="cmccabe" created="Wed, 20 Nov 2013 23:52:30 +0000"  >&lt;p&gt;We have never supported mixing and matching jars from trunk with jars from other branches.  For example, you can&apos;t compile the trunk version of HDFS and run it against the branch-2.1 version of common.  It may happen to work sometimes, but it will never be a supported configuration.  I don&apos;t see why Tez would be any different here.&lt;/p&gt;

&lt;p&gt;If you do want to mix and match in the Tez project, I suggest using Maven-shade to include the hadoop-common jar inside the client-side Tez jar.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12610430" name="HADOOP-9478.001.patch" size="22363" author="cmccabe" created="Sat, 26 Oct 2013 02:09:25 +0000"/>
                            <attachment id="12611455" name="HADOOP-9478.002.patch" size="31263" author="cmccabe" created="Thu, 31 Oct 2013 19:10:14 +0000"/>
                            <attachment id="12611473" name="HADOOP-9478.003.patch" size="88542" author="cmccabe" created="Thu, 31 Oct 2013 20:31:17 +0000"/>
                            <attachment id="12611680" name="HADOOP-9478.004.patch" size="92189" author="cmccabe" created="Fri, 1 Nov 2013 20:30:07 +0000"/>
                            <attachment id="12611748" name="HADOOP-9478.005.patch" size="92371" author="cmccabe" created="Sat, 2 Nov 2013 07:26:39 +0000"/>
                            <attachment id="12609532" name="hadoop-9478-1.patch" size="1465" author="andrew.wang" created="Mon, 21 Oct 2013 21:35:11 +0000"/>
                            <attachment id="12609731" name="hadoop-9478-2.patch" size="7265" author="andrew.wang" created="Tue, 22 Oct 2013 21:48:12 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>7.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>323125</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1jqzz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>323470</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12325048">2.2.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>