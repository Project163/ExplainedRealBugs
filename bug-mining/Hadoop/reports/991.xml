<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:43:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-10012] Secure Oozie jobs fail with delegation token renewal exception in Namenode HA setup</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10012</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description></description>
                <environment></environment>
        <key id="12671649">HADOOP-10012</key>
            <summary>Secure Oozie jobs fail with delegation token renewal exception in Namenode HA setup</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sureshms">Suresh Srinivas</assignee>
                                    <reporter username="arpitgupta">Arpit Gupta</reporter>
                        <labels>
                    </labels>
                <created>Tue, 1 Oct 2013 20:02:43 +0000</created>
                <updated>Tue, 30 Jun 2015 07:11:21 +0000</updated>
                            <resolved>Wed, 2 Oct 2013 04:22:18 +0000</resolved>
                                    <version>2.1.1-beta</version>
                                    <fixVersion>2.2.0</fixVersion>
                                    <component>ha</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="13783277" author="arpitgupta" created="Tue, 1 Oct 2013 20:03:23 +0000"  >&lt;p&gt;Here is hte stack trace&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2013-08-29 20:07:05,773 INFO  resourcemanager.ClientRMService (ClientRMService.java:getNewApplicationId(206)) - Allocated &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; applicationId: 8
2013-08-29 20:07:06,713 WARN  token.Token (Token.java:getRenewer(352)) - No TokenRenewer defined &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; token kind Localizer
2013-08-29 20:07:06,731 ERROR security.UserGroupInformation (UserGroupInformation.java:doAs(1480)) - PriviledgedActionException as:rm/hostname&quot;:8020;
2013-08-29 20:07:06,731 WARN  resourcemanager.RMAppManager (RMAppManager.java:submitApplication(297)) - Unable to add the application to the delegation token renewer.
java.io.IOException: Failed on local exception: java.io.EOFException; Host Details : local host is: &lt;span class=&quot;code-quote&quot;&gt;&quot;hostname&quot;&lt;/span&gt;:8020;
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
        at org.apache.hadoop.ipc.Client.call(Client.java:1351)
        at org.apache.hadoop.ipc.Client.call(Client.java:1300)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at $Proxy9.renewDelegationToken(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:188)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at $Proxy9.renewDelegationToken(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewDelegationToken(ClientNamenodeProtocolTranslatorPB.java:820)
        at org.apache.hadoop.hdfs.DFSClient$Renewer.renew(DFSClient.java:932)
        at org.apache.hadoop.security.token.Token.renew(Token.java:372)
        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:385)
        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$1.run(DelegationTokenRenewer.java:382)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.renewToken(DelegationTokenRenewer.java:381)
        at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.addApplication(DelegationTokenRenewer.java:301)
        at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.submitApplication(RMAppManager.java:291)
        at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.submitApplication(ClientRMService.java:315)
        at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.submitApplication(ApplicationClientProtocolPBServiceImpl.java:163)
        at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:243)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2048)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2042)
Caused by: java.io.EOFException
        at java.io.DataInputStream.readInt(DataInputStream.java:375)
        at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:995)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:891)
2013-08-29 20:07:06,733 INFO  rmapp.RMAppImpl (RMAppImpl.java:handle(565)) - application_1377802472892_0008 State change from NEW to FAILED
2013-08-29 20:07:06,734 WARN  resourcemanager.RMAuditLogger (RMAuditLogger.java:logFailure(255)) - USER=hrt_qa  OPERATION=Application Finished - Failed TARGET=RMAppManager     RESULT=FAILURE  DESCRIPTION=App failed with state: FAILED       PERMISSIONS=Failed on local exception: java.io.EOFException; Host Details : local host is: &lt;span class=&quot;code-quote&quot;&gt;&quot;hostname&quot;&lt;/span&gt;:8020;         APPID=application_1377802472892_0008
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13783293" author="sureshms" created="Tue, 1 Oct 2013 20:16:35 +0000"  >&lt;p&gt;In DFSClient, we clone the delegation token associated with logical service name to two physical addresses corresponding to the active and standby namenode addresse. In Oozie job, when the oozie job launcher submits a jobs to the YARN RM, the RM tries to renew the delegation tokens including the cloned tokens. The standby namenode does not allow token renewal. This results in Token renewal failure at the RM and subsequent failure of job submitted by Oozie.&lt;/p&gt;</comment>
                            <comment id="13783294" author="vinodkv" created="Tue, 1 Oct 2013 20:16:35 +0000"  >&lt;p&gt;Tx for filing this Arpit. I&apos;d like to also credit &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=venkatnrangan&quot; class=&quot;user-hover&quot; rel=&quot;venkatnrangan&quot;&gt;venkatnrangan&lt;/a&gt; for his extensive debugging to figure out the underlying issue.&lt;/p&gt;

&lt;p&gt;What&apos;s happening here is that&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;In the oozie&apos;s launcher job, before we create a job-client, Cluster.java creates a file-system object which eventually invokes DFS HAUtils code that clones the single delegation token with logical URI as service-name into multiple tokens with the ip-addresses&lt;/li&gt;
	&lt;li&gt;Once the UGI is &apos;polluted&apos; with these duplicate tokens, JobClient uses the tokens from UGI to submit to RM which eventually fails to renew these &apos;fake&apos; tokens as it cannot reach the stand-by NN for renewal&lt;/li&gt;
	&lt;li&gt;The failure to renew tokens fails the job.&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13783295" author="vinodkv" created="Tue, 1 Oct 2013 20:17:12 +0000"  >&lt;p&gt;Hehe, race conditions for comments.&lt;/p&gt;

&lt;p&gt;I think we should get this fixed for 2.1.2.&lt;/p&gt;</comment>
                            <comment id="13783331" author="sureshms" created="Tue, 1 Oct 2013 20:54:54 +0000"  >&lt;p&gt;Here is a patch that @Daryn had given me. I have added unit tests to his code. The patch adds a new subclass type for cloned tokens called PrivateToken. Such tokens are not returned in UserGroupInformation#getCredentials() method.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=venkatnrangan&quot; class=&quot;user-hover&quot; rel=&quot;venkatnrangan&quot;&gt;venkatnrangan&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vinodkv&quot; class=&quot;user-hover&quot; rel=&quot;vinodkv&quot;&gt;vinodkv&lt;/a&gt; spent long hours debugging this issue. Also &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=venkatnrangan&quot; class=&quot;user-hover&quot; rel=&quot;venkatnrangan&quot;&gt;venkatnrangan&lt;/a&gt; helped in verifying that this patch worked. Thanks guys for the help.&lt;/p&gt;</comment>
                            <comment id="13783439" author="sanjay.radia" created="Tue, 1 Oct 2013 22:44:36 +0000"  >&lt;p&gt;I am little bit worried about the key name in the map &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;Text alias = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Text(HA_DT_SERVICE_PREFIX + &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-comment&quot;&gt;//&quot;&lt;/span&gt; + specificToken.getService());
&lt;/span&gt; ugi.addToken(alias, specificToken);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The original code added it using the unchanged service name.&lt;/p&gt;</comment>
                            <comment id="13783455" author="sanjay.radia" created="Tue, 1 Oct 2013 23:07:54 +0000"  >&lt;p&gt;Turns out the key name in the map is not used to lookup a token when connecting to a service. Instead the token selector grabs all tokens and uses the service name &lt;b&gt;inside&lt;/b&gt; the token:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Token&amp;lt;? &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; TokenIdentifier&amp;gt; token : tokens) {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (kindName.equals(token.getKind())
          &amp;amp;&amp;amp; service.equals(token.getService())) {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; (Token&amp;lt;TokenIdent&amp;gt;) token;
      }
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;I think changing the key in the map should be okay.&lt;br/&gt;
Daryn added this for debugging assistance - quote from IM:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I figured it should have a unique name just in case, for some reason, the client really did have a token for the physical service.  Plus to simplify debugging if something goes awry again.&lt;br/&gt;
it won&apos;t break anything, because nothing really looks for a token by its key other than some mr/yarn stuff (grumble)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt; +1 for the patch.&lt;/p&gt;

&lt;p&gt;Todd/Atm - didn&apos;t you run into this bug with CDH4 and CDH5 (even though CDH ships MR1, wouldn&apos;t it run into the same issue?)&lt;/p&gt;</comment>
                            <comment id="13783487" author="sureshms" created="Tue, 1 Oct 2013 23:44:59 +0000"  >&lt;p&gt;Attached patch removes unnecessary code change in TestDelegationToken.java.&lt;/p&gt;</comment>
                            <comment id="13783596" author="hadoopqa" created="Wed, 2 Oct 2013 03:11:25 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12606225/HADOOP-10012.1.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12606225/HADOOP-10012.1.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3156//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3156//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/3156//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/3156//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13783625" author="hudson" created="Wed, 2 Oct 2013 04:08:55 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #4512 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/4512/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/4512/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10012&quot; title=&quot;Secure Oozie jobs fail with delegation token renewal exception in Namenode HA setup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10012&quot;&gt;&lt;del&gt;HADOOP-10012&lt;/del&gt;&lt;/a&gt;. Secure Oozie jobs fail with delegation token renewal exception in Namenode HA setup. Contributed by Daryn Sharp and Suresh Srinivas. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528301&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528301&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/Token.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestUserGroupInformation.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13783637" author="sureshms" created="Wed, 2 Oct 2013 04:22:18 +0000"  >&lt;p&gt;I committed the patch to 2.1.2, branch-2 and trunk.&lt;/p&gt;

&lt;p&gt;Thank you Daryn for the initial patch. Thank you Sanjay for the review.&lt;/p&gt;</comment>
                            <comment id="13783817" author="hudson" created="Wed, 2 Oct 2013 11:00:48 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #350 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/350/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/350/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10012&quot; title=&quot;Secure Oozie jobs fail with delegation token renewal exception in Namenode HA setup&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10012&quot;&gt;&lt;del&gt;HADOOP-10012&lt;/del&gt;&lt;/a&gt;. Secure Oozie jobs fail with delegation token renewal exception in Namenode HA setup. Contributed by Daryn Sharp and Suresh Srinivas. (suresh: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528301&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1528301&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/token/Token.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestUserGroupInformation.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/HAUtil.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13895938" author="shivram" created="Sun, 9 Feb 2014 17:50:24 +0000"  >&lt;p&gt;We had a similar issue with Hadoop 2.0.5-alpha when launching a hive action from Oozie (fixed on applying the patch posted in this jira).&lt;/p&gt;

&lt;p&gt;Below is the stack trace&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.io.IOException: org.apache.hadoop.ipc.RemoteException(java.io.IOException): Delegation Token can be issued only with kerberos or web authentication
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:5293)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:382)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:841)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:43521)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1014)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1741)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1737)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1478)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1735)

    at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:544)
    at org.apache.hadoop.hive.ql.exec.MapredLocalTask.startForward(MapredLocalTask.java:329)
    at org.apache.hadoop.hive.ql.exec.MapredLocalTask.executeFromChildJVM(MapredLocalTask.java:287)
    at org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:676)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): Delegation Token can be issued only with kerberos or web authentication
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:5293)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:382)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:841)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:43521)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1014)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1741)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1737)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1478)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1735)

    at org.apache.hadoop.ipc.Client.call(Client.java:1235)
    at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:202)
    at com.sun.proxy.$Proxy15.getDelegationToken(Unknown Source)
    at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getDelegationToken(ClientNamenodeProtocolTranslatorPB.java:821)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:164)
    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:83)
    at com.sun.proxy.$Proxy16.getDelegationToken(Unknown Source)
    at org.apache.hadoop.hdfs.DFSClient.getDelegationToken(DFSClient.java:756)
    at org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken(DistributedFileSystem.java:859)
    at org.apache.hadoop.fs.FileSystem.collectDelegationTokens(FileSystem.java:476)
    at org.apache.hadoop.fs.FileSystem.addDelegationTokens(FileSystem.java:454)
    at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:121)
    at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:100)
    at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:80)
    at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:187)
    at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:251)
    at org.apache.hadoop.hive.ql.exec.FetchOperator.getRecordReader(FetchOperator.java:380)
    at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:508)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Why wouldn&apos;t the same sequence of actions in the Resource Manager (invocation of DFS HAUtils code to clone the tokens) be invoked in other use cases ?&lt;br/&gt;
The above issue doesn&apos;t surface when we invoke either a mapreduce or a pig action through Oozie.&lt;/p&gt;</comment>
                            <comment id="13895942" author="shivram" created="Sun, 9 Feb 2014 17:56:26 +0000"  >&lt;p&gt;Once we (&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bhooshan&quot; class=&quot;user-hover&quot; rel=&quot;bhooshan&quot;&gt;bhooshan&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sumedh&quot; class=&quot;user-hover&quot; rel=&quot;sumedh&quot;&gt;sumedh&lt;/a&gt;) remove the patch we get the below stack trace&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.io.IOException: Failed to run job : Operation category WRITE is not supported in state standby
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1411)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:859)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewDelegationToken(FSNamesystem.java:5333)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewDelegationToken(NameNodeRpcServer.java:388)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:859)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:43523)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1014)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1741)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1737)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1478)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1735)

	at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:307)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:395)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1218)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1215)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1478)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1215)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:568)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:563)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1478)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:563)
	at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:447)
	at org.apache.hadoop.hive.ql.exec.MapRedTask.execute(MapRedTask.java:138)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:144)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:57)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1355)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1139)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:945)
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:259)
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:216)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:413)
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:348)
	at org.apache.hadoop.hive.cli.CliDriver.processReader(CliDriver.java:446)
	at org.apache.hadoop.hive.cli.CliDriver.processFile(CliDriver.java:456)
	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:712)
	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:614)
	at org.apache.oozie.action.hadoop.HiveMain.runHive(HiveMain.java:261)
	at org.apache.oozie.action.hadoop.HiveMain.run(HiveMain.java:238)
	at org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:37)
	at org.apache.oozie.action.hadoop.HiveMain.main(HiveMain.java:49)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:491)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:429)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1478)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
Job Submission failed with exception &apos;java.io.IOException(Failed to run job : Operation category WRITE is not supported in state standby
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1411)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:859)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewDelegationToken(FSNamesystem.java:5333)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewDelegationToken(NameNodeRpcServer.java:388)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:859)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:43523)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:454)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1014)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1741)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1737)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1478)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1735)
)&apos;
FAILED: Execution Error, &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; code 1 from org.apache.hadoop.hive.ql.exec.MapRedTask
Intercepting &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.exit(1)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The above error (though related to failover), occurs when issuing the oozie hive action.&lt;/p&gt;</comment>
                            <comment id="14607629" author="vinodkv" created="Tue, 30 Jun 2015 07:11:21 +0000"  >&lt;p&gt;Closing old tickets that are already shipped in a release.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                            <attachment id="12606225" name="HADOOP-10012.1.patch" size="9957" author="sureshms" created="Tue, 1 Oct 2013 23:44:59 +0000"/>
                            <attachment id="12606195" name="HADOOP-10012.patch" size="12947" author="sureshms" created="Tue, 1 Oct 2013 20:54:54 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>351359</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 21 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1okx3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>351651</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12325048">2.2.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>