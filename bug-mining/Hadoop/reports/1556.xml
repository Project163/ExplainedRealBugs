<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:47:57 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-11802] DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-11802</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;In &lt;tt&gt;DataXceiver#requestShortCircuitShm&lt;/tt&gt;, we attempt to recover from some errors by closing the &lt;tt&gt;DomainSocket&lt;/tt&gt;.  However, this violates the invariant that the domain socket should never be closed when it is being managed by the &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt;.  Instead, we should call &lt;tt&gt;shutdown&lt;/tt&gt; on the &lt;tt&gt;DomainSocket&lt;/tt&gt;.  When this bug hits, it terminates the &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; thread.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12788036">HADOOP-11802</key>
            <summary>DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cmccabe">Colin McCabe</assignee>
                                    <reporter username="epayne">Eric Payne</reporter>
                        <labels>
                            <label>2.6.1-candidate</label>
                    </labels>
                <created>Fri, 3 Apr 2015 16:33:39 +0000</created>
                <updated>Mon, 14 Oct 2019 15:37:33 +0000</updated>
                            <resolved>Fri, 24 Apr 2015 02:10:17 +0000</resolved>
                                    <version>2.7.0</version>
                                    <fixVersion>2.6.1</fixVersion>
                    <fixVersion>2.8.0</fixVersion>
                    <fixVersion>2.7.1</fixVersion>
                    <fixVersion>3.0.0-alpha1</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>12</watches>
                                                                                                                <comments>
                            <comment id="14394675" author="eepayne" created="Fri, 3 Apr 2015 16:48:43 +0000"  >&lt;p&gt;In the main finally block of the &lt;tt&gt;DomainSocketWatcher#watcherThread&lt;/tt&gt;, the call to &lt;tt&gt;sendCallback&lt;/tt&gt; can encounter an &lt;tt&gt;IllegalStateException&lt;/tt&gt;, and leave some cleanup tasks undone.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
        lock.lock();
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
          kick(); &lt;span class=&quot;code-comment&quot;&gt;// allow the handler &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; notificationSockets[0] to read a &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;
&lt;/span&gt;          &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (Entry entry : entries.values()) {
            &lt;span class=&quot;code-comment&quot;&gt;// We &lt;span class=&quot;code-keyword&quot;&gt;do&lt;/span&gt; not remove from entries as we iterate, because that can
&lt;/span&gt;            &lt;span class=&quot;code-comment&quot;&gt;// cause a ConcurrentModificationException.
&lt;/span&gt;            sendCallback(&lt;span class=&quot;code-quote&quot;&gt;&quot;close&quot;&lt;/span&gt;, entries, fdSet, entry.getDomainSocket().fd);
          }
          entries.clear();
          fdSet.close();
        } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
          lock.unlock();
        }
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The exception causes &lt;tt&gt;watcherThread&lt;/tt&gt; to skip the calls to &lt;tt&gt;entries.clear()&lt;/tt&gt; and &lt;tt&gt;fdSet.close()&lt;/tt&gt;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;2015-04-02 11:48:09,941 [DataXceiver &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; client unix:/home/gs/&lt;span class=&quot;code-keyword&quot;&gt;var&lt;/span&gt;/run/hdfs/dn_socket [Waiting &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; operation #1]] INFO DataNode.clienttrace: cliID: DFSClient_NONMAPREDUCE_-807148576_1, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: n/a, srvID: e6b6cdd7-1bf8-415f-a412-32d8493554df, success: &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
2015-04-02 11:48:09,941 [&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-14] ERROR unix.DomainSocketWatcher: &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;[&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;-14,5,main] terminating on unexpected exception
java.lang.IllegalStateException: failed to remove b845649551b6b1eab5c17f630e42489d
        at com.google.common.base.Preconditions.checkState(Preconditions.java:145)
        at org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.removeShm(ShortCircuitRegistry.java:119)
        at org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry$RegisteredShm.handle(ShortCircuitRegistry.java:102)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.sendCallback(DomainSocketWatcher.java:402)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$1100(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:522)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:722)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Please note that this is not a duplicate of &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11333&quot; title=&quot;Fix deadlock in DomainSocketWatcher when the notification pipe is full&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11333&quot;&gt;&lt;del&gt;HADOOP-11333&lt;/del&gt;&lt;/a&gt;, &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11604&quot; title=&quot;Prevent ConcurrentModificationException while closing domain sockets during shutdown of DomainSocketWatcher thread.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11604&quot;&gt;&lt;del&gt;HADOOP-11604&lt;/del&gt;&lt;/a&gt;, or &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10404&quot; title=&quot;Some accesses to DomainSocketWatcher#closed are not protected by lock&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10404&quot;&gt;&lt;del&gt;HADOOP-10404&lt;/del&gt;&lt;/a&gt;. The cluster installation is running code with all of these fixes.&lt;/p&gt;

&lt;p&gt;The place in &lt;tt&gt;sendCallback&lt;/tt&gt; where it is encountering the exception is&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (entry.getHandler().handle(sock)) {
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the &lt;tt&gt;IllegalStateException&lt;/tt&gt; occurs, I am seeing 4069 datanode threads getting stuck in &lt;tt&gt;DomainSocketWatcher#add&lt;/tt&gt; when &lt;tt&gt;DataXceiver&lt;/tt&gt; is trying to request a new short circuit read. This is similar to the symptoms seen in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11333&quot; title=&quot;Fix deadlock in DomainSocketWatcher when the notification pipe is full&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11333&quot;&gt;&lt;del&gt;HADOOP-11333&lt;/del&gt;&lt;/a&gt;, but, as I mentioned above, the cluster is already running with that fix.&lt;/p&gt;

&lt;p&gt;Here is the stack trace from the stuck threads, for reference:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&quot;DataXceiver for client unix:/home/gs/var/run/hdfs/dn_socket [Waiting for operat
ion #1]&quot; daemon prio=10 tid=0x00007fcbbcae1000 nid=0x498a waiting on condition [
0x00007fcb61132000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  &amp;lt;0x00000000d06c3a78&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.add(DomainSocketWatcher.java:323)
        at org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.createNewMemorySegment(ShortCircuitRegistry.java:322)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.requestShortCircuitShm(DataXceiver.java:403)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opRequestShortCircuitShm(Receiver.java:214)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:95)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:235)
        at java.lang.Thread.run(Thread.java:722)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14484509" author="cmccabe" created="Wed, 8 Apr 2015 01:23:37 +0000"  >&lt;p&gt;Hi Eric,&lt;/p&gt;

&lt;p&gt;You should never be in &quot;the main finally block&quot; of DomainSocketWatcher unless you are in a unit test.  If you are in this finally block in the actual DataNode, something is wrong.  You should see a string like &quot;terminating on InterruptedException&quot; or &quot;terminating on IOException&quot; explaining why you ended up in this finally block in the first place.  This should be the root cause.  Do you have a log line like that?&lt;/p&gt;</comment>
                            <comment id="14485289" author="eepayne" created="Wed, 8 Apr 2015 14:21:37 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;cmccabe&lt;/a&gt; for your comment and interest in this issue.&lt;/p&gt;

&lt;p&gt;This problem is happening in multiple different live clusters. Only a small percentage of datanodes are affected each day, but once they hit this and the threads pile up, the datanodes must be restarted.&lt;/p&gt;

&lt;p&gt;The only &apos;terminating on&apos; message in the DN log is coming from DomainSocketWatchers unhandled exception handler. That is, it&apos;s the one documented in the description above:&lt;/p&gt;
&lt;blockquote&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2015-04-04 13:12:31,059 [Thread-12] ERROR unix.DomainSocketWatcher: Thread[Thread-12,5,main] terminating on unexpected exception
java.lang.IllegalStateException: failed to remove 17e33191fa8238098d7d22142f5787e2
2015-04-02 11:48:09,941 [DataXceiver for client unix:/home/gs/var/run/hdfs/dn_socket [Waiting for operation #1]] INFO DataNode.clienttrace: cliID: DFSClient_NONMAPREDUCE_-807148576_1, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: n/a, srvID: e6b6cdd7-1bf8-415f-a412-32d8493554df, success: false
2015-04-02 11:48:09,941 [Thread-14] ERROR unix.DomainSocketWatcher: Thread[Thread-14,5,main] terminating on unexpected exception
java.lang.IllegalStateException: failed to remove b845649551b6b1eab5c17f630e42489d
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;However, as you pointed out, that is happening after something went wrong in the main try block of the watcher thread. Since I&apos;m seeing neither &apos;terminating on InterruptedException&apos; nor &apos;terminating on IOException&apos;, there must be some other exception occurring. However, the only reference in the DN log of &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; is in the stack trace already mentioned.&lt;/p&gt;

&lt;p&gt;However, just above the IllegalStateException stacktrace is the following that indicated a premature EOF occurred. There were several of these, but it&apos;s not clear that they are related to the reason why the DomainSocketWatcher exited.&lt;br/&gt;
Your input would be greatly appreciated.&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2015-04-02 11:48:09,885 [DataXceiver for client DFSClient_attempt_1427231924849_569467_m_000135_0_346288762_1 at /xxx.xxx.xxx.xxx:41908 [Receiving block BP-658831282-xxx.xxx.xxx.xxx-1351509219914:blk_3365919992_1105804585360]] ERROR datanode.DataNode: gsta70851.tan.ygrid.yahoo.com:1004:DataXceiver error processing WRITE_BLOCK operation  src: /xxx.xxx.xxx.xxx:41908 dst: /xxx.xxx.xxx.xxx:1004
java.io.IOException: Premature EOF from inputStream
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:194)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:213)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:467)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:781)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:730)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:137)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:74)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:235)
        at java.lang.Thread.run(Thread.java:722)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14485380" author="eepayne" created="Wed, 8 Apr 2015 15:24:47 +0000"  >&lt;p&gt;Sorry, I just noticed that the following was the first exception in the series:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2015-04-02 11:48:09,866 [DataXceiver for client unix:/home/gs/var/run/hdfs/dn_socket [Waiting for operation #1]] ERROR datanode.DataNode: gsta70851.tan.ygrid.yahoo.com:1004:DataXceiver error processing REQUEST_SHORT_CIRCUIT_SHM operation  src: unix:/home/gs/var/run/hdfs/dn_socket dst: &amp;lt;local&amp;gt;
java.net.SocketException: write(2) error: Broken pipe
        at org.apache.hadoop.net.unix.DomainSocket.writeArray0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocket.access$300(DomainSocket.java:45)
        at org.apache.hadoop.net.unix.DomainSocket$DomainOutputStream.write(DomainSocket.java:601)
        at com.google.protobuf.CodedOutputStream.refreshBuffer(CodedOutputStream.java:833)
        at com.google.protobuf.CodedOutputStream.flush(CodedOutputStream.java:843)
        at com.google.protobuf.AbstractMessageLite.writeDelimitedTo(AbstractMessageLite.java:91)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.sendShmSuccessResponse(DataXceiver.java:380)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.requestShortCircuitShm(DataXceiver.java:418)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opRequestShortCircuitShm(Receiver.java:214)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:95)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:235)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="14486133" author="cmccabe" created="Wed, 8 Apr 2015 21:48:50 +0000"  >&lt;p&gt;It&apos;s clear to me that the proximate cause of the &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; thread exiting on the &lt;tt&gt;DataNode&lt;/tt&gt; is that it tried to remove a shared memory segment ID that was not registered.  But if I&apos;m reading these stack traces right, the attempted removal is happening in the finally block-- a place where we should never actually be, except in unit tests.  That means  that there was another exception that triggered this whole problem.  Without knowing what that root cause is, I don&apos;t think we can get any farther on this.&lt;/p&gt;

&lt;p&gt;I suggest adding another catch block here: &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;        doPoll0(interruptCheckPeriodMs, fdSet);
        }
      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (InterruptedException e) {
        LOG.info(toString() + &lt;span class=&quot;code-quote&quot;&gt;&quot; terminating on InterruptedException&quot;&lt;/span&gt;);
      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
        LOG.error(toString() + &lt;span class=&quot;code-quote&quot;&gt;&quot; terminating on IOException&quot;&lt;/span&gt;, e);
      } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
        lock.lock();
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If we had a catch block catching &lt;tt&gt;RuntimeException&lt;/tt&gt; and printing it out, that might give you the true root cause.&lt;/p&gt;</comment>
                            <comment id="14486155" author="cmccabe" created="Wed, 8 Apr 2015 22:00:04 +0000"  >&lt;p&gt;I thought about this a little bit more, and I wonder whether this finally block inside requestShortCircuitShm is causing a &quot;double removal&quot;:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void requestShortCircuitShm(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; clientName) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {                                             
    NewShmInfo shmInfo = &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;                                                                                           
    &lt;span class=&quot;code-object&quot;&gt;boolean&lt;/span&gt; success = &lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;;                                                                                             
    DomainSocket sock = peer.getDomainSocket();                                                                          
    &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {                                                                                                                
...
    } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {                                                                                                          
...
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((!success) &amp;amp;&amp;amp; (peer == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)) {
        &lt;span class=&quot;code-comment&quot;&gt;// If we failed to pass the shared memory segment to the client,                                                 
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// close the UNIX domain socket now.  This will trigger the                                                      
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// DomainSocketWatcher callback, cleaning up the segment.                                                        
&lt;/span&gt;        IOUtils.cleanup(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, sock);                                                                                     
      }
      IOUtils.cleanup(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, shmInfo);                                                                                    
    }                                                                                                                    
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Closing the socket will remove that shmID, but so will closing the NewShmInfo object... let me look into this.&lt;/p&gt;

&lt;p&gt;edit: NewShmInfo#close just closes the shared memory segment, but not the domain socket.  Since DomainSocketWatcher is watching the domain socket rather than the shm fd, doing both close operations should not be a problem.  So I would still recommend adding the catch block and seeing what that tells us.&lt;/p&gt;</comment>
                            <comment id="14493182" author="eepayne" created="Mon, 13 Apr 2015 22:10:29 +0000"  >&lt;p&gt;Thanks again, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;cmccabe&lt;/a&gt;, for your comments and taking time on this issue.&lt;/p&gt;

&lt;p&gt;One thing to note is that just prior to these problems, a 195-second GC was taking place on the DN.&lt;/p&gt;

&lt;p&gt;I added a catch of &lt;tt&gt;Throwable&lt;/tt&gt; in the main thread of the &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; and reproduced the problem. AFAICT, the following represents what is happening:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Request for short circuit read is received&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;DataXceiver#requestShortCircuitShm&lt;/tt&gt; calls &lt;tt&gt;ShortCircuitRegistry#createNewMemorySegment&lt;/tt&gt;, which creates a shared memory segment and associates it with the passed domain socket in the &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt;. Then, in that thread, &lt;tt&gt;createNewMemorySegment&lt;/tt&gt; waits on that socket/shm entry in &lt;tt&gt;DomainSocketWatcher#add&lt;/tt&gt;.
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; NewShmInfo createNewMemorySegment(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; clientName,
...
    watcher.add(sock, shm);
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;It&apos;s at this point that things get confusing, and I&apos;m still working on why this happens. The wait wakes up, but things are not normal, but it wasn&apos;t woken up because of an exception, either. You can tell that no exception was thrown inside &lt;tt&gt;createNewMemorySegment&lt;/tt&gt; to wake it up because the following code goes on to call &lt;tt&gt;sendShmSuccessRespons&lt;/tt&gt;, which is where the next bad thing happens:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void requestShortCircuitShm(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; clientName) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
...
      &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
        shmInfo = datanode.shortCircuitRegistry.
            createNewMemorySegment(clientName, sock);
        &lt;span class=&quot;code-comment&quot;&gt;// After calling #{ShortCircuitRegistry#createNewMemorySegment}, the
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// socket is managed by the DomainSocketWatcher, not the DataXceiver.
&lt;/span&gt;        releaseSocket();
      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (UnsupportedOperationException e) {
        sendShmErrorResponse(ERROR_UNSUPPORTED, 
            &lt;span class=&quot;code-quote&quot;&gt;&quot;This datanode has not been configured to support &quot;&lt;/span&gt; +
            &lt;span class=&quot;code-quote&quot;&gt;&quot;&lt;span class=&quot;code-object&quot;&gt;short&lt;/span&gt;-circuit shared memory segments.&quot;&lt;/span&gt;);
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
        sendShmErrorResponse(ERROR,
            &lt;span class=&quot;code-quote&quot;&gt;&quot;Failed to create shared file descriptor: &quot;&lt;/span&gt; + e.getMessage());
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
      }
      sendShmSuccessResponse(sock, shmInfo);
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;At this point, the call to &lt;tt&gt;sendShmSuccessResponse&lt;/tt&gt; gets an exception:
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;2015-04-04 13:12:30,973 [DataXceiver for client unix:/home/gs/var/run/hdfs/dn_socket [Waiting for operation #1]]
      INFO DataNode.clienttrace: cliID: DFSClient_attempt_1427231924849_569269_m_002116_0_-161414780_1,
      src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: n/a,
      srvID: a2d3bac0-e98b-4b73-a5a1-82c7eb557a7a, success: false
2015-04-04 13:12:30,984 [DataXceiver for client unix:/home/gs/var/run/hdfs/dn_socket [Waiting for operation #1]]
      ERROR datanode.DataNode: host.domain.com:1004:DataXceiver error processing
      REQUEST_SHORT_CIRCUIT_SHM operation  src: unix:/home/gs/var/run/hdfs/dn_socket dst: &amp;lt;local&amp;gt;
     
java.net.SocketException: write(2) error: Broken pipe
        at org.apache.hadoop.net.unix.DomainSocket.writeArray0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocket.access$300(DomainSocket.java:45)
        at org.apache.hadoop.net.unix.DomainSocket$DomainOutputStream.write(DomainSocket.java:601)
        at com.google.protobuf.CodedOutputStream.refreshBuffer(CodedOutputStream.java:833)
        at com.google.protobuf.CodedOutputStream.flush(CodedOutputStream.java:843)
        at com.google.protobuf.AbstractMessageLite.writeDelimitedTo(AbstractMessageLite.java:91)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.sendShmSuccessResponse(DataXceiver.java:380)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.requestShortCircuitShm(DataXceiver.java:418)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opRequestShortCircuitShm(Receiver.java:214)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:95)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:235)
        at java.lang.Thread.run(Thread.java:722)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;At this point, it bubbles back up to &lt;tt&gt;DataXceiver#requestShortCircuitShm&lt;/tt&gt;, which cleans up, closing the socket:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;...
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((!success) &amp;amp;&amp;amp; (peer == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)) {
        &lt;span class=&quot;code-comment&quot;&gt;// If we failed to pass the shared memory segment to the client,
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// close the UNIX domain socket now.  This will trigger the 
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// DomainSocketWatcher callback, cleaning up the segment.
&lt;/span&gt;        IOUtils.cleanup(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, sock);
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
	&lt;li&gt;Then, the main &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; thread wakes up (after regular timeout interval has expired), and tries to call &lt;tt&gt;sendCallbackAndRemove&lt;/tt&gt;, which encounters the following &lt;tt&gt;IllegalArgumentException&lt;/tt&gt;:
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;  &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; watcherThread = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;Runnable&lt;/span&gt;() {
...
        &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;) {
          lock.lock();
          &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
            &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; fd : fdSet.getAndClearReadableFds()) {
              sendCallbackAndRemove(&lt;span class=&quot;code-quote&quot;&gt;&quot;getAndClearReadableFds&quot;&lt;/span&gt;, entries, fdSet,
                  fd);
            }
...
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;ERROR unix.DomainSocketWatcher: org.apache.hadoop.net.unix.DomainSocketWatcher$2@76845081
      terminating on Throwable
java.lang.IllegalArgumentException: DomainSocketWatcher(103231254): file descriptor 249 was closed
      while still in the poll(2) loop.
        at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.sendCallback(DomainSocketWatcher.java:421)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.sendCallbackAndRemove(DomainSocketWatcher.java:448)
        at org.apache.hadoop.net.unix.DomainSocketWatcher.access$500(DomainSocketWatcher.java:52)
        at org.apache.hadoop.net.unix.DomainSocketWatcher$2.run(DomainSocketWatcher.java:470)
        at java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;I welcome your suggestions and look forward to your feedback.&lt;br/&gt;
Thanks,&lt;br/&gt;
Eric&lt;/p&gt;</comment>
                            <comment id="14494364" author="cmccabe" created="Tue, 14 Apr 2015 16:37:07 +0000"  >&lt;p&gt;Thanks for following up, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=epayne&quot; class=&quot;user-hover&quot; rel=&quot;epayne&quot;&gt;epayne&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;java.net.SocketException: write(2) error: Broken pipe
        at org.apache.hadoop.net.unix.DomainSocket.writeArray0(Native Method)
        at org.apache.hadoop.net.unix.DomainSocket.access$300(DomainSocket.java:45)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This error means that the socket was closed by the remote end.  This is not surprising since there was a really long GC, and the client read operation timed out.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Then, the main DomainSocketWatcher thread wakes up (after regular timeout interval has expired), and tries to call sendCallbackAndRemove&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Small correction, &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; is event-triggered rather than timeout triggered.  The only timeout we have is so we can check if someone sent a Java &lt;tt&gt;InterruptedException&lt;/tt&gt;.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;ERROR unix.DomainSocketWatcher: org.apache.hadoop.net.unix.DomainSocketWatcher$2@76845081
      terminating on Throwable
java.lang.IllegalArgumentException: DomainSocketWatcher(103231254): file descriptor 249 was closed
      &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; still in the poll(2) loop.
        at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This is the root cause.  &lt;tt&gt;DomainSocket#close&lt;/tt&gt; is not supposed to be closed while the socket is in the poll(2) loop.  Another file descriptor could be opened and get the same number, which would cause bad behavior.  I can see now that the call to &lt;tt&gt;DomainSocket#close&lt;/tt&gt; in DataXceiver is a mistake.&lt;/p&gt;</comment>
                            <comment id="14495110" author="cmccabe" created="Tue, 14 Apr 2015 23:13:32 +0000"  >&lt;p&gt;version 1 of the patch:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&lt;tt&gt;DataXceiver.java&lt;/tt&gt;: do not close the DomainSocket on an error.  This is bad because the socket might already be getting poll()ed by the thread.  Instead, call &lt;tt&gt;shutdown(RDWR)&lt;/tt&gt; on the socket.&lt;/li&gt;
	&lt;li&gt;Log all &lt;tt&gt;Throwables&lt;/tt&gt; that terminate the &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; thread.  If there is a follow-on error, we don&apos;t want it to obscure the true cause of the problem.&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;DomainSocketWatcher.c&lt;/tt&gt;: look for both &lt;tt&gt;POLLIN&lt;/tt&gt; and &lt;tt&gt;POLLHUP&lt;/tt&gt; events when calling &lt;tt&gt;poll()&lt;/tt&gt;.  Some UNIX variants (although not Linux) return POLLHUP instead of POLLIN when shutdown is called on the socket.&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;BlockReaderFactory.java&lt;/tt&gt;: add a &lt;tt&gt;injectRequestShortCircuitShmFailure&lt;/tt&gt; method to the &lt;tt&gt;BlockReaderFactory#FailureInjector&lt;/tt&gt; class.&lt;/li&gt;
	&lt;li&gt;&lt;tt&gt;TestShortCircuitCache&lt;/tt&gt;: add unit test&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14495153" author="hadoopqa" created="Tue, 14 Apr 2015 23:35:18 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12725419/HADOOP-11802.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12725419/HADOOP-11802.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision fddd552.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;&lt;/font&gt;-1 javac&lt;font color=&quot;red&quot;&gt;&lt;/font&gt;.  The patch appears to cause the build to fail.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6102//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6102//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14495627" author="cmccabe" created="Wed, 15 Apr 2015 04:13:08 +0000"  >&lt;p&gt;fix typo&lt;/p&gt;</comment>
                            <comment id="14495835" author="hadoopqa" created="Wed, 15 Apr 2015 08:04:56 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12725472/HADOOP-11802.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12725472/HADOOP-11802.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision fddd552.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  There were no new javadoc warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6103//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6103//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6103//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6103//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14498828" author="eepayne" created="Thu, 16 Apr 2015 22:05:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;cmccabe&lt;/a&gt;, Thanks very much for the patch.&lt;/p&gt;

&lt;p&gt;I was able to manually verify that the patch fixed the problem we were encountering when &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt;&apos;s main thread was dying. Using the same methods as used previously to generate the exception in &lt;tt&gt;DataXceiver#requestShortCircuitShm&lt;/tt&gt;, I was able to verify that the main thread of &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; remains running.&lt;/p&gt;

&lt;p&gt;However, I don&apos;t think the unit test is verifying this use case. Here&apos;s what I did:&lt;br/&gt;
1. I patched branch-2 with &lt;tt&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11802&quot; title=&quot;DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11802&quot;&gt;&lt;del&gt;HADOOP-11802&lt;/del&gt;&lt;/a&gt;.002.patch&lt;/tt&gt;, built it, and ran the test for &lt;tt&gt;TestShortCircuitCache#testDataXceiverHandlesRequestShortCircuitShmFailure&lt;/tt&gt;. This was successful.&lt;br/&gt;
2. I commented out the following code in &lt;tt&gt;DataXceiver#requestShortCircuitShm&lt;/tt&gt;&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((!success) &amp;amp;&amp;amp; releasedSocket) {
        &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
          sock.shutdown();
        } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
          LOG.warn(&lt;span class=&quot;code-quote&quot;&gt;&quot;Failed to shut down socket in error handler&quot;&lt;/span&gt;, e);
        }
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and replaced it with the original code:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; ((!success) &amp;amp;&amp;amp; (peer == &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;)) {
        IOUtils.cleanup(&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;, sock);
      }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This also succeeded.&lt;/p&gt;</comment>
                            <comment id="14504148" author="cmccabe" created="Tue, 21 Apr 2015 01:54:17 +0000"  >&lt;p&gt;Hi Eric,&lt;/p&gt;

&lt;p&gt;Good catch.  I think the issue here is that there is a lot of buffering in the domain socket.  So it&apos;s difficult to get the DataNode to fail when doing its write on the socket.  In my experience, the write will succeed even when the other end has already shut down the socket.  This buffering can be set by configuring SO_RCVBUF, but even the smallest value still buffers enough that the unit test will pass under every condition.  This buffering is not a problem since in the event of a communication failure, the client will close the socket, triggering the DataNode to free the resources.  However, it does make unit testing by injecting faults on the client side more difficult to do.&lt;/p&gt;

&lt;p&gt;The solution to this problem is to inject the failure directly on the DataNode side.  The latest patch does this.  I have confirmed that it fails without the fix applied.&lt;/p&gt;</comment>
                            <comment id="14504377" author="hadoopqa" created="Tue, 21 Apr 2015 05:43:06 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12726751/HADOOP-11802.003.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12726751/HADOOP-11802.003.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 44872b7.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  There were no new javadoc warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6134//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6134//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6134//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6134//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14507815" author="eepayne" created="Wed, 22 Apr 2015 20:21:34 +0000"  >&lt;p&gt;Thanks for the new patch, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;cmccabe&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I have verified that patch 003 still fixes the problem of the dying &lt;tt&gt;DomainSocketWatcher&lt;/tt&gt; thread in my manual tests. I have also verified that the new unit test fails without the patch and succeeds with it.&lt;/p&gt;

&lt;p&gt;+1 : LGTM&lt;/p&gt;</comment>
                            <comment id="14509569" author="andrew.wang" created="Thu, 23 Apr 2015 18:41:51 +0000"  >&lt;p&gt;Cool patch, only have nit-like stuff. +1 pending, though it is a lot of nits.&lt;/p&gt;

&lt;ul&gt;
	&lt;li&gt;There&apos;s CHANGES.txt included in the patch&lt;/li&gt;
	&lt;li&gt;extra imports in DataXCeiver, though really you probably meant to add the @Private annotation and just forgot.&lt;/li&gt;
	&lt;li&gt;Add a newline in the DSW C file change, break the new POLLHUP check to the next line (like the other if you changed). Adding a link to the webpage reference (along with mentioning portability / Cygwin) would also be nice, since I wondered why we didn&apos;t have to catch yet more poll errors.&lt;/li&gt;
	&lt;li&gt;Typo &quot;repsponse&quot; in DataXceiver&lt;/li&gt;
	&lt;li&gt;We typically have used a singleton to do fault injection, would be good to be consistent since it doesn&apos;t look like we need per-instance injection. See DataNodeFaultInjector, probably the best home.&lt;/li&gt;
	&lt;li&gt;Good fix on the javadoc for allocSlot, but mind adding the blockId param doc too for full coverage?&lt;/li&gt;
	&lt;li&gt;The Throwable catch, it subsumes the IOException catch, so can we just delete it? I think the more specific name of the exception will be printed by its toString.&lt;/li&gt;
	&lt;li&gt;Param indentation in TestSCCache#checkNumberOfSeg... is inconsistent, I think we typically do double indent?&lt;/li&gt;
	&lt;li&gt;TestSCCache, the comment &quot;Remove the failure injector&quot; should be moved up a few lines&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14509652" author="cmccabe" created="Thu, 23 Apr 2015 19:38:04 +0000"  >&lt;blockquote&gt;&lt;p&gt;extra imports in DataXCeiver, though really you probably meant to add the @Private annotation and just forgot.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;fixed&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Add a newline in the DSW C file change, break the new POLLHUP check to the next line (like the other if you changed)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ok&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Adding a link to the webpage reference (along with mentioning portability / Cygwin) would also be nice, since I wondered why we didn&apos;t have to catch yet more poll errors.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I added a comment explaining why POLLHUP&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Typo &quot;repsponse&quot; in DataXceiver&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;fixed&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We typically have used a singleton to do fault injection, would be good to be consistent since it doesn&apos;t look like we need per-instance injection. See DataNodeFaultInjector, probably the best home.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;OK.  That would eliminate the need to make the DataXceiver class public, which would be nice.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Good fix on the javadoc for allocSlot, but mind adding the blockId param doc too for full coverage?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Hey, I&apos;m trying to make incremental changes here &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;  Fixed.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The Throwable catch, it subsumes the IOException catch, so can we just delete it? I think the more specific name of the exception will be printed by its toString.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ok&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Param indentation in TestSCCache#checkNumberOfSeg... is inconsistent, I think we typically do double indent?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;ok&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;TestSCCache, the comment &quot;Remove the failure injector&quot; should be moved up a few lines&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;let me just get rid of that since the log messages says the same thing&lt;/p&gt;</comment>
                            <comment id="14509959" author="andrew.wang" created="Thu, 23 Apr 2015 22:23:22 +0000"  >&lt;p&gt;Thanks Colin, +1 pending Jenkins.&lt;/p&gt;</comment>
                            <comment id="14510095" author="hadoopqa" created="Thu, 23 Apr 2015 23:55:31 +0000"  >&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/error.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;b&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;&lt;/b&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Vote &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Runtime &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Comment &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;blue&quot;&gt;0&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; pre-patch &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  14m 26s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Pre-patch trunk compilation is healthy. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; @author &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The patch does not contain any @author tags. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; tests included &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The patch appears to include 1 new or modified test files. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; whitespace &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The patch has no lines that end in whitespace. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; javac &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   7m 24s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; There were no new javac warning messages. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; javadoc &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   9m 34s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; There were no new javadoc warning messages. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; release audit &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 23s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The applied patch does not increase the total number of release audit warnings. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;red&quot;&gt;-1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; checkstyle &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   5m 29s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The applied patch generated  2  additional checkstyle issues. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; install &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   1m 32s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; mvn install still works. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; eclipse:eclipse &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 32s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The patch built with eclipse:eclipse. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; findbugs &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   4m 46s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; The patch does not introduce any new Findbugs (version 2.0.3) warnings. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; common tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  22m 55s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Tests passed in hadoop-common. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;font color=&quot;green&quot;&gt;+1&lt;/font&gt; &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; hdfs tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 168m  3s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Tests passed in hadoop-hdfs. &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 235m  9s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br class=&quot;atl-forced-newline&quot; /&gt;
&lt;br class=&quot;atl-forced-newline&quot; /&gt;&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Subsystem &lt;/th&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; Report/Notes &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Patch URL &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12727690/HADOOP-11802.004.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12727690/HADOOP-11802.004.patch&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Optional Tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; javadoc javac unit findbugs checkstyle &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; git revision &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; trunk / 416b843 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; checkstyle &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/artifact/patchprocess/checkstyle-result-diff.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/artifact/patchprocess/checkstyle-result-diff.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; hadoop-common test log &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/artifact/patchprocess/testrun_hadoop-common.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/artifact/patchprocess/testrun_hadoop-common.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; hadoop-hdfs test log &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/artifact/patchprocess/testrun_hadoop-hdfs.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/artifact/patchprocess/testrun_hadoop-hdfs.txt&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Test Results &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/testReport/&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Console output &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/6169/console&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;



&lt;p&gt;This message was automatically generated.&lt;/p&gt;</comment>
                            <comment id="14510346" author="cmccabe" created="Fri, 24 Apr 2015 02:07:46 +0000"  >&lt;p&gt;the checkstyle plugin has some known issues right now.  committing to 2.7.1  thanks for the reviews.&lt;/p&gt;</comment>
                            <comment id="14510353" author="hudson" created="Fri, 24 Apr 2015 02:14:44 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-trunk-Commit #7658 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/7658/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/7658/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11802&quot; title=&quot;DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11802&quot;&gt;&lt;del&gt;HADOOP-11802&lt;/del&gt;&lt;/a&gt;. DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm (cmccabe) (cmccabe: rev a0e0a63209b5eb17dca5cc503be36aa52defeabd)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNodeFaultInjector.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocketWatcher.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocketWatcher.c&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14510842" author="hudson" created="Fri, 24 Apr 2015 11:34:59 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #2105 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/2105/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/2105/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11802&quot; title=&quot;DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11802&quot;&gt;&lt;del&gt;HADOOP-11802&lt;/del&gt;&lt;/a&gt;. DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm (cmccabe) (cmccabe: rev a0e0a63209b5eb17dca5cc503be36aa52defeabd)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocketWatcher.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocketWatcher.c&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNodeFaultInjector.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14510859" author="hudson" created="Fri, 24 Apr 2015 11:35:59 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #164 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/164/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/164/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11802&quot; title=&quot;DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11802&quot;&gt;&lt;del&gt;HADOOP-11802&lt;/del&gt;&lt;/a&gt;. DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm (cmccabe) (cmccabe: rev a0e0a63209b5eb17dca5cc503be36aa52defeabd)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocketWatcher.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocketWatcher.c&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNodeFaultInjector.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14510878" author="hudson" created="Fri, 24 Apr 2015 11:37:31 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #173 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/173/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/173/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11802&quot; title=&quot;DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11802&quot;&gt;&lt;del&gt;HADOOP-11802&lt;/del&gt;&lt;/a&gt;. DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm (cmccabe) (cmccabe: rev a0e0a63209b5eb17dca5cc503be36aa52defeabd)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNodeFaultInjector.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocketWatcher.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocketWatcher.c&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14510917" author="hudson" created="Fri, 24 Apr 2015 12:02:19 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Yarn-trunk #907 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/907/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/907/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11802&quot; title=&quot;DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11802&quot;&gt;&lt;del&gt;HADOOP-11802&lt;/del&gt;&lt;/a&gt;. DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm (cmccabe) (cmccabe: rev a0e0a63209b5eb17dca5cc503be36aa52defeabd)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocketWatcher.c&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNodeFaultInjector.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocketWatcher.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14511020" author="hudson" created="Fri, 24 Apr 2015 13:21:38 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #174 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/174/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/174/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11802&quot; title=&quot;DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11802&quot;&gt;&lt;del&gt;HADOOP-11802&lt;/del&gt;&lt;/a&gt;. DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm (cmccabe) (cmccabe: rev a0e0a63209b5eb17dca5cc503be36aa52defeabd)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocketWatcher.c&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocketWatcher.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNodeFaultInjector.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14511059" author="hudson" created="Fri, 24 Apr 2015 13:42:01 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2123 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2123/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2123/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11802&quot; title=&quot;DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11802&quot;&gt;&lt;del&gt;HADOOP-11802&lt;/del&gt;&lt;/a&gt;. DomainSocketWatcher thread terminates sometimes after there is an I/O error during requestShortCircuitShm (cmccabe) (cmccabe: rev a0e0a63209b5eb17dca5cc503be36aa52defeabd)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/net/unix/DomainSocketWatcher.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocketWatcher.c&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataXceiver.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/datanode/DataNodeFaultInjector.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14696282" author="ajisakaa" created="Fri, 14 Aug 2015 01:12:33 +0000"  >&lt;p&gt;If we are going to backport this issue to branch-2.6, we need to backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-7915&quot; title=&quot;The DataNode can sometimes allocate a ShortCircuitShm slot and fail to tell the DFSClient about it because of a network error&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-7915&quot;&gt;&lt;del&gt;HDFS-7915&lt;/del&gt;&lt;/a&gt; before. If we backport these, we should backport &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-8070&quot; title=&quot;Pre-HDFS-7915 DFSClient cannot use short circuit on post-HDFS-7915 DataNode&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-8070&quot;&gt;&lt;del&gt;HDFS-8070&lt;/del&gt;&lt;/a&gt; as well because &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-7915&quot; title=&quot;The DataNode can sometimes allocate a ShortCircuitShm slot and fail to tell the DFSClient about it because of a network error&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-7915&quot;&gt;&lt;del&gt;HDFS-7915&lt;/del&gt;&lt;/a&gt; breaks it.&lt;/p&gt;</comment>
                            <comment id="14696310" author="ajisakaa" created="Fri, 14 Aug 2015 01:40:25 +0000"  >&lt;p&gt;Attaching a patch to backport this issue to branch-2.6.&lt;/p&gt;</comment>
                            <comment id="14728083" author="vinodkv" created="Wed, 2 Sep 2015 21:48:07 +0000"  >&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ajisakaa&quot; class=&quot;user-hover&quot; rel=&quot;ajisakaa&quot;&gt;ajisakaa&lt;/a&gt;. Pulled this into 2.6.1 after running compilation and TestShortCircuitCache.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="12960611">HDFS-10322</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12781074">HDFS-7915</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12725419" name="HADOOP-11802.001.patch" size="21124" author="cmccabe" created="Tue, 14 Apr 2015 23:13:32 +0000"/>
                            <attachment id="12725472" name="HADOOP-11802.002.patch" size="21126" author="cmccabe" created="Wed, 15 Apr 2015 04:13:08 +0000"/>
                            <attachment id="12726751" name="HADOOP-11802.003.patch" size="15552" author="cmccabe" created="Tue, 21 Apr 2015 01:55:50 +0000"/>
                            <attachment id="12727690" name="HADOOP-11802.004.patch" size="13601" author="cmccabe" created="Thu, 23 Apr 2015 19:54:18 +0000"/>
                            <attachment id="12750420" name="HADOOP-11802.branch-2.6.patch" size="13744" author="aajisaka" created="Fri, 14 Aug 2015 01:40:25 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            10 years, 11 weeks, 5 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i27rhj:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12331977">2.7.1</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>