<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:41:26 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-8833] fs -text should make sure to call inputstream.seek(0) before using input stream</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-8833</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;From Muddy Dixon on &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8449&quot; title=&quot;hadoop fs -text fails with compressed sequence files with the codec file extension&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8449&quot;&gt;&lt;del&gt;HADOOP-8449&lt;/del&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;Hi&lt;br/&gt;
We found the changes in order of switch and guard block in&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; InputStream forMagic(Path p, FileSystem srcFs) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Because of this change, return value of&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;codec.createInputStream(i)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is changed if codec exists.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; InputStream forMagic(Path p, FileSystem srcFs) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    FSDataInputStream i = srcFs.open(p);

    &lt;span class=&quot;code-comment&quot;&gt;// check codecs
&lt;/span&gt;    CompressionCodecFactory cf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CompressionCodecFactory(getConf());
    CompressionCodec codec = cf.getCodec(p);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (codec != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; codec.createInputStream(i);
    }

    &lt;span class=&quot;code-keyword&quot;&gt;switch&lt;/span&gt;(i.readShort()) {
       &lt;span class=&quot;code-comment&quot;&gt;// cases
&lt;/span&gt;    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;New:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; InputStream forMagic(Path p, FileSystem srcFs) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    FSDataInputStream i = srcFs.open(p);

    &lt;span class=&quot;code-keyword&quot;&gt;switch&lt;/span&gt;(i.readShort()) { &lt;span class=&quot;code-comment&quot;&gt;// &amp;lt;=== index (or pointer) processes!!
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// cases
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;: {
        &lt;span class=&quot;code-comment&quot;&gt;// Check the type of compression instead, depending on Codec &lt;span class=&quot;code-keyword&quot;&gt;class&apos;&lt;/span&gt;s
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// own detection methods, based on the provided path.
&lt;/span&gt;        CompressionCodecFactory cf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CompressionCodecFactory(getConf());
        CompressionCodec codec = cf.getCodec(p);
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (codec != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; codec.createInputStream(i);
        }
        &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
      }
    }

    &lt;span class=&quot;code-comment&quot;&gt;// File is non-compressed, or not a file container we know.
&lt;/span&gt;    i.seek(0);
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; i;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Fix is to use i.seek(0) before we use i anywhere. I missed that.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12608576">HADOOP-8833</key>
            <summary>fs -text should make sure to call inputstream.seek(0) before using input stream</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="qwertymaniac">Harsh J</assignee>
                                    <reporter username="qwertymaniac">Harsh J</reporter>
                        <labels>
                    </labels>
                <created>Fri, 21 Sep 2012 05:47:49 +0000</created>
                <updated>Fri, 15 Feb 2013 13:12:49 +0000</updated>
                            <resolved>Sat, 22 Sep 2012 20:10:14 +0000</resolved>
                                    <version>2.0.2-alpha</version>
                                    <fixVersion>2.0.3-alpha</fixVersion>
                                    <component>fs</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>9</watches>
                                                                                                                <comments>
                            <comment id="13460335" author="qwertymaniac" created="Fri, 21 Sep 2012 08:03:03 +0000"  >&lt;p&gt;This should fix it.&lt;/p&gt;</comment>
                            <comment id="13460399" author="hadoopqa" created="Fri, 21 Sep 2012 09:51:56 +0000"  >&lt;p&gt;+1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12546011/HADOOP-8833.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12546011/HADOOP-8833.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1490//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1490//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1490//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1490//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13460435" author="tomwhite" created="Fri, 21 Sep 2012 11:51:17 +0000"  >&lt;p&gt;+1 on the fix. I noticed that the test doesn&apos;t fail without the fix though. This is because BZip2Codec.BZip2CompressionInputStream.readStreamHeader() tolerates a missing (two-byte) header, so BZip2 files happen to work anyway. I&apos;ve modified the test slightly to test a deflate-compressed file, and this one does fail without the seek fix.&lt;/p&gt;</comment>
                            <comment id="13460488" author="qwertymaniac" created="Fri, 21 Sep 2012 13:40:38 +0000"  >&lt;p&gt;Thanks Tom, I did wonder about that. Then though it to be my maven local repo cause I had first run test with fix installed. thanks for revising the patch. Committing to trunk and branch-2 now, but leaving open for 2.0.2 (gatekeeper has to grant).&lt;/p&gt;</comment>
                            <comment id="13460489" author="qwertymaniac" created="Fri, 21 Sep 2012 13:41:12 +0000"  >&lt;p&gt;Oh, first gotta wait for jenkins again.&lt;/p&gt;</comment>
                            <comment id="13460682" author="kkambatl" created="Fri, 21 Sep 2012 18:34:34 +0000"  >&lt;p&gt;Cancelling patch to re-submit and kick Jenkins&lt;/p&gt;</comment>
                            <comment id="13460685" author="kkambatl" created="Fri, 21 Sep 2012 18:36:53 +0000"  >&lt;p&gt;Uploading the same patch again.&lt;/p&gt;</comment>
                            <comment id="13461246" author="qwertymaniac" created="Sat, 22 Sep 2012 18:52:02 +0000"  >&lt;p&gt;I ran the new test locally - works on a Mac too so apparently no native dependency as I&apos;d originally thought (due to deflate):&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.hdfs.TestDFSShell
Tests run: 20, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 36.699 sec
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Committing shortly. Thanks again Tom and Karthik.&lt;/p&gt;</comment>
                            <comment id="13461250" author="hudson" created="Sat, 22 Sep 2012 19:05:39 +0000"  >&lt;p&gt;Integrated in Hadoop-Common-trunk-Commit #2755 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2755/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2755/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8833&quot; title=&quot;fs -text should make sure to call inputstream.seek(0) before using input stream&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8833&quot;&gt;&lt;del&gt;HADOOP-8833&lt;/del&gt;&lt;/a&gt;. fs -text should make sure to call inputstream.seek(0) before using input stream. Contributed by Tom White and Harsh J. (harsh) (Revision 1388869)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13461251" author="hudson" created="Sat, 22 Sep 2012 19:06:50 +0000"  >&lt;p&gt;Integrated in Hadoop-Hdfs-trunk-Commit #2818 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2818/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2818/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8833&quot; title=&quot;fs -text should make sure to call inputstream.seek(0) before using input stream&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8833&quot;&gt;&lt;del&gt;HADOOP-8833&lt;/del&gt;&lt;/a&gt;. fs -text should make sure to call inputstream.seek(0) before using input stream. Contributed by Tom White and Harsh J. (harsh) (Revision 1388869)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13461256" author="qwertymaniac" created="Sat, 22 Sep 2012 19:49:48 +0000"  >&lt;p&gt;Committed to trunk. Pending commit to branch-2 (svn up seems to be going too slow here).&lt;/p&gt;</comment>
                            <comment id="13461257" author="hudson" created="Sat, 22 Sep 2012 19:50:42 +0000"  >&lt;p&gt;Integrated in Hadoop-Mapreduce-trunk-Commit #2777 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2777/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2777/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8833&quot; title=&quot;fs -text should make sure to call inputstream.seek(0) before using input stream&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8833&quot;&gt;&lt;del&gt;HADOOP-8833&lt;/del&gt;&lt;/a&gt;. fs -text should make sure to call inputstream.seek(0) before using input stream. Contributed by Tom White and Harsh J. (harsh) (Revision 1388869)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13461410" author="hudson" created="Sun, 23 Sep 2012 12:57:58 +0000"  >&lt;p&gt;Integrated in Hadoop-Hdfs-trunk #1174 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1174/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1174/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8833&quot; title=&quot;fs -text should make sure to call inputstream.seek(0) before using input stream&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8833&quot;&gt;&lt;del&gt;HADOOP-8833&lt;/del&gt;&lt;/a&gt;. fs -text should make sure to call inputstream.seek(0) before using input stream. Contributed by Tom White and Harsh J. (harsh) (Revision 1388869)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13461420" author="hudson" created="Sun, 23 Sep 2012 13:58:51 +0000"  >&lt;p&gt;Integrated in Hadoop-Mapreduce-trunk #1205 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1205/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1205/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8833&quot; title=&quot;fs -text should make sure to call inputstream.seek(0) before using input stream&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8833&quot;&gt;&lt;del&gt;HADOOP-8833&lt;/del&gt;&lt;/a&gt;. fs -text should make sure to call inputstream.seek(0) before using input stream. Contributed by Tom White and Harsh J. (harsh) (Revision 1388869)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1388869&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12558609">HADOOP-8449</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12546074" name="HADOOP-8833.patch" size="4323" author="kkambatl" created="Fri, 21 Sep 2012 18:36:53 +0000"/>
                            <attachment id="12546031" name="HADOOP-8833.patch" size="4323" author="tomwhite" created="Fri, 21 Sep 2012 11:51:17 +0000"/>
                            <attachment id="12546011" name="HADOOP-8833.patch" size="3603" author="qwertymaniac" created="Fri, 21 Sep 2012 08:03:03 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>3.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>240728</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 9 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0155j:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4604</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>