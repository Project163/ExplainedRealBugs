<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:45:15 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-10591] Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-10591</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Currently direct buffers allocated by compression codecs like Gzip (which allocates 2 direct buffers per instance) are not deallocated when the stream is closed. Eventually for long running processes which create a huge number of files, these direct buffers are left hanging till a full gc, which may or may not happen in a reasonable amount of time - especially if the process does not use a whole lot of heap.&lt;/p&gt;

&lt;p&gt;Either these buffers should be pooled or they should be deallocated when the stream is closed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12713258">HADOOP-10591</key>
            <summary>Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cmccabe">Colin McCabe</assignee>
                                    <reporter username="hshreedharan">Hari Shreedharan</reporter>
                        <labels>
                    </labels>
                <created>Fri, 9 May 2014 07:23:38 +0000</created>
                <updated>Wed, 20 May 2015 14:39:48 +0000</updated>
                            <resolved>Thu, 17 Jul 2014 18:21:15 +0000</resolved>
                                    <version>2.2.0</version>
                                    <fixVersion>2.6.0</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="13995717" author="andrew.wang" created="Mon, 12 May 2014 22:18:17 +0000"  >&lt;p&gt;This change was made in &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10047&quot; title=&quot;Add a directbuffer Decompressor API to hadoop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10047&quot;&gt;&lt;del&gt;HADOOP-10047&lt;/del&gt;&lt;/a&gt;. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gopalv&quot; class=&quot;user-hover&quot; rel=&quot;gopalv&quot;&gt;gopalv&lt;/a&gt; or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=cmccabe&quot; class=&quot;user-hover&quot; rel=&quot;cmccabe&quot;&gt;cmccabe&lt;/a&gt; any thoughts on this one?&lt;/p&gt;</comment>
                            <comment id="13996789" author="cmccabe" created="Tue, 13 May 2014 19:10:28 +0000"  >&lt;p&gt;We have two ways we could go on this one.  One is to implement a buffer pooling scheme.  Another is to manually free the direct buffers.&lt;/p&gt;

&lt;p&gt;The buffer-pooling scheme initially might seem more attractive, but it&apos;s problematic.  We don&apos;t know that all the buffers we&apos;re creating will be the same size, so we end up with the same kind of problems you get when implementing &lt;tt&gt;malloc&lt;/tt&gt;.  It&apos;s also unclear how long we should hang on to buffers when they&apos;re not in use.&lt;/p&gt;

&lt;p&gt;Manually freeing the buffers is possible through a Sun-specific API.  We do this in a few other cases-- for example, to &lt;tt&gt;munmap&lt;/tt&gt; a memory segment.  This is probably the simpler route to go.&lt;/p&gt;</comment>
                            <comment id="13997046" author="chris.douglas" created="Tue, 13 May 2014 23:37:57 +0000"  >&lt;p&gt;The &lt;a href=&quot;https://hadoop.apache.org/docs/r2.4.0/api/org/apache/hadoop/io/compress/CodecPool.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;CodecPool&lt;/a&gt; class implements pooling of direct buffers for compression codecs.&lt;/p&gt;</comment>
                            <comment id="13997048" author="chris.douglas" created="Tue, 13 May 2014 23:40:14 +0000"  >&lt;p&gt;(well, it pools the Compressor/Decompressor, but the intent is to pool the direct buffers)&lt;/p&gt;</comment>
                            <comment id="13998011" author="cmccabe" created="Wed, 14 May 2014 20:54:12 +0000"  >&lt;p&gt;Hmm.  The JIRA talks about &quot;direct buffers allocated by compression codecs like Gzip (which allocates 2 direct buffers per instance).&quot;&lt;br/&gt;
I assume this is a reference to &lt;tt&gt;ZlibDecompressor#compressedDirectBuf&lt;/tt&gt; and &lt;tt&gt;ZlibDecompressor#uncompressedDirectBuf&lt;/tt&gt;.  Those are buffers inside &lt;tt&gt;Decompressor&lt;/tt&gt; objects, not buffers inside &lt;tt&gt;Codec&lt;/tt&gt; objects.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;However&lt;/b&gt;... &lt;tt&gt;CodecPool&lt;/tt&gt; has a cache for &lt;tt&gt;Compressor&lt;/tt&gt; and &lt;tt&gt;Decompressor&lt;/tt&gt; objects, but it seems to be optional, not mandatory.  For example, this code in &lt;tt&gt;SequenceFile&lt;/tt&gt; is careful to use the &lt;tt&gt;Decompressor&lt;/tt&gt; cache:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt; 
         keyLenDecompressor = CodecPool.getDecompressor(codec);
          keyLenInFilter = codec.createInputStream(keyLenBuffer, 
                                                   keyLenDecompressor);
 &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;On the other hand, there are also one-argument versions of the &lt;tt&gt;createInputStream&lt;/tt&gt; functions that always create a new &lt;tt&gt;Decompressor&lt;/tt&gt; (and similar one-argument versions for &lt;tt&gt;createOutputStream&lt;/tt&gt;).&lt;/p&gt;

&lt;p&gt;What&apos;s the right resolution here?  Is it just to mark the one-argument versions as deprecated and audit HDFS and Hadoop client programs to remove usages?  That certainly seems like a good idea, if we want to cache these &lt;tt&gt;ByteBuffers&lt;/tt&gt; without adding more caching mechanisms.&lt;/p&gt;</comment>
                            <comment id="13998319" author="gopalv" created="Thu, 15 May 2014 00:30:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=andrew.wang&quot; class=&quot;user-hover&quot; rel=&quot;andrew.wang&quot;&gt;andrew.wang&lt;/a&gt;: &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10047&quot; title=&quot;Add a directbuffer Decompressor API to hadoop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10047&quot;&gt;&lt;del&gt;HADOOP-10047&lt;/del&gt;&lt;/a&gt; was a change which avoided the need to allocate direct buffers by the decompressors implementing the DirectDecompressor interface.&lt;/p&gt;

&lt;p&gt;DirectDecompressor::decompress(ByteBuffer src, ByteBuffer dst)&lt;/p&gt;

&lt;p&gt;was meant to avoid allocating objects in the decompressor object&apos;s control. That does a decompress from src into dst without an intermediate allocation or copy.&lt;/p&gt;

&lt;p&gt;Before that ORC couldn&apos;t use own the buffer pools for src/dst. &lt;/p&gt;

&lt;p&gt;The issue in this bug pre-dates &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10047&quot; title=&quot;Add a directbuffer Decompressor API to hadoop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10047&quot;&gt;&lt;del&gt;HADOOP-10047&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="13998537" author="cmccabe" created="Thu, 15 May 2014 07:36:37 +0000"  >&lt;p&gt;Thanks, Gopal.  I agree that this is a pre-existing issue, definitely not introduced by &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10047&quot; title=&quot;Add a directbuffer Decompressor API to hadoop&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10047&quot;&gt;&lt;del&gt;HADOOP-10047&lt;/del&gt;&lt;/a&gt;.  And, in fact, that JIRA should improve the situation in many cases by eliminating the need for the &lt;tt&gt;Decompressor&lt;/tt&gt; to allocate its own direct buffer.&lt;/p&gt;

&lt;p&gt;semi-related: One thing that I notice in the constructor for &lt;tt&gt;ZlibDirectDecompressor&lt;/tt&gt; is that it invokes the superclass constructor (&lt;tt&gt;ZlibDecompressor&lt;/tt&gt;) with &lt;tt&gt;directBufferSize = 0&lt;/tt&gt;, causing us to call &lt;tt&gt;allocateDirect&lt;/tt&gt; with a size of 0.  I do wonder what this actually does... I didn&apos;t manage to find any documentation for this case (maybe I missed it?).&lt;/p&gt;</comment>
                            <comment id="14039539" author="cmccabe" created="Fri, 20 Jun 2014 23:34:34 +0000"  >&lt;p&gt;This is a patch which makes the one-argument forms of &lt;tt&gt;Codec#createOutputStream&lt;/tt&gt; and  &lt;tt&gt;Codec#createInputStream&lt;/tt&gt; take the codecs from the global &lt;tt&gt;CodecPool&lt;/tt&gt;, rather than allocating a new one each time.&lt;/p&gt;</comment>
                            <comment id="14039619" author="hadoopqa" created="Sat, 21 Jun 2014 01:08:45 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12651774/HADOOP-10591.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12651774/HADOOP-10591.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  There were no new javadoc warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/4132//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/4132//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/4132//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/4132//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14062955" author="atm" created="Wed, 16 Jul 2014 00:58:26 +0000"  >&lt;p&gt;Latest patch looks pretty good to me. Two nits:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Any reason we can&apos;t make &lt;tt&gt;CompressionOutputStream.trackedCompressor&lt;/tt&gt; private?&lt;/li&gt;
	&lt;li&gt;The javadoc for &lt;tt&gt;createInputStreamWithCodecPool&lt;/tt&gt; says &quot;The codec to use to create the &lt;b&gt;output&lt;/b&gt; stream.&quot;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;+1 once these are addressed.&lt;/p&gt;</comment>
                            <comment id="14063951" author="cmccabe" created="Wed, 16 Jul 2014 19:17:44 +0000"  >&lt;blockquote&gt;&lt;p&gt;Any reason we can&apos;t make CompressionOutputStream.trackedCompressor private?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yeah, let&apos;s make it private.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;The javadoc for createInputStreamWithCodecPool says &quot;The codec to use to create the output stream.&quot;&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Fixed.&lt;/p&gt;</comment>
                            <comment id="14064015" author="hadoopqa" created="Wed, 16 Jul 2014 20:10:34 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12656112/HADOOP-10591.002.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12656112/HADOOP-10591.002.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  There were no new javadoc warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 core tests&lt;/font&gt;.  The patch failed these unit tests in hadoop-common-project/hadoop-common:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.fs.TestSymlinkLocalFSFileContext&lt;br/&gt;
                  org.apache.hadoop.ipc.TestIPC&lt;br/&gt;
                  org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/4295//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/4295//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/4295//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/4295//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14064390" author="cmccabe" created="Thu, 17 Jul 2014 00:26:52 +0000"  >&lt;p&gt;Test failures are unrelated.  TestIPC is timing out resolving a hostname (looks like a jenkins problem), and the symlink tests have been failing for some other patches too.&lt;/p&gt;</comment>
                            <comment id="14064393" author="atm" created="Thu, 17 Jul 2014 00:29:20 +0000"  >&lt;p&gt;Agreed.&lt;/p&gt;

&lt;p&gt;+1, the latest patch looks good to me. Thanks, Colin.&lt;/p&gt;</comment>
                            <comment id="14065295" author="hudson" created="Thu, 17 Jul 2014 18:23:28 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-trunk-Commit #5900 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/5900/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/5900/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10591&quot; title=&quot;Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10591&quot;&gt;&lt;del&gt;HADOOP-10591&lt;/del&gt;&lt;/a&gt;. Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1611423&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1611423&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/BZip2Codec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionInputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionOutputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/DefaultCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/GzipCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/Lz4Codec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/SnappyCodec.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14066252" author="hudson" created="Fri, 18 Jul 2014 10:41:34 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #616 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/616/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/616/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10591&quot; title=&quot;Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10591&quot;&gt;&lt;del&gt;HADOOP-10591&lt;/del&gt;&lt;/a&gt;. Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1611423&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1611423&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/BZip2Codec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionInputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionOutputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/DefaultCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/GzipCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/Lz4Codec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/SnappyCodec.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14066343" author="hudson" created="Fri, 18 Jul 2014 13:38:10 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1835 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1835/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1835/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10591&quot; title=&quot;Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10591&quot;&gt;&lt;del&gt;HADOOP-10591&lt;/del&gt;&lt;/a&gt;. Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1611423&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1611423&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/BZip2Codec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionInputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionOutputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/DefaultCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/GzipCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/Lz4Codec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/SnappyCodec.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14066366" author="hudson" created="Fri, 18 Jul 2014 14:00:16 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Hdfs-trunk #1808 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1808/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1808/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10591&quot; title=&quot;Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10591&quot;&gt;&lt;del&gt;HADOOP-10591&lt;/del&gt;&lt;/a&gt;. Compression codecs must used pooled direct buffers or deallocate direct buffers when stream is closed (cmccabe) (cmccabe: &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1611423&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1611423&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/BZip2Codec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionInputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/CompressionOutputStream.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/DefaultCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/GzipCodec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/Lz4Codec.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/SnappyCodec.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12831293">HADOOP-12007</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12723994">FLUME-2416</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12651774" name="HADOOP-10591.001.patch" size="11950" author="cmccabe" created="Fri, 20 Jun 2014 23:34:34 +0000"/>
                            <attachment id="12656112" name="HADOOP-10591.002.patch" size="11957" author="cmccabe" created="Wed, 16 Jul 2014 19:17:56 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>391574</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 18 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1vfu7:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>391786</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12327179">2.6.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>