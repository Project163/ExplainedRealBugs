<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:43:07 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-9566] Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-9566</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;Reading using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT from JVM_handle_linux_signal). This can lead to crashes in the client application. It would be nice if libhdfs handled this signal internally.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12648046">HADOOP-9566</key>
            <summary>Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="cmccabe">Colin McCabe</assignee>
                                    <reporter username="lskuff">Lenni Kuff</reporter>
                        <labels>
                    </labels>
                <created>Thu, 16 May 2013 20:42:28 +0000</created>
                <updated>Tue, 27 Aug 2013 22:06:36 +0000</updated>
                            <resolved>Fri, 17 May 2013 00:11:57 +0000</resolved>
                                    <version>2.0.4-alpha</version>
                                    <fixVersion>2.1.0-beta</fixVersion>
                                    <component>native</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                                                                                <comments>
                            <comment id="13659980" author="cmccabe" created="Thu, 16 May 2013 20:54:46 +0000"  >&lt;p&gt;Logs and stack trace from a libhdfs run:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;13/05/16 08:37:01 DEBUG hdfs.BlockReaderLocal: putting FileInputStream &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; /test-warehouse/tpch.lineitem/lineitem.tbl back into FileInputStreamCache
[&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0x7fffcfc88700 (LWP 2810) exited]
13/05/16 08:37:01 DEBUG ipc.Client: IPC Client (1002500837) connection to localhost/127.0.0.1:20500 from lskuff sending #9
13/05/16 08:37:01 DEBUG ipc.Client: IPC Client (1002500837) connection to localhost/127.0.0.1:20500 from lskuff got value #9
13/05/16 08:37:01 DEBUG ipc.ProtobufRpcEngine: Call: getBlockLocations took 2ms
13/05/16 08:37:01 DEBUG hdfs.DFSClient: newInfo = LocatedBlocks{
  fileLength=753862072
  underConstruction=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;
  blocks=[LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_8973605789866450572_6252; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=0; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_6529746879505750363_6253; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=67108864; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_7137931742725996903_6254; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=134217728; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_2512286346981490115_6255; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=201326592; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_-4910107063321244927_6256; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=268435456; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_2541626567081697462_6257; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=335544320; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_3773253961084852594_6258; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=402653184; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_9156075801845636610_6259; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=469762048; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_-4734840374398159095_6260; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=536870912; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}, LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_7292053749276395282_6261; getBlockSize()=67108864; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=603979776; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}]
  lastLocatedBlock=LocatedBlock{BP-866712037-127.0.0.1-1366931725003:blk_-1379632012241044332_6263; getBlockSize()=15664568; corrupt=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;; offset=738197504; locs=[127.0.0.1:47890, 127.0.0.1:60135, 127.0.0.1:47287]}
  isLastBlockComplete=&lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;}
13/05/16 08:37:01 DEBUG hdfs.DFSClient: Connecting to datanode 127.0.0.1:47890

Program received signal SIGPIPE, Broken pipe.
[Switching to &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt; 0x7fffebd58700 (LWP 2592)]
0x00007ffff79b2ccd in write () from /lib/x86_64-linux-gnu/libpthread.so.0
(gdb) bt
#0  0x00007ffff79b2ccd in write () from /lib/x86_64-linux-gnu/libpthread.so.0
#1  0x00007fffebf7a4ce in write_fully (env=0x32e79d0, fd=179, buf=0x7fffebd54a20 &quot;&quot;, amt=76)
    at hadoop/hadoop-common-project/hadoop-common/src/main/&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;/src/org/apache/hadoop/net/unix/DomainSocket.c:586
#2  0x00007fffebf7a623 in Java_org_apache_hadoop_net_unix_DomainSocket_writeArray0 (env=0x32e79d0, 
    clazz=&amp;lt;optimized out&amp;gt;, fd=179, b=0x7fffebd56b08, offset=0, length=76)
    at hadoop/hadoop-common-project/hadoop-common/src/main/&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;/src/org/apache/hadoop/net/unix/DomainSocket.c:902
#3  0x00007fffefb46eee in ?? ()
#4  0x0000000604d1a794 in ?? ()
#5  0x00007fffebd56ac8 in ?? ()
#6  0x0000000604d1b2c8 in ?? ()
#7  0x0000000000000000 in ?? ()
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13659990" author="cmccabe" created="Thu, 16 May 2013 21:00:51 +0000"  >&lt;p&gt;It&apos;s interesting that this is coming up only for &lt;tt&gt;libhdfs&lt;/tt&gt; users.  My guess is that when you launch a standalone JVM, it sets up a signal handler that ignores &lt;tt&gt;SIGPIPE&lt;/tt&gt;, but JNI code does not get this same benefit.&lt;/p&gt;

&lt;p&gt;One way to fix this is modify your program which uses &lt;tt&gt;libhdfs&lt;/tt&gt; to call this prior to initializing &lt;tt&gt;JNI&lt;/tt&gt;:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;signal(SIGPIPE, SIG_IGN);
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This ignores the &lt;tt&gt;SIGPIPE&lt;/tt&gt; signal whenever it happens.  When you initialize JNI, it creates its own signal handlers, which will call the previously installed signal handler if it was explicitly set (i.e., is not the default).&lt;/p&gt;

&lt;p&gt;However, this is kind of a hack.  We shouldn&apos;t expect &lt;tt&gt;libhdfs&lt;/tt&gt; users to have to jump through these kind of hoops.  The best fix is to use &lt;tt&gt;MSG_NOSIGNAL&lt;/tt&gt; or &lt;tt&gt;MSG_NOSIGPIPE&lt;/tt&gt; to avoid generating these signals in the first place.&lt;/p&gt;</comment>
                            <comment id="13659997" author="cmccabe" created="Thu, 16 May 2013 21:04:04 +0000"  >&lt;p&gt;I took the liberty of removing #define_GNU_SOURCE, to squash this compiler warning:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;/home/cmccabe/hadoop2/hadoop-common-project/hadoop-common/src/main/&lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;/src/org/apache/hadoop/net/unix/DomainSocket.c:19:0: warning: &lt;span class=&quot;code-quote&quot;&gt;&quot;_GNU_SOURCE&quot;&lt;/span&gt; redefined [enabled by &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;]
&amp;lt;command-line&amp;gt;:0:0: note: &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; is the location of the previous definition
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We don&apos;t need to define this file-by-file since it&apos;s a compiler flag now.&lt;/p&gt;</comment>
                            <comment id="13660032" author="hadoopqa" created="Thu, 16 May 2013 21:38:43 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12583542/HDFS-4831.001.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12583542/HDFS-4831.001.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/4405//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/4405//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/4405//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/4405//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13660037" author="cmccabe" created="Thu, 16 May 2013 21:42:30 +0000"  >&lt;p&gt;I did the compile on FreeBSD 9.1.  Spotted that it needed to include string.h, and also MSG_NOSIGPIPE should be SO_NOSIGPIPE.&lt;/p&gt;</comment>
                            <comment id="13660096" author="hadoopqa" created="Thu, 16 May 2013 22:37:30 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12583547/HDFS-4831.003.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12583547/HDFS-4831.003.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/4406//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/4406//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HDFS-Build/4406//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HDFS-Build/4406//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13660134" author="lskuff" created="Thu, 16 May 2013 23:23:35 +0000"  >&lt;p&gt;This problem appears to fix my use case. I applied the &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9566&quot; title=&quot;Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9566&quot;&gt;&lt;del&gt;HDFS-4831&lt;/del&gt;&lt;/a&gt;.003.patch and rebuilt the native libaries (hadoop/hdfs). My client application is no longer crashing after applying this fix.  I then changed back to the old binaries (the ones without this fix) and my client app started crashing again.&lt;/p&gt;</comment>
                            <comment id="13660170" author="atm" created="Thu, 16 May 2013 23:58:26 +0000"  >&lt;p&gt;Good find, and thanks a lot for testing out the fix, Lenni.&lt;/p&gt;

&lt;p&gt;+1, the patch looks good to me. I don&apos;t think tests are necessary for this change since the issue is so difficult to reproduce. I also tested this by running the following, since I&apos;m not sure if test-patch runs with native support:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;$ mvn -Pnative clean test -Dtest=TestParallelShortCircuitReadUnCached,TestParallelShortCircuitLegacyRead,TestParallelShortCircuitReadNoChecksum,TestShortCircuitLocalRead,TestParallelShortCircuitRead
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;All the tests passed as expected.&lt;/p&gt;

&lt;p&gt;I&apos;m going to commit this momentarily.&lt;/p&gt;</comment>
                            <comment id="13660175" author="cmccabe" created="Fri, 17 May 2013 00:01:04 +0000"  >&lt;p&gt;Thanks, ATM.  test-patch does run with native support, although at the moment, it builds 32-bit which is a little non-standard, and doesn&apos;t test fuse_dfs.&lt;/p&gt;</comment>
                            <comment id="13660179" author="atm" created="Fri, 17 May 2013 00:05:48 +0000"  >&lt;p&gt;Good to know, Colin. Thanks for that.&lt;/p&gt;

&lt;p&gt;Moved this JIRA to Common since that&apos;s where the change is.&lt;/p&gt;</comment>
                            <comment id="13660183" author="atm" created="Fri, 17 May 2013 00:11:57 +0000"  >&lt;p&gt;I&apos;ve just committed this to trunk and branch-2.&lt;/p&gt;

&lt;p&gt;Thanks a lot for the contribution, Colin. And thanks a lot to Lenni for running those tests as well.&lt;/p&gt;</comment>
                            <comment id="13660223" author="hudson" created="Fri, 17 May 2013 01:01:53 +0000"  >&lt;p&gt;Integrated in Hadoop-trunk-Commit #3762 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/3762/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/3762/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9566&quot; title=&quot;Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9566&quot;&gt;&lt;del&gt;HADOOP-9566&lt;/del&gt;&lt;/a&gt;. Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes. Contributed by Colin Patrick McCabe. (Revision 1483612)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
atm : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483612&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483612&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocket.c&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13660547" author="hudson" created="Fri, 17 May 2013 10:45:48 +0000"  >&lt;p&gt;Integrated in Hadoop-Yarn-trunk #212 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/212/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/212/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9566&quot; title=&quot;Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9566&quot;&gt;&lt;del&gt;HADOOP-9566&lt;/del&gt;&lt;/a&gt;. Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes. Contributed by Colin Patrick McCabe. (Revision 1483612)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
atm : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483612&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483612&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocket.c&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13660691" author="hudson" created="Fri, 17 May 2013 13:10:33 +0000"  >&lt;p&gt;Integrated in Hadoop-Hdfs-trunk #1401 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1401/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1401/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9566&quot; title=&quot;Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9566&quot;&gt;&lt;del&gt;HADOOP-9566&lt;/del&gt;&lt;/a&gt;. Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes. Contributed by Colin Patrick McCabe. (Revision 1483612)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
atm : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483612&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483612&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocket.c&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13660711" author="hudson" created="Fri, 17 May 2013 13:36:17 +0000"  >&lt;p&gt;Integrated in Hadoop-Mapreduce-trunk #1428 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1428/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1428/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-9566&quot; title=&quot;Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-9566&quot;&gt;&lt;del&gt;HADOOP-9566&lt;/del&gt;&lt;/a&gt;. Performing direct read using libhdfs sometimes raises SIGPIPE (which in turn throws SIGABRT) causing client crashes. Contributed by Colin Patrick McCabe. (Revision 1483612)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
atm : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483612&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1483612&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/net/unix/DomainSocket.c&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                    <attachments>
                            <attachment id="12583542" name="HDFS-4831.001.patch" size="2469" author="cmccabe" created="Thu, 16 May 2013 21:02:16 +0000"/>
                            <attachment id="12583547" name="HDFS-4831.003.patch" size="2660" author="cmccabe" created="Thu, 16 May 2013 21:42:30 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>328402</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 27 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1kntb:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>328746</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12324030">2.1.0-beta</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>