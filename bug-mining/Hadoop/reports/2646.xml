<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:56:12 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-16998] WASB : NativeAzureFsOutputStream#close() throwing IllegalArgumentException</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-16998</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;During HFile create, at the end when called close() on the OutputStream, there is some pending data to get flushed. When this flush happens, an Exception is thrown back from Storage. The Azure-storage SDK layer will throw back IOE. (Even if it is a StorageException thrown from the Storage, the SDK converts it to IOE.) But at HBase, we end up getting IllegalArgumentException which causes the RS to get aborted. If we get back IOE, the flush will get retried instead of aborting RS.&lt;br/&gt;
The reason is this&lt;br/&gt;
NativeAzureFsOutputStream uses Azure-storage SDK&apos;s BlobOutputStreamInternal. But the BlobOutputStreamInternal is wrapped within a SyncableDataOutputStream which is a FilterOutputStream. During the close op, NativeAzureFsOutputStream calls close on SyncableDataOutputStream and it uses below method from FilterOutputStream&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void close() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
  &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; (OutputStream ostream = out) {
              flush();
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Here the flush call caused an IOE to be thrown to here. The finally will issue close call on ostream (Which is an instance of BlobOutputStreamInternal)&lt;br/&gt;
When BlobOutputStreamInternal#close() is been called, if there was any exception already occured on that Stream, it will throw back the same Exception&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; void close() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
  &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
              &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; the user has already closed the stream, &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; will &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; a STREAM_CLOSED exception
&lt;/span&gt;              &lt;span class=&quot;code-comment&quot;&gt;// &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; an exception was thrown by any thread in the threadExecutor, realize it now
&lt;/span&gt;              &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.checkStreamState();
              ...
}
&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; void checkStreamState() &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
  &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastError != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
              &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.lastError;
  }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So here both try and finally block getting Exceptions and Java uses Throwable#addSuppressed() &lt;br/&gt;
Within this method if both Exceptions are same objects, it throws back IllegalArgumentException&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; void addSuppressed(Throwable exception) {
              &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (exception == &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;)
                             &lt;span class=&quot;code-keyword&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; IllegalArgumentException(SELF_SUPPRESSION_MESSAGE, exception);
              ....
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13299344">HADOOP-16998</key>
            <summary>WASB : NativeAzureFsOutputStream#close() throwing IllegalArgumentException</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="anoop.hbase">Anoop Sam John</assignee>
                                    <reporter username="anoop.hbase">Anoop Sam John</reporter>
                        <labels>
                    </labels>
                <created>Sat, 18 Apr 2020 08:03:37 +0000</created>
                <updated>Fri, 17 Jul 2020 07:53:59 +0000</updated>
                            <resolved>Tue, 14 Jul 2020 14:32:46 +0000</resolved>
                                                    <fixVersion>3.3.1</fixVersion>
                    <fixVersion>3.4.0</fixVersion>
                                    <component>fs/azure</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>6</watches>
                                                                                                                <comments>
                            <comment id="17087348" author="liuml07" created="Mon, 20 Apr 2020 04:35:40 +0000"  >&lt;p&gt;I found some other &lt;a href=&quot;http://mail.openjdk.java.net/pipermail/core-libs-dev/2014-May/026724.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;discussions&lt;/a&gt; about &lt;tt&gt;FilterOutputStream&lt;/tt&gt; using try-with-resource in &lt;tt&gt;close()&lt;/tt&gt;. &lt;/p&gt;

&lt;p&gt;&lt;tt&gt;FilterOutputStream&lt;/tt&gt; is in Java SDK and &lt;tt&gt;BlobOutputStreamInternal&lt;/tt&gt; is from Azure SDK. So what a potential fix would like? Implementing the &lt;tt&gt;SyncableDataOutputStream::close()&lt;/tt&gt; method and not using&lt;br/&gt;
try-with-resource? I mean, we deal with the thrown exception both in try-catch and re-throw without suppressed. What&apos;s in your mind &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=anoop.hbase&quot; class=&quot;user-hover&quot; rel=&quot;anoop.hbase&quot;&gt;anoop.hbase&lt;/a&gt;? Thanks,&lt;/p&gt;</comment>
                            <comment id="17087352" author="anoop.hbase" created="Mon, 20 Apr 2020 04:46:15 +0000"  >&lt;p&gt;Yes same way.  Seems in some versions of JDK, FilterOutputStream is changed to handle this possible issue in close().  But we might have to fix this at the WASB layer itself as long as we support JDK 1.8+.. Because some versions of JDK 1.8 will have this issue possibly coming. &lt;/p&gt;</comment>
                            <comment id="17087354" author="anoop.hbase" created="Mon, 20 Apr 2020 04:48:19 +0000"  >&lt;p&gt;Just attached the patch. I need to work with the PR. But some time later.&lt;/p&gt;</comment>
                            <comment id="17087371" author="liuml07" created="Mon, 20 Apr 2020 05:34:38 +0000"  >&lt;p&gt;+1&#160;I&apos;d leave to &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ayushtkn&quot; class=&quot;user-hover&quot; rel=&quot;ayushtkn&quot;&gt;ayushtkn&lt;/a&gt;&#160;and/or &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt; to review (again) and commit.&lt;/p&gt;

&lt;p&gt;Could you also add the Jira number in the nice comments like &quot;See&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-16998&quot; title=&quot;WASB : NativeAzureFsOutputStream#close() throwing IllegalArgumentException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-16998&quot;&gt;&lt;del&gt;HADOOP-16998&lt;/del&gt;&lt;/a&gt; for more context&quot; etc. So we have a place (this Jira) to revisit this in future? Thanks,&lt;/p&gt;

&lt;p&gt;I think it would be ideally a test case if possible.&#160;&lt;/p&gt;</comment>
                            <comment id="17087375" author="anoop.hbase" created="Mon, 20 Apr 2020 05:40:44 +0000"  >&lt;p&gt;Thanks for having a look. Sure I will work on it.. Just attached for the ref.&lt;/p&gt;</comment>
                            <comment id="17087834" author="stevel@apache.org" created="Mon, 20 Apr 2020 15:11:44 +0000"  >&lt;p&gt;you got a full stack?&lt;/p&gt;</comment>
                            <comment id="17087838" author="stevel@apache.org" created="Mon, 20 Apr 2020 15:19:35 +0000"  >&lt;p&gt;can tag this with the specific version of hadoop you are having problems with.&lt;/p&gt;

&lt;p&gt;Try hadoop branch-3/trunk if not already done -that is, something with &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-16785&quot; title=&quot;Improve wasb and abfs resilience on double close() calls&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-16785&quot;&gt;&lt;del&gt;HADOOP-16785&lt;/del&gt;&lt;/a&gt; in, which tried to harden thos close work. If that&apos;s not enough, at least it has a start with where to begin testing this.&lt;/p&gt;

&lt;p&gt;Patches up on github as PRs for review, thanks.&lt;/p&gt;</comment>
                            <comment id="17087871" author="anoop.hbase" created="Mon, 20 Apr 2020 15:47:58 +0000"  >&lt;p&gt;Thanks Steve.&lt;br/&gt;
The version on which this was observed was 2.7.3.. But I believe this should be there in all versions and even in master.&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-16785&quot; title=&quot;Improve wasb and abfs resilience on double close() calls&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-16785&quot;&gt;&lt;del&gt;HADOOP-16785&lt;/del&gt;&lt;/a&gt; handles cases where writes are called after close().  Here it is different.  When close() is been called there is still data pending for flush.  That write fails with IOE from Azure Storage SDK. And then in finally block of the close() it try to close the Azure Storage SDK level OS which throws back same IOE.  This is the stack trace of the Exception what we see at HBase level.&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.lang.IllegalArgumentException: ...
                  at java.lang.Throwable.addSuppressed(Throwable.java:1072)
                  at java.io.FilterOutputStream.close(FilterOutputStream.java:159)
                  at org.apache.hadoop.fs.azure.NativeAzureFileSystem$NativeAzureFsOutputStream.close(NativeAzureFileSystem.java:1055)
                  at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
                  at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
                  at org.apache.hadoop.hbase.io.hfile.AbstractHFileWriter.finishClose(AbstractHFileWriter.java:248)
                  at org.apache.hadoop.hbase.io.hfile.HFileWriterV3.finishClose(HFileWriterV3.java:133)
                  at org.apache.hadoop.hbase.io.hfile.HFileWriterV2.close(HFileWriterV2.java:368)
                  at org.apache.hadoop.hbase.regionserver.StoreFile$Writer.close(StoreFile.java:1080)
                  at org.apache.hadoop.hbase.regionserver.StoreFlusher.finalizeWriter(StoreFlusher.java:67)
                  at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:80)
                  at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:960)
                  at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:2411)
                  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2511)
                  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2256)
                  at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2218)
                  at org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2110)
                  at org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:2036)
                  at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:501)
                  at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.flushRegion(MemStoreFlusher.java:471)
                  at org.apache.hadoop.hbase.regionserver.MemStoreFlusher.access$800(MemStoreFlusher.java:75)
                  at org.apache.hadoop.hbase.regionserver.MemStoreFlusher$FlushHandler.run(MemStoreFlusher.java:259)
                  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: java.io.IOException: ...
                  at com.microsoft.azure.storage.core.Utility.initIOException(Utility.java:778)
                  at com.microsoft.azure.storage.blob.BlobOutputStreamInternal.writeBlock(BlobOutputStreamInternal.java:462)
                  at com.microsoft.azure.storage.blob.BlobOutputStreamInternal.access$000(BlobOutputStreamInternal.java:47)
                  at com.microsoft.azure.storage.blob.BlobOutputStreamInternal$1.call(BlobOutputStreamInternal.java:406)
                  at com.microsoft.azure.storage.blob.BlobOutputStreamInternal$1.call(BlobOutputStreamInternal.java:403)
                  at java.util.concurrent.FutureTask.run(FutureTask.java:266)
                  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
                  at java.util.concurrent.FutureTask.run(FutureTask.java:266)
                  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
                  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
                  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
Caused by: com.microsoft.azure.storage.StorageException: ..
                  at com.microsoft.azure.storage.StorageException.translateException(StorageException.java:87)
                  at com.microsoft.azure.storage.core.StorageRequest.materializeException(StorageRequest.java:315)
                  at com.microsoft.azure.storage.core.ExecutionEngine.executeWithRetry(ExecutionEngine.java:185)
                  at com.microsoft.azure.storage.blob.CloudBlockBlob.uploadBlockInternal(CloudBlockBlob.java:1097)
                  at com.microsoft.azure.storage.blob.CloudBlockBlob.uploadBlock(CloudBlockBlob.java:1069)
                  at com.microsoft.azure.storage.blob.BlobOutputStreamInternal.writeBlock(BlobOutputStreamInternal.java:456)
                  at com.microsoft.azure.storage.blob.BlobOutputStreamInternal.access$000(BlobOutputStreamInternal.java:47)
                  at com.microsoft.azure.storage.blob.BlobOutputStreamInternal$1.call(BlobOutputStreamInternal.java:406)
                  at com.microsoft.azure.storage.blob.BlobOutputStreamInternal$1.call(BlobOutputStreamInternal.java:403)
                  at java.util.concurrent.FutureTask.run(FutureTask.java:266)
                  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
                  at java.util.concurrent.FutureTask.run(FutureTask.java:266)
                  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
                  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
                  at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If the flush gets IOE, we will have retry at our end. But here as it throws IllegalArgumentException we end up aborting RS&lt;/p&gt;




</comment>
                            <comment id="17087873" author="anoop.hbase" created="Mon, 20 Apr 2020 15:48:59 +0000"  >&lt;blockquote&gt;&lt;p&gt;Patches up on github as PRs for review&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Bit busy with some other stuff.. Surely will do after that. Tks.&lt;/p&gt;</comment>
                            <comment id="17088658" author="ram_krish" created="Tue, 21 Apr 2020 13:06:38 +0000"  >&lt;p&gt;+1 on patch&apos;s approach. (non binding). We need test anyway. &lt;/p&gt;</comment>
                            <comment id="17134913" author="anoop.hbase" created="Sat, 13 Jun 2020 17:52:28 +0000"  >&lt;p&gt;PR raised &lt;a href=&quot;https://github.com/apache/hadoop/pull/2073&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/2073&lt;/a&gt;&lt;br/&gt;
Pls help with review.  Ping &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17141305" author="anoop.hbase" created="Sun, 21 Jun 2020 05:46:29 +0000"  >&lt;p&gt;Thanks all for the reviews..  Fixed the comments in latest PR.&lt;/p&gt;
</comment>
                            <comment id="17157359" author="hudson" created="Tue, 14 Jul 2020 13:24:46 +0000"  >&lt;p&gt;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #18432 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/18432/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/18432/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-16998&quot; title=&quot;WASB : NativeAzureFsOutputStream#close() throwing IllegalArgumentException&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-16998&quot;&gt;&lt;del&gt;HADOOP-16998&lt;/del&gt;&lt;/a&gt;. WASB : NativeAzureFsOutputStream#close() throwing (github: rev 380e0f4506a818d6337271ae6d996927f70b601b)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;(edit) hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azure/SyncableDataOutputStream.java&lt;/li&gt;
	&lt;li&gt;(add) hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azure/TestSyncableDataOutputStream.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="17157427" author="stevel@apache.org" created="Tue, 14 Jul 2020 14:32:46 +0000"  >&lt;p&gt;Fixed in Hadoop 3.3.1&lt;/p&gt;</comment>
                            <comment id="17157637" author="ayushtkn" created="Tue, 14 Jul 2020 19:48:05 +0000"  >&lt;p&gt;Seems this is in trunk as well, &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt; Should we add 3.4.0 as well in the fix version?&lt;/p&gt;</comment>
                            <comment id="17159757" author="liuml07" created="Fri, 17 Jul 2020 07:53:31 +0000"  >&lt;p&gt;Yes &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ayushtkn&quot; class=&quot;user-hover&quot; rel=&quot;ayushtkn&quot;&gt;ayushtkn&lt;/a&gt;. I have updated the &quot;fixed versions&quot;. Thanks!&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13277342">HADOOP-16785</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13000472" name="HADOOP-16998.patch" size="2316" author="anoop.hbase" created="Mon, 20 Apr 2020 04:47:35 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 17 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0dsfc:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>