<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:56:32 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-17096] Fix ZStandardCompressor input buffer offset</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-17096</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;A bug in index handling causes ZStandardCompressor.c to pass a malformed&#160;ZSTD_inBuffer to libzstd. libzstd then returns an &quot;Error (generic)&quot; that gets thrown. The crux of the issue is two variables, uncompressedDirectBufLen and uncompressedDirectBufOff. The hadoop code counts uncompressedDirectBufOff from the start of uncompressedDirectBuf, then uncompressedDirectBufLen is counted from uncompressedDirectBufOff. However, libzstd considers pos and size to both be counted from the start of the buffer. As a result, this line&#160;&lt;a href=&quot;https://github.com/apache/hadoop/blob/rel/release-3.2.1/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/zstd/ZStandardCompressor.c#L228&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/rel/release-3.2.1/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/zstd/ZStandardCompressor.c#L228&lt;/a&gt;&#160;causes a malformed buffer to be passed to libzstd, where pos&amp;gt;size.&#160;Here&apos;s a longer description of the bug in case this abstract explanation is unclear:&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Suppose we initialize uncompressedDirectBuf (via setInputFromSavedData) with five bytes of input. This results in uncompressedDirectBufOff=0 and uncompressedDirectBufLen=5 (&lt;a href=&quot;https://github.com/apache/hadoop/blob/rel/release-3.2.1/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/zstd/ZStandardCompressor.java#L140-L146&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/rel/release-3.2.1/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/compress/zstd/ZStandardCompressor.java#L140-L146&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Then we call compress(), which initializes a ZSTD_inBuffer (&lt;a href=&quot;https://github.com/apache/hadoop/blob/rel/release-3.2.1/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/zstd/ZStandardCompressor.c#L195-L196&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/rel/release-3.2.1/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/zstd/ZStandardCompressor.c#L195-L196&lt;/a&gt;). The definition of those libzstd structs is here &lt;a href=&quot;https://github.com/facebook/zstd/blob/v1.3.1/lib/zstd.h#L251-L261&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/facebook/zstd/blob/v1.3.1/lib/zstd.h#L251-L261&lt;/a&gt; - note that we set size=uncompressedDirectBufLen and pos=uncompressedDirectBufOff. The ZSTD_inBuffer gets passed to libzstd, compression happens, etc. When libzstd returns from the compression function, it updates the ZSTD_inBuffer struct to indicate how many bytes were consumed (&lt;a href=&quot;https://github.com/facebook/zstd/blob/v1.3.1/lib/compress/zstd_compress.c#L3919-L3920&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/facebook/zstd/blob/v1.3.1/lib/compress/zstd_compress.c#L3919-L3920&lt;/a&gt;). Note that pos is advanced, but size is unchanged.&lt;/p&gt;

&lt;p&gt;Now, libzstd does not guarantee that the entire input will be compressed in a single call of the compression function. (Some of the compression libraries used by hadoop, such as snappy, &lt;em&gt;do&lt;/em&gt; provide this guarantee, but libzstd is not one of them.) So the hadoop native code updates uncompressedDirectBufOff and uncompressedDirectBufLen using the updated ZSTD_inBuffer: &lt;a href=&quot;https://github.com/apache/hadoop/blob/rel/release-3.2.1/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/zstd/ZStandardCompressor.c#L227-L228&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/rel/release-3.2.1/hadoop-common-project/hadoop-common/src/main/native/src/org/apache/hadoop/io/compress/zstd/ZStandardCompressor.c#L227-L228&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Now, returning to our example, we started with 5 bytes of uncompressed input. Suppose libzstd compressed 4 of those bytes, leaving one unread. This would result in a ZSTD_inBuffer struct with size=5 (unchanged) and pos=4 (four bytes were consumed). The hadoop native code would then set uncompressedDirectBufOff=4, but it would also set uncompressedDirectBufLen=1 (five minus four equals one).&lt;/p&gt;

&lt;p&gt;Since some of the input was not consumed, we will eventually call compress() again. Then we instantiate another ZSTD_inBuffer struct, this time with size=1 and pos=4. This is a bug - libzstd expects size and pos to both be counted from the start of the buffer, therefore pos&amp;gt;size is unsound. So it returns an error &lt;a href=&quot;https://github.com/facebook/zstd/blob/v1.3.1/lib/compress/zstd_compress.c#L3932&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/facebook/zstd/blob/v1.3.1/lib/compress/zstd_compress.c#L3932&lt;/a&gt; which gets escalated as a java.lang.InternalError.&lt;/p&gt;

&lt;p&gt;I will be submitting a pull request on github with a fix for this bug. The key is that the hadoop code should handle offsets the same way libzstd does, ie uncompressedDirectBufLen should be counted from the start of uncompressedDirectBuf, not from uncompressedDirectBufOff.&lt;/p&gt;</description>
                <environment>&lt;p&gt;Our repro is on ubuntu xenial LTS, with hadoop 3.2.1 linking to libzstd 1.3.1. The bug is difficult to reproduce in an end-to-end environment (eg running an actual hadoop job with zstd compression) because it&apos;s very sensitive to the exact input and output characteristics. I reproduced the bug by turning one of the existing unit tests into a crude fuzzer, but I&apos;m not sure upstream will accept that patch, so I&apos;ve attached it separately on this ticket.&lt;/p&gt;

&lt;p&gt;Note that the existing unit test for&#160;testCompressingWithOneByteOutputBuffer fails to reproduce this bug. This is because it&apos;s using the license file as input, and this file is too small. libzstd has internal buffering (in our environment it seems to be 128 kilobytes), and the license file is only 10 kilobytes. Thus libzstd is able to consume all the input and compress it in a single call, then return pieces of its internal buffer one byte at a time. Since all the input is consumed in a single call, uncompressedDirectBufOff and uncompressedDirectBufLen are both set to zero and thus the bug does not reproduce.&lt;/p&gt;</environment>
        <key id="13313687">HADOOP-17096</key>
            <summary>Fix ZStandardCompressor input buffer offset</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">Major</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="sjung-stripe">Stephen Jung (Stripe)</assignee>
                                    <reporter username="sjung-stripe">Stephen Jung (Stripe)</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Fri, 26 Jun 2020 20:22:49 +0000</created>
                <updated>Mon, 21 Feb 2022 09:15:12 +0000</updated>
                            <resolved>Tue, 10 Nov 2020 19:44:05 +0000</resolved>
                                    <version>3.2.1</version>
                                    <fixVersion>3.2.2</fixVersion>
                    <fixVersion>3.3.1</fixVersion>
                    <fixVersion>3.4.0</fixVersion>
                                    <component>io</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="600">10m</timespent>
                                <comments>
                            <comment id="17146626" author="jojochuang" created="Fri, 26 Jun 2020 20:37:57 +0000"  >&lt;p&gt;Thanks for filing the jira. I wonder if it&apos;s related to a zstd bug my colleague found:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.mail-archive.com/common-dev@hadoop.apache.org/msg32307.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.mail-archive.com/common-dev@hadoop.apache.org/msg32307.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;we were unable to root cause it.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;A temporary workaround is to set buffer size &quot;set io.compression.codec.zstd.buffersize=8192;&quot;&lt;/p&gt;&lt;/blockquote&gt;</comment>
                            <comment id="17146639" author="sjung-stripe" created="Fri, 26 Jun 2020 21:03:54 +0000"  >&lt;p&gt;Yeah, your bug looks very similar to ours. The fact that buffer size fixed it for you makes me especially suspicious that you have the same problem as us. This bug only reproduces if the input buffer has to go through multiple rounds of compression, thus a larger output buffer or smaller input buffer can make it &quot;disappear&quot;.&lt;/p&gt;</comment>
                            <comment id="17229471" author="jojochuang" created="Tue, 10 Nov 2020 19:44:05 +0000"  >&lt;p&gt;Great fix. Thanks.&lt;br/&gt;
I&apos;m really sorry it took so long to review it.&lt;/p&gt;</comment>
                            <comment id="17239961" author="hexiaoqiao" created="Sat, 28 Nov 2020 13:17:45 +0000"  >&lt;p&gt;bulk update: backport to branch-3.2.2.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310000">
                    <name>Duplicate</name>
                                                                <inwardlinks description="is duplicated by">
                                        <issuelink>
            <issuekey id="13314197">HADOOP-17219</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13002509">HADOOP-13578</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13200576">HDFS-14099</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="13006562" name="fuzztest.patch" size="2049" author="sjung-stripe" created="Fri, 26 Jun 2020 20:23:45 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>1.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            4 years, 50 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0g8fs:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>