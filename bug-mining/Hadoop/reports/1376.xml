<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:46:47 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-11286] Map/Reduce dangerously adds Guava @Beta class to CryptoUtils</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-11286</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;See &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-7040&quot; title=&quot;HDFS dangerously uses @Beta methods from very old versions of Guava&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-7040&quot;&gt;&lt;del&gt;HDFS-7040&lt;/del&gt;&lt;/a&gt; for more background/details.&lt;/p&gt;

&lt;p&gt;In recent 2.6.0-SNAPSHOTs, the use of LimitInputStream was added to CryptoUtils. This is part of the API components of Hadoop, which severely impacts users who were utilizing newer versions of Guava, where the @Beta and @Deprecated class, LimitInputStream, has been removed (removed in version 15 and later), beyond the impact already experienced in 2.4.0 as identified in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-7040&quot; title=&quot;HDFS dangerously uses @Beta methods from very old versions of Guava&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-7040&quot;&gt;&lt;del&gt;HDFS-7040&lt;/del&gt;&lt;/a&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12740623">HADOOP-11286</key>
            <summary>Map/Reduce dangerously adds Guava @Beta class to CryptoUtils</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.svg">Blocker</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="ctubbsii">Christopher Tubbs</reporter>
                        <labels>
                            <label>beta</label>
                            <label>deprecated</label>
                            <label>guava</label>
                    </labels>
                <created>Wed, 10 Sep 2014 22:00:31 +0000</created>
                <updated>Thu, 29 Jan 2015 06:47:28 +0000</updated>
                            <resolved>Sun, 9 Nov 2014 13:27:19 +0000</resolved>
                                    <version>2.6.0</version>
                                    <fixVersion>2.6.0</fixVersion>
                                        <due></due>
                            <votes>1</votes>
                                    <watches>3</watches>
                                                                                                                <comments>
                            <comment id="14129210" author="ctubbsii" created="Wed, 10 Sep 2014 22:03:01 +0000"  >&lt;p&gt;The changes in &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-6134&quot; title=&quot;Transparent data at rest encryption&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-6134&quot;&gt;&lt;del&gt;HDFS-6134&lt;/del&gt;&lt;/a&gt; and &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-10150&quot; title=&quot;Hadoop cryptographic file system&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-10150&quot;&gt;&lt;del&gt;HADOOP-10150&lt;/del&gt;&lt;/a&gt; appear to have introduced this additional breakage for downstream users.&lt;/p&gt;</comment>
                            <comment id="14129237" author="ctubbsii" created="Wed, 10 Sep 2014 22:16:08 +0000"  >&lt;p&gt;Attached patch to CryptoUtils, &lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12667871/12667871_0001-MAPREDUCE-6083-Avoid-client-use-of-deprecated-LimitI.patch&quot; title=&quot;0001-MAPREDUCE-6083-Avoid-client-use-of-deprecated-LimitI.patch attached to HADOOP-11286&quot;&gt;0001-MAPREDUCE-6083-Avoid-client-use-of-deprecated-LimitI.patch&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt; for the 2.6.0-SNAPSHOT branch. (Bumps Guava dependency to version 14.0.1, which is the last version with both LimitInputStream and the alternative, in order to minimize impact with maximal benefit.)&lt;/p&gt;</comment>
                            <comment id="14129288" author="hadoopqa" created="Wed, 10 Sep 2014 22:48:56 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12667871/12667871_0001-MAPREDUCE-6083-Avoid-client-use-of-deprecated-LimitI.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12667871/12667871_0001-MAPREDUCE-6083-Avoid-client-use-of-deprecated-LimitI.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 7d38ffc.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;      &lt;font color=&quot;red&quot;&gt;-1 javac&lt;/font&gt;.  The applied patch generated 1293 javac compiler warnings (more than the trunk&apos;s current 1264 warnings).&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  There were no new javadoc warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//testReport/&lt;/a&gt;&lt;br/&gt;
Javac warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//artifact/trunk/patchprocess/diffJavacWarnings.txt&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//artifact/trunk/patchprocess/diffJavacWarnings.txt&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/4866//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14159089" author="gwdfl59u" created="Sat, 4 Oct 2014 11:53:31 +0000"  >&lt;p&gt;Does this patch also remove the use of LimitInputStream in other parts of Hadoop? For example, in MiniDFSCluster?&lt;/p&gt;</comment>
                            <comment id="14159090" author="gwdfl59u" created="Sat, 4 Oct 2014 11:55:35 +0000"  >&lt;p&gt;version 2.5.1:&lt;/p&gt;

&lt;p&gt;java.lang.NoClassDefFoundError: com/google/common/io/LimitInputStream&lt;br/&gt;
	at java.net.URLClassLoader$1.run(URLClassLoader.java:366)&lt;br/&gt;
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)&lt;br/&gt;
	at java.security.AccessController.doPrivileged(Native Method)&lt;br/&gt;
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)&lt;br/&gt;
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)&lt;br/&gt;
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)&lt;br/&gt;
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSImageFormat$LoaderDelegator.load(FSImageFormat.java:223)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:913)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:899)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:722)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:660)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.&amp;lt;init&amp;gt;(NameNode.java:751)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.&amp;lt;init&amp;gt;(NameNode.java:735)&lt;br/&gt;
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:998)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:869)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:704)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster.&amp;lt;init&amp;gt;(MiniDFSCluster.java:376)&lt;br/&gt;
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:357)&lt;br/&gt;
	at de.mstier.hadoop.WordCountTest.setUp(WordCountTest.java:65)&lt;/p&gt;</comment>
                            <comment id="14159218" author="ctubbsii" created="Sat, 4 Oct 2014 17:20:19 +0000"  >&lt;blockquote&gt;&lt;p&gt;Does this patch also remove the use of LimitInputStream in other parts of Hadoop? For example, in MiniDFSCluster?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;No. See the referenced &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-7040&quot; title=&quot;HDFS dangerously uses @Beta methods from very old versions of Guava&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-7040&quot;&gt;&lt;del&gt;HDFS-7040&lt;/del&gt;&lt;/a&gt;. This only mitigates the new problem introduced in 2.6.0. &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-7040&quot; title=&quot;HDFS dangerously uses @Beta methods from very old versions of Guava&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-7040&quot;&gt;&lt;del&gt;HDFS-7040&lt;/del&gt;&lt;/a&gt; addresses the issue introduced in 2.4.0, which is limited to MiniDFSCluster. This problem is worse, though, because it directly impacts many more users than the MiniDFSCluster one.&lt;/p&gt;</comment>
                            <comment id="14172896" author="ctubbsii" created="Wed, 15 Oct 2014 20:39:25 +0000"  >&lt;p&gt;Would this be more likely to be accepted for 2.6.0 if it were provided as a copied/re-implemented version of LimitInputStream instead of a dependency version change?&lt;/p&gt;</comment>
                            <comment id="14198360" author="acmurthy" created="Wed, 5 Nov 2014 13:28:32 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ctubbsii&quot; class=&quot;user-hover&quot; rel=&quot;ctubbsii&quot;&gt;ctubbsii&lt;/a&gt; - Apologies for the late response. Unfortunately, we can&apos;t change guava versions in 2.6 since it would be incompatible. &lt;/p&gt;</comment>
                            <comment id="14199565" author="ctubbsii" created="Thu, 6 Nov 2014 01:27:58 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=acmurthy&quot; class=&quot;user-hover&quot; rel=&quot;acmurthy&quot;&gt;acmurthy&lt;/a&gt;: I understand. What about my previous question, about whether a fix would be accepted if implemented as a copied/re-implemented version of LimitInputStream instead of a guava version change?&lt;/p&gt;</comment>
                            <comment id="14199694" author="acmurthy" created="Thu, 6 Nov 2014 03:01:46 +0000"  >&lt;p&gt;Yes, I&apos;m cool with that. Tx!&lt;/p&gt;</comment>
                            <comment id="14202774" author="ctubbsii" created="Fri, 7 Nov 2014 21:59:09 +0000"  >&lt;p&gt;Uploading a new patch (&lt;span class=&quot;nobr&quot;&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12680280/12680280_0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch&quot; title=&quot;0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch attached to HADOOP-11286&quot;&gt;0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch&lt;sup&gt;&lt;img class=&quot;rendericon&quot; src=&quot;https://issues.apache.org/jira/images/icons/link_attachment_7.gif&quot; height=&quot;7&quot; width=&quot;7&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt;) which copies the HBase solution for the same issue. It also incidentally adds &lt;a href=&quot;https://issues.apache.org/jira/browse/HDFS-7040&quot; title=&quot;HDFS dangerously uses @Beta methods from very old versions of Guava&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HDFS-7040&quot;&gt;&lt;del&gt;HDFS-7040&lt;/del&gt;&lt;/a&gt;, which is the other places where LimitInputStream is used (but only for version 2.6.0 and later).&lt;/p&gt;</comment>
                            <comment id="14203318" author="hadoopqa" created="Sat, 8 Nov 2014 08:33:23 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12680280/12680280_0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12680280/12680280_0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 9a4e0d3.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 tests included&lt;/font&gt;.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  There were no new javadoc warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5001//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5001//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5001//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5001//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14203687" author="hadoopqa" created="Sat, 8 Nov 2014 23:40:28 +0000"  >&lt;p&gt;&lt;font color=&quot;red&quot;&gt;-1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12680280/12680280_0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12680280/12680280_0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision 6caa810.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;red&quot;&gt;-1 patch&lt;/font&gt;.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/5053//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/5053//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="14203688" author="hudson" created="Sat, 8 Nov 2014 23:52:59 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-trunk-Commit #6493 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/6493/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/6493/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11286&quot; title=&quot;Map/Reduce dangerously adds Guava @Beta class to CryptoUtils&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11286&quot;&gt;&lt;del&gt;HADOOP-11286&lt;/del&gt;&lt;/a&gt;. Copied LimitInputStream from guava-0.14 to hadoop to avoid issues with newer versions of guava in applications. Contributed by Christopher Tubbs. (acmurthy: rev 6caa8100d5d2547e34356dc279fd5e65b81a925a)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java&lt;/li&gt;
	&lt;li&gt;hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/CryptoUtils.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14203887" author="hudson" created="Sun, 9 Nov 2014 11:31:39 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Yarn-trunk #738 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/738/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/738/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11286&quot; title=&quot;Map/Reduce dangerously adds Guava @Beta class to CryptoUtils&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11286&quot;&gt;&lt;del&gt;HADOOP-11286&lt;/del&gt;&lt;/a&gt;. Copied LimitInputStream from guava-0.14 to hadoop to avoid issues with newer versions of guava in applications. Contributed by Christopher Tubbs. (acmurthy: rev 6caa8100d5d2547e34356dc279fd5e65b81a925a)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java&lt;/li&gt;
	&lt;li&gt;hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/CryptoUtils.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14203916" author="acmurthy" created="Sun, 9 Nov 2014 13:27:19 +0000"  >&lt;p&gt;I just committed this. Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ctubbsii&quot; class=&quot;user-hover&quot; rel=&quot;ctubbsii&quot;&gt;ctubbsii&lt;/a&gt;!&lt;/p&gt;</comment>
                            <comment id="14203930" author="hudson" created="Sun, 9 Nov 2014 14:18:07 +0000"  >&lt;p&gt;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1928 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1928/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1928/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11286&quot; title=&quot;Map/Reduce dangerously adds Guava @Beta class to CryptoUtils&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11286&quot;&gt;&lt;del&gt;HADOOP-11286&lt;/del&gt;&lt;/a&gt;. Copied LimitInputStream from guava-0.14 to hadoop to avoid issues with newer versions of guava in applications. Contributed by Christopher Tubbs. (acmurthy: rev 6caa8100d5d2547e34356dc279fd5e65b81a925a)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java&lt;/li&gt;
	&lt;li&gt;hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/CryptoUtils.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="14203958" author="hudson" created="Sun, 9 Nov 2014 15:16:28 +0000"  >&lt;p&gt;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1952 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1952/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1952/&lt;/a&gt;)&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-11286&quot; title=&quot;Map/Reduce dangerously adds Guava @Beta class to CryptoUtils&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-11286&quot;&gt;&lt;del&gt;HADOOP-11286&lt;/del&gt;&lt;/a&gt;. Copied LimitInputStream from guava-0.14 to hadoop to avoid issues with newer versions of guava in applications. Contributed by Christopher Tubbs. (acmurthy: rev 6caa8100d5d2547e34356dc279fd5e65b81a925a)&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/LimitInputStream.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FSImageLoader.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/FileDistributionCalculator.java&lt;/li&gt;
	&lt;li&gt;hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/CryptoUtils.java&lt;/li&gt;
	&lt;li&gt;hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.java&lt;/li&gt;
	&lt;li&gt;hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12740621">HDFS-7040</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12765850">HADOOP-11470</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12679226">HADOOP-10101</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12739507">ACCUMULO-3100</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is broken by">
                                        <issuelink>
            <issuekey id="12666081">HADOOP-10150</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12702810">HDFS-6134</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12667871" name="0001-MAPREDUCE-6083-Avoid-client-use-of-deprecated-LimitI.patch" size="2834" author="ctubbsii" created="Wed, 10 Sep 2014 22:16:08 +0000"/>
                            <attachment id="12680280" name="0001-MAPREDUCE-6083-and-HDFS-7040-Avoid-Guava-s-LimitInpu.patch" size="9444" author="ctubbsii" created="Fri, 7 Nov 2014 21:59:09 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            11 years, 2 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i1zwh3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12327179">2.6.0</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>