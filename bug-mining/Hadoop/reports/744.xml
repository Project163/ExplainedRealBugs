<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:42:13 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-6762] exception while doing RPC I/O closes channel</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-6762</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;If a single process creates two unique fileSystems to the same NN using FileSystem.newInstance(), and one of them issues a close(), the leasechecker thread is interrupted.  This interrupt races with the rpc namenode.renew() and can cause a ClosedByInterruptException.  This closes the underlying channel and the other filesystem, sharing the connection will get errors.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12464362">HADOOP-6762</key>
            <summary>exception while doing RPC I/O closes channel</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">Critical</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="rash37">sam rash</assignee>
                                    <reporter username="rash37">sam rash</reporter>
                        <labels>
                    </labels>
                <created>Wed, 12 May 2010 16:24:40 +0000</created>
                <updated>Thu, 30 Jun 2022 22:57:55 +0000</updated>
                            <resolved>Mon, 10 Dec 2012 21:26:01 +0000</resolved>
                                    <version>0.20.2</version>
                                    <fixVersion>2.0.3-alpha</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>18</watches>
                                                                                                                <comments>
                            <comment id="12866619" author="rash37" created="Wed, 12 May 2010 16:28:52 +0000"  >&lt;p&gt;the general problem is that &apos;client&apos; threads hold the socket and do writes to it to send RPCs.  If a client thread receives an interrupt, it will leave the socket in an unusable state. &lt;/p&gt;

&lt;p&gt;i have a test for this general case and a patch which moves the actual writing to the socket to a thread owned by the Client object.  This means a client can be interrupted and not ruin the socket for other clients.&lt;/p&gt;

&lt;p&gt;note:  other socket errors may occur that make the socket unusable. The patch doesn&apos;t handle this (only intended to help with interrupted cases since that is common with filesystem.close).&lt;/p&gt;

&lt;p&gt;we might also want to consider finding a way to fail fast when RPC goes bad.  Near as I can tell from watching this happen, until the filesystem is closed, the underlying RPC is in a bad state.  It seems like we could fail on one operation, detect the bad socket and perhaps recreate the socket or the whole RPC object.  not sure where this retry logic goes&lt;/p&gt;</comment>
                            <comment id="12866647" author="rash37" created="Wed, 12 May 2010 17:36:33 +0000"  >&lt;p&gt;test uses MiniDFSCluster and includes a patch to it.  i might need to make a test case that doesn&apos;t rely on hdfs testing utils&lt;/p&gt;</comment>
                            <comment id="12867216" author="rash37" created="Thu, 13 May 2010 18:57:08 +0000"  >&lt;p&gt;updated test to not used MiniDFSCluster&lt;/p&gt;</comment>
                            <comment id="12867312" author="rash37" created="Thu, 13 May 2010 23:34:40 +0000"  >&lt;p&gt;1. previous patch had a bug where a race condition could cause indefinite hang of the client&lt;br/&gt;
2. cleaned up case of close by shutting down executor (speeds up shutdown as thread is interrupted)&lt;/p&gt;</comment>
                            <comment id="12870941" author="rash37" created="Tue, 25 May 2010 01:34:55 +0000"  >&lt;p&gt;unit tests would hang since threads in executor were not daemon threads.  change to daemon threads&lt;/p&gt;</comment>
                            <comment id="12874977" author="tlipcon" created="Thu, 3 Jun 2010 06:39:25 +0000"  >&lt;p&gt;Hey Sam. Is it not sufficient to simply add a &quot;this.interrupt()&quot; in the catch clause of sendParams?&lt;/p&gt;

&lt;p&gt;I was running into an occasional issue with 1 minute pauses during DFSClient pipeline recovery, and I think it&apos;s due to this issue. I added this.interrupt() and it seems to pass test case, I&apos;ll see if it also fixes my 1 minute pauses.&lt;/p&gt;</comment>
                            <comment id="12875140" author="rash37" created="Thu, 3 Jun 2010 15:08:39 +0000"  >&lt;p&gt;so you mean add Thread.currentThread.interrupt() above markClosed(e) ?  I don&apos;t think this fixes the underlying problem.&lt;/p&gt;

&lt;p&gt;The problem is if a channel is doing a wait for IO and an interrupt comes in, you get a ClosedByInterrupt exception&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://java.sun.com/javase/6/docs/api/java/nio/channels/ClosedByInterruptException.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://java.sun.com/javase/6/docs/api/java/nio/channels/ClosedByInterruptException.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;from the doc, this closes the channel and sets the interrupt status (ie interrupt() shouldn&apos;t have an effect--means my test doesn&apos;t repro the same thing I saw).&lt;br/&gt;
What I then saw was that other RPC instances using the same channel would get ChannelClosedException.  The only way to avoid this in the FileSystem case was to move the thread that uses the channel to its own so the lease checker won&apos;t interrupt it.&lt;/p&gt;

&lt;p&gt;I&apos;ll play with the test case and see why your change makes it pass when it doesn&apos;t seem like it can&apos;t fix the underlying problem&lt;/p&gt;</comment>
                            <comment id="12875193" author="rash37" created="Thu, 3 Jun 2010 17:09:24 +0000"  >&lt;p&gt;maybe you can elaborate on where you are adding the interrupt() call as trying what I understand you to have suggested didn&apos;t make the test pass.&lt;/p&gt;

&lt;p&gt;Is this what you mean for sendParam:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void sendParam(Call call) {
      &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (shouldCloseConnection.get()) {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt;;
      }

      DataOutputBuffer d=&lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;;
      &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt; {
        &lt;span class=&quot;code-keyword&quot;&gt;synchronized&lt;/span&gt; (&lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;.out) {
          &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (LOG.isDebugEnabled())
            LOG.debug(getName() + &lt;span class=&quot;code-quote&quot;&gt;&quot; sending #&quot;&lt;/span&gt; + call.id);
          
          &lt;span class=&quot;code-comment&quot;&gt;//&lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; serializing the
&lt;/span&gt;          &lt;span class=&quot;code-comment&quot;&gt;//data to be written
&lt;/span&gt;          d = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DataOutputBuffer();
          d.writeInt(call.id);
          call.param.write(d);
          &lt;span class=&quot;code-object&quot;&gt;byte&lt;/span&gt;[] data = d.getData();
          &lt;span class=&quot;code-object&quot;&gt;int&lt;/span&gt; dataLength = d.getLength();
          out.writeInt(dataLength);      &lt;span class=&quot;code-comment&quot;&gt;//first put the data length
&lt;/span&gt;          out.write(data, 0, dataLength);&lt;span class=&quot;code-comment&quot;&gt;//write the data
&lt;/span&gt;          out.flush();
        }
      } &lt;span class=&quot;code-keyword&quot;&gt;catch&lt;/span&gt;(IOException e) {
        &lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.currentThread().interrupt(); &lt;span class=&quot;code-comment&quot;&gt;//add &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt;--should have no effect on ClosedByInterrupt as it sets the current thread to be interrupted already
&lt;/span&gt;        markClosed(e);
      } &lt;span class=&quot;code-keyword&quot;&gt;finally&lt;/span&gt; {
        &lt;span class=&quot;code-comment&quot;&gt;//the buffer is just an in-memory buffer, but it is still polite to
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// close early
&lt;/span&gt;        IOUtils.closeStream(d);
      }
    }  
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="12875197" author="tlipcon" created="Thu, 3 Jun 2010 17:18:58 +0000"  >&lt;p&gt;Hey Sam. Instead of Thread.currentThread().interrupt(), I mean this.interrupt(), in order to interrupt the Connection thread (not the caller thread).&lt;/p&gt;</comment>
                            <comment id="12875200" author="rash37" created="Thu, 3 Jun 2010 17:26:46 +0000"  >&lt;p&gt;sorry, I&apos;m still confused--once you catch the IOException here, the channel is closed.  How does interrupting the Connection help avoid this?&lt;/p&gt;</comment>
                            <comment id="12875203" author="rash37" created="Thu, 3 Jun 2010 17:29:43 +0000"  >&lt;p&gt;maybe my test case is not sufficiently deterministic so it works differently for you.  I replaced &quot;Thread.currentThread.interrupt()&quot; with &quot;this.interrupt()&quot; in the code I pasted above.  &lt;/p&gt;

&lt;p&gt;The test still fails&lt;br/&gt;
(and regardless, I don&apos;t think that can affect the underlying problem that if something interrupts a thread that is doing RPC and that thread is blocked on the channel, it gets closed automatically)&lt;/p&gt;</comment>
                            <comment id="12875380" author="rash37" created="Fri, 4 Jun 2010 00:15:03 +0000"  >&lt;p&gt;improved test case: runs 200 threads doing rpc via the same connection.  shows that interrupting one can cause errors in the others.&lt;/p&gt;</comment>
                            <comment id="12875382" author="rash37" created="Fri, 4 Jun 2010 00:16:58 +0000"  >&lt;p&gt;had unnecessary Runnable cast&lt;/p&gt;</comment>
                            <comment id="12875383" author="rash37" created="Fri, 4 Jun 2010 00:18:49 +0000"  >&lt;p&gt;todd : you can try this.interrupt() now.  please let me know if it passes the new test case&lt;/p&gt;</comment>
                            <comment id="12875406" author="tlipcon" created="Fri, 4 Jun 2010 01:17:28 +0000"  >&lt;p&gt;Hey Sam. Sorry, I misunderstood your point earlier. You&apos;re definitely right that interrupting one thread shouldn&apos;t take down the RPC connection.&lt;/p&gt;

&lt;p&gt;Adding yet another thread to IPC seems a bit complicated, though. What about if we added a flag to Connection saying &quot;no more sends on this connection&quot;, so that interrupting the sender did kill the connection but lets currently pending calls complete? Then when the queue has been quiesced the connection shuts down like it does today?&lt;/p&gt;

&lt;p&gt;The issue I&apos;m thinking is that we solve the interrupt problem, but don&apos;t solve the general case of exceptions during sendparam. The user can still have a Writable which eg throws an NPE, and we&apos;re back to the same problem of lack of isolation between writers.&lt;/p&gt;</comment>
                            <comment id="12875411" author="rash37" created="Fri, 4 Jun 2010 01:27:23 +0000"  >&lt;p&gt;Hmm, how would pending calls complete?  They already have a Connection object with a socket channel that is in bad shape.  basically there would have to be a check inside a sync block that the channel is valid before sending.  If it&apos;s not, it would have to create a new socket (or whole Connection, again all in sync block).  Does this make sense?  A bunch of threads get the Connection object and pile up on the synchronized(this.out) and if one of them is interrupted, the whole pile will get errors.  I think having the test &amp;amp; fix code is more complicated than using another thread actually, but I may be biased (having already done it the other way)&lt;/p&gt;

&lt;p&gt;FWIW, we&apos;re already using this on our 0.20 branch in production where we have up to 200+ threads using the same RPC instance.&lt;/p&gt;

&lt;p&gt;also, i don&apos;t actually think the code is complex--it&apos;s using an executor so the thread management is as simple as it can get. &lt;br/&gt;
We can even get rid of the latch--it&apos;s not necessary, but I wanted the change to function exactly as it does now, so I put it in.&lt;/p&gt;

</comment>
                            <comment id="12875413" author="tlipcon" created="Fri, 4 Jun 2010 01:29:51 +0000"  >&lt;p&gt;Hey Sam, that&apos;s a fair argument. Let me look over your patch more closely. Do you have this against 0.20 as well? The test case I have that caused me to notice this is an 0.20 based cluster test.&lt;/p&gt;</comment>
                            <comment id="12875415" author="tlipcon" created="Fri, 4 Jun 2010 01:38:22 +0000"  >&lt;p&gt;oh, i see now that this essentially applies to 20 without changes. Will try it out and let you know.&lt;/p&gt;</comment>
                            <comment id="12875416" author="rash37" created="Fri, 4 Jun 2010 01:38:25 +0000"  >&lt;p&gt;This patch should largely work against 0.20.  I originally patched our 0.20 and then ported to trunk (which was mostly re-writing the test case)&lt;/p&gt;

&lt;p&gt;if this doesn&apos;t apply, let me know and i&apos;ll back-port this (including test case) to 0.20&lt;/p&gt;

&lt;p&gt;also, I do agree on one point about the extra thread:  while I don&apos;t see it as inherently complex, I do see it as an additional resource.  if we could solve it w/o the thread and similar in code complexity, that would be the superior solution imo&lt;/p&gt;</comment>
                            <comment id="12875421" author="tlipcon" created="Fri, 4 Jun 2010 01:53:34 +0000"  >&lt;p&gt;Looking at the code:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Instead of using the CountdownLatch, can you change the Runnable to a Callable&amp;lt;Void&amp;gt;() and then get back a Future&amp;lt;Void&amp;gt;? Seems a little cleaner.&lt;/li&gt;
	&lt;li&gt;The behavior is different since we&apos;ve added a timeout waiting to sendParam. Do you think this change is necessary? (under what case would we block forever waiting to write?)&lt;/li&gt;
	&lt;li&gt;Regarding the issue I raised above with a Writable param that throws NPE, can we move the actual buffer construction back into the calling thread? Then if it throws an RTE, the user will see it (rather than it getting lost somewhere). There&apos;s still an issue that this will leave the call on the connection queue, but that&apos;s probably worth a separate jira.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Regarding the resource usage issue: can we just use a static  cachedthreadpool that&apos;s shared across all of RPC for sending params? In the common case it would only have 0 or 1 threads but it could grow as necessary and then shrink back when idle.&lt;/p&gt;</comment>
                            <comment id="12875424" author="rash37" created="Fri, 4 Jun 2010 02:07:33 +0000"  >&lt;p&gt;thanks for reviewing the patch so quickly.  &lt;/p&gt;

&lt;p&gt;1. latch : I agree.  I&apos;ll change it to use a future &amp;amp; get (with timeout, see #2).&lt;/p&gt;

&lt;p&gt;2. actually the timeout helped me debug a switch issue today.  I would see a flurry of timeouts when I saturated a switch that wasn&apos;t performing to spec.  getting the timeouts was far preferable than hanging indefinitely.  i agree it changes the behavior, but it&apos;s the same we do pings at I think.  Also, playing a game of adversary, &lt;b&gt;if&lt;/b&gt; somehow the connection thread in the executor did die, the latch would hang indefinitely.&lt;/p&gt;

&lt;p&gt;perhaps the timeout value should be something else? I choose the timeout value that was used to connect the socket (pingInterval) as it seemed appropriate.&lt;/p&gt;

&lt;p&gt;3. ah, i misread your comment above--that&apos;s a great idea.  Only the actual push out the socket needs to be in critical section (in theory could improve perf a tiny bit).&lt;/p&gt;

&lt;p&gt;I&apos;ll get to the changes and post another patch.&lt;/p&gt;</comment>
                            <comment id="12875426" author="tlipcon" created="Fri, 4 Jun 2010 02:11:52 +0000"  >&lt;p&gt;re timeout: I&apos;m a little nervous about such a change in the semantics of IPC at this point. The ping system ensures that the other side isn&apos;t completely dead, so some people use IPCs that are &lt;b&gt;supposed&lt;/b&gt; to take a really long time, and rely on ping to know it&apos;s at least still connected. Maybe if you find it useful you could introduce a new parameter for the IPC timeout, and have it default to 0 (no timeout?)&lt;/p&gt;

&lt;p&gt;I could also see a situation where we wait for the ping time, and then print a LOG.warn(&quot;IPC call Protocol.callName to &amp;lt;IP&amp;gt; still waiting after 60000ms&quot;) once every ping interval. This would help debugging without changing behavior. (I too have often wished for such a thing)&lt;/p&gt;</comment>
                            <comment id="12875427" author="tlipcon" created="Fri, 4 Jun 2010 02:15:15 +0000"  >&lt;p&gt;Hey Sam,&lt;/p&gt;

&lt;p&gt;My cluster test case just spat out a nice warning and then deadlocked my DFS client:&lt;/p&gt;

&lt;p&gt;10/06/03 18:48:54 WARN hdfs.DFSClient: Error Recovery for block blk_832465809601113490_3336818 in pipeline 192.168.42.40:11072, 192.168.42.41:11072, 192.168.42.43:11072: bad datanode 192.168.42.41:11072&lt;br/&gt;
Exception in thread &quot;DataStreamer for file /user/todd/test-sync block blk_832465809601113490_3336818&quot; java.lang.reflect.UndeclaredThrowableException&lt;br/&gt;
        at $Proxy1.getProtocolVersion(Unknown Source)&lt;br/&gt;
        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)&lt;br/&gt;
        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:346)&lt;br/&gt;
        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:383)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient.createClientDatanodeProtocolProxy(DFSClient.java:146)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2627)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$1600(DFSClient.java:2139)&lt;br/&gt;
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2306)&lt;br/&gt;
Caused by: java.lang.InterruptedException&lt;br/&gt;
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1238)&lt;br/&gt;
        at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:253)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:526)&lt;br/&gt;
        at org.apache.hadoop.ipc.Client.call(Client.java:765)&lt;br/&gt;
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)&lt;br/&gt;
        ... 8 more&lt;/p&gt;

&lt;p&gt;I think we need to add another catch (InterruptedException) and rethrow as IOException around the sendParam call in Client.call&lt;/p&gt;</comment>
                            <comment id="12875428" author="rash37" created="Fri, 4 Jun 2010 02:15:48 +0000"  >&lt;p&gt;forgot to comment on static cachedThreadPool:&lt;/p&gt;

&lt;p&gt;This concerns me as if we don&apos;t bound the size of this, we could get a massive # of threads;  if we do bound it, then it seems to me we might have some form of deadlock possible where one RPC depends on another (indirectly) and due to limited threads, it can&apos;t complete.  Basically we would want at least one thread per Connection, but no more (which is what have now)&lt;/p&gt;

&lt;p&gt;We have seem one case of distributed deadlock here on the IPC workers in the DN, so this isn&apos;t 100% theory&lt;/p&gt;

&lt;p&gt;While it is an extra resource, for simplicity and safety, I &lt;b&gt;do&lt;/b&gt; prefer one thread Connection.  &lt;/p&gt;

&lt;p&gt;What do you think?&lt;/p&gt;
</comment>
                            <comment id="12875429" author="rash37" created="Fri, 4 Jun 2010 02:16:42 +0000"  >&lt;p&gt;yea, we do need to catch the interruptedException--our 0.20 version had that.  i&apos;ll also add that one&lt;/p&gt;

&lt;p&gt;thx&lt;/p&gt;</comment>
                            <comment id="12875430" author="rash37" created="Fri, 4 Jun 2010 02:18:43 +0000"  >&lt;p&gt;re: timeout, so if a server disappeared, the ping would fail and the RPC would fail that way?  if that&apos;s the case, then I think removing the timeout on the Future.get() is fine. &lt;/p&gt;</comment>
                            <comment id="12875431" author="tlipcon" created="Fri, 4 Jun 2010 02:25:08 +0000"  >&lt;blockquote&gt;&lt;p&gt;re: timeout, so if a server disappeared, the ping would fail and the RPC would fail that way? if that&apos;s the case, then I think removing the timeout on the Future.get() is fine.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep, that should be the case. Of course a server can stay up but be unresponsive (eg deadlocked). In those cases, while it&apos;s annoying that clients get blocked forever, I don&apos;t know that changing the behavior to be timeout based would be a change we could really make at this point without worrying that it would break lots and lots of downstream users &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;We have seem one case of distributed deadlock here on the IPC workers in the DN, so this isn&apos;t 100% theory&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Yep, I&apos;ve seen internode deadlocks several times as well. Not pretty! However, I can&apos;t think of a situation where this could happen here &amp;#8211; the only thing that can block one of these sendParam calls is TCP backpressure on the socket, and that only happens when the network is stalled. I don&apos;t see a case where allowing other threads to start sending would have unstalled a prior sender.&lt;/p&gt;

&lt;p&gt;We could actually enforce the max one thread per connection thing by synchronizing on Connection.this.out &lt;b&gt;outside&lt;/b&gt; the submission of the runnable. That way we know there&apos;s only one sending going on at a time, and we&apos;re just using the thread exactly for avoiding interruption and nothing else.&lt;/p&gt;</comment>
                            <comment id="12875435" author="rash37" created="Fri, 4 Jun 2010 02:32:15 +0000"  >&lt;p&gt;hmm, actually with a Future, if there is a runtime exception, it&apos;ll show up as an ExecutionException on future.get(), so there isn&apos;t a need to move the buffer construction outside (requires another try/catch clause due to IOException).   We can use getCause() on the ExecutionException to find the underlying exception and use markClosed() if it&apos;s an IOException, and re-throw if it&apos;s a runtime exception (same behavior as now)&lt;/p&gt;

&lt;p&gt;or we can move it into the caller thread.  Using the future requires handling the ExecutionException anyway, so I sort of lean this way as it kills two birds. i don&apos;t know how much more parallelism we gain moving the buffer construction outside the sync block.&lt;/p&gt;

&lt;p&gt;what do you think?&lt;/p&gt;

</comment>
                            <comment id="12875437" author="tlipcon" created="Fri, 4 Jun 2010 02:39:13 +0000"  >&lt;p&gt;Either way seems cool. I&apos;ve never seen call param serialization be a bottleneck where parallelization would really help. Whichever one makes the code cleaner &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12875675" author="rash37" created="Fri, 4 Jun 2010 17:32:33 +0000"  >&lt;p&gt;I almost have an updated patch.  I loved the idea of sync on Connection.this.out around submit + wait, but this causes deadlock as the out.write() call inside is a synchronized function.  I instead sync&apos;d on the connection object itself (seems safe and gives the same result.  1 : 1 Connection/socket =&amp;gt; bounds the threads by the # of connections&lt;br/&gt;
(really, very clean/clever idea to optimize thread use)&lt;/p&gt;

&lt;p&gt;one catch with the static executor instance:  nothing ever shuts it down.  While this isn&apos;t an issue for actual execution, it won&apos;t cause unit tests to hang, will it?  (I made a thread factory that makes the threads daemons for this purpose)&lt;/p&gt;

&lt;p&gt;patch coming after i run a larger set of unit tests&lt;/p&gt;</comment>
                            <comment id="12875679" author="rash37" created="Fri, 4 Jun 2010 17:52:57 +0000"  >&lt;p&gt;1. changed to use Future.get() w/o timeout&lt;br/&gt;
2. static executor instance with cached thread instances (with daemon thread factory)&lt;br/&gt;
3. added catch of interruptedException around sendParams call to avoid undeclared throwable exception&lt;/p&gt;

&lt;p&gt;note : used a dedicated lock var around the submit + wait for a sendParams call.  I didn&apos;t want to worry about reasoning through lock contention/deadlock with synchronized methods (why I didn&apos;t synchronize on &quot;this&quot;)&lt;/p&gt;</comment>
                            <comment id="12875680" author="rash37" created="Fri, 4 Jun 2010 17:53:42 +0000"  >&lt;p&gt;btw, is it appropriate to delete the very old patches as they aren&apos;t really relevant?  or just leave them?&lt;/p&gt;</comment>
                            <comment id="12876060" author="rash37" created="Sun, 6 Jun 2010 17:04:33 +0000"  >&lt;p&gt;todd : actually i want open the timeout discussion back up.  I think there might be some confusion.  The 20s timeout that was there was &lt;b&gt;not&lt;/b&gt; on the RPC, but &lt;b&gt;only&lt;/b&gt; on sending the RPC.  Basically this is the time to write to the socket (which there might a timeout on the actual out.write call already--i need to double-check).&lt;/p&gt;

&lt;p&gt;The RPC itself still would have no timeout.&lt;/p&gt;

&lt;p&gt;let me know what you think.&lt;/p&gt;</comment>
                            <comment id="12876081" author="tlipcon" created="Sun, 6 Jun 2010 20:24:56 +0000"  >&lt;blockquote&gt;&lt;p&gt;btw, is it appropriate to delete the very old patches as they aren&apos;t really relevant? or just leave them?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Usually just leave them - makes it easier to follow the conversation and see how the patch evolved.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;(which there might a timeout on the actual out.write call already--i need to double-check)&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Looks like there is one - a timeout is set when NetUtils.getOutputStream is called on the socket in setupIOStreams(). So I don&apos;t think we need a separate timeout in awaiting the send param.&lt;/p&gt;


&lt;p&gt;I think the patch is good. I ran it with my test case since Friday night and didn&apos;t see any RPC hangs. The test case eventually failed with &quot;Too many open files&quot; but I think it&apos;s some other bug/socket leak in DFS code, not IPC. Mark Patch Available to swing it through Hudson?&lt;/p&gt;</comment>
                            <comment id="12876088" author="hadoopqa" created="Sun, 6 Jun 2010 21:20:04 +0000"  >&lt;p&gt;+1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12446356/hadoop-6762-7.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12446356/hadoop-6762-7.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision 951624.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/567/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/567/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/567/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/567/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/567/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/567/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/567/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/567/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12876205" author="umamahesh" created="Mon, 7 Jun 2010 11:27:22 +0000"  >&lt;p&gt;I applied the patch and ran this test continuously.&lt;br/&gt;
Seems still race condition is occuring randomly.&lt;br/&gt;
That means this patch is not working. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/sad.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="12876311" author="rash37" created="Mon, 7 Jun 2010 16:57:13 +0000"  >&lt;p&gt;can you elaborate on what you ran and what error messages + exceptions you saw in the test logs?  the thread that does the IO cannot receive an interrupt so if you are seeing an error, i don&apos;t think it can be the same one.&lt;/p&gt;</comment>
                            <comment id="12876322" author="rash37" created="Mon, 7 Jun 2010 17:29:17 +0000"  >&lt;p&gt;Actually, this might be an artifact of the test.  The threads in the executor&apos;s threadpool will be interrupted on shutdown.  the test doesn&apos;t wait for all of the threads to terminate gracefully before doing so.  This means there is a race in the test for rpc threads to finish before getting interrupted.  I have an updated test that uses a latch to wait for all threads to terminate before letting the test complete. I haven&apos;t been able to repro, but can post the patch this afternoon and let you try.&lt;/p&gt;

&lt;p&gt;please do still post what exception and any relevant looking log parts here.  it will help me ascertain if this is the case&lt;/p&gt;</comment>
                            <comment id="12876433" author="rash37" created="Mon, 7 Jun 2010 21:40:51 +0000"  >&lt;p&gt;turns out this is just a really bad case of logging.  the exception was a BrokenBarrierException and I wasn&apos;t logging the real exception.  changed that and fixed the test so this doesn&apos;t occur&lt;/p&gt;</comment>
                            <comment id="12876541" author="umamahesh" created="Tue, 8 Jun 2010 04:29:08 +0000"  >&lt;p&gt;testRPCInterrupted3:--&lt;br/&gt;
i also feel this may be the test problem.&lt;br/&gt;
 in this test, inside run method it is throwing the exception i.e java.util.concurrent.BrokenBarrierException&lt;br/&gt;
This is happening some times.&lt;br/&gt;
I added some wait to complete all the threads before assertion.&lt;br/&gt;
This is happenning randomly...most of the times passing the test.&lt;br/&gt;
Please post the latest test.&lt;/p&gt;</comment>
                            <comment id="12876546" author="rash37" created="Tue, 8 Jun 2010 05:02:46 +0000"  >&lt;p&gt;-8 is the latest.  i ran it 100 times and did not get any failures.  do you still see a failure with rev 8?  if so, I can do some more work with latches to tighten it up (right now I have a simple sleep that should allow the threads to get warmed up, and a latch to let them gracefully exit)&lt;/p&gt;</comment>
                            <comment id="12877262" author="eli" created="Wed, 9 Jun 2010 23:21:28 +0000"  >&lt;p&gt;-8 is identical to -7, did you mean to upload a different patch?&lt;/p&gt;</comment>
                            <comment id="12877286" author="rash37" created="Thu, 10 Jun 2010 01:26:41 +0000"  >&lt;p&gt;this is downright odd--if I click and view&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12446356/hadoop-6762-7.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12446356/hadoop-6762-7.txt&lt;/a&gt;&lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12446530/hadoop-6762-8.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12446530/hadoop-6762-8.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;they differ (the latter has a Thread.sleep() in the unit test)&lt;/p&gt;

&lt;p&gt;but grabbing with wget &lt;/p&gt;

&lt;p&gt;wget &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12446530/hadoop-6762-7.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12446530/hadoop-6762-7.txt&lt;/a&gt; --no-check-certificate&lt;br/&gt;
wget &lt;a href=&quot;https://issues.apache.org/jira/secure/attachment/12446530/hadoop-6762-8.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/secure/attachment/12446530/hadoop-6762-8.txt&lt;/a&gt; --no-check-certificate&lt;/p&gt;

&lt;p&gt;they both have the Thread.sleep()&lt;/p&gt;

&lt;p&gt;is something up with JIRA?  or what did I do?&lt;/p&gt;</comment>
                            <comment id="12877482" author="tlipcon" created="Thu, 10 Jun 2010 16:47:45 +0000"  >&lt;p&gt;Note that one of the path segments differs between the two URLs. I think it just pulls an attachment ID from that path segment and downloads that, regardless of the name at the end of the path (your two wget urls have the same path segment, I guess you manually edited the last bit?)&lt;/p&gt;</comment>
                            <comment id="12877488" author="rash37" created="Thu, 10 Jun 2010 17:00:04 +0000"  >&lt;p&gt;yes, I did &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;so the two patches do differ, probably in one line, Thread.sleep(1000);&lt;/p&gt;

&lt;p&gt;As I said, I ran ant test-core in a loop 100x and did not see the failure.  If someone does, though, I can do something more sophisticated in the test (like using another latch to make sure the leader has started before interrupting it and causing the BrokenBarrierException)&lt;/p&gt;

&lt;p&gt;let me know&lt;/p&gt;
</comment>
                            <comment id="12880057" author="tlipcon" created="Fri, 18 Jun 2010 02:56:15 +0000"  >&lt;p&gt;Hey Sam, one small thing in the newest patch: there are some unspecified generics - eg should be new AtomicReference&amp;lt;Throwable&amp;gt;, not just new AtomicReference. Otherwise we get some warnings compiling the tests.&lt;/p&gt;</comment>
                            <comment id="12880258" author="rash37" created="Fri, 18 Jun 2010 17:26:37 +0000"  >&lt;p&gt;AtomicReference typed now&lt;/p&gt;</comment>
                            <comment id="12883813" author="dhruba" created="Wed, 30 Jun 2010 07:13:43 +0000"  >&lt;p&gt;This looks ready for commit. Please resubmit to hadoopQA so that the final round of tests pass.&lt;/p&gt;</comment>
                            <comment id="12883954" author="hadoopqa" created="Wed, 30 Jun 2010 15:31:01 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12447484/hadoop-6762-9.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12447484/hadoop-6762-9.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision 957074.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/597/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/597/testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/597/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/597/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Checkstyle results: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/597/artifact/trunk/build/test/checkstyle-errors.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/597/artifact/trunk/build/test/checkstyle-errors.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/597/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/597/console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12883999" author="rash37" created="Wed, 30 Jun 2010 17:56:04 +0000"  >&lt;p&gt;the javadoc warnings do not appear to be from my patch&lt;br/&gt;
(and I see 6, not 1)&lt;/p&gt;

&lt;p&gt;     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Constructing Javadoc information...&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /grid/0/hudson/hudson-slave/workspace/Hadoop-Patch-h4.grid.sp2.yahoo.net/trunk/src/java/org/apache/hadoop/security/KerberosName.java:31: warning: sun.securi&lt;br/&gt;
ty.krb5.Config is Sun proprietary API and may be removed in a future release&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.krb5.Config;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                         ^&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /grid/0/hudson/hudson-slave/workspace/Hadoop-Patch-h4.grid.sp2.yahoo.net/trunk/src/java/org/apache/hadoop/security/KerberosName.java:32: warning: sun.securi&lt;br/&gt;
ty.krb5.KrbException is Sun proprietary API and may be removed in a future release&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.krb5.KrbException;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                         ^&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /grid/0/hudson/hudson-slave/workspace/Hadoop-Patch-h4.grid.sp2.yahoo.net/trunk/src/java/org/apache/hadoop/security/KerberosName.java:81: warning: sun.securi&lt;br/&gt;
ty.krb5.Config is Sun proprietary API and may be removed in a future release&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;   private static Config kerbConf;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                  ^&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /grid/0/hudson/hudson-slave/workspace/Hadoop-Patch-h4.grid.sp2.yahoo.net/trunk/src/java/org/apache/hadoop/security/SecurityUtil.java:33: warning: sun.securi&lt;br/&gt;
ty.jgss.krb5.Krb5Util is Sun proprietary API and may be removed in a future release&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.jgss.krb5.Krb5Util;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                              ^&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /grid/0/hudson/hudson-slave/workspace/Hadoop-Patch-h4.grid.sp2.yahoo.net/trunk/src/java/org/apache/hadoop/security/SecurityUtil.java:34: warning: sun.securi&lt;br/&gt;
ty.krb5.Credentials is Sun proprietary API and may be removed in a future release&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.krb5.Credentials;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                         ^&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /grid/0/hudson/hudson-slave/workspace/Hadoop-Patch-h4.grid.sp2.yahoo.net/trunk/src/java/org/apache/hadoop/security/SecurityUtil.java:35: warning: sun.securi&lt;br/&gt;
ty.krb5.PrincipalName is Sun proprietary API and may be removed in a future release&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.krb5.PrincipalName;&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                         ^&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; ExcludePrivateAnnotationsStandardDoclet&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Standard Doclet version 1.6.0_11&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building tree for all the packages and classes...&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building index for all the packages and classes...&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building index for all classes...&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Generating /grid/0/hudson/hudson-slave/workspace/Hadoop-Patch-h4.grid.sp2.yahoo.net/trunk/build/docs/api/stylesheet.css...&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt;   &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; 6 warnings&lt;br/&gt;
     &lt;span class=&quot;error&quot;&gt;&amp;#91;exec&amp;#93;&lt;/span&gt; &lt;/p&gt;</comment>
                            <comment id="12902556" author="tlipcon" created="Wed, 25 Aug 2010 18:19:37 +0000"  >&lt;p&gt;Hi Sam,&lt;/p&gt;

&lt;p&gt;With this patch, I see occasinal failures of TestGridmixSubmission when the JobMonitor gets interrupted:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;10/08/25 11:05:20 WARN ipc.Client: interrupted waiting to send params to server
java.lang.InterruptedException
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1215)
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:218)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:754)
        at org.apache.hadoop.ipc.Client.call(Client.java:1001)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:224)
        at org.apache.hadoop.mapred.$Proxy10.getJobStatus(Unknown Source)
        at org.apache.hadoop.mapred.JobClient$NetworkedJob.updateStatus(JobClient.java:250)
        at org.apache.hadoop.mapred.JobClient$NetworkedJob.isSuccessful(JobClient.java:339)
        at org.apache.hadoop.mapreduce.Job.isSuccessful(Job.java:332)
        at org.apache.hadoop.mapred.gridmix.JobMonitor$MonitorThread.process(JobMonitor.java:134)
        at org.apache.hadoop.mapred.gridmix.JobMonitor$MonitorThread.run(JobMonitor.java:175)
10/08/25 11:05:20 WARN gridmix.JobMonitor: Lost job GRIDMIX00000
java.io.IOException: java.lang.InterruptedException
        at org.apache.hadoop.ipc.Client.call(Client.java:1007)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:224)
        at org.apache.hadoop.mapred.$Proxy10.getJobStatus(Unknown Source)
        at org.apache.hadoop.mapred.JobClient$NetworkedJob.updateStatus(JobClient.java:250)
        at org.apache.hadoop.mapred.JobClient$NetworkedJob.isSuccessful(JobClient.java:339)
        at org.apache.hadoop.mapreduce.Job.isSuccessful(Job.java:332)
        at org.apache.hadoop.mapred.gridmix.JobMonitor$MonitorThread.process(JobMonitor.java:134)
        at org.apache.hadoop.mapred.gridmix.JobMonitor$MonitorThread.run(JobMonitor.java:175)
Caused by: java.lang.InterruptedException
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1215)
        at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:218)
        at java.util.concurrent.FutureTask.get(FutureTask.java:83)
        at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:754)
        at org.apache.hadoop.ipc.Client.call(Client.java:1001)
        ... 7 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I think the patch is doing the right thing here for the most part, but it should throw InterruptedIOException instead of just a normal IOException. Then the caller can at least catch it distinctly from a normal IOException.&lt;/p&gt;</comment>
                            <comment id="12902557" author="tlipcon" created="Wed, 25 Aug 2010 18:24:39 +0000"  >&lt;p&gt;actually, I might take it back - it looks like you can&apos;t pass cause information into an InterruptedIOException, so it&apos;s better to have callers check e.getCause() instanceof InterruptedException instead? What do you think? The gridmix case above already checks for ClosedByInterruptException, so it can easy check for InterruptedException too.&lt;/p&gt;</comment>
                            <comment id="12902685" author="rash37" created="Wed, 25 Aug 2010 22:39:24 +0000"  >&lt;p&gt;I think IOException makes sense for 2 reasons&lt;/p&gt;

&lt;p&gt;1. the reason you stated--we can pass the actual cause&lt;br/&gt;
2. my read is that only if you are the thread doing the IO should you throw InterruptedIOException.  In this case, the thread truly was interrupted--the IO happens in the other thread.  &lt;br/&gt;
&lt;a href=&quot;http://download-llnw.oracle.com/javase/6/docs/api/java/io/InterruptedIOException.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://download-llnw.oracle.com/javase/6/docs/api/java/io/InterruptedIOException.html&lt;/a&gt;&lt;br/&gt;
it also has a field for the partial bytes transfered.  In fact, this patch is supposed to keep the IO from actually being interrupted &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;how can we make it so the test will pass?  does the test have a faulty assumption that I should fix?&lt;/p&gt;</comment>
                            <comment id="12902692" author="tlipcon" created="Wed, 25 Aug 2010 22:56:47 +0000"  >&lt;p&gt;I think we just need this fix to the gridmix test:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;#8212; a/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/JobMonitor.java&lt;br/&gt;
+++ b/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/JobMonitor.java&lt;br/&gt;
@@ -177,7 +177,8 @@ class JobMonitor implements Gridmix.Component&amp;lt;Job&amp;gt; &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {                 continue;               }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;             } catch (IOException e) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (e.getCause() instanceof ClosedByInterruptException) {&lt;br/&gt;
+              if (e.getCause() instanceof ClosedByInterruptException ||&lt;br/&gt;
+                  e.getCause() instanceof InterruptedException) {&lt;br/&gt;
                 // Job doesn&apos;t throw InterruptedException, but RPC socket layer&lt;br/&gt;
                 // is blocking and may throw a wrapped Exception if this thread&lt;br/&gt;
                 // is interrupted. Since the lower level cleared the flag,&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;</comment>
                            <comment id="12908097" author="rash37" created="Fri, 10 Sep 2010 17:15:12 +0000"  >&lt;p&gt;just getting around to this--this requires a patch to the mapred project rt?  so do i file a separate jira for that?&lt;/p&gt;</comment>
                            <comment id="12928503" author="hadoopqa" created="Fri, 5 Nov 2010 06:17:42 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12447484/hadoop-6762-9.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12447484/hadoop-6762-9.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision 1031422.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/35//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/35//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12928936" author="rash37" created="Sat, 6 Nov 2010 06:13:35 +0000"  >&lt;p&gt;i&apos;ll update the patch.  I think it just needs to be rebased&lt;/p&gt;</comment>
                            <comment id="12928937" author="rash37" created="Sat, 6 Nov 2010 06:14:03 +0000"  >&lt;p&gt;also this was run against trunk?&lt;/p&gt;</comment>
                            <comment id="12933510" author="rash37" created="Thu, 18 Nov 2010 18:20:24 +0000"  >&lt;p&gt;rebase off latest trunk&lt;/p&gt;</comment>
                            <comment id="12933519" author="hadoopqa" created="Thu, 18 Nov 2010 18:46:14 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12459934/hadoop-6762-10.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12459934/hadoop-6762-10.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision 1036130.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated 1 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed core unit tests.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;    +1 system test framework.  The patch passed system test framework compile.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/110//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/110//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/110//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/110//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/110//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/110//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="12933889" author="rash37" created="Fri, 19 Nov 2010 17:58:10 +0000"  >&lt;p&gt;the javadoc warnings are not in any files I touched.  The warnings in tr&lt;/p&gt;

&lt;p&gt;-----------&lt;/p&gt;

&lt;p&gt;  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Loading source files for package org.apache.hadoop.contrib.failmon...  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Constructing Javadoc information...  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /data/users/srash/apache/hadoop-common/src/java/org/apache/hadoop/security/SecurityUtil.java:39: warning: sun.security.jgss.krb5.Krb5Util is Sun proprietary API and may&lt;br/&gt;
 be removed in a future release&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.jgss.krb5.Krb5Util;  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                              ^  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /data/users/srash/apache/hadoop-common/src/java/org/apache/hadoop/security/SecurityUtil.java:40: warning: sun.security.krb5.Credentials is Sun proprietary API and may b&lt;br/&gt;
e removed in a future release&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.krb5.Credentials;  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                         ^&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /data/users/srash/apache/hadoop-common/src/java/org/apache/hadoop/security/SecurityUtil.java:41: warning: sun.security.krb5.PrincipalName is Sun proprietary API and may be removed in a future release&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.krb5.PrincipalName;  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                         ^&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /data/users/srash/apache/hadoop-common/src/java/org/apache/hadoop/security/KerberosName.java:31: warning: sun.security.krb5.Config is Sun proprietary API and may be rem&lt;br/&gt;
oved in a future release&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.krb5.Config;  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                         ^&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /data/users/srash/apache/hadoop-common/src/java/org/apache/hadoop/security/KerberosName.java:32: warning: sun.security.krb5.KrbException is Sun proprietary API and may &lt;br/&gt;
be removed in a future release&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; import sun.security.krb5.KrbException;  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                         ^&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; /data/users/srash/apache/hadoop-common/src/java/org/apache/hadoop/security/KerberosName.java:81: warning: sun.security.krb5.Config is Sun proprietary API and may be rem&lt;br/&gt;
oved in a future release&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;   private static Config kerbConf;  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt;                  ^&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; ExcludePrivateAnnotationsStandardDoclet&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Standard Doclet version 1.6.0_21&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building tree for all the packages and classes...  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building index for all the packages and classes...&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Building index for all classes...&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; Generating /data/users/srash/apache/hadoop-common/build/docs/api/stylesheet.css...&lt;br/&gt;
  &lt;span class=&quot;error&quot;&gt;&amp;#91;javadoc&amp;#93;&lt;/span&gt; 6 warnings&lt;/p&gt;</comment>
                            <comment id="12933890" author="rash37" created="Fri, 19 Nov 2010 17:59:13 +0000"  >&lt;p&gt;todd: where are we on this?  you said some gridmx test in the mapred project needs updated based on this? shall we commit this and file a mapreduce jira?&lt;/p&gt;
</comment>
                            <comment id="12980179" author="tlipcon" created="Tue, 11 Jan 2011 16:55:25 +0000"  >&lt;p&gt;Sorry, Sam, this one dropped off my radar. I&apos;d like to get it in for 0.22, let me swing around and see what work&apos;s remaining.&lt;/p&gt;</comment>
                            <comment id="12996898" author="hadoopqa" created="Sat, 19 Feb 2011 22:09:49 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12459934/hadoop-6762-10.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12459934/hadoop-6762-10.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision 1071364.&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 3 new or modified tests.&lt;/p&gt;

&lt;p&gt;    -1 patch.  The patch command could not apply the patch.&lt;/p&gt;

&lt;p&gt;Console output: &lt;a href=&quot;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/272//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/272//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13002871" author="tlipcon" created="Fri, 4 Mar 2011 23:44:11 +0000"  >&lt;p&gt;Hi Sam,&lt;/p&gt;

&lt;p&gt;We saw the following deadlock which I think is related to this patch:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Thread 50994 (IPC Client (47) connection to XXXXXXXXX:8020 from hdfs):
State: BLOCKED
Blocked count: 7168
Waited count: 7122
Blocked on java.io.DataOutputStream@2e932fec
Blocked by 50828 (sendParams-14)
Stack:
org.apache.hadoop.ipc.Client$Connection.sendPing(Client.java:676)
org.apache.hadoop.ipc.Client$Connection.access$400(Client.java:210)
org.apache.hadoop.ipc.Client$Connection$PingInputStream.handleTimeout(Client.java:340)
org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:370)
java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
java.io.BufferedInputStream.read(BufferedInputStream.java:237)
java.io.DataInputStream.readInt(DataInputStream.java:370)
org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:781)
org.apache.hadoop.ipc.Client$Connection.run(Client.java:689)


Thread 50828 (sendParams-14):
State: BLOCKED
Blocked count: 54
Waited count: 8313
Blocked on org.apache.hadoop.ipc.Client$Connection@54aeb3dd
Blocked by 50994 (IPC Client (47) connection to XXXXXX:8020 from hdfs)
Stack:
org.apache.hadoop.ipc.Client$Connection.markClosed(Client.java:809)
org.apache.hadoop.ipc.Client$Connection.access$1200(Client.java:210)
org.apache.hadoop.ipc.Client$Connection$3.run(Client.java:745)
java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
java.util.concurrent.FutureTask.run(FutureTask.java:138)
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
java.lang.Thread.run(Thread.java:619)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The issue is that in the patch, we have the following inverted lock orders:&lt;br/&gt;
sendParam&apos;s senderFuture: Connection.out -&amp;gt; Connection (in markClosed)&lt;br/&gt;
sendPing: Connection -&amp;gt; Connection.out (explicit sync)&lt;/p&gt;

&lt;p&gt;Have you guys seen this issue?&lt;/p&gt;</comment>
                            <comment id="13002873" author="rash37" created="Fri, 4 Mar 2011 23:52:49 +0000"  >&lt;p&gt;I haven&apos;t noticed this.  In the rev we&apos;re running,  inside sendParams(), markClosed() is called outside the synchronized(Connection.this.out), so that lock isn&apos;t held...?&lt;/p&gt;

&lt;p&gt;(I&apos;m using the original patch I uploaded before we changed it to a Future--it uses a latch)&lt;/p&gt;


</comment>
                            <comment id="13090604" author="tlipcon" created="Wed, 24 Aug 2011 23:05:35 +0000"  >&lt;p&gt;I&apos;d really like to get this in for 0.23. I&apos;m going to steal the patch and rebase Sam&apos;s work to trunk.&lt;/p&gt;</comment>
                            <comment id="13091979" author="tlipcon" created="Fri, 26 Aug 2011 19:40:11 +0000"  >&lt;p&gt;Rebased on trunk. A few changes since the earlier revs:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;added a new &quot;simple&quot; test case with a single thread&lt;/li&gt;
	&lt;li&gt;moved the serialization of the call response into the calling thread, outside of the lock acquisition, to get better CPU parallelism&lt;/li&gt;
	&lt;li&gt;used guava&apos;s ThreadFactoryBuilder to make the thread factory&lt;/li&gt;
	&lt;li&gt;Cleaned up some of the warning messages to include thread name&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13091985" author="hadoopqa" created="Fri, 26 Aug 2011 19:51:13 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12491826/hadoop-6762.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12491826/hadoop-6762.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 4 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    -1 core tests.  The patch failed these unit tests:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.ipc.TestRPC&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-annotations.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-auth.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-auth.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/89//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13092118" author="tlipcon" created="Fri, 26 Aug 2011 23:06:39 +0000"  >&lt;p&gt;Test failed since one of the new tests was leaving the main thread in an interrupted state, so a Thread.sleep crashed in the next test case. I added a &quot;Thread.interrupted()&quot; in the tests to clear state between test cases.&lt;/p&gt;

&lt;p&gt;The -1 findbugs issue is due to &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-7587&quot; title=&quot;hadoop-auth module has 4 findbugs warnings&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-7587&quot;&gt;&lt;del&gt;HADOOP-7587&lt;/del&gt;&lt;/a&gt; (not this patch)&lt;/p&gt;</comment>
                            <comment id="13092128" author="hadoopqa" created="Fri, 26 Aug 2011 23:15:23 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12491826/hadoop-6762.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12491826/hadoop-6762.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 4 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    -1 core tests.  The patch failed these unit tests:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.ipc.TestRPC&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-auth.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-auth.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-annotations.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-annotations.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/92//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13092129" author="hadoopqa" created="Fri, 26 Aug 2011 23:21:01 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12491851/hadoop-6762.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12491851/hadoop-6762.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 6 new or modified tests.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 findbugs.  The patch appears to introduce 4 new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    +1 core tests.  The patch passed unit tests in hadoop-common-project.&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//testReport/&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-annotations.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-annotations.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-common.html&lt;/a&gt;&lt;br/&gt;
Findbugs warnings: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-auth.html&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-auth.html&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/93//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13277046" author="eli2" created="Wed, 16 May 2012 19:35:16 +0000"  >&lt;p&gt;Todd,&lt;br/&gt;
Looks like the patch is out of date, mind updating it?&lt;/p&gt;</comment>
                            <comment id="13461192" author="qwertymaniac" created="Sat, 22 Sep 2012 15:25:47 +0000"  >&lt;p&gt;Unsure if this is still needed but here&apos;s a &quot;rebase&quot;. Had to add in some hunks manually, as certain parts seem to have been highly updated since back then.&lt;/p&gt;</comment>
                            <comment id="13461203" author="hadoopqa" created="Sat, 22 Sep 2012 16:09:17 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12546168/HADOOP-6762.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12546168/HADOOP-6762.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 2 new or modified test files.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    -1 core tests.  The patch failed these unit tests in hadoop-common-project/hadoop-common:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.ipc.TestSaslRPC&lt;br/&gt;
                  org.apache.hadoop.ipc.TestMultipleProtocolServer&lt;br/&gt;
                  org.apache.hadoop.ipc.TestProtoBufRpc&lt;br/&gt;
                  org.apache.hadoop.ipc.TestRPCCallBenchmark&lt;br/&gt;
                  org.apache.hadoop.ha.TestZKFailoverController&lt;br/&gt;
                  org.apache.hadoop.ipc.TestRPC&lt;br/&gt;
                  org.apache.hadoop.ipc.TestIPC&lt;br/&gt;
                  org.apache.hadoop.ipc.TestRPCCompatibility&lt;br/&gt;
                  org.apache.hadoop.ipc.TestIPCServerResponder&lt;br/&gt;
                  org.apache.hadoop.security.TestDoAsEffectiveUser&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1499//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1499//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1499//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1499//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13461393" author="qwertymaniac" created="Sun, 23 Sep 2012 11:33:31 +0000"  >&lt;p&gt;Cancelling patch as it fails several relevant tests. Needs to be re-investigated.&lt;/p&gt;

&lt;p&gt;Todd - Would you have a chance to look into this soon? Is this still required?&lt;/p&gt;</comment>
                            <comment id="13509131" author="tlipcon" created="Mon, 3 Dec 2012 22:15:34 +0000"  >&lt;p&gt;Thanks for updating the patch, Harsh. I&apos;m looking into this again now. I&apos;ll try to post another patch later today.&lt;/p&gt;</comment>
                            <comment id="13509278" author="tlipcon" created="Mon, 3 Dec 2012 22:41:43 +0000"  >&lt;p&gt;Here&apos;s an updated patch against trunk.&lt;/p&gt;

&lt;p&gt;I ran all of the unit tests in the ipc package locally and they passed. I also tried the new unit tests &lt;em&gt;without&lt;/em&gt; the patch, and they failed as expected.&lt;/p&gt;

&lt;p&gt;Given that there was a deadlock found in an early rev of this patch, I also ran all of the IPC unit tests under jcarder to look for lock inversions and it found none.&lt;/p&gt;

&lt;p&gt;I ran the RPCCallBenchmark for 30 seconds with and without the patch, with the following results:&lt;/p&gt;

&lt;p&gt;With patch:&lt;br/&gt;
====== Results ======&lt;br/&gt;
Options:&lt;br/&gt;
rpcEngine=class org.apache.hadoop.ipc.ProtobufRpcEngine&lt;br/&gt;
serverThreads=30&lt;br/&gt;
serverReaderThreads=4&lt;br/&gt;
clientThreads=30&lt;br/&gt;
host=0.0.0.0&lt;br/&gt;
port=12345&lt;br/&gt;
secondsToRun=30&lt;br/&gt;
msgSize=1024&lt;br/&gt;
Total calls per second: 24668.0&lt;br/&gt;
CPU time per call on client: 58639 ns&lt;br/&gt;
CPU time per call on server: 64893 ns&lt;/p&gt;


&lt;p&gt;Without patch:&lt;br/&gt;
====== Results ======&lt;br/&gt;
Options:&lt;br/&gt;
rpcEngine=class org.apache.hadoop.ipc.ProtobufRpcEngine&lt;br/&gt;
serverThreads=30&lt;br/&gt;
serverReaderThreads=4&lt;br/&gt;
clientThreads=30&lt;br/&gt;
host=0.0.0.0&lt;br/&gt;
port=12345&lt;br/&gt;
secondsToRun=30&lt;br/&gt;
msgSize=1024&lt;br/&gt;
Total calls per second: 27881.0&lt;br/&gt;
CPU time per call on client: 68079 ns&lt;br/&gt;
CPU time per call on server: 62582 ns&lt;/p&gt;

&lt;p&gt;As expected, the CPU time on the client was increased and the throughput went down by about 13%, since the RPC calls are now being shuttled between threads on the client side. That&apos;s unfortunate, but given that this fixes an important bug, and given that &lt;em&gt;client&lt;/em&gt; side RPC throughput is rarely a bottleneck in common usage scenarios, I think it is acceptable.&lt;/p&gt;

&lt;p&gt;This patch is also nearly identical to a patch that we&apos;ve shipped in CDH since June 2010, so I&apos;m fairly confident that the approach is correct.&lt;/p&gt;</comment>
                            <comment id="13509297" author="tlipcon" created="Mon, 3 Dec 2012 23:02:04 +0000"  >&lt;p&gt;Also figured I&apos;d write up a short summary of this, since the above discussion is long and somewhat hard to follow after 2.5 years and ~15 attachments &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;The issue at hand is what happens when an IPC caller thread (i.e the user thread who is making an IPC call, for example to the NN) is interrupted while in the process of writing the call to the wire. Java NIO&apos;s semantics are that a ClosedByInterruptException is thrown on the blocked thread, &lt;em&gt;and also that the underlying channel is closed&lt;/em&gt;. In the context of IPC, this meant that the caller thread would receive a ClosedByInterruptException, and that any other threads which were sharing the same IPC socket would then receive ClosedChannelExceptions, even though those other threads were never meant to be interrupted.&lt;/p&gt;

&lt;p&gt;The solution is to change the call-sending code such that the actual write() call happens on a new thread, created by the &lt;tt&gt;SEND_PARAMS_EXECUTOR&lt;/tt&gt; in the patch. Since the user code has no reference to this thread, it won&apos;t ever get interrupted, even if someone interrupts the user thread making the call. So, the user thread will receive an InterruptedException, but any other threads using the same socket continue to run unaffected.&lt;/p&gt;</comment>
                            <comment id="13510204" author="atm" created="Wed, 5 Dec 2012 01:39:03 +0000"  >&lt;p&gt;The latest patch looks good to me. +1 pending Jenkins.&lt;/p&gt;

&lt;p&gt;Jenkins appears to be down right now, and I think Jenkins flakiness caused test-patch not to notice this one. May need to manually kick it once Jenkins comes back up.&lt;/p&gt;</comment>
                            <comment id="13528219" author="hadoopqa" created="Mon, 10 Dec 2012 19:52:57 +0000"  >&lt;p&gt;&lt;font color=&quot;green&quot;&gt;+1 overall&lt;/font&gt;.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12555841/hadoop-6762.txt&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12555841/hadoop-6762.txt&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 @author&lt;/font&gt;.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 tests included&lt;/font&gt;.  The patch appears to include 2 new or modified test files.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javac&lt;/font&gt;.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 javadoc&lt;/font&gt;.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 eclipse:eclipse&lt;/font&gt;.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 findbugs&lt;/font&gt;.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 release audit&lt;/font&gt;.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 core tests&lt;/font&gt;.  The patch passed unit tests in hadoop-common-project/hadoop-common.&lt;/p&gt;

&lt;p&gt;    &lt;font color=&quot;green&quot;&gt;+1 contrib tests&lt;/font&gt;.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1843//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1843//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1843//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1843//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13528309" author="tlipcon" created="Mon, 10 Dec 2012 21:26:01 +0000"  >&lt;p&gt;Committed to trunk and branch-2. Thanks, Sam.&lt;/p&gt;</comment>
                            <comment id="13528326" author="hudson" created="Mon, 10 Dec 2012 21:47:39 +0000"  >&lt;p&gt;Integrated in Hadoop-trunk-Commit #3106 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-trunk-Commit/3106/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-trunk-Commit/3106/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6762&quot; title=&quot;exception while doing RPC I/O closes channel&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-6762&quot;&gt;&lt;del&gt;HADOOP-6762&lt;/del&gt;&lt;/a&gt;. Exception while doing RPC I/O closes channel. Contributed by Sam Rash and Todd Lipcon. (Revision 1419782)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
todd : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1419782&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1419782&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestIPC.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13528876" author="hudson" created="Tue, 11 Dec 2012 10:45:40 +0000"  >&lt;p&gt;Integrated in Hadoop-Yarn-trunk #62 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Yarn-trunk/62/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Yarn-trunk/62/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6762&quot; title=&quot;exception while doing RPC I/O closes channel&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-6762&quot;&gt;&lt;del&gt;HADOOP-6762&lt;/del&gt;&lt;/a&gt;. Exception while doing RPC I/O closes channel. Contributed by Sam Rash and Todd Lipcon. (Revision 1419782)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
todd : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1419782&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1419782&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestIPC.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13528941" author="hudson" created="Tue, 11 Dec 2012 13:11:47 +0000"  >&lt;p&gt;Integrated in Hadoop-Hdfs-trunk #1251 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1251/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1251/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6762&quot; title=&quot;exception while doing RPC I/O closes channel&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-6762&quot;&gt;&lt;del&gt;HADOOP-6762&lt;/del&gt;&lt;/a&gt;. Exception while doing RPC I/O closes channel. Contributed by Sam Rash and Todd Lipcon. (Revision 1419782)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
todd : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1419782&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1419782&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestIPC.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13528991" author="hudson" created="Tue, 11 Dec 2012 14:09:57 +0000"  >&lt;p&gt;Integrated in Hadoop-Mapreduce-trunk #1282 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1282/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1282/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-6762&quot; title=&quot;exception while doing RPC I/O closes channel&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-6762&quot;&gt;&lt;del&gt;HADOOP-6762&lt;/del&gt;&lt;/a&gt;. Exception while doing RPC I/O closes channel. Contributed by Sam Rash and Todd Lipcon. (Revision 1419782)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
todd : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1419782&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1419782&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ipc/Client.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestIPC.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                            <outwardlinks description="causes">
                                        <issuelink>
            <issuekey id="13469534">HADOOP-18324</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="12618230">HADOOP-9107</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12645042">HIVE-4436</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="12501652">MAPREDUCE-2392</issuekey>
        </issuelink>
                            </outwardlinks>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="12464664">HADOOP-6768</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12546168" name="HADOOP-6762.patch" size="12948" author="qwertymaniac" created="Sat, 22 Sep 2012 15:25:47 +0000"/>
                            <attachment id="12444323" name="hadoop-6762-1.txt" size="6913" author="rash37" created="Wed, 12 May 2010 17:36:33 +0000"/>
                            <attachment id="12459934" name="hadoop-6762-10.txt" size="10134" author="rash37" created="Thu, 18 Nov 2010 18:20:24 +0000"/>
                            <attachment id="12444414" name="hadoop-6762-2.txt" size="6226" author="rash37" created="Thu, 13 May 2010 18:57:08 +0000"/>
                            <attachment id="12444439" name="hadoop-6762-3.txt" size="7650" author="rash37" created="Thu, 13 May 2010 23:34:40 +0000"/>
                            <attachment id="12445408" name="hadoop-6762-4.txt" size="8358" author="rash37" created="Tue, 25 May 2010 01:34:55 +0000"/>
                            <attachment id="12446307" name="hadoop-6762-6.txt" size="8835" author="rash37" created="Fri, 4 Jun 2010 00:16:58 +0000"/>
                            <attachment id="12446356" name="hadoop-6762-7.txt" size="9857" author="rash37" created="Fri, 4 Jun 2010 17:52:57 +0000"/>
                            <attachment id="12446530" name="hadoop-6762-8.txt" size="10166" author="rash37" created="Mon, 7 Jun 2010 21:41:04 +0000"/>
                            <attachment id="12447484" name="hadoop-6762-9.txt" size="10184" author="rash37" created="Fri, 18 Jun 2010 17:26:37 +0000"/>
                            <attachment id="12555841" name="hadoop-6762.txt" size="13569" author="tlipcon" created="Mon, 3 Dec 2012 22:41:43 +0000"/>
                            <attachment id="12491851" name="hadoop-6762.txt" size="13710" author="tlipcon" created="Fri, 26 Aug 2011 23:06:39 +0000"/>
                            <attachment id="12491826" name="hadoop-6762.txt" size="13631" author="tlipcon" created="Fri, 26 Aug 2011 19:40:11 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>13.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>252</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            12 years, 50 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i02sgf:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>14211</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310320" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
                        <customfieldname>Target Version/s</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue id="12323273">2.0.3-alpha</customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>