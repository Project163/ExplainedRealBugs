<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:39:31 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-8449] hadoop fs -text fails with compressed sequence files with the codec file extension</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-8449</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;When the -text command is run on a file and the file ends in the default extension for a codec (e.g. snappy or gz), but is a compressed sequence file, the command will fail.&lt;/p&gt;

&lt;p&gt;The issue is that it assumes that if it matches the extension, then it&apos;s plain compressed file. It might be more helpful to check if it&apos;s a sequence file first, and then check the file extension second.&lt;/p&gt;</description>
                <environment></environment>
        <key id="12558609">HADOOP-8449</key>
            <summary>hadoop fs -text fails with compressed sequence files with the codec file extension</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="6" iconUrl="https://issues.apache.org/jira/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="qwertymaniac">Harsh J</assignee>
                                    <reporter username="fwiffo">Joey Echeverria</reporter>
                        <labels>
                    </labels>
                <created>Wed, 30 May 2012 14:37:13 +0000</created>
                <updated>Fri, 6 Feb 2015 00:38:24 +0000</updated>
                            <resolved>Sat, 30 Jun 2012 05:06:10 +0000</resolved>
                                    <version>1.0.3</version>
                    <version>2.0.0-alpha</version>
                                    <fixVersion>2.0.2-alpha</fixVersion>
                                        <due></due>
                            <votes>0</votes>
                                    <watches>10</watches>
                                                                                                                <comments>
                            <comment id="13285845" author="qwertymaniac" created="Wed, 30 May 2012 17:47:22 +0000"  >&lt;p&gt;Snappy is currently un-detectable code wise, at least AFAICT, since it lacks a container format. However, yeah, we should check for SEQ magic header (and the likes) first I think.&lt;/p&gt;</comment>
                            <comment id="13285850" author="fwiffo" created="Wed, 30 May 2012 17:56:24 +0000"  >&lt;p&gt;Yup. I&apos;m cool with using extensions, but after we check for SEQ. Today, it&apos;s reversed. It checks the extension before checking for the magic header.&lt;/p&gt;</comment>
                            <comment id="13285935" author="qwertymaniac" created="Wed, 30 May 2012 19:22:46 +0000"  >&lt;p&gt;This patch ought to take care of this. The reverse order is what Hue does as well, as I remember from my &lt;a href=&quot;https://issues.cloudera.org/browse/HUE-1&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://issues.cloudera.org/browse/HUE-1&lt;/a&gt; patch.&lt;/p&gt;

&lt;p&gt;I could not find tests for this command (or others) so haven&apos;t added any.&lt;/p&gt;</comment>
                            <comment id="13286060" author="hadoopqa" created="Wed, 30 May 2012 21:10:53 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12530258/HADOOP-8449.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12530258/HADOOP-8449.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    -1 tests included.  The patch doesn&apos;t appear to include any new or modified tests.&lt;br/&gt;
                        Please justify why no new tests are needed for this patch.&lt;br/&gt;
                        Also please list what manual steps were performed to verify this patch.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    +1 javadoc.  The javadoc tool did not generate any warning messages.&lt;/p&gt;

&lt;p&gt;    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    -1 core tests.  The patch failed these unit tests in hadoop-common-project/hadoop-common:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.fs.viewfs.TestViewFsTrash&lt;br/&gt;
                  org.apache.hadoop.ha.TestZKFailoverController&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1059//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1059//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1059//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1059//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13286133" author="fwiffo" created="Wed, 30 May 2012 22:27:02 +0000"  >&lt;p&gt;As Harsh pointed out, there are no tests for the FsShell commands. The two failing tests look unrelated, so I&apos;m +1 on the patch.&lt;/p&gt;</comment>
                            <comment id="13286188" author="atm" created="Wed, 30 May 2012 23:31:06 +0000"  >&lt;blockquote&gt;&lt;p&gt;there are no tests for the FsShell commands.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;There are many tests for the shell commands, but they&apos;re unfortunately in the HDFS sub-project, even though FsShell is implemented in Common. See: hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/p&gt;</comment>
                            <comment id="13286275" author="qwertymaniac" created="Thu, 31 May 2012 02:35:04 +0000"  >&lt;p&gt;Thanks ATM. Totally missed that class. I&apos;ll improve the Text test in it to catch regressions in future, and provide a new patch. Cancelling current patch.&lt;/p&gt;</comment>
                            <comment id="13286615" author="daryn" created="Thu, 31 May 2012 14:36:13 +0000"  >&lt;p&gt;Please link the hdfs jira to this one.  Pending tests, I think this looks good.  One trivial suggestion would be to move the codec stuff into a default case for the switch.&lt;/p&gt;</comment>
                            <comment id="13286731" author="atm" created="Thu, 31 May 2012 16:41:36 +0000"  >&lt;blockquote&gt;&lt;p&gt;Please link the hdfs jira to this one.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t think there&apos;s a need for a separate JIRA, now that test-patch.sh supports cross-project patches.&lt;/p&gt;</comment>
                            <comment id="13401631" author="qwertymaniac" created="Tue, 26 Jun 2012 19:26:39 +0000"  >&lt;p&gt;Attached patch addresses Aaron and Daryn&apos;s comments. Added test bits fail without the Display.java changes, expectedly. Passes otherwise.&lt;/p&gt;</comment>
                            <comment id="13401691" author="daryn" created="Tue, 26 Jun 2012 21:18:37 +0000"  >&lt;p&gt;Which &lt;tt&gt;Display&lt;/tt&gt; changes are you referring to?&lt;/p&gt;</comment>
                            <comment id="13401696" author="hadoopqa" created="Tue, 26 Jun 2012 21:23:48 +0000"  >&lt;p&gt;-1 overall.  Here are the results of testing the latest attachment &lt;br/&gt;
  &lt;a href=&quot;http://issues.apache.org/jira/secure/attachment/12533528/HADOOP-8449.patch&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;http://issues.apache.org/jira/secure/attachment/12533528/HADOOP-8449.patch&lt;/a&gt;&lt;br/&gt;
  against trunk revision .&lt;/p&gt;

&lt;p&gt;    +1 @author.  The patch does not contain any @author tags.&lt;/p&gt;

&lt;p&gt;    +1 tests included.  The patch appears to include 1 new or modified test files.&lt;/p&gt;

&lt;p&gt;    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.&lt;/p&gt;

&lt;p&gt;    -1 javadoc.  The javadoc tool appears to have generated 2 warning messages.&lt;/p&gt;

&lt;p&gt;    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.&lt;/p&gt;

&lt;p&gt;    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.&lt;/p&gt;

&lt;p&gt;    +1 release audit.  The applied patch does not increase the total number of release audit warnings.&lt;/p&gt;

&lt;p&gt;    -1 core tests.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:&lt;/p&gt;

&lt;p&gt;                  org.apache.hadoop.fs.viewfs.TestViewFsTrash&lt;br/&gt;
                  org.apache.hadoop.hdfs.TestDatanodeBlockScanner&lt;/p&gt;

&lt;p&gt;    +1 contrib tests.  The patch passed contrib unit tests.&lt;/p&gt;

&lt;p&gt;Test results: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1141//testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1141//testReport/&lt;/a&gt;&lt;br/&gt;
Console output: &lt;a href=&quot;https://builds.apache.org/job/PreCommit-HADOOP-Build/1141//console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/PreCommit-HADOOP-Build/1141//console&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This message is automatically generated.&lt;/p&gt;</comment>
                            <comment id="13401750" author="fwiffo" created="Tue, 26 Jun 2012 22:32:32 +0000"  >&lt;p&gt;I think he means he ran the new tests without the fix to Display.java and it failed as expected, but passes with the patched Display.java as desired.&lt;/p&gt;</comment>
                            <comment id="13401766" author="daryn" created="Tue, 26 Jun 2012 22:57:57 +0000"  >&lt;p&gt;Looks good, please check if the javadoc warnings are related.&lt;/p&gt;</comment>
                            <comment id="13401952" author="qwertymaniac" created="Wed, 27 Jun 2012 04:08:00 +0000"  >&lt;p&gt;The javadocs are from &lt;a href=&quot;https://issues.apache.org/jira/browse/MAPREDUCE-4355&quot; title=&quot;Add RunningJob.getJobStatus()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;MAPREDUCE-4355&quot;&gt;&lt;del&gt;MAPREDUCE-4355&lt;/del&gt;&lt;/a&gt; and will be addressed from its follow ups.&lt;/p&gt;

&lt;p&gt;Thanks Aaron, Daryn and Joey! Committing by EOD to trunk and branch-2 unless there&apos;s any other comment.&lt;/p&gt;</comment>
                            <comment id="13402248" author="daryn" created="Wed, 27 Jun 2012 14:21:40 +0000"  >&lt;p&gt;+1&lt;/p&gt;</comment>
                            <comment id="13404393" author="qwertymaniac" created="Sat, 30 Jun 2012 05:06:10 +0000"  >&lt;p&gt;Thank you Daryn. Committed to branch-2 and trunk.&lt;/p&gt;</comment>
                            <comment id="13404397" author="hudson" created="Sat, 30 Jun 2012 05:19:16 +0000"  >&lt;p&gt;Integrated in Hadoop-Hdfs-trunk-Commit #2482 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2482/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2482/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8449&quot; title=&quot;hadoop fs -text fails with compressed sequence files with the codec file extension&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8449&quot;&gt;&lt;del&gt;HADOOP-8449&lt;/del&gt;&lt;/a&gt;. hadoop fs -text fails with compressed sequence files with the codec file extension. (harsh) (Revision 1355636)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13404398" author="hudson" created="Sat, 30 Jun 2012 05:20:55 +0000"  >&lt;p&gt;Integrated in Hadoop-Common-trunk-Commit #2414 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2414/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2414/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8449&quot; title=&quot;hadoop fs -text fails with compressed sequence files with the codec file extension&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8449&quot;&gt;&lt;del&gt;HADOOP-8449&lt;/del&gt;&lt;/a&gt;. hadoop fs -text fails with compressed sequence files with the codec file extension. (harsh) (Revision 1355636)&lt;/p&gt;

&lt;p&gt;     Result = SUCCESS&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13404408" author="hudson" created="Sat, 30 Jun 2012 06:09:45 +0000"  >&lt;p&gt;Integrated in Hadoop-Mapreduce-trunk-Commit #2431 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2431/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2431/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8449&quot; title=&quot;hadoop fs -text fails with compressed sequence files with the codec file extension&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8449&quot;&gt;&lt;del&gt;HADOOP-8449&lt;/del&gt;&lt;/a&gt;. hadoop fs -text fails with compressed sequence files with the codec file extension. (harsh) (Revision 1355636)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13404464" author="hudson" created="Sat, 30 Jun 2012 11:43:43 +0000"  >&lt;p&gt;Integrated in Hadoop-Hdfs-trunk #1092 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1092/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Hdfs-trunk/1092/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8449&quot; title=&quot;hadoop fs -text fails with compressed sequence files with the codec file extension&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8449&quot;&gt;&lt;del&gt;HADOOP-8449&lt;/del&gt;&lt;/a&gt;. hadoop fs -text fails with compressed sequence files with the codec file extension. (harsh) (Revision 1355636)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13404501" author="hudson" created="Sat, 30 Jun 2012 14:06:33 +0000"  >&lt;p&gt;Integrated in Hadoop-Mapreduce-trunk #1125 (See &lt;a href=&quot;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1125/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1125/&lt;/a&gt;)&lt;br/&gt;
    &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8449&quot; title=&quot;hadoop fs -text fails with compressed sequence files with the codec file extension&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-8449&quot;&gt;&lt;del&gt;HADOOP-8449&lt;/del&gt;&lt;/a&gt;. hadoop fs -text fails with compressed sequence files with the codec file extension. (harsh) (Revision 1355636)&lt;/p&gt;

&lt;p&gt;     Result = FAILURE&lt;br/&gt;
harsh : &lt;a href=&quot;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&amp;amp;view=rev&amp;amp;rev=1355636&lt;/a&gt;&lt;br/&gt;
Files : &lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/Display.java&lt;/li&gt;
	&lt;li&gt;/hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java&lt;/li&gt;
&lt;/ul&gt;
</comment>
                            <comment id="13459352" author="muddydixon" created="Thu, 20 Sep 2012 05:12:10 +0000"  >&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;We found the changes in order of switch and guard block in &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; InputStream forMagic(Path p, FileSystem srcFs) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Because of this change, return value of &lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;codec.createInputStream(i)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt; is changed if codec exists.&lt;/p&gt;

&lt;h4&gt;&lt;a name=&quot;cdh3u3&quot;&gt;&lt;/a&gt;cdh3u3&lt;/h4&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; InputStream forMagic(Path p, FileSystem srcFs) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    FSDataInputStream i = srcFs.open(p);

    &lt;span class=&quot;code-comment&quot;&gt;// check codecs
&lt;/span&gt;    CompressionCodecFactory cf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CompressionCodecFactory(getConf());
    CompressionCodec codec = cf.getCodec(p);
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (codec != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; codec.createInputStream(i);
    }

    &lt;span class=&quot;code-keyword&quot;&gt;switch&lt;/span&gt;(i.readShort()) {
       &lt;span class=&quot;code-comment&quot;&gt;// cases
&lt;/span&gt;    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;


&lt;h4&gt;&lt;a name=&quot;cdh3u5&quot;&gt;&lt;/a&gt;cdh3u5&lt;/h4&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;&lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; InputStream forMagic(Path p, FileSystem srcFs) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; IOException {
    FSDataInputStream i = srcFs.open(p);

    &lt;span class=&quot;code-keyword&quot;&gt;switch&lt;/span&gt;(i.readShort()) { &lt;span class=&quot;code-comment&quot;&gt;// &amp;lt;=== index (or pointer) processes!!
&lt;/span&gt;      &lt;span class=&quot;code-comment&quot;&gt;// cases
&lt;/span&gt;      &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt;: {
        &lt;span class=&quot;code-comment&quot;&gt;// Check the type of compression instead, depending on Codec &lt;span class=&quot;code-keyword&quot;&gt;class&apos;&lt;/span&gt;s
&lt;/span&gt;        &lt;span class=&quot;code-comment&quot;&gt;// own detection methods, based on the provided path.
&lt;/span&gt;        CompressionCodecFactory cf = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; CompressionCodecFactory(getConf());
        CompressionCodec codec = cf.getCodec(p);
        &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; (codec != &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;) {
          &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; codec.createInputStream(i);
        }
        &lt;span class=&quot;code-keyword&quot;&gt;break&lt;/span&gt;;
      }
    }

    &lt;span class=&quot;code-comment&quot;&gt;// File is non-compressed, or not a file container we know.
&lt;/span&gt;    i.seek(0);
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; i;
  }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="13460239" author="qwertymaniac" created="Fri, 21 Sep 2012 05:48:47 +0000"  >&lt;p&gt;Thanks Muddy, silly mistake of mine. I filed &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-8833&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/HADOOP-8833&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310050">
                    <name>Regression</name>
                                            <outwardlinks description="breaks">
                                        <issuelink>
            <issuekey id="12608576">HADOOP-8833</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                            <outwardlinks description="supercedes">
                                        <issuelink>
            <issuekey id="12526963">HDFS-2444</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12533528" name="HADOOP-8449.patch" size="5267" author="qwertymaniac" created="Tue, 26 Jun 2012 19:26:39 +0000"/>
                            <attachment id="12530258" name="HADOOP-8449.patch" size="1534" author="qwertymaniac" created="Wed, 30 May 2012 19:22:46 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>2.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>241056</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310191" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
                        <customfieldname>Hadoop Flags</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="10343"><![CDATA[Reviewed]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            13 years, 9 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i0188f:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>5103</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>