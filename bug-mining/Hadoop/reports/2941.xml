<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 21:58:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[HADOOP-18793] S3A StagingCommitter does not clean up staging-uploads directory</title>
                <link>https://issues.apache.org/jira/browse/HADOOP-18793</link>
                <project id="12310240" key="HADOOP">Hadoop Common</project>
                    <description>&lt;p&gt;When setting up StagingCommitter and its internal FileOutputCommitter, a temporary directory that holds MPU information will be created on the default FS, which by default is to be /user/${USER}/tmp/staging/${USER}/${UUID}/staging-uploads.&lt;/p&gt;

&lt;p&gt;On a successful job commit, its child directory (_temporary) will be &lt;a href=&quot;https://github.com/apache/hadoop/blob/a36d8adfd18e88f2752f4387ac4497aadd3a74e7/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/staging/StagingCommitter.java#L516&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;cleaned up&lt;/a&gt; properly, but ${UUID}/staging-uploads will remain.&lt;/p&gt;

&lt;p&gt;This will result in having too many empty ${UUID}/staging-uploads directories under /user/${USER}/tmp/staging/${USER}, and will eventually cause an issue in an environment where the max number of items in a directory is capped (e.g. by dfs.namenode.fs-limits.max-directory-items in HDFS).&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;The directory item limit of /user/${USER}/tmp/staging/${USER} is exceeded: limit=1048576 items=1048576
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxDirItems(FSDirectory.java:1205)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13542678">HADOOP-18793</key>
            <summary>S3A StagingCommitter does not clean up staging-uploads directory</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="4" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">Minor</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="hdaikoku">Harunobu Daikoku</assignee>
                                    <reporter username="hdaikoku">Harunobu Daikoku</reporter>
                        <labels>
                            <label>pull-request-available</label>
                    </labels>
                <created>Thu, 6 Jul 2023 10:39:44 +0000</created>
                <updated>Mon, 10 Jul 2023 13:36:18 +0000</updated>
                            <resolved>Sat, 8 Jul 2023 13:04:02 +0000</resolved>
                                    <version>3.2.2</version>
                                    <fixVersion>3.3.9</fixVersion>
                                    <component>fs/s3</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>5</watches>
                                                                                                                <comments>
                            <comment id="17740546" author="hdaikoku" created="Thu, 6 Jul 2023 10:49:00 +0000"  >&lt;p&gt;I&apos;m guessing ${UUID} directory is preserved on purpose as the commit job ID provided by Spark was not guaranteed to be unique historically, as described in the document.&lt;br/&gt;
Deleting one&apos;s own staging directory might impact other ongoing commit jobs sharing the same ID (timestamp).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/committers.html#Job_commit_fails_java.io.FileNotFoundException_.E2.80.9CFile_hdfs:.2F.2F....2Fstaging-uploads.2F_temporary.2F0_does_not_exist.E2.80.9D&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/committers.html#Job_commit_fails_java.io.FileNotFoundException_.E2.80.9CFile_hdfs:.2F.2F....2Fstaging-uploads.2F_temporary.2F0_does_not_exist.E2.80.9D&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Spark generates job IDs for its committers using the current timestamp, and if two jobs/stages are started in the same second, they will have the same job ID.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;But now I think it would be safe to delete it on a certain condition: fs.s3a.committer.require.uuid is enabled and there is almost no risk of ${UUID} collision.&lt;/p&gt;</comment>
                            <comment id="17740662" author="stevel@apache.org" created="Thu, 6 Jul 2023 15:18:13 +0000"  >&lt;p&gt;should be done in cleanupStagingDirs()&lt;/p&gt;

&lt;p&gt;can you do a run at debug and make sure that &quot;Cleaning up work path&quot; is printed? &lt;/p&gt;


&lt;p&gt;we should always be able to delete the dir as if the uuids are not unique then the jobs are corrupted.&lt;/p&gt;</comment>
                            <comment id="17740675" author="hdaikoku" created="Thu, 6 Jul 2023 15:53:46 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt;, as I checked, workPath here seems to be pointing to a local fs path under fs.s3a.buffer.dir.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-none&quot;&gt;
23/07/06 15:54:56 DEBUG AbstractS3ACommitter: Setting work path to file:/ssd/yarn/nm/usercache/${USER}/appcache/application_1687403148782_2731269/s3a/0e9bd28b-296c-4d6e-bff1-3f7049bd7ecd/_temporary/0/_temporary/attempt_202307061554568951051086712533391_0000_m_000000_0

23/07/06 15:54:56 INFO AbstractS3ACommitterFactory: Using Commmitter StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202307061554568951051086712533391_0000_m_000000_0, name=directory, outputPath=s3a://${USER}/checkpoints/user/${USER}/7663e766-9630-434c-aa7d-a8f429b98dff/e67f2bbf-3850-4f63-9b4b-b722a5fbd81f, workPath=file:/ssd/yarn/nm/usercache/${USER}/appcache/application_1687403148782_2731269/s3a/0e9bd28b-296c-4d6e-bff1-3f7049bd7ecd/_temporary/0/_temporary/attempt_202307061554568951051086712533391_0000_m_000000_0}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202307061554568951051086712533391_0000}; taskId=attempt_202307061554568951051086712533391_0000_m_000000_0, status=&apos;&apos;}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@11ac570b}; outputPath=hdfs://nameservice1/user/${USER}/tmp/staging/${USER}/0e9bd28b-296c-4d6e-bff1-3f7049bd7ecd/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=true}} for s3a://${USER}/checkpoints/user/${USER}/7663e766-9630-434c-aa7d-a8f429b98dff/e67f2bbf-3850-4f63-9b4b-b722a5fbd81f

23/07/06 15:54:56 DEBUG StagingCommitter: Cleaning up work path file:/ssd/yarn/nm/usercache/${USER}/appcache/application_1687403148782_2731269/s3a/0e9bd28b-296c-4d6e-bff1-3f7049bd7ecd/_temporary/0/_temporary/attempt_202307061554568951051086712533391_0000_m_000000_0
23/07/06 15:54:56 INFO AbstractS3ACommitter: Task committer attempt_202307061554568951051086712533391_0000_m_000000_0: commitJob((no job ID)): duration 0:00.430s
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17740690" author="stevel@apache.org" created="Thu, 6 Jul 2023 16:20:12 +0000"  >&lt;p&gt;oh, I see. looking at the staging committer, it does call  wrappedCommitter.cleanupJob() which will delete the _temporary subdir under that staging dir which is where the .pendingset files go, but the parent dir is left alone. so although all files are cleaned up, dirs get leaked.&lt;/p&gt;

&lt;p&gt;how about you provide a patch for this, with a new test case in ITestStagingCommitProtocol? &lt;/p&gt;</comment>
                            <comment id="17740698" author="hdaikoku" created="Thu, 6 Jul 2023 16:43:04 +0000"  >&lt;p&gt;Sure let me work on this.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we should always be able to delete the dir as if the uuids are not unique then the jobs are corrupted.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I agree with you on this. I think we can always simply delete it.&lt;/p&gt;</comment>
                            <comment id="17741095" author="githubbot" created="Fri, 7 Jul 2023 15:38:24 +0000"  >&lt;p&gt;hdaikoku opened a new pull request, #5818:&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Description of PR&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   This PR fixes a bug in StagingCommitter, which leaks the staging uploads directory, by deleting the directory in `StagingCommitter#cleanup()`.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;How was this patch tested?&lt;br/&gt;
   Ran the integration tests in `org.apache.hadoop.fs.s3a.commit.staging.integration` against a LocalStack instance running on my laptop.&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   ```xml&lt;br/&gt;
       &amp;lt;property&amp;gt;&lt;br/&gt;
           &amp;lt;name&amp;gt;fs.s3a.endpoint&amp;lt;/name&amp;gt;&lt;br/&gt;
           &amp;lt;value&amp;gt;s3.ap-south-1.localhost.localstack.cloud:4566&amp;lt;/value&amp;gt;&lt;br/&gt;
       &amp;lt;/property&amp;gt;&lt;/p&gt;

&lt;p&gt;       &amp;lt;property&amp;gt;&lt;br/&gt;
           &amp;lt;name&amp;gt;fs.s3a.connection.ssl.enabled&amp;lt;/name&amp;gt;&lt;br/&gt;
           &amp;lt;value&amp;gt;false&amp;lt;/value&amp;gt;&lt;br/&gt;
       &amp;lt;/property&amp;gt;&lt;br/&gt;
   ```&lt;/p&gt;

&lt;p&gt;   ```&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; -------------------------------------------------------&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt;  T E S T S&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; -------------------------------------------------------&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Running org.apache.hadoop.fs.s3a.commit.staging.integration.ITestStagingCommitProtocol&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Tests run: 24, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.196 s - in org.apache.hadoop.fs.s3a.commit.staging.integration.ITestStagingCommitProtocol&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Running org.apache.hadoop.fs.s3a.commit.staging.integration.ITestDirectoryCommitProtocol&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.62 s - in org.apache.hadoop.fs.s3a.commit.staging.integration.ITestDirectoryCommitProtocol&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Running org.apache.hadoop.fs.s3a.commit.staging.integration.ITestPartitionedCommitProtocol&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING&amp;#93;&lt;/span&gt; Tests run: 24, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 26.316 s - in org.apache.hadoop.fs.s3a.commit.staging.integration.ITestPartitionedCommitProtocol&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Running org.apache.hadoop.fs.s3a.commit.staging.integration.ITestStagingCommitProtocolFailure&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.166 s - in org.apache.hadoop.fs.s3a.commit.staging.integration.ITestStagingCommitProtocolFailure&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; &lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; Results:&lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;INFO&amp;#93;&lt;/span&gt; &lt;br/&gt;
   &lt;span class=&quot;error&quot;&gt;&amp;#91;WARNING&amp;#93;&lt;/span&gt; Tests run: 74, Failures: 0, Errors: 0, Skipped: 1&lt;br/&gt;
   ```&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;For code changes:&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt; Does the title or this PR starts with the corresponding JIRA issue id (e.g. &apos;&lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-17799&quot; title=&quot;Improve the GitHub pull request template&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-17799&quot;&gt;&lt;del&gt;HADOOP-17799&lt;/del&gt;&lt;/a&gt;. Your PR title ...&apos;)?&lt;/li&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt; Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?&lt;/li&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt; If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under &lt;span class=&quot;error&quot;&gt;&amp;#91;ASF 2.0&amp;#93;&lt;/span&gt;(&lt;a href=&quot;http://www.apache.org/legal/resolved.html#category-a)?&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/legal/resolved.html#category-a)?&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;x&amp;#93;&lt;/span&gt; If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?&lt;/li&gt;
&lt;/ul&gt;




</comment>
                            <comment id="17741101" author="githubbot" created="Fri, 7 Jul 2023 15:43:40 +0000"  >&lt;p&gt;hdaikoku commented on code in PR #5818:&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818#discussion_r1256030064&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818#discussion_r1256030064&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;##########&lt;br/&gt;
hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/staging/StagingCommitter.java:&lt;br/&gt;
##########&lt;br/&gt;
@@ -556,14 +574,6 @@ protected void abortJobInternal(CommitContext commitContext,&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;@throws IOException IO failure&lt;br/&gt;
    */&lt;br/&gt;
   protected void deleteDestinationPaths(JobContext context) throws IOException {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Path attemptPath = getJobAttemptPath(context);&lt;/li&gt;
	&lt;li&gt;ignoreIOExceptions(LOG,&lt;/li&gt;
	&lt;li&gt;&quot;Deleting Job attempt Path&quot;, attemptPath.toString(),&lt;/li&gt;
	&lt;li&gt;() -&amp;gt; deleteWithWarning(&lt;/li&gt;
	&lt;li&gt;getJobAttemptFileSystem(context),&lt;/li&gt;
	&lt;li&gt;attemptPath,&lt;/li&gt;
	&lt;li&gt;true));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;Review Comment:&lt;br/&gt;
   Removed these as `attemptPath` here is a sub dir under `${UUID}/staging-uploads`, which has already been deleted in  `deleteStagingUploadsParentDirectory()`.&lt;/p&gt;


</comment>
                            <comment id="17741150" author="githubbot" created="Fri, 7 Jul 2023 17:50:07 +0000"  >&lt;p&gt;hadoop-yetus commented on PR #5818:&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818#issuecomment-1625745185&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818#issuecomment-1625745185&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;   :confetti_ball: *&lt;b&gt;+1 overall&lt;/b&gt;*&lt;/p&gt;






&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Vote &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Subsystem &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Runtime &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  Logfile &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Comment &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;:----:&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;----------:&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;--------:&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;:--------:&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;:-------:&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +0 :ok: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  reexec  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 37s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  Docker mode activated.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; _ Prechecks _ &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  dupname  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  No case conflicting files found.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +0 :ok: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  codespell  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  codespell was not available.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +0 :ok: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  detsecrets  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  1s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  detect-secrets was not available.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  @author  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  The patch does not contain any @author tags.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  test4tests  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  The patch appears to include 2 new or modified test files.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; _ trunk Compile Tests _ &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  mvninstall  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  46m 21s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  trunk passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  compile  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 41s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  trunk passed with JDK Ubuntu-11.0.19+7-post-Ubuntu-0ubuntu120.04.1  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  compile  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 39s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  trunk passed with JDK Private Build-1.8.0_362-8u372-ga~us1-0ubuntu1~20.04-b09  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  checkstyle  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 37s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  trunk passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  mvnsite  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 45s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  trunk passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  javadoc  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 33s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  trunk passed with JDK Ubuntu-11.0.19+7-post-Ubuntu-0ubuntu120.04.1  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  javadoc  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 38s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  trunk passed with JDK Private Build-1.8.0_362-8u372-ga~us1-0ubuntu1~20.04-b09  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  spotbugs  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   1m 13s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  trunk passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  shadedclient  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  33m 39s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  branch has no errors when building and testing our client artifacts.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; _ Patch Compile Tests _ &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  mvninstall  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 30s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  compile  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 32s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed with JDK Ubuntu-11.0.19+7-post-Ubuntu-0ubuntu120.04.1  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  javac  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 32s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  compile  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 28s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed with JDK Private Build-1.8.0_362-8u372-ga~us1-0ubuntu1~20.04-b09  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  javac  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 28s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  blanks  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m  0s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  The patch has no blanks issues.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  checkstyle  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 22s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  mvnsite  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 31s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  javadoc  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 18s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed with JDK Ubuntu-11.0.19+7-post-Ubuntu-0ubuntu120.04.1  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  javadoc  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 27s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed with JDK Private Build-1.8.0_362-8u372-ga~us1-0ubuntu1~20.04-b09  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  spotbugs  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   1m  6s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  the patch passed  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  shadedclient  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  33m 18s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  patch has no errors when building and testing our client artifacts.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th class=&apos;confluenceTh&apos;&gt; _ Other Tests _ &lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  unit  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   2m 39s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  hadoop-aws in the patch passed.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; +1 :green_heart: &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  asflicense  &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;   0m 42s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  The patch does not generate ASF License warnings.  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 130m 15s &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;&amp;nbsp;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;



&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Subsystem &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Report/Notes &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;----------:&lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;:-------------&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Docker &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; ClientAPI=1.43 ServerAPI=1.43 base: &lt;a href=&quot;https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5818/1/artifact/out/Dockerfile&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5818/1/artifact/out/Dockerfile&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; GITHUB PR &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Optional Tests &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient spotbugs checkstyle codespell detsecrets &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; uname &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Linux aad5e097edc1 4.15.0-212-generic #223-Ubuntu SMP Tue May 23 13:09:22 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Build tool &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; maven &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Personality &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; dev-support/bin/hadoop.sh &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; git revision &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; trunk / 47aefe5031078e6d4b2886a48c7aa3344ba01384 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Default Java &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Private Build-1.8.0_362-8u372-ga~us1-0ubuntu1~20.04-b09 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Multi-JDK versions &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.19+7-post-Ubuntu-0ubuntu120.04.1 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_362-8u372-ga~us1-0ubuntu1~20.04-b09 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt;  Test Results &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5818/1/testReport/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5818/1/testReport/&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Max. process+thread count &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; 699 (vs. ulimit of 5500) &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; modules &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Console output &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;a href=&quot;https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5818/1/console&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-5818/1/console&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; versions &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; git=2.25.1 maven=3.6.3 spotbugs=4.2.2 &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Powered by &lt;/td&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; Apache Yetus 0.14.0 &lt;a href=&quot;https://yetus.apache.org&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://yetus.apache.org&lt;/a&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;



&lt;p&gt;   This message was automatically generated.&lt;/p&gt;



</comment>
                            <comment id="17741189" author="JIRAUSER301027" created="Fri, 7 Jul 2023 20:51:02 +0000"  >&lt;p&gt;Hi &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt; I have a similar issue related to this method: &lt;b&gt;cleanupStagingDirs()&lt;/b&gt; using &lt;b&gt;magic committers&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;We have two spark jobs writing to the same s3a directory. We have the property&#160;&lt;b&gt;spark.hadoop.fs.s3a.committer.abort.pending.uploads=false&lt;/b&gt;&lt;br/&gt;
So we see in logs this line:&#160;&lt;/p&gt;

&lt;p&gt;DEBUG &lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; o.a.h.fs.s3a.commit.AbstractS3ACommitter (819): Not cleanup up pending uploads to s3a ...&lt;/p&gt;

&lt;p&gt;(from &lt;a href=&quot;https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/AbstractS3ACommitter.java#L952&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/AbstractS3ACommitter.java#L952&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;But we also see in logs that when the first job finalize &lt;b&gt;the __magic directory is deleted&lt;/b&gt;:&lt;br/&gt;
INFO &#160;&lt;span class=&quot;error&quot;&gt;&amp;#91;main&amp;#93;&lt;/span&gt; o.a.h.fs.s3a.commit.magic.MagicS3GuardCommitter (98): Deleting magic directory s3a://my-bucket/my-table/__magic: duration 0:00.560s&lt;/p&gt;

&lt;p&gt;(from&#160;&#160;&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/magic/MagicS3GuardCommitter.java#L137&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/blob/trunk/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/commit/magic/MagicS3GuardCommitter.java#L137&lt;/a&gt;)&lt;br/&gt;
&#160;&lt;br/&gt;
I&apos;m not sure but I think that this is affecting to the second job that is still running.&lt;br/&gt;
The fact that __magic &lt;b&gt;is deleted recursively&lt;/b&gt; (including all subdirectories like: __magic/job-1 , __magic/job-2 ...) , &lt;b&gt;could be a problem?&lt;/b&gt;&lt;/p&gt;</comment>
                            <comment id="17741280" author="stevel@apache.org" created="Sat, 8 Jul 2023 11:44:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=emanuelvelzi&quot; class=&quot;user-hover&quot; rel=&quot;emanuelvelzi&quot;&gt;emanuelvelzi&lt;/a&gt; that is &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-18568&quot; title=&quot;Magic Committer optional clean up &quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-18568&quot;&gt;&lt;del&gt;HADOOP-18568&lt;/del&gt;&lt;/a&gt;; if someone can provide a patch with tests I will review it. &lt;/p&gt;</comment>
                            <comment id="17741281" author="githubbot" created="Sat, 8 Jul 2023 11:52:29 +0000"  >&lt;p&gt;steveloughran commented on code in PR #5818:&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818#discussion_r1257243324&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818#discussion_r1257243324&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;##########&lt;br/&gt;
hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/commit/AbstractITCommitProtocol.java:&lt;br/&gt;
##########&lt;br/&gt;
@@ -403,6 +403,30 @@ public JobData(Job job,&lt;br/&gt;
       this.committer = committer;&lt;br/&gt;
       conf = job.getConfiguration();&lt;br/&gt;
     }&lt;br/&gt;
+&lt;br/&gt;
+    public Job getJob() &lt;/p&gt;
{
+      return job;
+    }
&lt;p&gt;+&lt;br/&gt;
+    public JobContext getJContext() {&lt;/p&gt;

&lt;p&gt;Review Comment:&lt;br/&gt;
   use JobContext and TaskContext in getters, even if field names aren&apos;t as informative&lt;/p&gt;


</comment>
                            <comment id="17741282" author="githubbot" created="Sat, 8 Jul 2023 11:52:54 +0000"  >&lt;p&gt;steveloughran commented on code in PR #5818:&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818#discussion_r1257244503&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818#discussion_r1257244503&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;##########&lt;br/&gt;
hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/commit/AbstractITCommitProtocol.java:&lt;br/&gt;
##########&lt;br/&gt;
@@ -403,6 +403,30 @@ public JobData(Job job,&lt;br/&gt;
       this.committer = committer;&lt;br/&gt;
       conf = job.getConfiguration();&lt;br/&gt;
     }&lt;br/&gt;
+&lt;br/&gt;
+    public Job getJob() &lt;/p&gt;
{
+      return job;
+    }
&lt;p&gt;+&lt;br/&gt;
+    public JobContext getJContext() {&lt;/p&gt;

&lt;p&gt;Review Comment:&lt;br/&gt;
   actually i&apos;m not worrying about this; will merge as is.&lt;/p&gt;


</comment>
                            <comment id="17741284" author="githubbot" created="Sat, 8 Jul 2023 11:53:57 +0000"  >&lt;p&gt;steveloughran merged PR #5818:&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818&lt;/a&gt;&lt;/p&gt;

</comment>
                            <comment id="17741316" author="githubbot" created="Sat, 8 Jul 2023 16:13:26 +0000"  >&lt;p&gt;hdaikoku commented on PR #5818:&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818#issuecomment-1627391468&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818#issuecomment-1627391468&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;   Thank you for the review &#128591; &lt;/p&gt;

</comment>
                            <comment id="17741320" author="githubbot" created="Sat, 8 Jul 2023 16:36:46 +0000"  >&lt;p&gt;steveloughran commented on PR #5818:&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/hadoop/pull/5818#issuecomment-1627396088&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/hadoop/pull/5818#issuecomment-1627396088&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;   oh, thank for a lovely little patch!&lt;/p&gt;

</comment>
                            <comment id="17741333" author="JIRAUSER301027" created="Sat, 8 Jul 2023 21:15:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt;, I believe this is not exactly the same case.&lt;/p&gt;

&lt;p&gt;I want to perform a clean-up operation, but I want to ensure that I only clean the prefix associated with the job that is currently finalizing.&lt;/p&gt;

&lt;p&gt;I think something like this could be a good solution:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
/**
 * Delete the magic directory.
 */
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void cleanupStagingDirs() {
&lt;span class=&quot;code-comment&quot;&gt;//Path path = magicSubdir(getOutputPath());
&lt;/span&gt;&#160; Path path = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; Path(magicSubdir(getOutputPath()), formatAppAttemptDir(getUUID()));
  &lt;span class=&quot;code-keyword&quot;&gt;try&lt;/span&gt;(DurationInfo ignored = &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; DurationInfo(LOG, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;,
      &lt;span class=&quot;code-quote&quot;&gt;&quot;Deleting magic directory %s&quot;&lt;/span&gt;, path)) {
    Invoker.ignoreIOExceptions(LOG, &lt;span class=&quot;code-quote&quot;&gt;&quot;cleanup magic directory&quot;&lt;/span&gt;, path.toString(),
        () -&amp;gt; deleteWithWarning(getDestFS(), path, &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;));
  }
} &lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;br/&gt;
What do you think of this approach?&lt;/p&gt;</comment>
                            <comment id="17741621" author="JIRAUSER301027" created="Mon, 10 Jul 2023 13:36:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=stevel%40apache.org&quot; class=&quot;user-hover&quot; rel=&quot;stevel@apache.org&quot;&gt;stevel@apache.org&lt;/a&gt;&#160;I have created a related Jira ticket, &lt;a href=&quot;https://issues.apache.org/jira/browse/HADOOP-18797&quot; title=&quot;Support Concurrent Writes With S3A Magic Committer&quot; class=&quot;issue-link&quot; data-issue-key=&quot;HADOOP-18797&quot;&gt;&lt;del&gt;HADOOP-18797&lt;/del&gt;&lt;/a&gt;, to address my problem.&lt;/p&gt;

&lt;p&gt;(I apologize for interrupting this ticket with my issue.)&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[false]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                    <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            2 years, 18 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z1izz4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </customfields>
    </item>
</channel>
</rss>