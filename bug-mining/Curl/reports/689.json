{"url":"https://api.github.com/repos/curl/curl/issues/16955","repository_url":"https://api.github.com/repos/curl/curl","labels_url":"https://api.github.com/repos/curl/curl/issues/16955/labels{/name}","comments_url":"https://api.github.com/repos/curl/curl/issues/16955/comments","events_url":"https://api.github.com/repos/curl/curl/issues/16955/events","html_url":"https://github.com/curl/curl/issues/16955","id":2970979461,"node_id":"I_kwDOAAiu0c6xFYyF","number":16955,"title":"HTTP/2 protocol deadlock when using flow control and when streams have very different data rates","user":{"login":"lf-","id":6652840,"node_id":"MDQ6VXNlcjY2NTI4NDA=","avatar_url":"https://avatars.githubusercontent.com/u/6652840?v=4","gravatar_id":"","url":"https://api.github.com/users/lf-","html_url":"https://github.com/lf-","followers_url":"https://api.github.com/users/lf-/followers","following_url":"https://api.github.com/users/lf-/following{/other_user}","gists_url":"https://api.github.com/users/lf-/gists{/gist_id}","starred_url":"https://api.github.com/users/lf-/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lf-/subscriptions","organizations_url":"https://api.github.com/users/lf-/orgs","repos_url":"https://api.github.com/users/lf-/repos","events_url":"https://api.github.com/users/lf-/events{/privacy}","received_events_url":"https://api.github.com/users/lf-/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":194601710,"node_id":"MDU6TGFiZWwxOTQ2MDE3MTA=","url":"https://api.github.com/repos/curl/curl/labels/HTTP/2","name":"HTTP/2","color":"009800","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"icing","id":15102,"node_id":"MDQ6VXNlcjE1MTAy","avatar_url":"https://avatars.githubusercontent.com/u/15102?v=4","gravatar_id":"","url":"https://api.github.com/users/icing","html_url":"https://github.com/icing","followers_url":"https://api.github.com/users/icing/followers","following_url":"https://api.github.com/users/icing/following{/other_user}","gists_url":"https://api.github.com/users/icing/gists{/gist_id}","starred_url":"https://api.github.com/users/icing/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/icing/subscriptions","organizations_url":"https://api.github.com/users/icing/orgs","repos_url":"https://api.github.com/users/icing/repos","events_url":"https://api.github.com/users/icing/events{/privacy}","received_events_url":"https://api.github.com/users/icing/received_events","type":"User","user_view_type":"public","site_admin":false},"assignees":[{"login":"icing","id":15102,"node_id":"MDQ6VXNlcjE1MTAy","avatar_url":"https://avatars.githubusercontent.com/u/15102?v=4","gravatar_id":"","url":"https://api.github.com/users/icing","html_url":"https://github.com/icing","followers_url":"https://api.github.com/users/icing/followers","following_url":"https://api.github.com/users/icing/following{/other_user}","gists_url":"https://api.github.com/users/icing/gists{/gist_id}","starred_url":"https://api.github.com/users/icing/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/icing/subscriptions","organizations_url":"https://api.github.com/users/icing/orgs","repos_url":"https://api.github.com/users/icing/repos","events_url":"https://api.github.com/users/icing/events{/privacy}","received_events_url":"https://api.github.com/users/icing/received_events","type":"User","user_view_type":"public","site_admin":false}],"milestone":null,"comments":2,"created_at":"2025-04-04T00:25:44Z","updated_at":"2025-04-05T12:56:37Z","closed_at":"2025-04-05T12:56:37Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"### I did this\n\nYou can clone the whole repro from https://gist.github.com/lf-/276cb01858d894f4946787f69254a923.\n\nUpstream bug report: https://git.lix.systems/lix-project/lix/issues/662\n\nThis is the bug I promised to report after https://github.com/curl/curl/issues/16280 was fixed.\n\n# What is going wrong?\n\nCurl fails to send window size updates when large differences exist in HTTP/2 stream throughput when using pauses.\nThis then presents as the transfer getting deadlocked, since Curl fails to request more data with more window size.\n\n## Symptoms\n\nThe first transfer finishes, the second transfer has a *bunch* of bytes buffered up after its initial window size, and the receiver is slowly drip-feeding them out.\n\n```\n<...>\n!! UNPAUSE !! 0x5555c91e9d20 uri = https://localhost:9999/foo\n!! UNPAUSE !! 0x5555c91e9d20 uri = https://localhost:9999/foo\n!! UNPAUSE !! 0x5555c91e9d20 uri = https://localhost:9999/foo\n!! UNPAUSE !! 0x5555c91e9d20 uri = https://localhost:9999/foo\n!! UNPAUSE !! 0x5555c91e9d20 uri = https://localhost:9999/foo\n!! UNPAUSE !! 0x5555c91e9d20 uri = https://localhost:9999/foo\ncurl: [0-0] [MULTI] [PERFORMING] multi_perform(running=2)\ncurl: [0-0] [TCP] recv(len=5) -> 5, err=0\ncurl: [0-0] [SSL] ossl_bio_cf_in_read(len=5) -> 5, err=0\ncurl: [0-0] [TCP] recv(len=33) -> 33, err=0\ncurl: [0-0] [SSL] ossl_bio_cf_in_read(len=33) -> 33, err=0\ncurl: [0-0] [SSL] cf_recv(len=16384) -> 16, 0\ncurl: [0-0] [HTTP/2] [0] ingress: read 16 bytes\ncurl: [0-0] [WRITE] [OUT] wrote 7 body bytes -> 7\ncurl: [0-0] [WRITE] [PAUSE] writing 7/7 bytes of type 1 -> 0\ncurl: [0-0] [WRITE] download_write body(type=1, blen=7) -> 0\ncurl: [0-0] [WRITE] client_write(type=1, len=7) -> 0\ncurl: [0-0] [WRITE] xfer_write_resp(len=7, eos=0) -> 0\ncurl: [0-0] [HTTP/2] [1] <- FRAME[DATA, len=7, eos=1, padlen=0]\ncurl: [0-0] [HTTP/2] [1] DATA, window=7/10485760\ncurl: [0-0] [HTTP/2] [1] DRAIN select_bits=1\ncurl: [0-0] [HTTP/2] [1] CLOSED\ncurl: [0-0] [HTTP/2] [1] DRAIN select_bits=1\ncurl: [0-0] [HTTP/2] [0] progress ingress: inbufg=0\ncurl: [0-0] [HTTP/2] [1] DRAIN select_bits=1\ncurl: [0-0] [HTTP/2] [0] progress ingress: done\ncurl: [0-0] [HTTP/2] [1] returning CLOSE\ncurl: [0-0] [HTTP/2] handle_stream_close -> 0, 0\ncurl: [0-0] [HTTP/2] [1] cf_recv(len=16384) -> 0 0, window=-1/-1, connection 933230227/1048576000\ncurl: [0-0] sendrecv_dl: we are done\ncurl: [0-0] nread == 0, stream closed, bailing\ncurl: [0-0] [WRITE] [PAUSE] writing 0/0 bytes of type 81 -> 0\ncurl: [0-0] [WRITE] download_write body(type=81, blen=0) -> 0\ncurl: [0-0] [WRITE] client_write(type=81, len=0) -> 0\ncurl: [0-0] [WRITE] xfer_write_resp(len=0, eos=1) -> 0\ncurl: [0-0] [MULTI] [PERFORMING] -> [DONE] (line 1856)\ncurl: [0-0] [MULTI] [DONE] multi_done: status: 0 prem: 0 done: 0\ncurl: [0-0] [WRITE] [OUT] done\ncurl: [0-0] [READ] client_reset, clear readers\ncurl: [0-x] [MULTI] [DONE] Connection still in use 1, no more multi_done now!\ncurl: [0-x] [MULTI] [DONE] -> [COMPLETED] (line 2471)\ncurl: [0-x] [MULTI] [COMPLETED] Expire cleared\ncurl: [0-x] [MULTI] [COMPLETED] -> [MSGSENT] (line 2566)\nfinished download of 'https://localhost:9999/foo'; curl status = 0, body = 104860013d bytes\ncurl: [0-x] [MULTI] [COMPLETED] removed, transfers=1\ncurl: [1-0] [MULTI] [PERFORMING] multi_wait pollset[], timeouts=0, paused 0/1 (r/w)\n!! UNPAUSE !! 0x5555c91e9d20 uri = https://localhost:9999/foo\n!! UNPAUSE !! 0x5555c91e9d20 uri = https://localhost:9999/foo\ncurl: [1-0] [MULTI] [PERFORMING] multi_perform(running=1)\ncurl: [1-0] [MULTI] [PERFORMING] multi_wait pollset[], timeouts=0, paused 0/1 (r/w)\n!! UNPAUSE !! 0x5555c91e9760 uri = https://localhost:9999/bar\ncurl: [1-0] [HTTP/2] [3] DRAIN select_bits=1\ncurl: [1-0] [HTTP/2] [3] stream now unpaused\ncurl: [1-0] [WRITE] [OUT] unpause\ncurl: [1-0] [WRITE] [OUT] paused, buffering 16384 more bytes (16384/67108864)\n```\n\nFirst one done!\n\n```\n<...>\n\ncurl: [1-0] [WRITE] [PAUSE] flushed 16384/901066 bytes, type=1 -> 0\n!! PAUSE !!https://localhost:9999/bar\ncurl: [1-0] [WRITE] [OUT] wrote 16384 body bytes -> 268435457\ncurl: [1-0] [WRITE] [OUT] PAUSE requested by client\ncurl: [1-0] [WRITE] [OUT] paused, buffering 16384 more bytes (0/67108864)\ncurl: [1-0] [WRITE] [PAUSE] flushed 16384/884682 bytes, type=1 -> 0\ncurl: [1-0] [MULTI] [PERFORMING] multi_perform(running=1)\ncurl: [1-0] [MULTI] [PERFORMING] multi_wait pollset[], timeouts=0, paused 0/1 (r/w)\ncurl: [1-0] [MULTI] [PERFORMING] multi_perform(running=1)\ncurl: [1-0] [MULTI] [PERFORMING] multi_wait pollset[], timeouts=0, paused 0/1 (r/w)\n!! UNPAUSE !! 0x5555c91e9760 uri = https://localhost:9999/bar\ncurl: [1-0] [HTTP/2] [3] DRAIN select_bits=1\ncurl: [1-0] [HTTP/2] [3] stream now unpaused\ncurl: [1-0] [WRITE] [OUT] unpause\ncurl: [1-0] [WRITE] [OUT] paused, buffering 16384 more bytes (16384/67108864)\ncurl: [1-0] [WRITE] [OUT] wrote 16384 body bytes -> 16384\ncurl: [1-0] [WRITE] [OUT] wrote 16384 body bytes -> 16384\ncurl: [1-0] [WRITE] [PAUSE] flushed 16384/868298 bytes, type=1 -> 0\n\n<...>\n\ncurl: [1-0] [WRITE] [PAUSE] flushed 16384/65482 bytes, type=1 -> 0\ncurl: [1-0] [WRITE] [OUT] wrote 16384 body bytes -> 16384\ncurl: [1-0] [WRITE] [PAUSE] flushed 16384/49098 bytes, type=1 -> 0\ncurl: [1-0] [WRITE] [OUT] wrote 16384 body bytes -> 16384\ncurl: [1-0] [WRITE] [PAUSE] flushed 16384/32714 bytes, type=1 -> 0\ncurl: [1-0] [WRITE] [OUT] wrote 16330 body bytes -> 16330\ncurl: [1-0] [WRITE] [PAUSE] flushed 16330/16330 bytes, type=1 -> 0\ncurl: [1-0] [MULTI] [PERFORMING] multi_perform(running=1)\ncurl: [1-0] [TCP] recv(len=5) -> -1, err=81\ncurl: [1-0] [SSL] ossl_bio_cf_in_read(len=5) -> -1, err=81\ncurl: [1-0] [SSL] cf_recv(len=16384) -> -1, 81\ncurl: [1-0] [HTTP/2] [0] progress ingress: done\ncurl: [1-0] [HTTP/2] [3] cf_recv(len=16384) -> -1 81, window=10485760/10485760, connection 933230227/1048576000\ncurl: [1-0] [MULTI] [PERFORMING] multi_wait pollset[fd=5 IN], timeouts=0\ncurl: [1-0] [MULTI] [PERFORMING] multi_perform(running=1)\ncurl: [1-0] [TCP] recv(len=5) -> -1, err=81\ncurl: [1-0] [SSL] ossl_bio_cf_in_read(len=5) -> -1, err=81\ncurl: [1-0] [SSL] cf_recv(len=16384) -> -1, 81\ncurl: [1-0] [HTTP/2] [0] progress ingress: done\ncurl: [1-0] [HTTP/2] [3] cf_recv(len=16384) -> -1 81, window=10485760/10485760, connection 933230227/1048576000\ncurl: [1-0] [MULTI] [PERFORMING] multi_wait pollset[fd=5 IN], timeouts=0\n!! UNPAUSE !! 0x5555c91e9760 uri = https://localhost:9999/bar\ncurl: [1-0] [MULTI] [PERFORMING] multi_perform(running=1)\ncurl: [1-0] [TCP] recv(len=5) -> -1, err=81\ncurl: [1-0] [SSL] ossl_bio_cf_in_read(len=5) -> -1, err=81\ncurl: [1-0] [SSL] cf_recv(len=16384) -> -1, 81\ncurl: [1-0] [HTTP/2] [0] progress ingress: done\ncurl: [1-0] [HTTP/2] [3] cf_recv(len=16384) -> -1 81, window=10485760/10485760, connection 933230227/1048576000\ncurl: [1-0] [MULTI] [PERFORMING] multi_wait pollset[fd=5 IN], timeouts=0\n!! UNPAUSE !! 0x5555c91e9760 uri = https://localhost:9999/bar\n```\n\nAt this point it's stuck and will not make any forward progress:\n\n```\ncurl: [1-0] [MULTI] [PERFORMING] multi_perform(running=1)\ncurl: [1-0] [TCP] recv(len=5) -> -1, err=81\ncurl: [1-0] [SSL] ossl_bio_cf_in_read(len=5) -> -1, err=81\ncurl: [1-0] [SSL] cf_recv(len=16384) -> -1, 81\ncurl: [1-0] [HTTP/2] [0] progress ingress: done\ncurl: [1-0] [HTTP/2] [3] cf_recv(len=16384) -> -1 81, window=10485760/10485760, connection 933230227/1048576000\ncurl: [1-0] [MULTI] [PERFORMING] multi_wait pollset[fd=5 IN], timeouts=0\ncurl: [1-0] [MULTI] [PERFORMING] multi_perform(running=1)\ncurl: [1-0] [TCP] recv(len=5) -> -1, err=81\ncurl: [1-0] [SSL] ossl_bio_cf_in_read(len=5) -> -1, err=81\ncurl: [1-0] [SSL] cf_recv(len=16384) -> -1, 81\ncurl: [1-0] [HTTP/2] [0] progress ingress: done\ncurl: [1-0] [HTTP/2] [3] cf_recv(len=16384) -> -1 81, window=10485760/10485760, connection 933230227/1048576000\n```\n\nThe streams have received the following approximate amounts of data at time of deadlock:\n\n```\n(rr) p nix::recvd1\n$1 = 104860013\n(rr) p nix::recvd2\n$2 = 10485760\n```\n\nI have captured a packet capture of the problem with `SSLKEYLOGFILE` and tcpdump and observed that there are numerous WINDOW_UPDATE frames for stream 1 and only one (at the very beginning) for stream 3 (the slow one).\n\nThat is to say, stream 3 has more data to read from the server, but curl didn't ask the server for it and is sitting twiddling its thumbs hoping someone, anyone, will give it some data.\n\n## Reproducer\n\nThis is a reproducer using a hacked up version of the Lix HTTP library.\nThere are two streams being fetched via the same connection, the latter of which is much much slower to read.\nThey are both fetching the same 100MB file of urandom garbage.\nThe data being fetched is zstd encoded (unsure if this matters; curl compression support is disabled for testing purposes).\n\n```\nmkdir trash\ndd if=/dev/urandom of=trash/foo bs=1M count=1024\nln -s foo trash/bar\n```\n\nCaddyfile:\n\n```\n{\n    local_certs\n    skip_install_trust\n    auto_https disable_redirects\n    debug\n}\n:9999 {\n    bind 127.0.0.1\n    tls internal {\n        on_demand\n    }\n\n    root * ./trash\n    file_server\n\n    encode {\n        zstd\n        match {\n            header Content-Type *\n        }\n    }\n}\n```\n\nShort version of the reproducer:\n\n```c++\n    auto ft = makeCurlFileTransfer2(0);\n    auto a = ft->download(\"https://localhost:9999/foo\");\n    auto b = ft->download(\"https://localhost:9999/bar\");\n\n    auto af = std::async(std::launch::async, [&] {\n        char c[1024];\n        for (;;) {\n            recvd1 += a->read(c, sizeof(c));\n        }\n    });\n    auto bf = std::async(std::launch::async, [&] {\n        char c[1024];\n        for (;;) {\n            recvd2 += b->read(c, sizeof(c));\n            usleep(1000);\n        }\n    });\n\n    return 0;\n```\n\nFor the runnable version, see `repro.cc` and Makefile; it has been checked to build with Clang 18 on NixOS.\nI am deeply sorry about submitting 600 lines of C++ of repro.\nI cut down the lines by about 50% over the original code, and it is now self-contained.\nMore reduction would take rewriting it and that would probably make the code harder to deal with for debugging.\n\nIf you need more reduction, I can do it, but it will take a while.\n\nSet up the Caddy (2.8.4 was used) server as above (mkdir trash, dd some randomness), then run it:\n\n```\ncaddy run --config Caddyfile\n```\n\nRun the repro:\n\n```\n$ make repro\n$ SSLKEYLOGFILE=keys.log LD_PRELOAD=/path/to/curl/lib/libcurl.so CURL_DEBUG=all ./repro\n```\n\nIf you don't want to copy paste this stuff, you can `git clone https://gist.github.com/lf-/276cb01858d894f4946787f69254a923 repro/`\n\n<details>\n<summary>\nMakefile\n</summary>\n\n```Makefile\nCXXFLAGS = -std=c++20 -g -O2\nCXXFLAGS += $(shell pkg-config --cflags libcurl)\nCC = $(CXX)\nLDFLAGS += $(shell pkg-config --libs libcurl)\nrepro: repro.o\n```\n\n</details>\n\n<details>\n<summary>\nrepro.cc\n</summary>\n\n```c++\n#include <cstring>\n#include <curl/curl.h>\n#include <iostream>\n#include <inttypes.h>\n#include <future>\n#include <map>\n#include <memory>\n#include <set>\n#include <sstream>\n#include <vector>\n#include <unistd.h>\n\n#include <cstdlib>\n#include <list>\n#include <mutex>\n#include <condition_variable>\n#include <cassert>\n#include <optional>\n#include <utility>\n\n/**\n * Abstract source of binary data.\n */\nstruct Source\n{\n    virtual ~Source() {}\n\n    /**\n     * Store exactly ‘len’ bytes in the buffer pointed to by ‘data’.\n     * It blocks until all the requested data is available, or throws\n     * an error if it is not going to be available.\n     */\n    void operator()(char * data, size_t len);\n\n    /**\n     * Store up to ‘len’ in the buffer pointed to by ‘data’, and\n     * return the number of bytes stored.  It blocks until at least\n     * one byte is available.\n     *\n     * Should not return 0 (generally you want to throw EndOfFile), but nothing\n     * stops that.\n     *\n     * \\throws EndOfFile if there is no more data.\n     */\n    virtual size_t read(char * data, size_t len) = 0;\n\n    virtual bool good()\n    {\n        return true;\n    }\n};\n\n/**\n * This template class ensures synchronized access to a value of type\n * T. It is used as follows:\n *\n *   struct Data { int x; ... };\n *\n *   Sync<Data> data;\n *\n *   {\n *     auto data_(data.lock());\n *     data_->x = 123;\n *   }\n *\n * Here, \"data\" is automatically unlocked when \"data_\" goes out of\n * scope.\n */\ntemplate<class T, class M = std::mutex>\nclass Sync\n{\nprivate:\n    M mutex;\n    T data;\n\npublic:\n\n    Sync() {}\n    Sync(const T & data) : data(data) {}\n    Sync(T && data) noexcept : data(std::move(data)) {}\n\n    template<typename... Args>\n    Sync(std::in_place_t, Args &&... args) : data(std::forward<Args>(args)...)\n    {\n    }\n\n    class Lock\n    {\n    protected:\n        // Non-owning pointer. This would be an\n        // optional<reference_wrapper<Sync>> if it didn't break gdb accessing\n        // Lock values (as of 2024-06-15, gdb 14.2)\n        Sync * s;\n        std::unique_lock<M> lk;\n        friend Sync;\n        Lock(Sync & s) : s(&s), lk(s.mutex) {}\n        Lock(Sync & s, std::unique_lock<M> lk) : s(&s), lk(std::move(lk)) {}\n\n        inline void checkLockingInvariants()\n        {\n            assert(s);\n            assert(lk.owns_lock());\n        }\n\n    public:\n        Lock(Lock && l) : s(l.s), lk(std::move(l.lk))\n        {\n            l.s = nullptr;\n        }\n\n        Lock(const Lock & l) = delete;\n\n        ~Lock() = default;\n\n        T * operator->()\n        {\n            checkLockingInvariants();\n            return &s->data;\n        }\n\n        T & operator*()\n        {\n            checkLockingInvariants();\n            return s->data;\n        }\n\n        /**\n         * Wait for the given condition variable with no timeout.\n         *\n         * May spuriously wake up.\n         */\n        void wait(std::condition_variable & cv)\n        {\n            checkLockingInvariants();\n            cv.wait(lk);\n        }\n    };\n\n    /**\n     * Lock this Sync and return a RAII guard object.\n     */\n    Lock lock()\n    {\n        return Lock(*this);\n    }\n\n    std::optional<Lock> tryLock()\n    {\n        if (std::unique_lock lk(mutex, std::try_to_lock_t{}); lk.owns_lock()) {\n            return Lock{*this, std::move(lk)};\n        } else {\n            return std::nullopt;\n        }\n    }\n};\n\nstruct curlFileTransfer2\n{\n    std::unique_ptr<CURLM, decltype([](auto * m) { curl_multi_cleanup(m); })> curlm;\n\n    const unsigned int baseRetryTimeMs;\n\n    void wakeup()\n    {\n        if (auto mc = curl_multi_wakeup(curlm.get())) {\n            std::ostringstream err;\n            err << \"unexpected error from curl_multi_wakeup(): \" << curl_multi_strerror(mc);\n            throw std::runtime_error(err.str());\n        }\n    }\n\n    void stopWorkerThread()\n    {\n        /* Signal the worker thread to exit. */\n        {\n            auto state(state_.lock());\n            state->quit = true;\n        }\n        wakeup();\n    }\n\n    struct TransferItem\n    {\n        struct DownloadState\n        {\n            bool done = false;\n            std::exception_ptr exc;\n            std::string data;\n        };\n\n        std::string uri;\n        Sync<DownloadState> downloadState;\n        std::condition_variable downloadEvent;\n        bool headersDone = false, metadataReturned = false;\n        std::promise<void> metadataPromise;\n\n        uint64_t bodySize = 0;\n\n        std::unique_ptr<curl_slist, decltype([](auto * s) { curl_slist_free_all(s); })>\n            requestHeaders;\n        std::unique_ptr<CURL, decltype([](auto * c) { curl_easy_cleanup(c); })> req;\n        // buffer to accompany the `req` above\n        char errbuf[CURL_ERROR_SIZE];\n\n        inline static const std::set<long>\n            successfulStatuses{200, 201, 204, 206, 304, 0 /* other protocol */};\n        void appendCurlHeader(std::string_view name, std::string_view value)\n        {\n            std::ostringstream ss;\n            ss << name << \": \" << value;\n            auto header = ss.str();\n            if (auto next = curl_slist_append(requestHeaders.get(), header.c_str())) {\n                (void) requestHeaders.release(); // next now owns this pointer\n                requestHeaders.reset(next);\n            } else {\n                abort();\n            }\n        }\n\n        TransferItem(const std::string & uri) : uri(uri), req(curl_easy_init())\n        {\n            if (req == nullptr) {\n                abort();\n            }\n\n            curl_easy_setopt(req.get(), CURLOPT_VERBOSE, 1);\n            curl_easy_setopt(req.get(), CURLOPT_DEBUGFUNCTION, TransferItem::debugCallback);\n\n            curl_easy_setopt(req.get(), CURLOPT_URL, uri.c_str());\n            curl_easy_setopt(req.get(), CURLOPT_FOLLOWLOCATION, 1L);\n\n            curl_easy_setopt(\n                req.get(), CURLOPT_ACCEPT_ENCODING, nullptr\n            ); // Disable internal handling\n            appendCurlHeader(\"Accept-Encoding\", \"zstd\");\n\n            curl_easy_setopt(req.get(), CURLOPT_MAXREDIRS, 10);\n            curl_easy_setopt(req.get(), CURLOPT_NOSIGNAL, 1);\n            curl_easy_setopt(req.get(), CURLOPT_PIPEWAIT, 1);\n            curl_easy_setopt(req.get(), CURLOPT_HTTP_VERSION, CURL_HTTP_VERSION_2TLS);\n            curl_easy_setopt(req.get(), CURLOPT_WRITEFUNCTION, TransferItem::writeCallbackWrapper);\n            curl_easy_setopt(req.get(), CURLOPT_WRITEDATA, this);\n\n            curl_easy_setopt(req.get(), CURLOPT_NOPROGRESS, 1);\n\n            curl_easy_setopt(req.get(), CURLOPT_ERRORBUFFER, errbuf);\n            errbuf[0] = 0;\n\n            curl_easy_setopt(req.get(), CURLOPT_PROTOCOLS_STR, \"http,https,ftp,ftps\");\n\n            curl_easy_setopt(req.get(), CURLOPT_HTTPHEADER, requestHeaders.get());\n            // This is a repro, we don't need any of that \"security\"\n            curl_easy_setopt(req.get(), CURLOPT_SSL_VERIFYPEER, 0);\n        }\n\n        void maybeFinishSetup()\n        {\n            if (headersDone) {\n                return;\n            }\n\n            metadataPromise.set_value();\n            metadataReturned = true;\n\n            headersDone = true;\n        }\n\n        std::exception_ptr callbackException;\n\n        size_t writeCallback(void * contents, size_t size, size_t nmemb)\n        {\n            const size_t realSize = size * nmemb;\n\n            try {\n                maybeFinishSetup();\n\n                auto state = downloadState.lock();\n\n                // when the buffer is full (as determined by a historical magic value) we\n                // pause the transfer and wait for the receiver to unpause it when ready.\n                if (state->data.size() > 1024 * 1024) {\n                    std::cout << \"!! PAUSE !!\" << this->uri << \"\\n\";\n                    return CURL_WRITEFUNC_PAUSE;\n                }\n\n                state->data.append(static_cast<const char *>(contents), realSize);\n                downloadEvent.notify_all();\n                bodySize += realSize;\n                return realSize;\n            } catch (...) {\n                callbackException = std::current_exception();\n                return CURL_WRITEFUNC_ERROR;\n            }\n        }\n\n        static size_t writeCallbackWrapper(void * contents, size_t size, size_t nmemb, void * userp)\n        {\n            return static_cast<TransferItem *>(userp)->writeCallback(contents, size, nmemb);\n        }\n\n        static int\n        debugCallback(CURL * handle, curl_infotype type, char * data, size_t size, void * userptr)\n        {\n            if (type == CURLINFO_TEXT) {\n                std::cout << \"curl: \" << std::string(data, size);\n            }\n            return 0;\n        }\n\n        void finish(CURLcode code)\n        {\n            maybeFinishSetup();\n\n            printf(\n                \"finished download of '%s'; curl status = %d, body = %\" PRIu64 \"d bytes\\n\",\n                uri.c_str(),\n                code,\n                bodySize\n            );\n\n            if (callbackException) {\n                abort();\n            }\n\n            else if (code == CURLE_OK)\n            {\n                downloadState.lock()->done = true;\n                downloadEvent.notify_all();\n            } else {\n                std::cout << \"foo\\n\";\n            }\n        }\n    };\n\n    void unpause(const std::shared_ptr<TransferItem> & transfer)\n    {\n        auto lock = state_.lock();\n        lock->unpause.push_back(transfer);\n        wakeup();\n    }\n\n    struct State\n    {\n        bool quit = false;\n        std::vector<std::shared_ptr<TransferItem>> incoming;\n        std::vector<std::shared_ptr<TransferItem>> unpause;\n    };\n\n    Sync<State> state_;\n\n    std::thread workerThread;\n\n    void workerThreadEntry()\n    {\n        workerThreadMain();\n        exit(1);\n    }\n\n    curlFileTransfer2(unsigned int baseRetryTimeMs)\n        : curlm(curl_multi_init())\n        , baseRetryTimeMs(baseRetryTimeMs)\n    {\n        if (curlm == nullptr) {\n            abort();\n        }\n\n        static std::once_flag globalInit;\n        std::call_once(globalInit, curl_global_init, CURL_GLOBAL_ALL);\n\n        curl_multi_setopt(curlm.get(), CURLMOPT_PIPELINING, CURLPIPE_MULTIPLEX);\n        curl_multi_setopt(curlm.get(), CURLMOPT_MAX_TOTAL_CONNECTIONS, 25);\n\n        workerThread = std::thread([&]() { workerThreadEntry(); });\n    }\n\n    ~curlFileTransfer2()\n    {\n        stopWorkerThread();\n        workerThread.join();\n    }\n\n    void workerThreadMain()\n    {\n        std::map<CURL *, std::shared_ptr<TransferItem>> items;\n\n        bool quit = false;\n\n        while (true) {\n            /* Let curl do its thing. */\n            int running;\n            CURLMcode mc = curl_multi_perform(curlm.get(), &running);\n            if (mc != CURLM_OK) {\n                std::ostringstream err;\n                err << \"unexpected error from curl_multi_perform():\" << curl_multi_strerror(mc);\n                throw std::runtime_error(err.str());\n            }\n\n            /* Set the promises of any finished requests. */\n            CURLMsg * msg;\n            int left;\n            while ((msg = curl_multi_info_read(curlm.get(), &left))) {\n                if (msg->msg == CURLMSG_DONE) {\n                    auto i = items.find(msg->easy_handle);\n                    assert(i != items.end());\n                    i->second->finish(msg->data.result);\n                    curl_multi_remove_handle(curlm.get(), i->second->req.get());\n                    items.erase(i);\n                }\n            }\n\n            // only exit when all transfers are done (which will happen through the\n            // progress callback issuing an abort in the case of user interruption)\n            if (items.empty() && quit) {\n                break;\n            }\n\n            /* Wait for activity, including wakeup events. */\n            mc = curl_multi_poll(curlm.get(), nullptr, 0, 1000, nullptr);\n            if (mc != CURLM_OK) {\n                std::ostringstream err;\n                err << \"unexpected error from curl_multi_poll(): \" << curl_multi_strerror(mc);\n                throw std::runtime_error(err.str());\n            }\n\n            /* Add new curl requests from the incoming requests queue,\n               except for requests that are embargoed (waiting for a\n               retry timeout to expire). */\n\n            std::vector<std::shared_ptr<TransferItem>> incoming;\n\n            {\n                auto unpause = [&] { return std::move(state_.lock()->unpause); }();\n                for (auto & item : unpause) {\n                    std::cout << \"!! UNPAUSE !! \" << item.get() << \" uri = \" << item->uri << \"\\n\";\n                    curl_easy_pause(item->req.get(), CURLPAUSE_CONT);\n                }\n            }\n\n            {\n                auto state(state_.lock());\n                incoming = std::move(state->incoming);\n                quit = state->quit;\n            }\n\n            for (auto & item : incoming) {\n                std::cout << \"starting download of \" << item->uri << \"\\n\";\n                curl_multi_add_handle(curlm.get(), item->req.get());\n                items[item->req.get()] = item;\n            }\n        }\n\n        std::cout << \"download thread shutting down\\n\";\n    }\n\n    void enqueueItem(std::shared_ptr<TransferItem> item)\n    {\n        {\n            auto state(state_.lock());\n            if (state->quit) {\n                abort();\n            }\n            state->incoming.push_back(item);\n        }\n        wakeup();\n    }\n\n    std::unique_ptr<Source> enqueueFileTransfer(const std::string & uri)\n    {\n        auto source = std::make_unique<TransferSource>(*this, uri);\n        source->awaitData();\n        return std::move(source);\n    }\n\n    struct TransferSource : Source\n    {\n        curlFileTransfer2 & parent;\n        std::string uri;\n\n        std::shared_ptr<TransferItem> transfer;\n        std::string chunk;\n        std::string_view buffered;\n\n        TransferSource(curlFileTransfer2 & parent, const std::string & uri)\n            : parent(parent)\n            , uri(uri)\n        {\n            startTransfer(uri);\n        }\n\n        void startTransfer(const std::string & uri)\n        {\n            transfer = std::make_shared<TransferItem>(uri);\n            parent.enqueueItem(transfer);\n            return transfer->metadataPromise.get_future().get();\n        }\n\n        bool awaitData()\n        {\n            auto waitForData = [&] {\n                /* Grab data if available, otherwise wait for the download\n                   thread to wake us up. */\n                while (buffered.empty()) {\n                    auto state(transfer->downloadState.lock());\n\n                    if (!state->data.empty()) {\n                        chunk = std::move(state->data);\n                        buffered = chunk;\n                        parent.unpause(transfer);\n                    } else if (state->done) {\n                        return false;\n                    } else {\n                        parent.unpause(transfer);\n                        state.wait(transfer->downloadEvent);\n                    }\n                }\n\n                return true;\n            };\n            return waitForData();\n        }\n\n        size_t read(char * data, size_t len) override\n        {\n            size_t total = 0;\n            while (total < len && awaitData()) {\n                const auto available = std::min(len - total, buffered.size());\n                memcpy(data + total, buffered.data(), available);\n                buffered.remove_prefix(available);\n                total += available;\n            }\n\n            if (total == 0) {\n                throw std::runtime_error(\"transfer finished\");\n            }\n\n            return total;\n        }\n    };\n\n    std::unique_ptr<Source> download(const std::string & uri)\n    {\n        return enqueueFileTransfer(uri);\n    }\n};\n\nstd::shared_ptr<curlFileTransfer2> makeCurlFileTransfer2(std::optional<unsigned int> baseRetryTimeMs\n)\n{\n    return std::make_shared<curlFileTransfer2>(baseRetryTimeMs.value_or(250));\n}\n\nvolatile size_t recvd1 = 0;\nvolatile size_t recvd2 = 0;\n\nint main()\n{\n    auto ft = makeCurlFileTransfer2(0);\n    auto a = ft->download(\"https://localhost:9999/foo\");\n    auto b = ft->download(\"https://localhost:9999/bar\");\n\n    auto af = std::async(std::launch::async, [&] {\n        char c[1024];\n        for (;;) {\n            recvd1 += a->read(c, sizeof(c));\n        }\n    });\n    auto bf = std::async(std::launch::async, [&] {\n        char c[1024];\n        for (;;) {\n            recvd2 += b->read(c, sizeof(c));\n            usleep(1000);\n        }\n    });\n\n    return 0;\n}\n```\n</details>\n\n### I expected the following\n\nThe second transfer of `bar` should not get stuck partially completed with no window size remaining.\n\n### curl/libcurl version\n\nCOMMIT ID: 8a45c2851aeb6f3ec18ad5c39c4042ab516891dd, which was HEAD as of the time of writing\n\n```\nWARNING: this libcurl is Debug-enabled, do not use in production\n\ncurl 8.13.0-DEV (x86_64-pc-linux-gnu) libcurl/8.13.0-DEV OpenSSL/3.4.1 zlib/1.3.1 brotli/1.1.0 zstd/1.5.6 libidn2/2.3.7 libpsl/0.21.5 libssh2\n/1.11.1 nghttp2/1.64.0\nRelease-Date: [unreleased]\nProtocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns mqtt pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp\nFeatures: alt-svc AsynchDNS brotli Debug GSS-API HSTS HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM PSL SPNEGO SSL threadsafe TLS-SRP TrackMemory UnixSockets zstd\n```\n\nHere is the way to obtain an approximately byte-identical Curl that I used using Nix, if necessary: put this in a file, then `nix-build file.nix -A all`. The results will be in `result*` symlinks. If you have to debug a Nix build of Curl, use `NIX_DEBUG_INFO_DIRS=result-debug/lib/debug`\n\n```nix\nlet\n  pkgs =\n    import\n      (builtins.fetchTarball \"https://github.com/nixos/nixpkgs/archive/a18002797a7128bfc247a090b6c2349b4a1877f7.tar.gz\")\n      { };\nin\npkgs.curl.overrideAttrs (old: {\n  # src = builtins.fetchGit ./.;\n  src = builtins.fetchTarball \"https://github.com/curl/curl/archive/8a45c2851aeb6f3ec18ad5c39c4042ab516891dd.tar.gz\";\n  patches = [ ];\n  postPatch = null;\n  nativeBuildInputs = old.nativeBuildInputs or [ ] ++ [\n    pkgs.buildPackages.autoreconfHook\n    pkgs.buildPackages.updateAutotoolsGnuConfigScriptsHook\n  ];\n  configureFlags = old.configureFlags or [ ] ++ [\n    \"--enable-debug\"\n  ];\n  env.CFLAGS = \"-O2 -g\";\n  preConfigure = ''\n    sed -e 's|/usr/bin|/no-such-path|g' -i.bak configure\n    patchShebangs scripts/\n  '';\n})\n```\n\n\n### operating system\n\nLinux nucury 6.12.19 #1-NixOS SMP PREEMPT_DYNAMIC Thu Mar 13 12:02:20 UTC 2025 x86_64 GNU/Linux\n","closed_by":{"login":"bagder","id":177011,"node_id":"MDQ6VXNlcjE3NzAxMQ==","avatar_url":"https://avatars.githubusercontent.com/u/177011?v=4","gravatar_id":"","url":"https://api.github.com/users/bagder","html_url":"https://github.com/bagder","followers_url":"https://api.github.com/users/bagder/followers","following_url":"https://api.github.com/users/bagder/following{/other_user}","gists_url":"https://api.github.com/users/bagder/gists{/gist_id}","starred_url":"https://api.github.com/users/bagder/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bagder/subscriptions","organizations_url":"https://api.github.com/users/bagder/orgs","repos_url":"https://api.github.com/users/bagder/repos","events_url":"https://api.github.com/users/bagder/events{/privacy}","received_events_url":"https://api.github.com/users/bagder/received_events","type":"User","user_view_type":"public","site_admin":false},"reactions":{"url":"https://api.github.com/repos/curl/curl/issues/16955/reactions","total_count":6,"+1":6,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/curl/curl/issues/16955/timeline","performed_via_github_app":null,"state_reason":"completed"}