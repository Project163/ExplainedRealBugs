{"url":"https://api.github.com/repos/curl/curl/issues/16280","repository_url":"https://api.github.com/repos/curl/curl","labels_url":"https://api.github.com/repos/curl/curl/issues/16280/labels{/name}","comments_url":"https://api.github.com/repos/curl/curl/issues/16280/comments","events_url":"https://api.github.com/repos/curl/curl/issues/16280/events","html_url":"https://github.com/curl/curl/issues/16280","id":2841069776,"node_id":"I_kwDOAAiu0c6pV0jQ","number":16280,"title":"CURLE_TOO_LARGE due to full pause buffer if you use curl with http2 and pause transfers especially with compression","user":{"login":"lf-","id":6652840,"node_id":"MDQ6VXNlcjY2NTI4NDA=","avatar_url":"https://avatars.githubusercontent.com/u/6652840?v=4","gravatar_id":"","url":"https://api.github.com/users/lf-","html_url":"https://github.com/lf-","followers_url":"https://api.github.com/users/lf-/followers","following_url":"https://api.github.com/users/lf-/following{/other_user}","gists_url":"https://api.github.com/users/lf-/gists{/gist_id}","starred_url":"https://api.github.com/users/lf-/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/lf-/subscriptions","organizations_url":"https://api.github.com/users/lf-/orgs","repos_url":"https://api.github.com/users/lf-/repos","events_url":"https://api.github.com/users/lf-/events{/privacy}","received_events_url":"https://api.github.com/users/lf-/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":194601710,"node_id":"MDU6TGFiZWwxOTQ2MDE3MTA=","url":"https://api.github.com/repos/curl/curl/labels/HTTP/2","name":"HTTP/2","color":"009800","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"icing","id":15102,"node_id":"MDQ6VXNlcjE1MTAy","avatar_url":"https://avatars.githubusercontent.com/u/15102?v=4","gravatar_id":"","url":"https://api.github.com/users/icing","html_url":"https://github.com/icing","followers_url":"https://api.github.com/users/icing/followers","following_url":"https://api.github.com/users/icing/following{/other_user}","gists_url":"https://api.github.com/users/icing/gists{/gist_id}","starred_url":"https://api.github.com/users/icing/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/icing/subscriptions","organizations_url":"https://api.github.com/users/icing/orgs","repos_url":"https://api.github.com/users/icing/repos","events_url":"https://api.github.com/users/icing/events{/privacy}","received_events_url":"https://api.github.com/users/icing/received_events","type":"User","user_view_type":"public","site_admin":false},"assignees":[{"login":"icing","id":15102,"node_id":"MDQ6VXNlcjE1MTAy","avatar_url":"https://avatars.githubusercontent.com/u/15102?v=4","gravatar_id":"","url":"https://api.github.com/users/icing","html_url":"https://github.com/icing","followers_url":"https://api.github.com/users/icing/followers","following_url":"https://api.github.com/users/icing/following{/other_user}","gists_url":"https://api.github.com/users/icing/gists{/gist_id}","starred_url":"https://api.github.com/users/icing/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/icing/subscriptions","organizations_url":"https://api.github.com/users/icing/orgs","repos_url":"https://api.github.com/users/icing/repos","events_url":"https://api.github.com/users/icing/events{/privacy}","received_events_url":"https://api.github.com/users/icing/received_events","type":"User","user_view_type":"public","site_admin":false}],"milestone":null,"comments":3,"created_at":"2025-02-10T00:43:38Z","updated_at":"2025-02-20T14:53:30Z","closed_at":"2025-02-20T14:53:30Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"body":"### I did this\n\nWith the following program downloading 128MB of gzipped zeros from my website, libcurl will fail http2 transfers with `CURLE_TOO_LARGE`. Part of the problem here is that it is extremely easy to fill up the pause buffer if there is compression at play: a tiny amount of data transferred with gzip compression (of which the sample here is a pathological case, but it happens in less unreasonable cases too). I think that this most commonly happens inside of Lix where someone is running on a slow machine with an extremely fast internet connection (say, github actions) which is downloading especially huge files and is not eating up the data it's downloading very quickly so is giving a lot of pauses for flow control.\n\nIt's especially bad with compression due to the buffer in question being *post* decompression, whereas the window size control is applied to the compressed bytes. This is the part of the problem that feels like a curl bug and is relatively clearly not API misuse.\n\nFor curious reasons, you have to do two transfers to the same machine simultaneously to hit this problem, but the problem code below reproduces it 100% of the time on my machine at least.\n\nThis is a reduction of the Lix file transfer code with all fancy dependencies removed, so it is just C++ and libcurl; I could have written a C sample but it would likely be harder to read and even longer. This is the bug we are having with curl on our end: https://git.lix.systems/lix-project/lix/issues/662.\n\nCompile the program below with `c++ -std=c++20 $(pkg-config --libs --cflags libcurl) bad.cc -o bad` and run with `./bad`.\n\n<details>\n<summary>C++ sample program extracted from Lix</summary>\n\n```c++\n#include <cassert>\n#include <condition_variable>\n#include <curl/curl.h>\n#include <thread>\n#include <atomic>\n#include <iostream>\n#include <map>\n#include <mutex>\n#include <set>\n#include <vector>\n#include <memory>\n\nclass TransferItem2\n{\n    std::mutex lk;\n    std::vector<char> buf1;\n    std::condition_variable cv;\n    bool done = false;\npublic:\n    std::unique_ptr<CURL, decltype([](auto * c) { curl_easy_cleanup(c); })> req;\n\n    static size_t writeCallbackWrapper(void * contents, size_t size, size_t nmemb, void * userp)\n    {\n        return static_cast<TransferItem2 *>(userp)->writeCallback(contents, size, nmemb);\n    }\n\n    size_t writeCallback(void *contents, size_t size, size_t nmemb)\n    {\n        const size_t realSize = size * nmemb;\n        std::lock_guard<std::mutex> _l(lk);\n\n        if (buf1.size() > 1024 * 1024) {\n            std::cout << \"pause \" << req.get() << \"\\n\";\n            return CURL_WRITEFUNC_PAUSE;\n        }\n\n        // std::cout << \"recv \" << req.get() << \" bytes: \" << realSize << \"\\n\";\n\n        buf1.insert(buf1.end(), realSize, realSize + size);\n        cv.notify_all();\n        return realSize;\n    }\n\n    // In a real application this would actually do something with the data.\n    bool consume()\n    {\n        std::unique_lock<std::mutex> g(lk);\n        if (done) return true;\n        if (buf1.empty()) {\n            cv.wait(g);\n        }\n        auto _ = std::move(buf1);\n        buf1 = {};\n        return done;\n    }\n\n    void finish(CURLcode code)\n    {\n        std::cout << \"Finish item \" << req.get() << \" with code \" << code << \" error: \" << curl_easy_strerror(code) << \"\\n\";\n        done = true;\n    }\n\n    static int debugCallback(CURL * handle, curl_infotype type, char * data, size_t size, void * userptr)\n    {\n        if (type == CURLINFO_TEXT)\n            std::cout << \"curl: \" << std::string(data, size) << \"\\n\";\n        return 0;\n    }\n\n    TransferItem2(std::string uri) : req(curl_easy_init()) {\n        curl_easy_setopt(req.get(), CURLOPT_VERBOSE, 1);\n        curl_easy_setopt(req.get(), CURLOPT_DEBUGFUNCTION, TransferItem2::debugCallback);\n        curl_easy_setopt(req.get(), CURLOPT_URL, uri.c_str());\n        curl_easy_setopt(req.get(), CURLOPT_FOLLOWLOCATION, 1L);\n        curl_easy_setopt(req.get(), CURLOPT_ACCEPT_ENCODING, \"\"); // all of them!\n        curl_easy_setopt(req.get(), CURLOPT_MAXREDIRS, 10);\n        curl_easy_setopt(req.get(), CURLOPT_NOSIGNAL, 1);\n        curl_easy_setopt(req.get(), CURLOPT_PIPEWAIT, 1);\n        curl_easy_setopt(req.get(), CURLOPT_HTTP_VERSION, CURL_HTTP_VERSION_2TLS);\n        curl_easy_setopt(req.get(), CURLOPT_WRITEFUNCTION, TransferItem2::writeCallbackWrapper);\n        curl_easy_setopt(req.get(), CURLOPT_WRITEDATA, this);\n\n        curl_easy_setopt(req.get(), CURLOPT_NOPROGRESS, 1);\n\n        curl_easy_setopt(req.get(), CURLOPT_PROTOCOLS_STR, \"http,https,ftp,ftps\");\n\n        curl_easy_setopt(req.get(), CURLOPT_CONNECTTIMEOUT, 5);\n\n        curl_easy_setopt(req.get(), CURLOPT_LOW_SPEED_LIMIT, 1L);\n        curl_easy_setopt(req.get(), CURLOPT_LOW_SPEED_TIME, 300);\n    }\n};\n\nclass Transferrer\n{\n    std::unique_ptr<CURLM, decltype([](auto * m) { curl_multi_cleanup(m); })> curlm;\n    std::thread thread;\n    std::atomic<bool> stop = false;\n    std::map<CURL *, std::shared_ptr<TransferItem2>> items;\n\n    std::vector<std::shared_ptr<TransferItem2>> incoming;\n    std::set<std::shared_ptr<TransferItem2>> unpause;\n    std::mutex lk;\n\n    public:\n    void add(std::shared_ptr<TransferItem2> item)\n    {\n        auto _l = std::lock_guard(lk);\n        incoming.push_back(item);\n    }\n\n    void requestUnpause(std::shared_ptr<TransferItem2> item)\n    {\n        std::cout << \"requestUnpause \" << item->req.get() << \"\\n\";\n        std::lock_guard<std::mutex> _l(lk);\n        unpause.insert(item);\n    }\n\n    bool consume(std::shared_ptr<TransferItem2> item)\n    {\n        requestUnpause(item);\n        return item->consume();\n    }\n\n    void transferThread()\n    {\n        while (!stop) {\n            int running;\n            CURLMcode mc = curl_multi_perform(curlm.get(), &running);\n            if (mc != CURLM_OK)\n                throw std::runtime_error(\"curl_multi_perform\");\n\n            CURLMsg * msg;\n            int left;\n            while ((msg = curl_multi_info_read(curlm.get(), &left))) {\n                if (msg->msg == CURLMSG_DONE) {\n                    auto i = items.find(msg->easy_handle);\n                    assert(i != items.end());\n                    i->second->finish(msg->data.result);\n                    curl_multi_remove_handle(curlm.get(), i->second->req.get());\n                    items.erase(i);\n                }\n            }\n\n            /* Wait for activity, including wakeup events. */\n            mc = curl_multi_poll(curlm.get(), nullptr, 0, 64, nullptr);\n            if (mc != CURLM_OK)\n                throw std::runtime_error(\"unexpected error from curl_multi_poll()\");\n\n            {\n                auto unpause_ = ([&]() {\n                    std::lock_guard _l(lk);\n                    auto ret = std::move(this->unpause);\n                    this->unpause.clear();\n                    return ret;\n                })();\n\n                for (auto & item : unpause_) {\n                    std::cout << \"unpause \" << item->req.get() << \"\\n\";\n                    curl_easy_pause(item->req.get(), CURLPAUSE_CONT);\n                }\n            }\n\n\n            {\n                auto _l = std::lock_guard(lk);\n                auto incoming_ = std::move(incoming);\n                incoming.clear();\n\n                for (auto && tf : incoming_) {\n                    items.insert(std::make_pair(tf->req.get(), tf));\n                    curl_multi_add_handle(curlm.get(), tf->req.get());\n                }\n            }\n        }\n    }\n\n    Transferrer() : curlm(curl_multi_init()) {\n        static std::once_flag globalInit;\n        std::call_once(globalInit, curl_global_init, CURL_GLOBAL_ALL);\n\n        curl_multi_setopt(curlm.get(), CURLMOPT_PIPELINING, CURLPIPE_MULTIPLEX);\n        curl_multi_setopt(curlm.get(), CURLMOPT_MAX_TOTAL_CONNECTIONS, 10);\n\n        thread = std::thread([&]() {\n            transferThread();\n        });\n    }\n\n    ~Transferrer()\n    {\n        stop = true;\n        thread.join();\n    }\n};\n\n\nint main()\n{\n    auto t1 = std::make_shared<TransferItem2>(\"https://jade.fyi/zeros.txt\");\n    auto t2 = std::make_shared<TransferItem2>(\"https://jade.fyi/zeros.txt\");\n    auto mgr = Transferrer{};\n    std::cout << \"t1 is \" << t1->req.get() << \", t2 is \" << t2->req.get() << \"\\n\";\n\n    // take a little byte out of t1 and t2 so that they are definitely in a data transfer phase\n    mgr.add(t1);\n    mgr.consume(t1);\n    mgr.add(t2);\n    mgr.consume(t2);\n\n    // hungrily take more bytes out of t1\n    while (!mgr.consume(t1)) {\n        std::cout << \"omnomnom\\n\";\n    }\n}\n```\n</details>\n\n### I expected the following\n\nCurl should manage its window sizes such that it can deal with pauses on transfers with http2 with compression. It may require some redesign so that the buffer getting overly filled up is compressed data rather than decompressed data.\n\n### curl/libcurl version\n\n```\ncurl 8.11.0 (x86_64-pc-linux-gnu) libcurl/8.11.0 OpenSSL/3.3.2 zlib/1.3.1 brotli/1.1.0 zstd/1.5.6 libidn2/2.3.7 libpsl/0.21.5 libssh2/1.11.\n1 nghttp2/1.64.0\nRelease-Date: 2024-11-06\nProtocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns mqtt pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp\nFeatures: alt-svc AsynchDNS brotli GSS-API HSTS HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM PSL SPNEGO SSL threadsafe TLS-SRP U\nnixSockets zstd\n```\n\n### operating system\n\nThis is happening on various kernels; the affected userspace code is from nixpkgs 9ecb50d2fae8680be74c08bb0a995c5383747f89 but it also happens on newer nixpkgs with Curl 8.11.1.\n\n```\nLinux tail-bot 6.12.12-1-lts #1 SMP PREEMPT_DYNAMIC Sat, 01 Feb 2025 18:47:29 +0000 x86_64 GNU/Linux\n```","closed_by":{"login":"bagder","id":177011,"node_id":"MDQ6VXNlcjE3NzAxMQ==","avatar_url":"https://avatars.githubusercontent.com/u/177011?v=4","gravatar_id":"","url":"https://api.github.com/users/bagder","html_url":"https://github.com/bagder","followers_url":"https://api.github.com/users/bagder/followers","following_url":"https://api.github.com/users/bagder/following{/other_user}","gists_url":"https://api.github.com/users/bagder/gists{/gist_id}","starred_url":"https://api.github.com/users/bagder/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/bagder/subscriptions","organizations_url":"https://api.github.com/users/bagder/orgs","repos_url":"https://api.github.com/users/bagder/repos","events_url":"https://api.github.com/users/bagder/events{/privacy}","received_events_url":"https://api.github.com/users/bagder/received_events","type":"User","user_view_type":"public","site_admin":false},"reactions":{"url":"https://api.github.com/repos/curl/curl/issues/16280/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/curl/curl/issues/16280/timeline","performed_via_github_app":null,"state_reason":"completed"}