diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/BatchCommitQueue.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/BatchCommitQueue.java
index 678c185971..a0e320568f 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/BatchCommitQueue.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/BatchCommitQueue.java
@@ -16,7 +16,6 @@
  */
 package org.apache.jackrabbit.oak.plugins.document;
 
-import java.util.Comparator;
 import java.util.Map;
 import java.util.concurrent.Callable;
 
@@ -49,12 +48,8 @@ final class BatchCommitQueue {
 
     private final DocumentStore store;
 
-    private final Comparator<Revision> comparator;
-
-    BatchCommitQueue(@Nonnull DocumentStore store,
-                     @Nonnull Comparator<Revision> comparator) {
+    BatchCommitQueue(@Nonnull DocumentStore store) {
         this.store = checkNotNull(store);
-        this.comparator = checkNotNull(comparator);
     }
 
     Callable<NodeDocument> updateDocument(UpdateOp op) {
@@ -103,8 +98,4 @@ final class BatchCommitQueue {
     DocumentStore getStore() {
         return store;
     }
-
-    Comparator<Revision> getComparator() {
-        return comparator;
-    }
 }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Branch.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Branch.java
index 6e7e940868..ed8a687c01 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Branch.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Branch.java
@@ -53,7 +53,7 @@ class Branch {
     /**
      * The initial base revision of this branch.
      */
-    private final Revision base;
+    private final RevisionVector base;
 
     /**
      * The branch reference.
@@ -76,7 +76,7 @@ class Branch {
      * @throws IllegalArgumentException if base is a branch revision.
      */
     Branch(@Nonnull SortedSet<Revision> commits,
-           @Nonnull Revision base,
+           @Nonnull RevisionVector base,
            @Nonnull ReferenceQueue<Object> queue,
            @Nullable Object guard) {
         checkArgument(!checkNotNull(base).isBranch(), "base is not a trunk revision: %s", base);
@@ -97,7 +97,7 @@ class Branch {
      * @return the initial base of this branch.
      */
     @Nonnull
-    Revision getBase() {
+    RevisionVector getBase() {
         return base;
     }
 
@@ -110,7 +110,7 @@ class Branch {
      *                                  this branch.
      */
     @Nonnull
-    Revision getBase(@Nonnull Revision r) {
+    RevisionVector getBase(@Nonnull Revision r) {
         BranchCommit c = commits.get(checkNotNull(r).asBranchRevision());
         if (c == null) {
             throw new IllegalArgumentException(
@@ -127,11 +127,11 @@ class Branch {
      * @throws IllegalArgumentException if head is a trunk revision or base is a
      *                                  branch revision.
      */
-    void rebase(@Nonnull Revision head, @Nonnull Revision base) {
+    void rebase(@Nonnull Revision head, @Nonnull RevisionVector base) {
         checkArgument(checkNotNull(head).isBranch(), "Not a branch revision: %s", head);
         checkArgument(!checkNotNull(base).isBranch(), "Not a trunk revision: %s", base);
         Revision last = commits.lastKey();
-        checkArgument(commits.comparator().compare(head, last) > 0);
+        checkArgument(head.compareRevisionTime(last) > 0);
         commits.put(head, new RebaseCommit(base, head, commits));
     }
 
@@ -294,15 +294,15 @@ class Branch {
      */
     abstract static class BranchCommit implements LastRevTracker {
 
-        protected final Revision base;
+        protected final RevisionVector base;
         protected final Revision commit;
 
-        BranchCommit(Revision base, Revision commit) {
+        BranchCommit(RevisionVector base, Revision commit) {
             this.base = base;
             this.commit = commit;
         }
 
-        Revision getBase() {
+        RevisionVector getBase() {
             return base;
         }
 
@@ -322,7 +322,7 @@ class Branch {
 
         private final Set<String> modifications = Sets.newHashSet();
 
-        BranchCommitImpl(Revision base, Revision commit) {
+        BranchCommitImpl(RevisionVector base, Revision commit) {
             super(base, commit);
         }
 
@@ -365,7 +365,7 @@ class Branch {
 
         private final NavigableMap<Revision, BranchCommit> previous;
 
-        RebaseCommit(Revision base, Revision commit,
+        RebaseCommit(RevisionVector base, Revision commit,
                      NavigableMap<Revision, BranchCommit> previous) {
             super(base, commit);
             this.previous = squash(previous);
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Checkpoints.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Checkpoints.java
index 8a6a98c80a..42a01f3687 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Checkpoints.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Checkpoints.java
@@ -27,6 +27,7 @@ import java.util.concurrent.atomic.AtomicInteger;
 
 import javax.annotation.CheckForNull;
 import javax.annotation.Nonnull;
+import javax.annotation.Nullable;
 
 import org.apache.jackrabbit.oak.commons.json.JsopBuilder;
 import org.apache.jackrabbit.oak.commons.json.JsopReader;
@@ -37,12 +38,17 @@ import org.slf4j.LoggerFactory;
 
 import com.google.common.collect.Maps;
 
+import static com.google.common.base.Preconditions.checkNotNull;
+
 
 /**
  * Checkpoints provide details around which revision are to be kept. These
  * are stored in Settings collection.
  */
 class Checkpoints {
+
+    private static final Logger LOG = LoggerFactory.getLogger(Checkpoints.class);
+
     private static final String ID = "checkpoint";
 
     /**
@@ -76,10 +82,11 @@ class Checkpoints {
     public Revision create(long lifetimeInMillis, Map<String, String> info) {
         // create a unique dummy commit we can use as checkpoint revision
         Revision r = nodeStore.commitQueue.createRevision();
+        final RevisionVector[] rv = new RevisionVector[1];
         nodeStore.commitQueue.done(r, new CommitQueue.Callback() {
             @Override
             public void headOfQueue(@Nonnull Revision revision) {
-                // do nothing
+                rv[0] = nodeStore.getHeadRevision();
             }
         });
         createCounter.getAndIncrement();
@@ -88,7 +95,7 @@ class Checkpoints {
         long endTime = BigInteger.valueOf(nodeStore.getClock().getTime())
                 .add(BigInteger.valueOf(lifetimeInMillis))
                 .min(BigInteger.valueOf(Long.MAX_VALUE)).longValue();
-        op.setMapEntry(PROP_CHECKPOINT, r, new Info(endTime, info).toString());
+        op.setMapEntry(PROP_CHECKPOINT, r, new Info(endTime, rv[0], info).toString());
         store.createOrUpdate(Collection.SETTINGS, op);
         return r;
     }
@@ -113,7 +120,7 @@ class Checkpoints {
         //Get uncached doc
         SortedMap<Revision, Info> checkpoints = getCheckpoints();
 
-        if(checkpoints == null){
+        if(checkpoints.isEmpty()){
             log.debug("No checkpoint registered so far");
             return null;
         }
@@ -142,24 +149,53 @@ class Checkpoints {
     }
 
     @SuppressWarnings("unchecked")
-    @CheckForNull
+    @Nonnull
     SortedMap<Revision, Info> getCheckpoints() {
         Document cdoc = store.find(Collection.SETTINGS, ID, 0);
-        SortedMap<Revision, String> data =
-                (SortedMap<Revision, String>) cdoc.get(PROP_CHECKPOINT);
-        if (data == null) {
-            return null;
+        SortedMap<Revision, String> data = null;
+        if (cdoc != null) {
+            data = (SortedMap<Revision, String>) cdoc.get(PROP_CHECKPOINT);
         }
-        SortedMap<Revision, Info> checkpoints = Maps.newTreeMap(data.comparator());
-        for (Map.Entry<Revision, String> entry : data.entrySet()) {
-            checkpoints.put(entry.getKey(), Info.fromString(entry.getValue()));
+        SortedMap<Revision, Info> checkpoints = Maps.newTreeMap(StableRevisionComparator.REVERSE);
+        if (data != null) {
+            for (Map.Entry<Revision, String> entry : data.entrySet()) {
+                checkpoints.put(entry.getKey(), Info.fromString(entry.getValue()));
+            }
         }
         return checkpoints;
     }
 
-    int size(){
-        SortedMap<Revision, Info> checkpoints = getCheckpoints();
-        return checkpoints == null ? 0 : checkpoints.size();
+    /**
+     * Retrieves the head revision for the given {@code checkpoint}.
+     *
+     * @param checkpoint the checkpoint reference.
+     * @return the head revision associated with the checkpoint or {@code null}
+     *      if there is no such checkpoint.
+     * @throws IllegalArgumentException if the checkpoint is malformed.
+     */
+    @CheckForNull
+    RevisionVector retrieve(@Nonnull String checkpoint)
+            throws IllegalArgumentException {
+        Revision r;
+        try {
+            r = Revision.fromString(checkNotNull(checkpoint));
+        } catch (IllegalArgumentException e) {
+            LOG.warn("Malformed checkpoint reference: {}", checkpoint);
+            return null;
+        }
+        Info info = getCheckpoints().get(r);
+        if (info == null) {
+            return null;
+        }
+        RevisionVector rv = info.getCheckpoint();
+        if (rv == null) {
+            rv = expand(r);
+        }
+        return rv;
+    }
+
+    int size() {
+        return getCheckpoints().size();
     }
 
     /**
@@ -182,21 +218,47 @@ class Checkpoints {
         }
     }
 
+    private RevisionVector expand(Revision checkpoint) {
+        LOG.warn("Expanding {} single revision checkpoint into a " +
+                "RevisionVector. Please make sure all cluster nodes run " +
+                "with the same Oak version.", checkpoint);
+        // best effort conversion
+        Map<Integer, Revision> revs = Maps.newHashMap();
+        RevisionVector head = nodeStore.getHeadRevision();
+        for (Revision r : head) {
+            int cId = r.getClusterId();
+            if (cId == checkpoint.getClusterId()) {
+                revs.put(cId, r);
+            } else {
+                revs.put(cId, new Revision(checkpoint.getTimestamp(), 0, cId));
+            }
+        }
+        return head.pmin(new RevisionVector(revs.values()));
+    }
+
     static final class Info {
 
         private static final String EXPIRES = "expires";
 
+        private static final String REVISION_VECTOR = "rv";
+
         private final long expiryTime;
 
+        private final RevisionVector checkpoint;
+
         private final Map<String, String> info;
 
-        private Info(long expiryTime, Map<String, String> info) {
+        private Info(long expiryTime,
+                     @Nullable  RevisionVector checkpoint,
+                     @Nonnull Map<String, String> info) {
             this.expiryTime = expiryTime;
+            this.checkpoint = checkpoint;
             this.info = Collections.unmodifiableMap(info);
         }
 
         static Info fromString(String info) {
             long expiryTime;
+            RevisionVector rv = null;
             Map<String, String> map;
             if (info.startsWith("{")) {
                 map = Maps.newHashMap();
@@ -212,7 +274,19 @@ class Checkpoints {
                 while (reader.matches(',')) {
                     key = reader.readString();
                     reader.read(':');
-                    map.put(key, reader.readString());
+                    String value = reader.readString();
+                    // second entry is potentially checkpoint revision vector
+                    if (rv == null && map.isEmpty() && REVISION_VECTOR.equals(key)) {
+                        // try to read checkpoint
+                        try {
+                            rv = RevisionVector.fromString(value);
+                        } catch (IllegalArgumentException e) {
+                            // not a revision vector, read as regular info entry
+                            map.put(key, value);
+                        }
+                    } else {
+                        map.put(key, value);
+                    }
                 }
                 reader.read('}');
                 reader.read(JsopReader.END);
@@ -221,7 +295,7 @@ class Checkpoints {
                 map = Collections.emptyMap();
                 expiryTime = Long.parseLong(info);
             }
-            return new Info(expiryTime, map);
+            return new Info(expiryTime, rv, map);
         }
 
         Map<String, String> get() {
@@ -232,11 +306,26 @@ class Checkpoints {
             return expiryTime;
         }
 
+        /**
+         * The revision vector associated with this checkpoint or {@code null}
+         * if this checkpoint was created with a version of Oak, which did not
+         * yet support revision vectors.
+         *
+         * @return the revision vector checkpoint or {@code null}.
+         */
+        @CheckForNull
+        RevisionVector getCheckpoint() {
+            return checkpoint;
+        }
+
         @Override
         public String toString() {
             JsopWriter writer = new JsopBuilder();
             writer.object();
             writer.key(EXPIRES).value(Long.toString(expiryTime));
+            if (checkpoint != null) {
+                writer.key(REVISION_VECTOR).value(checkpoint.toString());
+            }
             for (Map.Entry<String, String> entry : info.entrySet()) {
                 writer.key(entry.getKey()).value(entry.getValue());
             }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfo.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfo.java
index 59d5f75ed4..2d66441f79 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfo.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfo.java
@@ -70,6 +70,11 @@ public class ClusterNodeInfo {
      */
     public static final String LEASE_END_KEY = "leaseEnd";
 
+    /**
+     * The start time.
+     */
+    public static final String START_TIME_KEY = "startTime";
+
     /**
      * The key for the root-revision of the last background write (of unsaved
      * modifications) - that is: the last root-revision written by the instance
@@ -385,6 +390,7 @@ public class ClusterNodeInfo {
             } else {
                 update.set(LEASE_END_KEY, clusterNode.leaseEndTime);
             }
+            update.set(START_TIME_KEY, clusterNode.startTime);
             update.set(INFO_KEY, clusterNode.toString());
             update.set(STATE, clusterNode.state.name());
             update.set(REV_RECOVERY_LOCK, clusterNode.revRecoveryLock.name());
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfoDocument.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfoDocument.java
index 6cc12897fe..1547eeddb0 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfoDocument.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfoDocument.java
@@ -39,10 +39,34 @@ public class ClusterNodeInfoDocument extends Document {
      */
     private static final String MAX_ID_VALUE = "a";
 
+    /**
+     * The timestamp when this document was created.
+     */
+    private final long created = Revision.getCurrentTimestamp();
+
+    /**
+     * @return the timestamp when this document was created.
+     */
+    public long getCreated() {
+        return created;
+    }
+
     public long getLeaseEndTime(){
         return checkNotNull((Long) get(ClusterNodeInfo.LEASE_END_KEY), "Lease End Time not set");
     }
 
+    /**
+     * @return the time when this cluster node was started or {@code -1} if not
+     *          available.
+     */
+    public long getStartTime() {
+        Long startTime = (Long) get(ClusterNodeInfo.START_TIME_KEY);
+        if (startTime == null) {
+            startTime = -1L;
+        }
+        return startTime;
+    }
+
     public boolean isActive(){
         return getState() == ClusterNodeState.ACTIVE;
     }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java
index d24876f52b..a9211633f8 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java
@@ -31,10 +31,13 @@ import javax.annotation.Nullable;
 
 import com.google.common.base.Function;
 import com.google.common.collect.Sets;
+
+import org.apache.jackrabbit.oak.api.PropertyState;
 import org.apache.jackrabbit.oak.commons.json.JsopStream;
 import org.apache.jackrabbit.oak.commons.json.JsopWriter;
 import org.apache.jackrabbit.oak.plugins.document.util.Utils;
 import org.apache.jackrabbit.oak.commons.PathUtils;
+import org.apache.jackrabbit.oak.spi.state.NodeState;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -47,7 +50,6 @@ import static org.apache.jackrabbit.oak.plugins.document.Collection.JOURNAL;
 import static org.apache.jackrabbit.oak.plugins.document.Collection.NODES;
 import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.COLLISIONS;
 import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.SPLIT_CANDIDATE_THRESHOLD;
-import static org.apache.jackrabbit.oak.plugins.document.util.Utils.isRevisionNewer;
 
 /**
  * A higher level object representing a commit.
@@ -58,7 +60,7 @@ public class Commit {
 
     protected final DocumentNodeStore nodeStore;
     private final DocumentNodeStoreBranch branch;
-    private final Revision baseRevision;
+    private final RevisionVector baseRevision;
     private final Revision revision;
     private final HashMap<String, UpdateOp> operations = new LinkedHashMap<String, UpdateOp>();
     private final JsopWriter diff = new JsopStream();
@@ -90,7 +92,7 @@ public class Commit {
      */
     Commit(@Nonnull DocumentNodeStore nodeStore,
            @Nonnull Revision revision,
-           @Nullable Revision baseRevision,
+           @Nullable RevisionVector baseRevision,
            @Nullable DocumentNodeStoreBranch branch) {
         this.nodeStore = checkNotNull(nodeStore);
         this.revision = checkNotNull(revision);
@@ -129,7 +131,7 @@ public class Commit {
      * @return the base revision of this commit or <code>null</code>.
      */
     @CheckForNull
-    Revision getBaseRevision() {
+    RevisionVector getBaseRevision() {
         return baseRevision;
     }
 
@@ -167,7 +169,7 @@ public class Commit {
             LOG.error(msg);
             throw new DocumentStoreException(msg);
         }
-        operations.put(path, n.asOperation(true));
+        operations.put(path, n.asOperation(revision));
         addedNodes.add(path);
     }
 
@@ -178,13 +180,11 @@ public class Commit {
     /**
      * Applies this commit to the store.
      *
-     * @return the commit revision.
      * @throws DocumentStoreException if the commit cannot be applied.
      */
-    @Nonnull
-    Revision apply() throws DocumentStoreException {
+    void apply() throws DocumentStoreException {
         boolean success = false;
-        Revision baseRev = getBaseRevision();
+        RevisionVector baseRev = getBaseRevision();
         boolean isBranch = baseRev != null && baseRev.isBranch();
         Revision rev = getRevision();
         if (isBranch && !nodeStore.isDisableBranches()) {
@@ -218,10 +218,6 @@ public class Commit {
         } else {
             applyInternal();
         }
-        if (isBranch) {
-            rev = rev.asBranchRevision();
-        }
-        return rev;
     }
 
     /**
@@ -235,7 +231,7 @@ public class Commit {
         }
     }
 
-    private void prepare(Revision baseRevision) {
+    private void prepare(RevisionVector baseRevision) {
         if (!operations.isEmpty()) {
             updateParentChildStatus();
             updateBinaryStatus();
@@ -271,7 +267,7 @@ public class Commit {
      * @param baseBranchRevision the base revision of this commit. Currently only
      *                     used for branch commits.
      */
-    private void applyToDocumentStore(Revision baseBranchRevision) {
+    private void applyToDocumentStore(RevisionVector baseBranchRevision) {
         // the value in _revisions.<revision> property of the commit root node
         // regular commits use "c", which makes the commit visible to
         // other readers. branch commits use the base revision to indicate
@@ -402,8 +398,8 @@ public class Commit {
                             dse = new DocumentStoreException(msg);
                         } else {
                             dse = new ConflictException(msg,
-                                    commitRootDoc.getMostRecentConflictFor(
-                                        Collections.singleton(revision), nodeStore));
+                                    commitRootDoc.getConflictsFor(
+                                        Collections.singleton(revision)));
                         }
                         throw dse;
                     } else {
@@ -513,7 +509,7 @@ public class Commit {
         if (baseRevision != null) {
             Revision newestRev = null;
             if (before != null) {
-                Revision base = baseRevision;
+                RevisionVector base = baseRevision;
                 if (nodeStore.isDisableBranches()) {
                     base = base.asTrunkRevision();
                 }
@@ -536,7 +532,7 @@ public class Commit {
                     conflictMessage = "The node " +
                             op.getId() + " was already added in revision\n" +
                             formatConflictRevision(newestRev);
-                } else if (nodeStore.isRevisionNewer(newestRev, baseRevision)
+                } else if (baseRevision.isRevisionNewer(newestRev)
                         && (op.isDelete() || isConflicting(before, op))) {
                     conflictMessage = "The node " +
                             op.getId() + " was changed in revision\n" +
@@ -576,9 +572,7 @@ public class Commit {
                 conflictMessage += ", before\n" + revision;
                 if (LOG.isDebugEnabled()) {
                     LOG.debug(conflictMessage  + "; document:\n" +
-                            (before == null ? "" : before.format()) +
-                            ",\nrevision order:\n" +
-                            nodeStore.getRevisionComparator());
+                            (before == null ? "" : before.format()));
                 }
                 throw new ConflictException(conflictMessage, conflictRevision);
             }
@@ -586,7 +580,7 @@ public class Commit {
     }
 
     private String formatConflictRevision(Revision r) {
-        if (isRevisionNewer(nodeStore, r, nodeStore.getHeadRevision())) {
+        if (nodeStore.getHeadRevision().isRevisionNewer(r)) {
             return r + " (not yet visible)";
         } else {
             return r.toString();
@@ -612,7 +606,7 @@ public class Commit {
             // or document did not exist before
             return false;
         }
-        return doc.isConflicting(op, baseRevision, revision, nodeStore,
+        return doc.isConflicting(op, baseRevision, revision,
                 nodeStore.getEnableConcurrentAddRemove());
     }
 
@@ -644,7 +638,8 @@ public class Commit {
             return null;
         }
         if (b == null) {
-            b = nodeStore.getBranches().getBranch(revision);
+            b = nodeStore.getBranches().getBranch(
+                    new RevisionVector(revision.asBranchRevision()));
         }
         return b;
     }
@@ -655,7 +650,7 @@ public class Commit {
      * @param before the revision right before this commit.
      * @param isBranchCommit whether this is a commit to a branch
      */
-    public void applyToCache(Revision before, boolean isBranchCommit) {
+    public void applyToCache(RevisionVector before, boolean isBranchCommit) {
         HashMap<String, ArrayList<String>> nodesWithChangedChildren = new HashMap<String, ArrayList<String>>();
         for (String p : modifiedNodes) {
             if (denotesRoot(p)) {
@@ -669,7 +664,8 @@ public class Commit {
             }
             list.add(p);
         }
-        DiffCache.Entry cacheEntry = nodeStore.getDiffCache().newEntry(before, revision, true);
+        RevisionVector after = before.update(revision);
+        DiffCache.Entry cacheEntry = nodeStore.getDiffCache().newEntry(before, after, true);
         LastRevTracker tracker = nodeStore.createTracker(revision, isBranchCommit);
         List<String> added = new ArrayList<String>();
         List<String> removed = new ArrayList<String>();
@@ -696,7 +692,7 @@ public class Commit {
                 // track intermediate node and root
                 tracker.track(path);
             }
-            nodeStore.applyChanges(revision, path, isNew,
+            nodeStore.applyChanges(after, path, isNew,
                     added, removed, changed, cacheEntry);
         }
         cacheEntry.done();
@@ -733,11 +729,14 @@ public class Commit {
         diff.tag('-').value(path).newline();
     }
 
-    public void removeNode(String path) {
+    public void removeNode(String path, NodeState state) {
         removedNodes.add(path);
         UpdateOp op = getUpdateOperationForNode(path);
         op.setDelete(true);
         NodeDocument.setDeleted(op, revision, true);
+        for (PropertyState p : state.getProperties()) {
+            updateProperty(path, p.getName(), null);
+        }
     }
 
     private static final Function<UpdateOp.Key, String> KEY_TO_NAME =
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/CommitDiff.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/CommitDiff.java
index 074e0c4f93..cb09bddf92 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/CommitDiff.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/CommitDiff.java
@@ -83,7 +83,8 @@ class CommitDiff implements NodeStateDiff {
     @Override
     public boolean childNodeAdded(String name, NodeState after) {
         String p = PathUtils.concat(path, name);
-        commit.addNode(new DocumentNodeState(store, p, commit.getRevision()));
+        commit.addNode(new DocumentNodeState(store, p,
+                new RevisionVector(commit.getRevision())));
         return after.compareAgainstBaseState(EMPTY_NODE,
                 new CommitDiff(store, commit, p, builder, blobs));
     }
@@ -100,7 +101,7 @@ class CommitDiff implements NodeStateDiff {
     @Override
     public boolean childNodeDeleted(String name, NodeState before) {
         String p = PathUtils.concat(path, name);
-        commit.removeNode(p);
+        commit.removeNode(p, before);
         return MISSING_NODE.compareAgainstBaseState(before,
                 new CommitDiff(store, commit, p, builder, blobs));
     }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/CommitQueue.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/CommitQueue.java
index 7a452a7cc1..6f4ee28585 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/CommitQueue.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/CommitQueue.java
@@ -19,7 +19,6 @@ package org.apache.jackrabbit.oak.plugins.document;
 import static com.google.common.base.Preconditions.checkArgument;
 import static com.google.common.base.Preconditions.checkNotNull;
 
-import java.util.Comparator;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
@@ -116,14 +115,13 @@ final class CommitQueue {
      * @param conflictRevisions the revisions to become visible.
      */
     void suspendUntilAll(@Nonnull Set<Revision> conflictRevisions) {
-        Comparator<Revision> comparator = context.getRevisionComparator();
         Semaphore s;
         int addedRevisions;
         synchronized (suspendedCommits) {
-            Revision headRevision = context.getHeadRevision();
+            RevisionVector headRevision = context.getHeadRevision();
             Set<Revision> afterHead = new HashSet<Revision>(conflictRevisions.size());
             for (Revision r : conflictRevisions) {
-                if (comparator.compare(r, headRevision) > 0) {
+                if (headRevision.isRevisionNewer(r)) {
                     afterHead.add(r);
                 }
             }
@@ -182,11 +180,11 @@ final class CommitQueue {
             if (suspendedCommits.isEmpty()) {
                 return;
             }
-            Revision headRevision = context.getHeadRevision();
+            RevisionVector headRevision = context.getHeadRevision();
             Iterator<SuspendedCommit> it = suspendedCommits.values().iterator();
             while (it.hasNext()) {
                 SuspendedCommit suspended = it.next();
-                if (suspended.removeRevisionsYoungerThan(headRevision) && suspended.revisions.isEmpty()) {
+                if (suspended.removeRevisionsVisibleFrom(headRevision) && suspended.revisions.isEmpty()) {
                     it.remove();
                 }
             }
@@ -308,12 +306,11 @@ final class CommitQueue {
             this.revisions = revisions;
         }
 
-        private boolean removeRevisionsYoungerThan(Revision revision) {
-            Comparator<Revision> comparator = context.getRevisionComparator();
+        private boolean removeRevisionsVisibleFrom(RevisionVector revision) {
             Iterator<Revision> it = revisions.iterator();
             boolean removed = false;
             while (it.hasNext()) {
-                if (comparator.compare(it.next(), revision) <= 0) {
+                if (!revision.isRevisionNewer(it.next())) {
                     it.remove();
                     semaphore.release();
                     removed = true;
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DiffCache.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DiffCache.java
index 6a9e0c7b59..e23b9ee7a3 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DiffCache.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DiffCache.java
@@ -49,8 +49,8 @@ abstract class DiffCache {
      * @return the diff or {@code null} if unknown and no loader was passed.
      */
     @CheckForNull
-    abstract String getChanges(@Nonnull Revision from,
-                               @Nonnull Revision to,
+    abstract String getChanges(@Nonnull RevisionVector from,
+                               @Nonnull RevisionVector to,
                                @Nonnull String path,
                                @Nullable Loader loader);
 
@@ -65,8 +65,8 @@ abstract class DiffCache {
      * @return the cache entry.
      */
     @Nonnull
-    abstract Entry newEntry(@Nonnull Revision from,
-                            @Nonnull Revision to,
+    abstract Entry newEntry(@Nonnull RevisionVector from,
+                            @Nonnull RevisionVector to,
                             boolean local);
 
     /**
@@ -77,7 +77,7 @@ abstract class DiffCache {
 
     /**
      * Parses the jsop diff returned by
-     * {@link #getChanges(Revision, Revision, String, Loader)} and reports the
+     * {@link #getChanges(RevisionVector, RevisionVector, String, Loader)} and reports the
      * changes by calling the appropriate methods on {@link Diff}.
      *
      * @param jsop the jsop diff to parse.
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentCheckpointMBean.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentCheckpointMBean.java
index 221f67b90a..0ff7226738 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentCheckpointMBean.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentCheckpointMBean.java
@@ -44,9 +44,6 @@ public class DocumentCheckpointMBean extends AbstractCheckpointMBean {
     @Override
     protected void collectCheckpoints(TabularDataSupport tab) throws OpenDataException {
         Map<Revision, Info> checkpoints = store.getCheckpoints().getCheckpoints();
-        if (checkpoints == null) {
-            checkpoints = Collections.emptyMap();
-        }
 
         for (Entry<Revision, Info> checkpoint : checkpoints.entrySet()) {
             String id = checkpoint.getKey().toString();
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentMK.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentMK.java
index fd5b742ddd..ba0d08ceec 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentMK.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentMK.java
@@ -183,8 +183,8 @@ public class DocumentMK {
         if (path == null || path.equals("")) {
             path = "/";
         }
-        Revision fromRev = Revision.fromString(fromRevisionId);
-        Revision toRev = Revision.fromString(toRevisionId);
+        RevisionVector fromRev = RevisionVector.fromString(fromRevisionId);
+        RevisionVector toRev = RevisionVector.fromString(toRevisionId);
         final DocumentNodeState before = nodeStore.getNode(path, fromRev);
         final DocumentNodeState after = nodeStore.getNode(path, toRev);
         if (before == null || after == null) {
@@ -206,7 +206,7 @@ public class DocumentMK {
             throw new DocumentStoreException("Path is not absolute: " + path);
         }
         revisionId = revisionId != null ? revisionId : nodeStore.getHeadRevision().toString();
-        Revision rev = Revision.fromString(revisionId);
+        RevisionVector rev = RevisionVector.fromString(revisionId);
         DocumentNodeState n;
         try {
             n = nodeStore.getNode(path, rev);
@@ -223,7 +223,7 @@ public class DocumentMK {
             throw new DocumentStoreException("Only depth 0 is supported, depth is " + depth);
         }
         revisionId = revisionId != null ? revisionId : nodeStore.getHeadRevision().toString();
-        Revision rev = Revision.fromString(revisionId);
+        RevisionVector rev = RevisionVector.fromString(revisionId);
         try {
             DocumentNodeState n = nodeStore.getNode(path, rev);
             if (n == null) {
@@ -267,22 +267,21 @@ public class DocumentMK {
     public String commit(String rootPath, String jsonDiff, String baseRevId,
             String message) throws DocumentStoreException {
         boolean success = false;
-        boolean isBranch = false;
-        Revision rev;
-        Commit commit = nodeStore.newCommit(baseRevId != null ? Revision.fromString(baseRevId) : null, null);
+        boolean isBranch;
+        RevisionVector rev;
+        Commit commit = nodeStore.newCommit(baseRevId != null ? RevisionVector.fromString(baseRevId) : null, null);
         try {
-            Revision baseRev = commit.getBaseRevision();
+            RevisionVector baseRev = commit.getBaseRevision();
             isBranch = baseRev != null && baseRev.isBranch();
             parseJsonDiff(commit, jsonDiff, rootPath);
-            rev = commit.apply();
+            commit.apply();
+            rev = nodeStore.done(commit, isBranch, null);
             success = true;
         } catch (DocumentStoreException e) {
             throw new DocumentStoreException(e);
         } finally {
             if (!success) {
                 nodeStore.canceled(commit);
-            } else {
-                nodeStore.done(commit, isBranch, null);
             }
         }
         return rev.toString();
@@ -291,15 +290,15 @@ public class DocumentMK {
     public String branch(@Nullable String trunkRevisionId) throws DocumentStoreException {
         // nothing is written when the branch is created, the returned
         // revision simply acts as a reference to the branch base revision
-        Revision revision = trunkRevisionId != null
-                ? Revision.fromString(trunkRevisionId) : nodeStore.getHeadRevision();
-        return revision.asBranchRevision().toString();
+        RevisionVector revision = trunkRevisionId != null
+                ? RevisionVector.fromString(trunkRevisionId) : nodeStore.getHeadRevision();
+        return revision.asBranchRevision(nodeStore.getClusterId()).toString();
     }
 
     public String merge(String branchRevisionId, String message)
             throws DocumentStoreException {
         // TODO improve implementation if needed
-        Revision revision = Revision.fromString(branchRevisionId);
+        RevisionVector revision = RevisionVector.fromString(branchRevisionId);
         if (!revision.isBranch()) {
             throw new DocumentStoreException("Not a branch: " + branchRevisionId);
         }
@@ -316,9 +315,9 @@ public class DocumentMK {
     public String rebase(@Nonnull String branchRevisionId,
                          @Nullable String newBaseRevisionId)
             throws DocumentStoreException {
-        Revision r = Revision.fromString(branchRevisionId);
-        Revision base = newBaseRevisionId != null ?
-                Revision.fromString(newBaseRevisionId) :
+        RevisionVector r = RevisionVector.fromString(branchRevisionId);
+        RevisionVector base = newBaseRevisionId != null ?
+                RevisionVector.fromString(newBaseRevisionId) :
                 nodeStore.getHeadRevision();
         return nodeStore.rebase(r, base).toString();
     }
@@ -327,11 +326,11 @@ public class DocumentMK {
     public String reset(@Nonnull String branchRevisionId,
                         @Nonnull String ancestorRevisionId)
             throws DocumentStoreException {
-        Revision branch = Revision.fromString(branchRevisionId);
+        RevisionVector branch = RevisionVector.fromString(branchRevisionId);
         if (!branch.isBranch()) {
             throw new DocumentStoreException("Not a branch revision: " + branchRevisionId);
         }
-        Revision ancestor = Revision.fromString(ancestorRevisionId);
+        RevisionVector ancestor = RevisionVector.fromString(ancestorRevisionId);
         if (!ancestor.isBranch()) {
             throw new DocumentStoreException("Not a branch revision: " + ancestorRevisionId);
         }
@@ -377,7 +376,7 @@ public class DocumentMK {
     //------------------------------< internal >--------------------------------
 
     private void parseJsonDiff(Commit commit, String json, String rootPath) {
-        Revision baseRev = commit.getBaseRevision();
+        RevisionVector baseRev = commit.getBaseRevision();
         String baseRevId = baseRev != null ? baseRev.toString() : null;
         Set<String> added = Sets.newHashSet();
         JsopReader t = new JsopTokenizer(json);
@@ -399,7 +398,7 @@ public class DocumentMK {
                     if (toRemove == null) {
                         throw new DocumentStoreException("Node not found: " + path + " in revision " + baseRevId);
                     }
-                    commit.removeNode(path);
+                    commit.removeNode(path, toRemove);
                     nodeStore.markAsDeleted(toRemove, commit, true);
                     commit.removeNodeDiff(path);
                     break;
@@ -460,7 +459,8 @@ public class DocumentMK {
     }
 
     private void parseAddNode(Commit commit, JsopReader t, String path) {
-        DocumentNodeState n = new DocumentNodeState(nodeStore, path, commit.getRevision());
+        DocumentNodeState n = new DocumentNodeState(nodeStore, path,
+                new RevisionVector(commit.getRevision()));
         if (!t.matches('}')) {
             do {
                 String key = t.readString();
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeState.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeState.java
index 8cc4ebf28b..0b56187176 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeState.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeState.java
@@ -81,9 +81,9 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
     static final int MAX_FETCH_SIZE = INITIAL_FETCH_SIZE << 4;
 
     final String path;
-    final Revision rev;
-    Revision lastRevision;
-    final Revision rootRevision;
+    final RevisionVector readRevision;
+    RevisionVector lastRevision;
+    final RevisionVector rootRevision;
     final boolean fromExternalChange;
     final Map<String, PropertyState> properties;
     final boolean hasChildren;
@@ -92,29 +92,29 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
 
     DocumentNodeState(@Nonnull DocumentNodeStore store,
                       @Nonnull String path,
-                      @Nonnull Revision rev) {
-        this(store, path, rev, false);
+                      @Nonnull RevisionVector readRevision) {
+        this(store, path, readRevision, false);
     }
 
     DocumentNodeState(@Nonnull DocumentNodeStore store, @Nonnull String path,
-                      @Nonnull Revision rev, boolean hasChildren) {
-        this(store, path, rev, new HashMap<String, PropertyState>(),
+                      @Nonnull RevisionVector readRevision, boolean hasChildren) {
+        this(store, path, readRevision, new HashMap<String, PropertyState>(),
                 hasChildren, null, null, false);
     }
 
     private DocumentNodeState(@Nonnull DocumentNodeStore store,
                               @Nonnull String path,
-                              @Nonnull Revision rev,
+                              @Nonnull RevisionVector readRevision,
                               @Nonnull Map<String, PropertyState> properties,
                               boolean hasChildren,
-                              @Nullable Revision lastRevision,
-                              @Nullable Revision rootRevision,
+                              @Nullable RevisionVector lastRevision,
+                              @Nullable RevisionVector rootRevision,
                               boolean fromExternalChange) {
         this.store = checkNotNull(store);
         this.path = checkNotNull(path);
-        this.rev = checkNotNull(rev);
+        this.readRevision = checkNotNull(readRevision);
         this.lastRevision = lastRevision;
-        this.rootRevision = rootRevision != null ? rootRevision : rev;
+        this.rootRevision = rootRevision != null ? rootRevision : readRevision;
         this.fromExternalChange = fromExternalChange;
         this.hasChildren = hasChildren;
         this.properties = checkNotNull(properties);
@@ -133,12 +133,12 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
      * @return a copy of this node state with the given root revision and
      *          external change flag.
      */
-    private DocumentNodeState withRootRevision(@Nonnull Revision root,
+    private DocumentNodeState withRootRevision(@Nonnull RevisionVector root,
                                                boolean externalChange) {
         if (rootRevision.equals(root) && fromExternalChange == externalChange) {
             return this;
         } else {
-            return new DocumentNodeState(store, path, rev, properties,
+            return new DocumentNodeState(store, path, readRevision, properties,
                     hasChildren, lastRevision, root, externalChange);
         }
     }
@@ -149,7 +149,7 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
      */
     @Nonnull
     DocumentNodeState fromExternalChange() {
-        return new DocumentNodeState(store, path, rev, properties, hasChildren,
+        return new DocumentNodeState(store, path, readRevision, properties, hasChildren,
                 lastRevision, rootRevision, true);
     }
 
@@ -162,8 +162,8 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
     }
 
     @Nonnull
-    Revision getRevision() {
-        return rev;
+    RevisionVector getRevision() {
+        return readRevision;
     }
 
     /**
@@ -178,7 +178,7 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
      *          same value as returned by {@link #getRevision()}.
      */
     @Nonnull
-    Revision getRootRevision() {
+    RevisionVector getRootRevision() {
         return rootRevision;
     }
 
@@ -295,9 +295,9 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
     @Override
     public NodeBuilder builder() {
         if ("/".equals(getPath())) {
-            if (rev.isBranch()) {
+            if (readRevision.isBranch()) {
                 // check if this node state is head of a branch
-                Branch b = store.getBranches().getBranch(rev);
+                Branch b = store.getBranches().getBranch(readRevision);
                 if (b == null) {
                     if (store.isDisableBranches()) {
                         if (DocumentNodeStoreBranch.getCurrentBranch() != null) {
@@ -306,10 +306,10 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
                             return new MemoryNodeBuilder(this);
                         }
                     } else {
-                        throw new IllegalStateException("No branch for revision: " + rev);
+                        throw new IllegalStateException("No branch for revision: " + readRevision);
                     }
                 }
-                if (b.isHead(rev)
+                if (b.isHead(readRevision.getBranchRevision())
                         && DocumentNodeStoreBranch.getCurrentBranch() != null) {
                     return new DocumentRootBuilder(this, store);
                 } else {
@@ -346,9 +346,9 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
                             perfLogger
                                     .end(start,
                                             1,
-                                            "compareAgainstBaseState, path={}, rev={}, lastRevision={}, base.path={}, base.rev={}, base.lastRevision={}",
-                                            path, rev, lastRevision,
-                                            mBase.path, mBase.rev,
+                                            "compareAgainstBaseState, path={}, readRevision={}, lastRevision={}, base.path={}, base.readRevision={}, base.lastRevision={}",
+                                            path, readRevision, lastRevision,
+                                            mBase.path, mBase.readRevision,
                                             mBase.lastRevision);
                         }
                     }
@@ -400,26 +400,28 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
     public String toString() {
         StringBuilder buff = new StringBuilder();
         buff.append("{ path: '").append(path).append("', ");
-        buff.append("rev: '").append(rev).append("', ");
+        buff.append("readRevision: '").append(readRevision).append("', ");
         buff.append("properties: '").append(properties.values()).append("' }");
         return buff.toString();
     }
 
     /**
-     * Create an add node operation for this node.
+     * Create an add operation for this node at the given revision.
+     *
+     * @param revision the revision this node is created.
      */
-    UpdateOp asOperation(boolean isNew) {
+    UpdateOp asOperation(@Nonnull Revision revision) {
         String id = Utils.getIdFromPath(path);
-        UpdateOp op = new UpdateOp(id, isNew);
+        UpdateOp op = new UpdateOp(id, true);
         op.set(Document.ID, id);
         if (Utils.isLongPath(path)) {
             op.set(NodeDocument.PATH, path);
         }
-        NodeDocument.setModified(op, rev);
-        NodeDocument.setDeleted(op, rev, false);
+        NodeDocument.setModified(op, revision);
+        NodeDocument.setDeleted(op, revision, false);
         for (String p : properties.keySet()) {
             String key = Utils.escapePropertyName(p);
-            op.setMapEntry(key, rev, getPropertyAsString(p));
+            op.setMapEntry(key, revision, getPropertyAsString(p));
         }
         return op;
     }
@@ -441,17 +443,21 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
         }
     }
 
-    void setLastRevision(Revision lastRevision) {
+    void setLastRevision(RevisionVector lastRevision) {
         this.lastRevision = lastRevision;
     }
 
-    Revision getLastRevision() {
+    RevisionVector getLastRevision() {
         return lastRevision;
     }
 
     @Override
     public int getMemory() {
-        int size = 164 + estimateMemoryUsage(path);
+        int size = 40 // shallow
+                + readRevision.getMemory()
+                + (lastRevision != null ? lastRevision.getMemory() : 0)
+                + rootRevision.getMemory()
+                + estimateMemoryUsage(path);
         // rough approximation for properties
         for (Map.Entry<String, PropertyState> entry : properties.entrySet()) {
             // name
@@ -461,10 +467,11 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
                     && propState.getType() != Type.BINARIES) {
                 for (int i = 0; i < propState.count(); i++) {
                     // size() returns length of string
-                    // overhead:
+                    // shallow memory:
                     // - 8 bytes per reference in values list
                     // - 48 bytes per string
-                    size += 56 + propState.size(i) * 2;
+                    // double useage per property because of parsed PropertyState
+                    size += (56 + propState.size(i) * 2) * 2;
                 }
             } else {
                 // calculate size based on blobId value
@@ -481,14 +488,14 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
 
     /**
      * Returns {@code true} if this state has the same revision as the
-     * {@code other} state. This method first compares the read {@link #rev}
+     * {@code other} state. This method first compares the {@link #readRevision}
      * and then the {@link #lastRevision}.
      *
      * @param other the other state to compare with.
      * @return {@code true} if the revisions are equal, {@code false} otherwise.
      */
     private boolean revisionEquals(DocumentNodeState other) {
-        return this.rev.equals(other.rev)
+        return this.readRevision.equals(other.readRevision)
                 || this.lastRevision.equals(other.lastRevision);
     }
 
@@ -529,12 +536,12 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
     public String asString() {
         JsopWriter json = new JsopBuilder();
         json.key("path").value(path);
-        json.key("rev").value(rev.toString());
+        json.key("rev").value(readRevision.toString());
         if (lastRevision != null) {
             json.key("lastRev").value(lastRevision.toString());
         }
         if (hasChildren) {
-            json.key("hasChildren").value(hasChildren);
+            json.key("hasChildren").value(true);
         }
         if (properties.size() > 0) {
             json.key("prop").object();
@@ -549,8 +556,8 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
     public static DocumentNodeState fromString(DocumentNodeStore store, String s) {
         JsopTokenizer json = new JsopTokenizer(s);
         String path = null;
-        Revision rev = null;
-        Revision lastRev = null;
+        RevisionVector rev = null;
+        RevisionVector lastRev = null;
         boolean hasChildren = false;
         DocumentNodeState state = null;
         HashMap<String, String> map = new HashMap<String, String>();
@@ -560,9 +567,9 @@ public class DocumentNodeState extends AbstractNodeState implements CacheValue {
             if ("path".equals(k)) {
                 path = json.readString();
             } else if ("rev".equals(k)) {
-                rev = Revision.fromString(json.readString());
+                rev = RevisionVector.fromString(json.readString());
             } else if ("lastRev".equals(k)) {
-                lastRev = Revision.fromString(json.readString());
+                lastRev = RevisionVector.fromString(json.readString());
             } else if ("hasChildren".equals(k)) {
                 hasChildren = json.read() == JsopReader.TRUE;
             } else if ("prop".equals(k)) {
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java
index 676e6ed5d4..093d90fa4b 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java
@@ -42,17 +42,14 @@ import java.lang.ref.WeakReference;
 import java.text.SimpleDateFormat;
 import java.util.Collections;
 import java.util.Date;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.NavigableSet;
 import java.util.Set;
-import java.util.SortedMap;
 import java.util.TimeZone;
 import java.util.concurrent.Callable;
-import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Executor;
@@ -68,6 +65,7 @@ import javax.annotation.Nullable;
 import javax.management.NotCompliantMBeanException;
 
 import com.google.common.base.Function;
+import com.google.common.base.Predicate;
 import com.google.common.base.Predicates;
 import com.google.common.base.Supplier;
 import com.google.common.base.Suppliers;
@@ -83,7 +81,6 @@ import org.apache.jackrabbit.oak.commons.jmx.AnnotatedStandardMBean;
 import org.apache.jackrabbit.oak.plugins.blob.BlobStoreBlob;
 import org.apache.jackrabbit.oak.plugins.blob.MarkSweepGarbageCollector;
 import org.apache.jackrabbit.oak.plugins.blob.ReferencedBlob;
-import org.apache.jackrabbit.oak.plugins.document.Checkpoints.Info;
 import org.apache.jackrabbit.oak.plugins.document.cache.CacheInvalidationStats;
 import org.apache.jackrabbit.oak.plugins.document.persistentCache.PersistentCache;
 import org.apache.jackrabbit.oak.spi.blob.BlobStore;
@@ -95,7 +92,6 @@ import org.apache.jackrabbit.oak.api.CommitFailedException;
 import org.apache.jackrabbit.oak.cache.CacheStats;
 import org.apache.jackrabbit.oak.commons.PathUtils;
 import org.apache.jackrabbit.oak.json.BlobSerializer;
-import org.apache.jackrabbit.oak.plugins.document.Branch.BranchCommit;
 import org.apache.jackrabbit.oak.plugins.document.util.LeaseCheckDocumentStoreWrapper;
 import org.apache.jackrabbit.oak.plugins.document.util.LoggingDocumentStoreWrapper;
 import org.apache.jackrabbit.oak.plugins.document.util.StringValue;
@@ -134,13 +130,6 @@ public final class DocumentNodeStore
      */
     static final int NUM_CHILDREN_CACHE_LIMIT = Integer.getInteger("oak.documentMK.childrenCacheLimit", 16 * 1024);
 
-    /**
-     * When trying to access revisions that are older than this many
-     * milliseconds, a warning is logged. The default is one minute.
-     */
-    private static final int WARN_REVISION_AGE =
-            Integer.getInteger("oak.documentMK.revisionAge", 60 * 1000);
-
     /**
      * Feature flag to enable concurrent add/remove operations of hidden empty
      * nodes. See OAK-2673.
@@ -154,12 +143,6 @@ public final class DocumentNodeStore
     private boolean fairBackgroundOperationLock =
             Boolean.parseBoolean(System.getProperty("oak.fairBackgroundOperationLock", "true"));
 
-    /**
-     * How long to remember the relative order of old revision of all cluster
-     * nodes, in milliseconds. The default is one hour.
-     */
-    static final int REMEMBER_REVISION_ORDER_MILLIS = 60 * 60 * 1000;
-
     /**
      * The document store (might be used by multiple node stores).
      */
@@ -214,24 +197,12 @@ public final class DocumentNodeStore
     private final int clusterId;
 
     /**
-     * Map of inactive cluster nodes and when the cluster node was last seen
-     * as inactive.
-     * Key: clusterId, value: timeInMillis
+     * Map of known cluster nodes and the last known state updated
+     * by {@link #updateClusterState()}.
+     * Key: clusterId, value: ClusterNodeInfoDocument
      */
-    private final ConcurrentMap<Integer, Long> inactiveClusterNodes
-            = new ConcurrentHashMap<Integer, Long>();
-
-    /**
-     * Map of active cluster nodes and when the cluster node's lease ends.
-     * Key: clusterId, value: leaseEndTimeInMillis
-     */
-    private final ConcurrentMap<Integer, Long> activeClusterNodes
-            = new ConcurrentHashMap<Integer, Long>();
-
-    /**
-     * The comparator for revisions.
-     */
-    private final Revision.RevisionComparator revisionComparator;
+    private final ConcurrentMap<Integer, ClusterNodeInfoDocument> clusterNodes
+            = Maps.newConcurrentMap();
 
     /**
      * Unmerged branches of this DocumentNodeStore instance.
@@ -261,17 +232,9 @@ public final class DocumentNodeStore
     private JournalEntry changes;
 
     /**
-     * The last known revision for each cluster instance.
-     *
-     * Key: the machine id, value: revision.
+     * The current root node state.
      */
-    private final Map<Integer, Revision> lastKnownRevision =
-            new ConcurrentHashMap<Integer, Revision>();
-
-    /**
-     * The last known head revision. This is the last-known revision.
-     */
-    private volatile Revision headRevision;
+    private volatile DocumentNodeState root;
 
     private Thread backgroundReadThread;
 
@@ -444,8 +407,7 @@ public final class DocumentNodeStore
         }
         this.store = s;
         this.clusterId = cid;
-        this.revisionComparator = new Revision.RevisionComparator(clusterId);
-        this.branches = new UnmergedBranches(getRevisionComparator());
+        this.branches = new UnmergedBranches();
         this.asyncDelay = builder.getAsyncDelay();
         this.versionGarbageCollector = new VersionGarbageCollector(
                 this, builder.createVersionGCSupport());
@@ -454,7 +416,8 @@ public final class DocumentNodeStore
         this.lastRevRecoveryAgent = new LastRevRecoveryAgent(this,
                 builder.createMissingLastRevSeeker());
         this.disableBranches = builder.isDisableBranches();
-        this.missing = new DocumentNodeState(this, "MISSING", new Revision(0, 0, 0)) {
+        this.missing = new DocumentNodeState(this, "MISSING",
+                new RevisionVector(new Revision(0, 0, 0))) {
             @Override
             public int getMemory() {
                 return 8;
@@ -482,14 +445,16 @@ public final class DocumentNodeStore
         NodeDocument rootDoc = store.find(NODES, Utils.getIdFromPath("/"));
         if (rootDoc == null) {
             // root node is missing: repository is not initialized
-            Revision head = newRevision();
-            Commit commit = new Commit(this, head, null, null);
+            Revision commitRev = newRevision();
+            Commit commit = new Commit(this, commitRev, null, null);
+            RevisionVector head = new RevisionVector(commitRev);
             DocumentNodeState n = new DocumentNodeState(this, "/", head);
             commit.addNode(n);
             commit.applyToDocumentStore();
             // use dummy Revision as before
-            commit.applyToCache(new Revision(0, 0, clusterId), false);
-            setHeadRevision(commit.getRevision());
+            RevisionVector before = new RevisionVector(new Revision(0, 0, clusterId));
+            commit.applyToCache(before, false);
+            setRoot(head);
             // make sure _lastRev is written back to store
             backgroundWrite();
             rootDoc = store.find(NODES, Utils.getIdFromPath("/"));
@@ -499,10 +464,10 @@ public final class DocumentNodeStore
             }
         } else {
             checkLastRevRecovery();
-            initializeHeadRevision(rootDoc);
+            initializeRootState(rootDoc);
             // check if _lastRev for our clusterId exists
             if (!rootDoc.getLastRev().containsKey(clusterId)) {
-                unsavedLastRevisions.put("/", headRevision);
+                unsavedLastRevisions.put("/", getRoot().getRevision().getRevision(clusterId));
                 backgroundWrite();
             }
         }
@@ -510,15 +475,13 @@ public final class DocumentNodeStore
         // Renew the lease because it may have been stale
         renewClusterIdLease();
 
-        getRevisionComparator().add(headRevision, Revision.newRevision(0));
-
         // initialize branchCommits
         branches.init(store, this);
 
         dispatcher = new ChangeDispatcher(getRoot());
         commitQueue = new CommitQueue(this);
         String threadNamePostfix = "(" + clusterId + ")";
-        batchCommitQueue = new BatchCommitQueue(store, revisionComparator);
+        batchCommitQueue = new BatchCommitQueue(store);
         backgroundReadThread = new Thread(
                 new BackgroundReadOperation(this, isDisposed),
                 "DocumentNodeStore background read thread " + threadNamePostfix);
@@ -617,14 +580,9 @@ public final class DocumentNodeStore
         return clusterNodeInfo.toString().replaceAll("[\r\n\t]", " ").trim();
     }
 
-    Revision setHeadRevision(@Nonnull Revision newHead) {
+    void setRoot(@Nonnull RevisionVector newHead) {
         checkArgument(!newHead.isBranch());
-        Revision previous = headRevision;
-        if (!checkNotNull(newHead).equals(previous)) {
-            // head changed
-            headRevision = newHead;
-        }
-        return previous;
+        root = getRoot(newHead);
     }
 
     @Nonnull
@@ -647,10 +605,10 @@ public final class DocumentNodeStore
      * @return a new commit.
      */
     @Nonnull
-    Commit newCommit(@Nullable Revision base,
+    Commit newCommit(@Nullable RevisionVector base,
                      @Nullable DocumentNodeStoreBranch branch) {
         if (base == null) {
-            base = headRevision;
+            base = getHeadRevision();
         }
         if (base.isBranch()) {
             return newBranchCommit(base, branch);
@@ -670,9 +628,9 @@ public final class DocumentNodeStore
      * @return a new merge commit.
      */
     @Nonnull
-    MergeCommit newMergeCommit(@Nullable Revision base, int numBranchCommits) {
+    MergeCommit newMergeCommit(@Nullable RevisionVector base, int numBranchCommits) {
         if (base == null) {
-            base = headRevision;
+            base = getHeadRevision();
         }
         backgroundOperationLock.readLock().lock();
         boolean success = false;
@@ -689,30 +647,34 @@ public final class DocumentNodeStore
         return c;
     }
 
-    void done(final @Nonnull Commit c, boolean isBranch, final @Nullable CommitInfo info) {
+    RevisionVector done(final @Nonnull Commit c, boolean isBranch, final @Nullable CommitInfo info) {
         if (commitQueue.contains(c.getRevision())) {
             try {
+                final RevisionVector[] newHead = new RevisionVector[1];
                 commitQueue.done(c.getRevision(), new CommitQueue.Callback() {
                     @Override
                     public void headOfQueue(@Nonnull Revision revision) {
                         // remember before revision
-                        Revision before = getHeadRevision();
+                        RevisionVector before = getHeadRevision();
                         // apply changes to cache based on before revision
                         c.applyToCache(before, false);
                         // track modified paths
                         changes.modified(c.getModifiedPaths());
                         // update head revision
-                        setHeadRevision(c.getRevision());
+                        newHead[0] = before.update(c.getRevision());
+                        setRoot(newHead[0]);
                         commitQueue.headRevisionChanged();
                         dispatcher.contentChanged(getRoot(), info);
                     }
                 });
+                return newHead[0];
             } finally {
                 backgroundOperationLock.readLock().unlock();
             }
         } else {
             // branch commit
             c.applyToCache(c.getBaseRevision(), isBranch);
+            return c.getBaseRevision().update(c.getRevision().asBranchRevision());
         }
     }
 
@@ -780,7 +742,7 @@ public final class DocumentNodeStore
         nodeChildrenCache.invalidateAll();
     }
 
-    void invalidateNodeCache(String path, Revision revision){
+    void invalidateNodeCache(String path, RevisionVector revision){
         nodeCache.invalidate(new PathRev(path, revision));
     }
 
@@ -792,17 +754,6 @@ public final class DocumentNodeStore
         return disableBranches;
     }
 
-    /**
-     * Checks that revision x is newer than another revision.
-     *
-     * @param x the revision to check
-     * @param previous the presumed earlier revision
-     * @return true if x is newer
-     */
-    boolean isRevisionNewer(@Nonnull Revision x, @Nonnull Revision previous) {
-        return getRevisionComparator().compare(x, previous) > 0;
-    }
-
     /**
      * Enqueue the document with the given id as a split candidate.
      *
@@ -821,7 +772,7 @@ public final class DocumentNodeStore
     }
 
     void markAsDeleted(DocumentNodeState node, Commit commit, boolean subTreeAlso) {
-        commit.removeNode(node.getPath());
+        commit.removeNode(node.getPath(), node);
 
         if (subTreeAlso) {
             // recurse down the tree
@@ -842,8 +793,10 @@ public final class DocumentNodeStore
      *          given revision.
      */
     @CheckForNull
-    DocumentNodeState getNode(@Nonnull final String path, @Nonnull final Revision rev) {
-        checkRevisionAge(checkNotNull(rev), checkNotNull(path));
+    DocumentNodeState getNode(@Nonnull final String path,
+                              @Nonnull final RevisionVector rev) {
+        checkNotNull(rev);
+        checkNotNull(path);
         final long start = PERFLOG.start();
         try {
             PathRev key = new PathRev(path, rev);
@@ -880,7 +833,7 @@ public final class DocumentNodeStore
             return DocumentNodeState.NO_CHILDREN;
         }
         final String path = checkNotNull(parent).getPath();
-        final Revision readRevision = parent.getLastRevision();
+        final RevisionVector readRevision = parent.getLastRevision();
         try {
             PathRev key = childNodeCacheKey(path, readRevision, name);
             DocumentNodeState.Children children = nodeChildrenCache.get(key, new Callable<DocumentNodeState.Children>() {
@@ -925,8 +878,8 @@ public final class DocumentNodeStore
                                             String name, int limit) {
         String queriedName = name;
         String path = parent.getPath();
-        Revision rev = parent.getLastRevision();
-        LOG.trace("Reading children for [{}] ast rev [{}]", path, rev);
+        RevisionVector rev = parent.getLastRevision();
+        LOG.trace("Reading children for [{}] at rev [{}]", path, rev);
         Iterable<NodeDocument> docs;
         DocumentNodeState.Children c = new DocumentNodeState.Children();
         // add one to the requested limit for the raw limit
@@ -1082,7 +1035,7 @@ public final class DocumentNodeStore
             return Collections.emptyList();
         }
 
-        final Revision readRevision = parent.getLastRevision();
+        final RevisionVector readRevision = parent.getLastRevision();
         return transform(getChildren(parent, name, limit).children, new Function<String, DocumentNodeState>() {
             @Override
             public DocumentNodeState apply(String input) {
@@ -1097,7 +1050,7 @@ public final class DocumentNodeStore
     }
 
     @CheckForNull
-    DocumentNodeState readNode(String path, Revision readRevision) {
+    DocumentNodeState readNode(String path, RevisionVector readRevision) {
         final long start = PERFLOG.start();
         String id = Utils.getIdFromPath(path);
         Revision lastRevision = getPendingModifications().get(path);
@@ -1124,7 +1077,7 @@ public final class DocumentNodeStore
      * @param changed the list of changed child nodes.
      *
      */
-    void applyChanges(Revision rev, String path,
+    void applyChanges(RevisionVector rev, String path,
                       boolean isNew, List<String> added,
                       List<String> removed, List<String> changed,
                       DiffCache.Entry cacheEntry) {
@@ -1245,7 +1198,7 @@ public final class DocumentNodeStore
      * @return the root node state at the given revision.
      */
     @Nonnull
-    DocumentNodeState getRoot(@Nonnull Revision revision) {
+    DocumentNodeState getRoot(@Nonnull RevisionVector revision) {
         DocumentNodeState root = getNode("/", revision);
         if (root == null) {
             throw new IllegalStateException(
@@ -1264,7 +1217,8 @@ public final class DocumentNodeStore
     }
 
     @Nonnull
-    Revision rebase(@Nonnull Revision branchHead, @Nonnull Revision base) {
+    RevisionVector rebase(@Nonnull RevisionVector branchHead,
+                          @Nonnull RevisionVector base) {
         checkNotNull(branchHead);
         checkNotNull(base);
         if (disableBranches) {
@@ -1274,33 +1228,33 @@ public final class DocumentNodeStore
         Branch b = getBranches().getBranch(branchHead);
         if (b == null) {
             // empty branch
-            return base.asBranchRevision();
+            return base.asBranchRevision(getClusterId());
         }
-        if (b.getBase(branchHead).equals(base)) {
+        if (b.getBase(branchHead.getBranchRevision()).equals(base)) {
             return branchHead;
         }
         // add a pseudo commit to make sure current head of branch
         // has a higher revision than base of branch
         Revision head = newRevision().asBranchRevision();
         b.rebase(head, base);
-        return head;
+        return base.update(head);
     }
 
     @Nonnull
-    Revision reset(@Nonnull Revision branchHead,
-                   @Nonnull Revision ancestor,
-                   @Nullable DocumentNodeStoreBranch branch) {
+    RevisionVector reset(@Nonnull RevisionVector branchHead,
+                         @Nonnull RevisionVector ancestor,
+                         @Nullable DocumentNodeStoreBranch branch) {
         checkNotNull(branchHead);
         checkNotNull(ancestor);
         Branch b = getBranches().getBranch(branchHead);
         if (b == null) {
             throw new DocumentStoreException("Empty branch cannot be reset");
         }
-        if (!b.getCommits().last().equals(branchHead)) {
+        if (!b.getCommits().last().equals(branchHead.getRevision(getClusterId()))) {
             throw new DocumentStoreException(branchHead + " is not the head " +
                     "of a branch");
         }
-        if (!b.containsCommit(ancestor)) {
+        if (!b.containsCommit(ancestor.getBranchRevision())) {
             throw new DocumentStoreException(ancestor + " is not " +
                     "an ancestor revision of " + branchHead);
         }
@@ -1311,15 +1265,17 @@ public final class DocumentNodeStore
         boolean success = false;
         Commit commit = newCommit(branchHead, branch);
         try {
-            Iterator<Revision> it = b.getCommits().tailSet(ancestor).iterator();
+            Iterator<Revision> it = b.getCommits().tailSet(ancestor.getBranchRevision()).iterator();
             // first revision is the ancestor (tailSet is inclusive)
             // do not undo changes for this revision
-            Revision base = it.next();
+            it.next();
             Map<String, UpdateOp> operations = Maps.newHashMap();
-            while (it.hasNext()) {
+            if (it.hasNext()) {
                 Revision reset = it.next();
-                getRoot(reset).compareAgainstBaseState(getRoot(base),
-                        new ResetDiff(reset.asTrunkRevision(), operations));
+                // TODO: correct?
+                getRoot(b.getCommit(reset).getBase().update(reset))
+                        .compareAgainstBaseState(getRoot(ancestor),
+                                new ResetDiff(reset.asTrunkRevision(), operations));
                 UpdateOp rootOp = operations.get("/");
                 if (rootOp == null) {
                     rootOp = new UpdateOp(Utils.getIdFromPath("/"), false);
@@ -1333,7 +1289,7 @@ public final class DocumentNodeStore
             if (store.findAndUpdate(Collection.NODES, operations.get("/")) != null) {
                 // clean up in-memory branch data
                 // first revision is the ancestor (tailSet is inclusive)
-                List<Revision> revs = Lists.newArrayList(b.getCommits().tailSet(ancestor));
+                List<Revision> revs = Lists.newArrayList(b.getCommits().tailSet(ancestor.getBranchRevision()));
                 for (Revision r : revs.subList(1, revs.size())) {
                     b.removeCommit(r);
                 }
@@ -1358,14 +1314,16 @@ public final class DocumentNodeStore
     }
 
     @Nonnull
-    Revision merge(@Nonnull Revision branchHead, @Nullable CommitInfo info)
+    RevisionVector merge(@Nonnull RevisionVector branchHead,
+                         @Nullable CommitInfo info)
             throws CommitFailedException {
         Branch b = getBranches().getBranch(branchHead);
-        Revision base = branchHead;
+        RevisionVector base = branchHead;
         if (b != null) {
-            base = b.getBase(branchHead);
+            base = b.getBase(branchHead.getBranchRevision());
         }
         int numBranchCommits = b != null ? b.getCommits().size() : 1;
+        RevisionVector newHead;
         boolean success = false;
         MergeCommit commit = newMergeCommit(base, numBranchCommits);
         try {
@@ -1387,22 +1345,21 @@ public final class DocumentNodeStore
                     getBranches().remove(b);
                 } else {
                     NodeDocument root = Utils.getRootDocument(store);
-                    Revision conflictRev = root.getMostRecentConflictFor(b.getCommits(), this);
+                    Set<Revision> conflictRevs = root.getConflictsFor(b.getCommits());
                     String msg = "Conflicting concurrent change. Update operation failed: " + op;
-                    throw new ConflictException(msg, conflictRev).asCommitFailedException();
+                    throw new ConflictException(msg, conflictRevs).asCommitFailedException();
                 }
             } else {
                 // no commits in this branch -> do nothing
             }
+            newHead = done(commit, false, info);
             success = true;
         } finally {
             if (!success) {
                 canceled(commit);
-            } else {
-                done(commit, false, info);
             }
         }
-        return commit.getRevision();
+        return newHead;
     }
 
     /**
@@ -1494,7 +1451,7 @@ public final class DocumentNodeStore
     @Nonnull
     @Override
     public DocumentNodeState getRoot() {
-        return getRoot(headRevision);
+        return root;
     }
 
     @Nonnull
@@ -1518,6 +1475,7 @@ public final class DocumentNodeStore
     }
 
     @Override
+    @Nonnull
     public BlobStoreBlob createBlob(InputStream inputStream) throws IOException {
         return new BlobStoreBlob(blobStore, blobStore.writeBlob(inputStream));
     }
@@ -1530,7 +1488,7 @@ public final class DocumentNodeStore
      * @return the blob.
      */
     @Override
-    public Blob getBlob(String reference) {
+    public Blob getBlob(@Nonnull String reference) {
         String blobId = blobStore.getBlobId(reference);
         if(blobId != null){
             return new BlobStoreBlob(blobStore, blobId);
@@ -1578,19 +1536,13 @@ public final class DocumentNodeStore
     @CheckForNull
     @Override
     public NodeState retrieve(@Nonnull String checkpoint) {
-        Revision r;
-        try {
-            r = Revision.fromString(checkpoint);
-        } catch (IllegalArgumentException e) {
-            LOG.warn("Malformed checkpoint reference: {}", checkpoint);
-            return null;
-        }
-        SortedMap<Revision, Info> checkpoints = this.checkpoints.getCheckpoints();
-        if (checkpoints != null && checkpoints.containsKey(r)) {
-            return getRoot(r);
-        } else {
+        RevisionVector rv = getCheckpoints().retrieve(checkpoint);
+        if (rv == null) {
             return null;
         }
+        // make sure all changes up to checkpoint are visible
+        suspendUntilAll(Sets.newHashSet(rv));
+        return getRoot(rv);
     }
 
     @Override
@@ -1611,19 +1563,14 @@ public final class DocumentNodeStore
         return unsavedLastRevisions;
     }
 
-    @Override
-    public Revision.RevisionComparator getRevisionComparator() {
-        return revisionComparator;
-    }
-
     @Override
     public int getClusterId() {
         return clusterId;
     }
 
     @Nonnull
-    public Revision getHeadRevision() {
-        return headRevision;
+    public RevisionVector getHeadRevision() {
+        return root.getRevision();
     }
 
     @Nonnull
@@ -1729,49 +1676,53 @@ public final class DocumentNodeStore
     }
 
     /**
-     * Updates the state about cluster nodes in {@link #activeClusterNodes}
-     * and {@link #inactiveClusterNodes}.
+     * Updates the state about cluster nodes in {@link #clusterNodes}.
+     *
      * @return true if the cluster state has changed, false if the cluster state
      * remained unchanged
      */
     boolean updateClusterState() {
         boolean hasChanged = false;
-        long now = clock.getTime();
-        Set<Integer> inactive = Sets.newHashSet();
+        Set<Integer> clusterIds = Sets.newHashSet();
         for (ClusterNodeInfoDocument doc : ClusterNodeInfoDocument.all(store)) {
             int cId = doc.getClusterId();
-            if (cId != this.clusterId && !doc.isActive()) {
-                inactive.add(cId);
-            } else {
-                hasChanged |= activeClusterNodes.put(cId, doc.getLeaseEndTime())==null;
+            clusterIds.add(cId);
+            ClusterNodeInfoDocument old = clusterNodes.get(cId);
+            // do not replace document for inactive cluster node
+            // in order to keep the created timestamp of the document
+            // for the time when the cluster node was first seen inactive
+            if (old != null && !old.isActive() && !doc.isActive()) {
+                continue;
+            }
+            clusterNodes.put(cId, doc);
+            if (old == null || old.isActive() != doc.isActive()) {
+                hasChanged = true;
             }
         }
-        hasChanged |= activeClusterNodes.keySet().removeAll(inactive);
-        hasChanged |= inactiveClusterNodes.keySet().retainAll(inactive);
-        for (Integer clusterId : inactive) {
-            hasChanged |= inactiveClusterNodes.putIfAbsent(clusterId, now)==null;
-        }
+        hasChanged |= clusterNodes.keySet().retainAll(clusterIds);
         return hasChanged;
     }
 
     /**
-     * Returns the cluster nodes currently known to be inactive.
-     *
-     * @return a map with the cluster id as key and the time in millis when it
-     *          was first seen inactive.
-     */
-    Map<Integer, Long> getInactiveClusterNodes() {
-        return new HashMap<Integer, Long>(inactiveClusterNodes);
-    }
-
-    /**
-     * Returns the cluster nodes currently known as active.
-     *
-     * @return a map with the cluster id as key and the time in millis when the
-     *          lease ends.
+     * @return the minimum revisions of foreign cluster nodes since they were
+     *          started. The revision is derived from the start time of the
+     *          cluster node.
      */
-    Map<Integer, Long> getActiveClusterNodes() {
-        return new HashMap<Integer, Long>(activeClusterNodes);
+    @Nonnull
+    RevisionVector getMinExternalRevisions() {
+        return new RevisionVector(transform(filter(clusterNodes.values(),
+                new Predicate<ClusterNodeInfoDocument>() {
+                    @Override
+                    public boolean apply(ClusterNodeInfoDocument input) {
+                        return input.getClusterId() != getClusterId();
+                    }
+                }),
+                new Function<ClusterNodeInfoDocument, Revision>() {
+            @Override
+            public Revision apply(ClusterNodeInfoDocument input) {
+                return new Revision(input.getStartTime(), 0, input.getClusterId());
+            }
+        }));
     }
 
     /**
@@ -1787,17 +1738,12 @@ public final class DocumentNodeStore
         }
         alignWithExternalRevisions(doc);
 
-        Revision.RevisionComparator revisionComparator = getRevisionComparator();
-        // the (old) head occurred first
-        Revision headSeen = Revision.newRevision(0);
-        // then we saw this new revision (from another cluster node)
-        Revision otherSeen = Revision.newRevision(0);
-
         StringSort externalSort = JournalEntry.newSorter();
 
         Map<Integer, Revision> lastRevMap = doc.getLastRev();
         try {
-            Map<Revision, Revision> externalChanges = Maps.newHashMap();
+            RevisionVector headRevision = getHeadRevision();
+            Set<Revision> externalChanges = Sets.newHashSet();
             for (Map.Entry<Integer, Revision> e : lastRevMap.entrySet()) {
                 int machineId = e.getKey();
                 if (machineId == clusterId) {
@@ -1805,20 +1751,18 @@ public final class DocumentNodeStore
                     continue;
                 }
                 Revision r = e.getValue();
-                Revision last = lastKnownRevision.get(machineId);
-                if (last == null || r.compareRevisionTime(last) > 0) {
-                    lastKnownRevision.put(machineId, r);
+                Revision last = headRevision.getRevision(machineId);
+                if (last == null) {
+                    // make sure we see all changes when a cluster node joins
+                    last = new Revision(0, 0, machineId);
+                }
+                if (r.compareRevisionTime(last) > 0) {
                     // OAK-2345
                     // only consider as external change if
-                    // - the revision changed for the machineId
-                    // or
-                    // - the revision is within the time frame we remember revisions
-                    if (last != null
-                            || r.getTimestamp() > revisionPurgeMillis()) {
-                        externalChanges.put(r, otherSeen);
-                    }
+                    // the revision changed for the machineId
+                    externalChanges.add(r);
                     // collect external changes
-                    if (last != null && externalSort != null) {
+                    if (externalSort != null) {
                         // add changes for this particular clusterId to the externalSort
                         try {
                             fillExternalChanges(externalSort, last, r, store);
@@ -1871,30 +1815,24 @@ public final class DocumentNodeStore
                 stats.cacheInvalidationTime = clock.getTime() - time;
                 time = clock.getTime();
 
-                // make sure update to revision comparator is atomic
-                // and no local commit is in progress
+                // make sure no local commit is in progress
                 backgroundOperationLock.writeLock().lock();
                 try {
                     stats.lock = clock.getTime() - time;
 
-                    // the latest revisions of the current cluster node
-                    // happened before the latest revisions of other cluster nodes
-                    revisionComparator.add(newRevision(), headSeen);
-                    // then we saw other revisions
-                    for (Map.Entry<Revision, Revision> e : externalChanges.entrySet()) {
-                        revisionComparator.add(e.getKey(), e.getValue());
+                    RevisionVector oldHead = getHeadRevision();
+                    RevisionVector newHead = oldHead;
+                    for (Revision r : externalChanges) {
+                        newHead = newHead.update(r);
                     }
-
-                    Revision oldHead = headRevision;
-                    // the new head revision is after other revisions
-                    setHeadRevision(newRevision());
+                    setRoot(newHead);
                     commitQueue.headRevisionChanged();
                     time = clock.getTime();
                     if (externalSort != null) {
                         // then there were external changes and reading them
                         // was successful -> apply them to the diff cache
                         try {
-                            JournalEntry.applyTo(externalSort, diffCache, oldHead, headRevision);
+                            JournalEntry.applyTo(externalSort, diffCache, oldHead, newHead);
                         } catch (Exception e1) {
                             LOG.error("backgroundRead: Exception while processing external changes from journal: {}", e1, e1);
                         }
@@ -1907,13 +1845,10 @@ public final class DocumentNodeStore
                     backgroundOperationLock.writeLock().unlock();
                 }
                 stats.dispatchChanges = clock.getTime() - time;
-                time = clock.getTime();
             }
         } finally {
             IOUtils.closeQuietly(externalSort);
         }
-        revisionComparator.purge(revisionPurgeMillis());
-        stats.purge = clock.getTime() - time;
 
         return stats;
     }
@@ -1925,7 +1860,6 @@ public final class DocumentNodeStore
         long populateDiffCache;
         long lock;
         long dispatchChanges;
-        long purge;
 
         @Override
         public String toString() {
@@ -1940,21 +1874,10 @@ public final class DocumentNodeStore
                     ", diff: " + populateDiffCache +
                     ", lock:" + lock +
                     ", dispatch:" + dispatchChanges +
-                    ", purge:" + purge +
                     '}';
         }
     }
 
-    /**
-     * Returns the time in milliseconds when revisions can be purged from the
-     * revision comparator.
-     *
-     * @return time in milliseconds.
-     */
-    private static long revisionPurgeMillis() {
-        return Revision.getCurrentTimestamp() - REMEMBER_REVISION_ORDER_MILLIS;
-    }
-
     private void cleanOrphanedBranches() {
         Branch b;
         while ((b = branches.pollOrphanedBranch()) != null) {
@@ -1975,7 +1898,7 @@ public final class DocumentNodeStore
         if (root == null) {
             return;
         }
-        Revision head = getHeadRevision();
+        RevisionVector head = getHeadRevision();
         Map<Revision, String> map = root.getLocalMap(NodeDocument.COLLISIONS);
         UpdateOp op = new UpdateOp(id, false);
         for (Revision r : map.keySet()) {
@@ -1985,7 +1908,7 @@ public final class DocumentNodeStore
                 // head. That is, the collision cannot be related to commit
                 // which is progress.
                 if (branches.getBranchCommit(r) == null 
-                        && isRevisionNewer(head, r)) {
+                        && !head.isRevisionNewer(r)) {
                     NodeDocument.removeCollision(op, r);
                 }
             }
@@ -1997,7 +1920,7 @@ public final class DocumentNodeStore
     }
 
     private void backgroundSplit() {
-        Revision head = getHeadRevision();
+        RevisionVector head = getHeadRevision();
         for (Iterator<String> it = splitCandidates.keySet().iterator(); it.hasNext();) {
             String id = it.next();
             NodeDocument doc = store.find(Collection.NODES, id);
@@ -2046,30 +1969,18 @@ public final class DocumentNodeStore
     //-----------------------------< internal >---------------------------------
 
     /**
-     * Performs an initial read of the _lastRevs on the root document,
-     * initializes the {@link #revisionComparator} and sets the head revision.
+     * Performs an initial read of the _lastRevs on the root document and sets
+     * the root state.
      *
      * @param rootDoc the current root document.
      */
-    private void initializeHeadRevision(NodeDocument rootDoc) {
-        checkState(headRevision == null);
+    private void initializeRootState(NodeDocument rootDoc) {
+        checkState(root == null);
 
         alignWithExternalRevisions(rootDoc);
-        Map<Integer, Revision> lastRevMap = rootDoc.getLastRev();
-        Revision seenAt = Revision.newRevision(0);
-        long purgeMillis = revisionPurgeMillis();
-        for (Map.Entry<Integer, Revision> entry : lastRevMap.entrySet()) {
-            Revision r = entry.getValue();
-            if (r.getTimestamp() > purgeMillis) {
-                revisionComparator.add(r, seenAt);
-            }
-            if (entry.getKey() == clusterId) {
-                continue;
-            }
-            lastKnownRevision.put(entry.getKey(), entry.getValue());
-        }
-        revisionComparator.purge(purgeMillis);
-        setHeadRevision(newRevision());
+        RevisionVector headRevision = new RevisionVector(
+                rootDoc.getLastRev().values()).update(newRevision());
+        setRoot(headRevision);
     }
 
     /**
@@ -2108,7 +2019,7 @@ public final class DocumentNodeStore
     }
 
     @Nonnull
-    private Commit newTrunkCommit(@Nonnull Revision base) {
+    private Commit newTrunkCommit(@Nonnull RevisionVector base) {
         checkArgument(!checkNotNull(base).isBranch(),
                 "base must not be a branch revision: " + base);
 
@@ -2128,7 +2039,7 @@ public final class DocumentNodeStore
     }
 
     @Nonnull
-    private Commit newBranchCommit(@Nonnull Revision base,
+    private Commit newBranchCommit(@Nonnull RevisionVector base,
                                    @Nullable DocumentNodeStoreBranch branch) {
         checkArgument(checkNotNull(base).isBranch(),
                 "base must be a branch revision: " + base);
@@ -2200,7 +2111,8 @@ public final class DocumentNodeStore
      * and that list does not have the given child node. A <code>false</code> indicates that node <i>might</i>
      * exist
      */
-    private boolean checkNodeNotExistsFromChildrenCache(String path, Revision rev) {
+    private boolean checkNodeNotExistsFromChildrenCache(String path,
+                                                        RevisionVector rev) {
         if (PathUtils.denotesRoot(path)) {
             return false;
         }
@@ -2247,8 +2159,8 @@ public final class DocumentNodeStore
         final long getChildrenDoneIn = debug ? now() : 0;
 
         String diffAlgo;
-        Revision fromRev = from.getLastRevision();
-        Revision toRev = to.getLastRevision();
+        RevisionVector fromRev = from.getLastRevision();
+        RevisionVector toRev = to.getLastRevision();
         if (!fromChildren.hasMore && !toChildren.hasMore) {
             diffAlgo = "diffFewChildren";
             diffFewChildren(w, from.getPath(), fromChildren,
@@ -2279,10 +2191,11 @@ public final class DocumentNodeStore
         return diff;
     }
 
-    private void diffManyChildren(JsopWriter w, String path, Revision fromRev, Revision toRev) {
-        long minTimestamp = Math.min(
-                revisionComparator.getMinimumTimestamp(fromRev, inactiveClusterNodes),
-                revisionComparator.getMinimumTimestamp(toRev, inactiveClusterNodes));
+    private void diffManyChildren(JsopWriter w, String path,
+                                  RevisionVector fromRev,
+                                  RevisionVector toRev) {
+        long minTimestamp = Utils.getMinTimestampForDiff(
+                fromRev, toRev, getMinExternalRevisions());
         long minValue = NodeDocument.getModifiedInSecs(minTimestamp);
         String fromKey = Utils.getKeyLowerLimit(path);
         String toKey = Utils.getKeyUpperLimit(path);
@@ -2299,9 +2212,10 @@ public final class DocumentNodeStore
         // also consider nodes with not yet stored modifications (OAK-1107)
         Revision minRev = new Revision(minTimestamp, 0, getClusterId());
         addPathsForDiff(path, paths, getPendingModifications().getPaths(minRev));
-        for (Revision r : new Revision[]{fromRev, toRev}) {
-            if (r.isBranch()) {
-                Branch b = branches.getBranch(r);
+        for (RevisionVector rv : new RevisionVector[]{fromRev, toRev}) {
+            if (rv.isBranch()) {
+                Revision r = rv.getBranchRevision();
+                Branch b = branches.getBranch(rv);
                 if (b != null) {
                     addPathsForDiff(path, paths, b.getModifiedPathsUntil(r));
                 }
@@ -2319,8 +2233,8 @@ public final class DocumentNodeStore
                 if (toNode != null) {
                     // exists in both revisions
                     // check if different
-                    Revision a = fromNode.getLastRevision();
-                    Revision b = toNode.getLastRevision();
+                    RevisionVector a = fromNode.getLastRevision();
+                    RevisionVector b = toNode.getLastRevision();
                     if (a == null && b == null) {
                         // ok
                     } else if (a == null || b == null || !a.equals(b)) {
@@ -2357,7 +2271,11 @@ public final class DocumentNodeStore
         }
     }
 
-    private void diffFewChildren(JsopWriter w, String parentPath, DocumentNodeState.Children fromChildren, Revision fromRev, DocumentNodeState.Children toChildren, Revision toRev) {
+    private void diffFewChildren(JsopWriter w, String parentPath,
+                                 DocumentNodeState.Children fromChildren,
+                                 RevisionVector fromRev,
+                                 DocumentNodeState.Children toChildren,
+                                 RevisionVector toRev) {
         Set<String> childrenSet = Sets.newHashSet(toChildren.children);
         for (String n : fromChildren.children) {
             if (!childrenSet.contains(n)) {
@@ -2386,7 +2304,7 @@ public final class DocumentNodeStore
     }
 
     private static PathRev childNodeCacheKey(@Nonnull String path,
-                                             @Nonnull Revision readRevision,
+                                             @Nonnull RevisionVector readRevision,
                                              @Nullable String name) {
         String p = (name == null ? "" : name) + path;
         return new PathRev(p, readRevision);
@@ -2417,7 +2335,8 @@ public final class DocumentNodeStore
         // of this commit i.e. transient nodes. If its required it would need to be looked
         // into
 
-        DocumentNodeState newNode = new DocumentNodeState(this, targetPath, commit.getRevision());
+        RevisionVector destRevision = commit.getBaseRevision().update(commit.getRevision());
+        DocumentNodeState newNode = new DocumentNodeState(this, targetPath, destRevision);
         source.copyTo(newNode);
 
         commit.addNode(newNode);
@@ -2431,15 +2350,6 @@ public final class DocumentNodeStore
         }
     }
 
-    private void checkRevisionAge(Revision r, String path) {
-        if (LOG.isDebugEnabled()) {
-            if ("/".equals(path) && headRevision.getTimestamp() - r.getTimestamp() > WARN_REVISION_AGE) {
-                LOG.debug("Requesting an old revision for path " + path + ", " +
-                        ((headRevision.getTimestamp() - r.getTimestamp()) / 1000) + " seconds old");
-            }
-        }
-    }
-
     /**
      * Creates and returns a MarkSweepGarbageCollector if the current BlobStore
      * supports garbage collection
@@ -2502,12 +2412,12 @@ public final class DocumentNodeStore
 
         @Override
         public String getRevisionComparatorState() {
-            return revisionComparator.toString();
+            return "";
         }
 
         @Override
         public String getHead(){
-            return headRevision.toString();
+            return getRoot().getRevision().toString();
         }
 
         @Override
@@ -2522,33 +2432,50 @@ public final class DocumentNodeStore
 
         @Override
         public String[] getInactiveClusterNodes() {
-            return toArray(transform(inactiveClusterNodes.entrySet(),
-                    new Function<Map.Entry<Integer, Long>, String>() {
+            return toArray(transform(filter(clusterNodes.values(),
+                    new Predicate<ClusterNodeInfoDocument>() {
+                        @Override
+                        public boolean apply(ClusterNodeInfoDocument input) {
+                            return !input.isActive();
+                        }
+                    }),
+                    new Function<ClusterNodeInfoDocument, String>() {
                         @Override
-                        public String apply(Map.Entry<Integer, Long> input) {
-                            return input.toString();
+                        public String apply(ClusterNodeInfoDocument input) {
+                            return input.getClusterId() + "=" + input.getCreated();
                         }
                     }), String.class);
         }
 
         @Override
         public String[] getActiveClusterNodes() {
-            return toArray(transform(activeClusterNodes.entrySet(),
-                    new Function<Map.Entry<Integer, Long>, String>() {
+            return toArray(transform(filter(clusterNodes.values(),
+                    new Predicate<ClusterNodeInfoDocument>() {
                         @Override
-                        public String apply(Map.Entry<Integer, Long> input) {
-                            return input.toString();
+                        public boolean apply(ClusterNodeInfoDocument input) {
+                            return input.isActive();
+                        }
+                    }),
+                    new Function<ClusterNodeInfoDocument, String>() {
+                        @Override
+                        public String apply(ClusterNodeInfoDocument input) {
+                            return input.getClusterId() + "=" + input.getLeaseEndTime();
                         }
                     }), String.class);
         }
 
         @Override
         public String[] getLastKnownRevisions() {
-            return toArray(transform(lastKnownRevision.entrySet(),
-                    new Function<Map.Entry<Integer, Revision>, String>() {
+            return toArray(transform(filter(getHeadRevision(), new Predicate<Revision>() {
+                        @Override
+                        public boolean apply(Revision input) {
+                            return input.getClusterId() != getClusterId();
+                        }
+                    }),
+                    new Function<Revision, String>() {
                         @Override
-                        public String apply(Map.Entry<Integer, Revision> input) {
-                            return input.toString();
+                        public String apply(Revision input) {
+                            return input.getClusterId() + "=" + input.toString();
                         }
                     }), String.class);
         }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreBranch.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreBranch.java
index 234b251446..4a022136fc 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreBranch.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreBranch.java
@@ -34,6 +34,8 @@ import java.util.concurrent.locks.ReadWriteLock;
 import javax.annotation.CheckForNull;
 import javax.annotation.Nonnull;
 
+import com.google.common.base.Function;
+import com.google.common.collect.Iterables;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 
@@ -279,7 +281,7 @@ class DocumentNodeStoreBranch implements NodeStoreBranch {
             CommitInfo info) {
         boolean success = false;
         Commit c = store.newCommit(base.getRevision(), this);
-        Revision rev;
+        RevisionVector rev;
         try {
             op.with(c);
             if (c.isEmpty()) {
@@ -287,12 +289,11 @@ class DocumentNodeStoreBranch implements NodeStoreBranch {
                 // finally clause cancel the commit
                 return base;
             }
-            rev = c.apply();
+            c.apply();
+            rev = store.done(c, base.getRevision().isBranch(), info);
             success = true;
         } finally {
-            if (success) {
-                store.done(c, base.getRevision().isBranch(), info);
-            } else {
+            if (!success) {
                 store.canceled(c);
             }
         }
@@ -546,7 +547,7 @@ class DocumentNodeStoreBranch implements NodeStoreBranch {
          * @return the branch state.
          */
         final DocumentNodeState createBranch(DocumentNodeState state) {
-            return store.getRoot(state.getRevision().asBranchRevision());
+            return store.getRoot(state.getRevision().asBranchRevision(store.getClusterId()));
         }
 
         @Override
@@ -641,8 +642,15 @@ class DocumentNodeStoreBranch implements NodeStoreBranch {
                 return;
             }
             NodeDocument doc = Utils.getRootDocument(store.getDocumentStore());
-            Set<Revision> collisions = doc.getLocalMap(COLLISIONS).keySet();
-            Set<Revision> conflicts = Sets.intersection(collisions, b.getCommits());
+            Set<Revision> collisions = Sets.newHashSet(doc.getLocalMap(COLLISIONS).keySet());
+            Set<Revision> commits = Sets.newHashSet(Iterables.transform(b.getCommits(),
+                    new Function<Revision, Revision>() {
+                        @Override
+                        public Revision apply(Revision input) {
+                            return input.asTrunkRevision();
+                        }
+                    }));
+            Set<Revision> conflicts = Sets.intersection(collisions, commits);
             if (!conflicts.isEmpty()) {
                 throw new CommitFailedException(STATE, 2,
                         "Conflicting concurrent change on branch commits " + conflicts);
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreMBean.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreMBean.java
index 20c67e9449..029d261ec3 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreMBean.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreMBean.java
@@ -25,6 +25,7 @@ import org.apache.jackrabbit.oak.commons.jmx.Name;
 public interface DocumentNodeStoreMBean {
     String TYPE = "DocumentNodeStore";
 
+    @Deprecated
     String getRevisionComparatorState();
 
     String getHead();
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/JournalEntry.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/JournalEntry.java
index 4782346fe9..abe5af2190 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/JournalEntry.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/JournalEntry.java
@@ -93,8 +93,8 @@ public final class JournalEntry extends Document {
 
     static void applyTo(@Nonnull StringSort externalSort,
                         @Nonnull DiffCache diffCache,
-                        @Nonnull Revision from,
-                        @Nonnull Revision to) throws IOException {
+                        @Nonnull RevisionVector from,
+                        @Nonnull RevisionVector to) throws IOException {
         LOG.debug("applyTo: starting for {} to {}", from, to);
         // note that it is not de-duplicated yet
         LOG.debug("applyTo: sorting done.");
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevs.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevs.java
index 023867b870..fd9a3a67b6 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevs.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevs.java
@@ -17,6 +17,7 @@
 package org.apache.jackrabbit.oak.plugins.document;
 
 import java.util.HashMap;
+import java.util.Iterator;
 import java.util.Map;
 
 import javax.annotation.CheckForNull;
@@ -28,17 +29,19 @@ import org.apache.jackrabbit.oak.plugins.document.util.Utils;
 /**
  * Helper class to track when a node was last modified.
  */
-final class LastRevs {
+final class LastRevs implements Iterable<Revision> {
 
     private final Map<Integer, Revision> revs;
 
-    private final Revision readRevision;
+    private final RevisionVector readRevision;
 
     private final Branch branch;
 
     private Revision branchRev;
 
-    LastRevs(Map<Integer, Revision> revs, Revision readRevision, Branch branch) {
+    LastRevs(Map<Integer, Revision> revs,
+             RevisionVector readRevision,
+             Branch branch) {
         this.revs = new HashMap<Integer, Revision>(revs);
         this.readRevision = readRevision;
         this.branch = branch;
@@ -60,7 +63,7 @@ final class LastRevs {
         }
         rev = rev.asBranchRevision();
         if (branch != null && branch.containsCommit(rev)
-                && readRevision.compareRevisionTime(rev) >= 0) {
+                && readRevision.getBranchRevision().compareRevisionTime(rev) >= 0) {
             branchRev = Utils.max(branchRev, rev);
         }
     }
@@ -70,8 +73,8 @@ final class LastRevs {
         return branchRev;
     }
 
-    @Nonnull
-    Map<Integer, Revision> get() {
-        return revs;
+    @Override
+    public Iterator<Revision> iterator() {
+        return revs.values().iterator();
     }
 }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LocalDiffCache.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LocalDiffCache.java
index 9894345e43..09be128186 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LocalDiffCache.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LocalDiffCache.java
@@ -54,8 +54,8 @@ public class LocalDiffCache extends DiffCache {
     }
 
     @Override
-    public String getChanges(@Nonnull Revision from,
-                             @Nonnull Revision to,
+    public String getChanges(@Nonnull RevisionVector from,
+                             @Nonnull RevisionVector to,
                              @Nonnull String path,
                              @Nullable Loader loader) {
         RevisionsKey key = new RevisionsKey(from, to);
@@ -72,8 +72,8 @@ public class LocalDiffCache extends DiffCache {
 
     @Nonnull
     @Override
-    public Entry newEntry(final @Nonnull Revision from,
-                          final @Nonnull Revision to,
+    public Entry newEntry(final @Nonnull RevisionVector from,
+                          final @Nonnull RevisionVector to,
                           boolean local /*ignored*/) {
         return new Entry() {
             private final Map<String, String> changesPerPath = Maps.newHashMap();
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MemoryDiffCache.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MemoryDiffCache.java
index b369542f80..a9c494ffaf 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MemoryDiffCache.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MemoryDiffCache.java
@@ -56,8 +56,8 @@ public class MemoryDiffCache extends DiffCache {
 
     @CheckForNull
     @Override
-    public String getChanges(@Nonnull final Revision from,
-                             @Nonnull final Revision to,
+    public String getChanges(@Nonnull final RevisionVector from,
+                             @Nonnull final RevisionVector to,
                              @Nonnull final String path,
                              @Nullable final Loader loader) {
         PathRev key = diffCacheKey(path, from, to);
@@ -89,8 +89,8 @@ public class MemoryDiffCache extends DiffCache {
 
     @Nonnull
     @Override
-    public Entry newEntry(@Nonnull Revision from,
-                          @Nonnull Revision to,
+    public Entry newEntry(@Nonnull RevisionVector from,
+                          @Nonnull RevisionVector to,
                           boolean local /*ignored*/) {
         return new MemoryEntry(from, to);
     }
@@ -103,10 +103,10 @@ public class MemoryDiffCache extends DiffCache {
 
     protected class MemoryEntry implements Entry {
 
-        private final Revision from;
-        private final Revision to;
+        private final RevisionVector from;
+        private final RevisionVector to;
 
-        protected MemoryEntry(Revision from, Revision to) {
+        protected MemoryEntry(RevisionVector from, RevisionVector to) {
             this.from = checkNotNull(from);
             this.to = checkNotNull(to);
         }
@@ -124,8 +124,8 @@ public class MemoryDiffCache extends DiffCache {
     }
 
     private static PathRev diffCacheKey(@Nonnull String path,
-                                        @Nonnull Revision from,
-                                        @Nonnull Revision to) {
+                                        @Nonnull RevisionVector from,
+                                        @Nonnull RevisionVector to) {
         return new PathRev(from + path, to);
     }
 
@@ -142,15 +142,15 @@ public class MemoryDiffCache extends DiffCache {
      * @return {@code true} if there are cache entries that indicate the node
      *      at the given path was modified between the two revisions.
      */
-    private boolean isUnchanged(@Nonnull final Revision from,
-                                @Nonnull final Revision to,
+    private boolean isUnchanged(@Nonnull final RevisionVector from,
+                                @Nonnull final RevisionVector to,
                                 @Nonnull final String path) {
         return !denotesRoot(path)
                 && isChildUnchanged(from, to, getParentPath(path), getName(path));
     }
 
-    private boolean isChildUnchanged(@Nonnull final Revision from,
-                                     @Nonnull final Revision to,
+    private boolean isChildUnchanged(@Nonnull final RevisionVector from,
+                                     @Nonnull final RevisionVector to,
                                      @Nonnull final String parent,
                                      @Nonnull final String name) {
         PathRev parentKey = diffCacheKey(parent, from, to);
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MergeCommit.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MergeCommit.java
index 86b4516766..e658abef8f 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MergeCommit.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MergeCommit.java
@@ -33,7 +33,7 @@ class MergeCommit extends Commit {
     private final Set<Revision> branchCommits = Sets.newHashSet();
 
     MergeCommit(DocumentNodeStore nodeStore,
-                Revision baseRevision,
+                RevisionVector baseRevision,
                 SortedSet<Revision> revisions) {
         super(nodeStore, revisions.last(), baseRevision, null);
         this.mergeRevs = revisions;
@@ -52,7 +52,7 @@ class MergeCommit extends Commit {
     }
 
     @Override
-    public void applyToCache(Revision before, boolean isBranchCommit) {
+    public void applyToCache(RevisionVector before, boolean isBranchCommit) {
         // do nothing for a merge commit, only notify node
         // store about merged revisions
         nodeStore.revisionsMerged(branchCommits);
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java
index 45559678c7..977f500164 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java
@@ -18,7 +18,6 @@ package org.apache.jackrabbit.oak.plugins.document;
 
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.Comparator;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Map.Entry;
@@ -55,7 +54,9 @@ import org.slf4j.LoggerFactory;
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
+import com.google.common.primitives.Longs;
 
+import static com.google.common.base.Objects.equal;
 import static com.google.common.base.Preconditions.checkArgument;
 import static com.google.common.base.Preconditions.checkNotNull;
 import static com.google.common.collect.Iterables.filter;
@@ -64,7 +65,6 @@ import static org.apache.jackrabbit.oak.plugins.document.Collection.NODES;
 import static org.apache.jackrabbit.oak.plugins.document.StableRevisionComparator.REVERSE;
 import static org.apache.jackrabbit.oak.plugins.document.UpdateOp.Key;
 import static org.apache.jackrabbit.oak.plugins.document.UpdateOp.Operation;
-import static org.apache.jackrabbit.oak.plugins.document.util.Utils.isRevisionNewer;
 import static org.apache.jackrabbit.oak.plugins.document.util.Utils.resolveCommitRevision;
 
 /**
@@ -654,42 +654,31 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
     }
 
     /**
-     * Returns the most recent conflict on the given {@code branchCommits} if
-     * there are any. The returned revision is the commit, which created the
-     * collision marker for one of the {@code branchCommits}.
+     * Returns the conflicts on the given {@code changes} if there are any. The
+     * returned revisions are the commits, which created the collision markers
+     * for one of the {@code changes}.
      *
-     * @param branchCommits the branch commits to check.
-     * @param context a revision context.
-     * @return the conflict revision or {@code null} if there aren't any or
-     *          the collision marker does not have a revision value.
+     * @param changes the changes to check.
+     * @return the conflict revisions.
      */
-    @CheckForNull
-    Revision getMostRecentConflictFor(@Nonnull Iterable<Revision> branchCommits,
-                                      @Nonnull RevisionContext context) {
-        checkNotNull(branchCommits);
-        checkNotNull(context);
-
-        Comparator<Revision> comparator = context.getRevisionComparator();
-        Revision conflict = null;
+    @Nonnull
+    Set<Revision> getConflictsFor(@Nonnull Iterable<Revision> changes) {
+        checkNotNull(changes);
 
+        Set<Revision> conflicts = Sets.newHashSet();
         Map<Revision, String> collisions = getLocalMap(COLLISIONS);
-        for (Revision r : branchCommits) {
+        for (Revision r : changes) {
             String value = collisions.get(r.asTrunkRevision());
             if (value == null) {
                 continue;
             }
-            Revision c;
             try {
-                c = Revision.fromString(value);
+                conflicts.add(Revision.fromString(value));
             } catch (IllegalArgumentException e) {
                 // backward compatibility: collision marker with value 'true'
-                continue;
-            }
-            if (conflict == null || comparator.compare(conflict, c) < 0) {
-                conflict = c;
             }
         }
-        return conflict;
+        return conflicts;
     }
 
     /**
@@ -740,20 +729,21 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
      */
     @CheckForNull
     Revision getNewestRevision(final RevisionContext context,
-                               final Revision baseRev,
+                               final RevisionVector baseRev,
                                final Revision changeRev,
                                final Branch branch,
                                final Set<Revision> collisions) {
         checkArgument(!baseRev.isBranch() || branch != null,
                 "Branch must be non-null if baseRev is a branch revision");
-        Revision head = context.getHeadRevision();
-        Revision lower = branch != null ? branch.getBase() : baseRev;
+        RevisionVector head = context.getHeadRevision();
+        RevisionVector lower = branch != null ? branch.getBase() : baseRev;
         // the clusterIds to check when walking the changes
         Set<Integer> clusterIds = Collections.emptySet();
         if (!getPreviousRanges().isEmpty()) {
             clusterIds = Sets.newHashSet();
             for (Revision prevRev : getPreviousRanges().keySet()) {
-                if (!isRevisionNewer(context, lower, prevRev)) {
+                if (lower.isRevisionNewer(prevRev) ||
+                        equal(prevRev, lower.getRevision(prevRev.getClusterId()))) {
                     clusterIds.add(prevRev.getClusterId());
                 }
             }
@@ -796,7 +786,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
             if (!fullScan) {
                 // check if we can stop going through changes
                 if (clusterIds.contains(r.getClusterId())
-                        && isRevisionNewer(context, lower, r)
+                        && !lower.isRevisionNewer(r)
                         && newestRevs.containsKey(r.getClusterId())) {
                     clusterIds.remove(r.getClusterId());
                     if (clusterIds.isEmpty()) {
@@ -813,7 +803,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                 // of the branch if this is for a commit on a branch
                 if (branch != null && !branch.containsCommit(r)) {
                     // change does not belong to the branch
-                    if (isRevisionNewer(context, r, branch.getBase())) {
+                    if (branch.getBase().isRevisionNewer(r)) {
                         // and happened after the base of the branch
                         collisions.add(r);
                     }
@@ -843,12 +833,12 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                         commitRevision = commitRoot.getCommitRevision(r);
                     }
                     if (commitRevision != null // committed but not yet visible
-                            && isRevisionNewer(context, commitRevision, head)) {
+                            && head.isRevisionNewer(commitRevision)) {
                         // case 4)
                         collisions.add(r);
                     } else if (commitRevision != null // committed
                             && branch == null         // changeRev not on branch
-                            && isRevisionNewer(context, r, baseRev)) {
+                            && baseRev.isRevisionNewer(r)) {
                         // case 5)
                         newestRevs.put(r.getClusterId(), r);
                     } else {
@@ -862,7 +852,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
         // select the newest committed change
         Revision newestRev = null;
         for (Revision r : newestRevs.values()) {
-            newestRev = Utils.max(newestRev, r, context.getRevisionComparator());
+            newestRev = Utils.max(newestRev, r, StableRevisionComparator.INSTANCE);
         }
 
         if (newestRev == null) {
@@ -913,7 +903,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
     boolean isValidRevision(@Nonnull RevisionContext context,
                             @Nonnull Revision rev,
                             @Nullable String commitValue,
-                            @Nonnull Revision readRevision,
+                            @Nonnull RevisionVector readRevision,
                             @Nonnull Map<Revision, String> validRevisions) {
         if (validRevisions.containsKey(rev)) {
             return true;
@@ -944,13 +934,12 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
      */
     @CheckForNull
     public DocumentNodeState getNodeAtRevision(@Nonnull DocumentNodeStore nodeStore,
-                                               @Nonnull Revision readRevision,
+                                               @Nonnull RevisionVector readRevision,
                                                @Nullable Revision lastModified) {
         Map<Revision, String> validRevisions = Maps.newHashMap();
         Branch branch = nodeStore.getBranches().getBranch(readRevision);
-        LastRevs lastRevs = new LastRevs(getLastRev(), readRevision, branch);
-        // overlay with unsaved last modified from this instance
-        lastRevs.update(lastModified);
+        LastRevs lastRevs = createLastRevs(readRevision,
+                validRevisions, branch, lastModified);
 
         Revision min = getLiveRevision(nodeStore, readRevision, validRevisions, lastRevs);
         if (min == null) {
@@ -959,7 +948,6 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
         }
         String path = getPath();
         DocumentNodeState n = new DocumentNodeState(nodeStore, path, readRevision, hasChildren());
-        Revision lastRevision = min;
         for (String key : keySet()) {
             if (!Utils.isPropertyName(key)) {
                 continue;
@@ -970,80 +958,79 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                 continue;
             }
             // first check local map, which contains most recent values
-            Value value = getLatestValue(nodeStore, local,
-                    min, readRevision, validRevisions, lastRevs);
+            Value value = getLatestValue(nodeStore, local, readRevision, validRevisions, lastRevs);
 
             // check if there may be more recent values in a previous document
-            if (!getPreviousRanges().isEmpty()) {
-                if (!isMostRecentCommitted(nodeStore, local, value.revision)) {
-                    // not reading the most recent value, we may need to
-                    // consider previous documents as well
-                    Revision newestPrev = getPreviousRanges().firstKey();
-                    if (isRevisionNewer(nodeStore, newestPrev, value.revision)) {
+            if (value != null
+                    && !getPreviousRanges().isEmpty()
+                    && !isMostRecentCommitted(local, value.revision)) {
+                // not reading the most recent value, we may need to
+                // consider previous documents as well
+                for (Revision prev : getPreviousRanges().keySet()) {
+                    if (prev.compareRevisionTimeThenClusterId(value.revision) > 0) {
                         // a previous document has more recent changes
                         // than value.revision
                         value = null;
+                        break;
                     }
                 }
             }
 
             if (value == null && !getPreviousRanges().isEmpty()) {
                 // check complete revision history
-                value = getLatestValue(nodeStore, getValueMap(key),
-                        min, readRevision, validRevisions, lastRevs);
+                value = getLatestValue(nodeStore, getValueMap(key), readRevision, validRevisions, lastRevs);
             }
             String propertyName = Utils.unescapePropertyName(key);
             String v = value != null ? value.value : null;
             n.setProperty(propertyName, v);
-            // keep track of when this node was last modified
-            if (value != null && isRevisionNewer(nodeStore, value.revision, lastRevision)) {
-                lastRevision = value.revision;
-            }
         }
 
-        // lastRevision now points to the revision when this node was
-        // last modified directly. but it may also have been 'modified'
-        // by an operation on a descendant node, which is tracked in
-        // _lastRev.
-
         // when was this node last modified?
-        Revision branchBase = null;
+        RevisionVector lastRevision = new RevisionVector(min);
+        RevisionVector branchBase = null;
         if (branch != null) {
-            branchBase = branch.getBase(readRevision);
+            branchBase = branch.getBase(readRevision.getBranchRevision());
         }
-        for (Revision r : lastRevs.get().values()) {
-            // ignore if newer than readRevision
-            if (isRevisionNewer(nodeStore, r, readRevision)) {
+        for (Revision r : lastRevs) {
+            if (readRevision.isRevisionNewer(r)) {
                 // the node has a _lastRev which is newer than readRevision
                 // this means we don't know when this node was
                 // modified by an operation on a descendant node between
                 // current lastRevision and readRevision. therefore we have
                 // to stay on the safe side and use readRevision
-                lastRevision = readRevision;
-                continue;
-            } else if (branchBase != null && isRevisionNewer(nodeStore, r, branchBase)) {
+                Revision rev = readRevision.getRevision(r.getClusterId());
+                if (rev != null) {
+                    lastRevision = lastRevision.update(rev);
+                } else {
+                    // readRevision does not have a revision for this
+                    // clusterId -> remove from lastRevision
+                    lastRevision = lastRevision.remove(r.getClusterId());
+                }
+            } else if (branchBase != null && branchBase.isRevisionNewer(r)) {
                 // readRevision is on a branch and the node has a
                 // _lastRev which is newer than the base of the branch
                 // we cannot use this _lastRev because it is not visible
                 // from this branch. highest possible revision of visible
                 // changes is the base of the branch
-                r = branchBase;
-            }
-            if (revisionAreAmbiguous(nodeStore, r, lastRevision)) {
-                // _lastRev entries from multiple cluster nodes are ambiguous
-                // use readRevision to make sure read is consistent
-                lastRevision = readRevision;
-            } else if (isRevisionNewer(nodeStore, r, lastRevision)) {
-                lastRevision = r;
+                Revision rev = branchBase.getRevision(r.getClusterId());
+                if (rev != null) {
+                    lastRevision = lastRevision.update(rev);
+                } else {
+                    // branchBase does not have a revision for this
+                    // clusterId -> remove from lastRevision
+                    lastRevision = lastRevision.remove(r.getClusterId());
+                }
+            } else if (lastRevision.isRevisionNewer(r)) {
+                lastRevision = lastRevision.update(r);
             }
         }
         if (branch != null) {
             // read from a branch
             // -> possibly overlay with unsaved last revs from branch
-            lastRevs.updateBranch(branch.getUnsavedLastRevision(path, readRevision));
+            lastRevs.updateBranch(branch.getUnsavedLastRevision(path, readRevision.getBranchRevision()));
             Revision r = lastRevs.getBranchRevision();
             if (r != null) {
-                lastRevision = r;
+                lastRevision = lastRevision.update(r);
             }
         }
         n.setLastRevision(lastRevision);
@@ -1055,27 +1042,26 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
      * the provided revision, if the node was alive at the given revision.
      *
      * @param context the revision context
-     * @param maxRev the maximum revision to return
+     * @param readRevision the read revision
      * @param validRevisions the map of revisions to commit value already
-     *                       checked against maxRev and considered valid.
+     *                       checked against readRevision and considered valid.
      * @param lastRevs to keep track of the last modification.
      * @return the earliest revision, or null if the node is deleted at the
      *         given revision
      */
     @CheckForNull
-    public Revision getLiveRevision(RevisionContext context, Revision maxRev,
+    public Revision getLiveRevision(RevisionContext context,
+                                    RevisionVector readRevision,
                                     Map<Revision, String> validRevisions,
                                     LastRevs lastRevs) {
         // check local deleted map first
-        Value value = getLatestValue(context, getLocalDeleted(),
-                null, maxRev, validRevisions, lastRevs);
-        if (value.value == null && !getPreviousRanges().isEmpty()) {
+        Value value = getLatestValue(context, getLocalDeleted(), readRevision, validRevisions, lastRevs);
+        if (value == null && !getPreviousRanges().isEmpty()) {
             // need to check complete map
-            value = getLatestValue(context, getDeleted(),
-                    null, maxRev, validRevisions, lastRevs);
+            value = getLatestValue(context, getDeleted(), readRevision, validRevisions, lastRevs);
         }
 
-        return "false".equals(value.value) ? value.revision : null;
+        return value != null && "false".equals(value.value) ? value.revision : null;
     }
 
     /**
@@ -1085,14 +1071,12 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
      * @param op the update operation.
      * @param baseRevision the base revision for the update operation.
      * @param commitRevision the commit revision of the update operation.
-     * @param context the revision context.
      * @param enableConcurrentAddRemove feature flag for OAK-2673.
      * @return <code>true</code> if conflicting, <code>false</code> otherwise.
      */
     boolean isConflicting(@Nonnull UpdateOp op,
-                          @Nonnull Revision baseRevision,
+                          @Nonnull RevisionVector baseRevision,
                           @Nonnull Revision commitRevision,
-                          @Nonnull RevisionContext context,
                           boolean enableConcurrentAddRemove) {
         // did existence of node change after baseRevision?
         // only check local deleted map, which contains the most
@@ -1105,7 +1089,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                 continue;
             }
 
-            if (isRevisionNewer(context, entry.getKey(), baseRevision)) {
+            if (baseRevision.isRevisionNewer(entry.getKey())) {
                 boolean newerDeleted = Boolean.parseBoolean(entry.getValue());
                 if (!allowConflictingDeleteChange || op.isDelete() != newerDeleted) {
                     return true;
@@ -1127,11 +1111,11 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                 continue;
             }
             // was this property touched after baseRevision?
-            for (Revision rev : getChanges(name, baseRevision, context)) {
+            for (Revision rev : getChanges(name, baseRevision)) {
                 if (rev.equals(commitRevision)) {
                     continue;
                 }
-                if (isRevisionNewer(context, rev, baseRevision)) {
+                if (baseRevision.isRevisionNewer(rev)) {
                     return true;
                 }
             }
@@ -1203,7 +1187,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
      */
     @Nonnull
     public Iterable<UpdateOp> split(@Nonnull RevisionContext context,
-                                    @Nonnull Revision head) {
+                                    @Nonnull RevisionVector head) {
         return SplitOperations.forDocument(this, context, head, NUM_REVS_THRESHOLD);
     }
 
@@ -1551,13 +1535,11 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
      *
      * @param property the name of the property.
      * @param min the lower bound revision (exclusive).
-     * @param context the revision context.
      * @return changes back to {@code min} revision.
      */
     @Nonnull
     Iterable<Revision> getChanges(@Nonnull final String property,
-                                  @Nonnull final Revision min,
-                                  @Nonnull final RevisionContext context) {
+                                  @Nonnull final RevisionVector min) {
         return new Iterable<Revision>() {
             @Override
             public Iterator<Revision> iterator() {
@@ -1567,7 +1549,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                     clusterIds.add(r.getClusterId());
                 }
                 for (Range r : getPreviousRanges().values()) {
-                    if (isRevisionNewer(context, r.high, min)) {
+                    if (min.isRevisionNewer(r.high)) {
                         clusterIds.add(r.high.getClusterId());
                     }
                 }
@@ -1577,7 +1559,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                     protected Revision computeNext() {
                         while (unfiltered.hasNext()) {
                             Revision next = unfiltered.next();
-                            if (isRevisionNewer(context, next, min)) {
+                            if (min.isRevisionNewer(next)) {
                                 return next;
                             } else {
                                 // further revisions with this clusterId
@@ -1769,67 +1751,91 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
 
     //----------------------------< internal >----------------------------------
 
+    private LastRevs createLastRevs(@Nonnull RevisionVector readRevision,
+                                    @Nonnull Map<Revision, String> validRevisions,
+                                    @Nullable Branch branch,
+                                    @Nullable Revision pendingLastRev) {
+        LastRevs lastRevs = new LastRevs(getLastRev(), readRevision, branch);
+        // overlay with unsaved last modified from this instance
+        lastRevs.update(pendingLastRev);
+        // collect clusterIds
+        SortedSet<Revision> mostRecentChanges = Sets.newTreeSet(REVERSE);
+        mostRecentChanges.addAll(getLocalRevisions().keySet());
+        mostRecentChanges.addAll(getLocalCommitRoot().keySet());
+        Set<Integer> clusterIds = Sets.newHashSet();
+        for (Revision r : getLocalRevisions().keySet()) {
+            clusterIds.add(r.getClusterId());
+        }
+        for (Revision r : getLocalCommitRoot().keySet()) {
+            clusterIds.add(r.getClusterId());
+        }
+        for (Revision r : mostRecentChanges) {
+            if (!clusterIds.contains(r.getClusterId())) {
+                // already found most recent change from this cluster node
+                continue;
+            }
+            String commitValue = validRevisions.get(r);
+            if (commitValue == null) {
+                commitValue = resolveCommitValue(r);
+            }
+            if (commitValue == null) {
+                continue;
+            }
+            // resolve revision
+            Revision commitRev = resolveCommitRevision(r, commitValue);
+            if (Utils.isCommitted(commitValue)) {
+                lastRevs.update(commitRev);
+                clusterIds.remove(r.getClusterId());
+            } else if (branch != null) {
+                Revision branchRev = commitRev.asBranchRevision();
+                if (branch.containsCommit(branchRev)) {
+                    lastRevs.updateBranch(branchRev);
+                    clusterIds.remove(r.getClusterId());
+                }
+            }
+        }
+        return lastRevs;
+    }
+
+    private String resolveCommitValue(Revision revision) {
+        NodeDocument commitRoot = getCommitRoot(revision);
+        if (commitRoot == null) {
+            return null;
+        }
+        return commitRoot.getCommitValue(revision);
+    }
+
     /**
      * Returns {@code true} if the given {@code revision} is more recent or
      * equal to the committed revision in {@code valueMap}. This method assumes
      * the given {@code revision} is committed.
      *
-     * @param context the revision context.
      * @param valueMap the value map sorted most recent first.
      * @param revision a committed revision.
      * @return if {@code revision} is the most recent committed revision in the
      *          {@code valueMap}.
      */
-    private boolean isMostRecentCommitted(RevisionContext context,
-                                          SortedMap<Revision, String> valueMap,
+    private boolean isMostRecentCommitted(SortedMap<Revision, String> valueMap,
                                           Revision revision) {
         if (valueMap.isEmpty()) {
             return true;
         }
         // shortcut when revision is the first key
         Revision first = valueMap.firstKey();
-        if (!isRevisionNewer(context, first, revision)) {
+        if (first.compareRevisionTimeThenClusterId(revision) <= 0) {
             return true;
         }
         // need to check commit status
         for (Revision r : valueMap.keySet()) {
             Revision c = getCommitRevision(r);
             if (c != null) {
-                return !isRevisionNewer(context, c, revision);
+                return c.compareRevisionTimeThenClusterId(revision) <= 0;
             }
         }
         // no committed revision found in valueMap
         return true;
     }
 
-    /**
-     * Returns {@code true} if the two revisions are ambiguous. That is, they
-     * are from different cluster nodes and the comparison of the two revision
-     * depends on the seen at revision and is different when just comparing the
-     * timestamps of the revisions.
-     *
-     * @param context the revision context.
-     * @param r1 the first revision.
-     * @param r2 the second revision.
-     * @return {@code true} if ambiguous, {@code false} otherwise.
-     */
-    static boolean revisionAreAmbiguous(@Nonnull RevisionContext context,
-                                        @Nonnull Revision r1,
-                                        @Nonnull Revision r2) {
-        if (r1.getClusterId() == r2.getClusterId()) {
-            return false;
-        }
-        int c1 = context.getRevisionComparator().compare(r1, r2);
-        int c2 = r1.compareTo(r2);
-        if (c1 == 0) {
-            return c2 == 0;
-        } else if (c1 < 0) {
-            return c2 >= 0;
-        } else {
-            return c2 <= 0;
-        }
-    }
-
     /**
      * Returns the commit root document for the given revision. This may either
      * be this document or another one.
@@ -1922,7 +1928,7 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
     private boolean isCommitted(@Nonnull RevisionContext context,
                                 @Nonnull Revision revision,
                                 @Nullable String commitValue,
-                                @Nonnull Revision readRevision) {
+                                @Nonnull RevisionVector readRevision) {
         if (commitValue == null) {
             commitValue = getCommitValue(revision);
         }
@@ -1936,17 +1942,18 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                 revision = resolveCommitRevision(revision, commitValue);
                 // readRevision is not from a branch
                 // compare resolved revision as is
-                return !isRevisionNewer(context, revision, readRevision);
+                return !readRevision.isRevisionNewer(revision);
             } else {
                 // on same merged branch?
-                if (commitValue.equals(getCommitValue(readRevision.asTrunkRevision()))) {
+                if (commitValue.equals(getCommitValue(readRevision.getBranchRevision().asTrunkRevision()))) {
                     // compare unresolved revision
-                    return !isRevisionNewer(context, revision, readRevision);
+                    return !readRevision.isRevisionNewer(revision);
                 }
             }
         } else {
             // branch commit (not merged)
-            if (Revision.fromString(commitValue).getClusterId() != context.getClusterId()) {
+            RevisionVector branchCommit = RevisionVector.fromString(commitValue);
+            if (branchCommit.getBranchRevision().getClusterId() != context.getClusterId()) {
                 // this is an unmerged branch commit from another cluster node,
                 // hence never visible to us
                 return false;
@@ -1978,70 +1985,61 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
 
     private static boolean includeRevision(RevisionContext context,
                                            Revision x,
-                                           Revision requestRevision) {
-        Branch b = context.getBranches().getBranch(x);
+                                           RevisionVector readRevision) {
+        Branch b = null;
+        if (x.getClusterId() == context.getClusterId()) {
+            RevisionVector branchRev = new RevisionVector(x).asBranchRevision(context.getClusterId());
+            b = context.getBranches().getBranch(branchRev);
+        }
         if (b != null) {
-            // only include if requested revision is also a branch revision
+            // only include if read revision is also a branch revision
             // with a history including x
-            if (b.containsCommit(requestRevision)) {
+            if (readRevision.isBranch()
+                    && b.containsCommit(readRevision.getBranchRevision())) {
                 // in same branch, include if the same revision or
-                // requestRevision is newer
-                return x.equalsIgnoreBranch(requestRevision)
-                        || isRevisionNewer(context, requestRevision, x);
+                // readRevision is newer
+                return !readRevision.isRevisionNewer(x);
             }
             // not part of branch identified by requestedRevision
             return false;
         }
         // assert: x is not a branch commit
-        b = context.getBranches().getBranch(requestRevision);
+        b = context.getBranches().getBranch(readRevision);
         if (b != null) {
-            // reset requestRevision to branch base revision to make
+            // reset readRevision to branch base revision to make
             // sure we don't include revisions committed after branch
             // was created
-            requestRevision = b.getBase(requestRevision);
+            readRevision = b.getBase(readRevision.getBranchRevision());
         }
-        return context.getRevisionComparator().compare(requestRevision, x) >= 0;
+        return !readRevision.isRevisionNewer(x);
     }
 
     /**
-     * Get the latest property value that is larger or equal the min revision,
-     * and smaller or equal the readRevision revision. The returned value will
-     * provide the revision when the value was set between the {@code min} and
-     * {@code readRevision}. The returned value will have a {@code null} value
-     * contained if there is no valid change within the given range. In this
-     * case the associated revision is {@code min} or {@code readRevision} if
-     * no {@code min} is provided.
+     * Get the latest property value smaller or equal the readRevision revision.
      *
      * @param valueMap the sorted revision-value map
-     * @param min the minimum revision (null meaning unlimited)
      * @param readRevision the maximum revision
      * @param validRevisions map of revision to commit value considered valid
      *                       against the given readRevision.
      * @param lastRevs to keep track of the most recent modification.
      * @return the latest value from the {@code readRevision} point of view.
      */
-    @Nonnull
+    @CheckForNull
     private Value getLatestValue(@Nonnull RevisionContext context,
                                  @Nonnull Map<Revision, String> valueMap,
-                                 @Nullable Revision min,
-                                 @Nonnull Revision readRevision,
+                                 @Nonnull RevisionVector readRevision,
                                  @Nonnull Map<Revision, String> validRevisions,
                                  @Nonnull LastRevs lastRevs) {
         for (Map.Entry<Revision, String> entry : valueMap.entrySet()) {
             Revision propRev = entry.getKey();
             String commitValue = validRevisions.get(propRev);
             if (commitValue == null) {
-                // resolve revision
-                NodeDocument commitRoot = getCommitRoot(propRev);
-                if (commitRoot == null) {
-                    continue;
-                }
-                commitValue = commitRoot.getCommitValue(propRev);
-                if (commitValue == null) {
-                    continue;
-                }
+                commitValue = resolveCommitValue(propRev);
             }
-
+            if (commitValue == null) {
+                continue;
+            }
+            // resolve revision
             Revision commitRev = resolveCommitRevision(propRev, commitValue);
             if (Utils.isCommitted(commitValue)) {
                 lastRevs.update(commitRev);
@@ -2050,17 +2048,11 @@ public final class NodeDocument extends Document implements CachedNodeDocument{
                 lastRevs.updateBranch(commitRev.asBranchRevision());
             }
 
-            if (min != null && isRevisionNewer(context, min, commitRev)) {
-                continue;
-            }
             if (isValidRevision(context, propRev, commitValue, readRevision, validRevisions)) {
-                // TODO: need to check older revisions as well?
                 return new Value(commitRev, entry.getValue());
             }
         }
-
-        Revision r = min != null ? min : readRevision;
-        return new Value(r, null);
+        return null;
     }
 
     @Override
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/PathRev.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/PathRev.java
index 0d0b31987b..23ff228ec4 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/PathRev.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/PathRev.java
@@ -21,6 +21,7 @@ package org.apache.jackrabbit.oak.plugins.document;
 import javax.annotation.Nonnull;
 
 import org.apache.jackrabbit.oak.cache.CacheValue;
+import org.apache.jackrabbit.oak.commons.StringUtils;
 
 import static com.google.common.base.Preconditions.checkNotNull;
 
@@ -32,18 +33,18 @@ public final class PathRev implements CacheValue {
 
     private final String path;
 
-    private final Revision revision;
+    private final RevisionVector revision;
 
-    public PathRev(@Nonnull String path, @Nonnull Revision revision) {
+    public PathRev(@Nonnull String path, @Nonnull RevisionVector revision) {
         this.path = checkNotNull(path);
         this.revision = checkNotNull(revision);
     }
 
     @Override
     public int getMemory() {
-        return 24                           // shallow size
-                + 40 + path.length() * 2    // path
-                + 32;                       // revision
+        return 24                                       // shallow size
+                + StringUtils.estimateMemoryUsage(path) // path
+                + revision.getMemory();                 // revision
     }
 
     //----------------------------< Object >------------------------------------
@@ -76,7 +77,8 @@ public final class PathRev implements CacheValue {
 
     public static PathRev fromString(String s) {
         int index = s.lastIndexOf('@');
-        return new PathRev(s.substring(0, index), Revision.fromString(s.substring(index + 1)));
+        return new PathRev(s.substring(0, index),
+                RevisionVector.fromString(s.substring(index + 1)));
     }
 
     public int compareTo(PathRev b) {
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Revision.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Revision.java
index 86eefcf526..26634e3935 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Revision.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Revision.java
@@ -16,16 +16,7 @@
  */
 package org.apache.jackrabbit.oak.plugins.document;
 
-import java.util.ArrayList;
-import java.util.Comparator;
-import java.util.List;
-import java.util.Map;
-import java.util.TreeSet;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-
-import javax.annotation.Nonnull;
-
+import org.apache.jackrabbit.oak.cache.CacheValue;
 import org.apache.jackrabbit.oak.plugins.document.util.Utils;
 import org.apache.jackrabbit.oak.stats.Clock;
 
@@ -34,7 +25,9 @@ import static com.google.common.base.Preconditions.checkNotNull;
 /**
  * A revision.
  */
-public class Revision {
+public final class Revision implements CacheValue {
+
+    static final int SHALLOW_MEMORY_USAGE = 32;
 
     private static volatile long lastTimestamp;
 
@@ -339,7 +332,7 @@ public class Revision {
      * Returns a revision with the same timestamp, counter and clusterId as this
      * revision and the branch flag set to <code>false</code>.
      *
-     * @return trunkrevision with this timestamp, counter and clusterId.
+     * @return trunk revision with this timestamp, counter and clusterId.
      */
     public Revision asTrunkRevision() {
         if (!isBranch()) {
@@ -370,379 +363,12 @@ public class Revision {
                 r.branch == this.branch;
     }
 
-    public boolean equalsIgnoreBranch(Revision other) {
-        if (this == other) {
-            return true;
-        } else if (other == null) {
-            return false;
-        }
-        return other.timestamp == this.timestamp &&
-                other.counter == this.counter &&
-                other.clusterId == this.clusterId;
-    }
-
     public int getClusterId() {
         return clusterId;
     }
 
-    /**
-     * Revision ranges allow to compare revisions ids of different cluster instances. A
-     * range tells when a list of revisions from a certain cluster instance was seen by
-     * the current process.
-     */
-    static class RevisionRange {
-
-        /**
-         * The newest revision for the given cluster instance and time.
-         */
-        Revision revision;
-
-        /**
-         * The (local) revision; the time when this revision was seen by this
-         * cluster instance.
-         */
-        Revision seenAt;
-
-        @Override
-        public String toString() {
-            return revision + ":" + seenAt;
-        }
-
-    }
-
-    /**
-     * A facility that is able to compare revisions of different cluster instances.
-     * It contains a map of revision ranges.
-     */
-    public static class RevisionComparator implements Comparator<Revision> {
-
-        static final Revision NEWEST = new Revision(Long.MAX_VALUE, 0, 0);
-
-        static final Revision FUTURE = new Revision(Long.MAX_VALUE, Integer.MAX_VALUE, 0);
-
-        /**
-         * The map of cluster instances to lists of revision ranges.
-         */
-        private final ConcurrentMap<Integer, List<RevisionRange>> map =
-                new ConcurrentHashMap<Integer, List<RevisionRange>>();
-
-        /**
-         * When comparing revisions that occurred before, the timestamp is ignored.
-         */
-        private long oldestTimestamp;
-
-        /**
-         * The cluster node id of the current cluster node. Revisions
-         * from this cluster node that are newer than the newest range
-         * (new local revisions)
-         * are considered to be the newest revisions overall.
-         */
-        private final int currentClusterNodeId;
-
-        RevisionComparator(int currentClusterNodId) {
-            this.currentClusterNodeId = currentClusterNodId;
-        }
-
-        /**
-         * Forget the order of older revisions. After calling this method, when comparing
-         * revisions that happened before the given value, the timestamp order is used
-         * (time dilation is ignored for older events).
-         *
-         * @param timestamp the time in milliseconds (see {@link #getCurrentTimestamp})
-         */
-        public void purge(long timestamp) {
-            oldestTimestamp = timestamp;
-            for (int clusterId : map.keySet()) {
-                while (true) {
-                    List<RevisionRange> list = map.get(clusterId);
-                    List<RevisionRange> newList = purge(list);
-                    if (newList == null) {
-                        // retry if removing was not successful
-                        if (map.remove(clusterId, list)) {
-                            break;
-                        }
-                    } else if (newList == list) {
-                        // no change
-                        break;
-                    } else {
-                        // retry if replacing was not successful
-                        if (map.replace(clusterId, list, newList)) {
-                            break;
-                        }
-                    }
-                }
-            }
-        }
-
-        private List<RevisionRange> purge(List<RevisionRange> list) {
-            int i = 0;
-            for (; i < list.size(); i++) {
-                RevisionRange r = list.get(i);
-                if (r.seenAt.getTimestamp() > oldestTimestamp) {
-                    break;
-                }
-            }
-            if (i > list.size() - 1) {
-                return null;
-            } else if (i == 0) {
-                return list;
-            }
-            return new ArrayList<RevisionRange>(list.subList(i, list.size()));
-        }
-
-        /**
-         * Add the revision to the top of the queue for the given cluster node.
-         * If an entry for this timestamp already exists, it is replaced.
-         *
-         * @param r the revision
-         * @param seenAt the (local) revision where this revision was seen here
-         */
-        public void add(Revision r, Revision seenAt) {
-            int clusterId = r.getClusterId();
-            while (true) {
-                List<RevisionRange> list = map.get(clusterId);
-                List<RevisionRange> newList;
-                if (list == null) {
-                    newList = new ArrayList<RevisionRange>();
-                } else {
-                    RevisionRange last = list.get(list.size() - 1);
-                    if (last.seenAt.equals(seenAt)) {
-                        // replace existing
-                        if (r.compareRevisionTime(last.revision) > 0) {
-                            // but only if newer
-                            last.revision = r;
-                        }
-                        return;
-                    }
-                    if (last.revision.compareRevisionTime(r) > 0) {
-                        throw new IllegalArgumentException(
-                                "Can not add an earlier revision: " + last.revision + " > " + r +
-                                "; current cluster node is " + currentClusterNodeId);
-                    }
-                    newList = new ArrayList<RevisionRange>(list);
-                }
-                RevisionRange range = new RevisionRange();
-                range.seenAt = seenAt;
-                range.revision = r;
-                newList.add(range);
-                if (list == null) {
-                    if (map.putIfAbsent(clusterId, newList) == null) {
-                        return;
-                    }
-                } else {
-                    if (map.replace(clusterId, list, newList)) {
-                        return;
-                    }
-                }
-            }
-        }
-
-        /**
-         * Returns the minimum timestamp of the most recent revisions from all
-         * active cluster nodes as seen from the given {@code revision}.
-         *
-         * @param revision a revision.
-         * @param inactive map of cluster nodes considered inactive.
-         * @return the minimum timestamp.
-         */
-        public long getMinimumTimestamp(@Nonnull Revision revision,
-                                        @Nonnull Map<Integer, Long> inactive) {
-            long timestamp = checkNotNull(revision).getTimestamp();
-            Revision seenAt = getRevisionSeen(revision);
-            if (seenAt == null) {
-                // already purged
-                return timestamp;
-            }
-            // go through all known cluster nodes
-            for (Map.Entry<Integer, List<RevisionRange>> e : map.entrySet()) {
-                if (revision.getClusterId() == currentClusterNodeId
-                        && e.getKey() == currentClusterNodeId) {
-                    // range and revision is for current cluster node
-                    // no need to adjust timestamp
-                    continue;
-                }
-                List<RevisionRange> list = e.getValue();
-                RevisionRange range;
-                for (int i = list.size() - 1; i >= 0; i--) {
-                    range = list.get(i);
-                    if (range.seenAt.compareRevisionTimeThenClusterId(seenAt) <= 0) {
-                        // found newest range older or equal the given seenAt
-                        // check if the cluster node is still active
-                        Long inactiveSince = inactive.get(range.revision.getClusterId());
-                        if (inactiveSince != null
-                                && revision.getTimestamp() > inactiveSince
-                                && range.revision.getTimestamp() < inactiveSince) {
-                            // ignore, because the revision is after the
-                            // cluster node became inactive and the most recent
-                            // range is before it became inactive
-                        } else {
-                            timestamp = Math.min(timestamp, range.revision.getTimestamp());
-                        }
-                        break;
-                    }
-                }
-            }
-            return timestamp;
-        }
-
-        @Override
-        public int compare(Revision o1, Revision o2) {
-            if (o1.getClusterId() == o2.getClusterId()) {
-                return o1.compareRevisionTime(o2);
-            }
-            Revision range1 = getRevisionSeen(o1);
-            Revision range2 = getRevisionSeen(o2);
-            if (range1 == FUTURE && range2 == FUTURE) {
-                return o1.compareTo(o2);
-            }
-            if (range1 == null && range2 == null) {
-                return o1.compareTo(o2);
-            }
-            if (range1 == null) {
-                return -1;
-            } else if (range2 == null) {
-                return 1;
-            }
-            int comp = range1.compareTo(range2);
-            if (comp != 0) {
-                return comp;
-            }
-            return o1.compareTo(o2);
-        }
-
-        /**
-         * Get the seen-at revision from the revision range.
-         * <p>
-         * <ul>
-         *     <li>
-         *         {@code null} if the revision is older than the earliest range
-         *         and the revision timestamp is less than or equal the time
-         *         of the last {@link #purge(long)} (see also
-         *         {@link #oldestTimestamp}).
-         *     </li>
-         *     <li>
-         *         if the revision is newer than the lower bound of the newest
-         *         range, then {@link #NEWEST} is returned for a local cluster
-         *         revision and {@link #FUTURE} for a foreign cluster revision.
-         *     </li>
-         *     <li>
-         *         if the revision matches the lower seen-at bound of a range,
-         *         then this seen-at revision is returned.
-         *     </li>
-         *     <li>
-         *         otherwise the lower bound seen-at revision of next higher
-         *         range is returned.
-         *     </li>
-         * </ul>
-         *
-         * Below is a graph for a revision comparison example as seen from one
-         * cluster node with some known revision ranges. Revision ranges less
-         * than or equal r2-0-0 have been purged and there are known ranges for
-         * cluster node 1 (this cluster node) and cluster node 2 (some other
-         * cluster node).
-         * <pre>
-         *     View from cluster node 1:
-         *
-         *                purge    r3-0-1    r5-0-2    r7-0-1
-         *                                             
-         *     ---+---------+---------+---------+---------+---------
-         *     r1-0-0    r2-0-0    r3-0-0    r4-0-0    r5-0-0
-         *
-         *            ^
-         *         r1-0-1 -> null (1)
-         *
-         *                      ^
-         *                   r4-0-2 -> r4-0-0 (2)
-         *
-         *                            ^
-         *                         r3-0-1 -> r3-0-0 (3)
-         *
-         *                                           ^
-         *                                        r6-0-2 -> FUTURE (4)
-         *
-         *                                                       ^
-         *                                                    r9-0-1 -> NEWEST (5)
-         * </pre>
-         * <ol>
-         *     <li>older than earliest range and purge time</li>
-         *     <li>seen-at of next higher range</li>
-         *     <li>seen-at of matching lower bound of range</li>
-         *     <li>foreign revision is newer than most recent range</li>
-         *     <li>local revision is newer than most recent range</li>
-         * </ol>
-         * This gives the following revision ordering:
-         * <pre>
-         * r1-0-1 < r3-0-1 < r-4-0-2 < r9-0-1 < r6-0-2
-         * </pre>
-         *
-         * @param r the revision
-         * @return the seen-at revision or {@code null} if the revision is older
-         *          than the earliest range and purge time.
-         */
-        Revision getRevisionSeen(Revision r) {
-            List<RevisionRange> list = map.get(r.getClusterId());
-            if (list == null) {
-                if (r.getTimestamp() <= oldestTimestamp) {
-                    // old revision with already purged range
-                    return null;
-                }
-                if (r.getClusterId() != currentClusterNodeId) {
-                    // this is from a cluster node we did not see yet
-                    // see also OAK-1170
-                    return FUTURE;
-                }
-                return null;
-            }
-            // search from latest backward
-            // (binary search could be used, but we expect most queries
-            // at the end of the list)
-            RevisionRange range = null;
-            for (int i = list.size() - 1; i >= 0; i--) {
-                range = list.get(i);
-                int compare = r.compareRevisionTime(range.revision);
-                if (compare == 0) {
-                    return range.seenAt;
-                } else if (compare > 0) {
-                    if (i == list.size() - 1) {
-                        // newer than the newest range
-                        if (r.getClusterId() == currentClusterNodeId) {
-                            // newer than all others, except for FUTURE
-                            return NEWEST;
-                        } else {
-                            // happens in the future (not visible yet)
-                            return FUTURE;
-                        }
-                    } else {
-                        // there is a newer range
-                        return list.get(i + 1).seenAt;
-                    }
-                }
-            }
-            if (range != null && r.getTimestamp() > oldestTimestamp) {
-                // revision is older than earliest range and after purge
-                // timestamp. return seen-at revision of earliest range.
-                return range.seenAt;
-            }
-            return null;
-        }
-
-        @Override
-        public String toString() {
-            StringBuilder buff = new StringBuilder();
-            for (int clusterId : new TreeSet<Integer>(map.keySet())) {
-                int i = 0;
-                buff.append(clusterId).append(":");
-                for (RevisionRange r : map.get(clusterId)) {
-                    if (i++ % 4 == 0) {
-                        buff.append('\n');
-                    }
-                    buff.append(" ").append(r);
-                }
-                buff.append("\n");
-            }
-            return buff.toString();
-        }
-
+    @Override
+    public int getMemory() {
+        return SHALLOW_MEMORY_USAGE;
     }
-
 }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/RevisionContext.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/RevisionContext.java
index e4fb6d2859..6f5c00e62e 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/RevisionContext.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/RevisionContext.java
@@ -36,11 +36,6 @@ public interface RevisionContext {
      */
     UnsavedModifications getPendingModifications();
 
-    /**
-     * @return the revision comparator.
-     */
-    Comparator<Revision> getRevisionComparator();
-
     /**
      * @return the cluster id of the local DocumentMK instance.
      */
@@ -50,7 +45,7 @@ public interface RevisionContext {
      * @return the current head revision.
      */
     @Nonnull
-    Revision getHeadRevision();
+    RevisionVector getHeadRevision();
 
     /**
      * @return a new revision for the local document node store instance.
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/RevisionVector.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/RevisionVector.java
new file mode 100644
index 0000000000..f2f327b269
--- /dev/null
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/RevisionVector.java
@@ -0,0 +1,499 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.plugins.document;
+
+import java.util.Arrays;
+import java.util.Comparator;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
+
+import javax.annotation.CheckForNull;
+import javax.annotation.Nonnull;
+
+import com.google.common.collect.AbstractIterator;
+import com.google.common.collect.Iterators;
+import com.google.common.collect.Lists;
+import com.google.common.collect.PeekingIterator;
+import com.google.common.collect.Sets;
+import com.google.common.primitives.Ints;
+
+import org.apache.jackrabbit.oak.cache.CacheValue;
+import org.apache.jackrabbit.oak.plugins.document.util.Utils;
+
+import static com.google.common.base.Preconditions.checkNotNull;
+import static com.google.common.collect.Iterables.toArray;
+import static com.google.common.collect.Iterators.peekingIterator;
+import static com.google.common.collect.Lists.newArrayListWithCapacity;
+import static java.util.Arrays.sort;
+
+/**
+ * A vector of revisions. Instances of this class are immutable and methods
+ * like {@link #update(Revision)} create a new instance as needed.
+ *
+ * This class implements {@link Comparable}. While
+ * {@link #compareTo(RevisionVector)} provides a total order of revision
+ * vector instances, this order is unrelated to when changes are visible in
+ * a DocumentNodeStore cluster. Do not use this method to determine whether
+ * a given revision vector happened before or after another!
+ */
+public final class RevisionVector implements Iterable<Revision>, Comparable<RevisionVector>, CacheValue {
+
+    private final static RevisionVector EMPTY = new RevisionVector();
+
+    private final Revision[] revisions;
+
+    private RevisionVector(@Nonnull Revision[] revisions,
+                           boolean checkUniqueClusterIds,
+                           boolean sort) {
+        checkNotNull(revisions);
+        if (checkUniqueClusterIds) {
+            checkUniqueClusterIds(revisions);
+        }
+        if (sort) {
+            sort(revisions, RevisionComparator.INSTANCE);
+        }
+        this.revisions = revisions;
+    }
+
+    public RevisionVector(@Nonnull Revision... revisions) {
+        this(Arrays.copyOf(revisions, revisions.length), true, true);
+    }
+
+    public RevisionVector(@Nonnull Iterable<Revision> revisions) {
+        this(toArray(revisions, Revision.class), true, true);
+    }
+
+    public RevisionVector(@Nonnull Set<Revision> revisions) {
+        this(toArray(revisions, Revision.class), false, true);
+    }
+
+    /**
+     * Creates a new revision vector with based on this vector and the given
+     * {@code revision}. If this vector contains a revision with the same
+     * clusterId as {@code revision}, the returned vector will have the
+     * revision updated with the given one. Otherwise the returned vector will
+     * have all elements of this vector plus the given {@code revision}.
+     *
+     * @param revision the revision set to use for the new vector.
+     * @return the resulting revision vector.
+     */
+    public RevisionVector update(@Nonnull Revision revision) {
+        checkNotNull(revision);
+        Revision existing = null;
+        int i;
+        for (i = 0; i < revisions.length; i++) {
+            Revision r = revisions[i];
+            if (r.getClusterId() == revision.getClusterId()) {
+                existing = r;
+                break;
+            }
+        }
+        Revision[] newRevisions;
+        boolean sort;
+        if (existing != null) {
+            if (revision.equals(existing)) {
+                return this;
+            } else {
+                newRevisions = Arrays.copyOf(revisions, revisions.length);
+                newRevisions[i] = revision;
+                sort = false;
+            }
+        } else {
+            newRevisions = new Revision[revisions.length + 1];
+            System.arraycopy(revisions, 0, newRevisions, 0, revisions.length);
+            newRevisions[revisions.length] = revision;
+            sort = true;
+        }
+        return new RevisionVector(newRevisions, false, sort);
+    }
+
+    /**
+     * Returns a RevisionVector without the revision element with the given
+     * {@code clusterId}.
+     *
+     * @param clusterId the clusterId of the revision to remove.
+     * @return RevisionVector without the revision element.
+     */
+    public RevisionVector remove(int clusterId) {
+        if (revisions.length == 0) {
+            return this;
+        }
+        boolean found = false;
+        for (Revision r : revisions) {
+            if (r.getClusterId() == clusterId) {
+                found = true;
+                break;
+            } else if (r.getClusterId() > clusterId) {
+                break;
+            }
+        }
+        if (!found) {
+            return this;
+        }
+        Revision[] revs = new Revision[revisions.length - 1];
+        int idx = 0;
+        for (Revision r : revisions) {
+            if (r.getClusterId() != clusterId) {
+                revs[idx++] = r;
+            }
+        }
+        return new RevisionVector(revs, false, false);
+    }
+
+    /**
+     * Calculates the parallel minimum of this and the given {@code vector}.
+     *
+     * @param vector the other vector.
+     * @return the parallel minimum of the two.
+     */
+    public RevisionVector pmin(@Nonnull RevisionVector vector) {
+        // optimize single revision case
+        if (revisions.length == 1 && vector.revisions.length == 1) {
+            if (revisions[0].getClusterId() == vector.revisions[0].getClusterId()) {
+                return revisions[0].compareRevisionTime(vector.revisions[0]) < 0 ? this : vector;
+            } else {
+                return EMPTY;
+            }
+        }
+        int capacity = Math.min(revisions.length, vector.revisions.length);
+        List<Revision> pmin = newArrayListWithCapacity(capacity);
+        PeekingIterator<Revision> it = peekingIterator(vector.iterator());
+        for (Revision r : revisions) {
+            Revision other = peekRevision(it, r.getClusterId());
+            if (other != null) {
+                if (other.getClusterId() == r.getClusterId()) {
+                    pmin.add(Utils.min(r, other));
+                }
+            } else {
+                break;
+            }
+        }
+        return new RevisionVector(toArray(pmin, Revision.class), false, false);
+    }
+
+    /**
+     * Calculates the parallel maximum of this and the given {@code vector}.
+     *
+     * @param vector the other vector.
+     * @return the parallel maximum of the two.
+     */
+    public RevisionVector pmax(@Nonnull RevisionVector vector) {
+        // optimize single revision case
+        if (revisions.length == 1 && vector.revisions.length == 1) {
+            if (revisions[0].getClusterId() == vector.revisions[0].getClusterId()) {
+                return revisions[0].compareRevisionTime(vector.revisions[0]) > 0 ? this : vector;
+            } else {
+                return new RevisionVector(revisions[0], vector.revisions[0]);
+            }
+        }
+        int capacity = Math.max(revisions.length, vector.revisions.length);
+        List<Revision> pmax = newArrayListWithCapacity(capacity);
+        PeekingIterator<Revision> it = peekingIterator(vector.iterator());
+        for (Revision r : revisions) {
+            while (it.hasNext() && it.peek().getClusterId() < r.getClusterId()) {
+                pmax.add(it.next());
+            }
+            Revision other = peekRevision(it, r.getClusterId());
+            if (other != null && other.getClusterId() == r.getClusterId()) {
+                pmax.add(Utils.max(r, other));
+                it.next();
+            } else {
+                // other does not have a revision with r.clusterId
+                pmax.add(r);
+            }
+        }
+        // add remaining
+        Iterators.addAll(pmax, it);
+        return new RevisionVector(toArray(pmax, Revision.class), false, false);
+    }
+
+    /**
+     * Returns the difference of this and the other vector. The returned vector
+     * contains all revisions of this vector that are not contained in the
+     * other vector.
+     *
+     * @param vector the other vector.
+     * @return the difference of the two vectors.
+     */
+    public RevisionVector difference(RevisionVector vector) {
+        List<Revision> diff = newArrayListWithCapacity(revisions.length);
+        PeekingIterator<Revision> it = peekingIterator(vector.iterator());
+        for (Revision r : revisions) {
+            Revision other = peekRevision(it, r.getClusterId());
+            if (!r.equals(other)) {
+                diff.add(r);
+            }
+        }
+        return new RevisionVector(toArray(diff, Revision.class), false, false);
+    }
+
+    /**
+     * Returns {@code true} if the given revision is newer than the revision
+     * element with the same clusterId in the vector. The given revision is
+     * also considered newer if there is no revision element with the same
+     * clusterId in this vector.
+     *
+     * @param revision the revision to check.
+     * @return {@code true} if considered newer, {@code false} otherwise.
+     */
+    public boolean isRevisionNewer(@Nonnull Revision revision) {
+        checkNotNull(revision);
+        for (Revision r : revisions) {
+            if (r.getClusterId() == revision.getClusterId()) {
+                return r.compareRevisionTime(revision) < 0;
+            } else if (r.getClusterId() > revision.getClusterId()) {
+                // revisions are sorted by clusterId ascending
+                break;
+            }
+        }
+        return true;
+    }
+
+    /**
+     * @return {@code true} if any of the revisions in this vector is a branch
+     *          revision, {@code false} otherwise.
+     */
+    public boolean isBranch() {
+        for (Revision r : revisions) {
+            if (r.isBranch()) {
+                return true;
+            }
+        }
+        return false;
+    }
+
+    /**
+     * @return the first branch revision in this vector.
+     * @throws IllegalStateException if this vector does not contain a branch
+     *          revision.
+     */
+    @Nonnull
+    public Revision getBranchRevision() {
+        for (Revision r : revisions) {
+            if (r.isBranch()) {
+                return r;
+            }
+        }
+        throw new IllegalStateException(
+                "This vector does not contain a branch revision: " + this);
+    }
+
+    /**
+     * Returns the revision element with the given clusterId or {@code null}
+     * if there is no such revision in this vector.
+     *
+     * @param clusterId a clusterId.
+     * @return the revision element with the given clusterId or {@code null}
+     *      if none exists.
+     */
+    public Revision getRevision(int clusterId) {
+        for (Revision r : revisions) {
+            int cmp = Ints.compare(r.getClusterId(), clusterId);
+            if (cmp == 0) {
+                return r;
+            } else if (cmp > 0) {
+                break;
+            }
+        }
+        return null;
+    }
+
+    /**
+     * Returns a string representation of this revision vector, which can be
+     * parsed again by {@link #fromString(String)}.
+     *
+     * @return a string representation of this revision vector.
+     */
+    public String asString() {
+        StringBuilder sb = new StringBuilder();
+        String comma = "";
+        for (Revision r : revisions) {
+            sb.append(comma);
+            comma = ",";
+            r.toStringBuilder(sb);
+        }
+        return sb.toString();
+    }
+
+    /**
+     * Creates a revision vector from a string representation as returned by
+     * {@link #asString()}.
+     *
+     * @param s the string representation of a revision vector.
+     * @return the revision vector.
+     * @throws IllegalArgumentException if the string is malformed
+     */
+    public static RevisionVector fromString(String s) {
+        List<Revision> revisions = Lists.newArrayListWithCapacity(3);
+        for (String str : s.split(",")) {
+            revisions.add(Revision.fromString(str));
+        }
+        return new RevisionVector(revisions);
+    }
+
+    /**
+     * Returns a revision vector where all revision elements are turned into
+     * trunk revisions.
+     *
+     * @return a trunk representation of this revision vector.
+     */
+    public RevisionVector asTrunkRevision() {
+        if (!isBranch()) {
+            return this;
+        }
+        Revision[] revs = new Revision[revisions.length];
+        for (int i = 0; i < revisions.length; i++) {
+            revs[i] = revisions[i].asTrunkRevision();
+        }
+        return new RevisionVector(revs, false, false);
+    }
+
+    /**
+     * A clone of this revision vector with the revision for the given
+     * clusterId set to a branch revision.
+     *
+     * @param clusterId the clusterId of the revision to be turned into a branch
+     *                  revision.
+     * @return the revision vector with the branch revision.
+     * @throws IllegalArgumentException if there is no revision element with the
+     *      given clusterId.
+     */
+    public RevisionVector asBranchRevision(int clusterId) {
+        boolean found = false;
+        Revision[] revs = new Revision[revisions.length];
+        for (int i = 0; i < revisions.length; i++) {
+            Revision r = revisions[i];
+            if (r.getClusterId() == clusterId) {
+                r = r.asBranchRevision();
+                found = true;
+            }
+            revs[i] = r;
+        }
+        if (!found) {
+            throw new IllegalArgumentException("RevisionVector [" + asString() +
+                    "] does not have a revision for clusterId " + clusterId);
+        }
+        return new RevisionVector(revs, false, false);
+    }
+
+    //------------------------< CacheValue >------------------------------------
+
+    @Override
+    public int getMemory() {
+        return 32 // shallow size
+                + revisions.length * (Revision.SHALLOW_MEMORY_USAGE + 4);
+    }
+
+    //------------------------< Comparable >------------------------------------
+
+    @Override
+    public int compareTo(@Nonnull RevisionVector other) {
+        Iterator<Revision> it = other.iterator();
+        for (Revision r : revisions) {
+            if (!it.hasNext()) {
+                return 1;
+            }
+            Revision otherRev = it.next();
+            int cmp = -Ints.compare(r.getClusterId(), otherRev.getClusterId());
+            if (cmp != 0) {
+                return cmp;
+            }
+            cmp = r.compareTo(otherRev);
+            if (cmp != 0) {
+                return cmp;
+            }
+        }
+        return it.hasNext() ? -1 : 0;
+    }
+
+    //-------------------------< Iterable >-------------------------------------
+
+    @Override
+    public Iterator<Revision> iterator() {
+        return new AbstractIterator<Revision>() {
+            int i = 0;
+            @Override
+            protected Revision computeNext() {
+                if (i >= revisions.length) {
+                    return endOfData();
+                } else {
+                    return revisions[i++];
+                }
+            }
+        };
+    }
+
+    //--------------------------< Object >--------------------------------------
+
+    @Override
+    public String toString() {
+        return asString();
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+        if (obj instanceof RevisionVector) {
+            RevisionVector other = (RevisionVector) obj;
+            return Arrays.equals(revisions, other.revisions);
+        }
+        return false;
+    }
+
+    @Override
+    public int hashCode() {
+        return Arrays.hashCode(revisions);
+    }
+
+    //-------------------------< internal >-------------------------------------
+
+    @CheckForNull
+    private Revision peekRevision(PeekingIterator<Revision> it,
+                                  int minClusterId) {
+        while (it.hasNext() && it.peek().getClusterId() < minClusterId) {
+            it.next();
+        }
+        return it.hasNext() ? it.peek() : null;
+    }
+
+    private static void checkUniqueClusterIds(Revision[] revisions)
+            throws IllegalArgumentException {
+        if (revisions.length < 2) {
+            return;
+        }
+        Set<Integer> known = Sets.newHashSetWithExpectedSize(revisions.length);
+        for (Revision revision : revisions) {
+            if (!known.add(revision.getClusterId())) {
+                throw new IllegalArgumentException(
+                        "Multiple revisions with clusterId " + revision.getClusterId());
+            }
+        }
+    }
+
+    /**
+     * Compares revisions according to their clusterId.
+     */
+    private static final class RevisionComparator implements Comparator<Revision> {
+
+        private static final Comparator<Revision> INSTANCE = new RevisionComparator();
+
+        @Override
+        public int compare(Revision o1, Revision o2) {
+            return Ints.compare(o1.getClusterId(), o2.getClusterId());
+        }
+    }
+}
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java
index d33ba8b9f6..dc3eb5e872 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java
@@ -20,7 +20,6 @@ package org.apache.jackrabbit.oak.plugins.document;
 
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.Comparator;
 import java.util.List;
 import java.util.Map;
 import java.util.NavigableMap;
@@ -55,7 +54,6 @@ import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.setHasBina
 import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.setPrevious;
 import static org.apache.jackrabbit.oak.plugins.document.util.Utils.PROPERTY_OR_DELETED;
 import static org.apache.jackrabbit.oak.plugins.document.util.Utils.getPreviousIdFor;
-import static org.apache.jackrabbit.oak.plugins.document.util.Utils.isRevisionNewer;
 
 /**
  * Utility class to create document split operations.
@@ -86,13 +84,13 @@ class SplitOperations {
 
     private SplitOperations(@Nonnull NodeDocument doc,
                             @Nonnull RevisionContext context,
-                            @Nonnull Revision headRevision,
+                            @Nonnull RevisionVector headRevision,
                             int numRevsThreshold) {
         this.doc = checkNotNull(doc);
         this.context = checkNotNull(context);
         this.path = doc.getPath();
         this.id = doc.getId();
-        this.headRevision = checkNotNull(headRevision);
+        this.headRevision = checkNotNull(headRevision).getRevision(context.getClusterId());
         this.numRevsThreshold = numRevsThreshold;
     }
 
@@ -117,7 +115,7 @@ class SplitOperations {
     @Nonnull
     static List<UpdateOp> forDocument(@Nonnull NodeDocument doc,
                                       @Nonnull RevisionContext context,
-                                      @Nonnull Revision headRevision,
+                                      @Nonnull RevisionVector headRevision,
                                       int numRevsThreshold) {
         if (doc.isSplitDocument()) {
             throw new IllegalArgumentException(
@@ -208,7 +206,7 @@ class SplitOperations {
      */
     private void collectRevisionsAndCommitRoot() {
         NavigableMap<Revision, String> revisions =
-                new TreeMap<Revision, String>(context.getRevisionComparator());
+                new TreeMap<Revision, String>(StableRevisionComparator.INSTANCE);
         for (Map.Entry<Revision, String> entry : doc.getLocalRevisions().entrySet()) {
             if (splitRevs.contains(entry.getKey())) {
                 revisions.put(entry.getKey(), entry.getValue());
@@ -232,7 +230,7 @@ class SplitOperations {
         }
         committedChanges.put(REVISIONS, revisions);
         NavigableMap<Revision, String> commitRoot =
-                new TreeMap<Revision, String>(context.getRevisionComparator());
+                new TreeMap<Revision, String>(StableRevisionComparator.INSTANCE);
         boolean mostRecent = true;
         for (Map.Entry<Revision, String> entry : doc.getLocalCommitRoot().entrySet()) {
             Revision r = entry.getKey();
@@ -269,10 +267,10 @@ class SplitOperations {
                 Revision h = null;
                 Revision l = null;
                 for (Range r : entry.getValue()) {
-                    if (h == null || isRevisionNewer(context, r.high, h)) {
+                    if (h == null || r.high.compareRevisionTime(h) > 0) {
                         h = r.high;
                     }
-                    if (l == null || isRevisionNewer(context, l, r.low)) {
+                    if (l == null || l.compareRevisionTime(r.low) > 0) {
                         l = r.low;
                     }
                     removePrevious(main, r);
@@ -391,7 +389,7 @@ class SplitOperations {
             Set<Revision> changes) {
         for (String property : filter(doc.keySet(), PROPERTY_OR_DELETED)) {
             NavigableMap<Revision, String> splitMap
-                    = new TreeMap<Revision, String>(context.getRevisionComparator());
+                    = new TreeMap<Revision, String>(StableRevisionComparator.INSTANCE);
             committedLocally.put(property, splitMap);
             Map<Revision, String> valueMap = doc.getLocalMap(property);
             // collect committed changes of this cluster node
@@ -411,10 +409,9 @@ class SplitOperations {
     }
     
     private boolean isGarbage(Revision rev) {
-        Comparator<Revision> comp = context.getRevisionComparator();
         // use headRevision as passed in the constructor instead
         // of the head revision from the RevisionContext. see OAK-3081
-        if (comp.compare(headRevision, rev) <= 0) {
+        if (headRevision.compareRevisionTime(rev) <= 0) {
             // this may be an in-progress commit
             return false;
         }
@@ -489,13 +486,13 @@ class SplitOperations {
     }
 
     private void trackHigh(Revision r) {
-        if (high == null || isRevisionNewer(context, r, high)) {
+        if (high == null || r.compareRevisionTime(high) > 0) {
             high = r;
         }
     }
 
     private void trackLow(Revision r) {
-        if (low == null || isRevisionNewer(context, low, r)) {
+        if (low == null || low.compareRevisionTime(r) > 0) {
             low = r;
         }
     }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/StableRevisionComparator.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/StableRevisionComparator.java
index 89c0f7f1a6..efe7dd7914 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/StableRevisionComparator.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/StableRevisionComparator.java
@@ -22,9 +22,7 @@ import java.util.Comparator;
 /**
  * <code>StableRevisionComparator</code> implements a revision comparator, which
  * is only based on stable information available in the two revisions presented
- * to this comparator. This is different from {@link Revision.RevisionComparator},
- * which also takes the time into account when a foreign revision (from another
- * cluster nodes) was first seen. This class is used in sorted collections where
+ * to this comparator. This class is used in sorted collections where
  * revision keys must have a stable ordering independent from the time when
  * a revision was seen.
  * <p>
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/TieredDiffCache.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/TieredDiffCache.java
index ff23891f81..19f695189f 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/TieredDiffCache.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/TieredDiffCache.java
@@ -38,8 +38,8 @@ class TieredDiffCache extends DiffCache {
     }
 
     @Override
-    public String getChanges(@Nonnull Revision from,
-                             @Nonnull Revision to,
+    public String getChanges(@Nonnull RevisionVector from,
+                             @Nonnull RevisionVector to,
                              @Nonnull String path,
                              @Nullable Loader loader) {
         // check local first without loader
@@ -60,7 +60,7 @@ class TieredDiffCache extends DiffCache {
      */
     @Nonnull
     @Override
-    public Entry newEntry(@Nonnull Revision from, @Nonnull Revision to, boolean local) {
+    public Entry newEntry(@Nonnull RevisionVector from, @Nonnull RevisionVector to, boolean local) {
         if (local) {
             return localCache.newEntry(from, to, true);
         } else {
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranches.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranches.java
index 1464b596da..8643ce8af0 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranches.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranches.java
@@ -17,7 +17,6 @@
 package org.apache.jackrabbit.oak.plugins.document;
 
 import java.lang.ref.ReferenceQueue;
-import java.util.Comparator;
 import java.util.List;
 import java.util.SortedSet;
 import java.util.TreeSet;
@@ -63,15 +62,6 @@ class UnmergedBranches {
      */
     private final AtomicBoolean initialized = new AtomicBoolean(false);
 
-    /**
-     * The revision comparator.
-     */
-    private final Comparator<Revision> comparator;
-
-    UnmergedBranches(@Nonnull Comparator<Revision> comparator) {
-        this.comparator = checkNotNull(comparator);
-    }
-
     /**
      * Initialize with un-merged branches from <code>store</code> for this
      * <code>clusterId</code>.
@@ -112,14 +102,14 @@ class UnmergedBranches {
      *          or {@code initial} is not a branch revision.
      */
     @Nonnull
-    Branch create(@Nonnull Revision base,
+    Branch create(@Nonnull RevisionVector base,
                   @Nonnull Revision initial,
                   @Nullable Object guard) {
         checkArgument(!checkNotNull(base).isBranch(),
                 "base is not a trunk revision: %s", base);
         checkArgument(checkNotNull(initial).isBranch(),
                 "initial is not a branch revision: %s", initial);
-        SortedSet<Revision> commits = new TreeSet<Revision>(comparator);
+        SortedSet<Revision> commits = new TreeSet<Revision>(StableRevisionComparator.INSTANCE);
         commits.add(initial);
         Branch b = new Branch(commits, base, queue, guard);
         branches.add(b);
@@ -134,9 +124,13 @@ class UnmergedBranches {
      * @return the branch containing the given revision or <code>null</code>.
      */
     @CheckForNull
-    Branch getBranch(@Nonnull Revision r) {
+    Branch getBranch(@Nonnull RevisionVector r) {
+        if (!r.isBranch()) {
+            return null;
+        }
+        Revision branchRev = r.getBranchRevision();
         for (Branch b : branches) {
-            if (b.containsCommit(r)) {
+            if (b.containsCommit(branchRev)) {
                 return b;
             }
         }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/VersionGarbageCollector.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/VersionGarbageCollector.java
index 39dbd317a4..54321409b3 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/VersionGarbageCollector.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/VersionGarbageCollector.java
@@ -85,7 +85,7 @@ public class VersionGarbageCollector {
         Stopwatch sw = Stopwatch.createStarted();
         VersionGCStats stats = new VersionGCStats();
         final long oldestRevTimeStamp = nodeStore.getClock().getTime() - maxRevisionAgeInMillis;
-        final Revision headRevision = nodeStore.getHeadRevision();
+        final RevisionVector headRevision = nodeStore.getHeadRevision();
 
         log.info("Starting revision garbage collection. Revisions older than [{}] will be " +
                 "removed", Utils.timestampToString(oldestRevTimeStamp));
@@ -121,7 +121,7 @@ public class VersionGarbageCollector {
     }
 
     private void collectDeletedDocuments(VersionGCStats stats,
-                                         Revision headRevision,
+                                         RevisionVector headRevision,
                                          long oldestRevTimeStamp)
             throws IOException {
         int docsTraversed = 0;
@@ -190,13 +190,13 @@ public class VersionGarbageCollector {
      */
     private class DeletedDocsGC implements Closeable {
 
-        private final Revision headRevision;
+        private final RevisionVector headRevision;
         private final StringSort docIdsToDelete = newStringSort();
         private final StringSort prevDocIdsToDelete = newStringSort();
         private final Set<String> exclude = Sets.newHashSet();
         private boolean sorted = false;
 
-        public DeletedDocsGC(@Nonnull Revision headRevision) {
+        public DeletedDocsGC(@Nonnull RevisionVector headRevision) {
             this.headRevision = checkNotNull(headRevision);
         }
 
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/RevisionsKey.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/RevisionsKey.java
index 25394c30f3..4aece63334 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/RevisionsKey.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/RevisionsKey.java
@@ -20,7 +20,7 @@ import javax.annotation.Nonnull;
 
 import org.apache.jackrabbit.oak.cache.CacheValue;
 import org.apache.jackrabbit.oak.plugins.document.Revision;
-import org.apache.jackrabbit.oak.plugins.document.StableRevisionComparator;
+import org.apache.jackrabbit.oak.plugins.document.RevisionVector;
 
 import static com.google.common.base.Preconditions.checkNotNull;
 
@@ -29,16 +29,16 @@ import static com.google.common.base.Preconditions.checkNotNull;
  */
 public final class RevisionsKey implements CacheValue, Comparable<RevisionsKey> {
 
-    private final Revision r1, r2;
+    private final RevisionVector r1, r2;
 
-    public RevisionsKey(Revision r1, Revision r2) {
+    public RevisionsKey(RevisionVector r1, RevisionVector r2) {
         this.r1 = checkNotNull(r1);
         this.r2 = checkNotNull(r2);
     }
 
     @Override
     public int getMemory() {
-        return 88;
+        return 32 + r1.getMemory() + r2.getMemory();
     }
 
     @Override
@@ -65,11 +65,11 @@ public final class RevisionsKey implements CacheValue, Comparable<RevisionsKey>
     }
 
     public int compareTo(@Nonnull RevisionsKey k) {
-        int c = StableRevisionComparator.INSTANCE.compare(r1, k.r1);
+        int c = r1.compareTo(k.r1);
         if (c != 0) {
             return c;
         }
-        return StableRevisionComparator.INSTANCE.compare(r2, k.r2);
+        return r2.compareTo(k.r2);
     }
 
     public static RevisionsKey fromString(String s) {
@@ -78,7 +78,7 @@ public final class RevisionsKey implements CacheValue, Comparable<RevisionsKey>
             throw new IllegalArgumentException(s);
         }
         return new RevisionsKey(
-                Revision.fromString(s.substring(0, idx)),
-                Revision.fromString(s.substring(idx + 1)));
+                RevisionVector.fromString(s.substring(0, idx)),
+                RevisionVector.fromString(s.substring(idx + 1)));
     }
 }
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/Utils.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/Utils.java
index 45cdd100de..6c5a8948d1 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/Utils.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/Utils.java
@@ -46,7 +46,7 @@ import org.apache.jackrabbit.oak.plugins.document.Collection;
 import org.apache.jackrabbit.oak.plugins.document.DocumentStore;
 import org.apache.jackrabbit.oak.plugins.document.NodeDocument;
 import org.apache.jackrabbit.oak.plugins.document.Revision;
-import org.apache.jackrabbit.oak.plugins.document.RevisionContext;
+import org.apache.jackrabbit.oak.plugins.document.RevisionVector;
 import org.apache.jackrabbit.oak.plugins.document.StableRevisionComparator;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -466,19 +466,6 @@ public class Utils {
         return (new Timestamp(timestamp) + "00").substring(0, 23);
     }
 
-    /**
-     * Checks that revision x is newer than another revision.
-     *
-     * @param x the revision to check
-     * @param previous the presumed earlier revision
-     * @return true if x is newer
-     */
-    public static boolean isRevisionNewer(@Nonnull RevisionContext context,
-                                          @Nonnull Revision x,
-                                          @Nonnull Revision previous) {
-        return context.getRevisionComparator().compare(x, previous) > 0;
-    }
-
     /**
      * Returns the revision with the newer timestamp or {@code null} if both
      * revisions are {@code null}. The implementation will return the first
@@ -516,6 +503,43 @@ public class Utils {
         return c.compare(a, b) >= 0 ? a : b;
     }
 
+    /**
+     * Returns the revision with the older timestamp or {@code null} if both
+     * revisions are {@code null}. The implementation will return the first
+     * revision if both have the same timestamp.
+     *
+     * @param a the first revision (or {@code null}).
+     * @param b the second revision (or {@code null}).
+     * @return the revision with the older timestamp.
+     */
+    @CheckForNull
+    public static Revision min(@Nullable Revision a, @Nullable Revision b) {
+        return min(a, b, StableRevisionComparator.INSTANCE);
+    }
+
+    /**
+     * Returns the revision which is considered older or {@code null} if
+     * both revisions are {@code null}. The implementation will return the first
+     * revision if both are considered equal. The comparison is done using the
+     * provided comparator.
+     *
+     * @param a the first revision (or {@code null}).
+     * @param b the second revision (or {@code null}).
+     * @param c the comparator.
+     * @return the revision considered more recent.
+     */
+    @CheckForNull
+    public static Revision min(@Nullable Revision a,
+                               @Nullable Revision b,
+                               @Nonnull Comparator<Revision> c) {
+        if (a == null) {
+            return b;
+        } else if (b == null) {
+            return a;
+        }
+        return c.compare(a, b) <= 0 ? a : b;
+    }
+
     /**
      * Returns an {@link Iterable} over all {@link NodeDocument}s in the given
      * store. The returned {@linkplain Iterable} does not guarantee a consistent
@@ -686,4 +710,34 @@ public class Utils {
             return n.longValue();
         }
     }
+
+    /**
+     * Returns the minimum timestamp to use for a query for child documents that
+     * have been modified between {@code fromRev} and {@code toRev}.
+     *
+     * @param fromRev the from revision.
+     * @param toRev the to revision.
+     * @param minRevisions the minimum revisions of foreign cluster nodes. These
+     *                     are derived from the startTime of a cluster node.
+     * @return the minimum timestamp.
+     */
+    public static long getMinTimestampForDiff(@Nonnull RevisionVector fromRev,
+                                              @Nonnull RevisionVector toRev,
+                                              @Nonnull RevisionVector minRevisions) {
+        // make sure we have minimum revisions for all known cluster nodes
+        fromRev = fromRev.pmax(minRevisions);
+        toRev = toRev.pmax(minRevisions);
+        // keep only revision entries that changed
+        RevisionVector from = fromRev.difference(toRev);
+        RevisionVector to = toRev.difference(fromRev);
+        // now calculate minimum timestamp
+        long min = Long.MAX_VALUE;
+        for (Revision r : from) {
+            min = Math.min(r.getTimestamp(), min);
+        }
+        for (Revision r : to) {
+            min = Math.min(r.getTimestamp(), min);
+        }
+        return min;
+    }
 }
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/AmnesiaDiffCache.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/AmnesiaDiffCache.java
index f9606eb68b..0aff8a4de5 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/AmnesiaDiffCache.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/AmnesiaDiffCache.java
@@ -35,8 +35,8 @@ class AmnesiaDiffCache extends DiffCache {
     }
 
     @Override
-    public String getChanges(@Nonnull Revision from,
-                             @Nonnull Revision to,
+    public String getChanges(@Nonnull RevisionVector from,
+                             @Nonnull RevisionVector to,
                              @Nonnull String path,
                              @Nullable Loader loader) {
         if (loader != null) {
@@ -47,7 +47,7 @@ class AmnesiaDiffCache extends DiffCache {
 
     @Nonnull
     @Override
-    public Entry newEntry(@Nonnull Revision from, @Nonnull Revision to, boolean local) {
+    public Entry newEntry(@Nonnull RevisionVector from, @Nonnull RevisionVector to, boolean local) {
         return new Entry() {
             @Override
             public void append(@Nonnull String path, @Nonnull String changes) {
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/BranchTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/BranchTest.java
index f85d22e784..b538d1801e 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/BranchTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/BranchTest.java
@@ -28,9 +28,9 @@ public class BranchTest {
 
     @Test
     public void getModifiedPathsUntil() {
-        UnmergedBranches branches = new UnmergedBranches(StableRevisionComparator.INSTANCE);
+        UnmergedBranches branches = new UnmergedBranches();
 
-        Revision base = Revision.newRevision(1);
+        RevisionVector base = new RevisionVector(Revision.newRevision(1));
         Revision c1 = Revision.newRevision(1).asBranchRevision();
         Branch b = branches.create(base, c1, null);
 
@@ -43,7 +43,7 @@ public class BranchTest {
         bc2.track("/bar");
 
         Revision c3 = Revision.newRevision(1).asBranchRevision();
-        b.rebase(c3, Revision.newRevision(1));
+        b.rebase(c3, new RevisionVector(Revision.newRevision(1)));
 
         Revision c4 = Revision.newRevision(1).asBranchRevision();
         b.addCommit(c4);
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CheckpointsTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CheckpointsTest.java
index fe4302ac8d..75f7b24c3e 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CheckpointsTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CheckpointsTest.java
@@ -22,9 +22,11 @@ import java.util.Collections;
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
 
+import org.apache.jackrabbit.oak.plugins.document.memory.MemoryDocumentStore;
 import org.apache.jackrabbit.oak.spi.commit.CommitInfo;
 import org.apache.jackrabbit.oak.spi.commit.EmptyHook;
 import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
+import org.apache.jackrabbit.oak.spi.state.NodeState;
 import org.apache.jackrabbit.oak.stats.Clock;
 import org.junit.Before;
 import org.junit.Rule;
@@ -33,6 +35,7 @@ import org.junit.Test;
 import com.google.common.collect.ImmutableMap;
 
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNotSame;
 import static org.junit.Assert.assertNull;
@@ -70,7 +73,7 @@ public class CheckpointsTest {
         Revision r1 = null;
         for(int i = 0; i < Checkpoints.CLEANUP_INTERVAL; i++){
             r1 = Revision.fromString(store.checkpoint(expiryTime));
-            store.setHeadRevision(Revision.newRevision(0));
+            store.setRoot(new RevisionVector(Revision.newRevision(store.getClusterId())));
         }
         assertEquals(r1, store.getCheckpoints().getOldestRevisionToKeep());
         assertEquals(Checkpoints.CLEANUP_INTERVAL, store.getCheckpoints().size());
@@ -204,4 +207,148 @@ public class CheckpointsTest {
         assertNotNull(info);
         assertEquals(props, info);
     }
+
+    @Test
+    public void parseInfo() {
+        long expires = System.currentTimeMillis();
+        // initial 1.0 format: only expiry time
+        Checkpoints.Info info = Checkpoints.Info.fromString(String.valueOf(expires));
+        assertEquals(expires, info.getExpiryTime());
+        // 1.2 format: json with expiry and info map
+        String infoString = "{\"expires\":\"" + expires + "\",\"foo\":\"bar\"}";
+        info = Checkpoints.Info.fromString(infoString);
+        assertEquals(expires, info.getExpiryTime());
+        assertEquals(Collections.singleton("foo"), info.get().keySet());
+        assertEquals("bar", info.get().get("foo"));
+        // 1.4 format: json with expiry, revision vector and info map
+        Revision r1 = new Revision(1, 0, 1);
+        Revision r2 = new Revision(1, 0, 2);
+        RevisionVector rv = new RevisionVector(r1, r2);
+        infoString = "{\"expires\":\"" + expires +
+                "\",\"rv\":\"" + rv.toString() +
+                "\",\"foo\":\"bar\"}";
+        info = Checkpoints.Info.fromString(infoString);
+        assertEquals(expires, info.getExpiryTime());
+        assertEquals(Collections.singleton("foo"), info.get().keySet());
+        assertEquals("bar", info.get().get("foo"));
+        assertEquals(rv, info.getCheckpoint());
+        assertEquals(infoString, info.toString());
+    }
+
+    @Test
+    public void crossClusterNodeCheckpoint() throws Exception {
+        // use an async delay to ensure DocumentNodeStore.suspendUntil() works
+        // but set it to a high value and control background ops manually in
+        // this test
+        final int asyncDelay = (int) TimeUnit.MINUTES.toMillis(1);
+        DocumentStore store = new MemoryDocumentStore();
+        final DocumentNodeStore ns1 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(asyncDelay).getNodeStore();
+        final DocumentNodeStore ns2 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(asyncDelay).getNodeStore();
+
+        // create node on ns1
+        NodeBuilder builder = ns1.getRoot().builder();
+        builder.child("foo");
+        ns1.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
+        // make visible on ns2
+        ns1.runBackgroundOperations();
+        ns2.runBackgroundOperations();
+        // create checkpoint on ns1
+        String cp1 = ns1.checkpoint(Long.MAX_VALUE);
+        // retrieve checkpoint on ns2
+        NodeState root = ns2.retrieve(cp1);
+        assertNotNull(root);
+        assertTrue(root.hasChildNode("foo"));
+        ns2.release(cp1);
+
+        // create node on ns1
+        builder = ns1.getRoot().builder();
+        builder.child("bar");
+        ns1.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
+        // create checkpoint when 'bar' is not yet visible to ns2
+        final String cp2 = ns1.checkpoint(Long.MAX_VALUE);
+        // retrieve checkpoint on ns2
+        final NodeState state[] = new NodeState[1];
+        Thread t = new Thread(new Runnable() {
+            @Override
+            public void run() {
+                state[0] = ns2.retrieve(cp2);
+            }
+        });
+        t.start();
+        ns1.runBackgroundOperations();
+        ns2.runBackgroundOperations();
+        t.join();
+        assertNotNull(state[0]);
+        assertTrue(state[0].hasChildNode("bar"));
+    }
+
+    @Test
+    public void crossClusterCheckpointNewClusterNode() throws Exception {
+        DocumentStore store = new MemoryDocumentStore();
+        DocumentNodeStore ns1 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(0).getNodeStore();
+
+        // create 'foo' on ns1
+        NodeBuilder b1 = ns1.getRoot().builder();
+        b1.child("foo");
+        ns1.merge(b1, EmptyHook.INSTANCE, CommitInfo.EMPTY);
+
+        // checkpoint sees 'foo' but not 'bar'
+        String checkpoint = ns1.checkpoint(Long.MAX_VALUE);
+
+        // create 'bar' on ns1
+        b1 = ns1.getRoot().builder();
+        b1.child("bar");
+        ns1.merge(b1, EmptyHook.INSTANCE, CommitInfo.EMPTY);
+
+        // make visible
+        ns1.runBackgroundOperations();
+
+        // now start second node store
+        DocumentNodeStore ns2 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(0).getNodeStore();
+        NodeBuilder b2 = ns2.getRoot().builder();
+        b2.child("baz");
+        ns2.merge(b2, EmptyHook.INSTANCE, CommitInfo.EMPTY);
+
+        NodeState root = ns2.retrieve(checkpoint);
+        assertNotNull(root);
+        assertTrue(root.hasChildNode("foo"));
+        assertFalse(root.hasChildNode("bar"));
+        assertFalse(root.hasChildNode("baz"));
+    }
+
+    @Test
+    public void crossClusterReadOldCheckpoint() throws Exception {
+        DocumentStore store = new MemoryDocumentStore();
+        DocumentNodeStore ns1 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(0).getNodeStore();
+
+        NodeBuilder b1 = ns1.getRoot().builder();
+        b1.child("foo");
+        ns1.merge(b1, EmptyHook.INSTANCE, CommitInfo.EMPTY);
+        ns1.runBackgroundOperations();
+
+        // manually create a check point in 1.2 format
+        Revision headRev = Revision.fromString(ns1.getHeadRevision().toString());
+        long expires = Long.MAX_VALUE;
+        String data = "{\"expires\":\"" + expires + "\"}";
+        UpdateOp update = new UpdateOp("checkpoint", false);
+        update.setMapEntry("data", headRev, data);
+        store.createOrUpdate(Collection.SETTINGS, update);
+
+        // now start second node store
+        DocumentNodeStore ns2 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(0).getNodeStore();
+        NodeBuilder b2 = ns2.getRoot().builder();
+        b2.child("baz");
+        ns2.merge(b2, EmptyHook.INSTANCE, CommitInfo.EMPTY);
+
+        NodeState root = ns2.retrieve(headRev.toString());
+        assertNotNull(root);
+        assertTrue(root.hasChildNode("foo"));
+        assertFalse(root.hasChildNode("baz"));
+    }
 }
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterRevisionComparisonTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterRevisionComparisonTest.java
index ea0aa890f7..42246ec27f 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterRevisionComparisonTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterRevisionComparisonTest.java
@@ -92,8 +92,6 @@ public class ClusterRevisionComparisonTest {
         c1.invalidateNodeCache("/a/c2" , ((DocumentNodeState)c1ns1.getChildNode("a")).getLastRevision());
         c1.invalidateNodeCache("/a/c3" , ((DocumentNodeState)c1ns1.getChildNode("a")).getLastRevision());
 
-        //Revision comparator purge by moving in future
-        clock.waitUntil(clock.getTime() + DocumentNodeStore.REMEMBER_REVISION_ORDER_MILLIS * 2);
         runBgOps(c1);
 
         NodeState a = c1ns1.getChildNode("a");
@@ -139,8 +137,6 @@ public class ClusterRevisionComparisonTest {
         c1.invalidateNodeCache("/a/c1" , ((DocumentNodeState)a).getLastRevision());
         c1.invalidateNodeCache("/a/c2" , ((DocumentNodeState)a).getLastRevision());
 
-        //Revision comparator purge by moving in future
-        clock.waitUntil(clock.getTime() + DocumentNodeStore.REMEMBER_REVISION_ORDER_MILLIS * 2);
         runBgOps(c1);
 
         assertTrue("/a/c1 disappeared", a.hasChildNode("c1"));
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterTest.java
index 89489fd380..776c15f2a0 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterTest.java
@@ -216,9 +216,9 @@ public class ClusterTest {
 
         mk3.runBackgroundOperations(); // pick up changes from mk2
 
-        DocumentNodeState base = ns3.getNode("/", Revision.fromString(base3));
+        DocumentNodeState base = ns3.getNode("/", RevisionVector.fromString(base3));
         assertNotNull(base);
-        NodeState branchHead = ns3.getNode("/", Revision.fromString(b3));
+        NodeState branchHead = ns3.getNode("/", RevisionVector.fromString(b3));
         assertNotNull(branchHead);
         TrackingDiff diff = new TrackingDiff();
         branchHead.compareAgainstBaseState(base, diff);
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CommitQueueTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CommitQueueTest.java
index 254b20cf51..3cb2d15480 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CommitQueueTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CommitQueueTest.java
@@ -68,14 +68,15 @@ public class CommitQueueTest {
         AtomicBoolean running = new AtomicBoolean(true);
 
         Closeable observer = store.addObserver(new Observer() {
-            private Revision before = new Revision(0, 0, store.getClusterId());
+            private RevisionVector before = new RevisionVector(
+                    new Revision(0, 0, store.getClusterId()));
 
             @Override
             public void contentChanged(@Nonnull NodeState root, @Nullable CommitInfo info) {
                 DocumentNodeState after = (DocumentNodeState) root;
-                Revision r = after.getRevision();
+                RevisionVector r = after.getRevision();
                 LOG.debug("seen: {}", r);
-                if (r.compareRevisionTime(before) < 0) {
+                if (r.compareTo(before) < 0) {
                     exceptions.add(new Exception(
                             "Inconsistent revision sequence. Before: " +
                                     before + ", after: " + r));
@@ -187,7 +188,7 @@ public class CommitQueueTest {
         final DocumentNodeStore ds = builderProvider.newBuilder().getNodeStore();
 
         // simulate start of a branch commit
-        Commit c = ds.newCommit(ds.getHeadRevision().asBranchRevision(), null);
+        Commit c = ds.newCommit(ds.getHeadRevision().asBranchRevision(ds.getClusterId()), null);
 
         Thread t = new Thread(new Runnable() {
             @Override
@@ -212,16 +213,15 @@ public class CommitQueueTest {
 
     @Test
     public void suspendUntil() throws Exception {
-        final AtomicReference<Revision> headRevision = new AtomicReference<Revision>();
+        final AtomicReference<RevisionVector> headRevision = new AtomicReference<RevisionVector>();
         RevisionContext context = new DummyRevisionContext() {
             @Nonnull
             @Override
-            public Revision getHeadRevision() {
+            public RevisionVector getHeadRevision() {
                 return headRevision.get();
             }
         };
-        headRevision.set(context.newRevision());
-
+        headRevision.set(new RevisionVector(context.newRevision()));
         final CommitQueue queue = new CommitQueue(context);
 
         final Revision newHeadRev = context.newRevision();
@@ -247,7 +247,7 @@ public class CommitQueueTest {
         // must still be suspended
         assertEquals(1, queue.numSuspendedThreads());
 
-        headRevision.set(newHeadRev);
+        headRevision.set(new RevisionVector(newHeadRev));
         queue.headRevisionChanged();
         // must still be suspended
         assertEquals(1, queue.numSuspendedThreads());
@@ -261,15 +261,15 @@ public class CommitQueueTest {
 
     @Test
     public void suspendUntilTimeout() throws Exception {
-        final AtomicReference<Revision> headRevision = new AtomicReference<Revision>();
+        final AtomicReference<RevisionVector> headRevision = new AtomicReference<RevisionVector>();
         RevisionContext context = new DummyRevisionContext() {
             @Nonnull
             @Override
-            public Revision getHeadRevision() {
+            public RevisionVector getHeadRevision() {
                 return headRevision.get();
             }
         };
-        headRevision.set(context.newRevision());
+        headRevision.set(new RevisionVector(context.newRevision()));
         final CommitQueue queue = new CommitQueue(context);
         queue.setSuspendTimeoutMillis(0);
 
@@ -288,15 +288,15 @@ public class CommitQueueTest {
 
     @Test
     public void concurrentSuspendUntil() throws Exception {
-        final AtomicReference<Revision> headRevision = new AtomicReference<Revision>();
+        final AtomicReference<RevisionVector> headRevision = new AtomicReference<RevisionVector>();
         RevisionContext context = new DummyRevisionContext() {
             @Nonnull
             @Override
-            public Revision getHeadRevision() {
+            public RevisionVector getHeadRevision() {
                 return headRevision.get();
             }
         };
-        headRevision.set(context.newRevision());
+        headRevision.set(new RevisionVector(context.newRevision()));
 
         List<Thread> threads = new ArrayList<Thread>();
         List<Revision> allRevisions = new ArrayList<Revision>();
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CommitTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CommitTest.java
index 107bc98a7c..f6ee15887c 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CommitTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CommitTest.java
@@ -57,7 +57,8 @@ public class CommitTest {
         // this commit should fail
         Commit c = ns.newCommit(ns.getHeadRevision(), null);
         try {
-            c.addNode(new DocumentNodeState(ns, "/foo/baz", c.getRevision()));
+            c.addNode(new DocumentNodeState(ns, "/foo/baz",
+                    new RevisionVector(c.getRevision())));
             UpdateOp op = c.getUpdateOperationForNode("/bar");
             op.setMapEntry("p", c.getRevision(), "v");
             try {
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CountingTieredDiffCache.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CountingTieredDiffCache.java
index d7c01702ca..1370cfc5aa 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CountingTieredDiffCache.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/CountingTieredDiffCache.java
@@ -56,8 +56,8 @@ public class CountingTieredDiffCache extends TieredDiffCache {
     }
 
     @Override
-    public String getChanges(@Nonnull Revision from,
-                             @Nonnull Revision to,
+    public String getChanges(@Nonnull RevisionVector from,
+                             @Nonnull RevisionVector to,
                              @Nonnull String path,
                              @Nullable Loader loader) {
         return super.getChanges(from, to, path, new CountingLoader(loader));
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStateTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStateTest.java
new file mode 100644
index 0000000000..0517f0a4a8
--- /dev/null
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStateTest.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.plugins.document;
+
+import org.junit.Rule;
+import org.junit.Test;
+
+import static org.junit.Assert.assertEquals;
+
+public class DocumentNodeStateTest {
+
+    @Rule
+    public DocumentMKBuilderProvider builderProvider = new DocumentMKBuilderProvider();
+
+    @Test
+    public void getMemory() {
+        DocumentNodeStore store = builderProvider.newBuilder().getNodeStore();
+        RevisionVector rv = new RevisionVector(Revision.newRevision(1));
+        DocumentNodeState state = new DocumentNodeState(store, "/foo", rv);
+        assertEquals(232, state.getMemory());
+    }
+}
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreTest.java
index 334fd9bb8a..e8661ae252 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreTest.java
@@ -19,7 +19,6 @@ package org.apache.jackrabbit.oak.plugins.document;
 import static java.util.concurrent.TimeUnit.SECONDS;
 import static org.apache.jackrabbit.oak.api.CommitFailedException.CONSTRAINT;
 import static org.apache.jackrabbit.oak.plugins.document.Collection.NODES;
-import static org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.REMEMBER_REVISION_ORDER_MILLIS;
 import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.MODIFIED_IN_SECS;
 import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.MODIFIED_IN_SECS_RESOLUTION;
 import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.NUM_REVS_THRESHOLD;
@@ -99,7 +98,6 @@ import org.apache.jackrabbit.oak.spi.state.NodeState;
 import org.apache.jackrabbit.oak.spi.state.NodeStore;
 import org.apache.jackrabbit.oak.stats.Clock;
 import org.junit.After;
-import org.junit.Ignore;
 import org.junit.Rule;
 import org.junit.Test;
 import org.slf4j.Logger;
@@ -266,7 +264,7 @@ public class DocumentNodeStoreTest {
         builder.child("deletedNode").remove();
         merge(store, builder);
 
-        final Revision head = store.getHeadRevision();
+        final RevisionVector head = store.getHeadRevision();
 
         Thread writer = new Thread(new Runnable() {
             @Override
@@ -274,8 +272,8 @@ public class DocumentNodeStoreTest {
                 try {
                     Revision r = store.newRevision();
                     Commit c = new Commit(store, r, head, null);
-                    c.addNode(new DocumentNodeState(store, "/newConflictingNode", r));
-                    c.addNode(new DocumentNodeState(store, "/deletedNode", r));
+                    c.addNode(new DocumentNodeState(store, "/newConflictingNode", new RevisionVector(r)));
+                    c.addNode(new DocumentNodeState(store, "/deletedNode", new RevisionVector(r)));
                     c.updateProperty("/updateNode", "foo", "baz");
                     c.apply();
                 } catch (DocumentStoreException e) {
@@ -292,8 +290,8 @@ public class DocumentNodeStoreTest {
         // commit will succeed and add collision marker to writer commit
         Revision r = store.newRevision();
         Commit c = new Commit(store, r, head, null);
-        c.addNode(new DocumentNodeState(store, "/newConflictingNode", r));
-        c.addNode(new DocumentNodeState(store, "/newNonConflictingNode", r));
+        c.addNode(new DocumentNodeState(store, "/newConflictingNode", new RevisionVector(r)));
+        c.addNode(new DocumentNodeState(store, "/newNonConflictingNode", new RevisionVector(r)));
         c.apply();
         // allow writer to continue
         s.release();
@@ -356,7 +354,7 @@ public class DocumentNodeStoreTest {
                 .setDocumentStore(docStore).setAsyncDelay(0)
                 .setClusterId(1).getNodeStore();
         ns1.getRoot();
-        Revision r1 = ns1.getHeadRevision();
+        Revision r1 = ns1.getHeadRevision().getRevision(ns1.getClusterId());
         ns1.runBackgroundOperations();
         DocumentNodeStore ns2 = builderProvider.newBuilder()
                 .setDocumentStore(docStore).setAsyncDelay(0)
@@ -434,48 +432,6 @@ public class DocumentNodeStoreTest {
         }
     }
 
-    // OAK-1814
-    @Test
-    public void visibilityAfterRevisionComparatorPurge() throws Exception {
-        Clock clock = new Clock.Virtual();
-        clock.waitUntil(System.currentTimeMillis());
-        Revision.setClock(clock);
-        MemoryDocumentStore docStore = new MemoryDocumentStore();
-        DocumentNodeStore nodeStore1 = builderProvider.newBuilder()
-                .setDocumentStore(docStore).setClusterId(1)
-                .setAsyncDelay(0).clock(clock).getNodeStore();
-        nodeStore1.runBackgroundOperations();
-        DocumentNodeStore nodeStore2 = builderProvider.newBuilder()
-                .setDocumentStore(docStore).setClusterId(2)
-                .setAsyncDelay(0).clock(clock).getNodeStore();
-        DocumentNodeStore nodeStore3 = builderProvider.newBuilder()
-                .setDocumentStore(docStore).setClusterId(3)
-                .setAsyncDelay(0).clock(clock).getNodeStore();
-
-        NodeDocument doc = docStore.find(NODES, Utils.getIdFromPath("/"));
-        assertNotNull(doc);
-        Revision created = doc.getLocalDeleted().firstKey();
-        assertEquals(1, created.getClusterId());
-
-        clock.waitUntil(System.currentTimeMillis() +
-                REMEMBER_REVISION_ORDER_MILLIS / 2);
-
-        NodeBuilder builder = nodeStore2.getRoot().builder();
-        builder.setProperty("prop", "value");
-        nodeStore2.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
-        nodeStore2.runBackgroundOperations();
-
-        clock.waitUntil(System.currentTimeMillis() +
-                REMEMBER_REVISION_ORDER_MILLIS + 1000);
-        nodeStore3.runBackgroundOperations();
-
-        doc = docStore.find(NODES, Utils.getIdFromPath("/"));
-        assertNotNull(doc);
-        NodeState state = doc.getNodeAtRevision(nodeStore3,
-                nodeStore3.getHeadRevision(), null);
-        assertNotNull(state);
-    }
-
     @Test
     public void modifiedReset() throws Exception {
         Clock clock = new Clock.Virtual();
@@ -580,7 +536,7 @@ public class DocumentNodeStoreTest {
         builder.child("test").setProperty("prop", "value");
         ns.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
 
-        Revision rev = ns.getHeadRevision();
+        RevisionVector rev = ns.getHeadRevision();
         NodeDocument doc = docStore.find(NODES, Utils.getIdFromPath("/test"));
         assertNotNull(doc);
         DocumentNodeState state = doc.getNodeAtRevision(ns, rev, null);
@@ -677,28 +633,30 @@ public class DocumentNodeStoreTest {
         DocumentNodeStore ns1 = builderProvider.newBuilder().setAsyncDelay(0)
                 .setClusterId(1).setDocumentStore(docStore)
                 .getNodeStore();
+        int cId1 = ns1.getClusterId();
         DocumentNodeStore ns2 = builderProvider.newBuilder().setAsyncDelay(0)
                 .setClusterId(2).setDocumentStore(docStore)
                 .getNodeStore();
+        int cId2 = ns2.getClusterId();
 
         ns1.updateClusterState();
         ns2.updateClusterState();
 
-        assertEquals(0, ns1.getInactiveClusterNodes().size());
-        assertEquals(0, ns2.getInactiveClusterNodes().size());
-        assertEquals(2, ns1.getActiveClusterNodes().size());
-        assertEquals(2, ns2.getActiveClusterNodes().size());
+        assertEquals(0, ns1.getMBean().getInactiveClusterNodes().length);
+        assertEquals(0, ns2.getMBean().getInactiveClusterNodes().length);
+        assertEquals(2, ns1.getMBean().getActiveClusterNodes().length);
+        assertEquals(2, ns2.getMBean().getActiveClusterNodes().length);
 
         ns1.dispose();
 
         ns2.updateClusterState();
 
-        Map<Integer, Long> inactive = ns2.getInactiveClusterNodes();
-        Map<Integer, Long> active = ns2.getActiveClusterNodes();
-        assertEquals(1, inactive.size());
-        assertEquals(1, (int) inactive.keySet().iterator().next());
-        assertEquals(1, active.size());
-        assertEquals(2, (int) active.keySet().iterator().next());
+        String[] inactive = ns2.getMBean().getInactiveClusterNodes();
+        String[] active = ns2.getMBean().getActiveClusterNodes();
+        assertEquals(1, inactive.length);
+        assertTrue(inactive[0].startsWith(cId1 + "="));
+        assertEquals(1, active.length);
+        assertTrue(active[0].startsWith(cId2 + "="));
     }
 
     // OAK-2288
@@ -723,7 +681,7 @@ public class DocumentNodeStoreTest {
 
         NodeDocument doc = docStore.find(NODES, id);
         assertNotNull(doc);
-        Revision rev = doc.getLocalDeleted().firstKey();
+        RevisionVector rev = new RevisionVector(doc.getLocalDeleted().firstKey());
 
         merge(store, builder1);
 
@@ -829,41 +787,6 @@ public class DocumentNodeStoreTest {
         }
     }
 
-    // OAK-2345
-    @Test
-    public void inactiveClusterId() throws Exception {
-        Clock clock = new Clock.Virtual();
-        clock.waitUntil(System.currentTimeMillis());
-        Revision.setClock(clock);
-        MemoryDocumentStore docStore = new MemoryDocumentStore();
-        DocumentNodeStore ns1 = builderProvider.newBuilder()
-                .setDocumentStore(docStore).setClusterId(1)
-                .setAsyncDelay(0).clock(clock).getNodeStore();
-        NodeBuilder builder = ns1.getRoot().builder();
-        builder.child("test");
-        merge(ns1, builder);
-        Revision r = ns1.getHeadRevision();
-        ns1.dispose();
-
-        // start other cluster node
-        DocumentNodeStore ns2 = builderProvider.newBuilder()
-                .setDocumentStore(docStore).setClusterId(2)
-                .setAsyncDelay(0).clock(clock).getNodeStore();
-        assertNotNull(ns2.getRevisionComparator().getRevisionSeen(r));
-        ns2.dispose();
-
-        // wait until revision is old
-        clock.waitUntil(System.currentTimeMillis()
-                + REMEMBER_REVISION_ORDER_MILLIS + 1000);
-
-        // start cluster 2 again
-        ns2 = builderProvider.newBuilder()
-                .setDocumentStore(docStore).setClusterId(2)
-                .setAsyncDelay(0).clock(clock).getNodeStore();
-        // now r is considered old and revisionSeen is null
-        assertNull(ns2.getRevisionComparator().getRevisionSeen(r));
-    }
-
     // OAK-1782
     @Test
     public void diffOnce() throws Exception {
@@ -892,9 +815,11 @@ public class DocumentNodeStoreTest {
         }
         merge(ns, builder);
 
-        final Revision head = ns.getHeadRevision();
-        final Revision to = new Revision(
-                head.getTimestamp() + 1000, 0, head.getClusterId());
+        final RevisionVector head = ns.getHeadRevision();
+        Revision localHead = head.getRevision(ns.getClusterId());
+        assertNotNull(localHead);
+        final RevisionVector to = new RevisionVector(new Revision(
+                localHead.getTimestamp() + 1000, 0, localHead.getClusterId()));
         int numReaders = 10;
         final CountDownLatch ready = new CountDownLatch(numReaders);
         final CountDownLatch go = new CountDownLatch(1);
@@ -954,7 +879,7 @@ public class DocumentNodeStoreTest {
         builder.child("test").remove();
         merge(store, builder);
 
-        Revision removedAt = store.getHeadRevision();
+        RevisionVector removedAt = store.getHeadRevision();
 
         String id = Utils.getIdFromPath("/test");
         int count = 0;
@@ -973,7 +898,7 @@ public class DocumentNodeStoreTest {
         assertNoPreviousDocs(reads);
 
         reads.clear();
-        doc.getValueMap("foo").get(removedAt);
+        doc.getValueMap("foo").get(removedAt.getRevision(store.getClusterId()));
         assertNoPreviousDocs(reads);
     }
 
@@ -1244,7 +1169,7 @@ public class DocumentNodeStoreTest {
         String parentPath = "/:hidden/parent";
         NodeDocument parentDoc = docStore.find(Collection.NODES, Utils.getIdFromPath(parentPath));
         assertFalse("parent node of unseen children must not get deleted",
-                isDocDeleted(parentDoc, store1.getRevisionComparator()));
+                isDocDeleted(parentDoc));
 
         //Test 2 - parent shouldn't be removable if order of operation is:
         //# N1 and N2 know about /:hidden
@@ -1262,7 +1187,7 @@ public class DocumentNodeStoreTest {
 
         parentDoc = docStore.find(Collection.NODES, Utils.getIdFromPath(parentPath));
         assertFalse("parent node of unseen children must not get deleted",
-                isDocDeleted(parentDoc, store2.getRevisionComparator()));
+                isDocDeleted(parentDoc));
 
         store1.runBackgroundOperations();
         store2.runBackgroundOperations();
@@ -1296,7 +1221,7 @@ public class DocumentNodeStoreTest {
         parentPath = "/:hidden/parent1";
         parentDoc = docStore.find(Collection.NODES, Utils.getIdFromPath(parentPath));
         assertFalse("parent node of unseen children must not get deleted",
-                isDocDeleted(parentDoc, store1.getRevisionComparator()));
+                isDocDeleted(parentDoc));
 
         //Test 4 - parent shouldn't be removable if order of operation is:
         //# N1 and N2 know about /:hidden/parent1
@@ -1313,7 +1238,7 @@ public class DocumentNodeStoreTest {
 
         parentDoc = docStore.find(Collection.NODES, Utils.getIdFromPath(parentPath));
         assertFalse("parent node of unseen children must not get deleted",
-                isDocDeleted(parentDoc, store2.getRevisionComparator()));
+                isDocDeleted(parentDoc));
     }
 
     @Test
@@ -1699,7 +1624,6 @@ public class DocumentNodeStoreTest {
     }
 
     // OAK-3646
-    @Ignore("OAK-3646")
     @Test
     public void concurrentChildOperations() throws Exception {
         Clock clock = new Clock.Virtual();
@@ -1742,7 +1666,7 @@ public class DocumentNodeStoreTest {
         // on cluster node 2, remove of child-0 is not yet visible
         List<ChildNodeEntry> children = Lists.newArrayList(ns2.getRoot().getChildNode("foo").getChildNode("bar").getChildNodeEntries());
         assertEquals(2, Iterables.size(children));
-        Revision invalidate = null;
+        RevisionVector invalidate = null;
         for (ChildNodeEntry entry : children) {
             if (entry.getName().equals("child-0")) {
                 invalidate = asDocumentNodeState(entry.getNodeState()).getRevision();
@@ -1753,16 +1677,12 @@ public class DocumentNodeStoreTest {
         // this will make changes from cluster node 1 visible
         ns2.runBackgroundOperations();
 
-        // wait twice the time we remember revision order
-        clock.waitUntil(clock.getTime() + 2 * REMEMBER_REVISION_ORDER_MILLIS);
-        // collect everything older than one hour (time revision order is remembered)
+        // wait two hours
+        clock.waitUntil(clock.getTime() + TimeUnit.HOURS.toMillis(2));
+        // collect everything older than one hour
         // this will remove child-0 and child-1 doc
-        ns1.getVersionGarbageCollector().gc(REMEMBER_REVISION_ORDER_MILLIS, TimeUnit.MILLISECONDS);
+        ns1.getVersionGarbageCollector().gc(1, TimeUnit.HOURS);
 
-        // trigger purge of revisions older than one hour in RevisionComparator
-        // this is usually done by the background read operation, but we
-        // do it explicitly here to make sure it really happens in this test
-        ns2.getRevisionComparator().purge(clock.getTime() - REMEMBER_REVISION_ORDER_MILLIS);
         // forget cache entry for deleted node
         ns2.invalidateNodeCache("/foo/bar/child-0", invalidate);
 
@@ -1772,7 +1692,6 @@ public class DocumentNodeStoreTest {
 
     // OAK-3646
     // similar to previous test but both cluster nodes add a child node
-    @Ignore("OAK-3646")
     @Test
     public void concurrentChildOperations2() throws Exception {
         Clock clock = new Clock.Virtual();
@@ -1814,14 +1733,6 @@ public class DocumentNodeStoreTest {
         // this will make changes from cluster node 1 visible
         ns2.runBackgroundOperations();
 
-        // wait twice the time we remember revision order
-        clock.waitUntil(clock.getTime() + 2 * REMEMBER_REVISION_ORDER_MILLIS);
-
-        // trigger purge of revisions older than one hour in RevisionComparator
-        // this is usually done by the background read operation, but we
-        // do it explicitly here to make sure it really happens in this test
-        ns2.getRevisionComparator().purge(clock.getTime() - REMEMBER_REVISION_ORDER_MILLIS);
-
         children = Lists.newArrayList(ns2.getRoot().getChildNode("foo").getChildNodeEntries());
         assertEquals(2, Iterables.size(children));
     }
@@ -2156,11 +2067,11 @@ public class DocumentNodeStoreTest {
     public void dispatch() throws Exception {
         DocumentNodeStore ns = builderProvider.newBuilder().getNodeStore();
 
-        Revision from = ns.getHeadRevision();
+        RevisionVector from = ns.getHeadRevision();
         NodeBuilder builder = ns.getRoot().builder();
         builder.child("test");
         merge(ns, builder);
-        Revision to = ns.getHeadRevision();
+        RevisionVector to = ns.getHeadRevision();
 
         DiffCache.Entry entry = ns.getDiffCache().newEntry(from, to, true);
         entry.append("/", "-\"foo\"");
@@ -2188,7 +2099,7 @@ public class DocumentNodeStoreTest {
         builder.child("foo").child("child").child("node");
         merge(ns, builder);
 
-        Revision head = ns.getHeadRevision();
+        RevisionVector head = ns.getHeadRevision();
         NodeState child = ns.getRoot().getChildNode("bar").getChildNode("child");
         assertTrue(child instanceof DocumentNodeState);
         DocumentNodeState state = (DocumentNodeState) child;
@@ -2304,7 +2215,9 @@ public class DocumentNodeStoreTest {
         afterTest.compareAgainstBaseState(beforeTest, new DefaultNodeStateDiff());
 
         assertEquals(1, startValues.size());
-        long beforeModified = getModifiedInSecs(before.getRevision().getTimestamp());
+        Revision localHead = before.getRevision().getRevision(ns.getClusterId());
+        assertNotNull(localHead);
+        long beforeModified = getModifiedInSecs(localHead.getTimestamp());
         // startValue must be based on the revision of the before state
         // and not when '/test' was last modified
         assertEquals(beforeModified, (long) startValues.get(0));
@@ -2444,7 +2357,7 @@ public class DocumentNodeStoreTest {
         final List<Commit> commits = new ArrayList<Commit>();
         for (int i = 0; i < 10; i++) {
             Revision revision = ds.newRevision();
-            Commit commit = ds.newCommit(revision, ds.createBranch(root));
+            Commit commit = ds.newCommit(new RevisionVector(revision), ds.createBranch(root));
             commits.add(commit);
             revisions.add(revision);
         }
@@ -2655,6 +2568,80 @@ public class DocumentNodeStoreTest {
         assertTrue(diff.modified.contains("/parent/node-x/child"));
     }
 
+    @Test
+    public void lastRevWithRevisionVector() throws Exception {
+        MemoryDocumentStore store = new MemoryDocumentStore();
+        DocumentNodeStore ns1 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(0).getNodeStore();
+        DocumentNodeStore ns2 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(0).getNodeStore();
+
+        NodeBuilder b1 = ns1.getRoot().builder();
+        b1.child("parent");
+        merge(ns1, b1);
+        b1 = ns1.getRoot().builder();
+        NodeBuilder parent = b1.child("parent");
+        parent.setProperty("p", 1);
+        parent.child("child");
+        merge(ns1, b1);
+        ns1.runBackgroundOperations();
+        ns2.runBackgroundOperations();
+
+        NodeBuilder b2 = ns2.getRoot().builder();
+        b2.child("parent").setProperty("p", 2);
+        merge(ns2, b2);
+        ns2.runBackgroundOperations();
+        ns1.runBackgroundOperations();
+
+        assertTrue(ns1.getRoot().getChildNode("parent").hasChildNode("child"));
+    }
+
+    @Test
+    public void branchBaseBeforeClusterJoin() throws Exception {
+        MemoryDocumentStore store = new MemoryDocumentStore();
+        DocumentNodeStore ns1 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(0).getNodeStore();
+
+        NodeBuilder b1 = ns1.getRoot().builder();
+        b1.child("parent");
+        merge(ns1, b1);
+        ns1.runBackgroundOperations();
+
+        DocumentNodeStore ns2 = builderProvider.newBuilder()
+                .setDocumentStore(store).setAsyncDelay(0).getNodeStore();
+        NodeBuilder b2 = ns2.getRoot().builder();
+        b2.child("parent").child("baz");
+        merge(ns2, b2);
+        ns2.runBackgroundOperations();
+
+        DocumentNodeState root = ns1.getRoot();
+        DocumentNodeStoreBranch b = ns1.createBranch(root);
+        // branch state is now Unmodified
+        NodeBuilder builder = root.builder();
+        builder.child("parent").child("foo");
+        b.setRoot(builder.getNodeState());
+        // branch state is now InMemory
+        builder.child("parent").child("bar");
+        b.setRoot(builder.getNodeState());
+        // branch state is now Persisted
+
+        b.rebase();
+        NodeState parent = b.getHead().getChildNode("parent");
+        assertTrue(parent.exists());
+        assertTrue(parent.hasChildNode("foo"));
+        assertTrue(parent.hasChildNode("bar"));
+        assertFalse(parent.hasChildNode("baz"));
+
+        ns1.runBackgroundOperations();
+
+        b.merge(EmptyHook.INSTANCE, CommitInfo.EMPTY);
+        parent = ns1.getRoot().getChildNode("parent");
+        assertTrue(parent.exists());
+        assertTrue(parent.hasChildNode("foo"));
+        assertTrue(parent.hasChildNode("bar"));
+        assertTrue(parent.hasChildNode("baz"));
+    }
+
     private static DocumentNodeState asDocumentNodeState(NodeState state) {
         if (!(state instanceof DocumentNodeState)) {
             throw new IllegalArgumentException("Not a DocumentNodeState");
@@ -2768,11 +2755,10 @@ public class DocumentNodeStoreTest {
      * @param doc the document to be tested
      * @return latest committed value of _deleted map
      */
-    private boolean isDocDeleted(NodeDocument doc,
-                                 Comparator<Revision> comparator) {
+    private boolean isDocDeleted(NodeDocument doc) {
         boolean latestDeleted = false;
-        SortedMap<Revision, String> localDeleted = Maps.newTreeMap(
-                Collections.reverseOrder(comparator));
+        SortedMap<Revision, String> localDeleted =
+                Maps.newTreeMap(StableRevisionComparator.REVERSE);
         localDeleted.putAll(doc.getLocalDeleted());
 
         for (Map.Entry<Revision, String> entry : localDeleted.entrySet()) {
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentSplitTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentSplitTest.java
index b9fee36b48..216fd450a7 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentSplitTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentSplitTest.java
@@ -18,7 +18,6 @@ package org.apache.jackrabbit.oak.plugins.document;
 
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Comparator;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -95,7 +94,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
             assertTrue(doc.isCommitted(rev));
         }
         // check if document is still there
-        assertNotNull(ns.getNode("/", Revision.fromString(head)));
+        assertNotNull(ns.getNode("/", RevisionVector.fromString(head)));
 
         NodeDocument prevDoc = Iterators.getOnlyElement(doc.getAllPreviousDocs());
         assertEquals(SplitDocType.DEFAULT, prevDoc.getSplitDocType());
@@ -135,7 +134,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
                     || doc.getCommitRootPath(rev) != null);
             assertTrue(doc.isCommitted(rev));
         }
-        DocumentNodeState node = ns.getNode("/foo", Revision.fromString(head));
+        DocumentNodeState node = ns.getNode("/foo", RevisionVector.fromString(head));
         // check status of node
         if (create) {
             assertNull(node);
@@ -290,7 +289,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
             // read current value
             NodeDocument doc = ds.find(NODES, Utils.getIdFromPath("/test"));
             assertNotNull(doc);
-            Revision head = ns.getHeadRevision();
+            RevisionVector head = ns.getHeadRevision();
             Revision lastRev = ns.getPendingModifications().get("/test");
             DocumentNodeState n = doc.getNodeAtRevision(mk.getNodeStore(), head, lastRev);
             assertNotNull(n);
@@ -326,7 +325,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
         doc = store.find(NODES, Utils.getIdFromPath("/test/foo"));
         assertNotNull(doc);
         DocumentNodeState node = doc.getNodeAtRevision(ns,
-                Revision.fromString(rev), null);
+                RevisionVector.fromString(rev), null);
         assertNotNull(node);
     }
 
@@ -473,7 +472,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
         Map<Revision, String> valueMap = doc.getValueMap("prop");
         for (Map.Entry<Revision, String> entry : valueMap.entrySet()) {
             if (previous != null) {
-                assertTrue(ns.isRevisionNewer(previous, entry.getKey()));
+                assertTrue(previous.compareRevisionTime(entry.getKey()) > 0);
             }
             previous = entry.getKey();
             numValues++;
@@ -482,7 +481,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
         assertEquals(revs.size(), numValues);
         assertEquals(revs.size(), valueMap.size());
 
-        assertNotNull(doc.getNodeAtRevision(ns, Revision.fromString(rev), null));
+        assertNotNull(doc.getNodeAtRevision(ns, RevisionVector.fromString(rev), null));
     }
 
     @Test
@@ -525,7 +524,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
         }
         // some fake previous doc references to trigger UpdateOp
         // for an intermediate document
-        TreeSet<Revision> prev = Sets.newTreeSet(mk.getNodeStore().getRevisionComparator());
+        TreeSet<Revision> prev = Sets.newTreeSet(StableRevisionComparator.INSTANCE);
         for (int i = 0; i < PREV_SPLIT_FACTOR; i++) {
             Revision low = Revision.newRevision(clusterId);
             Revision high = Revision.newRevision(clusterId);
@@ -669,7 +668,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
         NodeDocument doc = new NodeDocument(mk.getDocumentStore());
         doc.put(NodeDocument.ID, Utils.getIdFromPath("/test"));
         doc.put(NodeDocument.SD_TYPE, NodeDocument.SplitDocType.DEFAULT.type);
-        Revision head = mk.getNodeStore().getHeadRevision();
+        RevisionVector head = mk.getNodeStore().getHeadRevision();
         SplitOperations.forDocument(doc, DummyRevisionContext.INSTANCE, head, NUM_REVS_THRESHOLD);
     }
 
@@ -780,7 +779,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
         final DocumentStore store = mk.getDocumentStore();
         final DocumentNodeStore ns = mk.getNodeStore();
         final List<Exception> exceptions = Lists.newArrayList();
-        final List<Revision> revisions = Lists.newArrayList();
+        final List<RevisionVector> revisions = Lists.newArrayList();
 
         Thread t = new Thread(new Runnable() {
             @Override
@@ -811,7 +810,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
         RevisionContext rc = new TestRevisionContext(ns);
         while (t.isAlive()) {
             for (String id : ns.getSplitCandidates()) {
-                Revision head = ns.getHeadRevision();
+                RevisionVector head = ns.getHeadRevision();
                 NodeDocument doc = store.find(NODES, id);
                 List<UpdateOp> ops = SplitOperations.forDocument(doc, rc, head, NUM_REVS_THRESHOLD);
                 Set<Revision> removed = Sets.newHashSet();
@@ -842,7 +841,10 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
             if (doc.isSplitDocument() || Utils.getDepthFromId(doc.getId()) < 2) {
                 continue;
             }
-            Set<Revision> revs = Sets.newHashSet(revisions);
+            Set<Revision> revs = Sets.newHashSet();
+            for (RevisionVector rv : revisions) {
+                Iterables.addAll(revs, rv);
+            }
             revs.removeAll(doc.getValueMap("_deleted").keySet());
             assertTrue("Missing _deleted entries on " + doc.getId() + ": " + revs, revs.isEmpty());
         }
@@ -866,11 +868,6 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
             return rc.getPendingModifications();
         }
 
-        @Override
-        public Comparator<Revision> getRevisionComparator() {
-            return rc.getRevisionComparator();
-        }
-
         @Override
         public int getClusterId() {
             return rc.getClusterId();
@@ -878,7 +875,7 @@ public class DocumentSplitTest extends BaseDocumentMKTest {
 
         @Nonnull
         @Override
-        public Revision getHeadRevision() {
+        public RevisionVector getHeadRevision() {
             try {
                 Thread.sleep((long) (Math.random() * 100));
             } catch (InterruptedException e) {
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DummyRevisionContext.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DummyRevisionContext.java
index 5270e7da8e..af5087ffa4 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DummyRevisionContext.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DummyRevisionContext.java
@@ -16,8 +16,6 @@
  */
 package org.apache.jackrabbit.oak.plugins.document;
 
-import java.util.Comparator;
-
 import javax.annotation.Nonnull;
 
 /**
@@ -27,12 +25,9 @@ public class DummyRevisionContext implements RevisionContext {
 
     static final RevisionContext INSTANCE = new DummyRevisionContext();
 
-    private final Comparator<Revision> comparator
-            = StableRevisionComparator.INSTANCE;
-
     @Override
     public UnmergedBranches getBranches() {
-        return new UnmergedBranches(comparator);
+        return new UnmergedBranches();
     }
 
     @Override
@@ -40,11 +35,6 @@ public class DummyRevisionContext implements RevisionContext {
         return new UnsavedModifications();
     }
 
-    @Override
-    public Comparator<Revision> getRevisionComparator() {
-        return comparator;
-    }
-
     @Override
     public int getClusterId() {
         return 1;
@@ -52,13 +42,13 @@ public class DummyRevisionContext implements RevisionContext {
 
     @Nonnull
     @Override
-    public Revision getHeadRevision() {
-        return Revision.newRevision(1);
+    public RevisionVector getHeadRevision() {
+        return new RevisionVector(Revision.newRevision(getClusterId()));
     }
 
     @Nonnull
     @Override
     public Revision newRevision() {
-        return Revision.newRevision(1);
+        return Revision.newRevision(getClusterId());
     }
 }
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/JournalEntryTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/JournalEntryTest.java
index 067cc51d5e..4ab7207312 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/JournalEntryTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/JournalEntryTest.java
@@ -53,8 +53,8 @@ public class JournalEntryTest {
         addRandomPaths(paths);
         StringSort sort = JournalEntry.newSorter();
         add(sort, paths);
-        Revision from = new Revision(1, 0, 1);
-        Revision to = new Revision(2, 0, 1);
+        RevisionVector from = new RevisionVector(new Revision(1, 0, 1));
+        RevisionVector to = new RevisionVector(new Revision(2, 0, 1));
         sort.sort();
         JournalEntry.applyTo(sort, cache, from, to);
 
@@ -72,9 +72,9 @@ public class JournalEntryTest {
     @Test
     public void useParentDiff() throws Exception {
         DiffCache cache = new MemoryDiffCache(new DocumentMK.Builder());
-        Revision from = new Revision(1, 0, 1);
-        Revision to = new Revision(2, 0, 1);
-        Revision unjournalled = new Revision(3, 0, 1);
+        RevisionVector from = new RevisionVector(new Revision(1, 0, 1));
+        RevisionVector to = new RevisionVector(new Revision(2, 0, 1));
+        RevisionVector unjournalled = new RevisionVector(new Revision(3, 0, 1));
 
         //Put one entry for (from, to, "/a/b")->["c1", "c2"] manually
         DiffCache.Entry entry = cache.newEntry(from, to, false);
@@ -190,7 +190,11 @@ public class JournalEntryTest {
         }
     }
 
-    private void validateCacheUsage(DiffCache cache, Revision from, Revision to, String path, boolean cacheExpected) {
+    private void validateCacheUsage(DiffCache cache,
+                                    RevisionVector from,
+                                    RevisionVector to,
+                                    String path,
+                                    boolean cacheExpected) {
         String nonLoaderDiff = cache.getChanges(from, to, path, null);
         final AtomicBoolean loaderCalled = new AtomicBoolean(false);
         cache.getChanges(from, to, path, new DiffCache.Loader() {
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/JournalTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/JournalTest.java
index 143351c098..9988a0774b 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/JournalTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/JournalTest.java
@@ -41,6 +41,7 @@ import org.junit.rules.TestRule;
 
 import static java.util.Collections.synchronizedList;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 
@@ -371,7 +372,7 @@ public class JournalTest extends AbstractJournalTest {
         Revision zlastRev2 = z1.getLastRev().get(c2Id);
         // /x/y/z is a new node and does not have a _lastRev
         assertNull(zlastRev2);
-        Revision head2 = ds2.getHeadRevision();
+        Revision head2 = ds2.getHeadRevision().getRevision(ds2.getClusterId());
 
         //lastRev should not be updated for C #2
         assertNull(y1.getLastRev().get(c2Id));
@@ -458,7 +459,8 @@ public class JournalTest extends AbstractJournalTest {
         NodeBuilder b2 = ns2.getRoot().builder();
         b2.child("bar");
         ns2.merge(b2, EmptyHook.INSTANCE, CommitInfo.EMPTY);
-        Revision h2 = ns2.getHeadRevision();
+        Revision h2 = ns2.getHeadRevision().getRevision(ns2.getClusterId());
+        assertNotNull(h2);
 
         ns2.runBackgroundReadOperations();
 
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgentTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgentTest.java
index 7409a5313c..f018c919e0 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgentTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgentTest.java
@@ -139,7 +139,7 @@ public class LastRevRecoveryAgentTest {
         b2.child("x").child("y").child("z").setProperty("foo", "bar");
         ds2.merge(b2, EmptyHook.INSTANCE, CommitInfo.EMPTY);
 
-        Revision zlastRev2 = ds2.getHeadRevision();
+        Revision zlastRev2 = ds2.getHeadRevision().getRevision(ds2.getClusterId());
 
         long leaseTime = ds1.getClusterInfo().getLeaseTime();
         ds1.runBackgroundOperations();
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryTest.java
index 603fb3f7a0..99b932173b 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryTest.java
@@ -122,7 +122,7 @@ public class LastRevRecoveryTest {
         Revision zlastRev2 = z1.getLastRev().get(c2Id);
         // /x/y/z is a new node and does not have a _lastRev
         assertNull(zlastRev2);
-        Revision head2 = ds2.getHeadRevision();
+        Revision head2 = ds2.getHeadRevision().getRevision(c2Id);
 
         //lastRev should not be updated for C #2
         assertNull(y1.getLastRev().get(c2Id));
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MeasureMemory.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MeasureMemory.java
index 6cd1082483..6d1fc20ab8 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MeasureMemory.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MeasureMemory.java
@@ -167,12 +167,50 @@ public class MeasureMemory {
             @Override
             public Object[] call() {
                 RevisionsKey k = new RevisionsKey(
-                        Revision.newRevision(0), Revision.newRevision(0));
+                        new RevisionVector(Revision.newRevision(0)),
+                        new RevisionVector(Revision.newRevision(0)));
                 return new Object[]{k, k.getMemory() + OVERHEAD};
             }
         });
     }
 
+    @Test
+    public void revisionVector() throws Exception {
+        measureMemory(new Callable<Object[]>() {
+            @Override
+            public Object[] call() throws Exception {
+                RevisionVector rv = new RevisionVector(
+                        Revision.newRevision(0),
+                        Revision.newRevision(1),
+                        Revision.newRevision(2),
+                        Revision.newRevision(3));
+                return new Object[]{rv, rv.getMemory() + OVERHEAD};
+            }
+        });
+    }
+
+    @Test
+    public void revisionVectorSingle() throws Exception {
+        measureMemory(new Callable<Object[]>() {
+            @Override
+            public Object[] call() throws Exception {
+                RevisionVector rv = new RevisionVector(Revision.newRevision(0));
+                return new Object[]{rv, rv.getMemory() + OVERHEAD};
+            }
+        });
+    }
+
+    @Test
+    public void revision() throws Exception {
+        measureMemory(new Callable<Object[]>() {
+            @Override
+            public Object[] call() throws Exception {
+                Revision r = Revision.newRevision(0);
+                return new Object[]{r, r.getMemory() + OVERHEAD};
+            }
+        });
+    }
+
     private static void measureMemory(Callable<Object[]> c) throws Exception {
         LinkedList<Object> list = new LinkedList<Object>();
         long base = getMemoryUsed();
@@ -201,11 +239,11 @@ public class MeasureMemory {
 
     static DocumentNodeState generateNode(int propertyCount) {
         DocumentNodeState n = new DocumentNodeState(STORE, new String("/hello/world"),
-                new Revision(1, 2, 3));
+                new RevisionVector(new Revision(1, 2, 3)));
         for (int i = 0; i < propertyCount; i++) {
             n.setProperty("property" + i, "\"values " + i + "\"");
         }
-        n.setLastRevision(new Revision(1, 2, 3));
+        n.setLastRevision(new RevisionVector(new Revision(1, 2, 3)));
         return n;
     }
 
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MongoDocumentStoreTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MongoDocumentStoreTest.java
index 95ff8a1b7d..983f388dcc 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MongoDocumentStoreTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MongoDocumentStoreTest.java
@@ -228,8 +228,9 @@ public class MongoDocumentStoreTest {
         Revision rev = Revision.newRevision(0);
         List<UpdateOp> inserts = new ArrayList<UpdateOp>();
         for (int i = 0; i < DocumentMK.MANY_CHILDREN_THRESHOLD * 2; i++) {
-            DocumentNodeState n = new DocumentNodeState(store, "/node-" + i, rev);
-            inserts.add(n.asOperation(true));
+            DocumentNodeState n = new DocumentNodeState(store, "/node-" + i,
+                    new RevisionVector(rev));
+            inserts.add(n.asOperation(rev));
         }
         docStore.create(Collection.NODES, inserts);
         List<NodeDocument> docs = docStore.query(Collection.NODES,
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/NodeDocumentTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/NodeDocumentTest.java
index 631195c068..611dea6c15 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/NodeDocumentTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/NodeDocumentTest.java
@@ -17,7 +17,6 @@
 package org.apache.jackrabbit.oak.plugins.document;
 
 import java.util.Collections;
-import java.util.Comparator;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
@@ -28,7 +27,6 @@ import java.util.Set;
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Iterators;
 import com.google.common.collect.Lists;
-import com.google.common.collect.Sets;
 
 import org.apache.jackrabbit.oak.api.CommitFailedException;
 import org.apache.jackrabbit.oak.plugins.document.VersionGarbageCollector.VersionGCStats;
@@ -40,10 +38,9 @@ import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
 import org.apache.jackrabbit.oak.spi.state.NodeStore;
 import org.junit.Test;
 
+import static com.google.common.collect.Sets.newHashSet;
 import static org.apache.jackrabbit.oak.plugins.document.Collection.NODES;
 import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.COLLISIONS;
-import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.revisionAreAmbiguous;
-import static org.apache.jackrabbit.oak.plugins.document.Revision.RevisionComparator;
 import static org.apache.jackrabbit.oak.plugins.document.util.Utils.getRootDocument;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
@@ -70,58 +67,20 @@ public class NodeDocumentTest {
             NodeDocument.addCollision(op, r, Revision.newRevision(1));
         }
         UpdateUtils.applyChanges(doc, op);
-        Revision head = DummyRevisionContext.INSTANCE.getHeadRevision();
+        RevisionVector head = DummyRevisionContext.INSTANCE.getHeadRevision();
         doc.split(DummyRevisionContext.INSTANCE, head);
     }
 
     @Test
-    public void ambiguousRevisions() {
-        // revisions from same cluster node are not ambiguous
-        RevisionContext context = DummyRevisionContext.INSTANCE;
-        Revision r1 = new Revision(1, 0, 1);
-        Revision r2 = new Revision(2, 0, 1);
-        assertFalse(revisionAreAmbiguous(context, r1, r1));
-        assertFalse(revisionAreAmbiguous(context, r1, r2));
-        assertFalse(revisionAreAmbiguous(context, r2, r1));
-
-        // revisions from different cluster nodes are not ambiguous
-        // if seen with stable revision comparator
-        r1 = new Revision(1, 0, 2);
-        r2 = new Revision(2, 0, 1);
-        assertFalse(revisionAreAmbiguous(context, r1, r1));
-        assertFalse(revisionAreAmbiguous(context, r1, r2));
-        assertFalse(revisionAreAmbiguous(context, r2, r1));
-
-        // now use a revision comparator with seen-at support
-        final RevisionComparator comparator = new RevisionComparator(1);
-        context = new DummyRevisionContext() {
-            @Override
-            public Comparator<Revision> getRevisionComparator() {
-                return comparator;
-            }
-        };
-        r1 = new Revision(1, 0, 2);
-        r2 = new Revision(2, 0, 1);
-        // add revision to comparator in reverse time order
-        comparator.add(r2, new Revision(2, 0, 0));
-        comparator.add(r1, new Revision(3, 0, 0)); // r1 seen after r2
-        assertFalse(revisionAreAmbiguous(context, r1, r1));
-        assertFalse(revisionAreAmbiguous(context, r2, r2));
-        assertTrue(revisionAreAmbiguous(context, r1, r2));
-        assertTrue(revisionAreAmbiguous(context, r2, r1));
-    }
-
-    @Test
-    public void getMostRecentConflictFor() {
-        RevisionContext context = DummyRevisionContext.INSTANCE;
+    public void getConflictsFor() {
         MemoryDocumentStore docStore = new MemoryDocumentStore();
         String id = Utils.getPathFromId("/");
         NodeDocument doc = new NodeDocument(docStore);
         doc.put(Document.ID, id);
 
         Iterable<Revision> branchCommits = Collections.emptyList();
-        Revision conflict = doc.getMostRecentConflictFor(branchCommits, context);
-        assertNull(conflict);
+        Set<Revision> conflicts = doc.getConflictsFor(branchCommits);
+        assertTrue(conflicts.isEmpty());
 
         // add some collisions
         UpdateOp op = new UpdateOp(id, false);
@@ -138,24 +97,24 @@ public class NodeDocumentTest {
         UpdateUtils.applyChanges(doc, op);
 
         branchCommits = Collections.singleton(r0);
-        conflict = doc.getMostRecentConflictFor(branchCommits, context);
-        assertNull(conflict);
+        conflicts = doc.getConflictsFor(branchCommits);
+        assertTrue(conflicts.isEmpty());
 
         branchCommits = Collections.singleton(r1.asBranchRevision());
-        conflict = doc.getMostRecentConflictFor(branchCommits, context);
-        assertEquals(c1, conflict);
+        conflicts = doc.getConflictsFor(branchCommits);
+        assertEquals(newHashSet(c1), conflicts);
 
         branchCommits = Collections.singleton(r2.asBranchRevision());
-        conflict = doc.getMostRecentConflictFor(branchCommits, context);
-        assertEquals(c2, conflict);
+        conflicts = doc.getConflictsFor(branchCommits);
+        assertEquals(newHashSet(c2), conflicts);
 
         branchCommits = Lists.newArrayList(r1.asBranchRevision(), r2.asBranchRevision());
-        conflict = doc.getMostRecentConflictFor(branchCommits, context);
-        assertEquals(c2, conflict);
+        conflicts = doc.getConflictsFor(branchCommits);
+        assertEquals(newHashSet(c1, c2), conflicts);
 
         branchCommits = Lists.newArrayList(r2.asBranchRevision(), r1.asBranchRevision());
-        conflict = doc.getMostRecentConflictFor(branchCommits, context);
-        assertEquals(c2, conflict);
+        conflicts = doc.getConflictsFor(branchCommits);
+        assertEquals(newHashSet(c1, c2), conflicts);
     }
 
     @Test
@@ -240,7 +199,7 @@ public class NodeDocumentTest {
             builder.setProperty("p-" + clusterIdx, i);
             merge(ns, builder);
             if (r.nextFloat() < 0.2) {
-                Revision head = ns.getHeadRevision();
+                RevisionVector head = ns.getHeadRevision();
                 for (UpdateOp op : SplitOperations.forDocument(
                         getRootDocument(store), ns, head, 2)) {
                     store.createOrUpdate(NODES, op);
@@ -328,7 +287,7 @@ public class NodeDocumentTest {
     @Test
     public void getNewestRevisionTooExpensive() throws Exception {
         final int NUM_CHANGES = 200;
-        final Set<String> prevDocCalls = Sets.newHashSet();
+        final Set<String> prevDocCalls = newHashSet();
         DocumentStore store = new MemoryDocumentStore() {
             @Override
             public <T extends Document> T find(Collection<T> collection,
@@ -354,7 +313,7 @@ public class NodeDocumentTest {
             }
             merge(ns, builder);
             if (Math.random() < 0.2) {
-                Revision head = ns.getHeadRevision();
+                RevisionVector head = ns.getHeadRevision();
                 NodeDocument doc = ns.getDocumentStore().find(
                         NODES, Utils.getIdFromPath("/test"));
                 for (UpdateOp op : SplitOperations.forDocument(
@@ -374,7 +333,8 @@ public class NodeDocumentTest {
         Revision changeRev = new Revision(baseRev.getTimestamp(), 1000, ns.getClusterId());
         // reset calls to previous documents
         prevDocCalls.clear();
-        doc.getNewestRevision(ns, baseRev, changeRev, null, new HashSet<Revision>());
+        doc.getNewestRevision(ns, new RevisionVector(baseRev), changeRev,
+                null, new HashSet<Revision>());
         // must not read all previous docs
         assertTrue("too many calls for previous documents: " + prevDocCalls,
                 prevDocCalls.size() <= 5);
@@ -391,10 +351,11 @@ public class NodeDocumentTest {
         NodeBuilder b1 = ns1.getRoot().builder();
         b1.child("test");
         merge(ns1, b1);
-        Revision created = ns1.getHeadRevision();
+        RevisionVector headCreated = ns1.getHeadRevision();
+        Revision created = headCreated.getRevision(ns1.getClusterId());
 
         NodeDocument doc = store.find(NODES, Utils.getIdFromPath("/test"));
-        Set<Revision> collisions = Sets.newHashSet();
+        Set<Revision> collisions = newHashSet();
         Revision newest = doc.getNewestRevision(ns1, ns1.getHeadRevision(),
                 ns1.newRevision(), null, collisions);
         assertEquals(created, newest);
@@ -444,14 +405,14 @@ public class NodeDocumentTest {
         b1 = ns1.getRoot().builder();
         b1.child("test").setProperty("q", "v");
         merge(ns1, b1);
-        Revision committed = ns1.getHeadRevision();
+        Revision committed = ns1.getHeadRevision().getRevision(ns1.getClusterId());
 
         collisions.clear();
         // ns1 must now report committed revision as newest
         // uncommitted is not considered a collision anymore
         // because it is older than the base revision
         doc = store.find(NODES, Utils.getIdFromPath("/test"));
-        newest = doc.getNewestRevision(ns1, created,
+        newest = doc.getNewestRevision(ns1, headCreated,
                 ns1.newRevision(), null, collisions);
         assertEquals(committed, newest);
         assertEquals(0, collisions.size());
@@ -479,9 +440,9 @@ public class NodeDocumentTest {
         builder.child("test");
         merge(ns, builder);
 
-        Set<Revision> collisions = Sets.newHashSet();
+        Set<Revision> collisions = newHashSet();
         NodeDocument doc = store.find(NODES, Utils.getIdFromPath("/test"));
-        Revision branchBase = ns.getHeadRevision().asBranchRevision();
+        RevisionVector branchBase = ns.getHeadRevision().asBranchRevision(ns.getClusterId());
         try {
             doc.getNewestRevision(ns, branchBase, ns.newRevision(), null, collisions);
             fail("Must fail with IllegalArgumentException");
@@ -489,7 +450,7 @@ public class NodeDocumentTest {
             // expected
         }
         try {
-            Revision head = ns.getHeadRevision();
+            RevisionVector head = ns.getHeadRevision();
             Branch b = ns.getBranches().create(head, ns.newRevision(), null);
             doc.getNewestRevision(ns, head, ns.newRevision(), b, collisions);
             fail("Must fail with IllegalArgumentException");
@@ -510,7 +471,7 @@ public class NodeDocumentTest {
         for (int i = 0; i < 10; i++) {
             int idx = random.nextInt(numChanges);
             Revision r = Iterables.get(doc.getValueMap("p").keySet(), idx);
-            Iterable<Revision> revs = doc.getChanges("p", r, ns);
+            Iterable<Revision> revs = doc.getChanges("p", new RevisionVector(r));
             assertEquals(idx, Iterables.size(revs));
         }
         ns.dispose();
@@ -525,15 +486,17 @@ public class NodeDocumentTest {
         DocumentNodeStore ns2 = createTestStore(store, 2, 0);
         List<DocumentNodeStore> nodeStores = Lists.newArrayList(ns1, ns2);
 
+        List<RevisionVector> headRevisions = Lists.newArrayList();
         for (int i = 0; i < numChanges; i++) {
             DocumentNodeStore ns = nodeStores.get(random.nextInt(nodeStores.size()));
             ns.runBackgroundOperations();
             NodeBuilder builder = ns.getRoot().builder();
             builder.setProperty("p", i);
             merge(ns, builder);
+            headRevisions.add(ns.getHeadRevision());
             ns.runBackgroundOperations();
             if (random.nextDouble() < 0.2) {
-                Revision head = ns.getHeadRevision();
+                RevisionVector head = ns.getHeadRevision();
                 for (UpdateOp op : SplitOperations.forDocument(
                         getRootDocument(store), ns, head, 2)) {
                     store.createOrUpdate(NODES, op);
@@ -541,12 +504,13 @@ public class NodeDocumentTest {
             }
         }
 
+        headRevisions = Lists.reverse(headRevisions);
         NodeDocument doc = getRootDocument(store);
         for (int i = 0; i < 10; i++) {
             int idx = random.nextInt(numChanges);
-            Revision r = Iterables.get(doc.getValueMap("p").keySet(), idx);
-            Iterable<Revision> revs1 = doc.getChanges("p", r, ns1);
-            Iterable<Revision> revs2 = doc.getChanges("p", r, ns2);
+            RevisionVector r = headRevisions.get(idx);
+            Iterable<Revision> revs1 = doc.getChanges("p", r);
+            Iterable<Revision> revs2 = doc.getChanges("p", r);
             assertEquals(Iterables.size(revs1), Iterables.size(revs2));
             assertEquals(idx, Iterables.size(revs1));
         }
@@ -559,7 +523,7 @@ public class NodeDocumentTest {
     @Test
     public void isConflicting() throws Exception {
         final int numChanges = 200;
-        final Set<String> prevDocCalls = Sets.newHashSet();
+        final Set<String> prevDocCalls = newHashSet();
         MemoryDocumentStore store = new MemoryDocumentStore() {
             @Override
             public <T extends Document> T find(Collection<T> collection,
@@ -574,13 +538,13 @@ public class NodeDocumentTest {
         NodeDocument doc = getRootDocument(store);
         Map<Revision, String> valueMap = doc.getValueMap("p");
         assertEquals(200, valueMap.size());
-        Revision baseRev = valueMap.keySet().iterator().next();
+        RevisionVector baseRev = new RevisionVector(valueMap.keySet().iterator().next());
         Revision commitRev = ns.newRevision();
         UpdateOp op = new UpdateOp(Utils.getIdFromPath("/"), false);
         op.setMapEntry("p", commitRev, "v");
 
         prevDocCalls.clear();
-        assertFalse(doc.isConflicting(op, baseRev, commitRev, ns, false));
+        assertFalse(doc.isConflicting(op, baseRev, commitRev, false));
         assertTrue("too many calls for previous documents: " + prevDocCalls,
                 prevDocCalls.size() <= 6);
         ns.dispose();
@@ -601,7 +565,7 @@ public class NodeDocumentTest {
             builder.setProperty("p", i);
             merge(ns, builder);
             if (Math.random() < 0.2) {
-                Revision head = ns.getHeadRevision();
+                RevisionVector head = ns.getHeadRevision();
                 for (UpdateOp op : SplitOperations.forDocument(
                         getRootDocument(store), ns, head, 2)) {
                     store.createOrUpdate(NODES, op);
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/OrphanedBranchTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/OrphanedBranchTest.java
index e45e568138..7a855581b8 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/OrphanedBranchTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/OrphanedBranchTest.java
@@ -58,7 +58,7 @@ public class OrphanedBranchTest {
         this.fixture = fixture;
     }
 
-    @Parameterized.Parameters
+    @Parameterized.Parameters(name="{0}")
     public static java.util.Collection<Object[]> fixtures() throws IOException {
         List<Object[]> fixtures = Lists.newArrayList();
         fixtures.add(new Object[] {new DocumentStoreFixture.MemoryFixture()});
@@ -185,7 +185,7 @@ public class OrphanedBranchTest {
         assertFalse(valueMap.isEmpty());
         UnmergedBranches branches = store.getBranches();
         Revision branchRev = doc.getLocalMap("prop").firstKey();
-        Branch b = branches.getBranch(branchRev);
+        Branch b = branches.getBranch(new RevisionVector(branchRev.asBranchRevision()));
         assertNotNull(b);
         branches.remove(b);
         
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/RevisionTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/RevisionTest.java
index 7c1ed28b33..9439844768 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/RevisionTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/RevisionTest.java
@@ -20,7 +20,6 @@ import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
-import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.CountDownLatch;
@@ -34,11 +33,10 @@ import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
 import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
 import com.google.common.collect.Queues;
 import com.google.common.collect.Sets;
 import com.google.common.util.concurrent.Uninterruptibles;
-import org.apache.jackrabbit.oak.plugins.document.Revision.RevisionComparator;
+
 import org.junit.Test;
 
 /**
@@ -128,246 +126,6 @@ public class RevisionTest {
         }
     }
 
-    @Test
-    public void compare2() {
-        RevisionComparator comp = new RevisionComparator(1);
-
-        Revision r2 = new Revision(7, 0, 2);
-        Revision r3 = new Revision(5, 0, 3);
-
-        Revision seenAt = new Revision(8, 0, 0);
-        comp.add(r2, seenAt);
-        comp.add(r3, seenAt);
-
-        // both revisions have same seenAt revision, must use
-        // revision timestamp for comparison
-        assertTrue(comp.compare(r2, r3) > 0);
-    }
-
-    @Test
-    public void revisionComparatorSimple() {
-        RevisionComparator comp = new RevisionComparator(0);
-        Revision r1 = Revision.newRevision(0);
-        Revision r2 = Revision.newRevision(0);
-        assertEquals(r1.compareRevisionTime(r2), comp.compare(r1, r2));
-        assertEquals(r2.compareRevisionTime(r1), comp.compare(r2, r1));
-        assertEquals(r1.compareRevisionTime(r1), comp.compare(r1, r1));
-    }
-
-    @Test
-    public void revisionComparatorCluster() {
-
-        RevisionComparator comp = new RevisionComparator(0);
-
-        Revision r0c1 = new Revision(0x010, 0, 1);
-        Revision r0c2 = new Revision(0x010, 0, 2);
-
-        Revision r1c1 = new Revision(0x110, 0, 1);
-        Revision r2c1 = new Revision(0x120, 0, 1);
-        Revision r3c1 = new Revision(0x130, 0, 1);
-        Revision r1c2 = new Revision(0x100, 0, 2);
-        Revision r2c2 = new Revision(0x200, 0, 2);
-        Revision r3c2 = new Revision(0x300, 0, 2);
-
-        // first, only timestamps are compared
-        assertEquals(1, comp.compare(r1c1, r1c2));
-        assertEquals(-1, comp.compare(r2c1, r2c2));
-        assertEquals(-1, comp.compare(r3c1, r3c2));
-
-        // now we declare r2+r3 of c1 to be after r2+r3 of c2
-        comp.add(r2c1, new Revision(0x20, 0, 0));
-        comp.add(r2c2, new Revision(0x10, 0, 0));
-
-        assertEquals(
-                "1:\n r120-0-1:r20-0-0\n" +
-                "2:\n r200-0-2:r10-0-0\n", comp.toString());
-
-        // r0c2 happens before r0c1 because r2c2 is declared before r2c1
-        assertEquals(1, comp.compare(r0c1, r0c2));
-
-        assertEquals(1, comp.compare(r1c1, r1c2));
-        assertEquals(1, comp.compare(r2c1, r2c2));
-        // both r3cx are still "in the future"
-        assertEquals(-1, comp.compare(r3c1, r3c2));
-
-        // now we declare r3 of c1 to be before r3 of c2
-        // (with the same range timestamp,
-        // the revision timestamps are compared)
-        comp.add(r3c1, new Revision(0x30, 0, 0));
-        comp.add(r3c2, new Revision(0x30, 0, 0));
-
-        assertEquals(
-                "1:\n r120-0-1:r20-0-0 r130-0-1:r30-0-0\n" +
-                "2:\n r200-0-2:r10-0-0 r300-0-2:r30-0-0\n", comp.toString());
-
-        assertEquals(1, comp.compare(r1c1, r1c2));
-        assertEquals(1, comp.compare(r2c1, r2c2));
-        assertEquals(-1, comp.compare(r3c1, r3c2));
-        // reverse
-        assertEquals(-1, comp.compare(r1c2, r1c1));
-        assertEquals(-1, comp.compare(r2c2, r2c1));
-        assertEquals(1, comp.compare(r3c2, r3c1));
-
-        // get rid of old timestamps
-        comp.purge(0x10);
-        assertEquals(
-                "1:\n r120-0-1:r20-0-0 r130-0-1:r30-0-0\n" +
-                "2:\n r300-0-2:r30-0-0\n", comp.toString());
-        comp.purge(0x20);
-        assertEquals(
-                "1:\n r130-0-1:r30-0-0\n" +
-                "2:\n r300-0-2:r30-0-0\n", comp.toString());
-
-        // update an entry
-        comp.add(new Revision(0x301, 1, 2), new Revision(0x30, 0, 0));
-        assertEquals(
-                "1:\n r130-0-1:r30-0-0\n" +
-                "2:\n r301-1-2:r30-0-0\n", comp.toString());
-
-        comp.purge(0x30);
-        assertEquals("", comp.toString());
-
-    }
-
-    @Test
-    public void clusterCompare() {
-        RevisionComparator comp = new RevisionComparator(1);
-
-        // sequence of revisions as added to comparator later
-        Revision r1c1 = new Revision(0x10, 0, 1);
-        Revision r1c2 = new Revision(0x20, 0, 2);
-        Revision r2c1 = new Revision(0x30, 0, 1);
-        Revision r2c2 = new Revision(0x40, 0, 2);
-
-        comp.add(r1c1, new Revision(0x10, 0, 0));
-        comp.add(r2c1, new Revision(0x30, 0, 0));
-
-        // there's no range for c2, and therefore this
-        // revision must be considered to be in the future
-        assertTrue(comp.compare(r1c2, r2c1) > 0);
-
-        // add a range for r2r2
-        comp.add(r2c2, new Revision(0x40, 0, 0));
-        comp.purge(0x20);
-
-        // now there is a range for c2, but the revision is old (before purge
-        // time, so it must be considered to be in the past
-        assertTrue(comp.compare(r1c2, r2c1) < 0);
-    }
-
-    // OAK-1727
-    @Test
-    public void clusterCompare2() {
-        RevisionComparator comp = new RevisionComparator(1);
-
-        comp.add(Revision.fromString("r3-0-1"), Revision.fromString("r1-1-0"));
-
-        Revision r1 = Revision.fromString("r1-0-2");
-        Revision r2 = Revision.fromString("r4-0-2");
-
-        // cluster sync
-        Revision c1sync = Revision.fromString("r5-0-1");
-        comp.add(c1sync,  Revision.fromString("r2-0-0"));
-        Revision c2sync = Revision.fromString("r4-1-2");
-        comp.add(c2sync,  Revision.fromString("r2-1-0"));
-        Revision c3sync = Revision.fromString("r5-0-3");
-        comp.add(c3sync, Revision.fromString("r2-1-0"));
-
-        assertTrue(comp.compare(r1, r2) < 0);
-        assertTrue(comp.compare(r2, c2sync) < 0);
-        // same seen-at revision, but rev timestamp c2sync < c3sync
-        assertTrue(comp.compare(c2sync, c3sync) < 0);
-
-        // this means, c3sync must be after r1 and r2
-        // because: r1 < r2 < c2sync < c3sync
-        assertTrue(comp.compare(r1, c3sync) < 0);
-        assertTrue(comp.compare(r2, c3sync) < 0);
-    }
-
-    @Test
-    public void revisionSeen() {
-        RevisionComparator comp = new RevisionComparator(1);
-        comp.purge(0);
-
-        Revision r0 = new Revision(0x01, 0, 1);
-        Revision r1 = new Revision(0x10, 0, 1);
-        Revision r2 = new Revision(0x20, 0, 1);
-        Revision r21 = new Revision(0x21, 0, 1);
-        Revision r3 = new Revision(0x30, 0, 1);
-        Revision r4 = new Revision(0x40, 0, 1);
-        Revision r5 = new Revision(0x50, 0, 1);
-
-        comp.add(r1, new Revision(0x10, 0, 0));
-        comp.add(r2, new Revision(0x20, 0, 0));
-        comp.add(r3, new Revision(0x30, 0, 0));
-        comp.add(r4, new Revision(0x40, 0, 0));
-
-        // older than first range, but after purge timestamp
-        // -> must return seen-at of first range
-        assertEquals(new Revision(0x10, 0, 0), comp.getRevisionSeen(r0));
-
-        // exact range start matches
-        assertEquals(new Revision(0x10, 0, 0), comp.getRevisionSeen(r1));
-        assertEquals(new Revision(0x20, 0, 0), comp.getRevisionSeen(r2));
-        assertEquals(new Revision(0x30, 0, 0), comp.getRevisionSeen(r3));
-        assertEquals(new Revision(0x40, 0, 0), comp.getRevisionSeen(r4));
-
-        // revision newer than most recent range -> NEWEST
-        assertEquals(RevisionComparator.NEWEST, comp.getRevisionSeen(r5));
-
-        // within a range -> must return lower bound of next higher range
-        assertEquals(new Revision(0x30, 0, 0), comp.getRevisionSeen(r21));
-    }
-
-    // OAK-1814
-    @Test
-    public void seenAtAfterPurge() throws Exception {
-        RevisionComparator comp = new RevisionComparator(1);
-
-        // some revisions from another cluster node
-        Revision r1 = new Revision(0x01, 0, 2);
-        Revision r2 = new Revision(0x02, 0, 2);
-
-        // make them visible
-        comp.add(r1, new Revision(0x01, 0, 0));
-        comp.add(r2, new Revision(0x02, 0, 0));
-
-        comp.purge(0x01);
-
-        // null indicates older than earliest range
-        assertNull(comp.getRevisionSeen(r1));
-        // r2 is still seen at 0x02
-        assertEquals(new Revision(0x02, 0, 0), comp.getRevisionSeen(r2));
-
-        comp.purge(0x02);
-
-        // now also r2 is considered old
-        assertNull(comp.getRevisionSeen(r2));
-    }
-
-    // OAK-1822
-    @Test
-    public void seenAtBeforeFirstRangeAfterPurge() {
-        RevisionComparator comp = new RevisionComparator(1);
-        comp.purge(0);
-
-        Revision r1 = new Revision(1, 0, 1);
-        Revision r2 = new Revision(2, 0, 1);
-        Revision r3 = new Revision(3, 0, 1);
-
-        Revision r3seen = new Revision(3, 0, 0);
-
-        comp.add(r3, r3seen);
-
-        assertEquals(r3seen, comp.getRevisionSeen(r1));
-        assertEquals(r3seen, comp.getRevisionSeen(r2));
-
-        comp.purge(1);
-
-        assertEquals(null, comp.getRevisionSeen(r1));
-        assertEquals(r3seen, comp.getRevisionSeen(r2));
-    }
-
     @Test
     public void uniqueRevision2() throws Exception {
         List<Thread> threads = new ArrayList<Thread>();
@@ -472,59 +230,4 @@ public class RevisionTest {
         }
         assertTrue(String.format("Duplicate rev seen %s %n Seen %s", duplicates, seenRevs), duplicates.isEmpty());
     }
-
-    @Test
-    public void getMinimumTimestamp() {
-        Map<Integer, Long> inactive = Maps.newHashMap();
-        RevisionComparator comp = new RevisionComparator(1);
-
-        Revision r11 = new Revision(1, 0, 1);
-        comp.add(r11, new Revision(1, 0, 0));
-
-        assertEquals(1, comp.getMinimumTimestamp(r11, inactive));
-
-        Revision r21 = new Revision(1, 0, 2);
-        comp.add(r21, new Revision(2, 0, 0));
-
-        assertEquals(1, comp.getMinimumTimestamp(r21, inactive));
-
-        Revision r13 = new Revision(3, 0, 1);
-        comp.add(r13, new Revision(3, 0, 0));
-
-        assertEquals(1, comp.getMinimumTimestamp(r13, inactive));
-
-        Revision r24 = new Revision(4, 0, 2);
-        comp.add(r24, new Revision(4, 0, 0));
-
-        assertEquals(3, comp.getMinimumTimestamp(r24, inactive));
-
-        Revision r15 = new Revision(5, 0, 1);
-        comp.add(r15, new Revision(5, 0, 0));
-
-        assertEquals(4, comp.getMinimumTimestamp(r15, inactive));
-
-        // simulate cluster node 2 is stopped
-        inactive.put(2, 6L);
-
-        Revision r17 = new Revision(7, 0, 1);
-        comp.add(r17, new Revision(7, 0, 0));
-
-        assertEquals(7, comp.getMinimumTimestamp(r17, inactive));
-    }
-
-    // OAK-2318
-    @Test
-    public void getMinimumTimestampSingleClusterId() {
-        Map<Integer, Long> inactive = Maps.newHashMap();
-        RevisionComparator comp = new RevisionComparator(1);
-
-        Revision r1 = new Revision(1, 0, 1);
-        comp.add(r1, new Revision(1, 0, 0));
-
-        assertEquals(1, comp.getMinimumTimestamp(r1, inactive));
-
-        Revision r2 = new Revision(2, 0, 1);
-        assertEquals(2, comp.getMinimumTimestamp(r2, inactive));
-    }
-
 }
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/RevisionVectorTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/RevisionVectorTest.java
new file mode 100644
index 0000000000..ebe11cb747
--- /dev/null
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/RevisionVectorTest.java
@@ -0,0 +1,385 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.plugins.document;
+
+import com.google.common.collect.Iterables;
+import com.google.common.collect.Lists;
+
+import org.junit.Test;
+
+import static com.google.common.collect.Sets.newHashSet;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNotEquals;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertSame;
+import static org.junit.Assert.assertTrue;
+
+public class RevisionVectorTest {
+
+    @Test(expected = IllegalArgumentException.class)
+    public void illegalArgument() {
+        Revision rev1 = new Revision(1, 0, 1);
+        new RevisionVector(rev1, rev1);
+    }
+
+    @Test
+    public void construct() {
+        RevisionVector rv = new RevisionVector();
+        assertEquals(newHashSet(), newHashSet(rv));
+
+        Revision rev1 = new Revision(1, 0, 1);
+        Revision rev2 = new Revision(1, 0, 2);
+        rv = new RevisionVector(newHashSet(rev1, rev2));
+        assertEquals(newHashSet(rev1, rev2), newHashSet(rv));
+
+        rv = new RevisionVector(Lists.newArrayList(rev1, rev2));
+        assertEquals(newHashSet(rev1, rev2), newHashSet(rv));
+    }
+
+    @Test
+    public void update() {
+        Revision rev1 = new Revision(1, 0, 1);
+        RevisionVector rv = new RevisionVector(rev1);
+        assertEquals(1, Iterables.size(rv));
+        assertSame(rv, rv.update(rev1));
+
+        Revision rev2 = new Revision(2, 0, 1);
+        rv = rv.update(rev2);
+        assertEquals(newHashSet(rev2), newHashSet(rv));
+
+        Revision rev3 = new Revision(3, 0, 2);
+        rv = rv.update(rev3);
+        assertEquals(newHashSet(rev2, rev3), newHashSet(rv));
+
+        rev3 = rev3.asBranchRevision();
+        rv = rv.update(rev3);
+        assertEquals(newHashSet(rev2, rev3), newHashSet(rv));
+    }
+
+    @Test
+    public void remove() {
+        RevisionVector rv = new RevisionVector();
+        assertSame(rv, rv.remove(1));
+
+        Revision rev1 = new Revision(1, 0, 1);
+        Revision rev2 = new Revision(1, 0, 2);
+        Revision rev3 = new Revision(1, 0, 3);
+        rv = new RevisionVector(rev1);
+        assertSame(rv, rv.remove(2));
+        assertEquals(new RevisionVector(), rv.remove(rev1.getClusterId()));
+        rv = new RevisionVector(rev1, rev2, rev3);
+        assertEquals(new RevisionVector(rev2, rev3), rv.remove(rev1.getClusterId()));
+        assertEquals(new RevisionVector(rev1, rev3), rv.remove(rev2.getClusterId()));
+        assertEquals(new RevisionVector(rev1, rev2), rv.remove(rev3.getClusterId()));
+    }
+
+    @Test
+    public void isNewer() {
+        Revision rev1 = new Revision(1, 0, 1);
+        Revision rev2 = new Revision(1, 0, 2);
+        Revision rev3 = new Revision(1, 0, 3);
+        RevisionVector rv = new RevisionVector(rev1, rev2);
+
+        assertFalse(rv.isRevisionNewer(rev1));
+        assertFalse(rv.isRevisionNewer(rev2));
+        assertTrue(rv.isRevisionNewer(rev3));
+
+        assertTrue(rv.isRevisionNewer(new Revision(2, 0, 1)));
+        assertTrue(rv.isRevisionNewer(new Revision(2, 0, 2)));
+        assertFalse(rv.isRevisionNewer(new Revision(0, 0, 1)));
+        assertFalse(rv.isRevisionNewer(new Revision(0, 0, 2)));
+    }
+
+    @Test
+    public void pmin() {
+        RevisionVector rv1 = new RevisionVector();
+        RevisionVector rv2 = new RevisionVector();
+        assertEquals(newHashSet(), newHashSet(rv1.pmin(rv2)));
+
+        Revision rev11 = new Revision(1, 0, 1);
+        Revision rev21 = new Revision(2, 0, 1);
+        Revision rev12 = new Revision(1, 0, 2);
+        Revision rev22 = new Revision(2, 0, 2);
+
+        rv1 = rv1.update(rev11);
+        // rv1: [r1-0-1], rv2: []
+        assertEquals(newHashSet(), newHashSet(rv1.pmin(rv2)));
+        assertEquals(newHashSet(), newHashSet(rv2.pmin(rv1)));
+
+        rv2 = rv2.update(rev12);
+        // rv1: [r1-0-1], rv2: [r1-0-2]
+        assertEquals(newHashSet(), newHashSet(rv1.pmin(rv2)));
+        assertEquals(newHashSet(), newHashSet(rv2.pmin(rv1)));
+
+        rv1 = rv1.update(rev12);
+        // rv1: [r1-0-1, r1-0-2], rv2: [r1-0-2]
+        assertEquals(newHashSet(rev12), newHashSet(rv1.pmin(rv2)));
+        assertEquals(newHashSet(rev12), newHashSet(rv2.pmin(rv1)));
+
+        rv2 = rv2.update(rev22);
+        // rv1: [r1-0-1, r1-0-2], rv2: [r2-0-2]
+        assertEquals(newHashSet(rev12), newHashSet(rv1.pmin(rv2)));
+        assertEquals(newHashSet(rev12), newHashSet(rv2.pmin(rv1)));
+
+        rv2 = rv2.update(rev11);
+        // rv1: [r1-0-1, r1-0-2], rv2: [r1-0-1, r2-0-2]
+        assertEquals(newHashSet(rev11, rev12), newHashSet(rv1.pmin(rv2)));
+        assertEquals(newHashSet(rev11, rev12), newHashSet(rv2.pmin(rv1)));
+
+        rv1 = rv1.update(rev21);
+        // rv1: [r2-0-1, r1-0-2], rv2: [r1-0-1, r2-0-2]
+        assertEquals(newHashSet(rev11, rev12), newHashSet(rv1.pmin(rv2)));
+        assertEquals(newHashSet(rev11, rev12), newHashSet(rv2.pmin(rv1)));
+
+        rv1 = rv1.update(rev22);
+        // rv1: [r2-0-1, r2-0-2], rv2: [r1-0-1, r2-0-2]
+        assertEquals(newHashSet(rev11, rev22), newHashSet(rv1.pmin(rv2)));
+        assertEquals(newHashSet(rev11, rev22), newHashSet(rv2.pmin(rv1)));
+
+        rv2 = rv2.update(rev21);
+        // rv1: [r2-0-1, r2-0-2], rv2: [r2-0-1, r2-0-2]
+        assertEquals(newHashSet(rev21, rev22), newHashSet(rv1.pmin(rv2)));
+        assertEquals(newHashSet(rev21, rev22), newHashSet(rv2.pmin(rv1)));
+    }
+
+    @Test
+    public void pmax() {
+        RevisionVector rv1 = new RevisionVector();
+        RevisionVector rv2 = new RevisionVector();
+        assertEquals(newHashSet(), newHashSet(rv1.pmax(rv2)));
+
+        Revision rev11 = new Revision(1, 0, 1);
+        Revision rev21 = new Revision(2, 0, 1);
+        Revision rev12 = new Revision(1, 0, 2);
+        Revision rev22 = new Revision(2, 0, 2);
+
+        rv1 = rv1.update(rev11);
+        // rv1: [r1-0-1], rv2: []
+        assertEquals(newHashSet(rev11), newHashSet(rv1.pmax(rv2)));
+        assertEquals(newHashSet(rev11), newHashSet(rv2.pmax(rv1)));
+
+        rv2 = rv2.update(rev12);
+        // rv1: [r1-0-1], rv2: [r1-0-2]
+        assertEquals(newHashSet(rev11, rev12), newHashSet(rv1.pmax(rv2)));
+        assertEquals(newHashSet(rev11, rev12), newHashSet(rv2.pmax(rv1)));
+
+        rv1 = rv1.update(rev12);
+        // rv1: [r1-0-1, r1-0-2], rv2: [r1-0-2]
+        assertEquals(newHashSet(rev11, rev12), newHashSet(rv1.pmax(rv2)));
+        assertEquals(newHashSet(rev11, rev12), newHashSet(rv2.pmax(rv1)));
+
+        rv2 = rv2.update(rev22);
+        // rv1: [r1-0-1, r1-0-2], rv2: [r2-0-2]
+        assertEquals(newHashSet(rev11, rev22), newHashSet(rv1.pmax(rv2)));
+        assertEquals(newHashSet(rev11, rev22), newHashSet(rv2.pmax(rv1)));
+
+        rv2 = rv2.update(rev11);
+        // rv1: [r1-0-1, r1-0-2], rv2: [r1-0-1, r2-0-2]
+        assertEquals(newHashSet(rev11, rev22), newHashSet(rv1.pmax(rv2)));
+        assertEquals(newHashSet(rev11, rev22), newHashSet(rv2.pmax(rv1)));
+
+        rv1 = rv1.update(rev21);
+        // rv1: [r2-0-1, r1-0-2], rv2: [r1-0-1, r2-0-2]
+        assertEquals(newHashSet(rev21, rev22), newHashSet(rv1.pmax(rv2)));
+        assertEquals(newHashSet(rev21, rev22), newHashSet(rv2.pmax(rv1)));
+
+        rv1 = rv1.update(rev22);
+        // rv1: [r2-0-1, r2-0-2], rv2: [r1-0-1, r2-0-2]
+        assertEquals(newHashSet(rev21, rev22), newHashSet(rv1.pmax(rv2)));
+        assertEquals(newHashSet(rev21, rev22), newHashSet(rv2.pmax(rv1)));
+
+        rv2 = rv2.update(rev21);
+        // rv1: [r2-0-1, r2-0-2], rv2: [r2-0-1, r2-0-2]
+        assertEquals(newHashSet(rev21, rev22), newHashSet(rv1.pmax(rv2)));
+        assertEquals(newHashSet(rev21, rev22), newHashSet(rv2.pmax(rv1)));
+    }
+
+    @Test
+    public void difference() {
+        RevisionVector rv1 = new RevisionVector();
+        RevisionVector rv2 = new RevisionVector();
+        assertEquals(new RevisionVector(), rv1.difference(rv2));
+
+        Revision r11 = new Revision(1, 0, 1);
+        rv1 = rv1.update(r11);
+        // rv1: [r1-0-1]
+        assertEquals(new RevisionVector(r11), rv1.difference(rv2));
+        assertEquals(new RevisionVector(), rv2.difference(rv1));
+
+        rv2 = rv2.update(r11);
+        // rv1: [r1-0-1], rv2: [r1-0-1]
+        assertEquals(new RevisionVector(), rv1.difference(rv2));
+        assertEquals(new RevisionVector(), rv2.difference(rv1));
+
+        Revision r12 = new Revision(1, 0, 2);
+        rv1 = rv1.update(r12);
+        // rv1: [r1-0-1, r1-0-2], rv2: [r1-0-1]
+        assertEquals(new RevisionVector(r12), rv1.difference(rv2));
+        assertEquals(new RevisionVector(), rv2.difference(rv1));
+
+        Revision r22 = new Revision(2, 0, 2);
+        rv2 = rv2.update(r22);
+        // rv1: [r1-0-1, r1-0-2], rv2: [r1-0-1, r2-0-2]
+        assertEquals(new RevisionVector(r12), rv1.difference(rv2));
+        assertEquals(new RevisionVector(r22), rv2.difference(rv1));
+
+        Revision r21 = new Revision(2, 0, 1);
+        rv1 = rv1.update(r21);
+        // rv1: [r2-0-1, r1-0-2], rv2: [r1-0-1, r2-0-2]
+        assertEquals(new RevisionVector(r21, r12), rv1.difference(rv2));
+        assertEquals(new RevisionVector(r11, r22), rv2.difference(rv1));
+    }
+
+    @Test
+    public void isBranch() {
+        RevisionVector rv = new RevisionVector();
+        assertFalse(rv.isBranch());
+        Revision r1 = new Revision(1, 0, 1);
+        rv = rv.update(r1);
+        assertFalse(rv.isBranch());
+        Revision r2 = new Revision(1, 0, 2, true);
+        rv = rv.update(r2);
+        assertTrue(rv.isBranch());
+    }
+
+    @Test
+    public void getBranchRevision() {
+        Revision r1 = new Revision(1, 0, 1);
+        Revision r2 = new Revision(1, 0, 2, true);
+        RevisionVector rv = new RevisionVector(r1, r2);
+        assertEquals(r2, rv.getBranchRevision());
+    }
+
+    @Test(expected = IllegalStateException.class)
+    public void exceptionOnGetBranchRevision() {
+        RevisionVector rv = new RevisionVector();
+        rv.getBranchRevision();
+    }
+
+    @Test
+    public void compareTo() {
+        RevisionVector rv1 = new RevisionVector();
+        RevisionVector rv2 = new RevisionVector();
+        assertEquals(0, rv1.compareTo(rv2));
+
+        Revision r11 = new Revision(1, 0, 1);
+        rv1 = rv1.update(r11); // [r1-0-1]
+        assertTrue(rv1.compareTo(rv2) > 0);
+        assertTrue(rv2.compareTo(rv1) < 0);
+
+        Revision r12 = new Revision(1, 0, 2);
+        rv2 = rv2.update(r12); // [r1-0-2]
+        assertTrue(rv1.compareTo(rv2) > 0);
+        assertTrue(rv2.compareTo(rv1) < 0);
+
+        rv2 = rv2.update(r11); // [r1-0-1, r1-0-2]
+        assertTrue(rv1.compareTo(rv2) < 0);
+        assertTrue(rv2.compareTo(rv1) > 0);
+
+        rv1 = rv1.update(r12); // [r1-0-1, r1-0-2]
+        assertEquals(0, rv1.compareTo(rv2));
+        assertEquals(0, rv2.compareTo(rv1));
+
+        Revision r22 = new Revision(2, 0, 2);
+        rv2 = rv2.update(r22); // [r1-0-1, r2-0-2]
+        assertTrue(rv1.compareTo(rv2) < 0);
+        assertTrue(rv2.compareTo(rv1) > 0);
+
+        Revision rb22 = r22.asBranchRevision();
+        rv1 = rv1.update(rb22);
+        assertTrue(rv1.compareTo(rv2) < 0);
+        assertTrue(rv2.compareTo(rv1) > 0);
+    }
+
+    @Test
+    public void equals() {
+        RevisionVector rv1 = new RevisionVector();
+        RevisionVector rv2 = new RevisionVector();
+        assertEquals(rv1, rv2);
+        Revision r11 = new Revision(1, 0, 1);
+        rv1 = rv1.update(r11);
+        assertNotEquals(rv1, rv2);
+        rv2 = rv2.update(r11);
+        assertEquals(rv1, rv2);
+        Revision r12 = new Revision(1, 0, 2);
+        rv1 = rv1.update(r12);
+        assertNotEquals(rv1, rv2);
+        rv2 = rv2.update(r12);
+        assertEquals(rv1, rv2);
+    }
+
+    @Test
+    public void hashCodeTest() {
+        RevisionVector rv1 = new RevisionVector();
+        RevisionVector rv2 = new RevisionVector();
+        assertEquals(rv1.hashCode(), rv2.hashCode());
+        Revision r11 = new Revision(1, 0, 1);
+        rv1 = rv1.update(r11);
+        rv2 = rv2.update(r11);
+        assertEquals(rv1.hashCode(), rv2.hashCode());
+        Revision r12 = new Revision(1, 0, 2);
+        rv1 = rv1.update(r12);
+        rv2 = rv2.update(r12);
+        assertEquals(rv1.hashCode(), rv2.hashCode());
+    }
+
+    @Test
+    public void getRevision() {
+        RevisionVector rv = new RevisionVector();
+        assertNull(rv.getRevision(1));
+        Revision r11 = new Revision(1, 0, 1);
+        rv = rv.update(r11);
+        assertEquals(r11, rv.getRevision(1));
+        assertNull(rv.getRevision(2));
+        Revision r13 = new Revision(1, 0, 3);
+        rv = rv.update(r13);
+        assertEquals(r13, rv.getRevision(3));
+        assertNull(rv.getRevision(2));
+    }
+
+    @Test
+    public void asTrunkRevision() {
+        RevisionVector rv = new RevisionVector();
+        assertFalse(rv.asTrunkRevision().isBranch());
+        rv = rv.update(new Revision(1, 0, 1, true));
+        assertTrue(rv.isBranch());
+        assertFalse(rv.asTrunkRevision().isBranch());
+    }
+
+    @Test(expected = IllegalArgumentException.class)
+    public void asBranchRevision1() {
+        new RevisionVector().asBranchRevision(1);
+    }
+
+    @Test(expected = IllegalArgumentException.class)
+    public void asBranchRevision2() {
+        new RevisionVector(new Revision(1, 0, 1)).asBranchRevision(2);
+    }
+
+    @Test
+    public void asBranchRevision3() {
+        Revision r11 = new Revision(1, 0, 1);
+        Revision br11 = r11.asBranchRevision();
+        RevisionVector rv = new RevisionVector(r11);
+        assertEquals(new RevisionVector(br11), rv.asBranchRevision(1));
+        rv = rv.asTrunkRevision();
+        Revision r12 = new Revision(1, 0, 2);
+        rv = rv.update(r12);
+        assertEquals(new RevisionVector(br11, r12), rv.asBranchRevision(1));
+    }
+}
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/SimpleTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/SimpleTest.java
index 71dc5b465a..56ca2b759e 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/SimpleTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/SimpleTest.java
@@ -75,12 +75,12 @@ public class SimpleTest {
         DocumentMK mk = builderProvider.newBuilder().open();
         DocumentStore s = mk.getDocumentStore();
         DocumentNodeStore ns = mk.getNodeStore();
-        Revision rev = Revision.fromString(mk.getHeadRevision());
+        RevisionVector rev = RevisionVector.fromString(mk.getHeadRevision());
         DocumentNodeState n = new DocumentNodeState(ns, "/test", rev);
         n.setProperty("name", "\"Hello\"");
-        UpdateOp op = n.asOperation(true);
+        UpdateOp op = n.asOperation(rev.getRevision(ns.getClusterId()));
         // mark as commit root
-        NodeDocument.setRevision(op, rev, "c");
+        NodeDocument.setRevision(op, rev.getRevision(ns.getClusterId()), "c");
         assertTrue(s.create(Collection.NODES, Lists.newArrayList(op)));
         DocumentNodeState n2 = ns.getNode("/test", rev);
         assertNotNull(n2);
@@ -245,11 +245,11 @@ public class SimpleTest {
         String r0 = mk.commit("/test", "+\"a\":{\"name\": \"World\"}", null, null);
         String r1 = mk.commit("/test", "+\"b\":{\"name\": \"!\"}", null, null);
         test = mk.getNodes("/test", r0, 0, 0, Integer.MAX_VALUE, null);
-        DocumentNodeState n = ns.getNode("/", Revision.fromString(r0));
+        DocumentNodeState n = ns.getNode("/", RevisionVector.fromString(r0));
         assertNotNull(n);
         Children c = ns.getChildren(n, null, Integer.MAX_VALUE);
         assertEquals("[test]", c.toString());
-        n = ns.getNode("/test", Revision.fromString(r1));
+        n = ns.getNode("/test", RevisionVector.fromString(r1));
         assertNotNull(n);
         c = ns.getChildren(n, null, Integer.MAX_VALUE);
         assertEquals("[a, b]", c.toString());
@@ -271,19 +271,19 @@ public class SimpleTest {
         mk.commit("/testDel", "+\"b\":{\"name\": \"!\"}", null, null);
         String r1 = mk.commit("/testDel", "+\"c\":{\"name\": \"!\"}", null, null);
 
-        DocumentNodeState n = ns.getNode("/testDel", Revision.fromString(r1));
+        DocumentNodeState n = ns.getNode("/testDel", RevisionVector.fromString(r1));
         assertNotNull(n);
         Children c = ns.getChildren(n, null, Integer.MAX_VALUE);
         assertEquals(3, c.children.size());
 
         String r2 = mk.commit("/testDel", "-\"c\"", null, null);
-        n = ns.getNode("/testDel", Revision.fromString(r2));
+        n = ns.getNode("/testDel", RevisionVector.fromString(r2));
         assertNotNull(n);
         c = ns.getChildren(n, null, Integer.MAX_VALUE);
         assertEquals(2, c.children.size());
 
         String r3 = mk.commit("/", "-\"testDel\"", null, null);
-        n = ns.getNode("/testDel", Revision.fromString(r3));
+        n = ns.getNode("/testDel", RevisionVector.fromString(r3));
         assertNull(n);
     }
 
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranchTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranchTest.java
index 70a919f5b6..018040a6c7 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranchTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranchTest.java
@@ -40,7 +40,9 @@ public class UnmergedBranchTest {
     public void purgeUnmergedBranch() throws Exception {
         DocumentStore testStore = new MemoryDocumentStore();
         DocumentMK mk1 = create(testStore, 1);
+        int cId1 = mk1.getNodeStore().getClusterId();
         DocumentMK mk2 = create(testStore, 2);
+        int cId2 = mk2.getNodeStore().getClusterId();
 
         //1. Create branch commits on both cluster nodes
         String rev1 = mk1.commit("", "+\"/child1\":{}", null, "");
@@ -51,12 +53,12 @@ public class UnmergedBranchTest {
         String branchRev2 = mk2.branch(rev2);
         String brev2 = mk2.commit("/child2", "^\"foo\":1", branchRev2, "");
 
-        Map<Revision, Revision> revs1 = getUncommittedRevisions(mk1);
-        Map<Revision, Revision> revs2 = getUncommittedRevisions(mk2);
+        Map<Revision, RevisionVector> revs1 = getUncommittedRevisions(mk1);
+        Map<Revision, RevisionVector> revs2 = getUncommittedRevisions(mk2);
 
         //2. Assert that branch rev are uncommited
-        assertTrue(revs1.containsKey(Revision.fromString(brev1).asTrunkRevision()));
-        assertTrue(revs2.containsKey(Revision.fromString(brev2).asTrunkRevision()));
+        assertTrue(revs1.containsKey(RevisionVector.fromString(brev1).asTrunkRevision().getRevision(cId1)));
+        assertTrue(revs2.containsKey(RevisionVector.fromString(brev2).asTrunkRevision().getRevision(cId2)));
 
         //3. Restart cluster 1 so that purge happens but only for cluster 1
         mk1.dispose();
@@ -65,23 +67,23 @@ public class UnmergedBranchTest {
         revs2 = getUncommittedRevisions(mk2);
 
         //4. Assert that post restart unmerged branch rev for c1 are purged
-        assertFalse(revs1.containsKey(Revision.fromString(brev1).asTrunkRevision()));
-        assertTrue(revs2.containsKey(Revision.fromString(brev2).asTrunkRevision()));
+        assertFalse(revs1.containsKey(RevisionVector.fromString(brev1).asTrunkRevision().getRevision(cId1)));
+        assertTrue(revs2.containsKey(RevisionVector.fromString(brev2).asTrunkRevision().getRevision(cId2)));
 
     }
 
-    public SortedMap<Revision, Revision> getUncommittedRevisions(DocumentMK mk) {
+    public SortedMap<Revision, RevisionVector> getUncommittedRevisions(DocumentMK mk) {
         // only look at revisions in this document.
         // uncommitted revisions are not split off
         NodeDocument doc = getRootDoc(mk);
         Map<Revision, String> valueMap = doc.getLocalMap(NodeDocument.REVISIONS);
-        SortedMap<Revision, Revision> revisions =
-                new TreeMap<Revision, Revision>(mk.getNodeStore().getRevisionComparator());
+        SortedMap<Revision, RevisionVector> revisions =
+                new TreeMap<Revision, RevisionVector>(StableRevisionComparator.INSTANCE);
         for (Map.Entry<Revision, String> commit : valueMap.entrySet()) {
             if (!Utils.isCommitted(commit.getValue())) {
                 Revision r = commit.getKey();
                 if (r.getClusterId() == mk.getNodeStore().getClusterId()) {
-                    Revision b = Revision.fromString(commit.getValue());
+                    RevisionVector b = RevisionVector.fromString(commit.getValue());
                     revisions.put(r, b);
                 }
             }
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/mongo/CollisionMarkerTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/mongo/CollisionMarkerTest.java
index 2c373e54ba..dadf1cb720 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/mongo/CollisionMarkerTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/mongo/CollisionMarkerTest.java
@@ -75,7 +75,7 @@ public class CollisionMarkerTest extends AbstractMongoConnectionTest {
         b1.child("node").child("foo");
         b1.child("test").setProperty("p", 1);
         merge(ns1, b1);
-        Revision head = ns1.getHeadRevision();
+        Revision head = ns1.getHeadRevision().getRevision(ns1.getClusterId());
 
         NodeBuilder b2 = ns2.getRoot().builder();
         b2.child("node").child("bar");
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/persistentCache/BroadcastTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/persistentCache/BroadcastTest.java
index fba8bbd21f..a3126a276c 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/persistentCache/BroadcastTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/persistentCache/BroadcastTest.java
@@ -32,6 +32,7 @@ import org.apache.commons.io.FileUtils;
 import org.apache.jackrabbit.oak.cache.CacheLIRS;
 import org.apache.jackrabbit.oak.plugins.document.PathRev;
 import org.apache.jackrabbit.oak.plugins.document.Revision;
+import org.apache.jackrabbit.oak.plugins.document.RevisionVector;
 import org.apache.jackrabbit.oak.plugins.document.persistentCache.broadcast.Broadcaster;
 import org.apache.jackrabbit.oak.plugins.document.persistentCache.broadcast.TCPBroadcaster;
 import org.apache.jackrabbit.oak.plugins.document.util.StringValue;
@@ -64,7 +65,7 @@ public class BroadcastTest {
             PersistentCache pc = new PersistentCache("target/broadcastTest/p" + nodes + ",broadcast=" + type);
             Cache<PathRev, StringValue> cache = openCache(pc);
             String key = "/test" + Math.random();
-            PathRev k = new PathRev(key, new Revision(0, 0, 0));
+            PathRev k = new PathRev(key, new RevisionVector(new Revision(0, 0, 0)));
             long time = System.currentTimeMillis();
             for (int i = 0; i < 2000; i++) {
                 cache.put(k, new StringValue("Hello World " + i));
@@ -196,7 +197,7 @@ public class BroadcastTest {
         Cache<PathRev, StringValue> c1 = openCache(p1);
         Cache<PathRev, StringValue> c2 = openCache(p2);
         String key = "/test" + Math.random();
-        PathRev k = new PathRev(key, new Revision(0, 0, 0));
+        PathRev k = new PathRev(key, new RevisionVector(new Revision(0, 0, 0)));
         int correct = 0;
         for (int i = 0; i < 50; i++) {
             c1.put(k, new StringValue("Hello World " + i));
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/persistentCache/CacheTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/persistentCache/CacheTest.java
index 8692877640..d97b85487c 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/persistentCache/CacheTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/persistentCache/CacheTest.java
@@ -32,6 +32,7 @@ import org.apache.commons.io.FileUtils;
 import org.apache.jackrabbit.oak.cache.CacheLIRS;
 import org.apache.jackrabbit.oak.plugins.document.PathRev;
 import org.apache.jackrabbit.oak.plugins.document.Revision;
+import org.apache.jackrabbit.oak.plugins.document.RevisionVector;
 import org.apache.jackrabbit.oak.plugins.document.util.StringValue;
 import org.apache.jackrabbit.oak.spi.blob.BlobStore;
 import org.apache.jackrabbit.oak.spi.blob.MemoryBlobStore;
@@ -57,7 +58,7 @@ public class CacheTest {
                 Thread.yield();
             }
             for (int i = 0; i < 100; i++) {
-                PathRev k = new PathRev("/" + counter, new Revision(0, 0, i));
+                PathRev k = new PathRev("/" + counter, new RevisionVector(new Revision(0, 0, i)));
                 map.getIfPresent(k);
                 map.put(k, new StringValue(largeString));
             }
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/util/RevisionsKeyTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/util/RevisionsKeyTest.java
index 3883e2088a..0599dec383 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/util/RevisionsKeyTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/util/RevisionsKeyTest.java
@@ -17,6 +17,7 @@
 package org.apache.jackrabbit.oak.plugins.document.util;
 
 import org.apache.jackrabbit.oak.plugins.document.Revision;
+import org.apache.jackrabbit.oak.plugins.document.RevisionVector;
 import org.junit.Test;
 
 import static org.junit.Assert.assertEquals;
@@ -29,7 +30,8 @@ public class RevisionsKeyTest {
     @Test
     public void fromAsString() {
         RevisionsKey k1 = new RevisionsKey(
-                new Revision(1, 0, 1), new Revision(2, 1, 2));
+                new RevisionVector(new Revision(1, 0, 1)),
+                new RevisionVector(new Revision(2, 1, 2)));
         RevisionsKey k2 = RevisionsKey.fromString(k1.asString());
         assertEquals(k1, k2);
     }
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/util/UtilsTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/util/UtilsTest.java
index abdbeb263c..8f2a7e62d4 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/util/UtilsTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/util/UtilsTest.java
@@ -27,6 +27,7 @@ import org.apache.jackrabbit.oak.commons.PathUtils;
 import org.apache.jackrabbit.oak.plugins.document.DocumentMK;
 import org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore;
 import org.apache.jackrabbit.oak.plugins.document.Revision;
+import org.apache.jackrabbit.oak.plugins.document.RevisionVector;
 import org.apache.jackrabbit.oak.spi.commit.CommitInfo;
 import org.apache.jackrabbit.oak.spi.commit.EmptyHook;
 import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
@@ -125,6 +126,20 @@ public class UtilsTest {
         assertNull(Utils.max(null, null));
     }
 
+    @Test
+    public void min() {
+        Revision a = new Revision(42, 1, 1);
+        Revision b = new Revision(43, 0, 1);
+        assertSame(a, Utils.min(a, b));
+
+        Revision a1 = new Revision(42, 0, 1);
+        assertSame(a1, Utils.min(a, a1));
+
+        assertSame(a, Utils.min(a, null));
+        assertSame(a, Utils.min(null, a));
+        assertNull(Utils.max(null, null));
+    }
+
     @Test
     public void getAllDocuments() throws CommitFailedException {
         DocumentNodeStore store = new DocumentMK.Builder().getNodeStore();
@@ -179,4 +194,24 @@ public class UtilsTest {
         revTime = Utils.getMaxExternalTimestamp(revs, localClusterId);
         assertEquals(3, revTime);
     }
+
+    @Test
+    public void getMinTimestampForDiff() {
+        RevisionVector from = new RevisionVector(new Revision(17, 0, 1));
+        RevisionVector to = new RevisionVector(new Revision(19, 0, 1));
+        assertEquals(17, Utils.getMinTimestampForDiff(from, to, new RevisionVector()));
+        assertEquals(17, Utils.getMinTimestampForDiff(to, from, new RevisionVector()));
+
+        RevisionVector minRevs = new RevisionVector(
+                new Revision(7, 0, 1),
+                new Revision(4, 0, 2));
+        assertEquals(17, Utils.getMinTimestampForDiff(from, to, minRevs));
+        assertEquals(17, Utils.getMinTimestampForDiff(to, from, minRevs));
+
+        to = to.update(new Revision(15, 0, 2));
+        // must return min revision of clusterId 2
+        assertEquals(4, Utils.getMinTimestampForDiff(from, to, minRevs));
+        assertEquals(4, Utils.getMinTimestampForDiff(to, from, minRevs));
+
+    }
 }
