diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/core/ContentRepositoryImpl.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/core/ContentRepositoryImpl.java
index 7eaef21b1a..5d473ed630 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/core/ContentRepositoryImpl.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/core/ContentRepositoryImpl.java
@@ -89,7 +89,6 @@ import org.apache.jackrabbit.commons.SimpleValueFactory;
 import org.apache.jackrabbit.oak.api.ContentRepository;
 import org.apache.jackrabbit.oak.api.ContentSession;
 import org.apache.jackrabbit.oak.api.Descriptors;
-import org.apache.jackrabbit.oak.kernel.KernelNodeStore;
 import org.apache.jackrabbit.oak.query.QueryEngineSettings;
 import org.apache.jackrabbit.oak.spi.commit.CommitHook;
 import org.apache.jackrabbit.oak.spi.query.CompositeQueryIndexProvider;
@@ -226,8 +225,7 @@ public class ContentRepositoryImpl implements ContentRepository, Closeable {
                 // locking support added via JCR layer
                 .put(OPTION_LOCKING_SUPPORTED, falseValue, true, true)
                 .put(OPTION_OBSERVATION_SUPPORTED, trueValue, true, true)
-                .put(OPTION_NODE_AND_PROPERTY_WITH_SAME_NAME_SUPPORTED,
-                        supportsSameNameNodeAndProperties() ? trueValue : falseValue, true, true)
+                .put(OPTION_NODE_AND_PROPERTY_WITH_SAME_NAME_SUPPORTED, trueValue, true, true)
                 .put(OPTION_QUERY_SQL_SUPPORTED, falseValue, true, true)
                 .put(OPTION_RETENTION_SUPPORTED, falseValue, true, true)
                 .put(OPTION_SHAREABLE_NODES_SUPPORTED, falseValue, true, true)
@@ -278,16 +276,6 @@ public class ContentRepositoryImpl implements ContentRepository, Closeable {
         return gd;
     }
 
-    /**
-     * Checks if this repository supports same name node and properties. currently this is tied to the underlying
-     * node store implementation class.
-     *
-     * @return {@code true} if this repository supports SNNP.
-     */
-    private boolean supportsSameNameNodeAndProperties() {
-        return !(nodeStore instanceof KernelNodeStore);
-    }
-
     /**
      * Returns the version of this repository implementation.
      * @return the version
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/core/SecureNodeBuilder.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/core/SecureNodeBuilder.java
index d3f447c8d1..1d31c830cd 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/core/SecureNodeBuilder.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/core/SecureNodeBuilder.java
@@ -16,6 +16,16 @@
  */
 package org.apache.jackrabbit.oak.core;
 
+import static com.google.common.base.Preconditions.checkNotNull;
+import static com.google.common.base.Preconditions.checkState;
+import static com.google.common.collect.Iterables.filter;
+import static com.google.common.collect.Iterables.size;
+import static java.util.Collections.emptyList;
+import static org.apache.jackrabbit.oak.api.Type.BOOLEAN;
+import static org.apache.jackrabbit.oak.api.Type.NAME;
+import static org.apache.jackrabbit.oak.api.Type.NAMES;
+import static org.apache.jackrabbit.oak.api.Type.STRING;
+
 import java.io.IOException;
 import java.io.InputStream;
 
@@ -24,12 +34,9 @@ import javax.annotation.Nonnull;
 import javax.annotation.Nullable;
 
 import com.google.common.base.Predicate;
-
 import org.apache.jackrabbit.oak.api.Blob;
 import org.apache.jackrabbit.oak.api.PropertyState;
 import org.apache.jackrabbit.oak.api.Type;
-import org.apache.jackrabbit.oak.kernel.FastMove;
-import org.apache.jackrabbit.oak.kernel.KernelNodeBuilder;
 import org.apache.jackrabbit.oak.plugins.tree.ImmutableTree;
 import org.apache.jackrabbit.oak.spi.security.Context;
 import org.apache.jackrabbit.oak.spi.security.authorization.permission.PermissionProvider;
@@ -37,17 +44,7 @@ import org.apache.jackrabbit.oak.spi.security.authorization.permission.TreePermi
 import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
 import org.apache.jackrabbit.oak.spi.state.NodeState;
 
-import static com.google.common.base.Preconditions.checkNotNull;
-import static com.google.common.base.Preconditions.checkState;
-import static com.google.common.collect.Iterables.filter;
-import static com.google.common.collect.Iterables.size;
-import static java.util.Collections.emptyList;
-import static org.apache.jackrabbit.oak.api.Type.BOOLEAN;
-import static org.apache.jackrabbit.oak.api.Type.NAME;
-import static org.apache.jackrabbit.oak.api.Type.NAMES;
-import static org.apache.jackrabbit.oak.api.Type.STRING;
-
-class SecureNodeBuilder implements NodeBuilder, FastMove {
+class SecureNodeBuilder implements NodeBuilder {
 
     /**
      * Root builder, or {@code this} for the root builder itself.
@@ -343,18 +340,6 @@ class SecureNodeBuilder implements NodeBuilder, FastMove {
         return builder.createBlob(stream);
     }
 
-    /**
-     * This implementation simply delegates back to {@code moveTo} method
-     * of {@code source} passing the underlying builder for {@code newParent}.
-     * @param source  source to move to this builder
-     * @param newName  the new name
-     * @return
-     */
-    @Override
-    public boolean moveFrom(KernelNodeBuilder source, String newName) {
-        return source.moveTo(builder, newName);
-    }
-
     /**
      * Permissions of this tree.
      *
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/FastMove.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/FastMove.java
deleted file mode 100644
index f68dc1c834..0000000000
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/FastMove.java
+++ /dev/null
@@ -1,37 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.apache.jackrabbit.oak.kernel;
-
-/**
- * This interface is intended to be implemented by
- * {@link org.apache.jackrabbit.oak.spi.state.NodeBuilder} implementations to indicate
- * support for optimised move and copy operations.
- */
-public interface FastMove {
-
-    /**
-     * Move the {@code source} builder to this builder with the
-     * given new name
-     * @param source  source to move to this builder
-     * @param newName  the new name
-     * @return  {@code true} on success, {@code false} otherwise
-     */
-    boolean moveFrom(KernelNodeBuilder source, String newName);
-}
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelBlob.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelBlob.java
deleted file mode 100644
index 84fe825a7c..0000000000
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelBlob.java
+++ /dev/null
@@ -1,94 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.jackrabbit.oak.kernel;
-
-import java.io.InputStream;
-
-import javax.annotation.Nonnull;
-
-import org.apache.jackrabbit.mk.api.MicroKernel;
-import org.apache.jackrabbit.oak.commons.mk.MicroKernelInputStream;
-import org.apache.jackrabbit.oak.plugins.memory.AbstractBlob;
-
-/**
- * This {@code Blob} implementation is backed by a binary stored in
- * a {@code MicroKernel}.
- */
-public class KernelBlob extends AbstractBlob {
-    private final String binaryID;
-    private final MicroKernel kernel;
-
-    /**
-     * The id returned from {@link MicroKernel#write(java.io.InputStream)}
-     * @return  the binary id of this blob
-     */
-    public String getBinaryID() {
-        return binaryID;
-    }
-
-    /**
-     * Create a new instance for a binary id and a Microkernel.
-     * @param binaryID  id of the binary
-     * @param kernel
-     */
-    public KernelBlob(String binaryID, MicroKernel kernel) {
-        this.binaryID = binaryID;
-        this.kernel = kernel;
-    }
-
-    @Nonnull
-    @Override
-    public InputStream getNewStream() {
-        return new MicroKernelInputStream(kernel, binaryID);
-    }
-
-    /**
-     * This implementation delegates the calculation of the length back
-     * to the underlying {@code MicroKernel}.
-     */
-    @Override
-    public long length() {
-        return kernel.getLength(binaryID);
-    }
-
-    @Override
-    public String getReference() {
-        return binaryID;
-    }
-
-    @Override
-    public String getContentIdentity() {
-        return binaryID;
-    }
-
-    /**
-     * This implementation delegates back to the underlying {@code Microkernel}
-     * if other is also of type {@code KernelBlob}.
-     */
-    @Override
-    public boolean equals(Object other) {
-        if (this == other) {
-            return true;
-        }
-        if (other instanceof KernelBlob) {
-            KernelBlob that = (KernelBlob) other;
-            return binaryID.equals(that.binaryID);
-        }
-
-        return super.equals(other);
-    }
-}
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeBuilder.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeBuilder.java
deleted file mode 100644
index bdc08bbd0a..0000000000
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeBuilder.java
+++ /dev/null
@@ -1,95 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.jackrabbit.oak.kernel;
-
-import org.apache.jackrabbit.oak.commons.PathUtils;
-import org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder;
-import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
-import org.apache.jackrabbit.oak.spi.state.NodeState;
-
-import static com.google.common.base.Preconditions.checkNotNull;
-import static org.apache.jackrabbit.oak.spi.state.AbstractNodeState.checkValidName;
-
-/**
- * This class refines move and copy operations by delegating
- * them to the underlying store if possible.
- * @see KernelRootBuilder
- */
-public class KernelNodeBuilder extends MemoryNodeBuilder implements FastMove {
-
-    private final KernelRootBuilder root;
-
-    private NodeState base = null;
-
-    private NodeState rootBase = null;
-
-    KernelNodeBuilder(MemoryNodeBuilder parent, String name, KernelRootBuilder root) {
-        super(parent, name);
-        this.root = checkNotNull(root);
-    }
-
-    //--------------------------------------------------< MemoryNodeBuilder >---
-
-    @Override
-    protected MemoryNodeBuilder createChildBuilder(String name) {
-        return new KernelNodeBuilder(this, name, root);
-    }
-
-    @Override
-    public NodeState getBaseState() {
-        if (base == null || rootBase != root.getBaseState()) {
-            base = getParent().getBaseState().getChildNode(getName());
-            rootBase = root.getBaseState();
-        }
-        return base;
-    }
-
-    @Override
-    public void reset(NodeState newBase) {
-        throw new IllegalStateException("Cannot reset a non-root builder");
-    }
-
-    /**
-     * If {@code newParent} is a {@link KernelNodeBuilder} this implementation
-     * purges all pending changes before applying the move operation. This allows the
-     * underlying store to better optimise move operations instead of just seeing
-     * them as an added and a removed node.
-     * If {@code newParent} is not a {@code KernelNodeBuilder} the implementation
-     * falls back to the super class.
-     */
-    @Override
-    public boolean moveTo(NodeBuilder newParent, String newName) {
-        if (newParent instanceof FastMove) {
-            checkNotNull(newParent);
-            checkValidName(newName);
-            annotateSourcePath();
-            boolean success = !isRoot() && exists() && !newParent.hasChildNode(newName) &&
-                    ((FastMove) newParent).moveFrom(this, newName);
-            return success;
-        } else {
-            return super.moveTo(newParent, newName);
-        }
-    }
-
-    @Override
-    public boolean moveFrom(KernelNodeBuilder source, String newName) {
-        String sourcePath = source.getPath();
-        String destPath = PathUtils.concat(getPath(), newName);
-        return root.move(sourcePath, destPath);
-    }
-
-}
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeState.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeState.java
deleted file mode 100644
index ab9ba8b63b..0000000000
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeState.java
+++ /dev/null
@@ -1,882 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.kernel;
-
-import static com.google.common.base.Preconditions.checkNotNull;
-import static java.util.Collections.emptyList;
-import static org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.EMPTY_NODE;
-import static org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.MISSING_NODE;
-import static org.apache.jackrabbit.oak.plugins.memory.PropertyStates.createProperty;
-
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.LinkedHashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.ExecutionException;
-
-import javax.annotation.Nonnull;
-import javax.jcr.PropertyType;
-
-import com.google.common.base.Function;
-import com.google.common.cache.CacheBuilder;
-import com.google.common.cache.CacheLoader;
-import com.google.common.cache.LoadingCache;
-import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
-
-import org.apache.jackrabbit.mk.api.MicroKernel;
-import org.apache.jackrabbit.mk.api.MicroKernelException;
-import org.apache.jackrabbit.oak.cache.StringCache;
-import org.apache.jackrabbit.oak.commons.json.JsopReader;
-import org.apache.jackrabbit.oak.commons.json.JsopTokenizer;
-import org.apache.jackrabbit.oak.api.PropertyState;
-import org.apache.jackrabbit.oak.api.Type;
-import org.apache.jackrabbit.oak.commons.PathUtils;
-import org.apache.jackrabbit.oak.json.TypeCodes;
-import org.apache.jackrabbit.oak.plugins.memory.BinaryPropertyState;
-import org.apache.jackrabbit.oak.plugins.memory.BooleanPropertyState;
-import org.apache.jackrabbit.oak.plugins.memory.DoublePropertyState;
-import org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState;
-import org.apache.jackrabbit.oak.plugins.memory.LongPropertyState;
-import org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder;
-import org.apache.jackrabbit.oak.plugins.memory.PropertyStates;
-import org.apache.jackrabbit.oak.plugins.memory.StringPropertyState;
-import org.apache.jackrabbit.oak.plugins.value.Conversions;
-import org.apache.jackrabbit.oak.spi.state.AbstractChildNodeEntry;
-import org.apache.jackrabbit.oak.spi.state.AbstractNodeState;
-import org.apache.jackrabbit.oak.spi.state.ChildNodeEntry;
-import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
-import org.apache.jackrabbit.oak.spi.state.NodeState;
-import org.apache.jackrabbit.oak.spi.state.NodeStateDiff;
-
-/**
- * Basic {@link NodeState} implementation based on the {@link MicroKernel}
- * interface. This class makes an attempt to load data lazily.
- */
-public final class KernelNodeState extends AbstractNodeState {
-
-    /**
-     * Maximum number of child nodes kept in memory.
-     */
-    public static final int MAX_CHILD_NAMES = 100;
-
-    /**
-     * Number of child nodes beyond which {@link MicroKernel#diff(String, String, String, int)}
-     * is used for diffing.
-     */
-    public static final int LOCAL_DIFF_THRESHOLD = 10;
-
-    /**
-     * Dummy cache instance for static {@link #NULL} kernel node state.
-     */
-    private static final LoadingCache<String, KernelNodeState> DUMMY_CACHE =
-        CacheBuilder.newBuilder().build(new CacheLoader<String, KernelNodeState>() {
-            @Override
-            public KernelNodeState load(String key) throws Exception {
-                throw new UnsupportedOperationException();
-            }
-        });
-
-    /**
-     * This {@code NULL} kernel node state is used as a value in the
-     * {@link #cache} to indicate that there is no node state at the given
-     * path and revision. This object is only used internally and never leaves
-     * this {@link KernelNodeState}.
-     */
-    private static final KernelNodeState NULL = new KernelNodeState();
-
-    private final KernelNodeStore store;
-
-    private final MicroKernel kernel;
-
-    private final String path;
-
-    private String revision;
-
-    private Map<String, PropertyState> properties;
-
-    private long childNodeCount = -1;
-
-    private long childNodeCountMin;
-
-    private String hash;
-
-    private String id;
-
-    private Set<String> childNames;
-
-    /**
-     * {@code true} is this is a node state from a branch. {@code false}
-     * otherwise.
-     * <p>
-     * FIXME: this is a workaround to avoid creating branches from a branch
-     * until this is supported by the MicroKernel. See {@link KernelNodeState#builder()}.
-     */
-    private boolean isBranch;
-
-    private final LoadingCache<String, KernelNodeState> cache;
-
-    /**
-     * Create a new instance of this class representing the node at the
-     * given {@code path} and {@code revision}. It is an error if the
-     * underlying Microkernel does not contain such a node.
-     *
-     * @param store the underlying KernelNodeStore
-     * @param path the path of this KernelNodeState
-     * @param revision the revision of the node to read from the kernel.
-     * @param cache the KernelNodeState cache
-     */
-    public KernelNodeState(
-            KernelNodeStore store, String path, String revision,
-            LoadingCache<String, KernelNodeState> cache) {
-        this.store = store;
-        this.kernel = store.getKernel();
-        this.path = checkNotNull(path);
-        this.revision = checkNotNull(revision);
-        this.cache = checkNotNull(cache);
-    }
-
-    private KernelNodeState() {
-        this.store = null;
-        this.kernel = null;
-        this.path = "null";
-        this.revision = "null";
-        this.cache = DUMMY_CACHE;
-    }
-
-    private void init() {
-        boolean initialized = false;
-        synchronized (this) {
-            if (properties == null) {
-                String json = kernel.getNodes(
-                        path, revision, 0, 0, MAX_CHILD_NAMES,
-                        "{\"properties\":[\"*\",\":hash\",\":id\"]}");
-
-                checkNotNull(json,"No node found at path [%s] for revision [%s]",path,revision);
-                JsopReader reader = new JsopTokenizer(json);
-                reader.read('{');
-                properties = new LinkedHashMap<String, PropertyState>();
-                childNames = new LinkedHashSet<String>();
-                do {
-                    String name = StringCache.get(reader.readString());
-                    reader.read(':');
-                    if (":childNodeCount".equals(name)) {
-                        childNodeCount =
-                                Long.valueOf(reader.read(JsopReader.NUMBER));
-                    } else if (":hash".equals(name)) {
-                        hash = new String(reader.read(JsopReader.STRING));
-                        if (hash.equals(id)) {
-                            // save some memory
-                            hash = id;
-                        }
-                    } else if (":id".equals(name)) {
-                        id = new String(reader.read(JsopReader.STRING));
-                        if (id.equals(hash)) {
-                            // save some memory
-                            id = hash;
-                        }
-                    } else if (reader.matches('{')) {
-                        reader.read('}');
-                        childNames.add(name);
-                    } else if (reader.matches('[')) {
-                        properties.put(name, readArrayProperty(name, reader));
-                    } else {
-                        properties.put(name, readProperty(name, reader));
-                    }
-                } while (reader.matches(','));
-                reader.read('}');
-                reader.read(JsopReader.END);
-                // optimize for empty childNodes
-                if (childNames.isEmpty()) {
-                    childNames = Collections.emptySet();
-                }
-                initialized = true;
-            }
-        }
-        if (initialized) {
-            // refresh cache to force re-calculation of weight (OAK-643)
-            cache.refresh(revision + path);
-        }
-        if (initialized && !PathUtils.denotesRoot(path)) {
-            // OAK-591: check if we can re-use a previous revision
-            // by looking up the node state by hash or id (if available)
-            // introducing this secondary lookup basically means we point
-            // back to a subtree in an older revision, in case it didn't change
-            String hashOrId = null;
-            if (hash != null) {
-                // hash takes precedence
-                hashOrId = hash;
-            } else if (id != null) {
-                hashOrId = id;
-            }
-            if (hashOrId != null) {
-                KernelNodeState cached = cache.getIfPresent(hashOrId);
-                if (cached != null && cached.path.equals(this.path)) {
-                    synchronized (this) {
-                        this.revision = cached.revision;
-                        this.childNames = cached.childNames;
-                        this.properties = cached.properties;
-                    }
-                } else {
-                    // store under secondary key
-                    cache.put(hashOrId, this);
-                }
-            }
-        }
-    }
-
-    @Override
-    public boolean exists() {
-        return true;
-    }
-
-    @Override
-    public long getPropertyCount() {
-        init();
-        return properties.size();
-    }
-
-    @Override
-    public boolean hasProperty(String name) {
-        init();
-        return properties.containsKey(name);
-    }
-
-    @Override
-    public PropertyState getProperty(String name) {
-        init();
-        return properties.get(name);
-    }
-
-    @Override
-    public Iterable<? extends PropertyState> getProperties() {
-        init();
-        return properties.values();
-    }
-    
-    @Override
-    public long getChildNodeCount(long max) {
-        init();
-        if (childNodeCount == Long.MAX_VALUE) {
-            if (childNodeCountMin > max) {
-                // getChildNodeCount(max) was already called,
-                // and we know the value is higher than max
-                return childNodeCountMin;
-            }
-            // count the entries
-            Iterator<? extends ChildNodeEntry> iterator = getChildNodeEntries().iterator();
-            long n = 0;
-            while (n <= max) {
-                if (!iterator.hasNext()) {
-                    // we know the exact number now
-                    childNodeCount = n;
-                    return n;
-                }
-                iterator.next();
-                n++;
-            }
-            // remember we have at least this number of entries
-            childNodeCountMin = n;
-            if (n == max) {
-                // we didn't count all entries
-                return max;
-            }
-        }
-        return childNodeCount;
-    }
-
-    @Override
-    public boolean hasChildNode(String name) {
-        init();
-        if (childNames.contains(name)) {
-            return true; // the named child node exits for sure
-        } else if (getChildNodeCount(MAX_CHILD_NAMES) <= MAX_CHILD_NAMES) {
-            return false; // all child node names are cached, and none match
-        } else {
-            return isValidName(name) && getChildNode(name).exists();
-        }
-    }
-
-    @Override
-    public NodeState getChildNode(String name) {
-        init();
-        String childPath = null;
-        if (childNames.contains(name)) {
-            childPath = PathUtils.concat(path, name);
-        } else if (!isValidName(name)) {
-            throw new IllegalArgumentException("Invalid name: " + name);
-        } else if (getChildNodeCount(MAX_CHILD_NAMES) <= MAX_CHILD_NAMES) {
-            return MISSING_NODE;
-        } else {
-            childPath = PathUtils.concat(path, name);
-            // OAK-506: Avoid the nodeExists() call when already cached
-            NodeState state = cache.getIfPresent(revision + childPath);
-            if (state == NULL) {
-                return MISSING_NODE;
-            } else if (state != null) {
-                return state;
-            }
-            // not able to tell from cache if node exists
-            // need to ask MicroKernel
-            if (!kernel.nodeExists(childPath, revision)) {
-                cache.put(revision + childPath, NULL);
-                return MISSING_NODE;
-            }
-        }
-        try {
-            return cache.get(revision + childPath);
-        } catch (ExecutionException e) {
-            throw new MicroKernelException(e);
-        }
-    }
-
-    @Override
-    public Iterable<? extends ChildNodeEntry> getChildNodeEntries() {
-        init();
-        if (childNodeCount <= MAX_CHILD_NAMES && childNodeCount <= childNames.size()) {
-            return iterable(childNames);
-        }
-        List<Iterable<ChildNodeEntry>> iterables = Lists.newArrayList();
-        iterables.add(iterable(childNames));
-        iterables.add(getChildNodeEntries(childNames.size()));
-        return Iterables.concat(iterables);
-    }
-
-    private Iterable<ChildNodeEntry> getChildNodeEntries(final long offset) {
-        return new Iterable<ChildNodeEntry>() {
-            @Override
-            public Iterator<ChildNodeEntry> iterator() {
-                return new Iterator<ChildNodeEntry>() {
-                    private long currentOffset = offset;
-                    private Iterator<ChildNodeEntry> current;
-
-                    {
-                        fetchEntries();
-                    }
-
-                    private void fetchEntries() {
-                        List<ChildNodeEntry> entries = Lists
-                                .newArrayListWithCapacity(MAX_CHILD_NAMES);
-                        String json = kernel.getNodes(path, revision, 0,
-                                currentOffset, MAX_CHILD_NAMES, null);
-                        JsopReader reader = new JsopTokenizer(json);
-                        reader.read('{');
-                        do {
-                            String name = StringCache.get(reader.readString());
-                            reader.read(':');
-                            if (reader.matches('{')) {
-                                reader.read('}');
-                                entries.add(new KernelChildNodeEntry(name));
-                            } else if (reader.matches('[')) {
-                                while (reader.read() != ']') {
-                                    // skip
-                                }
-                            } else {
-                                reader.read();
-                            }
-                        } while (reader.matches(','));
-                        reader.read('}');
-                        reader.read(JsopReader.END);
-                        if (entries.isEmpty()) {
-                            current = null;
-                        } else {
-                            currentOffset += entries.size();
-                            current = entries.iterator();
-                        }
-                    }
-
-                    @Override
-                    public boolean hasNext() {
-                        while (true) {
-                            if (current == null) {
-                                return false;
-                            } else if (current.hasNext()) {
-                                return true;
-                            }
-                            fetchEntries();
-                        }
-                    }
-
-                    @Override
-                    public ChildNodeEntry next() {
-                        if (!hasNext()) {
-                            throw new IllegalStateException(
-                                    "Reading past the end");
-                        }
-                        return current.next();
-                    }
-
-                    @Override
-                    public void remove() {
-                        throw new UnsupportedOperationException();
-                    }
-                    
-                };
-            }
-        };
-    }
-
-    /**
-     * This implementation returns a {@link KernelNodeBuilder} unless this is not
-     * a root node or {@link #isBranch} is {@code true} in which case a
-     * {@link MemoryNodeBuilder} is returned.
-     * <p>
-     * TODO: this is a workaround to avoid creating branches from a branch
-     * until this is supported by the MicroKernel.
-     */
-    @Override
-    public NodeBuilder builder() {
-        if (isBranch) {
-            return new MemoryNodeBuilder(this);
-        } else if ("/".equals(path)) {
-            return new KernelRootBuilder(this, store);
-        } else {
-            return new MemoryNodeBuilder(this);
-        }
-    }
-
-    /**
-     * Optimised comparison method that can avoid traversing all properties
-     * and child nodes if both this and the given base node state come from
-     * the same MicroKernel and either have the same content hash (when
-     * available) or are located at the same path in different revisions.
-     *
-     * @see <a href="https://issues.apache.org/jira/browse/OAK-175">OAK-175</a>
-     */
-    @Override
-    public boolean compareAgainstBaseState(NodeState base, NodeStateDiff diff) {
-        if (this == base) {
-            return true; // no differences
-        } else if (base == EMPTY_NODE || !base.exists()) { // special case
-            return EmptyNodeState.compareAgainstEmptyState(this, diff);
-        } else if (base instanceof KernelNodeState) {
-            KernelNodeState kbase = (KernelNodeState) base;
-            if (kernel.equals(kbase.kernel)) {
-                if (revision.equals(kbase.revision) && path.equals(kbase.path)) {
-                    return true; // no differences
-                } else {
-                    init();
-                    kbase.init();
-                    if (hash != null && hash.equals(kbase.hash)) {
-                        return true; // no differences
-                    } else if (id != null && id.equals(kbase.id)) {
-                        return true; // no differences
-                    } else if (path.equals(kbase.path)
-                            && getChildNodeCount(LOCAL_DIFF_THRESHOLD) > LOCAL_DIFF_THRESHOLD) {
-                        // use MK.diff() when there are 'many' child nodes
-                        String jsonDiff = kernel.diff(kbase.getRevision(), revision, path, 0);
-                        return processJsonDiff(jsonDiff, kbase, diff);
-                    }
-                }
-            }
-        }
-        // fall back to the generic node state diff algorithm
-        return super.compareAgainstBaseState(base, diff);
-    }
-
-    //------------------------------------------------------------< Object >--
-
-    /**
-     * Optimised equality check that can avoid a full tree comparison if
-     * both instances come from the same MicroKernel and have either
-     * the same revision and path or the same content hash (when available).
-     * Otherwise we fall back to the default tree comparison algorithm.
-     *
-     * @see <a href="https://issues.apache.org/jira/browse/OAK-172">OAK-172</a>
-     */
-    @Override
-    public boolean equals(Object object) {
-        if (this == object) {
-            return true;
-        } else if (object instanceof KernelNodeState) {
-            KernelNodeState that = (KernelNodeState) object;
-            if (kernel.equals(that.kernel)) {
-                if (revision.equals(that.revision) && path.equals(that.path)) {
-                    return true;
-                } else {
-                    this.init();
-                    that.init();
-                    if (hash != null && that.hash != null) {
-                        return hash.equals(that.hash);
-                    } else if (id != null && id.equals(that.id)) {
-                        // only return result of equals if ids are equal
-                        // different ids doesn't mean the node states are
-                        // definitively different.
-                        return true;
-                    } else if (path.equals(that.path) && !path.equals("/")) {
-                        String r1 = revision, r2 = that.getRevision();
-                        if (r1.compareTo(r2) > 0) {
-                            // sort the revisions, to allow the MicroKernel to cache the result
-                            String temp = r1;
-                            r1 = r2;
-                            r2 = temp;
-                        }
-                        String jsonDiff = kernel.diff(r1, r2, path, 0);
-                        return !hasChanges(jsonDiff);
-                    }
-                }
-            }
-        }
-        // fall back to the generic tree equality comparison algorithm
-        return super.equals(object);
-    }
-
-    //------------------------------------------------------------< internal >---
-
-    @Nonnull
-    String getRevision() {
-        return revision;
-    }
-
-    /**
-     * Mark this instance as from being on branch.
-     * <p>
-     * TODO this is a workaround to avoid creating branches from a branch
-     * until this is supported by the MicroKernel. See {@link KernelNodeState#builder()}.
-     * @return {@code this}
-     */
-    KernelNodeState setBranch() {
-        isBranch = true;
-        return this;
-    }
-
-    /**
-     * @return  {@code true} if this instance has been marked as being on a branch by a call
-     * to {@link #setBranch()}
-     */
-    boolean isBranch() {
-        return isBranch;
-    }
-
-    /**
-     * @return the approximate memory usage of this node state.
-     */
-    synchronized int getMemory() {
-        // base memory footprint is roughly 64 bytes
-        int memory = 64;
-        // path String
-        memory += 48 + path.length() * 2;
-        // revision String
-        memory += 48 + revision.length() * 2;
-        // optional hash String
-        if (hash != null) {
-            memory += 48 + hash.length() * 2;
-        }
-        // optional id String
-        if (id != null && !id.equals(hash)) {
-            memory += 48 + id.length() * 2;
-        }
-        // rough approximation for properties
-        if (properties != null) {
-            for (Map.Entry<String, PropertyState> entry : properties.entrySet()) {
-                // name
-                memory += 48 + entry.getKey().length() * 2;
-                PropertyState propState = entry.getValue();
-                if (propState.getType() != Type.BINARY
-                        && propState.getType() != Type.BINARIES) {
-                    // assume binaries go into blob store
-                    for (int i = 0; i < propState.count(); i++) {
-                        // size() returns length of string
-                        // overhead:
-                        // - 8 bytes per reference in values list
-                        // - 48 bytes per string
-                        memory += 56 + propState.size(i) * 2;
-                    }
-                }
-            }
-        }
-        // rough approximation for child nodes
-        if (childNames != null) {
-            memory += childNames.size() * 150;
-        }
-        return memory;
-    }
-
-    //------------------------------------------------------------< private >---
-
-    private static boolean hasChanges(String journal) {
-        return !journal.trim().isEmpty();
-    }
-
-    /**
-     * Process the given JSON diff, which is the diff of of the {@code base}
-     * node state to this node state.
-     *
-     * @param jsonDiff the JSON diff.
-     * @param base the base node state.
-     * @param diff where diffs are reported to.
-     * @return {@code true} to continue the comparison, {@code false} to stop
-     */
-    private boolean processJsonDiff(String jsonDiff,
-                                 KernelNodeState base,
-                                 NodeStateDiff diff) {
-        if (!hasChanges(jsonDiff)) {
-            return true;
-        }
-        if (!AbstractNodeState.comparePropertiesAgainstBaseState(this, base, diff)) {
-            return false;
-        }
-        JsopTokenizer t = new JsopTokenizer(jsonDiff);
-        boolean continueComparison = true;
-        while (continueComparison) {
-            int r = t.read();
-            if (r == JsopReader.END) {
-                break;
-            }
-            switch (r) {
-                case '+': {
-                    String path = t.readString();
-                    t.read(':');
-                    t.read('{');
-                    while (t.read() != '}') {
-                        // skip properties
-                    }
-                    String name = PathUtils.getName(path);
-                    continueComparison = diff.childNodeAdded(name, getChildNode(name));
-                    break;
-                }
-                case '-': {
-                    String path = t.readString();
-                    String name = PathUtils.getName(path);
-                    continueComparison = diff.childNodeDeleted(name, base.getChildNode(name));
-                    break;
-                }
-                case '^': {
-                    String path = t.readString();
-                    t.read(':');
-                    if (t.matches('{')) {
-                        t.read('}');
-                        String name = PathUtils.getName(path);
-                        continueComparison = diff.childNodeChanged(name,
-                                base.getChildNode(name), getChildNode(name));
-                    } else if (t.matches('[')) {
-                        // ignore multi valued property
-                        while (t.read() != ']') {
-                            // skip values
-                        }
-                    } else {
-                        // ignore single valued property
-                        t.read();
-                    }
-                    break;
-                }
-                case '>': {
-                    String from = t.readString();
-                    t.read(':');
-                    String to = t.readString();
-                    String fromName = PathUtils.getName(from);
-                    continueComparison = diff.childNodeDeleted(
-                            fromName, base.getChildNode(fromName));
-                    if (!continueComparison) {
-                        break;
-                    }
-                    String toName = PathUtils.getName(to);
-                    continueComparison = diff.childNodeAdded(
-                            toName, getChildNode(toName));
-                    break;
-                }
-                default:
-                    throw new IllegalArgumentException("jsonDiff: illegal token '"
-                            + t.getToken() + "' at pos: " + t.getLastPos() + ' ' + jsonDiff);
-            }
-        }
-        return continueComparison;
-    }
-
-    private Iterable<ChildNodeEntry> iterable(
-            Iterable<String> names) {
-        return Iterables.transform(
-                names,
-                new Function<String, ChildNodeEntry>() {
-                    @Override
-                    public ChildNodeEntry apply(String input) {
-                        return new KernelChildNodeEntry(input);
-                    }
-                });
-    }
-
-    private class KernelChildNodeEntry extends AbstractChildNodeEntry {
-
-        private final String name;
-
-        /**
-         * Creates a child node entry with the given name.
-         *
-         * @param name child node name
-         */
-        public KernelChildNodeEntry(String name) {
-            this.name = checkNotNull(name);
-        }
-
-        @Override
-        public String getName() {
-            return name;
-        }
-
-        @Override
-        public NodeState getNodeState() {
-            try {
-                return cache.get(revision + PathUtils.concat(path, name));
-            } catch (ExecutionException e) {
-                throw new MicroKernelException(e);
-            }
-        }
-
-    }
-
-    /**
-     * Read a {@code PropertyState} from a {@link JsopReader}
-     * @param name  The name of the property state
-     * @param reader  The reader
-     * @return new property state
-     */
-    private PropertyState readProperty(String name, JsopReader reader) {
-        if (reader.matches(JsopReader.NUMBER)) {
-            String number = reader.getToken();
-            try {
-                return new LongPropertyState(name, Long.parseLong(number));
-            } catch (NumberFormatException e) {
-                return new DoublePropertyState(name, Double.parseDouble(number));
-            }
-        } else if (reader.matches(JsopReader.TRUE)) {
-            return BooleanPropertyState.booleanProperty(name, true);
-        } else if (reader.matches(JsopReader.FALSE)) {
-            return BooleanPropertyState.booleanProperty(name, false);
-        } else if (reader.matches(JsopReader.STRING)) {
-            String jsonString = reader.getToken();
-            if (jsonString.startsWith(TypeCodes.EMPTY_ARRAY)) {
-                int type = PropertyType.valueFromName(
-                        jsonString.substring(TypeCodes.EMPTY_ARRAY.length()));
-                return PropertyStates.createProperty(
-                        name, emptyList(), Type.fromTag(type, true));
-            }
-            int split = TypeCodes.split(jsonString);
-            if (split != -1) {
-                int type = TypeCodes.decodeType(split, jsonString);
-                String value = TypeCodes.decodeName(split, jsonString);
-                if (type == PropertyType.BINARY) {
-                    return  BinaryPropertyState.binaryProperty(
-                            name, new KernelBlob(new String(value), kernel));
-                } else {
-                    return createProperty(name, StringCache.get(value), type);
-                }
-            } else {
-                return StringPropertyState.stringProperty(
-                        name, StringCache.get(jsonString));
-            }
-        } else {
-            throw new IllegalArgumentException("Unexpected token: " + reader.getToken());
-        }
-    }
-
-    /**
-     * Read a multi valued {@code PropertyState} from a {@link JsopReader}
-     * @param name  The name of the property state
-     * @param reader  The reader
-     * @return new property state
-     */
-    private PropertyState readArrayProperty(String name, JsopReader reader) {
-        int type = PropertyType.STRING;
-        List<Object> values = Lists.newArrayList();
-        while (!reader.matches(']')) {
-            if (reader.matches(JsopReader.NUMBER)) {
-                String number = reader.getToken();
-                try {
-                    type = PropertyType.LONG;
-                    values.add(Long.parseLong(number));
-                } catch (NumberFormatException e) {
-                    type = PropertyType.DOUBLE;
-                    values.add(Double.parseDouble(number));
-                }
-            } else if (reader.matches(JsopReader.TRUE)) {
-                type = PropertyType.BOOLEAN;
-                values.add(true);
-            } else if (reader.matches(JsopReader.FALSE)) {
-                type = PropertyType.BOOLEAN;
-                values.add(false);
-            } else if (reader.matches(JsopReader.STRING)) {
-                String jsonString = reader.getToken();
-                int split = TypeCodes.split(jsonString);
-                if (split != -1) {
-                    type = TypeCodes.decodeType(split, jsonString);
-                    String value = TypeCodes.decodeName(split, jsonString);
-                    if (type == PropertyType.BINARY) {
-                        values.add(new KernelBlob(new String(value), kernel));
-                    } else if (type == PropertyType.DOUBLE) {
-                        values.add(Conversions.convert(value).toDouble());
-                    } else if (type == PropertyType.DECIMAL) {
-                        values.add(Conversions.convert(value).toDecimal());
-                    } else {
-                        values.add(StringCache.get(value));
-                    }
-                } else {
-                    type = PropertyType.STRING;
-                    values.add(StringCache.get(jsonString));
-                }
-            } else {
-                throw new IllegalArgumentException("Unexpected token: " + reader.getToken());
-            }
-            reader.matches(',');
-        }
-        return createProperty(name, values, Type.fromTag(type, true));
-    }
-    
-    @Override
-    public String toString() {
-        StringBuilder builder = new StringBuilder();
-        builder.append(path).append('@').append(revision);
-        if (childNodeCount >= 0) {
-            builder.append(" children: ").append(childNodeCount);
-        }
-        if (hash != null) {
-            builder.append(" hash: ").append(hash);
-        }
-        if (id != null) {
-            builder.append(" id: ").append(id);
-        }
-        builder.append(" {");
-        int count = 0;
-        if (properties == null) {
-            builder.append(" /* props not initialized */");
-        } else {
-            for (PropertyState property : getProperties()) {
-                if (count++ > 0) {
-                    builder.append(',');
-                }
-                builder.append(' ').append(property);
-            }
-        }
-        if (childNames == null) {
-            builder.append(" /* child node names not initialized */");
-        } else {
-            for (String s : childNames) {
-                if (count++ > 0) {
-                    builder.append(',');
-                }
-                builder.append(' ').append(s);
-            }
-        }
-        builder.append(" }");
-        return builder.toString();
-    }
-
-}
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStore.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStore.java
deleted file mode 100644
index ce978075c9..0000000000
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStore.java
+++ /dev/null
@@ -1,302 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.jackrabbit.oak.kernel;
-
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
-
-import java.io.Closeable;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.Collections;
-import java.util.Map;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReentrantLock;
-
-import javax.annotation.CheckForNull;
-import javax.annotation.Nonnull;
-import javax.annotation.Nullable;
-
-import com.google.common.cache.CacheLoader;
-import com.google.common.cache.LoadingCache;
-import com.google.common.cache.Weigher;
-import com.google.common.util.concurrent.ListenableFuture;
-import com.google.common.util.concurrent.SettableFuture;
-import org.apache.jackrabbit.mk.api.MicroKernel;
-import org.apache.jackrabbit.mk.api.MicroKernelException;
-import org.apache.jackrabbit.oak.api.Blob;
-import org.apache.jackrabbit.oak.api.CommitFailedException;
-import org.apache.jackrabbit.oak.cache.CacheLIRS;
-import org.apache.jackrabbit.oak.cache.CacheStats;
-import org.apache.jackrabbit.oak.spi.commit.ChangeDispatcher;
-import org.apache.jackrabbit.oak.spi.commit.CommitHook;
-import org.apache.jackrabbit.oak.spi.commit.CommitInfo;
-import org.apache.jackrabbit.oak.spi.commit.Observable;
-import org.apache.jackrabbit.oak.spi.commit.Observer;
-import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
-import org.apache.jackrabbit.oak.spi.state.NodeState;
-import org.apache.jackrabbit.oak.spi.state.NodeStore;
-
-/**
- * {@code NodeStore} implementations against {@link MicroKernel}.
- */
-public class KernelNodeStore implements NodeStore, Observable {
-    public static final long DEFAULT_CACHE_SIZE = 16 * 1024 * 1024;
-
-    /**
-     * The {@link MicroKernel} instance used to store the content tree.
-     */
-    private final MicroKernel kernel;
-
-    private final LoadingCache<String, KernelNodeState> cache;
-
-    private final CacheStats cacheStats;
-
-    /**
-     * Lock passed to branches for coordinating merges
-     */
-    private final Lock mergeLock = new ReentrantLock();
-
-    private final ChangeDispatcher changeDispatcher;
-
-    /**
-     * State of the current root node.
-     */
-    private KernelNodeState root;
-
-    public KernelNodeStore(final MicroKernel kernel, long cacheSize) {
-        this.kernel = checkNotNull(kernel);
-
-        Weigher<String, KernelNodeState> weigher = new Weigher<String, KernelNodeState>() {
-            @Override
-            public int weigh(String key, KernelNodeState state) {
-                return state.getMemory();
-            }
-        };
-        this.cache = CacheLIRS.newBuilder()
-                .maximumWeight(cacheSize)
-                .recordStats()
-                .weigher(weigher)
-                .build(new CacheLoader<String, KernelNodeState>() {
-                    @Override
-                    public KernelNodeState load(String key) {
-                        int slash = key.indexOf('/');
-                        String revision = key.substring(0, slash);
-                        String path = key.substring(slash);
-                        return new KernelNodeState(KernelNodeStore.this, path, revision, cache);
-                    }
-
-                    @Override
-                    public ListenableFuture<KernelNodeState> reload(
-                            String key, KernelNodeState oldValue) {
-                        // LoadingCache.reload() is only used to re-calculate the
-                        // memory usage on KernelNodeState.init(). Therefore
-                        // we simply return the old value as is (OAK-643)
-                        SettableFuture<KernelNodeState> future = SettableFuture.create();
-                        future.set(oldValue);
-                        return future;
-                    }
-                });
-
-        cacheStats = new CacheStats(cache, "NodeStore", weigher, cacheSize);
-
-        try {
-            this.root = cache.get(kernel.getHeadRevision() + '/');
-        } catch (Exception e) {
-            throw new RuntimeException(e);
-        }
-        changeDispatcher = new ChangeDispatcher(root);
-    }
-
-    public KernelNodeStore(MicroKernel kernel) {
-        this(kernel, DEFAULT_CACHE_SIZE);
-    }
-
-    /**
-     * Returns a string representation the head state of this node store.
-     */
-    @Override
-    public String toString() {
-        return getRoot().toString();
-    }
-
-    //------------------------------------------------------------< Observable >---
-
-    @Override
-    public Closeable addObserver(Observer observer) {
-        return changeDispatcher.addObserver(observer);
-    }
-
-    //----------------------------------------------------------< NodeStore >---
-
-    @Override
-    public synchronized KernelNodeState getRoot() {
-        String revision = kernel.getHeadRevision();
-        if (!revision.equals(root.getRevision())) {
-            root = getRootState(revision);
-        }
-        return root;
-    }
-
-    /**
-     * This implementation delegates to {@link KernelRootBuilder#merge(CommitHook, CommitInfo)}
-     * if {@code builder} is a {@link KernelNodeBuilder} instance. Otherwise it throws
-     * an {@code IllegalArgumentException}.
-     */
-    @Override
-    public NodeState merge(
-            @Nonnull NodeBuilder builder, @Nonnull CommitHook commitHook,
-            @Nullable CommitInfo info) throws CommitFailedException {
-        checkArgument(builder instanceof KernelRootBuilder);
-        return ((KernelRootBuilder) builder).merge(checkNotNull(commitHook), info);
-    }
-
-    /**
-     * This implementation delegates to {@link KernelRootBuilder#rebase()} if {@code builder}
-     * is a {@link KernelNodeBuilder} instance. Otherwise Otherwise it throws an
-     * {@code IllegalArgumentException}.
-     * @param builder  the builder to rebase
-     */
-    @Override
-    public NodeState rebase(@Nonnull NodeBuilder builder) {
-        checkArgument(builder instanceof KernelRootBuilder);
-        return ((KernelRootBuilder) builder).rebase();
-    }
-
-    /**
-     * This implementation delegates to {@link KernelRootBuilder#reset()} if {@code builder}
-     * is a {@link KernelNodeBuilder} instance. Otherwise it throws an
-     * {@code IllegalArgumentException}.
-     * @param builder  the builder to rebase
-     */
-    @Override
-    public NodeState reset(@Nonnull NodeBuilder builder) {
-        checkArgument(builder instanceof KernelRootBuilder);
-        return ((KernelRootBuilder) builder).reset();
-    }
-
-    /**
-     * @return An instance of {@link KernelBlob}
-     */
-    @Override
-    public KernelBlob createBlob(InputStream inputStream) throws IOException {
-        try {
-            String blobId = kernel.write(inputStream);
-            return new KernelBlob(blobId, kernel);
-        } catch (MicroKernelException e) {
-            throw new IOException(e);
-        }
-    }
-
-    @Override
-    public Blob getBlob(@Nonnull String reference) {
-        try {
-            kernel.getLength(reference);  // throws if reference doesn't resolve
-            return new KernelBlob(reference, kernel);
-        } catch (MicroKernelException e) {
-            return null;
-        }
-    }
-
-
-    @Nonnull
-    @Override
-    public String checkpoint(long lifetime, @Nonnull Map<String, String> properties) {
-        throw new UnsupportedOperationException("MicroKernel based NodeStore implementations do " +
-                "not support checkpoint metadata");
-    }
-
-    @Override @Nonnull
-    public String checkpoint(long lifetime) {
-        checkArgument(lifetime > 0);
-        return kernel.checkpoint(lifetime);
-    }
-
-    @Nonnull
-    @Override
-    public Map<String, String> checkpointInfo(@Nonnull String checkpoint) {
-        return Collections.emptyMap();
-    }
-
-    @Override @CheckForNull
-    public NodeState retrieve(@Nonnull String checkpoint) {
-        try {
-            return getRootState(checkNotNull(checkpoint));
-        } catch (MicroKernelException e) {
-            // TODO: caused by the checkpoint no longer being available?
-            return null;
-        }
-    }
-
-    @Override
-    public boolean release(String checkpoint) {
-        // TODO
-        return true;
-    }
-
-    public CacheStats getCacheStats() {
-        return cacheStats;
-    }
-
-    //-----------------------------------------------------------< internal >---
-
-    private KernelNodeState getRootState(String revision) {
-        try {
-            return cache.get(revision + "/");
-        } catch (ExecutionException e) {
-            throw new MicroKernelException(e);
-        }
-    }
-
-    KernelNodeStoreBranch createBranch(KernelNodeState base) {
-        return new KernelNodeStoreBranch(this, changeDispatcher, mergeLock, base);
-    }
-
-    MicroKernel getKernel() {
-        return kernel;
-    }
-
-    KernelNodeState commit(String jsop, KernelNodeState base) {
-        if (jsop.isEmpty()) {
-            // nothing to commit
-            return base;
-        }
-        KernelNodeState rootState = getRootState(kernel.commit("", jsop, base.getRevision(), null));
-        if (base.isBranch()) {
-            rootState.setBranch();
-        }
-        return rootState;
-    }
-
-    KernelNodeState branch(KernelNodeState base) {
-        return getRootState(kernel.branch(base.getRevision())).setBranch();
-    }
-
-    KernelNodeState rebase(KernelNodeState branchHead, KernelNodeState base) {
-        return getRootState(kernel.rebase(branchHead.getRevision(), base.getRevision())).setBranch();
-    }
-
-    KernelNodeState merge(KernelNodeState branchHead) {
-        return getRootState(kernel.merge(branchHead.getRevision(), null));
-    }
-
-    KernelNodeState reset(KernelNodeState branchHead, KernelNodeState ancestor) {
-        return getRootState(kernel.reset(
-                branchHead.getRevision(), ancestor.getRevision()));
-    }
-}
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStoreBranch.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStoreBranch.java
deleted file mode 100644
index 4ece12be58..0000000000
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStoreBranch.java
+++ /dev/null
@@ -1,156 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.jackrabbit.oak.kernel;
-
-import java.io.IOException;
-import java.util.concurrent.locks.Lock;
-
-import javax.annotation.Nonnull;
-
-import org.apache.jackrabbit.mk.api.MicroKernel;
-import org.apache.jackrabbit.mk.api.MicroKernelException;
-import org.apache.jackrabbit.oak.api.Blob;
-import org.apache.jackrabbit.oak.api.CommitFailedException;
-import org.apache.jackrabbit.oak.json.BlobSerializer;
-import org.apache.jackrabbit.oak.json.JsopDiff;
-import org.apache.jackrabbit.oak.spi.commit.ChangeDispatcher;
-import org.apache.jackrabbit.oak.spi.commit.CommitHook;
-import org.apache.jackrabbit.oak.spi.commit.CommitInfo;
-import org.apache.jackrabbit.oak.spi.state.AbstractNodeStoreBranch;
-import org.apache.jackrabbit.oak.spi.state.NodeState;
-
-import static org.apache.jackrabbit.oak.api.CommitFailedException.MERGE;
-import static org.apache.jackrabbit.oak.api.CommitFailedException.OAK;
-
-/**
- * {@code NodeStoreBranch} based on {@link MicroKernel} branching and merging.
- * This implementation keeps changes in memory up to a certain limit and writes
- * them back to the Microkernel branch when the limit is exceeded.
- */
-public class KernelNodeStoreBranch extends
-        AbstractNodeStoreBranch<KernelNodeStore, KernelNodeState> {
-
-    private final BlobSerializer blobs = new BlobSerializer() {
-        @Override
-        public String serialize(Blob blob) {
-            KernelBlob kernelBlob;
-            if (blob instanceof KernelBlob) {
-                kernelBlob = (KernelBlob) blob;
-            } else {
-                try {
-                    kernelBlob = store.createBlob(blob.getNewStream());
-                } catch (IOException e) {
-                    throw new IllegalStateException(e);
-                }
-            }
-            return kernelBlob.getBinaryID();
-        }
-    };
-
-    public KernelNodeStoreBranch(KernelNodeStore kernelNodeStore,
-                                 ChangeDispatcher dispatcher,
-                                 Lock mergeLock,
-                                 KernelNodeState base) {
-        super(kernelNodeStore, dispatcher, mergeLock, base);
-    }
-
-    //----------------------< AbstractNodeStoreBranch >-------------------------
-
-    @Override
-    public KernelNodeState createBranch(KernelNodeState state) {
-        return store.branch(state);
-    }
-
-    @Override
-    public KernelNodeState getRoot() {
-        return store.getRoot();
-    }
-
-    @Override
-    protected KernelNodeState rebase(KernelNodeState branchHead,
-                                     KernelNodeState base) {
-        return store.rebase(branchHead, base);
-    }
-
-    @Override
-    protected KernelNodeState merge(KernelNodeState branchHead,
-                                    CommitInfo info)
-            throws CommitFailedException {
-        try {
-            return store.merge(branchHead);
-        } catch (MicroKernelException e) {
-            throw new CommitFailedException(MERGE, 1,
-                    "Failed to merge changes to the underlying MicroKernel", e);
-        }
-    }
-
-    @Nonnull
-    @Override
-    protected KernelNodeState reset(@Nonnull KernelNodeState branchHead,
-                                    @Nonnull KernelNodeState ancestor) {
-        return store.reset(branchHead, ancestor);
-    }
-
-    @Override
-    protected KernelNodeState persist(NodeState toPersist,
-                                      KernelNodeState base,
-                                      CommitInfo info) {
-        JsopDiff diff = new JsopDiff(blobs);
-        toPersist.compareAgainstBaseState(base, diff);
-        return store.commit(diff.toString(), base);
-    }
-
-    @Override
-    protected KernelNodeState copy(String source,
-                                   String target,
-                                   KernelNodeState base) {
-        return store.commit("*\"" + source + "\":\"" + target + '"', base);
-    }
-
-    @Override
-    protected KernelNodeState move(String source,
-                                   String target,
-                                   KernelNodeState base) {
-        return store.commit(">\"" + source + "\":\"" + target + '"', base);
-    }
-
-    @Override
-    protected CommitFailedException convertUnchecked(Exception cause,
-                                                     String msg) {
-        String type;
-        if (cause instanceof MicroKernelException) {
-            type = MERGE;
-        } else {
-            type = OAK;
-        }
-        return new CommitFailedException(type, 1, msg, cause);
-    }
-
-    //------------------------< NodeStoreBranch >-------------------------------
-
-    @Nonnull
-    @Override
-    public NodeState merge(@Nonnull CommitHook hook, @Nonnull CommitInfo info)
-            throws CommitFailedException {
-        try {
-            return super.merge(hook, info);
-        } catch (MicroKernelException e) {
-            throw new CommitFailedException(MERGE, 1,
-                    "Failed to merge changes to the underlying MicroKernel", e);
-        }
-    }
-}
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelRootBuilder.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelRootBuilder.java
deleted file mode 100644
index e5291c7948..0000000000
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelRootBuilder.java
+++ /dev/null
@@ -1,189 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.jackrabbit.oak.kernel;
-
-import static com.google.common.base.Preconditions.checkNotNull;
-
-import javax.annotation.Nonnull;
-
-import org.apache.jackrabbit.oak.api.CommitFailedException;
-import org.apache.jackrabbit.oak.plugins.memory.MemoryNodeBuilder;
-import org.apache.jackrabbit.oak.spi.commit.CommitHook;
-import org.apache.jackrabbit.oak.spi.commit.CommitInfo;
-import org.apache.jackrabbit.oak.spi.state.ConflictAnnotatingRebaseDiff;
-import org.apache.jackrabbit.oak.spi.state.NodeState;
-
-/**
- * This implementation tracks the number of pending changes and purges them to
- * a private branch of the underlying store if a certain threshold is met.
- */
-class KernelRootBuilder extends MemoryNodeBuilder implements FastMove {
-
-    /**
-     * Number of content updates that need to happen before the updates
-     * are automatically purged to the private branch.
-     */
-    private static final int UPDATE_LIMIT = Integer.getInteger("update.limit", 1000);
-
-    /**
-     * The underlying store
-     */
-    private final KernelNodeStore store;
-
-    /**
-     * The base state of this builder, possibly non-existent if this builder
-     * represents a new node that didn't yet exist in the base content tree.
-     * This differs from the base state of super since the latter one reflects
-     * the base created by the last purge.
-     */
-    @Nonnull
-    private NodeState base;
-
-    /**
-     * Private branch used to hold pending changes exceeding {@link #UPDATE_LIMIT}
-     */
-    private KernelNodeStoreBranch branch;
-
-    /**
-     * Number of updated not yet persisted to the private {@link #branch}
-     */
-    private int updates = 0;
-
-    KernelRootBuilder(KernelNodeState base, KernelNodeStore store) {
-        super(checkNotNull(base));
-        this.base = base;
-        this.store = store;
-        this.branch = store.createBranch(base);
-    }
-
-    //--------------------------------------------------< MemoryNodeBuilder >---
-
-
-    @Override @Nonnull
-    public NodeState getBaseState() {
-        return base;
-    }
-
-    @Override
-    public void reset(@Nonnull NodeState newBase) {
-        base = checkNotNull(newBase);
-        super.reset(newBase);
-    }
-
-    @Override
-    protected MemoryNodeBuilder createChildBuilder(String name) {
-        return new KernelNodeBuilder(this, name, this);
-    }
-
-    @Override
-    protected void updated() {
-        if (updates++ > UPDATE_LIMIT) {
-            purge();
-        }
-    }
-
-    @Override
-    public boolean moveFrom(KernelNodeBuilder source, String newName) {
-        String sourcePath = source.getPath();
-        return move(sourcePath, '/' + newName);
-    }
-
-    //------------------------------------------------------------< internal >---
-
-    /**
-     * Rebase this builder on top of the head of the underlying store
-     */
-    NodeState rebase() {
-        NodeState head = getNodeState();
-        NodeState inMemBase = super.getBaseState();
-
-        // Rebase branch
-        branch.rebase();
-
-        // Rebase in memory changes on top of the head of the rebased branch
-        super.reset(branch.getHead());
-        head.compareAgainstBaseState(inMemBase, new ConflictAnnotatingRebaseDiff(this));
-
-        // Set new base and return rebased head
-        base = branch.getBase();
-        return getNodeState();
-    }
-
-    /**
-     * Reset this builder by creating a new branch and setting the head
-     * state of that branch as the new base state of this builder.
-     */
-    NodeState reset() {
-        branch = store.createBranch(store.getRoot());
-        NodeState head = branch.getHead();
-        reset(head);
-        return head;
-    }
-
-    /**
-     * Merge all changes tracked in this builder into the underlying store.
-     */
-    NodeState merge(CommitHook hook, CommitInfo info) throws CommitFailedException {
-        purge();
-        boolean success = false;
-        try {
-            branch.merge(hook, info);
-            success = true;
-        } finally {
-            if (!success) {
-                // need to adjust base and head of this builder
-                // in case branch.merge() did a rebase and then
-                // a commit hook failed the merge
-                super.reset(branch.getHead());
-                this.base = branch.getBase();
-            }
-        }
-        return reset();
-    }
-
-    /**
-     * Applied all pending changes to the underlying branch and then
-     * move the node as a separate operation on the underlying store.
-     * This allows stores to optimise move operations instead of
-     * seeing them as an added node followed by a deleted node.
-     */
-    boolean move(String source, String target) {
-        purge();
-        boolean success = branch.move(source, target);
-        super.reset(branch.getHead());
-        return success;
-    }
-
-    /**
-     * Applied all pending changes to the underlying branch and then
-     * copy the node as a separate operation on the underlying store.
-     * This allows stores to optimise copy operations instead of
-     * seeing them as an added node.
-     */
-    boolean copy(String source, String target) {
-        purge();
-        boolean success = branch.copy(source, target);
-        super.reset(branch.getHead());
-        return success;
-    }
-
-    private void purge() {
-        branch.setRoot(getNodeState());
-        super.reset(branch.getHead());
-        updates = 0;
-    }
-}
diff --git a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreService.java b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreService.java
index be43f158a2..353a1acf09 100644
--- a/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreService.java
+++ b/oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreService.java
@@ -50,7 +50,6 @@ import org.apache.felix.scr.annotations.ReferencePolicy;
 import org.apache.jackrabbit.oak.api.jmx.CacheStatsMBean;
 import org.apache.jackrabbit.oak.api.jmx.CheckpointMBean;
 import org.apache.jackrabbit.oak.commons.PropertiesUtil;
-import org.apache.jackrabbit.oak.kernel.KernelNodeStore;
 import org.apache.jackrabbit.oak.osgi.ObserverTracker;
 import org.apache.jackrabbit.oak.osgi.OsgiWhiteboard;
 import org.apache.jackrabbit.oak.plugins.blob.BlobGC;
@@ -98,11 +97,6 @@ public class DocumentNodeStoreService {
      */
     private static final String FWK_PROP_DB = "oak.mongo.db";
 
-    //DocumentMK would be done away with so better not
-    //to expose this setting in config ui
-    @Property(boolValue = false, propertyPrivate = true)
-    private static final String PROP_USE_MK = "useMK";
-
     @Property(value = DEFAULT_URI)
     private static final String PROP_URI = "mongouri";
 
@@ -244,7 +238,6 @@ public class DocumentNodeStoreService {
         int changesSize = toInteger(prop(PROP_CHANGES_SIZE), DEFAULT_CHANGES_SIZE);
         int blobCacheSize = toInteger(prop(PROP_BLOB_CACHE_SIZE), DEFAULT_BLOB_CACHE_SIZE);
         String persistentCache = PropertiesUtil.toString(prop(PROP_PERSISTENT_CACHE), DEFAULT_PERSISTENT_CACHE);
-        boolean useMK = toBoolean(context.getProperties().get(PROP_USE_MK), false);
 
         DocumentMK.Builder mkBuilder =
                 new DocumentMK.Builder().
@@ -280,10 +273,9 @@ public class DocumentNodeStoreService {
             if (log.isInfoEnabled()) {
                 // Take care around not logging the uri directly as it
                 // might contain passwords
-                String type = useMK ? "MK" : "NodeStore";
-                log.info("Starting Document{} with host={}, db={}, cache size (MB)={}, Off Heap Cache size (MB)={}, " +
+                log.info("Starting DocumentNodeStore with host={}, db={}, cache size (MB)={}, Off Heap Cache size (MB)={}, " +
                                 "'changes' collection size (MB)={}, blobCacheSize (MB)={}, maxReplicationLagInSecs={}",
-                        type, mongoURI.getHosts(), db, cacheSize, offHeapCache, changesSize, blobCacheSize, maxReplicationLagInSecs);
+                        mongoURI.getHosts(), db, cacheSize, offHeapCache, changesSize, blobCacheSize, maxReplicationLagInSecs);
                 log.info("Mongo Connection details {}", MongoConnection.toString(mongoURI.getOptions()));
             }
 
@@ -303,15 +295,9 @@ public class DocumentNodeStoreService {
         registerLastRevRecoveryJob(mk.getNodeStore());
 
         NodeStore store;
-        if (useMK) {
-            KernelNodeStore kns = new KernelNodeStore(mk);
-            store = kns;
-            observerTracker = new ObserverTracker(kns);
-        } else {
-            DocumentNodeStore mns = mk.getNodeStore();
-            store = mns;
-            observerTracker = new ObserverTracker(mns);
-        }
+        DocumentNodeStore mns = mk.getNodeStore();
+        store = mns;
+        observerTracker = new ObserverTracker(mns);
 
         observerTracker.start(context.getBundleContext());
 
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterTest.java
index 2504224945..16e7084f04 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/ClusterTest.java
@@ -16,9 +16,6 @@
  */
 package org.apache.jackrabbit.oak.plugins.document;
 
-import java.util.HashSet;
-import java.util.Set;
-
 import static org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.EMPTY_NODE;
 import static org.apache.jackrabbit.oak.plugins.memory.EmptyNodeState.MISSING_NODE;
 import static org.junit.Assert.assertEquals;
@@ -27,12 +24,16 @@ import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
+import java.util.HashSet;
+import java.util.Set;
+
+import com.google.common.collect.Sets;
+import com.mongodb.DB;
 import org.apache.jackrabbit.mk.api.MicroKernelException;
-import org.apache.jackrabbit.oak.spi.blob.BlobStore;
-import org.apache.jackrabbit.oak.spi.blob.MemoryBlobStore;
 import org.apache.jackrabbit.oak.commons.PathUtils;
-import org.apache.jackrabbit.oak.kernel.KernelNodeStore;
 import org.apache.jackrabbit.oak.plugins.document.memory.MemoryDocumentStore;
+import org.apache.jackrabbit.oak.spi.blob.BlobStore;
+import org.apache.jackrabbit.oak.spi.blob.MemoryBlobStore;
 import org.apache.jackrabbit.oak.spi.state.ChildNodeEntry;
 import org.apache.jackrabbit.oak.spi.state.DefaultNodeStateDiff;
 import org.apache.jackrabbit.oak.spi.state.NodeState;
@@ -42,9 +43,6 @@ import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
-import com.google.common.collect.Sets;
-import com.mongodb.DB;
-
 /**
  * A set of simple cluster tests.
  */
@@ -214,7 +212,7 @@ public class ClusterTest {
         DocumentMK mk2 = createMK(2, 0);
         DocumentMK mk3 = createMK(3, 0);
 
-        KernelNodeStore ns3 = new KernelNodeStore(mk3);
+        DocumentNodeStore ns3 = mk3.getNodeStore();
         // the next line is required for the test even if it
         // just reads from the node store. do not remove!
         traverse(ns3.getRoot(), "/");
@@ -237,9 +235,9 @@ public class ClusterTest {
 
         mk3.runBackgroundOperations(); // pick up changes from mk2
 
-        NodeState base = ns3.retrieve(base3); // branch base
+        DocumentNodeState base = ns3.getNode("/", Revision.fromString(base3));
         assertNotNull(base);
-        NodeState branchHead = ns3.retrieve(b3);
+        NodeState branchHead = ns3.getNode("/", Revision.fromString(b3));
         assertNotNull(branchHead);
         TrackingDiff diff = new TrackingDiff();
         branchHead.compareAgainstBaseState(base, diff);
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreTest.java
index 8152025953..4a530b61eb 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreTest.java
@@ -16,6 +16,20 @@
  */
 package org.apache.jackrabbit.oak.plugins.document;
 
+import static java.util.concurrent.TimeUnit.SECONDS;
+import static org.apache.jackrabbit.oak.api.CommitFailedException.CONSTRAINT;
+import static org.apache.jackrabbit.oak.plugins.document.Collection.NODES;
+import static org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.REMEMBER_REVISION_ORDER_MILLIS;
+import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.MODIFIED_IN_SECS;
+import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.MODIFIED_IN_SECS_RESOLUTION;
+import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.NUM_REVS_THRESHOLD;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.fail;
+
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
@@ -32,10 +46,12 @@ import java.util.concurrent.atomic.AtomicInteger;
 import javax.annotation.CheckForNull;
 import javax.annotation.Nonnull;
 
+import com.google.common.collect.Iterables;
+import com.google.common.collect.Lists;
+import com.google.common.collect.Sets;
 import org.apache.jackrabbit.oak.api.CommitFailedException;
 import org.apache.jackrabbit.oak.api.PropertyState;
 import org.apache.jackrabbit.oak.api.Type;
-import org.apache.jackrabbit.oak.kernel.KernelNodeState;
 import org.apache.jackrabbit.oak.plugins.document.memory.MemoryDocumentStore;
 import org.apache.jackrabbit.oak.plugins.document.util.TimingDocumentStoreWrapper;
 import org.apache.jackrabbit.oak.plugins.document.util.Utils;
@@ -55,24 +71,6 @@ import org.apache.jackrabbit.oak.stats.Clock;
 import org.junit.After;
 import org.junit.Test;
 
-import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
-import com.google.common.collect.Sets;
-
-import static java.util.concurrent.TimeUnit.SECONDS;
-import static org.apache.jackrabbit.oak.api.CommitFailedException.CONSTRAINT;
-import static org.apache.jackrabbit.oak.plugins.document.Collection.NODES;
-import static org.apache.jackrabbit.oak.plugins.document.DocumentNodeStore.REMEMBER_REVISION_ORDER_MILLIS;
-import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.MODIFIED_IN_SECS;
-import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.MODIFIED_IN_SECS_RESOLUTION;
-import static org.apache.jackrabbit.oak.plugins.document.NodeDocument.NUM_REVS_THRESHOLD;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
-
 public class DocumentNodeStoreTest {
 
     @After
@@ -146,7 +144,7 @@ public class DocumentNodeStoreTest {
     public void childNodeCache() throws Exception {
         DocumentNodeStore store = new DocumentMK.Builder().getNodeStore();
         NodeBuilder builder = store.getRoot().builder();
-        int max = (int) (KernelNodeState.MAX_CHILD_NAMES * 1.5);
+        int max = (int) (100 * 1.5);
         SortedSet<String> children = new TreeSet<String>();
         for (int i = 0; i < max; i++) {
             String name = "c" + i;
@@ -156,7 +154,7 @@ public class DocumentNodeStoreTest {
         store.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
         builder = store.getRoot().builder();
         String name = new ArrayList<String>(children).get(
-                KernelNodeState.MAX_CHILD_NAMES / 2);
+                100 / 2);
         builder.child(name).remove();
         store.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
         int numEntries = Iterables.size(store.getRoot().getChildNodeEntries());
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MergeRetryTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MergeRetryTest.java
index 80134c15ea..4446257466 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MergeRetryTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/plugins/document/MergeRetryTest.java
@@ -18,11 +18,10 @@ package org.apache.jackrabbit.oak.plugins.document;
 
 import javax.annotation.CheckForNull;
 
-import org.apache.jackrabbit.oak.spi.blob.BlobStore;
-import org.apache.jackrabbit.oak.spi.blob.MemoryBlobStore;
 import org.apache.jackrabbit.oak.api.CommitFailedException;
-import org.apache.jackrabbit.oak.kernel.KernelNodeStore;
 import org.apache.jackrabbit.oak.plugins.document.memory.MemoryDocumentStore;
+import org.apache.jackrabbit.oak.spi.blob.BlobStore;
+import org.apache.jackrabbit.oak.spi.blob.MemoryBlobStore;
 import org.apache.jackrabbit.oak.spi.commit.CommitHook;
 import org.apache.jackrabbit.oak.spi.commit.CommitInfo;
 import org.apache.jackrabbit.oak.spi.commit.DefaultEditor;
@@ -31,7 +30,6 @@ import org.apache.jackrabbit.oak.spi.commit.EditorHook;
 import org.apache.jackrabbit.oak.spi.commit.EditorProvider;
 import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
 import org.apache.jackrabbit.oak.spi.state.NodeState;
-import org.apache.jackrabbit.oak.spi.state.NodeStore;
 import org.junit.Test;
 
 /**
@@ -64,29 +62,12 @@ public class MergeRetryTest {
      */
     @Test
     public void retryInMemory() throws Exception {
-        retryInMemory(true);
-        retryInMemory(false);
-    }
-
-
-    private void retryInMemory(boolean useMK) throws Exception {
         MemoryDocumentStore ds = new MemoryDocumentStore();
         MemoryBlobStore bs = new MemoryBlobStore();
 
-        DocumentMK mk1 = createMK(1, 1000, ds, bs);
-        DocumentMK mk2 = createMK(2, 1000, ds, bs);
-
+        DocumentNodeStore ns1 = createMK(1, 1000, ds, bs);
+        DocumentNodeStore ns2 = createMK(2, 1000, ds, bs);
         try {
-            NodeStore ns1;
-            NodeStore ns2;
-            if (useMK) {
-                ns1 = new KernelNodeStore(mk1);
-                ns2 = new KernelNodeStore(mk2);
-            } else {
-                ns1 = mk1.getNodeStore();
-                ns2 = mk2.getNodeStore();
-            }
-
             NodeBuilder builder1 = ns1.getRoot().builder();
             builder1.child("bar");
 
@@ -96,38 +77,23 @@ public class MergeRetryTest {
             ns1.merge(builder1, HOOK, CommitInfo.EMPTY);
             ns2.merge(builder2, HOOK, CommitInfo.EMPTY);
         } finally {
-            mk1.dispose();
-            mk2.dispose();
+            ns1.dispose();
+            ns2.dispose();
         }
     }
 
+
     /**
      * Test for OAK-1202
      */
     @Test
     public void retryPersisted() throws Exception {
-        retryPersisted(true);
-        retryPersisted(false);
-    }
-
-    private void retryPersisted(boolean useMK) throws Exception {
         MemoryDocumentStore ds = new MemoryDocumentStore();
         MemoryBlobStore bs = new MemoryBlobStore();
 
-        DocumentMK mk1 = createMK(1, 1000, ds, bs);
-        DocumentMK mk2 = createMK(2, 1000, ds, bs);
-
+        DocumentNodeStore ns1 = createMK(1, 1000, ds, bs);
+        DocumentNodeStore ns2 = createMK(2, 1000, ds, bs);
         try {
-            NodeStore ns1;
-            NodeStore ns2;
-            if (useMK) {
-                ns1 = new KernelNodeStore(mk1);
-                ns2 = new KernelNodeStore(mk2);
-            } else {
-                ns1 = mk1.getNodeStore();
-                ns2 = mk2.getNodeStore();
-            }
-
             NodeBuilder builder1 = ns1.getRoot().builder();
             createTree(builder1.child("bar"), 2);
 
@@ -137,8 +103,8 @@ public class MergeRetryTest {
             ns1.merge(builder1, HOOK, CommitInfo.EMPTY);
             ns2.merge(builder2, HOOK, CommitInfo.EMPTY);
         } finally {
-            mk1.dispose();
-            mk2.dispose();
+            ns1.dispose();
+            ns2.dispose();
         }
     }
 
@@ -154,9 +120,9 @@ public class MergeRetryTest {
         }
     }
 
-    private DocumentMK createMK(int clusterId, int asyncDelay,
-                             DocumentStore ds, BlobStore bs) {
+    private DocumentNodeStore createMK(int clusterId, int asyncDelay,
+            DocumentStore ds, BlobStore bs) {
         return new DocumentMK.Builder().setDocumentStore(ds).setBlobStore(bs)
-                .setClusterId(clusterId).setAsyncDelay(asyncDelay).open();
+                .setClusterId(clusterId).setAsyncDelay(asyncDelay).getNodeStore();
     }
 }
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/LargeNodeStateTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/LargeNodeStateTest.java
index 28e39c9ee0..93d4181eca 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/LargeNodeStateTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/LargeNodeStateTest.java
@@ -25,7 +25,6 @@ import static junit.framework.Assert.assertTrue;
 import org.apache.jackrabbit.oak.NodeStoreFixture;
 import org.apache.jackrabbit.oak.OakBaseTest;
 import org.apache.jackrabbit.oak.api.CommitFailedException;
-import org.apache.jackrabbit.oak.kernel.KernelNodeState;
 import org.apache.jackrabbit.oak.spi.commit.CommitInfo;
 import org.apache.jackrabbit.oak.spi.commit.EmptyHook;
 import org.junit.After;
@@ -33,7 +32,7 @@ import org.junit.Before;
 import org.junit.Test;
 
 public class LargeNodeStateTest extends OakBaseTest {
-    private static final int N = KernelNodeState.MAX_CHILD_NAMES;
+    private static final int N = 100;
 
     private NodeState state;
 
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/NodeStoreCacheTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/NodeStoreCacheTest.java
deleted file mode 100644
index 1b984e0b5b..0000000000
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/NodeStoreCacheTest.java
+++ /dev/null
@@ -1,307 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.spi.state;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-import java.io.Closeable;
-import java.io.IOException;
-import java.io.InputStream;
-
-import javax.annotation.Nonnull;
-
-import com.google.common.io.Closer;
-import org.apache.jackrabbit.mk.api.MicroKernel;
-import org.apache.jackrabbit.mk.api.MicroKernelException;
-import org.apache.jackrabbit.oak.NodeStoreFixture;
-import org.apache.jackrabbit.oak.OakBaseTest;
-import org.apache.jackrabbit.oak.kernel.KernelNodeStore;
-import org.apache.jackrabbit.oak.plugins.document.DocumentMK;
-import org.apache.jackrabbit.oak.plugins.document.DocumentMK.Builder;
-import org.apache.jackrabbit.oak.spi.commit.CommitInfo;
-import org.apache.jackrabbit.oak.spi.commit.EmptyHook;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.Test;
-
-/**
- * Tests if cache is used for repeated reads on unmodified subtree.
- * See also OAK-591.
- */
-public class NodeStoreCacheTest extends OakBaseTest {
-    private static final String PROP_FILTER = "{\"properties\":[\"*\"]}";
-    private static final String PROP_FILTER_WITH_HASH = "{\"properties\":[\"*\",\":hash\"]}";
-    private static final String PROP_FILTER_WITH_ID = "{\"properties\":[\"*\",\":id\"]}";
-
-    private final Closer closer = Closer.create();
-
-    private MicroKernelWrapper wrapper;
-    private NodeStore store;
-
-    public NodeStoreCacheTest(NodeStoreFixture fixture) {
-        super(fixture);
-    }
-
-    @Before
-    public void setUp() throws Exception {
-        final DocumentMK documentMK = new Builder().open();
-        closer.register(new Closeable() {
-            @Override
-            public void close() {
-                documentMK.dispose();
-            }
-        });
-        wrapper = new MicroKernelWrapper(documentMK);
-        this.store = new KernelNodeStore(wrapper);
-
-        NodeBuilder builder = store.getRoot().builder();
-        builder.child("a");
-        NodeBuilder b = builder.child("b");
-        b.child("c");
-        b.child("d");
-        b.child("e");
-        store.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
-    }
-
-    @After
-    public void tearDown() throws IOException {
-        closer.close();
-    }
-
-    /**
-     * Provide both :hash and :id
-     */
-    @Test
-    public void withDefaultFilter() throws Exception {
-        int uncachedReads = readTreeWithCleanedCache();
-        modifyContent();
-        int cachedReads = readTreeWithCache();
-        assertTrue("cachedReads: " + cachedReads + " uncachedReads: " + uncachedReads, 
-                cachedReads < uncachedReads);
-    }
-
-    /**
-     * Don't provide :hash nor :id. This will not reduce the number of
-     * MK.getNodes() after a commit.
-     */
-    @Test
-    public void withSimpleFilter() throws Exception {
-        wrapper.filter = PROP_FILTER;
-        int uncachedReads = readTreeWithCleanedCache();
-        modifyContent();
-        int cachedReads = readTreeWithCache();
-        assertEquals("cachedReads: " + cachedReads + " uncachedReads: " + uncachedReads, 
-                cachedReads, uncachedReads);
-    }
-
-    /**
-     * Only provide :hash in MK.getNodes()
-     */
-    @Test
-    public void withHashFilter() throws Exception {
-        wrapper.filter = PROP_FILTER_WITH_HASH;
-        int uncachedReads = readTreeWithCleanedCache();
-        modifyContent();
-        int cachedReads = readTreeWithCache();
-        assertTrue("cachedReads: " + cachedReads + " uncachedReads: " + uncachedReads, 
-                cachedReads < uncachedReads);
-    }
-
-    /**
-     * Only provide :id in MK.getNodes()
-     */
-    @Test
-    public void withIdFilter() throws Exception {
-        wrapper.filter = PROP_FILTER_WITH_ID;
-        int uncachedReads = readTreeWithCleanedCache();
-        // System.out.println("Uncached reads: " + uncachedReads);
-
-        modifyContent();
-
-        int cachedReads = readTreeWithCache();
-
-        // System.out.println("Cached reads: " + cachedReads);
-        assertTrue("cachedReads: " + cachedReads + " uncachedReads: " + uncachedReads, 
-                cachedReads < uncachedReads);
-    }
-
-    //---------------------------< internal >-----------------------------------
-
-    private int readTreeWithCache() {
-        NodeState root = store.getRoot();
-        int cachedReads = wrapper.numGetNodes;
-        readTree(root);
-        return wrapper.numGetNodes - cachedReads;
-    }
-
-    private int readTreeWithCleanedCache() {
-        // start with virgin store / empty cache
-        store = new KernelNodeStore(wrapper);
-        NodeState root = store.getRoot();
-        int uncachedReads = wrapper.numGetNodes;
-        readTree(root);
-        return wrapper.numGetNodes - uncachedReads;
-    }
-
-    private void modifyContent() throws Exception {
-        NodeBuilder builder = store.getRoot().builder();
-        builder.child("a").setProperty("foo", "bar");
-        store.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
-    }
-
-    private static void readTree(NodeState root) {
-        for (ChildNodeEntry cne : root.getChildNodeEntries()) {
-            readTree(cne.getNodeState());
-        }
-    }
-
-    private static final class MicroKernelWrapper implements MicroKernel {
-
-        private final MicroKernel kernel;
-
-        String filter = null;
-        int numGetNodes = 0;
-
-        MicroKernelWrapper(MicroKernel kernel) {
-            this.kernel = kernel;
-        }
-
-        @Override
-        public String getHeadRevision() throws MicroKernelException {
-            return kernel.getHeadRevision();
-        }
-
-        @Override @Nonnull
-        public String checkpoint(long lifetime) throws MicroKernelException {
-            return kernel.checkpoint(lifetime);
-        }
-
-        @Override
-        public String getRevisionHistory(long since,
-                                         int maxEntries,
-                                         String path)
-                throws MicroKernelException {
-            return kernel.getRevisionHistory(since, maxEntries, path);
-        }
-
-        @Override
-        public String waitForCommit(String oldHeadRevisionId, long timeout)
-                throws MicroKernelException, InterruptedException {
-            return kernel.waitForCommit(oldHeadRevisionId, timeout);
-        }
-
-        @Override
-        public String getJournal(String fromRevisionId,
-                                 String toRevisionId,
-                                 String path) throws MicroKernelException {
-            return kernel.getJournal(fromRevisionId, toRevisionId, path);
-        }
-
-        @Override
-        public String diff(String fromRevisionId,
-                           String toRevisionId,
-                           String path,
-                           int depth) throws MicroKernelException {
-            return kernel.diff(fromRevisionId, toRevisionId, path, depth);
-        }
-
-        @Override
-        public boolean nodeExists(String path, String revisionId)
-                throws MicroKernelException {
-            return kernel.nodeExists(path, revisionId);
-        }
-
-        @Override
-        public long getChildNodeCount(String path, String revisionId)
-                throws MicroKernelException {
-            return kernel.getChildNodeCount(path, revisionId);
-        }
-
-        @Override
-        public String getNodes(String path,
-                               String revisionId,
-                               int depth,
-                               long offset,
-                               int maxChildNodes,
-                               String filter) throws MicroKernelException {
-            numGetNodes++;
-            if (this.filter != null) {
-                filter = this.filter;
-            }
-            return kernel.getNodes(path, revisionId, depth, offset, maxChildNodes, filter);
-        }
-
-        @Override
-        public String commit(String path,
-                             String jsonDiff,
-                             String revisionId,
-                             String message) throws MicroKernelException {
-            return kernel.commit(path, jsonDiff, revisionId, message);
-        }
-
-        @Override
-        public String branch(String trunkRevisionId)
-                throws MicroKernelException {
-            return kernel.branch(trunkRevisionId);
-        }
-
-        @Override
-        public String merge(String branchRevisionId, String message)
-                throws MicroKernelException {
-            return kernel.merge(branchRevisionId, message);
-        }
-
-        @Nonnull
-        @Override
-        public String rebase(@Nonnull String branchRevisionId,
-                             String newBaseRevisionId)
-                throws MicroKernelException {
-            return kernel.rebase(branchRevisionId, newBaseRevisionId);
-        }
-
-        @Nonnull
-        @Override
-        public String reset(@Nonnull String branchRevisionId,
-                            @Nonnull String ancestorRevisionId)
-                throws MicroKernelException {
-            return kernel.reset(branchRevisionId, ancestorRevisionId);
-        }
-
-        @Override
-        public long getLength(String blobId) throws MicroKernelException {
-            return kernel.getLength(blobId);
-        }
-
-        @Override
-        public int read(String blobId,
-                        long pos,
-                        byte[] buff,
-                        int off,
-                        int length) throws MicroKernelException {
-            return kernel.read(blobId, pos, buff, off, length);
-        }
-
-        @Override
-        public String write(InputStream in) throws MicroKernelException {
-            return kernel.write(in);
-        }
-
-    }
-}
diff --git a/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/NodeStoreTest.java b/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/NodeStoreTest.java
index e912229e8e..30b0bf610a 100644
--- a/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/NodeStoreTest.java
+++ b/oak-core/src/test/java/org/apache/jackrabbit/oak/spi/state/NodeStoreTest.java
@@ -41,7 +41,6 @@ import org.apache.jackrabbit.oak.NodeStoreFixture;
 import org.apache.jackrabbit.oak.OakBaseTest;
 import org.apache.jackrabbit.oak.api.CommitFailedException;
 import org.apache.jackrabbit.oak.api.PropertyState;
-import org.apache.jackrabbit.oak.kernel.KernelNodeState;
 import org.apache.jackrabbit.oak.plugins.commit.ConflictHook;
 import org.apache.jackrabbit.oak.plugins.commit.ConflictValidatorProvider;
 import org.apache.jackrabbit.oak.plugins.commit.JcrConflictHandler;
@@ -228,7 +227,7 @@ public class NodeStoreTest extends OakBaseTest {
     public void manyChildNodes() throws CommitFailedException {
         NodeBuilder root = store.getRoot().builder();
         NodeBuilder parent = root.child("parent");
-        for (int i = 0; i <= KernelNodeState.MAX_CHILD_NAMES; i++) {
+        for (int i = 0; i <= 100; i++) {
             parent.child("child-" + i);
         }
         store.merge(root, EmptyHook.INSTANCE, CommitInfo.EMPTY);
@@ -455,7 +454,7 @@ public class NodeStoreTest extends OakBaseTest {
 
     @Test
     public void compareAgainstBaseState100() throws CommitFailedException {
-        compareAgainstBaseState(KernelNodeState.MAX_CHILD_NAMES);
+        compareAgainstBaseState(100);
     }
 
     @Test // OAK-1320
