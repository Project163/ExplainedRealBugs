diff --git a/index/scorch/scorch_test.go b/index/scorch/scorch_test.go
index 3be52cb1..cf784755 100644
--- a/index/scorch/scorch_test.go
+++ b/index/scorch/scorch_test.go
@@ -25,9 +25,12 @@ import (
 	"time"
 
 	"github.com/blevesearch/bleve/analysis"
+	"github.com/blevesearch/bleve/analysis/analyzer/keyword"
+	"github.com/blevesearch/bleve/analysis/analyzer/standard"
 	regexpTokenizer "github.com/blevesearch/bleve/analysis/tokenizer/regexp"
 	"github.com/blevesearch/bleve/document"
 	"github.com/blevesearch/bleve/index"
+	"github.com/blevesearch/bleve/mapping"
 )
 
 func DestroyTest() error {
@@ -1707,3 +1710,55 @@ func TestIndexDocumentVisitFieldTermsWithMultipleFieldOptions(t *testing.T) {
 	}
 
 }
+
+func TestAllFieldWithDifferentTermVectorsEnabled(t *testing.T) {
+	// Based on https://github.com/blevesearch/bleve/issues/895 from xeizmendi
+	mp := mapping.NewIndexMapping()
+
+	keywordMapping := mapping.NewTextFieldMapping()
+	keywordMapping.Analyzer = keyword.Name
+	keywordMapping.IncludeTermVectors = false
+	keywordMapping.IncludeInAll = true
+
+	textMapping := mapping.NewTextFieldMapping()
+	textMapping.Analyzer = standard.Name
+	textMapping.IncludeTermVectors = true
+	textMapping.IncludeInAll = true
+
+	docMapping := mapping.NewDocumentStaticMapping()
+	docMapping.AddFieldMappingsAt("keyword", keywordMapping)
+	docMapping.AddFieldMappingsAt("text", textMapping)
+
+	mp.DefaultMapping = docMapping
+
+	_ = os.RemoveAll(testConfig["path"].(string))
+	analysisQueue := index.NewAnalysisQueue(1)
+	idx, err := NewScorch("storeName", testConfig, analysisQueue)
+	if err != nil {
+		log.Fatalln(err)
+	}
+	err = idx.Open()
+	if err != nil {
+		t.Errorf("error opening index: %v", err)
+	}
+	defer func() {
+		_ = idx.Close()
+		_ = os.RemoveAll(testConfig["path"].(string))
+	}()
+
+	data := map[string]string{
+		"keyword": "something",
+		"text":    "A sentence that includes something within.",
+	}
+
+	doc := document.NewDocument("1")
+	err = mp.MapDocument(doc, data)
+	if err != nil {
+		t.Errorf("error mapping doc: %v", err)
+	}
+
+	err = idx.Update(doc)
+	if err != nil {
+		t.Errorf("Error updating index: %v", err)
+	}
+}
diff --git a/index/scorch/segment/zap/build.go b/index/scorch/segment/zap/build.go
index 2c261a3e..ae460cef 100644
--- a/index/scorch/segment/zap/build.go
+++ b/index/scorch/segment/zap/build.go
@@ -20,7 +20,7 @@ import (
 	"os"
 )
 
-const Version uint32 = 9
+const Version uint32 = 10
 
 const Type string = "zap"
 
diff --git a/index/scorch/segment/zap/merge.go b/index/scorch/segment/zap/merge.go
index f2a88185..9a7041b0 100644
--- a/index/scorch/segment/zap/merge.go
+++ b/index/scorch/segment/zap/merge.go
@@ -427,17 +427,30 @@ func mergeTermFreqNormLocs(fieldsMap map[string]uint16, term []byte, postItr *Po
 		}
 
 		if len(locs) > 0 {
+			numBytesLocs := 0
 			for _, loc := range locs {
-				if cap(bufLoc) < 5+len(loc.ArrayPositions()) {
-					bufLoc = make([]uint64, 0, 5+len(loc.ArrayPositions()))
+				ap := loc.ArrayPositions()
+				numBytesLocs += totalUvarintBytes(uint64(fieldsMap[loc.Field()]-1),
+					loc.Pos(), loc.Start(), loc.End(), uint64(len(ap)), ap)
+			}
+
+			err = locEncoder.Add(hitNewDocNum, uint64(numBytesLocs))
+			if err != nil {
+				return 0, 0, 0, nil, err
+			}
+
+			for _, loc := range locs {
+				ap := loc.ArrayPositions()
+				if cap(bufLoc) < 5+len(ap) {
+					bufLoc = make([]uint64, 0, 5+len(ap))
 				}
 				args := bufLoc[0:5]
 				args[0] = uint64(fieldsMap[loc.Field()] - 1)
 				args[1] = loc.Pos()
 				args[2] = loc.Start()
 				args[3] = loc.End()
-				args[4] = uint64(len(loc.ArrayPositions()))
-				args = append(args, loc.ArrayPositions()...)
+				args[4] = uint64(len(ap))
+				args = append(args, ap...)
 				err = locEncoder.Add(hitNewDocNum, args...)
 				if err != nil {
 					return 0, 0, 0, nil, err
diff --git a/index/scorch/segment/zap/new.go b/index/scorch/segment/zap/new.go
index da24988a..4d56b069 100644
--- a/index/scorch/segment/zap/new.go
+++ b/index/scorch/segment/zap/new.go
@@ -190,7 +190,7 @@ type interimStoredField struct {
 type interimFreqNorm struct {
 	freq    uint64
 	norm    float32
-	hasLocs bool
+	numLocs int
 }
 
 type interimLoc struct {
@@ -446,7 +446,7 @@ func (s *interim) processDocument(docNum uint64,
 				interimFreqNorm{
 					freq:    uint64(tf.Frequency()),
 					norm:    norm,
-					hasLocs: len(tf.Locations) > 0,
+					numLocs: len(tf.Locations),
 				})
 
 			if len(tf.Locations) > 0 {
@@ -632,18 +632,28 @@ func (s *interim) writeDicts() (fdvIndexOffset uint64, dictOffsets []uint64, err
 				freqNorm := freqNorms[freqNormOffset]
 
 				err = tfEncoder.Add(docNum,
-					encodeFreqHasLocs(freqNorm.freq, freqNorm.hasLocs),
+					encodeFreqHasLocs(freqNorm.freq, freqNorm.numLocs > 0),
 					uint64(math.Float32bits(freqNorm.norm)))
 				if err != nil {
 					return 0, nil, err
 				}
 
-				for i := uint64(0); i < freqNorm.freq; i++ {
-					if len(locs) > 0 {
-						loc := locs[locOffset]
+				if freqNorm.numLocs > 0 {
+					numBytesLocs := 0
+					for _, loc := range locs[locOffset : locOffset+freqNorm.numLocs] {
+						numBytesLocs += totalUvarintBytes(
+							uint64(loc.fieldID), loc.pos, loc.start, loc.end,
+							uint64(len(loc.arrayposs)), loc.arrayposs)
+					}
+
+					err = locEncoder.Add(docNum, uint64(numBytesLocs))
+					if err != nil {
+						return 0, nil, err
+					}
 
-						err = locEncoder.Add(docNum, uint64(loc.fieldID),
-							loc.pos, loc.start, loc.end,
+					for _, loc := range locs[locOffset : locOffset+freqNorm.numLocs] {
+						err = locEncoder.Add(docNum,
+							uint64(loc.fieldID), loc.pos, loc.start, loc.end,
 							uint64(len(loc.arrayposs)))
 						if err != nil {
 							return 0, nil, err
@@ -655,7 +665,7 @@ func (s *interim) writeDicts() (fdvIndexOffset uint64, dictOffsets []uint64, err
 						}
 					}
 
-					locOffset++
+					locOffset += freqNorm.numLocs
 				}
 
 				freqNormOffset++
@@ -775,3 +785,26 @@ func encodeFieldType(f document.Field) byte {
 	}
 	return fieldType
 }
+
+// returns the total # of bytes needed to encode the given uint64's
+// into binary.PutUVarint() encoding
+func totalUvarintBytes(a, b, c, d, e uint64, more []uint64) (n int) {
+	n = numUvarintBytes(a)
+	n += numUvarintBytes(b)
+	n += numUvarintBytes(c)
+	n += numUvarintBytes(d)
+	n += numUvarintBytes(e)
+	for _, v := range more {
+		n += numUvarintBytes(v)
+	}
+	return n
+}
+
+// returns # of bytes needed to encode x in binary.PutUvarint() encoding
+func numUvarintBytes(x uint64) (n int) {
+	for x >= 0x80 {
+		x >>= 7
+		n++
+	}
+	return n + 1
+}
diff --git a/index/scorch/segment/zap/posting.go b/index/scorch/segment/zap/posting.go
index f709920f..7bfbe0be 100644
--- a/index/scorch/segment/zap/posting.go
+++ b/index/scorch/segment/zap/posting.go
@@ -18,6 +18,7 @@ import (
 	"bytes"
 	"encoding/binary"
 	"fmt"
+	"io"
 	"math"
 	"reflect"
 
@@ -539,7 +540,10 @@ func (i *PostingsIterator) nextAtOrAfter(atOrAfter uint64) (segment.Posting, err
 	rv.norm = math.Float32frombits(uint32(normBits))
 
 	if i.includeLocs && hasLocs {
-		// read off 'freq' locations, into reused slices
+		// prepare locations into reused slices, where we assume
+		// rv.freq >= "number of locs", since in a composite field,
+		// some component fields might have their IncludeTermVector
+		// flags disabled while other component fields are enabled
 		if cap(i.nextLocs) >= int(rv.freq) {
 			i.nextLocs = i.nextLocs[0:rv.freq]
 		} else {
@@ -548,13 +552,22 @@ func (i *PostingsIterator) nextAtOrAfter(atOrAfter uint64) (segment.Posting, err
 		if cap(i.nextSegmentLocs) < int(rv.freq) {
 			i.nextSegmentLocs = make([]segment.Location, rv.freq, rv.freq*2)
 		}
-		rv.locs = i.nextSegmentLocs[0:rv.freq]
-		for j := 0; j < int(rv.freq); j++ {
+		rv.locs = i.nextSegmentLocs[:0]
+
+		numLocsBytes, err := binary.ReadUvarint(i.locReader)
+		if err != nil {
+			return nil, fmt.Errorf("error reading location numLocsBytes: %v", err)
+		}
+
+		j := 0
+		startBytesRemaining := i.locReader.Len() // # bytes remaining in the locReader
+		for startBytesRemaining-i.locReader.Len() < int(numLocsBytes) {
 			err := i.readLocation(&i.nextLocs[j])
 			if err != nil {
 				return nil, err
 			}
-			rv.locs[j] = &i.nextLocs[j]
+			rv.locs = append(rv.locs, &i.nextLocs[j])
+			j++
 		}
 	}
 
@@ -597,11 +610,16 @@ func (i *PostingsIterator) nextBytes() (
 	if hasLocs {
 		startLoc := len(i.currChunkLoc) - i.locReader.Len()
 
-		for j := uint64(0); j < freq; j++ {
-			err := i.readLocation(nil)
-			if err != nil {
-				return 0, 0, 0, nil, nil, err
-			}
+		numLocsBytes, err := binary.ReadUvarint(i.locReader)
+		if err != nil {
+			return 0, 0, 0, nil, nil,
+				fmt.Errorf("error reading location nextBytes numLocs: %v", err)
+		}
+
+		// skip over all the location bytes
+		_, err = i.locReader.Seek(int64(numLocsBytes), io.SeekCurrent)
+		if err != nil {
+			return 0, 0, 0, nil, nil, err
 		}
 
 		endLoc := len(i.currChunkLoc) - i.locReader.Len()
@@ -659,17 +677,21 @@ func (i *PostingsIterator) nextDocNumAtOrAfter(atOrAfter uint64) (uint64, bool,
 			}
 
 			// read off freq/offsets even though we don't care about them
-			freq, _, hasLocs, err := i.readFreqNormHasLocs()
+			_, _, hasLocs, err := i.readFreqNormHasLocs()
 			if err != nil {
 				return 0, false, err
 			}
 
 			if i.includeLocs && hasLocs {
-				for j := 0; j < int(freq); j++ {
-					err := i.readLocation(nil)
-					if err != nil {
-						return 0, false, err
-					}
+				numLocsBytes, err := binary.ReadUvarint(i.locReader)
+				if err != nil {
+					return 0, false, fmt.Errorf("error reading location numLocsBytes: %v", err)
+				}
+
+				// skip over all the location bytes
+				_, err = i.locReader.Seek(int64(numLocsBytes), io.SeekCurrent)
+				if err != nil {
+					return 0, false, err
 				}
 			}
 		}
