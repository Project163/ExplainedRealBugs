diff --git a/analysis/language/fr/analyzer_fr.go b/analysis/language/fr/analyzer_fr.go
index 7a6759dd..7b8f8741 100644
--- a/analysis/language/fr/analyzer_fr.go
+++ b/analysis/language/fr/analyzer_fr.go
@@ -39,7 +39,7 @@ func AnalyzerConstructor(config map[string]interface{}, cache *registry.Cache) (
 	if err != nil {
 		return nil, err
 	}
-	stemmerFrFilter, err := cache.TokenFilterNamed(StemmerName)
+	stemmerFrFilter, err := cache.TokenFilterNamed(LightStemmerName)
 	if err != nil {
 		return nil, err
 	}
diff --git a/analysis/language/fr/analyzer_fr_test.go b/analysis/language/fr/analyzer_fr_test.go
index c95dfd77..91580fe7 100644
--- a/analysis/language/fr/analyzer_fr_test.go
+++ b/analysis/language/fr/analyzer_fr_test.go
@@ -79,31 +79,28 @@ func TestFrenchAnalyzer(t *testing.T) {
 				},
 			},
 		},
-		// fails
-		// {
-		// 	input: []byte("mot \"entreguillemet\""),
-		// 	output: analysis.TokenStream{
-		// 		&analysis.Token{
-		// 			Term: []byte("mot"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("entreguilemet"),
-		// 		},
-		// 	},
-		// },
-		// fails, lucene light stemmer normalizes ç to c
-		// need to invsetigate french stemmer
-		// {
-		// 	input: []byte("Jean-François"),
-		// 	output: analysis.TokenStream{
-		// 		&analysis.Token{
-		// 			Term: []byte("jean"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("francoi"),
-		// 		},
-		// 	},
-		// },
+		{
+			input: []byte("mot \"entreguillemet\""),
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("mot"),
+				},
+				&analysis.Token{
+					Term: []byte("entreguilemet"),
+				},
+			},
+		},
+		{
+			input: []byte("Jean-François"),
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("jean"),
+				},
+				&analysis.Token{
+					Term: []byte("francoi"),
+				},
+			},
+		},
 		// stop words
 		{
 			input: []byte("le la chien les aux chat du des à cheval"),
@@ -120,70 +117,67 @@ func TestFrenchAnalyzer(t *testing.T) {
 			},
 		},
 		// nouns and adjectives
-		// fails, stemming difference on habitabl/habit and é to e normalization
-		// {
-		// 	input: []byte("lances chismes habitable chiste éléments captifs"),
-		// 	output: analysis.TokenStream{
-		// 		&analysis.Token{
-		// 			Term: []byte("lanc"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("chism"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("habitabl"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("chist"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("element"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("captif"),
-		// 		},
-		// 	},
-		// },
+		{
+			input: []byte("lances chismes habitable chiste éléments captifs"),
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("lanc"),
+				},
+				&analysis.Token{
+					Term: []byte("chism"),
+				},
+				&analysis.Token{
+					Term: []byte("habitabl"),
+				},
+				&analysis.Token{
+					Term: []byte("chist"),
+				},
+				&analysis.Token{
+					Term: []byte("element"),
+				},
+				&analysis.Token{
+					Term: []byte("captif"),
+				},
+			},
+		},
 		// verbs
-		// fails very different stemming results
-		// {
-		// 	input: []byte("finissions souffrirent rugissante"),
-		// 	output: analysis.TokenStream{
-		// 		&analysis.Token{
-		// 			Term: []byte("finision"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("soufrirent"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("rugisant"),
-		// 		},
-		// 	},
-		// },
-		// also fails, very different stemming results
-		// {
-		// 	input: []byte("C3PO aujourd'hui oeuf ïâöûàä anticonstitutionnellement Java++ "),
-		// 	output: analysis.TokenStream{
-		// 		&analysis.Token{
-		// 			Term: []byte("c3po"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("aujourd'hui"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("oeuf"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("ïaöuaä"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("anticonstitutionel'hui"),
-		// 		},
-		// 		&analysis.Token{
-		// 			Term: []byte("java"),
-		// 		},
-		// 	},
-		// },
+		{
+			input: []byte("finissions souffrirent rugissante"),
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("finision"),
+				},
+				&analysis.Token{
+					Term: []byte("soufrirent"),
+				},
+				&analysis.Token{
+					Term: []byte("rugisant"),
+				},
+			},
+		},
+		{
+			input: []byte("C3PO aujourd'hui oeuf ïâöûàä anticonstitutionnellement Java++ "),
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("c3po"),
+				},
+				&analysis.Token{
+					Term: []byte("aujourd'hui"),
+				},
+				&analysis.Token{
+					Term: []byte("oeuf"),
+				},
+				&analysis.Token{
+					Term: []byte("ïaöuaä"),
+				},
+				&analysis.Token{
+					Term: []byte("anticonstitutionel'hui"),
+				},
+				&analysis.Token{
+					Term: []byte("java"),
+				},
+			},
+		},
 	}
 
 	cache := registry.NewCache()
diff --git a/analysis/language/fr/light_stemmer_fr.go b/analysis/language/fr/light_stemmer_fr.go
new file mode 100644
index 00000000..1b598a3e
--- /dev/null
+++ b/analysis/language/fr/light_stemmer_fr.go
@@ -0,0 +1,308 @@
+//  Copyright (c) 2015 Couchbase, Inc.
+//  Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file
+//  except in compliance with the License. You may obtain a copy of the License at
+//    http://www.apache.org/licenses/LICENSE-2.0
+//  Unless required by applicable law or agreed to in writing, software distributed under the
+//  License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
+//  either express or implied. See the License for the specific language governing permissions
+//  and limitations under the License.
+
+package fr
+
+import (
+	"bytes"
+	"unicode"
+
+	"github.com/blevesearch/bleve/analysis"
+	"github.com/blevesearch/bleve/registry"
+)
+
+const LightStemmerName = "stemmer_fr_light"
+
+type FrenchLightStemmerFilter struct {
+}
+
+func NewFrenchLightStemmerFilter() *FrenchLightStemmerFilter {
+	return &FrenchLightStemmerFilter{}
+}
+
+func (s *FrenchLightStemmerFilter) Filter(input analysis.TokenStream) analysis.TokenStream {
+	for _, token := range input {
+		runes := bytes.Runes(token.Term)
+		runes = stem(runes)
+		token.Term = analysis.BuildTermFromRunes(runes)
+	}
+	return input
+}
+
+func stem(input []rune) []rune {
+
+	inputLen := len(input)
+
+	if inputLen > 5 && input[inputLen-1] == 'x' {
+		if input[inputLen-3] == 'a' && input[inputLen-2] == 'u' && input[inputLen-4] != 'e' {
+			input[inputLen-2] = 'l'
+		}
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+	}
+
+	if inputLen > 3 && input[inputLen-1] == 'x' {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+	}
+
+	if inputLen > 3 && input[inputLen-1] == 's' {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+	}
+
+	if inputLen > 9 && analysis.RunesEndsWith(input, "issement") {
+		input = input[0 : inputLen-6]
+		inputLen = len(input)
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 8 && analysis.RunesEndsWith(input, "issant") {
+		input = input[0 : inputLen-4]
+		inputLen = len(input)
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 6 && analysis.RunesEndsWith(input, "ement") {
+		input = input[0 : inputLen-4]
+		inputLen = len(input)
+		if inputLen > 3 && analysis.RunesEndsWith(input, "ive") {
+			input = input[0 : inputLen-1]
+			inputLen = len(input)
+			input[inputLen-1] = 'f'
+		}
+		return norm(input)
+	}
+
+	if inputLen > 11 && analysis.RunesEndsWith(input, "ficatrice") {
+		input = input[0 : inputLen-5]
+		inputLen = len(input)
+		input[inputLen-2] = 'e'
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 10 && analysis.RunesEndsWith(input, "ficateur") {
+		input = input[0 : inputLen-4]
+		inputLen = len(input)
+		input[inputLen-2] = 'e'
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 9 && analysis.RunesEndsWith(input, "catrice") {
+		input = input[0 : inputLen-3]
+		inputLen = len(input)
+		input[inputLen-4] = 'q'
+		input[inputLen-3] = 'u'
+		input[inputLen-2] = 'e'
+		//s[len-1] = 'r' <-- unnecessary, already 'r'.
+		return norm(input)
+	}
+
+	if inputLen > 8 && analysis.RunesEndsWith(input, "cateur") {
+		input = input[0 : inputLen-2]
+		inputLen = len(input)
+		input[inputLen-4] = 'q'
+		input[inputLen-3] = 'u'
+		input[inputLen-2] = 'e'
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 8 && analysis.RunesEndsWith(input, "atrice") {
+		input = input[0 : inputLen-4]
+		inputLen = len(input)
+		input[inputLen-2] = 'e'
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 7 && analysis.RunesEndsWith(input, "ateur") {
+		input = input[0 : inputLen-3]
+		inputLen = len(input)
+		input[inputLen-2] = 'e'
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 6 && analysis.RunesEndsWith(input, "trice") {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+		input[inputLen-3] = 'e'
+		input[inputLen-2] = 'u'
+		input[inputLen-1] = 'r'
+	}
+
+	if inputLen > 5 && analysis.RunesEndsWith(input, "ième") {
+		return norm(input[0 : inputLen-4])
+	}
+
+	if inputLen > 7 && analysis.RunesEndsWith(input, "teuse") {
+		input = input[0 : inputLen-2]
+		inputLen = len(input)
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 6 && analysis.RunesEndsWith(input, "teur") {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+		input[inputLen-1] = 'r'
+		return norm(input)
+	}
+
+	if inputLen > 5 && analysis.RunesEndsWith(input, "euse") {
+		return norm(input[0 : inputLen-2])
+	}
+
+	if inputLen > 8 && analysis.RunesEndsWith(input, "ère") {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+		input[inputLen-2] = 'e'
+		return norm(input)
+	}
+
+	if inputLen > 7 && analysis.RunesEndsWith(input, "ive") {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+		input[inputLen-1] = 'f'
+		return norm(input)
+	}
+
+	if inputLen > 4 &&
+		(analysis.RunesEndsWith(input, "folle") ||
+			analysis.RunesEndsWith(input, "molle")) {
+		input = input[0 : inputLen-2]
+		inputLen = len(input)
+		input[inputLen-1] = 'u'
+		return norm(input)
+	}
+
+	if inputLen > 9 && analysis.RunesEndsWith(input, "nnelle") {
+		return norm(input[0 : inputLen-5])
+	}
+
+	if inputLen > 9 && analysis.RunesEndsWith(input, "nnel") {
+		return norm(input[0 : inputLen-3])
+	}
+
+	if inputLen > 4 && analysis.RunesEndsWith(input, "ète") {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+		input[inputLen-2] = 'e'
+	}
+
+	if inputLen > 8 && analysis.RunesEndsWith(input, "ique") {
+		input = input[0 : inputLen-4]
+		inputLen = len(input)
+	}
+
+	if inputLen > 8 && analysis.RunesEndsWith(input, "esse") {
+		return norm(input[0 : inputLen-3])
+	}
+
+	if inputLen > 7 && analysis.RunesEndsWith(input, "inage") {
+		return norm(input[0 : inputLen-3])
+	}
+
+	if inputLen > 9 && analysis.RunesEndsWith(input, "isation") {
+		input = input[0 : inputLen-7]
+		inputLen = len(input)
+		if inputLen > 5 && analysis.RunesEndsWith(input, "ual") {
+			input[inputLen-2] = 'e'
+		}
+		return norm(input)
+	}
+
+	if inputLen > 9 && analysis.RunesEndsWith(input, "isateur") {
+		return norm(input[0 : inputLen-7])
+	}
+
+	if inputLen > 8 && analysis.RunesEndsWith(input, "ation") {
+		return norm(input[0 : inputLen-5])
+	}
+
+	if inputLen > 8 && analysis.RunesEndsWith(input, "ition") {
+		return norm(input[0 : inputLen-5])
+	}
+
+	return norm(input)
+
+}
+
+func norm(input []rune) []rune {
+
+	inputLen := len(input)
+	if inputLen > 4 {
+		for i := 0; i < inputLen; i++ {
+			switch input[i] {
+			case 'à', 'á', 'â':
+				input[i] = 'a'
+			case 'ô':
+				input[i] = 'o'
+			case 'è', 'é', 'ê':
+				input[i] = 'e'
+			case 'ù', 'û':
+				input[i] = 'u'
+			case 'î':
+				input[i] = 'i'
+			case 'ç':
+				input[i] = 'c'
+			}
+
+			ch := input[0]
+			for i := 1; i < inputLen; i++ {
+				if input[i] == ch && unicode.IsLetter(ch) {
+					input = analysis.DeleteRune(input, i)
+					i -= 1
+					inputLen = len(input)
+				} else {
+					ch = input[i]
+				}
+			}
+		}
+	}
+
+	if inputLen > 4 && analysis.RunesEndsWith(input, "ie") {
+		input = input[0 : inputLen-2]
+		inputLen = len(input)
+	}
+
+	if inputLen > 4 {
+		if input[inputLen-1] == 'r' {
+			input = input[0 : inputLen-1]
+			inputLen = len(input)
+		}
+		if input[inputLen-1] == 'e' {
+			input = input[0 : inputLen-1]
+			inputLen = len(input)
+		}
+		if input[inputLen-1] == 'e' {
+			input = input[0 : inputLen-1]
+			inputLen = len(input)
+		}
+		if input[inputLen-1] == input[inputLen-2] && unicode.IsLetter(input[inputLen-1]) {
+			input = input[0 : inputLen-1]
+			inputLen = len(input)
+		}
+	}
+
+	return input
+}
+
+func FrenchLightStemmerFilterConstructor(config map[string]interface{}, cache *registry.Cache) (analysis.TokenFilter, error) {
+	return NewFrenchLightStemmerFilter(), nil
+}
+
+func init() {
+	registry.RegisterTokenFilter(LightStemmerName, FrenchLightStemmerFilterConstructor)
+}
diff --git a/analysis/language/fr/light_stemmer_fr_test.go b/analysis/language/fr/light_stemmer_fr_test.go
new file mode 100644
index 00000000..915e730e
--- /dev/null
+++ b/analysis/language/fr/light_stemmer_fr_test.go
@@ -0,0 +1,997 @@
+//  Copyright (c) 2015 Couchbase, Inc.
+//  Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file
+//  except in compliance with the License. You may obtain a copy of the License at
+//    http://www.apache.org/licenses/LICENSE-2.0
+//  Unless required by applicable law or agreed to in writing, software distributed under the
+//  License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
+//  either express or implied. See the License for the specific language governing permissions
+//  and limitations under the License.
+
+package fr
+
+import (
+	"reflect"
+	"testing"
+
+	"github.com/blevesearch/bleve/analysis"
+	"github.com/blevesearch/bleve/registry"
+)
+
+func TestFrenchLightStemmer(t *testing.T) {
+	tests := []struct {
+		input  analysis.TokenStream
+		output analysis.TokenStream
+	}{
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chevaux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("cheval"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("cheval"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("cheval"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("hiboux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("hibou"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("hibou"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("hibou"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chantés"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chanter"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chante"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chant"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baronnes"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baron"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("barons"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baron"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baron"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baron"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("peaux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("peau"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("peau"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("peau"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("anneaux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("aneau"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("anneau"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("aneau"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("neveux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("neveu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("neveu"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("neveu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("affreux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("afreu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("affreuse"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("afreu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("investissement"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("investi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("investir"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("investi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("assourdissant"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("asourdi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("assourdir"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("asourdi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("pratiquement"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("pratiqu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("pratique"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("pratiqu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("administrativement"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("administratif"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("administratif"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("administratif"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("justificatrice"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("justifi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("justificateur"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("justifi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("justifier"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("justifi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("educatrice"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("eduqu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("eduquer"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("eduqu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("communicateur"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("comuniqu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("communiquer"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("comuniqu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("accompagnatrice"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("acompagn"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("accompagnateur"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("acompagn"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("administrateur"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("administr"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("administrer"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("administr"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("productrice"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("product"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("producteur"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("product"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("acheteuse"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("achet"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("acheteur"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("achet"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("planteur"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("plant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("plante"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("plant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("poreuse"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("poreu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("poreux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("poreu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("plieuse"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("plieu"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("bijoutière"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("bijouti"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("bijoutier"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("bijouti"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("caissière"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("caisi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("caissier"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("caisi"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("abrasive"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("abrasif"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("abrasif"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("abrasif"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("folle"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("fou"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("fou"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("fou"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("personnelle"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("person"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("personne"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("person"),
+				},
+			},
+		},
+		// algo bug: too short length
+		// {
+		// 	input: analysis.TokenStream{
+		// 		&analysis.Token{
+		// 			Term: []byte("personnel"),
+		// 		},
+		// 	},
+		// 	output: analysis.TokenStream{
+		// 		&analysis.Token{
+		// 			Term: []byte("person"),
+		// 		},
+		// 	},
+		// },
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("complète"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("complet"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("complet"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("complet"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("aromatique"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("aromat"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("faiblesse"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("faibl"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("faible"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("faibl"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("patinage"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("patin"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("patin"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("patin"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("sonorisation"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("sono"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("ritualisation"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("rituel"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("rituel"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("rituel"),
+				},
+			},
+		},
+		// algo bug: masked by rules above
+		// {
+		// 	input: analysis.TokenStream{
+		// 		&analysis.Token{
+		// 			Term: []byte("colonisateur"),
+		// 		},
+		// 	},
+		// 	output: analysis.TokenStream{
+		// 		&analysis.Token{
+		// 			Term: []byte("colon"),
+		// 		},
+		// 	},
+		// },
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("nomination"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("nomin"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("disposition"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("dispos"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("dispose"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("dispos"),
+				},
+			},
+		},
+		// SOLR-3463 : abusive compression of repeated characters in numbers
+		// Trailing repeated char elision :
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("1234555"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("1234555"),
+				},
+			},
+		},
+		// Repeated char within numbers with more than 4 characters :
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("12333345"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("12333345"),
+				},
+			},
+		},
+		// Short numbers weren't affected already:
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("1234"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("1234"),
+				},
+			},
+		},
+		// Ensure behaviour is preserved for words!
+		// Trailing repeated char elision :
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("abcdeff"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("abcdef"),
+				},
+			},
+		},
+		// Repeated char within words with more than 4 characters :
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("abcccddeef"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("abcdef"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("créées"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("cre"),
+				},
+			},
+		},
+		// Combined letter and digit repetition
+		// 10:00pm
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("22hh00"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("22h00"),
+				},
+			},
+		},
+	}
+
+	cache := registry.NewCache()
+	filter, err := cache.TokenFilterNamed(LightStemmerName)
+	if err != nil {
+		t.Fatal(err)
+	}
+	for _, test := range tests {
+		actual := filter.Filter(test.input)
+		if !reflect.DeepEqual(actual, test.output) {
+			t.Errorf("expected %s, got %s", test.output[0].Term, actual[0].Term)
+		}
+	}
+}
diff --git a/analysis/language/fr/minimal_stemmer_fr.go b/analysis/language/fr/minimal_stemmer_fr.go
new file mode 100644
index 00000000..4e09b90f
--- /dev/null
+++ b/analysis/language/fr/minimal_stemmer_fr.go
@@ -0,0 +1,81 @@
+//  Copyright (c) 2015 Couchbase, Inc.
+//  Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file
+//  except in compliance with the License. You may obtain a copy of the License at
+//    http://www.apache.org/licenses/LICENSE-2.0
+//  Unless required by applicable law or agreed to in writing, software distributed under the
+//  License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
+//  either express or implied. See the License for the specific language governing permissions
+//  and limitations under the License.
+
+package fr
+
+import (
+	"bytes"
+
+	"github.com/blevesearch/bleve/analysis"
+	"github.com/blevesearch/bleve/registry"
+)
+
+const MinimalStemmerName = "stemmer_fr_min"
+
+type FrenchMinimalStemmerFilter struct {
+}
+
+func NewFrenchMinimalStemmerFilter() *FrenchMinimalStemmerFilter {
+	return &FrenchMinimalStemmerFilter{}
+}
+
+func (s *FrenchMinimalStemmerFilter) Filter(input analysis.TokenStream) analysis.TokenStream {
+	for _, token := range input {
+		runes := bytes.Runes(token.Term)
+		runes = minstem(runes)
+		token.Term = analysis.BuildTermFromRunes(runes)
+	}
+	return input
+}
+
+func minstem(input []rune) []rune {
+
+	inputLen := len(input)
+
+	if inputLen < 6 {
+		return input
+	}
+
+	if input[inputLen-1] == 'x' {
+		if input[inputLen-3] == 'a' && input[inputLen-2] == 'u' {
+			input[inputLen-2] = 'l'
+		}
+		return input[0 : inputLen-1]
+	}
+
+	if input[inputLen-1] == 's' {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+	}
+	if input[inputLen-1] == 'r' {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+	}
+	if input[inputLen-1] == 'e' {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+	}
+	if input[inputLen-1] == 'é' {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+	}
+	if input[inputLen-1] == input[inputLen-2] {
+		input = input[0 : inputLen-1]
+		inputLen = len(input)
+	}
+	return input
+}
+
+func FrenchMinimalStemmerFilterConstructor(config map[string]interface{}, cache *registry.Cache) (analysis.TokenFilter, error) {
+	return NewFrenchMinimalStemmerFilter(), nil
+}
+
+func init() {
+	registry.RegisterTokenFilter(MinimalStemmerName, FrenchMinimalStemmerFilterConstructor)
+}
diff --git a/analysis/language/fr/minimal_stemmer_fr_test.go b/analysis/language/fr/minimal_stemmer_fr_test.go
new file mode 100644
index 00000000..b7aa0ffe
--- /dev/null
+++ b/analysis/language/fr/minimal_stemmer_fr_test.go
@@ -0,0 +1,134 @@
+//  Copyright (c) 2015 Couchbase, Inc.
+//  Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file
+//  except in compliance with the License. You may obtain a copy of the License at
+//    http://www.apache.org/licenses/LICENSE-2.0
+//  Unless required by applicable law or agreed to in writing, software distributed under the
+//  License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
+//  either express or implied. See the License for the specific language governing permissions
+//  and limitations under the License.
+
+package fr
+
+import (
+	"reflect"
+	"testing"
+
+	"github.com/blevesearch/bleve/analysis"
+	"github.com/blevesearch/bleve/registry"
+)
+
+func TestFrenchMinimalStemmer(t *testing.T) {
+	tests := []struct {
+		input  analysis.TokenStream
+		output analysis.TokenStream
+	}{
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chevaux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("cheval"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("hiboux"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("hibou"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chantés"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chanter"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chante"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("chant"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baronnes"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baron"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("barons"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baron"),
+				},
+			},
+		},
+		{
+			input: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baron"),
+				},
+			},
+			output: analysis.TokenStream{
+				&analysis.Token{
+					Term: []byte("baron"),
+				},
+			},
+		},
+	}
+
+	cache := registry.NewCache()
+	filter, err := cache.TokenFilterNamed(MinimalStemmerName)
+	if err != nil {
+		t.Fatal(err)
+	}
+	for _, test := range tests {
+		actual := filter.Filter(test.input)
+		if !reflect.DeepEqual(actual, test.output) {
+			t.Errorf("expected %s, got %s", test.output[0].Term, actual[0].Term)
+		}
+	}
+}
diff --git a/analysis/util.go b/analysis/util.go
index cf297809..f15f08e4 100644
--- a/analysis/util.go
+++ b/analysis/util.go
@@ -50,3 +50,20 @@ func TruncateRunes(input []byte, num int) []byte {
 	out := BuildTermFromRunes(runes)
 	return out
 }
+
+func RunesEndsWith(input []rune, suffix string) bool {
+	inputLen := len(input)
+	suffixRunes := []rune(suffix)
+	suffixLen := len(suffixRunes)
+	if suffixLen > inputLen {
+		return false
+	}
+
+	for i := suffixLen - 1; i >= 0; i-- {
+		if input[inputLen-(suffixLen-i)] != suffixRunes[i] {
+			return false
+		}
+	}
+
+	return true
+}
