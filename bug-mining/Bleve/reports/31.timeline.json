[{"id":147475198,"node_id":"MDEyOkxhYmVsZWRFdmVudDE0NzQ3NTE5OA==","url":"https://api.github.com/repos/blevesearch/bleve/issues/events/147475198","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2014-07-30T22:54:26Z","label":{"name":"enhancement","color":"84b6eb"},"performed_via_github_app":null},{"id":147487387,"node_id":"MDEyOkxhYmVsZWRFdmVudDE0NzQ4NzM4Nw==","url":"https://api.github.com/repos/blevesearch/bleve/issues/events/147487387","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2014-07-30T23:35:26Z","label":{"name":"analysis","color":"006b75"},"performed_via_github_app":null},{"id":150559475,"node_id":"MDE3OlJlbmFtZWRUaXRsZUV2ZW50MTUwNTU5NDc1","url":"https://api.github.com/repos/blevesearch/bleve/issues/events/150559475","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"renamed","commit_id":null,"commit_url":null,"created_at":"2014-08-08T02:25:47Z","rename":{"from":"need cjk_bigram","to":"cjk_bigram"},"performed_via_github_app":null},{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54739720","html_url":"https://github.com/blevesearch/bleve/issues/34#issuecomment-54739720","issue_url":"https://api.github.com/repos/blevesearch/bleve/issues/34","id":54739720,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NzM5NzIw","user":{"login":"purohit","id":336266,"node_id":"MDQ6VXNlcjMzNjI2Ng==","avatar_url":"https://avatars.githubusercontent.com/u/336266?v=4","gravatar_id":"","url":"https://api.github.com/users/purohit","html_url":"https://github.com/purohit","followers_url":"https://api.github.com/users/purohit/followers","following_url":"https://api.github.com/users/purohit/following{/other_user}","gists_url":"https://api.github.com/users/purohit/gists{/gist_id}","starred_url":"https://api.github.com/users/purohit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/purohit/subscriptions","organizations_url":"https://api.github.com/users/purohit/orgs","repos_url":"https://api.github.com/users/purohit/repos","events_url":"https://api.github.com/users/purohit/events{/privacy}","received_events_url":"https://api.github.com/users/purohit/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2014-09-07T07:30:08Z","updated_at":"2014-09-07T07:30:08Z","body":"What needs to be done for this? I'm considering using bleve for my website for Chinese, outspokenlanguage.com. Right now I use redis-go-search but it's not good with CJK searching.\n\nI can easily get a cleaned dataset of all simplified Chinese (and probably Traditional) unigrams and bigrams from Google's Ngram data. But I've never worked on word searching before, so you'd have to give me some guidance.\n","author_association":"NONE","reactions":{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54739720/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"purohit","id":336266,"node_id":"MDQ6VXNlcjMzNjI2Ng==","avatar_url":"https://avatars.githubusercontent.com/u/336266?v=4","gravatar_id":"","url":"https://api.github.com/users/purohit","html_url":"https://github.com/purohit","followers_url":"https://api.github.com/users/purohit/followers","following_url":"https://api.github.com/users/purohit/following{/other_user}","gists_url":"https://api.github.com/users/purohit/gists{/gist_id}","starred_url":"https://api.github.com/users/purohit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/purohit/subscriptions","organizations_url":"https://api.github.com/users/purohit/orgs","repos_url":"https://api.github.com/users/purohit/repos","events_url":"https://api.github.com/users/purohit/events{/privacy}","received_events_url":"https://api.github.com/users/purohit/received_events","type":"User","user_view_type":"public","site_admin":false}},{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54746636","html_url":"https://github.com/blevesearch/bleve/issues/34#issuecomment-54746636","issue_url":"https://api.github.com/repos/blevesearch/bleve/issues/34","id":54746636,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NzQ2NjM2","user":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2014-09-07T13:27:17Z","updated_at":"2014-09-07T13:27:17Z","body":"Great, we need help in this area.\n\nThe purpose of the CJK bigram filter is to form bigrams from the input tokens, but only if the tokens are CJK characters.  It outputs non-CJK tokens as is, and it can optionally output the CJK unigrams as well.\n\nI believe the main issue we have right now is that the ICU tokenizer doesn't give us exactly the same information as lucene, so I couldn't do a straight port.   In Lucene the tokenizer has already flagged the tokens with more detailed script information, specifically, ideographic, hiragana, katakana and hangul.  The ICU tokenizer only gives us alphanumeric, kana, and ideographic.  Worse, it seems to report hangul as alphanumeric, and kana as ideographic.\n\nI think ultimately we can ignore that for now and proceed anyway.  What we need to do is introduce token types for KANA and IDEOGRAPHIC, set those types based on the what the tokenizer gives us.  Then the  cjk bigram filter can operate on those token types, and pass through others unchanged.  Despite the problems I noted above, it probably will work pretty well for Chinese and Japanese text.\n\nI don't think we need the google ngram data.  Although for more sophisticated analysis it could be handy.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54746636/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false}},{"id":162206352,"node_id":"MDE1OlJlZmVyZW5jZWRFdmVudDE2MjIwNjM1Mg==","url":"https://api.github.com/repos/blevesearch/bleve/issues/events/162206352","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"9e78643badd925dfd84dc02746b57b5b43d3ec31","commit_url":"https://api.github.com/repos/blevesearch/bleve/commits/9e78643badd925dfd84dc02746b57b5b43d3ec31","created_at":"2014-09-07T14:24:50Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54748438","html_url":"https://github.com/blevesearch/bleve/issues/34#issuecomment-54748438","issue_url":"https://api.github.com/repos/blevesearch/bleve/issues/34","id":54748438,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NzQ4NDM4","user":{"login":"purohit","id":336266,"node_id":"MDQ6VXNlcjMzNjI2Ng==","avatar_url":"https://avatars.githubusercontent.com/u/336266?v=4","gravatar_id":"","url":"https://api.github.com/users/purohit","html_url":"https://github.com/purohit","followers_url":"https://api.github.com/users/purohit/followers","following_url":"https://api.github.com/users/purohit/following{/other_user}","gists_url":"https://api.github.com/users/purohit/gists{/gist_id}","starred_url":"https://api.github.com/users/purohit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/purohit/subscriptions","organizations_url":"https://api.github.com/users/purohit/orgs","repos_url":"https://api.github.com/users/purohit/repos","events_url":"https://api.github.com/users/purohit/events{/privacy}","received_events_url":"https://api.github.com/users/purohit/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2014-09-07T14:36:11Z","updated_at":"2014-09-07T14:36:11Z","body":"Ah. Do I understand you correctly: bigram meaning character bigrams, not word bigrams? (As in, 喜歡 is a character bigram, but a word unigram). The issue of word segmentation in Chinese is harder and would require the use of a corpus like Google's ngram data (http://www.hathitrust.org/blogs/large-scale-search/multilingual-issues-part-1-word-segmentation).\n","author_association":"NONE","reactions":{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54748438/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"purohit","id":336266,"node_id":"MDQ6VXNlcjMzNjI2Ng==","avatar_url":"https://avatars.githubusercontent.com/u/336266?v=4","gravatar_id":"","url":"https://api.github.com/users/purohit","html_url":"https://github.com/purohit","followers_url":"https://api.github.com/users/purohit/followers","following_url":"https://api.github.com/users/purohit/following{/other_user}","gists_url":"https://api.github.com/users/purohit/gists{/gist_id}","starred_url":"https://api.github.com/users/purohit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/purohit/subscriptions","organizations_url":"https://api.github.com/users/purohit/orgs","repos_url":"https://api.github.com/users/purohit/repos","events_url":"https://api.github.com/users/purohit/events{/privacy}","received_events_url":"https://api.github.com/users/purohit/received_events","type":"User","user_view_type":"public","site_admin":false}},{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54748674","html_url":"https://github.com/blevesearch/bleve/issues/34#issuecomment-54748674","issue_url":"https://api.github.com/repos/blevesearch/bleve/issues/34","id":54748674,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NzQ4Njc0","user":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2014-09-07T14:45:45Z","updated_at":"2014-09-07T14:45:45Z","body":"Yes.  My understanding is (possibly wrong), that lucene/elasticsearch index character bigrams, specifically because they don't do word segmentation well.\n\nAnd looking at this closer, this is actually even more problematic for us as the ICU tokenizer we use is dictionary based.  The ICU docs claim that dictionary tokenization is already done for Thai, Khmer and CJK.  See the section at the end \"Details about Dictionary-Based Break Iteration\" http://userguide.icu-project.org/boundaryanalysis\n\nBased on this, it sounds like the bigram filter may not even be needed for now.  If we later find that the ICU tokenizer is not good enough, then we could use a different tokenizer that just gives us each character, and index bigrams.\n\nDoes this make sense?\n\nI'm putting together an online tool to let us experiment with the analyzers, this should make it easier to experiment by inputing arbitrary text, and seeing how it would be indexed.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54748674/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false}},{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54748775","html_url":"https://github.com/blevesearch/bleve/issues/34#issuecomment-54748775","issue_url":"https://api.github.com/repos/blevesearch/bleve/issues/34","id":54748775,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NzQ4Nzc1","user":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2014-09-07T14:49:31Z","updated_at":"2014-09-07T14:49:31Z","body":"Also thanks for that link it has a lot of good background information in it.\n\nOne of the frustrating things is that so much of this information is stale.  They talk about what Lucene and ICU do, but the article is from 2011.  They talk about it only doing unigrams, but bigrams in the future.  Has that future arrived?  Hard to say.  :)\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54748775/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false}},{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54749233","html_url":"https://github.com/blevesearch/bleve/issues/34#issuecomment-54749233","issue_url":"https://api.github.com/repos/blevesearch/bleve/issues/34","id":54749233,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NzQ5MjMz","user":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2014-09-07T15:04:00Z","updated_at":"2014-09-07T15:04:00Z","body":"OK, having read that link in more detail it seems to confirm what I thought.  The default behavior in Lucene/Solr/ES is to tokenize into characters, then use a bigram filter to form overlapping character bigrams.  Then these character bigrams are what is indexed.\n\nI was thinking we'd used the ICU tokenizer since it was dictionary based.  But my thought that that would automatically better doesn't seem to be supported by docs.\n\nProbably we should introduce a tokenizer that just emits the characters individually.  Then use the cjk width and bigram filters.  This will more closely approximate Lucene/Solr/ES in the short term.\n\nLonger term we can experiment to see if the dictionary/word based tokenizers are any good yet.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54749233/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false}},{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54793181","html_url":"https://github.com/blevesearch/bleve/issues/34#issuecomment-54793181","issue_url":"https://api.github.com/repos/blevesearch/bleve/issues/34","id":54793181,"node_id":"MDEyOklzc3VlQ29tbWVudDU0NzkzMTgx","user":{"login":"Shugyousha","id":500068,"node_id":"MDQ6VXNlcjUwMDA2OA==","avatar_url":"https://avatars.githubusercontent.com/u/500068?v=4","gravatar_id":"","url":"https://api.github.com/users/Shugyousha","html_url":"https://github.com/Shugyousha","followers_url":"https://api.github.com/users/Shugyousha/followers","following_url":"https://api.github.com/users/Shugyousha/following{/other_user}","gists_url":"https://api.github.com/users/Shugyousha/gists{/gist_id}","starred_url":"https://api.github.com/users/Shugyousha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Shugyousha/subscriptions","organizations_url":"https://api.github.com/users/Shugyousha/orgs","repos_url":"https://api.github.com/users/Shugyousha/repos","events_url":"https://api.github.com/users/Shugyousha/events{/privacy}","received_events_url":"https://api.github.com/users/Shugyousha/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2014-09-08T09:12:10Z","updated_at":"2014-09-08T09:12:10Z","body":"On Sun, Sep 7, 2014 at 5:04 PM, Marty Schoch notifications@github.com wrote:\n\n> Probably we should introduce a tokenizer that just emits the characters individually. Then use the cjk width and bigram filters. This will more closely approximate Lucene/Solr/ES in the short term.\n\nIt seems like Solr/Lucene uses the term \"n-gram\" to mean \"character\nn-gram\" and \"shingles\"[1] to mean \"token n-grams\" (which is what is\nusually referred to as just \"n-grams\" outside of Solr/Lucene).\n\nThe Tokenizer interface in bleve is returning a TokenStream at the\nmoment. Would we then just refer to the individual characters as\ntokens when implementing a Tokenizer for CJK in bleve?\n\nI wonder if it wouldn't make more sense to return 'word' tokens\ndirectly in CJK as well which would be more consistent with how the\nother languages are handled AFAICT.\n\nI am also not sure how Lucene/Solr handle derivations like\n\n感激的\n\nfor example which seem like they would be mangled by a character bi-gram filter.\n\n> Longer term we can experiment to see if the dictionary/word based tokenizers are any good yet.\n\nI would be interested in helping with the analysis of Japanese.\n\nIf we decide to not use character n-grams as output for the tokenizer,\nwe could try to compare the unicode_word_boundary tokenizer and\nsomething like kagome[2]/mecab[3](which would give you POS tags as\nwell).\n\n[1] https://lucene.apache.org/core/3_6_0/api/all/org/apache/lucene/analysis/shingle/ShingleFilter.html\n[2] https://github.com/ikawaha/kagome (it seems to use the mecab dictionary)\n[3] http://mecab.googlecode.com/svn/trunk/mecab/doc/index.html\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54793181/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"Shugyousha","id":500068,"node_id":"MDQ6VXNlcjUwMDA2OA==","avatar_url":"https://avatars.githubusercontent.com/u/500068?v=4","gravatar_id":"","url":"https://api.github.com/users/Shugyousha","html_url":"https://github.com/Shugyousha","followers_url":"https://api.github.com/users/Shugyousha/followers","following_url":"https://api.github.com/users/Shugyousha/following{/other_user}","gists_url":"https://api.github.com/users/Shugyousha/gists{/gist_id}","starred_url":"https://api.github.com/users/Shugyousha/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Shugyousha/subscriptions","organizations_url":"https://api.github.com/users/Shugyousha/orgs","repos_url":"https://api.github.com/users/Shugyousha/repos","events_url":"https://api.github.com/users/Shugyousha/events{/privacy}","received_events_url":"https://api.github.com/users/Shugyousha/received_events","type":"User","user_view_type":"public","site_admin":false}},{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54809443","html_url":"https://github.com/blevesearch/bleve/issues/34#issuecomment-54809443","issue_url":"https://api.github.com/repos/blevesearch/bleve/issues/34","id":54809443,"node_id":"MDEyOklzc3VlQ29tbWVudDU0ODA5NDQz","user":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2014-09-08T12:17:54Z","updated_at":"2014-09-08T12:17:54Z","body":"> The Tokenizer interface in bleve is returning a TokenStream at the\n> moment. Would we then just refer to the individual characters as\n> tokens when implementing a Tokenizer for CJK in bleve?\n\nWe should have several tokenizers that behavior differently.  Then at a higher level we will assemble analyzers that correctly pair tokenizers with other filters to deliver useful functionality.  Even at this level there will probably be multiple options.  Users should have a choice as there may not be one single best solution.\n\nIt seems to me from what I've read so far, the simplest thing that can work acceptably is to tokenize CJK characters individually, and then apply a few other filters (such as the CJK bigram filter) before indexing.  To start down this path, I'm updating the \"whitespace\" tokenizer to give us this behavior (previously it just ate the characters which made no sense).  This will give acceptable behavior for a large number of languages using a simple tokenizer.\n\nBefore we expose this as a \"cjk\" analyzer in the registry, we still need to implement the cjk bigram filter.  I'll see if I can get around to this later today.\n\nBut this is still just part of the solution, as I'll explain below:\n\n> I wonder if it wouldn't make more sense to return 'word' tokens\n> directly in CJK as well which would be more consistent with how the\n> other languages are handled AFAICT.\n\nYes, I think we should have options here.  For some users the character tokenization won't be what they want.  We already have one tokenizer, named \"unicode\" which attempts to do word tokenization on CJK words.  It uses a dictionary based approach, but I have no idea how well it works.  What would help me is someone who knows a CJK language well to create some example test cases and report back how well it works.\n\n> I am also not sure how Lucene/Solr handle derivations like\n> \n> 感激的\n\nMy understanding (I'll test this one later today when working on the bigram filter) is that if you use the default CJK analyzer in Elasticsarch, it will tokenize on the characters, then for bigrams.  I'm assuming this is a 3 character word, and so on some level this is wrong.  But, if you read the link @purohit shared above, researchers have found that in practice this isn't a huge problem.  Often times the bigrams of 3 character words are related root words and this can increase search recall.\n\n> I would be interested in helping with the analysis of Japanese.\n\nThats  great.  Perhaps the best next step would be to research how well the  'unicode' tokenizer does on some Japanese text.  The google group may be a good place to discuss your findings.\n\n> If we decide to not use character n-grams as output for the tokenizer,\n> we could try to compare the unicode_word_boundary tokenizer and\n> something like kagome[2]/mecab[3](which would give you POS tags as\n> well).\n\nYes, I think the key that we should offer options.  I think proper CJK handling is complex enough that there will not be just one solution.\n\nI have a separate issue opened to track integration with kagome.  https://github.com/blevesearch/bleve/issues/93\n\nI'll take a look at the other links now.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/blevesearch/bleve/issues/comments/54809443/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false}},{"id":162441232,"node_id":"MDE0Ok1lbnRpb25lZEV2ZW50MTYyNDQxMjMy","url":"https://api.github.com/repos/blevesearch/bleve/issues/events/162441232","actor":{"login":"purohit","id":336266,"node_id":"MDQ6VXNlcjMzNjI2Ng==","avatar_url":"https://avatars.githubusercontent.com/u/336266?v=4","gravatar_id":"","url":"https://api.github.com/users/purohit","html_url":"https://github.com/purohit","followers_url":"https://api.github.com/users/purohit/followers","following_url":"https://api.github.com/users/purohit/following{/other_user}","gists_url":"https://api.github.com/users/purohit/gists{/gist_id}","starred_url":"https://api.github.com/users/purohit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/purohit/subscriptions","organizations_url":"https://api.github.com/users/purohit/orgs","repos_url":"https://api.github.com/users/purohit/repos","events_url":"https://api.github.com/users/purohit/events{/privacy}","received_events_url":"https://api.github.com/users/purohit/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"mentioned","commit_id":null,"commit_url":null,"created_at":"2014-09-08T12:17:54Z","performed_via_github_app":null},{"id":162441233,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDE2MjQ0MTIzMw==","url":"https://api.github.com/repos/blevesearch/bleve/issues/events/162441233","actor":{"login":"purohit","id":336266,"node_id":"MDQ6VXNlcjMzNjI2Ng==","avatar_url":"https://avatars.githubusercontent.com/u/336266?v=4","gravatar_id":"","url":"https://api.github.com/users/purohit","html_url":"https://github.com/purohit","followers_url":"https://api.github.com/users/purohit/followers","following_url":"https://api.github.com/users/purohit/following{/other_user}","gists_url":"https://api.github.com/users/purohit/gists{/gist_id}","starred_url":"https://api.github.com/users/purohit/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/purohit/subscriptions","organizations_url":"https://api.github.com/users/purohit/orgs","repos_url":"https://api.github.com/users/purohit/repos","events_url":"https://api.github.com/users/purohit/events{/privacy}","received_events_url":"https://api.github.com/users/purohit/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2014-09-08T12:17:54Z","performed_via_github_app":null},{"id":164249610,"node_id":"MDExOkNsb3NlZEV2ZW50MTY0MjQ5NjEw","url":"https://api.github.com/repos/blevesearch/bleve/issues/events/164249610","actor":{"login":"mschoch","id":298143,"node_id":"MDQ6VXNlcjI5ODE0Mw==","avatar_url":"https://avatars.githubusercontent.com/u/298143?v=4","gravatar_id":"","url":"https://api.github.com/users/mschoch","html_url":"https://github.com/mschoch","followers_url":"https://api.github.com/users/mschoch/followers","following_url":"https://api.github.com/users/mschoch/following{/other_user}","gists_url":"https://api.github.com/users/mschoch/gists{/gist_id}","starred_url":"https://api.github.com/users/mschoch/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/mschoch/subscriptions","organizations_url":"https://api.github.com/users/mschoch/orgs","repos_url":"https://api.github.com/users/mschoch/repos","events_url":"https://api.github.com/users/mschoch/events{/privacy}","received_events_url":"https://api.github.com/users/mschoch/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"closed","commit_id":"1a1cf32a861f8f1472d2a27b52effa026df6ab81","commit_url":"https://api.github.com/repos/blevesearch/bleve/commits/1a1cf32a861f8f1472d2a27b52effa026df6ab81","created_at":"2014-09-11T14:44:25Z","state_reason":null,"performed_via_github_app":null}]