diff --git a/sdks/python/apache_beam/pipeline.py b/sdks/python/apache_beam/pipeline.py
index 4c7d6012261..a797b7d8a50 100644
--- a/sdks/python/apache_beam/pipeline.py
+++ b/sdks/python/apache_beam/pipeline.py
@@ -329,6 +329,10 @@ class Pipeline(object):
       return Pipeline.from_runner_api(
           self.to_runner_api(), self.runner, self._options).run(False)
 
+    if self._options.view_as(TypeOptions).runtime_type_check:
+      from apache_beam.typehints import typecheck
+      self.visit(typecheck.TypeCheckVisitor())
+
     if self._options.view_as(SetupOptions).save_main_session:
       # If this option is chosen, verify we can pickle the main session early.
       tmpdir = tempfile.mkdtemp()
diff --git a/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py b/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py
index 7c165202a8a..d9ad3eebccf 100644
--- a/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py
+++ b/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py
@@ -201,6 +201,9 @@ class DataflowRunner(PipelineRunner):
       we could directly replace the coder instead of mutating the element type.
       """
 
+      def enter_composite_transform(self, transform_node):
+        self.visit_transform(transform_node)
+
       def visit_transform(self, transform_node):
         # Imported here to avoid circular dependencies.
         # pylint: disable=wrong-import-order, wrong-import-position
@@ -237,6 +240,9 @@ class DataflowRunner(PipelineRunner):
                   "Input to GroupByKey must be of Tuple or Any type. "
                   "Found %s for %s" % (element_type, pcoll))
           pcoll.element_type = coerce_to_kv_type(input_type)
+          key_type, value_type = pcoll.element_type.tuple_types
+          transform_node.outputs[None].element_type = typehints.KV[
+              key_type, typehints.Iterable[value_type]]
 
     return GroupByKeyInputVisitor()
 
diff --git a/sdks/python/apache_beam/runners/portability/fn_api_runner.py b/sdks/python/apache_beam/runners/portability/fn_api_runner.py
index 9daaebb4b50..88cd3e4b4db 100644
--- a/sdks/python/apache_beam/runners/portability/fn_api_runner.py
+++ b/sdks/python/apache_beam/runners/portability/fn_api_runner.py
@@ -29,6 +29,7 @@ import grpc
 
 import apache_beam as beam  # pylint: disable=ungrouped-imports
 from apache_beam import metrics
+from apache_beam import pipeline
 from apache_beam.coders import WindowedValueCoder
 from apache_beam.coders import registry
 from apache_beam.coders.coder_impl import create_InputStream
@@ -43,6 +44,7 @@ from apache_beam.runners import runner
 from apache_beam.runners.worker import bundle_processor
 from apache_beam.runners.worker import data_plane
 from apache_beam.runners.worker import sdk_worker
+from apache_beam.transforms import core
 from apache_beam.transforms import trigger
 from apache_beam.transforms.window import GlobalWindows
 from apache_beam.utils import proto_utils
@@ -192,6 +194,9 @@ class FnApiRunner(runner.PipelineRunner):
 
   def run_pipeline(self, pipeline):
     MetricsEnvironment.set_metrics_supported(False)
+    # This is sometimes needed if type checking is disabled.
+    from apache_beam.runners.dataflow.dataflow_runner import DataflowRunner
+    pipeline.visit(DataflowRunner.group_by_key_input_visitor())
     return self.run_via_runner_api(pipeline.to_runner_api())
 
   def run_via_runner_api(self, pipeline_proto):
diff --git a/sdks/python/apache_beam/transforms/core.py b/sdks/python/apache_beam/transforms/core.py
index 3c1f65d7f55..b4b8b7f64e0 100644
--- a/sdks/python/apache_beam/transforms/core.py
+++ b/sdks/python/apache_beam/transforms/core.py
@@ -1199,7 +1199,7 @@ class CombinePerKey(PTransformWithSideInputs):
     return '%s(%s)' % (self.__class__.__name__, self._fn_label)
 
   def _process_argspec_fn(self):
-    return self.fn._fn  # pylint: disable=protected-access
+    return lambda element, *args, **kwargs: None
 
   def expand(self, pcoll):
     args, kwargs = util.insert_values_in_args(
@@ -1207,6 +1207,20 @@ class CombinePerKey(PTransformWithSideInputs):
     return pcoll | GroupByKey() | 'Combine' >> CombineValues(
         self.fn, *args, **kwargs)
 
+  def default_type_hints(self):
+    hints = self.fn.get_type_hints().copy()
+    if hints.input_types:
+      K = typehints.TypeVariable('K')
+      args, kwargs = hints.input_types
+      args = (typehints.Tuple[K, args[0]],) + args[1:]
+      hints.set_input_types(*args, **kwargs)
+    else:
+      K = typehints.Any
+    if hints.output_types:
+      main_output_type = hints.simple_output_type('')
+      hints.set_output_types(typehints.Tuple[K, main_output_type])
+    return hints
+
   def to_runner_api_parameter(self, context):
     if self.args or self.kwargs:
       from apache_beam.transforms.combiners import curry_combine_fn
diff --git a/sdks/python/apache_beam/transforms/ptransform_test.py b/sdks/python/apache_beam/transforms/ptransform_test.py
index fb20d8c4e9b..91f93adb72f 100644
--- a/sdks/python/apache_beam/transforms/ptransform_test.py
+++ b/sdks/python/apache_beam/transforms/ptransform_test.py
@@ -143,6 +143,7 @@ class PTransformTest(unittest.TestCase):
 
   def test_do_with_do_fn_returning_string_raises_warning(self):
     pipeline = TestPipeline()
+    pipeline._options.view_as(TypeOptions).runtime_type_check = True
     pcoll = pipeline | 'Start' >> beam.Create(['2', '9', '3'])
     pcoll | 'Do' >> beam.FlatMap(lambda x: x + '1')
 
@@ -157,6 +158,7 @@ class PTransformTest(unittest.TestCase):
 
   def test_do_with_do_fn_returning_dict_raises_warning(self):
     pipeline = TestPipeline()
+    pipeline._options.view_as(TypeOptions).runtime_type_check = True
     pcoll = pipeline | 'Start' >> beam.Create(['2', '9', '3'])
     pcoll | 'Do' >> beam.FlatMap(lambda x: {x: '1'})
 
@@ -273,6 +275,7 @@ class PTransformTest(unittest.TestCase):
     def incorrect_par_do_fn(x):
       return x + 5
     pipeline = TestPipeline()
+    pipeline._options.view_as(TypeOptions).runtime_type_check = True
     pcoll = pipeline | 'Start' >> beam.Create([2, 9, 3])
     pcoll | 'Do' >> beam.FlatMap(incorrect_par_do_fn)
     # It's a requirement that all user-defined functions to a ParDo return
@@ -887,7 +890,7 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
 
   def test_do_fn_pipeline_pipeline_type_check_satisfied(self):
     @with_input_types(int, int)
-    @with_output_types(typehints.List[int])
+    @with_output_types(int)
     class AddWithFive(beam.DoFn):
       def process(self, element, five):
         return [element + five]
@@ -901,7 +904,7 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
 
   def test_do_fn_pipeline_pipeline_type_check_violated(self):
     @with_input_types(str, str)
-    @with_output_types(typehints.List[str])
+    @with_output_types(str)
     class ToUpperCaseWithPrefix(beam.DoFn):
       def process(self, element, prefix):
         return [prefix + element.upper()]
@@ -935,7 +938,7 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
     self.p._options.view_as(TypeOptions).runtime_type_check = True
 
     @with_input_types(int, int)
-    @with_output_types(typehints.List[int])
+    @with_output_types(int)
     class AddWithNum(beam.DoFn):
       def process(self, element, num):
         return [element + num]
@@ -1513,11 +1516,9 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
     self.assertStartswith(
         e.exception.message,
         "Runtime type violation detected within "
-        "ParDo(Mul/CombinePerKey/LiftedCombinePerKey/ParDo(FinishCombine)): "
-        "Tuple[TypeVariable[K], int] hint type-constraint violated. "
-        "The type of element #1 in the passed tuple is incorrect. "
-        "Expected an instance of type int, "
-        "instead received an instance of type str.")
+        "Mul/CombinePerKey: "
+        "Type-hint for return type violated. "
+        "Expected an instance of <type 'int'>, instead found")
 
   def test_combine_pipeline_type_check_using_methods(self):
     d = (self.p
@@ -1583,12 +1584,12 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
        | 'SortJoin' >> beam.CombineGlobally(lambda s: ''.join(sorted(s)))
        | 'F' >> beam.Map(lambda x: x + 1))
 
-    self.assertEqual(
+    self.assertStartswith(
+        e.exception.message,
         'Pipeline type checking is enabled, '
         'however no output type-hint was found for the PTransform '
         'ParDo('
-        'SortJoin/CombinePerKey/LiftedCombinePerKey/ParDo(FinishCombine))',
-        e.exception.message)
+        'SortJoin/CombinePerKey/')
 
   def test_mean_globally_pipeline_checking_satisfied(self):
     d = (self.p
@@ -1606,7 +1607,7 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
        | 'Mean' >> combine.Mean.Globally())
 
     self.assertEqual(
-        "Type hint violation for 'ParDo(PartialGroupByKeyCombiningValues)': "
+        "Type hint violation for 'CombinePerKey': "
         "requires Tuple[TypeVariable[K], Union[float, int, long]] "
         "but got Tuple[None, str] for element",
         e.exception.message)
@@ -1663,7 +1664,7 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
       self.p.run()
 
     self.assertEqual(
-        "Type hint violation for 'ParDo(PartialGroupByKeyCombiningValues)': "
+        "Type hint violation for 'CombinePerKey(MeanCombineFn)': "
         "requires Tuple[TypeVariable[K], Union[float, int, long]] "
         "but got Tuple[str, str] for element",
         e.exception.message)
@@ -1696,15 +1697,11 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
     self.assertStartswith(
         e.exception.message,
         "Runtime type violation detected within "
-        "ParDo(OddMean/CombinePerKey(MeanCombineFn)/LiftedCombinePerKey/"
-        "ParDo(PartialGroupByKeyCombiningValues)): "
+        "OddMean/CombinePerKey(MeanCombineFn): "
         "Type-hint for argument: 'element' violated: "
-        "Tuple[TypeVariable[K], Union[float, int, long]]"
-        " hint type-constraint violated. "
-        "The type of element #1 in the passed tuple is incorrect. "
         "Union[float, int, long] type-constraint violated. "
         "Expected an instance of one of: ('float', 'int', 'long'), "
-        "received str instead.")
+        "received str instead")
 
   def test_count_globally_pipeline_type_checking_satisfied(self):
     d = (self.p
@@ -1744,7 +1741,7 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
        | 'CountInt' >> combine.Count.PerKey())
 
     self.assertEqual(
-        "Type hint violation for 'ParDo(PartialGroupByKeyCombiningValues)': "
+        "Type hint violation for 'CombinePerKey(CountCombineFn)': "
         "requires Tuple[TypeVariable[K], Any] "
         "but got <type 'int'> for element",
         e.exception.message)
@@ -1825,7 +1822,7 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
        | 'TopMod' >> combine.Top.PerKey(1, lambda a, b: a < b))
 
     self.assertEqual(
-        "Type hint violation for 'ParDo(PartialGroupByKeyCombiningValues)': "
+        "Type hint violation for 'CombinePerKey(TopCombineFn)': "
         "requires Tuple[TypeVariable[K], TypeVariable[T]] "
         "but got <type 'int'> for element",
         e.exception.message)
@@ -1959,7 +1956,7 @@ class PTransformTypeCheckTestCase(TypeHintTestCase):
        | combine.ToDict())
 
     self.assertEqual(
-        "Type hint violation for 'ParDo(PartialGroupByKeyCombiningValues)': "
+        "Type hint violation for 'CombinePerKey': "
         "requires "
         "Tuple[TypeVariable[K], Tuple[TypeVariable[K], TypeVariable[V]]] "
         "but got Tuple[None, int] for element",
diff --git a/sdks/python/apache_beam/typehints/typecheck.py b/sdks/python/apache_beam/typehints/typecheck.py
index c47e9bacb96..056b5c9db87 100644
--- a/sdks/python/apache_beam/typehints/typecheck.py
+++ b/sdks/python/apache_beam/typehints/typecheck.py
@@ -25,7 +25,9 @@ import inspect
 import sys
 import types
 
+from apache_beam import pipeline
 from apache_beam.pvalue import TaggedOutput
+from apache_beam.transforms import core
 from apache_beam.transforms.core import DoFn
 from apache_beam.transforms.window import WindowedValue
 from apache_beam.typehints.decorators import GeneratorWrapper
@@ -35,6 +37,7 @@ from apache_beam.typehints.decorators import getcallargs_forhints
 from apache_beam.typehints.typehints import CompositeTypeHintError
 from apache_beam.typehints.typehints import SimpleTypeHintError
 from apache_beam.typehints.typehints import check_constraint
+from apache_beam.typehints.typehints import check_constraint
 
 
 class AbstractDoFnWrapper(DoFn):
@@ -178,3 +181,69 @@ class TypeCheckWrapperDoFn(AbstractDoFnWrapper):
                    "Instead, received '%s', an instance of type %s."
                    % (datum_type, type_constraint, datum, type(datum)))
       raise TypeCheckError, error_msg, sys.exc_info()[2]
+
+
+class TypeCheckCombineFn(core.CombineFn):
+  """A wrapper around a DoFn which performs type-checking of input and output.
+  """
+
+  def __init__(self, combinefn, type_hints, label=None):
+    self._combinefn = combinefn
+    self._input_type_hint = type_hints.input_types
+    self._output_type_hint = type_hints.simple_output_type(label)
+    self._label = label
+
+  def create_accumulator(self, *args, **kwargs):
+    return self._combinefn.create_accumulator(*args, **kwargs)
+
+  def add_input(self, accumulator, element, *args, **kwargs):
+    if self._input_type_hint:
+      try:
+        _check_instance_type(
+            self._input_type_hint[0][0].tuple_types[1], element, 'element', True)
+      except TypeCheckError as e:
+        error_msg = ('Runtime type violation detected within %s: '
+                     '%s' % (self._label, e))
+        raise TypeCheckError, error_msg, sys.exc_info()[2]
+    return self._combinefn.add_input(accumulator, element, *args, **kwargs)
+
+  def merge_accumulators(self, accumulators, *args, **kwargs):
+    return self._combinefn.merge_accumulators(accumulators, *args, **kwargs)
+
+  def extract_output(self, accumulator, *args, **kwargs):
+    result = self._combinefn.extract_output(accumulator, *args, **kwargs)
+    if self._output_type_hint:
+      try:
+        _check_instance_type(
+            self._output_type_hint.tuple_types[1], result, None, True)
+      except TypeCheckError as e:
+        error_msg = ('Runtime type violation detected within %s: '
+                     '%s' % (self._label, e))
+        raise TypeCheckError, error_msg, sys.exc_info()[2]
+    return result
+
+
+class TypeCheckVisitor(pipeline.PipelineVisitor):
+
+  _in_combine = False
+
+  def enter_composite_transform(self, applied_transform):
+    if isinstance(applied_transform.transform, core.CombinePerKey):
+      self._in_combine = True
+      applied_transform.transform.fn = TypeCheckCombineFn(
+          applied_transform.transform.fn,
+          applied_transform.transform.get_type_hints(),
+          applied_transform.full_label)
+  def leave_composite_transform(self, applied_transform):
+    if isinstance(applied_transform.transform, core.CombinePerKey):
+      self._in_combine = False
+
+  def visit_transform(self, applied_transform):
+    transform = applied_transform.transform
+    if isinstance(transform, core.ParDo) and not self._in_combine:
+      transform.fn = OutputCheckWrapperDoFn(
+          TypeCheckWrapperDoFn(
+              transform.fn,
+              transform.get_type_hints(),
+              applied_transform.full_label),
+          applied_transform.full_label)
