diff --git a/sdks/python/apache_beam/dataframe/frames.py b/sdks/python/apache_beam/dataframe/frames.py
index ef26761e7cc..794ea9ee2cf 100644
--- a/sdks/python/apache_beam/dataframe/frames.py
+++ b/sdks/python/apache_beam/dataframe/frames.py
@@ -176,17 +176,36 @@ class DeferredDataFrameOrSeries(frame_base.DeferredFrame):
         grouping_indexes = level
       else:
         grouping_indexes = [level]
-      all_levels = self._expr.proxy().index.names
-      levels = [
-          all_levels[i] if isinstance(i, int) else i for i in grouping_indexes
+
+      grouping_columns = []
+
+      index = self._expr.proxy().index
+
+      # Translate to level numbers only
+      grouping_indexes = [
+          l if isinstance(l, int) else index.names.index(l)
+          for l in grouping_indexes
       ]
-      levels_to_drop = self._expr.proxy().index.names.difference(levels)
-      if levels_to_drop:
-        to_group = self.droplevel(levels_to_drop)._expr
-      else:
+
+      if index.nlevels == 1:
+        to_group_with_index = self._expr
         to_group = self._expr
-      to_group_with_index = self._expr
-      grouping_columns = []
+      else:
+        levels_to_drop = [
+            i for i in range(index.nlevels) if i not in grouping_indexes
+        ]
+
+        # Reorder so the grouped indexes are first
+        to_group_with_index = self.reorder_levels(
+            grouping_indexes + levels_to_drop)
+
+        grouping_indexes = list(range(len(grouping_indexes)))
+        levels_to_drop = list(range(len(grouping_indexes), index.nlevels))
+        if levels_to_drop:
+          to_group = to_group_with_index.droplevel(levels_to_drop)._expr
+        else:
+          to_group = to_group_with_index._expr
+        to_group_with_index = to_group_with_index._expr
 
     elif callable(by):
 
@@ -490,6 +509,11 @@ class DeferredDataFrameOrSeries(frame_base.DeferredFrame):
   head = tail = frame_base.wont_implement_method('order-sensitive')
   interpolate = frame_base.wont_implement_method('order-sensitive')
 
+  reorder_levels = frame_base._proxy_method(
+      'reorder_levels',
+      requires_partition_by=partitionings.Arbitrary(),
+      preserves_partition_by=partitionings.Singleton())
+
 
 @populate_not_implemented(pd.Series)
 @frame_base.DeferredFrame._register_for(pd.Series)
diff --git a/sdks/python/apache_beam/dataframe/frames_test.py b/sdks/python/apache_beam/dataframe/frames_test.py
index e9cf2f2d15b..a5bc5f9dfda 100644
--- a/sdks/python/apache_beam/dataframe/frames_test.py
+++ b/sdks/python/apache_beam/dataframe/frames_test.py
@@ -32,6 +32,8 @@ GROUPBY_DF = pd.DataFrame({
     'foo': [None if i % 11 == 0 else i for i in range(100)],
     'bar': [None if i % 7 == 0 else 99 - i for i in range(100)],
     'baz': [None if i % 13 == 0 else i * 2 for i in range(100)],
+    'bool': [i % 17 == 0 for i in range(100)],
+    'str': [str(i) for i in range(100)],
 })
 
 
@@ -365,6 +367,10 @@ class DeferredFrameTest(unittest.TestCase):
         df)
     self._run_test(lambda df: df.groupby(level=0).apply(median_sum_fn), df)
     self._run_test(lambda df: df.groupby(lambda x: x % 3).apply(describe), df)
+    self._run_test(
+        lambda df: df.set_index(['str', 'group', 'bool']).groupby(
+            level='group').apply(median_sum_fn),
+        df)
 
   @unittest.skip('BEAM-11710')
   def test_groupby_aggregate_grouped_column(self):
@@ -650,6 +656,26 @@ class DeferredFrameTest(unittest.TestCase):
 
     self._run_test(change_index_names, df)
 
+  @parameterized.expand((x, ) for x in [
+      0,
+      [1],
+      3,
+      [0, 3],
+      [2, 1],
+      ['foo', 0],
+      [1, 'str'],
+      [3, 0, 2, 1],
+  ])
+  def test_groupby_level_agg(self, level):
+    df = GROUPBY_DF.set_index(['group', 'foo', 'bar', 'str'], drop=False)
+    self._run_test(lambda df: df.groupby(level=level).bar.max(), df)
+    self._run_test(
+        lambda df: df.groupby(level=level).sum(numeric_only=True), df)
+    self._run_test(
+        lambda df: df.groupby(level=level).apply(
+            lambda x: (x.foo + x.bar).median()),
+        df)
+
 
 class AllowNonParallelTest(unittest.TestCase):
   def _use_non_parallel_operation(self):
