diff --git a/sdks/python/apache_beam/transforms/core.py b/sdks/python/apache_beam/transforms/core.py
index 54fd139bc11..cd6fb666334 100644
--- a/sdks/python/apache_beam/transforms/core.py
+++ b/sdks/python/apache_beam/transforms/core.py
@@ -2896,6 +2896,15 @@ class Create(PTransform):
       values = values.items()
     self.values = tuple(values)
     self.reshuffle = reshuffle
+    self._coder = typecoders.registry.get_coder(self.get_output_type())
+
+  def __getstate__(self):
+    serialized_values = [self._coder.encode(v) for v in self.values]
+    return serialized_values, self.reshuffle, self._coder
+
+  def __setstate__(self, state):
+    serialized_values, self.reshuffle, self._coder = state
+    self.values = [self._coder.decode(v) for v in serialized_values]
 
   def to_runner_api_parameter(self, context):
     # type: (PipelineContext) -> typing.Tuple[str, bytes]
@@ -2917,8 +2926,7 @@ class Create(PTransform):
 
   def expand(self, pbegin):
     assert isinstance(pbegin, pvalue.PBegin)
-    coder = typecoders.registry.get_coder(self.get_output_type())
-    serialized_values = [coder.encode(v) for v in self.values]
+    serialized_values = [self._coder.encode(v) for v in self.values]
     reshuffle = self.reshuffle
 
     # Avoid the "redistributing" reshuffle for 0 and 1 element Creates.
@@ -2938,12 +2946,11 @@ class Create(PTransform):
         | Impulse()
         | FlatMap(lambda _: serialized_values).with_output_types(bytes)
         | MaybeReshuffle().with_output_types(bytes)
-        | Map(coder.decode).with_output_types(self.get_output_type()))
+        | Map(self._coder.decode).with_output_types(self.get_output_type()))
 
   def as_read(self):
     from apache_beam.io import iobase
-    coder = typecoders.registry.get_coder(self.get_output_type())
-    source = self._create_source_from_iterable(self.values, coder)
+    source = self._create_source_from_iterable(self.values, self._coder)
     return iobase.Read(source).with_output_types(self.get_output_type())
 
   def get_windowing(self, unused_inputs):
diff --git a/sdks/python/apache_beam/transforms/create_test.py b/sdks/python/apache_beam/transforms/create_test.py
index 6dd642bcbb2..37f32d47800 100644
--- a/sdks/python/apache_beam/transforms/create_test.py
+++ b/sdks/python/apache_beam/transforms/create_test.py
@@ -22,7 +22,9 @@ import logging
 import unittest
 
 from apache_beam import Create
+from apache_beam import coders
 from apache_beam.coders import FastPrimitivesCoder
+from apache_beam.internal import pickler
 from apache_beam.io import source_test_utils
 from apache_beam.testing.test_pipeline import TestPipeline
 from apache_beam.testing.util import assert_that
@@ -121,6 +123,45 @@ class CreateTest(unittest.TestCase):
 
     self.assertEqual(expected_split_points_report, split_points_report)
 
+  def test_create_uses_coder_for_pickling(self):
+    coders.registry.register_coder(_Unpicklable, _UnpicklableCoder)
+    create = Create([_Unpicklable(1), _Unpicklable(2), _Unpicklable(3)])
+    unpickled_create = pickler.loads(pickler.dumps(create))
+    self.assertEqual(
+        sorted(create.values, key=lambda v: v.value),
+        sorted(unpickled_create.values, key=lambda v: v.value))
+
+    with self.assertRaises(NotImplementedError):
+      # As there is no special coder for Union types, this will fall back to
+      # FastPrimitivesCoder, which in turn falls back to pickling.
+      create_mixed_types = Create([_Unpicklable(1), 2])
+      pickler.dumps(create_mixed_types)
+
+
+class _Unpicklable(object):
+  def __init__(self, value):
+    self.value = value
+
+  def __eq__(self, other):
+    return self.value == other.value
+
+  def __getstate__(self):
+    raise NotImplementedError()
+
+  def __setstate__(self, state):
+    raise NotImplementedError()
+
+
+class _UnpicklableCoder(coders.Coder):
+  def encode(self, value):
+    return str(value.value).encode()
+
+  def decode(self, encoded):
+    return _Unpicklable(int(encoded.decode()))
+
+  def to_type_hint(self):
+    return _Unpicklable
+
 
 if __name__ == '__main__':
   logging.getLogger().setLevel(logging.INFO)
