diff --git a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java
index a0977b7ce7d..47d82816ce8 100644
--- a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java
+++ b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java
@@ -61,6 +61,7 @@ import org.apache.beam.sdk.coders.Coder;
 import org.apache.beam.sdk.coders.CoderRegistry;
 import org.apache.beam.sdk.coders.CustomCoder;
 import org.apache.beam.sdk.coders.KvCoder;
+import org.apache.beam.sdk.coders.NullableCoder;
 import org.apache.beam.sdk.io.Read.Unbounded;
 import org.apache.beam.sdk.io.UnboundedSource;
 import org.apache.beam.sdk.io.UnboundedSource.CheckpointMark;
@@ -270,7 +271,7 @@ public class KafkaIO {
    * deserializer argument using the {@link Coder} registry.
    */
   @VisibleForTesting
-  static <T> Coder<T> inferCoder(
+  static <T> NullableCoder<T> inferCoder(
       CoderRegistry coderRegistry, Class<? extends Deserializer<T>> deserializer) {
     checkNotNull(deserializer);
 
@@ -289,7 +290,7 @@ public class KafkaIO {
         try {
           @SuppressWarnings("unchecked")
           Class<T> clazz = (Class<T>) parameter;
-          return coderRegistry.getDefaultCoder(clazz);
+          return NullableCoder.of(coderRegistry.getDefaultCoder(clazz));
         } catch (CannotProvideCoderException e) {
           LOG.warn("Could not infer coder from deserializer type", e);
         }
diff --git a/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java b/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java
index e6ed2f7d096..d713d9027c5 100644
--- a/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java
+++ b/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java
@@ -183,7 +183,7 @@ public class KafkaIOTest {
     // our responsibility to make sure currently enqueued records sync with partition offsets.
     // The following task will be called inside each invocation to MockConsumer.poll().
     // We enqueue only the records with the offset >= partition's current position.
-    Runnable recordEnquerTask = new Runnable() {
+    Runnable recordEnqueueTask = new Runnable() {
       @Override
       public void run() {
         // add all the records with offset >= current partition position.
@@ -199,7 +199,7 @@ public class KafkaIOTest {
       }
     };
 
-    consumer.schedulePollTask(recordEnquerTask);
+    consumer.schedulePollTask(recordEnqueueTask);
     return consumer;
   }
 
@@ -739,16 +739,16 @@ public class KafkaIOTest {
   public void testInferKeyCoder() {
     CoderRegistry registry = CoderRegistry.createDefault();
 
-    assertTrue(KafkaIO.inferCoder(registry, LongDeserializer.class)
+    assertTrue(KafkaIO.inferCoder(registry, LongDeserializer.class).getValueCoder()
             instanceof VarLongCoder);
 
-    assertTrue(KafkaIO.inferCoder(registry, StringDeserializer.class)
+    assertTrue(KafkaIO.inferCoder(registry, StringDeserializer.class).getValueCoder()
             instanceof StringUtf8Coder);
 
-    assertTrue(KafkaIO.inferCoder(registry, InstantDeserializer.class)
+    assertTrue(KafkaIO.inferCoder(registry, InstantDeserializer.class).getValueCoder()
             instanceof InstantCoder);
 
-    assertTrue(KafkaIO.inferCoder(registry, DeserializerWithInterfaces.class)
+    assertTrue(KafkaIO.inferCoder(registry, DeserializerWithInterfaces.class).getValueCoder()
             instanceof VarLongCoder);
   }
 
