diff --git a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTableProviderIT.java b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTableProviderIT.java
index 227dcdb6a09..0546c7a9025 100644
--- a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTableProviderIT.java
+++ b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTableProviderIT.java
@@ -66,7 +66,6 @@ import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TypeDescriptor;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.MoreObjects;
-import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;
 import org.apache.commons.csv.CSVFormat;
 import org.apache.kafka.clients.producer.KafkaProducer;
@@ -76,6 +75,7 @@ import org.apache.thrift.protocol.TBinaryProtocol;
 import org.apache.thrift.protocol.TProtocolFactory;
 import org.checkerframework.checker.nullness.qual.Nullable;
 import org.junit.Assert;
+import org.junit.Assume;
 import org.junit.Before;
 import org.junit.ClassRule;
 import org.junit.Rule;
@@ -108,12 +108,6 @@ public class KafkaTableProviderIT {
           .addStringField("f_string")
           .build();
 
-  private static final Schema NESTED_TABLE_SCHEMA =
-      Schema.builder()
-          .addRowField(Schemas.PAYLOAD_FIELD, TEST_TABLE_SCHEMA)
-          .addArrayField(Schemas.HEADERS_FIELD, Schemas.HEADERS_FIELD_TYPE)
-          .build();
-
   @Parameters
   public static Collection<Object[]> data() {
     return Arrays.asList(
@@ -206,11 +200,12 @@ public class KafkaTableProviderIT {
 
   @Test
   public void testFakeNested() throws InterruptedException {
+    Assume.assumeFalse(topic.equals("csv_topic"));
     pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);
     String createTableString =
         String.format(
             "CREATE EXTERNAL TABLE kafka_table(\n"
-                + "headers ARRAY<ROW<key VARCHAR, values ARRAY<BYTES>>>,"
+                + "headers ARRAY<ROW<key VARCHAR, `values` ARRAY<VARBINARY>>>,"
                 + "payload ROW<"
                 + "f_long BIGINT NOT NULL, \n"
                 + "f_int INTEGER NOT NULL, \n"
@@ -227,17 +222,19 @@ public class KafkaTableProviderIT {
     env.executeDdl(createTableString);
 
     PCollection<Row> queryOutput =
-        BeamSqlRelUtils.toPCollection(pipeline, env.parseQuery("SELECT * FROM kafka_table"));
+        BeamSqlRelUtils.toPCollection(
+            pipeline,
+            env.parseQuery(
+                "SELECT kafka_table.payload.f_long, kafka_table.payload.f_int, kafka_table.payload.f_string FROM kafka_table"));
 
     queryOutput
         .apply(ParDo.of(new FakeKvPair()))
-        .setCoder(KvCoder.of(StringUtf8Coder.of(), RowCoder.of(NESTED_TABLE_SCHEMA)))
+        .setCoder(KvCoder.of(StringUtf8Coder.of(), RowCoder.of(TEST_TABLE_SCHEMA)))
         .apply(
             "waitForSuccess",
             ParDo.of(
                 new StreamAssertEqual(
-                    ImmutableSet.of(
-                        generateNestedRow(0), generateNestedRow(1), generateNestedRow(2)))));
+                    ImmutableSet.of(generateRow(0), generateRow(1), generateRow(2)))));
     queryOutput.apply(logRecords(""));
     pipeline.run();
     TimeUnit.SECONDS.sleep(4);
@@ -313,12 +310,6 @@ public class KafkaTableProviderIT {
     return Row.withSchema(TEST_TABLE_SCHEMA).addValues((long) i, i % 3 + 1, "value" + i).build();
   }
 
-  private static Row generateNestedRow(int i) {
-    return Row.withSchema(NESTED_TABLE_SCHEMA)
-        .addValues(generateRow(i), ImmutableList.of())
-        .build();
-  }
-
   @SuppressWarnings("FutureReturnValueIgnored")
   private void produceSomeRecords(int num) {
     Producer<String, byte[]> producer = new KafkaProducer<>(producerProps());
