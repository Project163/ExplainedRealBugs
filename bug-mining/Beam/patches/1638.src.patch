diff --git a/CHANGES.md b/CHANGES.md
index 319e35d8e0a..44fda85c90f 100644
--- a/CHANGES.md
+++ b/CHANGES.md
@@ -44,7 +44,6 @@
 
 * ReadFromPubSub(topic=<topic>) in Python previously created a subscription under the same project as the topic. Now it will create the subscription under the project specified in pipeline_options. If the project is not specified in pipeline_options, then it will create the subscription under the same project as the topic. ([BEAM-3453](https://issues.apache.org/jira/browse/BEAM-3453)).
 * SpannerAccessor in Java is now package-private to reduce API surface. `SpannerConfig.connectToSpanner` has been moved to `SpannerAccessor.create`. ([BEAM-9310](https://issues.apache.org/jira/browse/BEAM-9310)).
-* PCollections will now have their tags correctly propagated through the Pipeline. Users may expect the old implementation which gave PCollection output ids a monotonically increasing id. To go back to the old implementation, use the "force_generated_pcollection_output_ids" experiment. The default is the new implementation (force_generated_pcollection_output_ids=False).
 * ParquetIO hadoop dependency should be now provided by the users ([BEAM-8616](https://issues.apache.org/jira/browse/BEAM-8616)).
 
 ### Deprecations
diff --git a/sdks/python/apache_beam/pipeline.py b/sdks/python/apache_beam/pipeline.py
index 22aa2a3b257..e7343e4d49d 100644
--- a/sdks/python/apache_beam/pipeline.py
+++ b/sdks/python/apache_beam/pipeline.py
@@ -620,23 +620,25 @@ class Pipeline(object):
         current.add_output(result, result._main_tag)
         continue
 
+      # TODO(BEAM-9322): Remove the experiment check and have this conditional
+      # be the default.
+      if self._options.view_as(DebugOptions).lookup_experiment(
+          'passthrough_pcollection_output_ids', default=False):
+        # Otherwise default to the new implementation which only auto-generates
+        # tags for multiple PCollections with an unset tag.
+        if result.tag is None and None in current.outputs:
+          tag = len(current.outputs)
+        else:
+          tag = result.tag
+        current.add_output(result, tag)
+        continue
+
       # TODO(BEAM-9322): Find the best auto-generated tags for nested
       # PCollections.
       # If the user wants the old implementation of always generated
       # PCollection output ids, then set the tag to None first, then count up
       # from 1.
-      if self._options.view_as(DebugOptions).lookup_experiment(
-          'force_generated_pcollection_output_ids', default=False):
-        tag = len(current.outputs) if None in current.outputs else None
-        current.add_output(result, tag)
-        continue
-
-      # Otherwise default to the new implementation which only auto-generates
-      # tags for multiple PCollections with an unset tag.
-      if result.tag is None and None in current.outputs:
-        tag = len(current.outputs)
-      else:
-        tag = result.tag
+      tag = len(current.outputs) if None in current.outputs else None
       current.add_output(result, tag)
 
     if (type_options is not None and
diff --git a/sdks/python/apache_beam/runners/interactive/interactive_runner.py b/sdks/python/apache_beam/runners/interactive/interactive_runner.py
index 66a1e14de1e..6b368d6864c 100644
--- a/sdks/python/apache_beam/runners/interactive/interactive_runner.py
+++ b/sdks/python/apache_beam/runners/interactive/interactive_runner.py
@@ -30,6 +30,7 @@ import logging
 
 import apache_beam as beam
 from apache_beam import runners
+from apache_beam.options.pipeline_options import DebugOptions
 from apache_beam.runners.direct import direct_runner
 from apache_beam.runners.interactive import cache_manager as cache
 from apache_beam.runners.interactive import interactive_environment as ie
@@ -133,6 +134,10 @@ class InteractiveRunner(runners.PipelineRunner):
 
   def apply(self, transform, pvalueish, options):
     # TODO(qinyeli, BEAM-646): Remove runner interception of apply.
+    # TODO(BEAM-9322): Once nested PCollection naming schemes have been ironed
+    # out, this can be removed.
+    options.view_as(DebugOptions).add_experiment(
+        'passthrough_pcollection_output_ids')
     return self._underlying_runner.apply(transform, pvalueish, options)
 
   def run_pipeline(self, pipeline, options):
