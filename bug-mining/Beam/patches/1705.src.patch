diff --git a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java
index 06cba97a87f..5475785b657 100644
--- a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java
+++ b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java
@@ -163,6 +163,14 @@ import org.slf4j.LoggerFactory;
  * <br>
  * 3. Start from <em>latest</em> offset by default;
  *
+ * <p>Seek to initial offset is a blocking operation in Kafka API, which can block forever for
+ * certain versions of Kafka client library. This is resolved by <a
+ * href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-266%3A+Fix+consumer+indefinite+blocking+behavior">KIP-266</a>
+ * which provides `default.api.timeout.ms` consumer config setting to control such timeouts.
+ * KafkaIO.read implements timeout itself, to not to block forever in case older Kafka client is
+ * used. It does recognize `default.api.timeout.ms` setting and will honor the timeout value if it
+ * is passes in consumer config.
+ *
  * <h3>Use Avro schema with Confluent Schema Registry</h3>
  *
  * <p>If you want to deserialize the keys and/or values based on a schema available in Confluent
diff --git a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaUnboundedReader.java b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaUnboundedReader.java
index c1856275fe3..1a5f35d8699 100644
--- a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaUnboundedReader.java
+++ b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaUnboundedReader.java
@@ -78,9 +78,6 @@ class KafkaUnboundedReader<K, V> extends UnboundedReader<KafkaRecord<K, V>> {
   @SuppressWarnings("FutureReturnValueIgnored")
   @Override
   public boolean start() throws IOException {
-    final int defaultPartitionInitTimeout = 60 * 1000;
-    final int kafkaRequestTimeoutMultiple = 2;
-
     Read<K, V> spec = source.getSpec();
     consumer = spec.getConsumerFactoryFn().apply(spec.getConsumerConfig());
     consumerSpEL.evaluateAssign(consumer, spec.getTopicPartitions());
@@ -93,18 +90,13 @@ class KafkaUnboundedReader<K, V> extends UnboundedReader<KafkaRecord<K, V>> {
     // Seek to start offset for each partition. This is the first interaction with the server.
     // Unfortunately it can block forever in case of network issues like incorrect ACLs.
     // Initialize partition in a separate thread and cancel it if takes longer than a minute.
+    // This problem of blocking API calls to kafka is solved in higher versions of kafka
+    // client by `KIP-266`
     for (final PartitionState pState : partitionStates) {
       Future<?> future = consumerPollThread.submit(() -> setupInitialOffset(pState));
-
       try {
-        // Timeout : 1 minute OR 2 * Kafka consumer request timeout if it is set.
-        Integer reqTimeout =
-            (Integer) spec.getConsumerConfig().get(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG);
-        future.get(
-            reqTimeout != null
-                ? kafkaRequestTimeoutMultiple * reqTimeout
-                : defaultPartitionInitTimeout,
-            TimeUnit.MILLISECONDS);
+        Duration timeout = resolveDefaultApiTimeout(spec);
+        future.get(timeout.getMillis(), TimeUnit.MILLISECONDS);
       } catch (TimeoutException e) {
         consumer.wakeup(); // This unblocks consumer stuck on network I/O.
         // Likely reason : Kafka servers are configured to advertise internal ips, but
@@ -767,4 +759,36 @@ class KafkaUnboundedReader<K, V> extends UnboundedReader<KafkaRecord<K, V>> {
     Closeables.close(offsetConsumer, true);
     Closeables.close(consumer, true);
   }
+
+  @VisibleForTesting
+  static Duration resolveDefaultApiTimeout(Read<?, ?> spec) {
+
+    // KIP-266 - let's allow to configure timeout in consumer settings. This is supported in
+    // higher versions of kafka client. We allow users to set this timeout and it will be
+    // respected
+    // in all places where Beam's KafkaIO handles possibility of API call being blocked.
+    // Later, we should replace the string with ConsumerConfig constant
+    Duration timeout =
+        tryParseDurationFromMillis(spec.getConsumerConfig().get("default.api.timeout.ms"));
+    if (timeout == null) {
+      Duration value =
+          tryParseDurationFromMillis(
+              spec.getConsumerConfig().get(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG));
+      if (value != null) {
+        // 2x request timeout to be compatible with previous version
+        timeout = Duration.millis(2 * value.getMillis());
+      }
+    }
+
+    return timeout == null ? Duration.standardSeconds(60) : timeout;
+  }
+
+  private static Duration tryParseDurationFromMillis(Object value) {
+    if (value == null) {
+      return null;
+    }
+    return value instanceof Integer
+        ? Duration.millis((Integer) value)
+        : Duration.millis(Integer.parseInt(value.toString()));
+  }
 }
diff --git a/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java b/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java
index 8627b8b4f84..544215a3d7b 100644
--- a/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java
+++ b/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java
@@ -526,10 +526,14 @@ public class KafkaIOTest {
                     .withValueDeserializer(LongDeserializer.class)
                     .withConsumerConfigUpdates(
                         ImmutableMap.of(
-                            ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 10,
-                            ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 5,
-                            ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 8,
-                            ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 8))
+                            ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG,
+                            5,
+                            ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG,
+                            8,
+                            ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG,
+                            8,
+                            "default.api.timeout.ms",
+                            10))
                     .withMaxNumRecords(10)
                     .withoutMetadata())
             .apply(Values.create());
@@ -538,6 +542,34 @@ public class KafkaIOTest {
     p.run();
   }
 
+  @Test
+  public void testResolveDefaultApiTimeout() {
+
+    final String defaultApiTimeoutConfig = "default.api.timeout.ms";
+
+    assertEquals(
+        Duration.millis(20),
+        KafkaUnboundedReader.resolveDefaultApiTimeout(
+            KafkaIO.<Integer, Long>read()
+                .withConsumerConfigUpdates(
+                    ImmutableMap.of(
+                        defaultApiTimeoutConfig,
+                        20,
+                        ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG,
+                        30))));
+
+    assertEquals(
+        Duration.millis(2 * 30),
+        KafkaUnboundedReader.resolveDefaultApiTimeout(
+            KafkaIO.<Integer, Long>read()
+                .withConsumerConfigUpdates(
+                    ImmutableMap.of(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 30))));
+
+    assertEquals(
+        Duration.millis(60 * 1000),
+        KafkaUnboundedReader.resolveDefaultApiTimeout(KafkaIO.<Integer, Long>read()));
+  }
+
   @Test
   public void testUnboundedSourceWithSingleTopic() {
     // same as testUnboundedSource, but with single topic
