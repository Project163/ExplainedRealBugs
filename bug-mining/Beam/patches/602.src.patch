diff --git a/sdks/go/pkg/beam/core/graph/node.go b/sdks/go/pkg/beam/core/graph/node.go
index d3acf1f0c18..9ed998f28b2 100644
--- a/sdks/go/pkg/beam/core/graph/node.go
+++ b/sdks/go/pkg/beam/core/graph/node.go
@@ -83,3 +83,13 @@ func NodeTypes(list []*Node) []typex.FullType {
 	}
 	return ret
 }
+
+// Bounded returns true iff all nodes are bounded.
+func Bounded(ns []*Node) bool {
+	for _, n := range ns {
+		if !n.Bounded() {
+			return false
+		}
+	}
+	return true
+}
diff --git a/sdks/go/pkg/beam/runners/dataflow/dataflow.go b/sdks/go/pkg/beam/runners/dataflow/dataflow.go
index 967d17be963..9bdc2acb141 100644
--- a/sdks/go/pkg/beam/runners/dataflow/dataflow.go
+++ b/sdks/go/pkg/beam/runners/dataflow/dataflow.go
@@ -45,6 +45,7 @@ import (
 	"golang.org/x/oauth2/google"
 	df "google.golang.org/api/dataflow/v1b3"
 	"google.golang.org/api/storage/v1"
+	"github.com/apache/beam/sdks/go/pkg/beam/core/graph"
 )
 
 // TODO(herohde) 5/16/2017: the Dataflow flags should match the other SDKs.
@@ -60,7 +61,6 @@ var (
 	network         = flag.String("network", "", "GCP network (optional)")
 	tempLocation    = flag.String("temp_location", "", "Temp location (optional)")
 	machineType     = flag.String("worker_machine_type", "", "GCE machine type (optional)")
-	streaming       = flag.Bool("streaming", false, "Streaming job")
 
 	dryRun         = flag.Bool("dry_run", false, "Dry run. Just print the job, but don't submit it.")
 	teardownPolicy = flag.String("teardown_policy", "", "Job teardown policy (internal only).")
@@ -103,7 +103,7 @@ func Execute(ctx context.Context, p *beam.Pipeline) error {
 	}
 	jobName := jobopts.GetJobName()
 
-	edges, _, err := p.Build()
+	edges, nodes, err := p.Build()
 	if err != nil {
 		return err
 	}
@@ -169,7 +169,9 @@ func Execute(ctx context.Context, p *beam.Pipeline) error {
 
 	jobType := "JOB_TYPE_BATCH"
 	apiJobType := "FNAPI_BATCH"
-	if *streaming {
+
+	streaming := !graph.Bounded(nodes)
+	if streaming {
 		jobType = "JOB_TYPE_STREAMING"
 		apiJobType = "FNAPI_STREAMING"
 	}
@@ -223,7 +225,7 @@ func Execute(ctx context.Context, p *beam.Pipeline) error {
 	if *tempLocation != "" {
 		job.Environment.TempStoragePrefix = *tempLocation
 	}
-	if *streaming {
+	if streaming {
 		// Add separate data disk for streaming jobs
 		job.Environment.WorkerPools[0].DataDisks = []*df.Disk{{}}
 	}
