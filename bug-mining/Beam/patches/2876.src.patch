diff --git a/CHANGES.md b/CHANGES.md
index 93dda69145a..16b35a51d73 100644
--- a/CHANGES.md
+++ b/CHANGES.md
@@ -124,6 +124,7 @@
 * Fix S3 copy for large objects (Java) ([BEAM-14011](https://issues.apache.org/jira/browse/BEAM-14011))
 * Fix quadratic behavior of pipeline canonicalization (Go) ([BEAM-14128](https://issues.apache.org/jira/browse/BEAM-14128))
   * This caused unnecessarily long pre-processing times before job submission for large complex pipelines.
+* Fix `pyarrow` version parsing (Python)([BEAM-14235](https://issues.apache.org/jira/browse/BEAM-14235))
 
 ## Known Issues
 
diff --git a/sdks/python/apache_beam/io/parquetio.py b/sdks/python/apache_beam/io/parquetio.py
index 872140d5d7f..6e00cf1f37f 100644
--- a/sdks/python/apache_beam/io/parquetio.py
+++ b/sdks/python/apache_beam/io/parquetio.py
@@ -32,6 +32,8 @@ Parquet file.
 
 from functools import partial
 
+from pkg_resources import parse_version
+
 from apache_beam.io import filebasedsink
 from apache_beam.io import filebasedsource
 from apache_beam.io.filesystem import CompressionTypes
@@ -50,7 +52,8 @@ except ImportError:
   pq = None
   ARROW_MAJOR_VERSION = None
 else:
-  ARROW_MAJOR_VERSION, _, _ = map(int, pa.__version__.split('.'))
+  base_pa_version = parse_version(pa.__version__).base_version
+  ARROW_MAJOR_VERSION, _, _ = map(int, base_pa_version.split('.'))
 
 __all__ = [
     'ReadFromParquet',
