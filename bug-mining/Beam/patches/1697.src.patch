diff --git a/sdks/python/apache_beam/options/pipeline_options.py b/sdks/python/apache_beam/options/pipeline_options.py
index c343ccf846e..f916e1fc5b8 100644
--- a/sdks/python/apache_beam/options/pipeline_options.py
+++ b/sdks/python/apache_beam/options/pipeline_options.py
@@ -256,7 +256,8 @@ class PipelineOptions(HasDisplayData):
   def get_all_options(
       self,
       drop_default=False,
-      add_extra_args_fn=None  # type: Optional[Callable[[_BeamArgumentParser], None]]
+      add_extra_args_fn=None,  # type: Optional[Callable[[_BeamArgumentParser], None]]
+      retain_unknown_options=False
   ):
     # type: (...) -> Dict[str, Any]
 
@@ -270,6 +271,9 @@ class PipelineOptions(HasDisplayData):
         values, are not returned as part of the result dictionary.
       add_extra_args_fn: Callback to populate additional arguments, can be used
         by runner to supply otherwise unknown args.
+      retain_unknown_options: If set to true, options not recognized by any
+        known pipeline options class will still be included in the result. If
+        set to false, they will be discarded.
 
     Returns:
       Dictionary of all args and values.
@@ -285,10 +289,25 @@ class PipelineOptions(HasDisplayData):
       cls._add_argparse_args(parser)  # pylint: disable=protected-access
     if add_extra_args_fn:
       add_extra_args_fn(parser)
+
     known_args, unknown_args = parser.parse_known_args(self._flags)
-    if unknown_args:
-      _LOGGER.warning("Discarding unparseable args: %s", unknown_args)
-    result = vars(known_args)
+    if retain_unknown_options:
+      i = 0
+      while i < len(unknown_args):
+        # Treat all unary flags as booleans, and all binary argument values as
+        # strings.
+        if i + 1 >= len(unknown_args) or unknown_args[i + 1].startswith('--'):
+          parser.add_argument(unknown_args[i], action='store_true')
+          i += 1
+        else:
+          parser.add_argument(unknown_args[i], type=str)
+          i += 2
+      parsed_args = parser.parse_args(self._flags)
+    else:
+      if unknown_args:
+        _LOGGER.warning("Discarding unparseable args: %s", unknown_args)
+      parsed_args = known_args
+    result = vars(parsed_args)
 
     overrides = self._all_options.copy()
     # Apply the overrides if any
diff --git a/sdks/python/apache_beam/options/pipeline_options_test.py b/sdks/python/apache_beam/options/pipeline_options_test.py
index 588773371e1..bf199334ff4 100644
--- a/sdks/python/apache_beam/options/pipeline_options_test.py
+++ b/sdks/python/apache_beam/options/pipeline_options_test.py
@@ -300,6 +300,21 @@ class PipelineOptionsTest(unittest.TestCase):
             'option with space'),
         ' value with space')
 
+  def test_retain_unknown_options_binary_store_string(self):
+    options = PipelineOptions(['--unknown_option', 'some_value'])
+    result = options.get_all_options(retain_unknown_options=True)
+    self.assertEqual(result['unknown_option'], 'some_value')
+
+  def test_retain_unknown_options_unary_store_true(self):
+    options = PipelineOptions(['--unknown_option'])
+    result = options.get_all_options(retain_unknown_options=True)
+    self.assertEqual(result['unknown_option'], True)
+
+  def test_retain_unknown_options_unary_missing_prefix(self):
+    options = PipelineOptions(['bad_option'])
+    with self.assertRaises(SystemExit):
+      result = options.get_all_options(retain_unknown_options=True)
+
   def test_override_options(self):
     base_flags = ['--num_workers', '5']
     options = PipelineOptions(base_flags)
diff --git a/sdks/python/apache_beam/runners/portability/flink_runner.py b/sdks/python/apache_beam/runners/portability/flink_runner.py
index d316a71f8c3..ab5c8b73cae 100644
--- a/sdks/python/apache_beam/runners/portability/flink_runner.py
+++ b/sdks/python/apache_beam/runners/portability/flink_runner.py
@@ -65,6 +65,13 @@ class FlinkRunner(portable_runner.PortableRunner):
     else:
       return job_server.StopOnExitJobServer(FlinkJarJobServer(options))
 
+  def create_job_service_handle(self, job_service, options):
+    return portable_runner.JobServiceHandle(
+        job_service,
+        options,
+        retain_unknown_options=options.view_as(
+            pipeline_options.FlinkRunnerOptions).flink_submit_uber_jar)
+
   @staticmethod
   def add_http_scheme(flink_master):
     """Adds a http protocol scheme if none provided."""
diff --git a/sdks/python/apache_beam/runners/portability/flink_uber_jar_job_server_test.py b/sdks/python/apache_beam/runners/portability/flink_uber_jar_job_server_test.py
index 869f0530f80..d8a0d101037 100644
--- a/sdks/python/apache_beam/runners/portability/flink_uber_jar_job_server_test.py
+++ b/sdks/python/apache_beam/runners/portability/flink_uber_jar_job_server_test.py
@@ -32,6 +32,7 @@ import requests_mock
 from apache_beam.options import pipeline_options
 from apache_beam.portability.api import beam_job_api_pb2
 from apache_beam.portability.api import beam_runner_api_pb2
+from apache_beam.runners.portability import flink_runner
 from apache_beam.runners.portability import flink_uber_jar_job_server
 from apache_beam.runners.portability.local_job_service_test import TestJobServicePlan
 
@@ -145,6 +146,21 @@ class FlinkUberJarJobServerTest(unittest.TestCase):
                            beam_job_api_pb2.JobState.DONE,
                        ])
 
+  def test_retain_unknown_options(self):
+    original_options = pipeline_options.PipelineOptions(
+        ['--unknown_option_foo', 'some_value'])
+    flink_options = original_options.view_as(
+        pipeline_options.FlinkRunnerOptions)
+    flink_options.flink_submit_uber_jar = True
+    flink_options.flink_master = 'http://host:port'
+    runner = flink_runner.FlinkRunner()
+
+    job_service_handle = runner.create_job_service(original_options)
+    options_proto = job_service_handle.get_pipeline_options()
+
+    self.assertEqual(
+        options_proto['beam:option:unknown_option_foo:v1'], 'some_value')
+
 
 if __name__ == '__main__':
   logging.getLogger().setLevel(logging.INFO)
diff --git a/sdks/python/apache_beam/runners/portability/portable_runner.py b/sdks/python/apache_beam/runners/portability/portable_runner.py
index 7d5f14ee7b9..1032208b021 100644
--- a/sdks/python/apache_beam/runners/portability/portable_runner.py
+++ b/sdks/python/apache_beam/runners/portability/portable_runner.py
@@ -88,10 +88,11 @@ class JobServiceHandle(object):
   - stage
   - run
   """
-  def __init__(self, job_service, options):
+  def __init__(self, job_service, options, retain_unknown_options=False):
     self.job_service = job_service
     self.options = options
     self.timeout = options.view_as(PortableOptions).job_server_timeout
+    self._retain_unknown_options = retain_unknown_options
 
   def submit(self, proto_pipeline):
     # type: (beam_runner_api_pb2.Pipeline) -> Tuple[str, Iterator[beam_job_api_pb2.JobStateEvent], Iterator[beam_job_api_pb2.JobMessagesResponse]]
@@ -157,7 +158,8 @@ class JobServiceHandle(object):
           _LOGGER.debug("Runner option '%s' was already added" % option.name)
 
     all_options = self.options.get_all_options(
-        add_extra_args_fn=add_runner_options)
+        add_extra_args_fn=add_runner_options,
+        retain_unknown_options=self._retain_unknown_options)
     # TODO: Define URNs for options.
     # convert int values: https://issues.apache.org/jira/browse/BEAM-5509
     p_options = {
@@ -288,6 +290,9 @@ class PortableRunner(runner.PipelineRunner):
           job_server.DockerizedJobServer())
     return self._dockerized_job_server
 
+  def create_job_service_handle(self, job_service, options):
+    return JobServiceHandle(job_service, options)
+
   def create_job_service(self, options):
     # type: (PipelineOptions) -> JobServiceHandle
 
@@ -303,7 +308,7 @@ class PortableRunner(runner.PipelineRunner):
         server = job_server.ExternalJobServer(job_endpoint, job_server_timeout)
     else:
       server = self.default_job_server(options)
-    return JobServiceHandle(server.start(), options)
+    return self.create_job_service_handle(server.start(), options)
 
   @staticmethod
   def get_proto_pipeline(pipeline, options):
diff --git a/sdks/python/apache_beam/runners/portability/spark_runner.py b/sdks/python/apache_beam/runners/portability/spark_runner.py
index f6cebb449f5..f4ef23f3a78 100644
--- a/sdks/python/apache_beam/runners/portability/spark_runner.py
+++ b/sdks/python/apache_beam/runners/portability/spark_runner.py
@@ -57,6 +57,12 @@ class SparkRunner(portable_runner.PortableRunner):
           spark_options.spark_rest_url, options)
     return job_server.StopOnExitJobServer(SparkJarJobServer(options))
 
+  def create_job_service_handle(self, job_service, options):
+    return portable_runner.JobServiceHandle(
+        job_service,
+        options,
+        retain_unknown_options=options.view_as(
+            pipeline_options.SparkRunnerOptions).spark_submit_uber_jar)
 
 class SparkJarJobServer(job_server.JavaJarJobServer):
   def __init__(self, options):
diff --git a/sdks/python/apache_beam/runners/portability/spark_uber_jar_job_server_test.py b/sdks/python/apache_beam/runners/portability/spark_uber_jar_job_server_test.py
index bcd2c5c574f..dffb3138d7b 100644
--- a/sdks/python/apache_beam/runners/portability/spark_uber_jar_job_server_test.py
+++ b/sdks/python/apache_beam/runners/portability/spark_uber_jar_job_server_test.py
@@ -32,10 +32,13 @@ import grpc
 import requests_mock
 
 from apache_beam.options import pipeline_options
+from apache_beam.options.pipeline_options import PipelineOptions
+from apache_beam.options.pipeline_options import SparkRunnerOptions
 from apache_beam.portability.api import beam_artifact_api_pb2
 from apache_beam.portability.api import beam_artifact_api_pb2_grpc
 from apache_beam.portability.api import beam_job_api_pb2
 from apache_beam.portability.api import beam_runner_api_pb2
+from apache_beam.runners.portability import spark_runner
 from apache_beam.runners.portability import spark_uber_jar_job_server
 
 
@@ -214,6 +217,19 @@ class SparkUberJarJobServerTest(unittest.TestCase):
                            beam_job_api_pb2.JobState.FAILED,
                        ])
 
+  def test_retain_unknown_options(self):
+    original_options = PipelineOptions(['--unknown_option_foo', 'some_value'])
+    spark_options = original_options.view_as(SparkRunnerOptions)
+    spark_options.spark_submit_uber_jar = True
+    spark_options.spark_rest_url = 'spark://localhost:6066'
+    runner = spark_runner.SparkRunner()
+
+    job_service_handle = runner.create_job_service(original_options)
+    options_proto = job_service_handle.get_pipeline_options()
+
+    self.assertEqual(
+        options_proto['beam:option:unknown_option_foo:v1'], 'some_value')
+
 
 if __name__ == '__main__':
   logging.getLogger().setLevel(logging.INFO)
