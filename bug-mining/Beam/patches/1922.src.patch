diff --git a/sdks/python/apache_beam/io/mongodbio.py b/sdks/python/apache_beam/io/mongodbio.py
index 1ce25f4f95e..324f1e35679 100644
--- a/sdks/python/apache_beam/io/mongodbio.py
+++ b/sdks/python/apache_beam/io/mongodbio.py
@@ -201,9 +201,9 @@ class _BoundedMongoSource(iobase.BoundedSource):
   def read(self, range_tracker):
     with MongoClient(self.uri, **self.spec) as client:
       all_filters = self._merge_id_filter(range_tracker)
-      docs_cursor = client[self.db][self.coll].find(filter=all_filters).sort([
-          ('_id', ASCENDING)
-      ])
+      docs_cursor = client[self.db][self.coll].find(
+          filter=all_filters,
+          projection=self.projection).sort([('_id', ASCENDING)])
       for doc in docs_cursor:
         if not range_tracker.try_claim(doc['_id']):
           return
@@ -230,13 +230,14 @@ class _BoundedMongoSource(iobase.BoundedSource):
       return []
     with MongoClient(self.uri, **self.spec) as client:
       name_space = '%s.%s' % (self.db, self.coll)
-      return (client[self.db].command(
-          'splitVector',
-          name_space,
-          keyPattern={'_id': 1},  # Ascending index
-          min={'_id': start_pos},
-          max={'_id': end_pos},
-          maxChunkSize=desired_chunk_size_in_mb)['splitKeys'])
+      return (
+          client[self.db].command(
+              'splitVector',
+              name_space,
+              keyPattern={'_id': 1},  # Ascending index
+              min={'_id': start_pos},
+              max={'_id': end_pos},
+              maxChunkSize=desired_chunk_size_in_mb)['splitKeys'])
 
   def _merge_id_filter(self, range_tracker):
     # Merge the default filter with refined _id field range of range_tracker.
diff --git a/sdks/python/apache_beam/io/mongodbio_test.py b/sdks/python/apache_beam/io/mongodbio_test.py
index a914d1e4d50..e327763b90d 100644
--- a/sdks/python/apache_beam/io/mongodbio_test.py
+++ b/sdks/python/apache_beam/io/mongodbio_test.py
@@ -51,7 +51,8 @@ class _MockMongoColl(object):
   def __init__(self, docs):
     self.docs = docs
 
-  def _filter(self, filter):
+  def _filter(self, filter, projection):
+    projection = [] if projection is None else projection
     match = []
     if not filter:
       return self
@@ -66,11 +67,13 @@ class _MockMongoColl(object):
         continue
       if end and doc['_id'] >= end:
         continue
+      if len(projection) > 0:
+        doc = {k: v for k, v in doc.items() if k in projection or k == '_id'}
       match.append(doc)
     return match
 
-  def find(self, filter=None, **kwargs):
-    return _MockMongoColl(self._filter(filter))
+  def find(self, filter=None, projection=None, **kwargs):
+    return _MockMongoColl(self._filter(filter, projection))
 
   def sort(self, sort_items):
     key, order = sort_items[0]
@@ -246,13 +249,24 @@ class MongoSourceTest(unittest.TestCase):
 class ReadFromMongoDBTest(unittest.TestCase):
   @mock.patch('apache_beam.io.mongodbio.MongoClient')
   def test_read_from_mongodb(self, mock_client):
-    documents = [{'_id': objectid.ObjectId(), 'x': i} for i in range(3)]
+    documents = [{
+        '_id': objectid.ObjectId(), 'x': i, 'selected': 1, 'unselected': 2
+    } for i in range(3)]
     mock_client.return_value = _MockMongoClient(documents)
 
+    projection = ['x', 'selected']
+    projected_documents = [{
+        k: v
+        for k, v in e.items() if k in projection or k == '_id'
+    } for e in documents]
+
     with TestPipeline() as p:
       docs = p | 'ReadFromMongoDB' >> ReadFromMongoDB(
-          uri='mongodb://test', db='db', coll='collection')
-      assert_that(docs, equal_to(documents))
+          uri='mongodb://test',
+          db='db',
+          coll='collection',
+          projection=projection)
+      assert_that(docs, equal_to(projected_documents))
 
 
 class GenerateObjectIdFnTest(unittest.TestCase):
