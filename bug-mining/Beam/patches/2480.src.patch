diff --git a/sdks/go/pkg/beam/runners/dataflow/dataflowlib/execute.go b/sdks/go/pkg/beam/runners/dataflow/dataflowlib/execute.go
index f518c455b39..a55c4c5c26e 100644
--- a/sdks/go/pkg/beam/runners/dataflow/dataflowlib/execute.go
+++ b/sdks/go/pkg/beam/runners/dataflow/dataflowlib/execute.go
@@ -117,7 +117,7 @@ func Execute(ctx context.Context, raw *pipepb.Pipeline, opts *JobOptions, worker
 	// (4) Wait for completion.
 	err = WaitForCompletion(ctx, client, opts.Project, opts.Region, upd.Id)
 
-	res, presultErr := newDataflowPipelineResult(ctx, client, job, opts.Project, opts.Region, upd.Id)
+	res, presultErr := newDataflowPipelineResult(ctx, client, p, opts.Project, opts.Region, upd.Id)
 	if presultErr != nil {
 		if err != nil {
 			return presult, errors.Wrap(err, presultErr.Error())
@@ -141,13 +141,12 @@ type dataflowPipelineResult struct {
 	metrics *metrics.Results
 }
 
-func newDataflowPipelineResult(ctx context.Context, client *df.Service, job *df.Job, project, region, jobID string) (*dataflowPipelineResult, error) {
+func newDataflowPipelineResult(ctx context.Context, client *df.Service, p *pipepb.Pipeline, project, region, jobID string) (*dataflowPipelineResult, error) {
 	res, err := GetMetrics(ctx, client, project, region, jobID)
 	if err != nil {
 		return &dataflowPipelineResult{jobID, nil}, errors.Wrap(err, "failed to get metrics")
 	}
-
-	return &dataflowPipelineResult{jobID, FromMetricUpdates(res.Metrics, job)}, nil
+	return &dataflowPipelineResult{jobID, FromMetricUpdates(res.Metrics, p)}, nil
 }
 
 func (pr dataflowPipelineResult) Metrics() metrics.Results {
diff --git a/sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics.go b/sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics.go
index de206fae41d..d5f42e1b37e 100644
--- a/sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics.go
+++ b/sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics.go
@@ -16,10 +16,10 @@
 package dataflowlib
 
 import (
-	"encoding/json"
 	"fmt"
 
 	"github.com/apache/beam/sdks/go/pkg/beam/core/metrics"
+	pipepb "github.com/apache/beam/sdks/go/pkg/beam/model/pipeline_v1"
 	df "google.golang.org/api/dataflow/v1b3"
 )
 
@@ -29,14 +29,14 @@ import (
 // Dataflow currently only reports Counter and Distribution metrics to Cloud
 // Monitoring. Gauge metrics are not supported. The output metrics.Results will
 // not contain any gauges.
-func FromMetricUpdates(allMetrics []*df.MetricUpdate, job *df.Job) *metrics.Results {
-	ac, ad := groupByType(allMetrics, job, true)
-	cc, cd := groupByType(allMetrics, job, false)
+func FromMetricUpdates(allMetrics []*df.MetricUpdate, p *pipepb.Pipeline) *metrics.Results {
+	ac, ad := groupByType(allMetrics, p, true)
+	cc, cd := groupByType(allMetrics, p, false)
 
 	return metrics.NewResults(metrics.MergeCounters(ac, cc), metrics.MergeDistributions(ad, cd), make([]metrics.GaugeResult, 0))
 }
 
-func groupByType(allMetrics []*df.MetricUpdate, job *df.Job, tentative bool) (
+func groupByType(allMetrics []*df.MetricUpdate, p *pipepb.Pipeline, tentative bool) (
 	map[metrics.StepKey]int64,
 	map[metrics.StepKey]metrics.DistributionValue) {
 	counters := make(map[metrics.StepKey]int64)
@@ -48,7 +48,7 @@ func groupByType(allMetrics []*df.MetricUpdate, job *df.Job, tentative bool) (
 			continue
 		}
 
-		key, err := extractKey(metric, job)
+		key, err := extractKey(metric, p)
 		if err != nil {
 			continue
 		}
@@ -70,18 +70,16 @@ func groupByType(allMetrics []*df.MetricUpdate, job *df.Job, tentative bool) (
 	return counters, distributions
 }
 
-func extractKey(metric *df.MetricUpdate, job *df.Job) (metrics.StepKey, error) {
+func extractKey(metric *df.MetricUpdate, p *pipepb.Pipeline) (metrics.StepKey, error) {
 	stepName, ok := metric.Name.Context["step"]
 	if !ok {
 		return metrics.StepKey{}, fmt.Errorf("could not find the internal step name")
 	}
 	userStepName := ""
 
-	for _, step := range job.Steps {
-		if step.Name == stepName {
-			properties := make(map[string]string)
-			json.Unmarshal(step.Properties, &properties)
-			userStepName = properties["user_name"]
+	for k, transform := range p.GetComponents().GetTransforms() {
+		if k == stepName {
+			userStepName = transform.GetUniqueName()
 			break
 		}
 	}
diff --git a/sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics_test.go b/sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics_test.go
index b0396d1d8ac..23a209dce66 100644
--- a/sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics_test.go
+++ b/sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics_test.go
@@ -16,11 +16,10 @@
 package dataflowlib
 
 import (
-	"encoding/json"
-	"fmt"
 	"testing"
 
 	"github.com/apache/beam/sdks/go/pkg/beam/core/metrics"
+	pipepb "github.com/apache/beam/sdks/go/pkg/beam/model/pipeline_v1"
 	"github.com/google/go-cmp/cmp"
 	df "google.golang.org/api/dataflow/v1b3"
 )
@@ -40,12 +39,12 @@ func TestFromMetricUpdates_Counters(t *testing.T) {
 	aName := newMetricStructuredName("customCounter", "customDoFn", true)
 	attempted := df.MetricUpdate{Name: &aName, Scalar: 15.0}
 
-	job, err := newJob("main.customDoFn")
+	p, err := newPipeline("main.customDoFn")
 	if err != nil {
 		t.Fatal(err)
 	}
 
-	got := FromMetricUpdates([]*df.MetricUpdate{&attempted, &committed}, &job).AllMetrics().Counters()
+	got := FromMetricUpdates([]*df.MetricUpdate{&attempted, &committed}, p).AllMetrics().Counters()
 	size := len(got)
 	if size < 1 {
 		t.Fatalf("Invalid array's size: got: %v, want: %v", size, 1)
@@ -87,12 +86,12 @@ func TestFromMetricUpdates_Distributions(t *testing.T) {
 	aName := newMetricStructuredName("customDist", "customDoFn", true)
 	attempted := df.MetricUpdate{Name: &aName, Distribution: distribution}
 
-	job, err := newJob("main.customDoFn")
+	p, err := newPipeline("main.customDoFn")
 	if err != nil {
 		t.Fatal(err)
 	}
 
-	got := FromMetricUpdates([]*df.MetricUpdate{&attempted, &committed}, &job).AllMetrics().Distributions()
+	got := FromMetricUpdates([]*df.MetricUpdate{&attempted, &committed}, p).AllMetrics().Distributions()
 	size := len(got)
 	if size < 1 {
 		t.Fatalf("Invalid array's size: got: %v, want: %v", size, 1)
@@ -114,20 +113,15 @@ func newMetricStructuredName(name, namespace string, attempted bool) df.MetricSt
 	return df.MetricStructuredName{Context: context, Name: name}
 }
 
-func newJob(stepName string) (df.Job, error) {
-	stepRepr := map[string]interface{}{
-		"name": "e5",
-		"properties": map[string]string{
-			"user_name": stepName,
+func newPipeline(stepName string) (*pipepb.Pipeline, error) {
+	p := &pipepb.Pipeline{
+		Components: &pipepb.Components{
+			Transforms: map[string]*pipepb.PTransform{
+				"e5": &pipepb.PTransform{
+					UniqueName: stepName,
+				},
+			},
 		},
 	}
-	stepJson, err := json.Marshal(&stepRepr)
-	if err != nil {
-		return df.Job{}, fmt.Errorf("Could not create Step object: %v", err)
-	}
-	step := df.Step{}
-	if err := json.Unmarshal(stepJson, &step); err != nil {
-		return df.Job{}, fmt.Errorf("Could not create Step object: %v", err)
-	}
-	return df.Job{Steps: []*df.Step{&step}}, nil
+	return p, nil
 }
