diff --git a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/BeamFnMapTaskExecutor.java b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/BeamFnMapTaskExecutor.java
index c18d4bbf365..c267062f056 100644
--- a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/BeamFnMapTaskExecutor.java
+++ b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/BeamFnMapTaskExecutor.java
@@ -345,16 +345,25 @@ public class BeamFnMapTaskExecutor extends DataflowMapTaskExecutor {
         // is deprecated.
         ProcessBundleProgressResponse processBundleProgressResponse =
             MoreFutures.get(bundleProcessOperation.getProcessBundleProgress());
-        updateMetrics(processBundleProgressResponse.getMonitoringInfosList());
+
+        final List<MonitoringInfo> monitoringInfosList =
+            processBundleProgressResponse.getMonitoringInfosList();
 
         // Supporting deprecated metrics until all supported runners are migrated to using
         // MonitoringInfos
         Metrics metrics = processBundleProgressResponse.getMetrics();
+        double elementsConsumed =
+            bundleProcessOperation.getInputElementsConsumed(monitoringInfosList);
+
+        if (elementsConsumed == 0) {
+          elementsConsumed = bundleProcessOperation.getInputElementsConsumed(metrics);
+        }
+
+        updateMetrics(monitoringInfosList);
         updateMetricsDeprecated(metrics);
 
         // todo(migryz): utilize monitoringInfos here.
         // Requires Element Count metrics to be implemented.
-        double elementsConsumed = bundleProcessOperation.getInputElementsConsumed(metrics);
 
         grpcWriteOperationElementsProcessed.accept((int) elementsConsumed);
         progressInterpolator.addPoint(
@@ -400,13 +409,19 @@ public class BeamFnMapTaskExecutor extends DataflowMapTaskExecutor {
      * @param monitoringInfos Usually received from FnApi.
      */
     private void updateMetrics(List<MonitoringInfo> monitoringInfos) {
+      List<MonitoringInfo> monitoringInfosCopy = new ArrayList<>(monitoringInfos);
+
+      List<MonitoringInfo> misToFilter =
+          bundleProcessOperation.findIOPCollectionMonitoringInfos(monitoringInfos);
+      monitoringInfosCopy.removeAll(misToFilter);
+
       final MonitoringInfoToCounterUpdateTransformer monitoringInfoToCounterUpdateTransformer =
           new FnApiMonitoringInfoToCounterUpdateTransformer(
               this.bundleProcessOperation.getPtransformIdToUserStepContext(),
               this.bundleProcessOperation.getPCollectionIdToNameContext());
 
       counterUpdates =
-          monitoringInfos.stream()
+          monitoringInfosCopy.stream()
               .map(monitoringInfoToCounterUpdateTransformer::transform)
               .filter(Objects::nonNull)
               .collect(Collectors.toList());
diff --git a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/MeanByteCountMonitoringInfoToCounterUpdateTransformer.java b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/MeanByteCountMonitoringInfoToCounterUpdateTransformer.java
index 6a35654bcf9..bd332eceff8 100644
--- a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/MeanByteCountMonitoringInfoToCounterUpdateTransformer.java
+++ b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/MeanByteCountMonitoringInfoToCounterUpdateTransformer.java
@@ -43,7 +43,7 @@ public class MeanByteCountMonitoringInfoToCounterUpdateTransformer
   private final Map<String, NameContext> pcollectionIdToNameContext;
 
   // TODO(BEAM-6945): utilize value from metrics.proto once it gets in.
-  private static final String SUPPORTED_URN = "beam:metric:sampled_byte_size:v1";
+  private static final String SUPPORTED_URN = MonitoringInfoConstants.Urns.SAMPLED_BYTE_SIZE;
 
   /**
    * @param specValidator SpecMonitoringInfoValidator to utilize for default validation.
@@ -74,7 +74,6 @@ public class MeanByteCountMonitoringInfoToCounterUpdateTransformer
       throw new RuntimeException(String.format("Received unexpected counter urn: %s", urn));
     }
 
-    // TODO(migryz): extract and utilize pcollection label from beam_fn_api.proto
     if (!pcollectionIdToNameContext.containsKey(
         monitoringInfo.getLabelsMap().get(MonitoringInfoConstants.Labels.PCOLLECTION))) {
       return Optional.of(
diff --git a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/RegisterAndProcessBundleOperation.java b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/RegisterAndProcessBundleOperation.java
index c2a3743d38e..740eb2f9731 100644
--- a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/RegisterAndProcessBundleOperation.java
+++ b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/fn/control/RegisterAndProcessBundleOperation.java
@@ -21,9 +21,12 @@ import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Prec
 
 import java.io.Closeable;
 import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Set;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CompletionStage;
 import java.util.concurrent.ConcurrentHashMap;
@@ -45,9 +48,11 @@ import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateRequest.RequestCase;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateResponse;
 import org.apache.beam.model.pipeline.v1.MetricsApi.MonitoringInfo;
 import org.apache.beam.model.pipeline.v1.RunnerApi;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PTransform;
 import org.apache.beam.runners.core.SideInputReader;
 import org.apache.beam.runners.core.StateNamespaces;
 import org.apache.beam.runners.core.StateTags;
+import org.apache.beam.runners.core.metrics.MonitoringInfoConstants;
 import org.apache.beam.runners.dataflow.worker.ByteStringCoder;
 import org.apache.beam.runners.dataflow.worker.DataflowExecutionContext.DataflowStepContext;
 import org.apache.beam.runners.dataflow.worker.DataflowOperationContext;
@@ -61,6 +66,7 @@ import org.apache.beam.sdk.coders.Coder;
 import org.apache.beam.sdk.coders.KvCoder;
 import org.apache.beam.sdk.fn.IdGenerator;
 import org.apache.beam.sdk.fn.data.RemoteGrpcPortRead;
+import org.apache.beam.sdk.fn.data.RemoteGrpcPortWrite;
 import org.apache.beam.sdk.state.BagState;
 import org.apache.beam.sdk.transforms.Materializations;
 import org.apache.beam.sdk.transforms.windowing.BoundedWindow;
@@ -110,6 +116,8 @@ public class RegisterAndProcessBundleOperation extends Operation {
 
   private @Nullable String grpcReadTransformId = null;
   private String grpcReadTransformOutputName = null;
+  private String grpcReadTransformOutputPCollectionName = null;
+  private final Set<String> grpcReadTransformReadWritePCollectionNames;
 
   public RegisterAndProcessBundleOperation(
       IdGenerator idGenerator,
@@ -145,6 +153,7 @@ public class RegisterAndProcessBundleOperation extends Operation {
       LOG.debug(
           "Process bundle descriptor {}", toDot(registerRequest.getProcessBundleDescriptor(0)));
     }
+
     for (Map.Entry<String, RunnerApi.PTransform> pTransform :
         registerRequest.getProcessBundleDescriptor(0).getTransformsMap().entrySet()) {
       if (pTransform.getValue().getSpec().getUrn().equals(RemoteGrpcPortRead.URN)) {
@@ -152,13 +161,45 @@ public class RegisterAndProcessBundleOperation extends Operation {
           // TODO: Handle the case of more than one input.
           grpcReadTransformId = null;
           grpcReadTransformOutputName = null;
+          grpcReadTransformOutputPCollectionName = null;
           break;
         }
         grpcReadTransformId = pTransform.getKey();
         grpcReadTransformOutputName =
             Iterables.getOnlyElement(pTransform.getValue().getOutputsMap().keySet());
+        grpcReadTransformOutputPCollectionName =
+            pTransform.getValue().getOutputsMap().get(grpcReadTransformOutputName);
       }
     }
+
+    grpcReadTransformReadWritePCollectionNames =
+        extractCrossBoundaryGrpcPCollectionNames(
+            registerRequest.getProcessBundleDescriptor(0).getTransformsMap().entrySet());
+  }
+
+  private Set<String> extractCrossBoundaryGrpcPCollectionNames(
+      final Set<Entry<String, PTransform>> ptransforms) {
+    Set<String> result = new HashSet<>();
+
+    // GRPC Read/Write expected to only have one Output/Input respectively.
+    for (Map.Entry<String, RunnerApi.PTransform> pTransform : ptransforms) {
+      if (pTransform.getValue().getSpec().getUrn().equals(RemoteGrpcPortRead.URN)) {
+        String grpcReadTransformOutputName =
+            Iterables.getOnlyElement(pTransform.getValue().getOutputsMap().keySet());
+        String pcollectionName =
+            pTransform.getValue().getOutputsMap().get(grpcReadTransformOutputName);
+        result.add(pcollectionName);
+      }
+
+      if (pTransform.getValue().getSpec().getUrn().equals(RemoteGrpcPortWrite.URN)) {
+        String grpcTransformInputName =
+            Iterables.getOnlyElement(pTransform.getValue().getInputsMap().keySet());
+        String pcollectionName = pTransform.getValue().getInputsMap().get(grpcTransformInputName);
+        result.add(pcollectionName);
+      }
+    }
+
+    return result;
   }
 
   /** Generates a dot description of the process bundle descriptor. */
@@ -375,6 +416,49 @@ public class RegisterAndProcessBundleOperation extends Operation {
     }
   }
 
+  /*
+   * Returns a subset of monitoring infos that refer to grpc IO.
+   */
+  public List<MonitoringInfo> findIOPCollectionMonitoringInfos(
+      Iterable<MonitoringInfo> monitoringInfos) {
+    List<MonitoringInfo> result = new ArrayList<MonitoringInfo>();
+    if (grpcReadTransformReadWritePCollectionNames.isEmpty()) {
+      return result;
+    }
+
+    for (MonitoringInfo mi : monitoringInfos) {
+      if (mi.getUrn().equals(MonitoringInfoConstants.Urns.ELEMENT_COUNT)) {
+        String pcollection =
+            mi.getLabelsOrDefault(MonitoringInfoConstants.Labels.PCOLLECTION, null);
+        if ((pcollection != null)
+            && (grpcReadTransformReadWritePCollectionNames.contains(pcollection))) {
+          result.add(mi);
+        }
+      }
+    }
+
+    return result;
+  }
+
+  long getInputElementsConsumed(final Iterable<MonitoringInfo> monitoringInfos) {
+    if (grpcReadTransformId == null) {
+      return 0;
+    }
+
+    for (MonitoringInfo mi : monitoringInfos) {
+      if (mi.getUrn().equals(MonitoringInfoConstants.Urns.ELEMENT_COUNT)) {
+        String pcollection =
+            mi.getLabelsOrDefault(MonitoringInfoConstants.Labels.PCOLLECTION, null);
+        if ((pcollection != null)
+            && (!pcollection.equals(grpcReadTransformOutputPCollectionName))) {
+          return mi.getMetric().getCounterData().getInt64Value();
+        }
+      }
+    }
+
+    return 0;
+  }
+
   /** Returns the number of input elements consumed by the gRPC read, if known, otherwise 0. */
   double getInputElementsConsumed(BeamFnApi.Metrics metrics) {
     return metrics
diff --git a/sdks/python/apache_beam/runners/dataflow/dataflow_exercise_streaming_metrics_pipeline_test.py b/sdks/python/apache_beam/runners/dataflow/dataflow_exercise_streaming_metrics_pipeline_test.py
index 3e6db0e071a..a2b0928fe23 100644
--- a/sdks/python/apache_beam/runners/dataflow/dataflow_exercise_streaming_metrics_pipeline_test.py
+++ b/sdks/python/apache_beam/runners/dataflow/dataflow_exercise_streaming_metrics_pipeline_test.py
@@ -126,6 +126,21 @@ class ExerciseStreamingMetricsPipelineTest(unittest.TestCase):
       ('apache_beam.runners.dataflow.'
        'dataflow_exercise_streaming_metrics_pipeline.StreamingUserMetricsDoFn')
     matchers = [
+        # System metrics
+        MetricResultMatcher(
+            name='ElementCount',
+            labels={"output_user_name": "generate_metrics-out0",
+                    "original_name": "generate_metrics-out0-ElementCount"},
+            attempted=len(MESSAGES_TO_PUBLISH),
+            committed=len(MESSAGES_TO_PUBLISH),
+        ),
+        MetricResultMatcher(
+            name='ElementCount',
+            labels={"output_user_name": "ReadFromPubSub/Read-out0",
+                    "original_name": "ReadFromPubSub/Read-out0-ElementCount"},
+            attempted=len(MESSAGES_TO_PUBLISH),
+            committed=len(MESSAGES_TO_PUBLISH),
+        ),
         # User Counter Metrics.
         MetricResultMatcher(
             name='double_msg_counter_name',
