diff --git a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
index 97bbfc2f568..d57307fc8b8 100644
--- a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
+++ b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
@@ -21,11 +21,16 @@ from __future__ import absolute_import
 import logging
 import unittest
 
+from nose.plugins.attrib import attr
+
 import apache_beam as beam
 from apache_beam import runners
 from apache_beam.options import pipeline_options
 from apache_beam.portability import common_urns
 from apache_beam.runners.portability.fn_api_runner import translations
+from apache_beam.testing.test_pipeline import TestPipeline
+from apache_beam.testing.util import assert_that
+from apache_beam.testing.util import equal_to
 from apache_beam.transforms import combiners
 from apache_beam.transforms import core
 from apache_beam.transforms import environments
@@ -227,6 +232,57 @@ class TranslationsTest(unittest.TestCase):
     assert_is_topologically_sorted(
         optimized_pipeline_proto.root_transform_ids[0], set())
 
+  @attr('ValidatesRunner')
+  def test_run_packable_combine_per_key(self):
+    class MultipleCombines(beam.PTransform):
+      def expand(self, pcoll):
+        # These CombinePerKey stages will be packed if and only if
+        # translations.pack_combiners is enabled in the TestPipeline runner.
+        assert_that(
+            pcoll | 'mean-perkey' >> combiners.Mean.PerKey(),
+            equal_to([('a', 3.4)]),
+            label='assert-mean-perkey')
+        assert_that(
+            pcoll | 'count-perkey' >> combiners.Count.PerKey(),
+            equal_to([('a', 10)]),
+            label='assert-count-perkey')
+        assert_that(
+            pcoll
+            | 'largest-perkey' >> core.CombinePerKey(combiners.Largest(1)),
+            equal_to([('a', [9])]),
+            label='assert-largest-perkey')
+
+    with TestPipeline() as pipeline:
+      vals = [6, 3, 1, 1, 9, 1, 5, 2, 0, 6]
+      _ = (
+          pipeline
+          | Create([('a', x) for x in vals])
+          | 'multiple-combines' >> MultipleCombines())
+
+  def test_run_packable_combine_globally(self):
+    class MultipleCombines(beam.PTransform):
+      def expand(self, pcoll):
+        # These CombineGlobally stages will be packed if and only if
+        # translations.eliminate_common_key_with_void and
+        # translations.pack_combiners are enabled in the TestPipeline runner.
+        assert_that(
+            pcoll | 'mean-globally' >> combiners.Mean.Globally(),
+            equal_to([3.4]),
+            label='assert-mean-globally')
+        assert_that(
+            pcoll | 'count-globally' >> combiners.Count.Globally(),
+            equal_to([10]),
+            label='assert-count-globally')
+        assert_that(
+            pcoll
+            | 'largest-globally' >> core.CombineGlobally(combiners.Largest(1)),
+            equal_to([[9]]),
+            label='assert-largest-globally')
+
+    with TestPipeline() as pipeline:
+      vals = [6, 3, 1, 1, 9, 1, 5, 2, 0, 6]
+      _ = pipeline | Create(vals) | 'multiple-combines' >> MultipleCombines()
+
 
 if __name__ == '__main__':
   logging.getLogger().setLevel(logging.INFO)
