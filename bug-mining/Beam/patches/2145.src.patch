diff --git a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py
index b3d6e027b57..31268228817 100644
--- a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py
+++ b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py
@@ -948,13 +948,46 @@ def pack_combiners(stages, context):
         component_coder_ids=[key_coder_id, pack_output_value_coder_id])
     pack_output_kv_coder_id = context.add_or_get_coder_id(pack_output_kv_coder)
 
-    # Set up packed PCollection
-    pack_combine_name = fused_stage.name
+    def make_pack_name(names):
+      """Return the packed Transform or Stage name.
+
+      The output name will contain the input names' common prefix, the infix
+      '/Packed', and the input names' suffixes in square brackets.
+      For example, if the input names are 'a/b/c1/d1' and 'a/b/c2/d2, then
+      the output name is 'a/b/Packed[c1/d1, c2/d2]'.
+      """
+      assert names
+      tokens_in_names = [name.split('/') for name in names]
+      common_prefix_tokens = []
+
+      # Find the longest common prefix of tokens.
+      while True:
+        first_token_in_names = set()
+        for tokens in tokens_in_names:
+          if not tokens:
+            break
+          first_token_in_names.add(tokens[0])
+        if len(first_token_in_names) != 1:
+          break
+        common_prefix_tokens.append(next(iter(first_token_in_names)))
+        for tokens in tokens_in_names:
+          tokens.pop(0)
+
+      common_prefix_tokens.append('Packed')
+      common_prefix = '/'.join(common_prefix_tokens)
+      suffixes = ['/'.join(tokens) for tokens in tokens_in_names]
+      return '%s[%s]' % (common_prefix, ', '.join(suffixes))
+
+    pack_stage_name = make_pack_name([stage.name for stage in packable_stages])
+    pack_transform_name = make_pack_name([
+        only_transform(stage.transforms).unique_name
+        for stage in packable_stages
+    ])
     pack_pcoll_id = unique_name(context.components.pcollections, 'pcollection')
     input_pcoll = context.components.pcollections[input_pcoll_id]
     context.components.pcollections[pack_pcoll_id].CopyFrom(
         beam_runner_api_pb2.PCollection(
-            unique_name=pack_combine_name + '.out',
+            unique_name=pack_transform_name + '/Pack.out',
             coder_id=pack_output_kv_coder_id,
             windowing_strategy_id=input_pcoll.windowing_strategy_id,
             is_bounded=input_pcoll.is_bounded))
@@ -969,7 +1002,7 @@ def pack_combiners(stages, context):
             for combine_payload in combine_payloads
         ]).to_runner_api(context)  # type: ignore[arg-type]
     pack_transform = beam_runner_api_pb2.PTransform(
-        unique_name=pack_combine_name + '/Pack',
+        unique_name=pack_transform_name + '/Pack',
         spec=beam_runner_api_pb2.FunctionSpec(
             urn=common_urns.composites.COMBINE_PER_KEY.urn,
             payload=beam_runner_api_pb2.CombinePayload(
@@ -980,7 +1013,7 @@ def pack_combiners(stages, context):
         outputs={'out': pack_pcoll_id},
         environment_id=fused_stage.environment)
     pack_stage = Stage(
-        pack_combine_name + '/Pack', [pack_transform],
+        pack_stage_name + '/Pack', [pack_transform],
         downstream_side_inputs=fused_stage.downstream_side_inputs,
         must_follow=fused_stage.must_follow,
         parent=fused_stage.parent,
@@ -991,7 +1024,7 @@ def pack_combiners(stages, context):
     tags = [str(i) for i in range(len(output_pcoll_ids))]
     pickled_do_fn_data = pickler.dumps((_UnpackFn(tags), (), {}, [], None))
     unpack_transform = beam_runner_api_pb2.PTransform(
-        unique_name=pack_combine_name + '/Unpack',
+        unique_name=pack_transform_name + '/Unpack',
         spec=beam_runner_api_pb2.FunctionSpec(
             urn=common_urns.primitives.PAR_DO.urn,
             payload=beam_runner_api_pb2.ParDoPayload(
@@ -1002,7 +1035,7 @@ def pack_combiners(stages, context):
         outputs=dict(zip(tags, output_pcoll_ids)),
         environment_id=fused_stage.environment)
     unpack_stage = Stage(
-        pack_combine_name + '/Unpack', [unpack_transform],
+        pack_stage_name + '/Unpack', [unpack_transform],
         downstream_side_inputs=fused_stage.downstream_side_inputs,
         must_follow=fused_stage.must_follow,
         parent=fused_stage.parent,
diff --git a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
index 8eb79609367..4c7643ba3ee 100644
--- a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
+++ b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
@@ -74,7 +74,8 @@ class TranslationsTest(unittest.TestCase):
         if transform.spec.urn == common_urns.composites.COMBINE_PER_KEY.urn:
           combine_per_key_stages.append(stage)
     self.assertEqual(len(combine_per_key_stages), 1)
-    self.assertIn('/Pack', combine_per_key_stages[0].name)
+    self.assertIn('Packed', combine_per_key_stages[0].name)
+    self.assertIn('Packed', combine_per_key_stages[0].transforms[0].unique_name)
     self.assertIn('multiple-combines', combine_per_key_stages[0].parent)
     self.assertNotIn('-perkey', combine_per_key_stages[0].parent)
 
@@ -101,7 +102,9 @@ class TranslationsTest(unittest.TestCase):
     # the beam:combinefn:packed_python:v1 capability.
     self.assertEqual(len(combine_per_key_stages), 2)
     for combine_per_key_stage in combine_per_key_stages:
-      self.assertNotIn('/Pack', combine_per_key_stage.name)
+      self.assertNotIn('Packed', combine_per_key_stage.name)
+      self.assertNotIn(
+          'Packed', combine_per_key_stage.transforms[0].unique_name)
 
   def test_pack_global_combiners(self):
     class MultipleCombines(beam.PTransform):
@@ -134,7 +137,8 @@ class TranslationsTest(unittest.TestCase):
         if transform.spec.urn == common_urns.composites.COMBINE_PER_KEY.urn:
           combine_per_key_stages.append(stage)
     self.assertEqual(len(combine_per_key_stages), 1)
-    self.assertIn('/Pack', combine_per_key_stages[0].name)
+    self.assertIn('Packed', combine_per_key_stages[0].name)
+    self.assertIn('Packed', combine_per_key_stages[0].transforms[0].unique_name)
     self.assertIn('multiple-combines', combine_per_key_stages[0].parent)
     self.assertNotIn('-globally', combine_per_key_stages[0].parent)
 
