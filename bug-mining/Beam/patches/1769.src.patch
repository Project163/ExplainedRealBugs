diff --git a/build.gradle b/build.gradle
index 708a66b63c6..681831bef7f 100644
--- a/build.gradle
+++ b/build.gradle
@@ -213,7 +213,9 @@ task pythonPreCommit() {
   dependsOn ":sdks:python:test-suites:tox:py36:preCommitPy36"
   dependsOn ":sdks:python:test-suites:tox:py37:preCommitPy37"
   dependsOn ":sdks:python:test-suites:dataflow:py2:preCommitIT"
+  dependsOn ":sdks:python:test-suites:dataflow:py2:preCommitIT_V2"
   dependsOn ":sdks:python:test-suites:dataflow:py37:preCommitIT"
+  dependsOn ":sdks:python:test-suites:dataflow:py37:preCommitIT_V2"
   // We don't include Py35, Py36 precommit ITs to reduce quota footprint.
   // We can reconsider if we ever see an issue that these suites would
   // have caught. Note that the same tests will still run in postcommit.
diff --git a/sdks/python/test-suites/dataflow/py2/build.gradle b/sdks/python/test-suites/dataflow/py2/build.gradle
index 6f5ee0abbc2..93bc633800c 100644
--- a/sdks/python/test-suites/dataflow/py2/build.gradle
+++ b/sdks/python/test-suites/dataflow/py2/build.gradle
@@ -33,37 +33,68 @@ def basicTestOpts = [
     "--process-timeout=4500", // timeout of whole command execution
 ]
 
-task preCommitIT {
-  dependsOn 'installGcpTest'
-  dependsOn ':sdks:python:sdist'
-  dependsOn ":runners:google-cloud-dataflow-java:worker:shadowJar"
+def preCommitIT(String runScriptsDir, String envdir, Boolean streaming, Boolean runnerV2) {
+    def suffix = runnerV2 ? '_V2' : ''
+    suffix = streaming ? "_streaming$suffix" : "_batch$suffix"
+    task "preCommitIT${suffix}" {
+        dependsOn 'installGcpTest'
+        dependsOn ':sdks:python:sdist'
+        dependsOn ":runners:google-cloud-dataflow-java:worker:shadowJar"
+
+        def dataflowWorkerJar = project(":runners:google-cloud-dataflow-java:worker").shadowJar.archivePath
+
+        doLast {
+            // Basic integration tests to run in PreCommit
+            def precommitTests = streaming ? [
+                    "apache_beam.examples.streaming_wordcount_it_test:StreamingWordCountIT.test_streaming_wordcount_it",
+            ] : [
+                    "apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it",
+            ]
+            def testOpts = [
+                    "--tests=${precommitTests.join(',')}",
+                    "--nocapture",    // Print stdout instantly
+                    "--processes=2",    // Number of tests running in parallel
+                    "--process-timeout=1800",   // Timeout of whole command execution
+            ]
+
+            def argMap = [
+                    "test_opts"   : testOpts,
+                    "sdk_location": files(configurations.distTarBall.files).singleFile,
+                    "worker_jar"  : dataflowWorkerJar,
+                    "suite"       : "preCommitIT-df"
+            ]
+
+            if (runnerV2) {
+                argMap.put("runner_v2", "true")
+                // KMS is not supported for streaming engine.
+                argMap.put("kms_key_name", "\"\"")
+            }
+            if (streaming){
+                argMap.put("streaming", "true")
+            }
+
+            def cmdArgs = mapToArgString(argMap)
+            exec {
+                executable 'sh'
+                args '-c', ". ${envdir}/bin/activate && ${runScriptsDir}/run_integration_test.sh $cmdArgs"
+            }
+        }
+    }
+}
 
-  def dataflowWorkerJar = project(":runners:google-cloud-dataflow-java:worker").shadowJar.archivePath
+preCommitIT(runScriptsDir, envdir, false, false)
+preCommitIT(runScriptsDir, envdir, true, false)
+preCommitIT(runScriptsDir, envdir, false, true)
+preCommitIT(runScriptsDir, envdir, true, true)
 
-  doLast {
-    // Basic integration tests to run in PreCommit
-    def precommitTests = [
-        "apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it",
-        "apache_beam.examples.streaming_wordcount_it_test:StreamingWordCountIT.test_streaming_wordcount_it",
-    ]
-    def testOpts = [
-        "--tests=${precommitTests.join(',')}",
-        "--nocapture",    // Print stdout instantly
-        "--processes=2",    // Number of tests running in parallel
-        "--process-timeout=1800",   // Timeout of whole command execution
-    ]
-    def cmdArgs = mapToArgString([
-        "test_opts": testOpts,
-        "sdk_location": files(configurations.distTarBall.files).singleFile,
-        "worker_jar": dataflowWorkerJar,
-        "suite": "preCommitIT-df"
-    ])
+task preCommitIT{
+    dependsOn preCommitIT_batch
+    dependsOn preCommitIT_streaming
+}
 
-    exec {
-      executable 'sh'
-      args '-c', ". ${envdir}/bin/activate && ${runScriptsDir}/run_integration_test.sh $cmdArgs"
-    }
-  }
+task preCommitIT_V2{
+    dependsOn preCommitIT_batch_V2
+    dependsOn preCommitIT_streaming_V2
 }
 
 // Run PostCommit integration tests on default runner (TestDataflowRunner)
diff --git a/sdks/python/test-suites/dataflow/py37/build.gradle b/sdks/python/test-suites/dataflow/py37/build.gradle
index 7ace1080fd7..22fed839ed5 100644
--- a/sdks/python/test-suites/dataflow/py37/build.gradle
+++ b/sdks/python/test-suites/dataflow/py37/build.gradle
@@ -37,37 +37,68 @@ def basicTestOpts = [
     "--process-timeout=4500", // timeout of whole command execution
 ]
 
-task preCommitIT {
-  dependsOn 'installGcpTest'
-  dependsOn ':sdks:python:sdist'
-  dependsOn ":runners:google-cloud-dataflow-java:worker:shadowJar"
+def preCommitIT(String runScriptsDir, String envdir, Boolean streaming, Boolean runnerV2) {
+  def suffix = runnerV2 ? '_V2' : ''
+  suffix = streaming ? "_streaming$suffix" : "_batch$suffix"
+  task "preCommitIT${suffix}" {
+    dependsOn 'installGcpTest'
+    dependsOn ':sdks:python:sdist'
+    dependsOn ":runners:google-cloud-dataflow-java:worker:shadowJar"
+
+    def dataflowWorkerJar = project(":runners:google-cloud-dataflow-java:worker").shadowJar.archivePath
+
+    doLast {
+      // Basic integration tests to run in PreCommit
+      def precommitTests = streaming ? [
+              "apache_beam.examples.streaming_wordcount_it_test:StreamingWordCountIT.test_streaming_wordcount_it",
+      ] : [
+              "apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it",
+      ]
+      def testOpts = [
+              "--tests=${precommitTests.join(',')}",
+              "--nocapture",    // Print stdout instantly
+              "--processes=2",    // Number of tests running in parallel
+              "--process-timeout=1800",   // Timeout of whole command execution
+      ]
+
+      def argMap = [
+              "test_opts"   : testOpts,
+              "sdk_location": files(configurations.distTarBall.files).singleFile,
+              "worker_jar"  : dataflowWorkerJar,
+              "suite"       : "preCommitIT-df-py37"
+      ]
+
+      if (runnerV2) {
+        argMap.put("runner_v2", "true")
+        // KMS is not supported for streaming engine.
+        argMap.put("kms_key_name", "\"\"")
+      }
+      if (streaming){
+        argMap.put("streaming", "true")
+      }
+
+      def cmdArgs = mapToArgString(argMap)
+      exec {
+        executable 'sh'
+        args '-c', ". ${envdir}/bin/activate && ${runScriptsDir}/run_integration_test.sh $cmdArgs"
+      }
+    }
+  }
+}
 
-  def dataflowWorkerJar = project(":runners:google-cloud-dataflow-java:worker").shadowJar.archivePath
+preCommitIT(runScriptsDir, envdir, false, false)
+preCommitIT(runScriptsDir, envdir, true, false)
+preCommitIT(runScriptsDir, envdir, false, true)
+preCommitIT(runScriptsDir, envdir, true, true)
 
-  doLast {
-    // Basic integration tests to run in PreCommit
-    def precommitTests = [
-        "apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it",
-        "apache_beam.examples.streaming_wordcount_it_test:StreamingWordCountIT.test_streaming_wordcount_it",
-    ]
-    def testOpts = [
-        "--tests=${precommitTests.join(',')}",
-        "--nocapture",    // Print stdout instantly
-        "--processes=2",    // Number of tests running in parallel
-        "--process-timeout=1800",   // Timeout of whole command execution
-    ]
-    def cmdArgs = mapToArgString([
-        "test_opts": testOpts,
-        "sdk_location": files(configurations.distTarBall.files).singleFile,
-        "worker_jar": dataflowWorkerJar,
-        "suite": "preCommitIT-df-py37"
-    ])
+task preCommitIT{
+  dependsOn preCommitIT_batch
+  dependsOn preCommitIT_streaming
+}
 
-    exec {
-      executable 'sh'
-      args '-c', ". ${envdir}/bin/activate && ${runScriptsDir}/run_integration_test.sh $cmdArgs"
-    }
-  }
+task preCommitIT_V2{
+  dependsOn preCommitIT_batch_V2
+  dependsOn preCommitIT_streaming_V2
 }
 
 task postCommitIT {
