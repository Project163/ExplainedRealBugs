diff --git a/sdks/java/io/debezium/expansion-service/build.gradle b/sdks/java/io/debezium/expansion-service/build.gradle
new file mode 100644
index 00000000000..a183c9128b2
--- /dev/null
+++ b/sdks/java/io/debezium/expansion-service/build.gradle
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * License); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an AS IS BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+apply plugin: 'org.apache.beam.module'
+apply plugin: 'application'
+mainClassName = "org.apache.beam.sdk.expansion.service.ExpansionService"
+
+applyJavaNature(
+        automaticModuleName: 'org.apache.beam.sdk.io.debezium.expansion.service',
+        exportJavadoc: false,
+        validateShadowJar: false,
+        shadowClosure: {},
+)
+
+description = "Apache Beam :: SDKs :: Java :: IO :: Debezium :: Expansion Service"
+ext.summary = "Expansion service serving DebeziumIO"
+
+dependencies {
+    compile project(":sdks:java:expansion-service")
+    permitUnusedDeclared project(":sdks:java:expansion-service") // BEAM-11761
+    compile project(":sdks:java:io:debezium")
+    permitUnusedDeclared project(":sdks:java:io:debezium") // BEAM-11761
+    runtime library.java.slf4j_jdk14
+
+    // Debezium runtime dependencies
+    def debezium_version = '1.3.1.Final'
+    runtimeOnly group: 'io.debezium', name: 'debezium-connector-mysql', version: debezium_version
+    runtimeOnly group: 'io.debezium', name: 'debezium-connector-postgres', version: debezium_version
+    runtimeOnly group: 'io.debezium', name: 'debezium-connector-sqlserver', version: debezium_version
+    runtimeOnly group: 'io.debezium', name: 'debezium-connector-oracle', version: debezium_version
+    runtimeOnly group: 'io.debezium', name: 'debezium-connector-db2', version: debezium_version
+}
\ No newline at end of file
diff --git a/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/Connectors.java b/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/Connectors.java
new file mode 100644
index 00000000000..7aa8b6d0dc7
--- /dev/null
+++ b/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/Connectors.java
@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.io.debezium;
+
+import org.apache.kafka.connect.source.SourceConnector;
+import org.checkerframework.checker.nullness.qual.Nullable;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/** Enumeration of debezium connectors. */
+public enum Connectors {
+  MYSQL("MySQL", "io.debezium.connector.mysql.MySqlConnector"),
+  POSTGRES("PostgreSQL", "io.debezium.connector.postgresql.PostgresConnector"),
+  SQLSERVER("SQLServer", "io.debezium.connector.sqlserver.SqlServerConnector"),
+  ORACLE("Oracle", "io.debezium.connector.oracle.OracleConnector"),
+  DB2("DB2", "io.debezium.connector.db2.Db2Connector"),
+  ;
+  private static final Logger LOG = LoggerFactory.getLogger(Connectors.class);
+  private final String name;
+  private final String connector;
+
+  Connectors(String name, String connector) {
+    this.name = name;
+    this.connector = connector;
+  }
+
+  /** The name of this connector class. */
+  public String getName() {
+    return name;
+  }
+
+  /** Class connector to debezium. */
+  public @Nullable Class<? extends SourceConnector> getConnector() {
+    Class<? extends SourceConnector> connectorClass = null;
+    try {
+      connectorClass = (Class<? extends SourceConnector>) Class.forName(this.connector);
+    } catch (ClassCastException | ClassNotFoundException e) {
+      LOG.error("Connector class is not found", e);
+    }
+    return connectorClass;
+  }
+
+  /**
+   * Returns a connector class corresponding to the given connector name.
+   *
+   * @param connectorName The name of the connector. Ex.: MySQL
+   * @return Connector enum representing the given connector name.
+   */
+  public static Connectors fromName(String connectorName) {
+    for (Connectors connector : Connectors.values()) {
+      if (connector.getName().equals(connectorName)) {
+        return connector;
+      }
+    }
+    throw new IllegalArgumentException("Cannot create enum from " + connectorName + " value!");
+  }
+}
diff --git a/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/DebeziumTransformRegistrar.java b/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/DebeziumTransformRegistrar.java
new file mode 100644
index 00000000000..a00f706abfb
--- /dev/null
+++ b/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/DebeziumTransformRegistrar.java
@@ -0,0 +1,125 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.io.debezium;
+
+import com.google.auto.service.AutoService;
+import java.util.List;
+import java.util.Map;
+import org.apache.beam.sdk.annotations.Experimental;
+import org.apache.beam.sdk.expansion.ExternalTransformRegistrar;
+import org.apache.beam.sdk.transforms.ExternalTransformBuilder;
+import org.apache.beam.sdk.transforms.PTransform;
+import org.apache.beam.sdk.values.PBegin;
+import org.apache.beam.sdk.values.PCollection;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
+import org.checkerframework.checker.nullness.qual.Nullable;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/** Exposes {@link DebeziumIO.Read} as an external transform for cross-language usage. */
+@Experimental(Experimental.Kind.PORTABILITY)
+@AutoService(ExternalTransformRegistrar.class)
+@SuppressWarnings({
+  "nullness" // TODO(https://issues.apache.org/jira/browse/BEAM-10402)
+})
+public class DebeziumTransformRegistrar implements ExternalTransformRegistrar {
+  private static final Logger LOG = LoggerFactory.getLogger(DebeziumTransformRegistrar.class);
+  public static final String READ_JSON_URN = "beam:external:java:debezium:read:v1";
+
+  @Override
+  public Map<String, Class<? extends ExternalTransformBuilder<?, ?, ?>>> knownBuilders() {
+    return ImmutableMap.of(
+        READ_JSON_URN,
+        (Class<? extends ExternalTransformBuilder<?, ?, ?>>) (Class<?>) ReadBuilder.class);
+  }
+
+  private abstract static class CrossLanguageConfiguration {
+    String username;
+    String password;
+    String host;
+    String port;
+    Connectors connectorClass;
+
+    public void setUsername(String username) {
+      this.username = username;
+    }
+
+    public void setPassword(String password) {
+      this.password = password;
+    }
+
+    public void setHost(String host) {
+      this.host = host;
+    }
+
+    public void setPort(String port) {
+      this.port = port;
+    }
+
+    public void setConnectorClass(String connectorClass) {
+      this.connectorClass = Connectors.fromName(connectorClass);
+    }
+  }
+
+  public static class ReadBuilder
+      implements ExternalTransformBuilder<ReadBuilder.Configuration, PBegin, PCollection<String>> {
+
+    public static class Configuration extends CrossLanguageConfiguration {
+      private @Nullable List<String> connectionProperties;
+      private @Nullable Long maxNumberOfRecords;
+
+      public void setConnectionProperties(@Nullable List<String> connectionProperties) {
+        this.connectionProperties = connectionProperties;
+      }
+
+      public void setMaxNumberOfRecords(@Nullable Long maxNumberOfRecords) {
+        this.maxNumberOfRecords = maxNumberOfRecords;
+      }
+    }
+
+    @Override
+    public PTransform<PBegin, PCollection<String>> buildExternal(Configuration configuration) {
+      DebeziumIO.ConnectorConfiguration connectorConfiguration =
+          DebeziumIO.ConnectorConfiguration.create()
+              .withUsername(configuration.username)
+              .withPassword(configuration.password)
+              .withHostName(configuration.host)
+              .withPort(configuration.port)
+              .withConnectorClass(configuration.connectorClass.getConnector());
+
+      if (configuration.connectionProperties != null) {
+        for (String connectionProperty : configuration.connectionProperties) {
+          String[] parts = connectionProperty.split("=", -1);
+          String key = parts[0];
+          String value = parts[1];
+          connectorConfiguration.withConnectionProperty(key, value);
+        }
+      }
+
+      DebeziumIO.Read<String> readTransform =
+          DebeziumIO.readAsJson().withConnectorConfiguration(connectorConfiguration);
+
+      if (configuration.maxNumberOfRecords != null) {
+        readTransform =
+            readTransform.withMaxNumberOfRecords(configuration.maxNumberOfRecords.intValue());
+      }
+
+      return readTransform;
+    }
+  }
+}
diff --git a/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/KafkaSourceConsumerFn.java b/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/KafkaSourceConsumerFn.java
index c5a5b4f25b7..6d5658f72b0 100644
--- a/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/KafkaSourceConsumerFn.java
+++ b/sdks/java/io/debezium/src/main/java/org/apache/beam/io/debezium/KafkaSourceConsumerFn.java
@@ -77,8 +77,9 @@ public class KafkaSourceConsumerFn<T> extends DoFn<Map<String, String>, T> {
   private final Class<? extends SourceConnector> connectorClass;
   private final SourceRecordMapper<T> fn;
 
-  private static long minutesToRun = -1;
-  private static Integer maxRecords;
+  private long minutesToRun = -1;
+  private Integer maxRecords;
+
   private static DateTime startTime;
   private static final Map<String, RestrictionTracker<OffsetHolder, Map<String, Object>>>
       restrictionTrackers = new ConcurrentHashMap<>();
@@ -90,11 +91,10 @@ public class KafkaSourceConsumerFn<T> extends DoFn<Map<String, String>, T> {
    * @param fn a SourceRecordMapper
    * @param minutesToRun Maximum time to run (in minutes)
    */
-  public KafkaSourceConsumerFn(
-      Class<?> connectorClass, SourceRecordMapper<T> fn, long minutesToRun) {
+  KafkaSourceConsumerFn(Class<?> connectorClass, SourceRecordMapper<T> fn, long minutesToRun) {
     this.connectorClass = (Class<? extends SourceConnector>) connectorClass;
     this.fn = fn;
-    KafkaSourceConsumerFn.minutesToRun = minutesToRun;
+    this.minutesToRun = minutesToRun;
   }
 
   /**
@@ -103,18 +103,17 @@ public class KafkaSourceConsumerFn<T> extends DoFn<Map<String, String>, T> {
    * @param connectorClass Supported Debezium connector class
    * @param fn a SourceRecordMapper
    */
-  public KafkaSourceConsumerFn(
-      Class<?> connectorClass, SourceRecordMapper<T> fn, Integer maxRecords) {
+  KafkaSourceConsumerFn(Class<?> connectorClass, SourceRecordMapper<T> fn, Integer maxRecords) {
     this.connectorClass = (Class<? extends SourceConnector>) connectorClass;
     this.fn = fn;
-    KafkaSourceConsumerFn.maxRecords = maxRecords;
+    this.maxRecords = maxRecords;
   }
 
   @GetInitialRestriction
   public OffsetHolder getInitialRestriction(@Element Map<String, String> unused)
       throws IOException {
     KafkaSourceConsumerFn.startTime = new DateTime();
-    return new OffsetHolder(null, null, null);
+    return new OffsetHolder(null, null, null, this.maxRecords, this.minutesToRun);
   }
 
   @NewTracker
@@ -259,14 +258,27 @@ public class KafkaSourceConsumerFn<T> extends DoFn<Map<String, String>, T> {
     public final @Nullable Map<String, ?> offset;
     public final @Nullable List<?> history;
     public final @Nullable Integer fetchedRecords;
+    public final @Nullable Integer maxRecords;
+    public final long minutesToRun;
 
     OffsetHolder(
         @Nullable Map<String, ?> offset,
         @Nullable List<?> history,
-        @Nullable Integer fetchedRecords) {
+        @Nullable Integer fetchedRecords,
+        @Nullable Integer maxRecords,
+        long minutesToRun) {
       this.offset = offset;
       this.history = history == null ? new ArrayList<>() : history;
       this.fetchedRecords = fetchedRecords;
+      this.maxRecords = maxRecords;
+      this.minutesToRun = minutesToRun;
+    }
+
+    OffsetHolder(
+        @Nullable Map<String, ?> offset,
+        @Nullable List<?> history,
+        @Nullable Integer fetchedRecords) {
+      this(offset, history, fetchedRecords, null, -1);
     }
   }
 
@@ -303,19 +315,29 @@ public class KafkaSourceConsumerFn<T> extends DoFn<Map<String, String>, T> {
       long elapsedTime = System.currentTimeMillis() - startTime.getMillis();
       int fetchedRecords =
           this.restriction.fetchedRecords == null ? 0 : this.restriction.fetchedRecords + 1;
-      LOG.debug("-------------- Time running: {} / {}", elapsedTime, (minutesToRun * MILLIS));
-      this.restriction = new OffsetHolder(position, this.restriction.history, fetchedRecords);
+      LOG.debug("------------Fetched records {} / {}", fetchedRecords, this.restriction.maxRecords);
+      LOG.debug(
+          "-------------- Time running: {} / {}",
+          elapsedTime,
+          (this.restriction.minutesToRun * MILLIS));
+      this.restriction =
+          new OffsetHolder(
+              position,
+              this.restriction.history,
+              fetchedRecords,
+              this.restriction.maxRecords,
+              this.restriction.minutesToRun);
       LOG.debug("-------------- History: {}", this.restriction.history);
 
-      if (maxRecords == null && minutesToRun == -1) {
+      if (this.restriction.maxRecords == null && this.restriction.minutesToRun == -1) {
         return true;
       }
 
-      if (maxRecords != null) {
-        return fetchedRecords < maxRecords;
+      if (this.restriction.maxRecords != null) {
+        return fetchedRecords < this.restriction.maxRecords;
       }
 
-      return elapsedTime < minutesToRun * MILLIS;
+      return elapsedTime < this.restriction.minutesToRun * MILLIS;
     }
 
     @Override
diff --git a/sdks/python/apache_beam/io/debezium.py b/sdks/python/apache_beam/io/debezium.py
new file mode 100644
index 00000000000..e598b97d452
--- /dev/null
+++ b/sdks/python/apache_beam/io/debezium.py
@@ -0,0 +1,176 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+""" Unbounded source transform for
+    `Debezium <href="https://debezium.io/"/>`_.
+
+  This transform is currently supported by Beam portable
+  Flink, Spark, and Dataflow v2 runners.
+
+  **Setup**
+
+  Transform provided in this module is cross-language transform
+  implemented in the Beam Java SDK. During the pipeline construction, Python SDK
+  will connect to a Java expansion service to expand this transform.
+  To facilitate this, a small amount of setup is needed before using this
+  transform in a Beam Python pipeline.
+
+  There are several ways to setup cross-language Debezium transform.
+
+  * Option 1: use the default expansion service
+  * Option 2: specify a custom expansion service
+
+  See below for details regarding each of these options.
+
+  *Option 1: Use the default expansion service*
+
+  This is the recommended and easiest setup option for using Python Debezium
+  transform. This option requires following pre-requisites
+  before running the Beam pipeline.
+
+  * Install Java runtime in the computer from where the pipeline is constructed
+    and make sure that 'java' command is available.
+
+  In this option, Python SDK will either download (for released Beam version) or
+  build (when running from a Beam Git clone) a expansion service jar and use
+  that to expand transforms. Currently Debezium transform use the
+  'beam-sdks-java-io-debezium-expansion-service' jar for this purpose.
+
+  *Option 2: specify a custom expansion service*
+
+  In this option, you startup your own expansion service and provide that as
+  a parameter when using the transform provided in this module.
+
+  This option requires following pre-requisites before running the Beam
+  pipeline.
+
+  * Startup your own expansion service.
+  * Update your pipeline to provide the expansion service address when
+    initiating Debezium transform provided in this module.
+
+  Flink Users can use the built-in Expansion Service of the Flink Runner's
+  Job Server. If you start Flink's Job Server, the expansion service will be
+  started on port 8097. For a different address, please set the
+  expansion_service parameter.
+
+  **More information**
+
+  For more information regarding cross-language transforms see:
+  - https://beam.apache.org/roadmap/portability/
+
+  For more information specific to Flink runner see:
+  - https://beam.apache.org/documentation/runners/flink/
+"""
+
+# pytype: skip-file
+
+import json
+from enum import Enum
+from typing import List
+from typing import NamedTuple
+from typing import Optional
+
+from apache_beam.transforms import DoFn
+from apache_beam.transforms import ParDo
+from apache_beam.transforms import PTransform
+from apache_beam.transforms.external import BeamJarExpansionService
+from apache_beam.transforms.external import ExternalTransform
+from apache_beam.transforms.external import NamedTupleBasedPayloadBuilder
+
+__all__ = ['ReadFromDebezium', 'DriverClassName']
+
+
+def default_io_expansion_service():
+  return BeamJarExpansionService(
+      'sdks:java:io:debezium:expansion-service:shadowJar')
+
+
+class DriverClassName(Enum):
+  MYSQL = 'MySQL'
+  POSTGRESQL = 'PostgreSQL'
+  ORACLE = 'Oracle'
+  DB2 = 'Db2'
+
+
+ReadFromDebeziumSchema = NamedTuple(
+    'ReadFromDebeziumSchema',
+    [('connector_class', str), ('username', str), ('password', str),
+     ('host', str), ('port', str), ('max_number_of_records', Optional[int]),
+     ('connection_properties', List[str])])
+
+
+class _JsonStringToDictionaries(DoFn):
+  """ A DoFn that consumes a JSON string and yields a python dictionary """
+  def process(self, json_string):
+    obj = json.loads(json_string)
+    yield obj
+
+
+class ReadFromDebezium(PTransform):
+  """
+        An external PTransform which reads from Debezium and returns
+        a Dictionary for each item in the specified database
+        connection.
+
+        Experimental; no backwards compatibility guarantees.
+    """
+  URN = 'beam:external:java:debezium:read:v1'
+
+  def __init__(
+      self,
+      connector_class,
+      username,
+      password,
+      host,
+      port,
+      max_number_of_records=None,
+      connection_properties=None,
+      expansion_service=None):
+    """
+        Initializes a read operation from Debezium.
+
+        :param connector_class: name of the jdbc driver class
+        :param username: database username
+        :param password: database password
+        :param host: database host
+        :param port: database port
+        :param max_number_of_records: maximum number of records
+                                      to be fetched before stop.
+        :param connection_properties: properties of the debezium
+                                      connection passed as string
+                                      with format
+                                      [propertyName=property;]*
+        :param expansion_service: The address (host:port)
+                                  of the ExpansionService.
+    """
+    self.params = ReadFromDebeziumSchema(
+        connector_class=connector_class.value,
+        username=username,
+        password=password,
+        host=host,
+        port=port,
+        max_number_of_records=max_number_of_records,
+        connection_properties=connection_properties)
+    self.expansion_service = expansion_service or default_io_expansion_service()
+
+  def expand(self, pbegin):
+    return (
+        pbegin | ExternalTransform(
+            self.URN,
+            NamedTupleBasedPayloadBuilder(self.params),
+            self.expansion_service,
+        ) | ParDo(_JsonStringToDictionaries()))
diff --git a/sdks/python/apache_beam/io/external/xlang_debeziumio_it_test.py b/sdks/python/apache_beam/io/external/xlang_debeziumio_it_test.py
new file mode 100644
index 00000000000..7829baba8b6
--- /dev/null
+++ b/sdks/python/apache_beam/io/external/xlang_debeziumio_it_test.py
@@ -0,0 +1,123 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+import logging
+import unittest
+
+from apache_beam.io.debezium import DriverClassName
+from apache_beam.io.debezium import ReadFromDebezium
+from apache_beam.options.pipeline_options import StandardOptions
+from apache_beam.testing.test_pipeline import TestPipeline
+from apache_beam.testing.util import assert_that
+from apache_beam.testing.util import equal_to
+
+# pylint: disable=wrong-import-order, wrong-import-position, ungrouped-imports
+try:
+  from testcontainers.postgres import PostgresContainer
+except ImportError:
+  PostgresContainer = None
+
+NUM_RECORDS = 1
+
+
+@unittest.skipIf(
+    PostgresContainer is None, 'testcontainers package is not installed')
+@unittest.skipIf(
+    TestPipeline().get_pipeline_options().view_as(StandardOptions).runner is
+    None,
+    'Do not run this test on precommit suites.')
+class CrossLanguageDebeziumIOTest(unittest.TestCase):
+  def setUp(self):
+    self.username = 'debezium'
+    self.password = 'dbz'
+    self.database = 'inventory'
+    self.start_db_container(retries=1)
+    self.host = self.db.get_container_host_ip()
+    self.port = self.db.get_exposed_port(5432)
+    self.connector_class = DriverClassName.POSTGRESQL
+    self.connection_properties = [
+        "database.dbname=inventory",
+        "database.server.name=dbserver1",
+        "database.include.list=inventory",
+        "include.schema.changes=false"
+    ]
+
+  def tearDown(self):
+    # Sometimes stopping the container raises ReadTimeout. We can ignore it
+    # here to avoid the test failure.
+    try:
+      self.db.stop()
+    except:  # pylint: disable=bare-except
+      logging.error('Could not stop the DB container.')
+
+  def test_xlang_debezium_read(self):
+    expected_response = [{
+        "metadata": {
+            "connector": "postgresql",
+            "version": "1.3.1.Final",
+            "name": "dbserver1",
+            "database": "inventory",
+            "schema": "inventory",
+            "table": "customers"
+        },
+        "before": None,
+        "after": {
+            "fields": {
+                "last_name": "Thomas",
+                "id": 1001,
+                "first_name": "Sally",
+                "email": "sally.thomas@acme.com"
+            }
+        }
+    }]
+
+    with TestPipeline() as p:
+      p.not_use_test_runner_api = True
+      results = (
+          p
+          | 'Read from debezium' >> ReadFromDebezium(
+              username=self.username,
+              password=self.password,
+              host=self.host,
+              port=self.port,
+              max_number_of_records=NUM_RECORDS,
+              connector_class=self.connector_class,
+              connection_properties=self.connection_properties))
+      assert_that(results, equal_to(expected_response))
+
+
+# Creating a container with testcontainers sometimes raises ReadTimeout
+# error. In java there are 2 retries set by default.
+
+  def start_db_container(self, retries):
+    for i in range(retries):
+      try:
+        self.db = PostgresContainer(
+            'debezium/example-postgres:latest',
+            user=self.username,
+            password=self.password,
+            dbname=self.database)
+        self.db.start()
+        break
+      except Exception as e:  # pylint: disable=bare-except
+        if i == retries - 1:
+          logging.error('Unable to initialize DB container.')
+          raise e
+
+if __name__ == '__main__':
+  logging.getLogger().setLevel(logging.INFO)
+  unittest.main()
diff --git a/sdks/python/test-suites/portable/common.gradle b/sdks/python/test-suites/portable/common.gradle
index 949eb7716c1..e37aa2298a4 100644
--- a/sdks/python/test-suites/portable/common.gradle
+++ b/sdks/python/test-suites/portable/common.gradle
@@ -171,6 +171,7 @@ project.task("postCommitPy${pythonVersionSuffix}IT") {
           ':sdks:java:io:google-cloud-platform:expansion-service:shadowJar',
           ':sdks:java:io:kinesis:expansion-service:shadowJar',
           ':sdks:java:extensions:schemaio-expansion-service:shadowJar',
+          ':sdks:java:io:debezium:expansion-service:shadowJar'
   ]
 
   doLast {
@@ -180,6 +181,7 @@ project.task("postCommitPy${pythonVersionSuffix}IT") {
             "apache_beam.io.external.xlang_kafkaio_it_test",
             "apache_beam.io.external.xlang_kinesisio_it_test",
             "apache_beam.io.gcp.tests.xlang_spannerio_it_test",
+            "apache_beam.io.external.xlang_debeziumio_it_test",
     ]
     def testOpts = ["--tests=${tests.join(',')}"]
     def pipelineOpts = [
diff --git a/settings.gradle.kts b/settings.gradle.kts
index b929499690c..64444556565 100644
--- a/settings.gradle.kts
+++ b/settings.gradle.kts
@@ -136,6 +136,7 @@ include(":sdks:java:io:clickhouse")
 include(":sdks:java:io:common")
 include(":sdks:java:io:contextualtextio")
 include(":sdks:java:io:debezium")
+include(":sdks:java:io:debezium:expansion-service")
 include(":sdks:java:io:elasticsearch")
 include(":sdks:java:io:elasticsearch-tests:elasticsearch-tests-2")
 include(":sdks:java:io:elasticsearch-tests:elasticsearch-tests-5")
