diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkBatchTransformTranslators.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkBatchTransformTranslators.java
index 264fa4c4330..c5231468588 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkBatchTransformTranslators.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkBatchTransformTranslators.java
@@ -476,16 +476,15 @@ class FlinkBatchTransformTranslators {
     public void translateNode(
         PTransform<PCollection<KV<K, InputT>>, PCollection<KV<K, OutputT>>> transform,
         FlinkBatchTranslationContext context) {
-      DataSet<WindowedValue<KV<K, InputT>>> inputDataSet =
+      final DataSet<WindowedValue<KV<K, InputT>>> inputDataSet =
           context.getInputDataSet(context.getInput(transform));
-
-      CombineFnBase.GlobalCombineFn<InputT, AccumT, OutputT> combineFn =
-          ((Combine.PerKey) transform).getFn();
-
-      KvCoder<K, InputT> inputCoder = (KvCoder<K, InputT>) context.getInput(transform).getCoder();
-
-      Coder<AccumT> accumulatorCoder;
-
+      final Combine.PerKey<K, InputT, OutputT> combineTransform =
+          (Combine.PerKey<K, InputT, OutputT>) transform;
+      final CombineFnBase.GlobalCombineFn<InputT, AccumT, OutputT> combineFn =
+          (CombineFnBase.GlobalCombineFn<InputT, AccumT, OutputT>) combineTransform.getFn();
+      final KvCoder<K, InputT> inputCoder =
+          (KvCoder<K, InputT>) context.getInput(transform).getCoder();
+      final Coder<AccumT> accumulatorCoder;
       try {
         accumulatorCoder =
             combineFn.getAccumulatorCoder(
@@ -495,40 +494,63 @@ class FlinkBatchTransformTranslators {
         throw new RuntimeException(e);
       }
 
-      WindowingStrategy<?, ?> windowingStrategy =
-          context.getInput(transform).getWindowingStrategy();
+      final WindowingStrategy<Object, BoundedWindow> windowingStrategy =
+          (WindowingStrategy<Object, BoundedWindow>)
+              context.getInput(transform).getWindowingStrategy();
 
-      TypeInformation<WindowedValue<KV<K, AccumT>>> partialReduceTypeInfo =
+      final TypeInformation<WindowedValue<KV<K, AccumT>>> partialReduceTypeInfo =
           context.getTypeInfo(
               KvCoder.of(inputCoder.getKeyCoder(), accumulatorCoder), windowingStrategy);
 
-      Grouping<WindowedValue<KV<K, InputT>>> inputGrouping =
-          inputDataSet.groupBy(new KvKeySelector<>(inputCoder.getKeyCoder()));
+      // In case of non-merging windows, we can pre-group elements by window to make code path more
+      // efficient.
+      final boolean canGroupByWindow =
+          windowingStrategy.getWindowFn().isNonMerging()
+              && windowingStrategy.getWindowFn().windowCoder().consistentWithEquals();
+
+      final String fullName = getCurrentTransformName(context);
+
+      final UnsortedGrouping<WindowedValue<KV<K, InputT>>> inputGrouping;
+      if (canGroupByWindow) {
+        inputGrouping =
+            new FlatMapOperator<>(
+                    inputDataSet,
+                    inputDataSet.getType(),
+                    new FlinkExplodeWindowsFunction<>(),
+                    "ExplodeWindows: " + fullName)
+                .groupBy(
+                    new WindowedKvKeySelector<>(
+                        inputCoder.getKeyCoder(), windowingStrategy.getWindowFn().windowCoder()));
+      } else {
+        inputGrouping = inputDataSet.groupBy(new KvKeySelector<>(inputCoder.getKeyCoder()));
+      }
 
       // construct a map from side input to WindowingStrategy so that
       // the DoFn runner can map main-input windows to side input windows
-      Map<PCollectionView<?>, WindowingStrategy<?, ?>> sideInputStrategies = new HashMap<>();
-      for (PCollectionView<?> sideInput :
-          (List<PCollectionView<?>>) ((Combine.PerKey) transform).getSideInputs()) {
+      final Map<PCollectionView<?>, WindowingStrategy<?, ?>> sideInputStrategies = new HashMap<>();
+      for (PCollectionView<?> sideInput : combineTransform.getSideInputs()) {
         sideInputStrategies.put(sideInput, sideInput.getWindowingStrategyInternal());
       }
 
-      WindowingStrategy<Object, BoundedWindow> boundedStrategy =
-          (WindowingStrategy<Object, BoundedWindow>) windowingStrategy;
-
-      String fullName = getCurrentTransformName(context);
       if (windowingStrategy.getWindowFn().isNonMerging()) {
-
-        FlinkPartialReduceFunction<K, InputT, AccumT, ?> partialReduceFunction =
+        final FlinkPartialReduceFunction<K, InputT, AccumT, ?> partialReduceFunction =
             new FlinkPartialReduceFunction<>(
-                combineFn, boundedStrategy, sideInputStrategies, context.getPipelineOptions());
+                combineFn,
+                windowingStrategy,
+                sideInputStrategies,
+                context.getPipelineOptions(),
+                canGroupByWindow);
 
-        FlinkReduceFunction<K, AccumT, OutputT, ?> reduceFunction =
+        final FlinkReduceFunction<K, AccumT, OutputT, ?> reduceFunction =
             new FlinkReduceFunction<>(
-                combineFn, boundedStrategy, sideInputStrategies, context.getPipelineOptions());
+                combineFn,
+                windowingStrategy,
+                sideInputStrategies,
+                context.getPipelineOptions(),
+                canGroupByWindow);
 
         // Partially GroupReduce the values into the intermediate format AccumT (combine)
-        GroupCombineOperator<WindowedValue<KV<K, InputT>>, WindowedValue<KV<K, AccumT>>>
+        final GroupCombineOperator<WindowedValue<KV<K, InputT>>, WindowedValue<KV<K, AccumT>>>
             groupCombine =
                 new GroupCombineOperator<>(
                     inputGrouping,
@@ -536,21 +558,29 @@ class FlinkBatchTransformTranslators {
                     partialReduceFunction,
                     "GroupCombine: " + fullName);
 
-        transformSideInputs(((Combine.PerKey) transform).getSideInputs(), groupCombine, context);
+        transformSideInputs(combineTransform.getSideInputs(), groupCombine, context);
 
-        TypeInformation<WindowedValue<KV<K, OutputT>>> reduceTypeInfo =
+        final TypeInformation<WindowedValue<KV<K, OutputT>>> reduceTypeInfo =
             context.getTypeInfo(context.getOutput(transform));
 
-        Grouping<WindowedValue<KV<K, AccumT>>> intermediateGrouping =
-            groupCombine.groupBy(new KvKeySelector<>(inputCoder.getKeyCoder()));
+        final Grouping<WindowedValue<KV<K, AccumT>>> intermediateGrouping;
+        if (canGroupByWindow) {
+          intermediateGrouping =
+              groupCombine.groupBy(
+                  new WindowedKvKeySelector<>(
+                      inputCoder.getKeyCoder(), windowingStrategy.getWindowFn().windowCoder()));
+        } else {
+          intermediateGrouping =
+              groupCombine.groupBy(new KvKeySelector<>(inputCoder.getKeyCoder()));
+        }
 
         // Fully reduce the values and create output format OutputT
-        GroupReduceOperator<WindowedValue<KV<K, AccumT>>, WindowedValue<KV<K, OutputT>>>
+        final GroupReduceOperator<WindowedValue<KV<K, AccumT>>, WindowedValue<KV<K, OutputT>>>
             outputDataSet =
                 new GroupReduceOperator<>(
                     intermediateGrouping, reduceTypeInfo, reduceFunction, fullName);
 
-        transformSideInputs(((Combine.PerKey) transform).getSideInputs(), outputDataSet, context);
+        transformSideInputs(combineTransform.getSideInputs(), outputDataSet, context);
 
         context.setOutputDataSet(context.getOutput(transform), outputDataSet);
 
@@ -559,23 +589,26 @@ class FlinkBatchTransformTranslators {
         // for merging windows we can't to a pre-shuffle combine step since
         // elements would not be in their correct windows for side-input access
 
-        RichGroupReduceFunction<WindowedValue<KV<K, InputT>>, WindowedValue<KV<K, OutputT>>>
+        final RichGroupReduceFunction<WindowedValue<KV<K, InputT>>, WindowedValue<KV<K, OutputT>>>
             reduceFunction =
                 new FlinkMergingNonShuffleReduceFunction<>(
-                    combineFn, boundedStrategy, sideInputStrategies, context.getPipelineOptions());
+                    combineFn,
+                    windowingStrategy,
+                    sideInputStrategies,
+                    context.getPipelineOptions());
 
-        TypeInformation<WindowedValue<KV<K, OutputT>>> reduceTypeInfo =
+        final TypeInformation<WindowedValue<KV<K, OutputT>>> reduceTypeInfo =
             context.getTypeInfo(context.getOutput(transform));
 
-        Grouping<WindowedValue<KV<K, InputT>>> grouping =
+        final Grouping<WindowedValue<KV<K, InputT>>> grouping =
             inputDataSet.groupBy(new KvKeySelector<>(inputCoder.getKeyCoder()));
 
         // Fully reduce the values and create output format OutputT
-        GroupReduceOperator<WindowedValue<KV<K, InputT>>, WindowedValue<KV<K, OutputT>>>
+        final GroupReduceOperator<WindowedValue<KV<K, InputT>>, WindowedValue<KV<K, OutputT>>>
             outputDataSet =
                 new GroupReduceOperator<>(grouping, reduceTypeInfo, reduceFunction, fullName);
 
-        transformSideInputs(((Combine.PerKey) transform).getSideInputs(), outputDataSet, context);
+        transformSideInputs(combineTransform.getSideInputs(), outputDataSet, context);
 
         context.setOutputDataSet(context.getOutput(transform), outputDataSet);
       }
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkPartialReduceFunction.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkPartialReduceFunction.java
index b0733048316..b7a694a1c7e 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkPartialReduceFunction.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkPartialReduceFunction.java
@@ -52,16 +52,28 @@ public class FlinkPartialReduceFunction<K, InputT, AccumT, W extends BoundedWind
   // TODO: Remove side input functionality since liftable Combines no longer have side inputs.
   protected final Map<PCollectionView<?>, WindowingStrategy<?, ?>> sideInputs;
 
+  /** WindowedValues has been exploded and pre-grouped by window. */
+  private final boolean groupedByWindow;
+
   public FlinkPartialReduceFunction(
       CombineFnBase.GlobalCombineFn<InputT, AccumT, ?> combineFn,
       WindowingStrategy<Object, W> windowingStrategy,
       Map<PCollectionView<?>, WindowingStrategy<?, ?>> sideInputs,
       PipelineOptions pipelineOptions) {
+    this(combineFn, windowingStrategy, sideInputs, pipelineOptions, false);
+  }
 
+  public FlinkPartialReduceFunction(
+      CombineFnBase.GlobalCombineFn<InputT, AccumT, ?> combineFn,
+      WindowingStrategy<Object, W> windowingStrategy,
+      Map<PCollectionView<?>, WindowingStrategy<?, ?>> sideInputs,
+      PipelineOptions pipelineOptions,
+      boolean groupedByWindow) {
     this.combineFn = combineFn;
     this.windowingStrategy = windowingStrategy;
     this.sideInputs = sideInputs;
     this.serializedOptions = new SerializablePipelineOptions(pipelineOptions);
+    this.groupedByWindow = groupedByWindow;
   }
 
   @Override
@@ -83,11 +95,15 @@ public class FlinkPartialReduceFunction<K, InputT, AccumT, W extends BoundedWind
 
     AbstractFlinkCombineRunner<K, InputT, AccumT, AccumT, W> reduceRunner;
 
-    if (!windowingStrategy.getWindowFn().isNonMerging()
-        && !windowingStrategy.getWindowFn().windowCoder().equals(IntervalWindow.getCoder())) {
-      reduceRunner = new HashingFlinkCombineRunner<>();
+    if (groupedByWindow) {
+      reduceRunner = new SingleWindowFlinkCombineRunner<>();
     } else {
-      reduceRunner = new SortingFlinkCombineRunner<>();
+      if (!windowingStrategy.getWindowFn().isNonMerging()
+          && !windowingStrategy.getWindowFn().windowCoder().equals(IntervalWindow.getCoder())) {
+        reduceRunner = new HashingFlinkCombineRunner<>();
+      } else {
+        reduceRunner = new SortingFlinkCombineRunner<>();
+      }
     }
 
     reduceRunner.combine(
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkReduceFunction.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkReduceFunction.java
index 8ebf63cbcb9..b7a15ac82e2 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkReduceFunction.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkReduceFunction.java
@@ -52,18 +52,28 @@ public class FlinkReduceFunction<K, AccumT, OutputT, W extends BoundedWindow>
 
   protected final SerializablePipelineOptions serializedOptions;
 
+  /** WindowedValues has been exploded and pre-grouped by window. */
+  private final boolean groupedByWindow;
+
   public FlinkReduceFunction(
       CombineFnBase.GlobalCombineFn<?, AccumT, OutputT> combineFn,
       WindowingStrategy<Object, W> windowingStrategy,
       Map<PCollectionView<?>, WindowingStrategy<?, ?>> sideInputs,
       PipelineOptions pipelineOptions) {
+    this(combineFn, windowingStrategy, sideInputs, pipelineOptions, false);
+  }
 
+  public FlinkReduceFunction(
+      CombineFnBase.GlobalCombineFn<?, AccumT, OutputT> combineFn,
+      WindowingStrategy<Object, W> windowingStrategy,
+      Map<PCollectionView<?>, WindowingStrategy<?, ?>> sideInputs,
+      PipelineOptions pipelineOptions,
+      boolean groupedByWindow) {
     this.combineFn = combineFn;
-
     this.windowingStrategy = windowingStrategy;
     this.sideInputs = sideInputs;
-
     this.serializedOptions = new SerializablePipelineOptions(pipelineOptions);
+    this.groupedByWindow = groupedByWindow;
   }
 
   @Override
@@ -85,12 +95,17 @@ public class FlinkReduceFunction<K, AccumT, OutputT, W extends BoundedWindow>
 
     AbstractFlinkCombineRunner<K, AccumT, AccumT, OutputT, W> reduceRunner;
 
-    if (!windowingStrategy.getWindowFn().isNonMerging()
-        && !windowingStrategy.getWindowFn().windowCoder().equals(IntervalWindow.getCoder())) {
-      reduceRunner = new HashingFlinkCombineRunner<>();
+    if (groupedByWindow) {
+      reduceRunner = new SingleWindowFlinkCombineRunner<>();
     } else {
-      reduceRunner = new SortingFlinkCombineRunner<>();
+      if (!windowingStrategy.getWindowFn().isNonMerging()
+          && !windowingStrategy.getWindowFn().windowCoder().equals(IntervalWindow.getCoder())) {
+        reduceRunner = new HashingFlinkCombineRunner<>();
+      } else {
+        reduceRunner = new SortingFlinkCombineRunner<>();
+      }
     }
+
     reduceRunner.combine(
         new AbstractFlinkCombineRunner.FinalFlinkCombiner<>(combineFn),
         windowingStrategy,
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/SingleWindowFlinkCombineRunner.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/SingleWindowFlinkCombineRunner.java
new file mode 100644
index 00000000000..976ba355ae6
--- /dev/null
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/SingleWindowFlinkCombineRunner.java
@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.runners.flink.translation.functions;
+
+import java.util.Collections;
+import java.util.Objects;
+import org.apache.beam.runners.core.SideInputReader;
+import org.apache.beam.sdk.options.PipelineOptions;
+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;
+import org.apache.beam.sdk.transforms.windowing.PaneInfo;
+import org.apache.beam.sdk.transforms.windowing.TimestampCombiner;
+import org.apache.beam.sdk.transforms.windowing.WindowFn;
+import org.apache.beam.sdk.util.WindowedValue;
+import org.apache.beam.sdk.values.KV;
+import org.apache.beam.sdk.values.WindowingStrategy;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterators;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.PeekingIterator;
+import org.apache.flink.api.java.tuple.Tuple2;
+import org.apache.flink.util.Collector;
+import org.joda.time.Instant;
+
+/**
+ * A Flink combine runner takes elements pre-grouped by window and produces output after seeing all
+ * input.
+ */
+public class SingleWindowFlinkCombineRunner<K, InputT, AccumT, OutputT, W extends BoundedWindow>
+    extends AbstractFlinkCombineRunner<K, InputT, AccumT, OutputT, W> {
+
+  @Override
+  public void combine(
+      FlinkCombiner<K, InputT, AccumT, OutputT> flinkCombiner,
+      WindowingStrategy<Object, W> windowingStrategy,
+      SideInputReader sideInputReader,
+      PipelineOptions options,
+      Iterable<WindowedValue<KV<K, InputT>>> elements,
+      Collector<WindowedValue<KV<K, OutputT>>> out) {
+    final TimestampCombiner timestampCombiner = windowingStrategy.getTimestampCombiner();
+    final WindowFn<Object, W> windowFn = windowingStrategy.getWindowFn();
+    final PeekingIterator<WindowedValue<KV<K, InputT>>> iterator =
+        Iterators.peekingIterator(elements.iterator());
+
+    @SuppressWarnings("unchecked")
+    final W currentWindow = (W) Iterables.getOnlyElement(iterator.peek().getWindows());
+    final K key = iterator.peek().getValue().getKey();
+
+    Tuple2<AccumT, Instant> combinedState = null;
+    while (iterator.hasNext()) {
+      final WindowedValue<KV<K, InputT>> currentValue = iterator.next();
+      Preconditions.checkState(
+          currentWindow.equals(Iterables.getOnlyElement(currentValue.getWindows())),
+          "Incompatible windows.");
+      if (combinedState == null) {
+        AccumT accumT =
+            flinkCombiner.firstInput(
+                key,
+                currentValue.getValue().getValue(),
+                options,
+                sideInputReader,
+                Collections.singleton(currentWindow));
+        Instant windowTimestamp =
+            timestampCombiner.assign(
+                currentWindow, windowFn.getOutputTime(currentValue.getTimestamp(), currentWindow));
+        combinedState = new Tuple2<>(accumT, windowTimestamp);
+      } else {
+        combinedState.f0 =
+            flinkCombiner.addInput(
+                key,
+                combinedState.f0,
+                currentValue.getValue().getValue(),
+                options,
+                sideInputReader,
+                Collections.singleton(currentWindow));
+        combinedState.f1 =
+            timestampCombiner.combine(
+                combinedState.f1,
+                timestampCombiner.assign(
+                    currentWindow,
+                    windowingStrategy
+                        .getWindowFn()
+                        .getOutputTime(currentValue.getTimestamp(), currentWindow)));
+      }
+    }
+
+    // Output the final value of combiners.
+    Objects.requireNonNull(combinedState);
+    final AccumT accumulator = combinedState.f0;
+    final Instant windowTimestamp = combinedState.f1;
+    out.collect(
+        WindowedValue.of(
+            KV.of(
+                key,
+                flinkCombiner.extractOutput(
+                    key,
+                    accumulator,
+                    options,
+                    sideInputReader,
+                    Collections.singleton(currentWindow))),
+            windowTimestamp,
+            currentWindow,
+            PaneInfo.NO_FIRING));
+  }
+}
