diff --git a/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/MultiDoFnFunction.java b/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/MultiDoFnFunction.java
index 661e23e7b6d..4db6858c322 100644
--- a/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/MultiDoFnFunction.java
+++ b/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/MultiDoFnFunction.java
@@ -22,10 +22,13 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.NoSuchElementException;
+import java.util.UUID;
+import java.util.WeakHashMap;
 import org.apache.beam.runners.core.DoFnRunner;
 import org.apache.beam.runners.core.DoFnRunners;
 import org.apache.beam.runners.core.InMemoryStateInternals;
 import org.apache.beam.runners.core.InMemoryTimerInternals;
+import org.apache.beam.runners.core.SideInputReader;
 import org.apache.beam.runners.core.StateInternals;
 import org.apache.beam.runners.core.StepContext;
 import org.apache.beam.runners.core.TimerInternals;
@@ -49,6 +52,8 @@ import org.apache.beam.vendor.guava.v20_0.com.google.common.collect.LinkedListMu
 import org.apache.beam.vendor.guava.v20_0.com.google.common.collect.Multimap;
 import org.apache.spark.Accumulator;
 import org.apache.spark.api.java.function.PairFlatMapFunction;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import scala.Tuple2;
 
 /**
@@ -61,6 +66,17 @@ import scala.Tuple2;
 public class MultiDoFnFunction<InputT, OutputT>
     implements PairFlatMapFunction<Iterator<WindowedValue<InputT>>, TupleTag<?>, WindowedValue<?>> {
 
+  private static final Logger LOG = LoggerFactory.getLogger(MultiDoFnFunction.class);
+
+  /** JVM wide side input cache. */
+  private static final Map<String, CachedSideInputReader> sideInputReaders =
+      Collections.synchronizedMap(new WeakHashMap<>());
+
+  /**
+   * Id that is consistent among executors. We can not use stepName because of possible collisions.
+   */
+  private final String uniqueId = UUID.randomUUID().toString();
+
   private final Accumulator<MetricsContainerStepMap> metricsAccum;
   private final String stepName;
   private final DoFn<InputT, OutputT> doFn;
@@ -150,11 +166,19 @@ public class MultiDoFnFunction<InputT, OutputT>
       context = new SparkProcessContext.NoOpStepContext();
     }
 
+    final SideInputReader sideInputReader =
+        sideInputReaders.computeIfAbsent(
+            uniqueId,
+            key -> {
+              LOG.info("Creating a new side input reader for [{}] with id [{}].", stepName, key);
+              return CachedSideInputReader.of(new SparkSideInputReader(sideInputs));
+            });
+
     final DoFnRunner<InputT, OutputT> doFnRunner =
         DoFnRunners.simpleRunner(
             options.get(),
             doFn,
-            CachedSideInputReader.of(new SparkSideInputReader(sideInputs)),
+            sideInputReader,
             outputManager,
             mainOutputTag,
             additionalOutputTags,
diff --git a/runners/spark/src/main/java/org/apache/beam/runners/spark/util/CachedSideInputReader.java b/runners/spark/src/main/java/org/apache/beam/runners/spark/util/CachedSideInputReader.java
index 49200c6c4b4..bfa87326956 100644
--- a/runners/spark/src/main/java/org/apache/beam/runners/spark/util/CachedSideInputReader.java
+++ b/runners/spark/src/main/java/org/apache/beam/runners/spark/util/CachedSideInputReader.java
@@ -24,10 +24,15 @@ import javax.annotation.Nullable;
 import org.apache.beam.runners.core.SideInputReader;
 import org.apache.beam.sdk.transforms.windowing.BoundedWindow;
 import org.apache.beam.sdk.values.PCollectionView;
+import org.apache.spark.util.SizeEstimator;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 /** {@link SideInputReader} that caches materialized views. */
 public class CachedSideInputReader implements SideInputReader {
 
+  private static final Logger LOG = LoggerFactory.getLogger(CachedSideInputReader.class);
+
   /**
    * Create a new cached {@link SideInputReader}.
    *
@@ -88,7 +93,14 @@ public class CachedSideInputReader implements SideInputReader {
     @SuppressWarnings("unchecked")
     final Map<Key<T>, T> materializedCasted = (Map) materialized;
     return materializedCasted.computeIfAbsent(
-        new Key<>(view, window), key -> delegate.get(view, window));
+        new Key<>(view, window),
+        key -> {
+          final T result = delegate.get(view, window);
+          LOG.info(
+              "Caching de-serialized side input of size [{}B] in memory.",
+              SizeEstimator.estimate(result));
+          return result;
+        });
   }
 
   @Override
