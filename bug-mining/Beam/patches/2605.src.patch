diff --git a/sdks/java/io/amazon-web-services2/src/main/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIO.java b/sdks/java/io/amazon-web-services2/src/main/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIO.java
index e483f2ce340..c35f90b6a80 100644
--- a/sdks/java/io/amazon-web-services2/src/main/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIO.java
+++ b/sdks/java/io/amazon-web-services2/src/main/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIO.java
@@ -128,10 +128,12 @@ import software.amazon.awssdk.services.dynamodb.model.WriteRequest;
  *       writeRequest>
  * </ul>
  *
- * If primary keys could repeat in your stream (i.e. an upsert stream), you could encounter a
- * ValidationError, as AWS does not allow writing duplicate keys within a single batch operation.
- * For such use cases, you can explicitly set the key names corresponding to the primary key to be
- * deduplicated using the withDeduplicateKeys method
+ * <b>Note:</b> AWS does not allow writing duplicate keys within a single batch operation. If
+ * primary keys possibly repeat in your stream (i.e. an upsert stream), you may encounter a
+ * `ValidationError`. To address this you have to provide the key names corresponding to your
+ * primary key using {@link Write#withDeduplicateKeys(List)}. Based on these keys only the last
+ * observed element is kept. Nevertheless, if no deduplication keys are provided, identical elements
+ * are still deduplicated.
  */
 @Experimental(Kind.SOURCE_SINK)
 @SuppressWarnings({
@@ -306,6 +308,8 @@ public final class DynamoDBIO {
    */
   @AutoValue
   public abstract static class RetryConfiguration implements Serializable {
+    private static final Duration DEFAULT_INITIAL_DURATION = Duration.standardSeconds(5);
+
     @VisibleForTesting
     static final RetryPredicate DEFAULT_RETRY_PREDICATE = new DefaultRetryPredicate();
 
@@ -313,13 +317,16 @@ public final class DynamoDBIO {
 
     abstract Duration getMaxDuration();
 
+    abstract Duration getInitialDuration();
+
     abstract RetryPredicate getRetryPredicate();
 
     abstract Builder toBuilder();
 
     public static Builder builder() {
       return new AutoValue_DynamoDBIO_RetryConfiguration.Builder()
-          .setRetryPredicate(DEFAULT_RETRY_PREDICATE);
+          .setRetryPredicate(DEFAULT_RETRY_PREDICATE)
+          .setInitialDuration(DEFAULT_INITIAL_DURATION);
     }
 
     @AutoValue.Builder
@@ -328,6 +335,8 @@ public final class DynamoDBIO {
 
       public abstract Builder setMaxDuration(Duration maxDuration);
 
+      abstract Builder setInitialDuration(Duration initialDuration);
+
       abstract Builder setRetryPredicate(RetryPredicate retryPredicate);
 
       abstract RetryConfiguration autoBuild();
@@ -339,6 +348,11 @@ public final class DynamoDBIO {
             configuration.getMaxDuration() != null
                 && configuration.getMaxDuration().isLongerThan(Duration.ZERO),
             "maxDuration should be greater than 0");
+
+        checkArgument(
+            configuration.getInitialDuration() != null
+                && configuration.getInitialDuration().isLongerThan(Duration.ZERO),
+            "initialDuration should be greater than 0");
         return configuration;
       }
     }
@@ -456,7 +470,6 @@ public final class DynamoDBIO {
       @VisibleForTesting
       static final String RETRY_ATTEMPT_LOG = "Error writing to DynamoDB. Retry attempt[%d]";
 
-      private static final Duration RETRY_INITIAL_BACKOFF = Duration.standardSeconds(5);
       private transient FluentBackoff retryBackoff; // defaults to no retries
       private static final Logger LOG = LoggerFactory.getLogger(WriteFn.class);
       private static final Counter DYNAMO_DB_WRITE_FAILURES =
@@ -474,14 +487,12 @@ public final class DynamoDBIO {
       @Setup
       public void setup() {
         client = spec.getDynamoDbClientProvider().getDynamoDbClient();
-        retryBackoff =
-            FluentBackoff.DEFAULT
-                .withMaxRetries(0) // default to no retrying
-                .withInitialBackoff(RETRY_INITIAL_BACKOFF);
+        retryBackoff = FluentBackoff.DEFAULT.withMaxRetries(0); // default to no retrying
         if (spec.getRetryConfiguration() != null) {
           retryBackoff =
               retryBackoff
                   .withMaxRetries(spec.getRetryConfiguration().getMaxAttempts() - 1)
+                  .withInitialBackoff(spec.getRetryConfiguration().getInitialDuration())
                   .withMaxCumulativeBackoff(spec.getRetryConfiguration().getMaxDuration());
         }
       }
@@ -504,17 +515,22 @@ public final class DynamoDBIO {
       }
 
       private Map<String, AttributeValue> extractDeduplicateKeyValues(WriteRequest request) {
+        List<String> deduplicationKeys = spec.getDeduplicateKeys();
+        Map<String, AttributeValue> attributes = Collections.emptyMap();
+
         if (request.putRequest() != null) {
-          return request.putRequest().item().entrySet().stream()
-              .filter(entry -> spec.getDeduplicateKeys().contains(entry.getKey()))
-              .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
+          attributes = request.putRequest().item();
         } else if (request.deleteRequest() != null) {
-          return request.deleteRequest().key().entrySet().stream()
-              .filter(entry -> spec.getDeduplicateKeys().contains(entry.getKey()))
-              .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
-        } else {
-          return Collections.emptyMap();
+          attributes = request.deleteRequest().key();
+        }
+
+        if (attributes.isEmpty() || deduplicationKeys.isEmpty()) {
+          return attributes;
         }
+
+        return attributes.entrySet().stream()
+            .filter(entry -> deduplicationKeys.contains(entry.getKey()))
+            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
       }
 
       @FinishBundle
diff --git a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOReadTest.java b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOReadTest.java
new file mode 100644
index 00000000000..2a29c612267
--- /dev/null
+++ b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOReadTest.java
@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.sdk.io.aws2.dynamodb;
+
+import static java.lang.Math.min;
+import static java.util.stream.Collectors.toList;
+import static java.util.stream.IntStream.range;
+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables.getLast;
+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists.newArrayList;
+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists.transform;
+import static org.mockito.ArgumentMatchers.argThat;
+import static org.mockito.Mockito.when;
+
+import java.util.Arrays;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.IntStream;
+import org.apache.beam.sdk.testing.PAssert;
+import org.apache.beam.sdk.testing.TestPipeline;
+import org.apache.beam.sdk.transforms.Count;
+import org.apache.beam.sdk.transforms.Flatten;
+import org.apache.beam.sdk.values.PCollection;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.ExpectedException;
+import org.junit.runner.RunWith;
+import org.mockito.ArgumentMatcher;
+import org.mockito.Mock;
+import org.mockito.junit.MockitoJUnitRunner;
+import software.amazon.awssdk.services.dynamodb.DynamoDbClient;
+import software.amazon.awssdk.services.dynamodb.model.AttributeValue;
+import software.amazon.awssdk.services.dynamodb.model.ScanRequest;
+import software.amazon.awssdk.services.dynamodb.model.ScanResponse;
+
+@RunWith(MockitoJUnitRunner.class)
+public class DynamoDBIOReadTest {
+  private static final String tableName = "Test";
+
+  @Rule public final TestPipeline pipeline = TestPipeline.create();
+  @Rule public final ExpectedException thrown = ExpectedException.none();
+  @Mock public DynamoDbClient client;
+
+  @Test
+  public void testReadOneSegment() {
+    MockData mockData = new MockData(range(0, 10));
+    mockData.mockScan(10, client); // 1 scan iteration
+
+    PCollection<List<Map<String, AttributeValue>>> actual =
+        pipeline.apply(
+            DynamoDBIO.<List<Map<String, AttributeValue>>>read()
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client))
+                .withScanRequestFn(
+                    in -> ScanRequest.builder().tableName(tableName).totalSegments(1).build())
+                .items());
+
+    PAssert.that(actual.apply(Count.globally())).containsInAnyOrder(1L);
+    PAssert.that(actual).containsInAnyOrder(mockData.getAllItems());
+
+    pipeline.run().waitUntilFinish();
+  }
+
+  @Test
+  public void testReadThreeSegments() {
+    MockData mockData = new MockData(range(0, 10), range(10, 20), range(20, 30));
+    mockData.mockScan(10, client); // 1 scan iteration per segment
+
+    PCollection<List<Map<String, AttributeValue>>> actual =
+        pipeline.apply(
+            DynamoDBIO.<List<Map<String, AttributeValue>>>read()
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client))
+                .withScanRequestFn(
+                    in -> ScanRequest.builder().tableName(tableName).totalSegments(3).build())
+                .items());
+
+    PAssert.that(actual.apply(Count.globally())).containsInAnyOrder(3L);
+    PAssert.that(actual.apply(Flatten.iterables())).containsInAnyOrder(mockData.getAllItems());
+
+    pipeline.run().waitUntilFinish();
+  }
+
+  @Test
+  public void testReadWithStartKey() {
+    MockData mockData = new MockData(range(0, 10), range(20, 32));
+    mockData.mockScan(5, client); // 2 + 3 scan iterations
+
+    PCollection<List<Map<String, AttributeValue>>> actual =
+        pipeline.apply(
+            DynamoDBIO.<List<Map<String, AttributeValue>>>read()
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client))
+                .withScanRequestFn(
+                    in -> ScanRequest.builder().tableName(tableName).totalSegments(2).build())
+                .items());
+
+    PAssert.that(actual.apply(Count.globally())).containsInAnyOrder(5L);
+    PAssert.that(actual.apply(Flatten.iterables())).containsInAnyOrder(mockData.getAllItems());
+
+    pipeline.run().waitUntilFinish();
+  }
+
+  @Test
+  public void testReadMissingScanRequestFn() {
+    pipeline.enableAbandonedNodeEnforcement(false);
+    thrown.expect(IllegalArgumentException.class);
+    thrown.expectMessage("withScanRequestFn() is required");
+
+    pipeline.apply(
+        DynamoDBIO.read().withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client)));
+  }
+
+  @Test
+  public void testReadMissingDynamoDbClientProvider() {
+    pipeline.enableAbandonedNodeEnforcement(false);
+    thrown.expect(IllegalArgumentException.class);
+    thrown.expectMessage("withDynamoDbClientProvider() is required");
+
+    pipeline.apply(DynamoDBIO.read().withScanRequestFn(in -> ScanRequest.builder().build()));
+  }
+
+  @Test
+  public void testReadMissingTotalSegments() {
+    pipeline.enableAbandonedNodeEnforcement(false);
+    thrown.expect(IllegalArgumentException.class);
+    thrown.expectMessage("TotalSegments is required with withScanRequestFn() and greater zero");
+
+    pipeline.apply(
+        DynamoDBIO.read()
+            .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client))
+            .withScanRequestFn(in -> ScanRequest.builder().build()));
+  }
+
+  @Test
+  public void testReadInvalidTotalSegments() {
+    pipeline.enableAbandonedNodeEnforcement(false);
+    thrown.expect(IllegalArgumentException.class);
+    thrown.expectMessage("TotalSegments is required with withScanRequestFn() and greater zero");
+
+    pipeline.apply(
+        DynamoDBIO.read()
+            .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client))
+            .withScanRequestFn(in -> ScanRequest.builder().totalSegments(0).build()));
+  }
+
+  private static class MockData {
+    private final List<List<Integer>> data;
+
+    MockData(IntStream... segments) {
+      data = Arrays.stream(segments).map(ids -> newArrayList(ids.iterator())).collect(toList());
+    }
+
+    List<Map<String, AttributeValue>> getAllItems() {
+      return data.stream().flatMap(ids -> ids.stream()).map(id -> item(id)).collect(toList());
+    }
+
+    void mockScan(int sizeLimit, DynamoDbClient mock) {
+      for (int segment = 0; segment < data.size(); segment++) {
+        List<Integer> ids = data.get(segment);
+
+        List<Map<String, AttributeValue>> items = null;
+        Map<String, AttributeValue> startKey, lastKey;
+        for (int start = 0; start < ids.size(); start += sizeLimit) {
+          startKey = items != null ? getLast(items) : ImmutableMap.of();
+          items = transform(ids.subList(start, min(ids.size(), start + sizeLimit)), id -> item(id));
+          lastKey = start + sizeLimit < ids.size() ? getLast(items) : ImmutableMap.of();
+
+          when(mock.scan(argThat(matchesScanRequest(segment, startKey))))
+              .thenReturn(ScanResponse.builder().items(items).lastEvaluatedKey(lastKey).build());
+        }
+      }
+    }
+
+    ArgumentMatcher<ScanRequest> matchesScanRequest(
+        Integer segment, Map<String, AttributeValue> startKey) {
+      return req ->
+          req != null && segment.equals(req.segment()) && startKey.equals(req.exclusiveStartKey());
+    }
+  }
+
+  private static Map<String, AttributeValue> item(int id) {
+    return ImmutableMap.of(
+        "rangeKey", AttributeValue.builder().n(String.valueOf(id)).build(),
+        "hashKey", AttributeValue.builder().s(String.valueOf(id)).build());
+  }
+}
diff --git a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOTest.java b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOTest.java
index 6567d54544a..b184c7f0eae 100644
--- a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOTest.java
+++ b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOTest.java
@@ -21,6 +21,7 @@ import static org.apache.beam.sdk.io.aws2.dynamodb.DynamoDBIO.RetryConfiguration
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 
+import java.io.IOException;
 import java.io.Serializable;
 import java.util.Arrays;
 import java.util.HashSet;
@@ -64,7 +65,10 @@ import software.amazon.awssdk.services.dynamodb.model.WriteRequest;
 /** Test Coverage for the IO. */
 public class DynamoDBIOTest implements Serializable {
   @Rule public final transient TestPipeline pipeline = TestPipeline.create();
-  @Rule public final transient ExpectedLogs expectedLogs = ExpectedLogs.none(DynamoDBIO.class);
+
+  @Rule
+  public final transient ExpectedLogs writeFnLogs =
+      ExpectedLogs.none(DynamoDBIO.Write.WriteFn.class);
 
   private static final String tableName = "TaskA";
   private static final int numOfItems = 10;
@@ -99,11 +103,9 @@ public class DynamoDBIOTest implements Serializable {
         pipeline.apply(
             DynamoDBIO.<List<Map<String, AttributeValue>>>read()
                 .withDynamoDbClientProvider(
-                    DynamoDbClientProviderMock.of(DynamoDBIOTestHelper.getDynamoDBClient()))
+                    StaticDynamoDBClientProvider.of(DynamoDBIOTestHelper.getDynamoDBClient()))
                 .withScanRequestFn(
-                    (SerializableFunction<Void, ScanRequest>)
-                        input ->
-                            ScanRequest.builder().tableName(tableName).totalSegments(1).build())
+                    input -> ScanRequest.builder().tableName(tableName).totalSegments(1).build())
                 .items());
     PAssert.that(actual).containsInAnyOrder(expected);
     pipeline.run().waitUntilFinish();
@@ -117,7 +119,7 @@ public class DynamoDBIOTest implements Serializable {
             .apply(
                 DynamoDBIO.<List<Map<String, AttributeValue>>>read()
                     .withDynamoDbClientProvider(
-                        DynamoDbClientProviderMock.of(DynamoDBIOTestHelper.getDynamoDBClient()))
+                        StaticDynamoDBClientProvider.of(DynamoDBIOTestHelper.getDynamoDBClient()))
                     .withScanRequestFn(
                         (SerializableFunction<Void, ScanRequest>)
                             input ->
@@ -156,7 +158,7 @@ public class DynamoDBIOTest implements Serializable {
             .apply(
                 DynamoDBIO.<List<Map<String, AttributeValue>>>read()
                     .withDynamoDbClientProvider(
-                        DynamoDbClientProviderMock.of(DynamoDBIOTestHelper.getDynamoDBClient()))
+                        StaticDynamoDBClientProvider.of(DynamoDBIOTestHelper.getDynamoDBClient()))
                     .withScanRequestFn(
                         (SerializableFunction<Void, ScanRequest>)
                             input ->
@@ -178,7 +180,7 @@ public class DynamoDBIOTest implements Serializable {
     pipeline.apply(
         DynamoDBIO.read()
             .withDynamoDbClientProvider(
-                DynamoDbClientProviderMock.of(DynamoDBIOTestHelper.getDynamoDBClient())));
+                StaticDynamoDBClientProvider.of(DynamoDBIOTestHelper.getDynamoDBClient())));
     try {
       pipeline.run().waitUntilFinish();
       fail("withScanRequestFn() is required");
@@ -212,7 +214,7 @@ public class DynamoDBIOTest implements Serializable {
                 (SerializableFunction<Void, ScanRequest>)
                     input -> ScanRequest.builder().tableName(tableName).build())
             .withDynamoDbClientProvider(
-                DynamoDbClientProviderMock.of(DynamoDBIOTestHelper.getDynamoDBClient())));
+                StaticDynamoDBClientProvider.of(DynamoDBIOTestHelper.getDynamoDBClient())));
     try {
       pipeline.run().waitUntilFinish();
       fail("TotalSegments is required with withScanRequestFn()");
@@ -230,7 +232,7 @@ public class DynamoDBIOTest implements Serializable {
                 (SerializableFunction<Void, ScanRequest>)
                     input -> ScanRequest.builder().tableName(tableName).totalSegments(-1).build())
             .withDynamoDbClientProvider(
-                DynamoDbClientProviderMock.of(DynamoDBIOTestHelper.getDynamoDBClient())));
+                StaticDynamoDBClientProvider.of(DynamoDBIOTestHelper.getDynamoDBClient())));
     try {
       pipeline.run().waitUntilFinish();
       fail("withTotalSegments() is expected and greater than zero");
@@ -275,7 +277,7 @@ public class DynamoDBIOTest implements Serializable {
                             .setRetryPredicate(DEFAULT_RETRY_PREDICATE)
                             .build())
                     .withDynamoDbClientProvider(
-                        DynamoDbClientProviderMock.of(DynamoDBIOTestHelper.getDynamoDBClient())));
+                        StaticDynamoDBClientProvider.of(DynamoDBIOTestHelper.getDynamoDBClient())));
 
     final PCollection<Long> publishedResultsSize = output.apply(Count.globally());
     PAssert.that(publishedResultsSize).containsInAnyOrder(0L);
@@ -291,7 +293,9 @@ public class DynamoDBIOTest implements Serializable {
 
   @Test
   public void testRetries() throws Throwable {
+    thrown.expect(IOException.class);
     thrown.expectMessage("Error writing to DynamoDB");
+    thrown.expectMessage("No more attempts allowed");
 
     List<KV<String, Integer>> items =
         ImmutableList.of(KV.of("test1", 111), KV.of("test2", 222), KV.of("test3", 333));
@@ -324,21 +328,21 @@ public class DynamoDBIOTest implements Serializable {
                 .withRetryConfiguration(
                     DynamoDBIO.RetryConfiguration.builder()
                         .setMaxAttempts(4)
+                        .setInitialDuration(Duration.millis(1))
                         .setMaxDuration(Duration.standardSeconds(10))
                         .setRetryPredicate(DEFAULT_RETRY_PREDICATE)
                         .build())
-                .withDynamoDbClientProvider(DynamoDbClientProviderMock.of(amazonDynamoDBMock)));
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(amazonDynamoDBMock)));
 
     try {
       pipeline.run().waitUntilFinish();
     } catch (final Pipeline.PipelineExecutionException e) {
       // check 3 retries were initiated by inspecting the log before passing on the exception
-      expectedLogs.verifyWarn(String.format(DynamoDBIO.Write.WriteFn.RETRY_ATTEMPT_LOG, 1));
-      expectedLogs.verifyWarn(String.format(DynamoDBIO.Write.WriteFn.RETRY_ATTEMPT_LOG, 2));
-      expectedLogs.verifyWarn(String.format(DynamoDBIO.Write.WriteFn.RETRY_ATTEMPT_LOG, 3));
+      writeFnLogs.verifyWarn(String.format(DynamoDBIO.Write.WriteFn.RETRY_ATTEMPT_LOG, 1));
+      writeFnLogs.verifyWarn(String.format(DynamoDBIO.Write.WriteFn.RETRY_ATTEMPT_LOG, 2));
+      writeFnLogs.verifyWarn(String.format(DynamoDBIO.Write.WriteFn.RETRY_ATTEMPT_LOG, 3));
       throw e.getCause();
     }
-    fail("Pipeline is expected to fail because we were unable to write to DynamoDb.");
   }
 
   /**
@@ -393,7 +397,7 @@ public class DynamoDBIOTest implements Serializable {
                         .setMaxDuration(Duration.standardMinutes(1))
                         .setRetryPredicate(DEFAULT_RETRY_PREDICATE)
                         .build())
-                .withDynamoDbClientProvider(DynamoDbClientProviderMock.of(amazonDynamoDBMock))
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(amazonDynamoDBMock))
                 .withDeduplicateKeys(deduplicateKeys));
 
     pipeline.run().waitUntilFinish();
diff --git a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOWriteTest.java b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOWriteTest.java
new file mode 100644
index 00000000000..94575ecf5fc
--- /dev/null
+++ b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDBIOWriteTest.java
@@ -0,0 +1,343 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.sdk.io.aws2.dynamodb;
+
+import static java.util.stream.Collectors.toList;
+import static java.util.stream.IntStream.range;
+import static java.util.stream.IntStream.rangeClosed;
+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Maps.transformValues;
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.Mockito.times;
+import static org.mockito.Mockito.verify;
+import static org.mockito.Mockito.when;
+
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.function.Function;
+import java.util.function.Supplier;
+import org.apache.beam.sdk.Pipeline;
+import org.apache.beam.sdk.PipelineResult;
+import org.apache.beam.sdk.coders.AvroCoder;
+import org.apache.beam.sdk.coders.DefaultCoder;
+import org.apache.beam.sdk.io.aws2.dynamodb.DynamoDBIO.RetryConfiguration;
+import org.apache.beam.sdk.io.aws2.dynamodb.DynamoDBIO.Write.WriteFn;
+import org.apache.beam.sdk.testing.ExpectedLogs;
+import org.apache.beam.sdk.testing.PAssert;
+import org.apache.beam.sdk.testing.TestPipeline;
+import org.apache.beam.sdk.transforms.Create;
+import org.apache.beam.sdk.transforms.DoFn;
+import org.apache.beam.sdk.transforms.ParDo;
+import org.apache.beam.sdk.transforms.SerializableBiFunction;
+import org.apache.beam.sdk.transforms.SerializableFunction;
+import org.apache.beam.sdk.values.KV;
+import org.apache.beam.sdk.values.PCollection;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
+import org.joda.time.Duration;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.ExpectedException;
+import org.junit.runner.RunWith;
+import org.mockito.ArgumentCaptor;
+import org.mockito.Mock;
+import org.mockito.junit.MockitoJUnitRunner;
+import software.amazon.awssdk.services.dynamodb.DynamoDbClient;
+import software.amazon.awssdk.services.dynamodb.model.AttributeValue;
+import software.amazon.awssdk.services.dynamodb.model.BatchWriteItemRequest;
+import software.amazon.awssdk.services.dynamodb.model.BatchWriteItemResponse;
+import software.amazon.awssdk.services.dynamodb.model.DeleteRequest;
+import software.amazon.awssdk.services.dynamodb.model.DynamoDbException;
+import software.amazon.awssdk.services.dynamodb.model.PutRequest;
+import software.amazon.awssdk.services.dynamodb.model.WriteRequest;
+
+@RunWith(MockitoJUnitRunner.class)
+public class DynamoDBIOWriteTest {
+  private static final String tableName = "Test";
+
+  @Rule public final TestPipeline pipeline = TestPipeline.create();
+  @Rule public final ExpectedLogs writeFnLogs = ExpectedLogs.none(WriteFn.class);
+  @Rule public final ExpectedException thrown = ExpectedException.none();
+
+  @Mock public DynamoDbClient client;
+
+  @Test
+  public void testWritePutItems() {
+    List<Item> items = range(0, 100).mapToObj(Item::of).collect(toList());
+
+    Supplier<List<Item>> capturePuts = captureBatchWrites(client, req -> req.putRequest().item());
+
+    PCollection<Void> output =
+        pipeline
+            .apply(Create.of(items))
+            .apply(
+                DynamoDBIO.<Item>write()
+                    .withWriteRequestMapperFn(putRequestMapper)
+                    .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client)));
+
+    PAssert.that(output).empty();
+    pipeline.run().waitUntilFinish();
+
+    assertThat(capturePuts.get()).containsExactlyInAnyOrderElementsOf(items);
+  }
+
+  @Test
+  public void testWritePutItemsWithDuplicates() {
+    List<Item> items = range(0, 100).mapToObj(Item::of).collect(toList());
+
+    Supplier<List<Item>> capturePuts = captureBatchWrites(client, req -> req.putRequest().item());
+
+    pipeline
+        .apply(Create.of(items))
+        // generate identical duplicates
+        .apply(ParDo.of(new AddDuplicatesDoFn(3, false)))
+        .apply(
+            DynamoDBIO.<Item>write()
+                .withWriteRequestMapperFn(putRequestMapper)
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client)));
+
+    pipeline.run().waitUntilFinish();
+
+    assertThat(capturePuts.get()).hasSize(100);
+    assertThat(capturePuts.get()).containsExactlyInAnyOrderElementsOf(items);
+  }
+
+  @Test
+  public void testWritePutItemsWithDuplicatesByKey() {
+    List<Item> items = range(0, 100).mapToObj(Item::of).collect(toList());
+
+    Supplier<List<Item>> capturePuts = captureBatchWrites(client, req -> req.putRequest().item());
+
+    pipeline
+        .apply(Create.of(items))
+        // decorate duplicates so they are different
+        .apply(ParDo.of(new AddDuplicatesDoFn(3, true)))
+        .apply(
+            DynamoDBIO.<Item>write()
+                .withWriteRequestMapperFn(putRequestMapper)
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client))
+                .withDeduplicateKeys(ImmutableList.of("id")));
+
+    pipeline.run().waitUntilFinish();
+
+    assertThat(capturePuts.get()).hasSize(100);
+    assertThat(capturePuts.get()).containsExactlyInAnyOrderElementsOf(items);
+  }
+
+  @Test
+  public void testWriteDeleteItems() {
+    List<Item> items = range(0, 100).mapToObj(Item::of).collect(toList());
+
+    Supplier<List<Item>> captureDeletes =
+        captureBatchWrites(client, req -> req.deleteRequest().key());
+
+    PCollection<Void> output =
+        pipeline
+            .apply(Create.of(items))
+            .apply(
+                DynamoDBIO.<Item>write()
+                    .withWriteRequestMapperFn(deleteRequestMapper)
+                    .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client)));
+
+    PAssert.that(output).empty();
+    pipeline.run().waitUntilFinish();
+
+    assertThat(captureDeletes.get()).hasSize(100);
+    assertThat(captureDeletes.get()).containsExactlyInAnyOrderElementsOf(items);
+  }
+
+  @Test
+  public void testWriteDeleteItemsWithDuplicates() {
+    List<Item> items = range(0, 100).mapToObj(Item::of).collect(toList());
+
+    Supplier<List<Item>> captureDeletes =
+        captureBatchWrites(client, req -> req.deleteRequest().key());
+
+    pipeline
+        .apply(Create.of(items))
+        // generate identical duplicates
+        .apply(ParDo.of(new AddDuplicatesDoFn(3, false)))
+        .apply(
+            DynamoDBIO.<Item>write()
+                .withWriteRequestMapperFn(deleteRequestMapper)
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client)));
+
+    pipeline.run().waitUntilFinish();
+
+    assertThat(captureDeletes.get()).hasSize(100);
+    assertThat(captureDeletes.get()).containsExactlyInAnyOrderElementsOf(items);
+  }
+
+  @Test
+  public void testWritePutItemsWithRetrySuccess() {
+    when(client.batchWriteItem(any(BatchWriteItemRequest.class)))
+        .thenThrow(DynamoDbException.class, DynamoDbException.class, DynamoDbException.class)
+        .thenReturn(BatchWriteItemResponse.builder().build());
+
+    pipeline
+        .apply(Create.of(Item.of(1)))
+        .apply(
+            "write",
+            DynamoDBIO.<Item>write()
+                .withWriteRequestMapperFn(putRequestMapper)
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client))
+                .withRetryConfiguration(try4Times));
+
+    PipelineResult result = pipeline.run();
+    result.waitUntilFinish();
+
+    verify(client, times(4)).batchWriteItem(any(BatchWriteItemRequest.class));
+    range(1, 4).forEach(i -> writeFnLogs.verifyWarn(String.format(WriteFn.RETRY_ATTEMPT_LOG, i)));
+  }
+
+  @Test
+  public void testWritePutItemsWithRetryFailure() throws Throwable {
+    thrown.expect(IOException.class);
+    thrown.expectMessage("Error writing to DynamoDB");
+    thrown.expectMessage("No more attempts allowed");
+
+    when(client.batchWriteItem(any(BatchWriteItemRequest.class)))
+        .thenThrow(DynamoDbException.class);
+
+    pipeline
+        .apply(Create.of(Item.of(1)))
+        .apply(
+            DynamoDBIO.<Item>write()
+                .withWriteRequestMapperFn(putRequestMapper)
+                .withDynamoDbClientProvider(StaticDynamoDBClientProvider.of(client))
+                .withRetryConfiguration(try4Times));
+
+    try {
+      pipeline.run().waitUntilFinish();
+    } catch (final Pipeline.PipelineExecutionException e) {
+      verify(client, times(4)).batchWriteItem(any(BatchWriteItemRequest.class));
+      range(1, 4).forEach(i -> writeFnLogs.verifyWarn(String.format(WriteFn.RETRY_ATTEMPT_LOG, i)));
+      throw e.getCause();
+    }
+  }
+
+  @DefaultCoder(AvroCoder.class)
+  static class Item implements Serializable {
+    Map<String, String> entries;
+
+    private Item() {}
+
+    private Item(Map<String, String> entries) {
+      this.entries = entries;
+    }
+
+    static Item of(int id) {
+      return new Item(ImmutableMap.of("id", String.valueOf(id)));
+    }
+
+    static Item of(Map<String, AttributeValue> attributes) {
+      return new Item(ImmutableMap.copyOf(transformValues(attributes, a -> a.s())));
+    }
+
+    Item withEntry(String key, String value) {
+      return new Item(
+          ImmutableMap.<String, String>builder().putAll(entries).put(key, value).build());
+    }
+
+    Map<String, AttributeValue> attributeMap() {
+      return new HashMap<>(transformValues(entries, v -> AttributeValue.builder().s(v).build()));
+    }
+
+    @Override
+    public boolean equals(Object o) {
+      if (this == o) {
+        return true;
+      }
+      if (o == null || getClass() != o.getClass()) {
+        return false;
+      }
+      return Objects.equals(entries, ((Item) o).entries);
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(entries);
+    }
+
+    @Override
+    public String toString() {
+      return "Item" + entries;
+    }
+  }
+
+  private Supplier<List<Item>> captureBatchWrites(
+      DynamoDbClient mock, Function<WriteRequest, Map<String, AttributeValue>> extractor) {
+    ArgumentCaptor<BatchWriteItemRequest> reqCaptor =
+        ArgumentCaptor.forClass(BatchWriteItemRequest.class);
+    when(mock.batchWriteItem(reqCaptor.capture()))
+        .thenReturn(BatchWriteItemResponse.builder().build());
+
+    return () ->
+        reqCaptor.getAllValues().stream()
+            .flatMap(req -> req.requestItems().values().stream())
+            .flatMap(writes -> writes.stream())
+            .map(extractor)
+            .map(Item::of)
+            .collect(toList());
+  }
+
+  private static SerializableFunction<Item, KV<String, WriteRequest>> putRequestMapper =
+      item -> {
+        PutRequest req = PutRequest.builder().item(item.attributeMap()).build();
+        return KV.of(tableName, WriteRequest.builder().putRequest(req).build());
+      };
+
+  private static SerializableFunction<Item, KV<String, WriteRequest>> deleteRequestMapper =
+      key -> {
+        DeleteRequest req = DeleteRequest.builder().key(key.attributeMap()).build();
+        return KV.of(tableName, WriteRequest.builder().deleteRequest(req).build());
+      };
+
+  private static RetryConfiguration try4Times =
+      RetryConfiguration.builder()
+          .setMaxAttempts(4)
+          .setInitialDuration(Duration.millis(1))
+          .setMaxDuration(Duration.standardSeconds(1))
+          .build();
+
+  /**
+   * A DoFn that adds N duplicates to a bundle. The original is emitted last and is the only item
+   * kept if deduplicating appropriately.
+   */
+  private static class AddDuplicatesDoFn extends DoFn<Item, Item> {
+    private final int duplicates;
+    private final SerializableBiFunction<Item, Integer, Item> decorator;
+
+    AddDuplicatesDoFn(int duplicates, boolean decorate) {
+      this.duplicates = duplicates;
+      this.decorator =
+          decorate ? (item, i) -> item.withEntry("duplicate", i.toString()) : (item, i) -> item;
+    }
+
+    @ProcessElement
+    public void processElement(ProcessContext ctx) {
+      Item original = ctx.element();
+      rangeClosed(1, duplicates).forEach(i -> ctx.output(decorator.apply(original, i)));
+      ctx.output(original);
+    }
+  }
+}
diff --git a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDbClientProviderMock.java b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/StaticDynamoDBClientProvider.java
similarity index 52%
rename from sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDbClientProviderMock.java
rename to sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/StaticDynamoDBClientProvider.java
index a01796607ba..106488f4d3a 100644
--- a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/DynamoDbClientProviderMock.java
+++ b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/dynamodb/StaticDynamoDBClientProvider.java
@@ -17,23 +17,39 @@
  */
 package org.apache.beam.sdk.io.aws2.dynamodb;
 
+import static java.util.Collections.synchronizedMap;
+
+import java.util.HashMap;
+import java.util.Map;
 import software.amazon.awssdk.services.dynamodb.DynamoDbClient;
 
-/** Mocking AwsClientProvider. */
-public class DynamoDbClientProviderMock implements DynamoDbClientProvider {
+/** Client provider supporting unserializable clients such as mock instances for unit tests. */
+class StaticDynamoDBClientProvider implements DynamoDbClientProvider {
+  private static final Map<Integer, DynamoDbClient> clients = synchronizedMap(new HashMap<>());
 
-  private static DynamoDbClientProviderMock instance = new DynamoDbClientProviderMock();
-  private static DynamoDbClient db;
+  private final int id;
+  private final transient boolean cleanup;
 
-  private DynamoDbClientProviderMock() {}
+  private StaticDynamoDBClientProvider(DynamoDbClient client) {
+    this.id = System.identityHashCode(client);
+    this.cleanup = true;
+  }
 
-  public static DynamoDbClientProviderMock of(DynamoDbClient dynamoDB) {
-    db = dynamoDB;
-    return instance;
+  static DynamoDbClientProvider of(DynamoDbClient client) {
+    StaticDynamoDBClientProvider provider = new StaticDynamoDBClientProvider(client);
+    clients.put(provider.id, client);
+    return provider;
   }
 
   @Override
   public DynamoDbClient getDynamoDbClient() {
-    return db;
+    return clients.get(id);
+  }
+
+  @Override
+  protected void finalize() {
+    if (cleanup) {
+      clients.remove(id);
+    }
   }
 }
