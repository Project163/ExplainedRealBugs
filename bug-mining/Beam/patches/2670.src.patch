diff --git a/sdks/java/io/amazon-web-services/src/main/java/org/apache/beam/sdk/io/aws/s3/S3WritableByteChannel.java b/sdks/java/io/amazon-web-services/src/main/java/org/apache/beam/sdk/io/aws/s3/S3WritableByteChannel.java
index 9e00e93c0be..abeed918fe7 100644
--- a/sdks/java/io/amazon-web-services/src/main/java/org/apache/beam/sdk/io/aws/s3/S3WritableByteChannel.java
+++ b/sdks/java/io/amazon-web-services/src/main/java/org/apache/beam/sdk/io/aws/s3/S3WritableByteChannel.java
@@ -118,13 +118,25 @@ class S3WritableByteChannel implements WritableByteChannel {
 
     int totalBytesWritten = 0;
     while (sourceBuffer.hasRemaining()) {
+      int position = sourceBuffer.position();
       int bytesWritten = Math.min(sourceBuffer.remaining(), uploadBuffer.remaining());
       totalBytesWritten += bytesWritten;
 
-      byte[] copyBuffer = new byte[bytesWritten];
-      sourceBuffer.get(copyBuffer);
-      uploadBuffer.put(copyBuffer);
-      md5.update(copyBuffer);
+      if (sourceBuffer.hasArray()) {
+        // If the underlying array is accessible, direct access is the most efficient approach.
+        int start = sourceBuffer.arrayOffset() + position;
+        uploadBuffer.put(sourceBuffer.array(), start, bytesWritten);
+        md5.update(sourceBuffer.array(), start, bytesWritten);
+      } else {
+        // Otherwise, use a readonly copy with an appropriate mark to read the current range of the
+        // buffer twice.
+        ByteBuffer copyBuffer = sourceBuffer.asReadOnlyBuffer();
+        copyBuffer.mark().limit(position + bytesWritten);
+        uploadBuffer.put(copyBuffer);
+        copyBuffer.reset();
+        md5.update(copyBuffer);
+      }
+      sourceBuffer.position(position + bytesWritten); // move position forward by the bytes written
 
       if (!uploadBuffer.hasRemaining() || sourceBuffer.hasRemaining()) {
         flush();
@@ -136,7 +148,8 @@ class S3WritableByteChannel implements WritableByteChannel {
 
   private void flush() throws IOException {
     uploadBuffer.flip();
-    ByteArrayInputStream inputStream = new ByteArrayInputStream(uploadBuffer.array());
+    ByteArrayInputStream inputStream =
+        new ByteArrayInputStream(uploadBuffer.array(), 0, uploadBuffer.limit());
 
     UploadPartRequest request =
         new UploadPartRequest()
@@ -144,7 +157,7 @@ class S3WritableByteChannel implements WritableByteChannel {
             .withKey(path.getKey())
             .withUploadId(uploadId)
             .withPartNumber(partNumber++)
-            .withPartSize(uploadBuffer.remaining())
+            .withPartSize(uploadBuffer.limit())
             .withMD5Digest(Base64.encodeAsString(md5.digest()))
             .withInputStream(inputStream);
     request.setSSECustomerKey(config.getSSECustomerKey());
diff --git a/sdks/java/io/amazon-web-services/src/test/java/org/apache/beam/sdk/io/aws/s3/S3WritableByteChannelTest.java b/sdks/java/io/amazon-web-services/src/test/java/org/apache/beam/sdk/io/aws/s3/S3WritableByteChannelTest.java
index 00f9cffda5f..cb577d86032 100644
--- a/sdks/java/io/amazon-web-services/src/test/java/org/apache/beam/sdk/io/aws/s3/S3WritableByteChannelTest.java
+++ b/sdks/java/io/amazon-web-services/src/test/java/org/apache/beam/sdk/io/aws/s3/S3WritableByteChannelTest.java
@@ -66,22 +66,24 @@ public class S3WritableByteChannelTest {
 
   @Test
   public void write() throws IOException {
-    writeFromConfig(s3Config("s3"));
-    writeFromConfig(s3ConfigWithSSEAlgorithm("s3"));
-    writeFromConfig(s3ConfigWithSSECustomerKey("s3"));
-    writeFromConfig(s3ConfigWithSSEAwsKeyManagementParams("s3"));
+    writeFromConfig(s3Config("s3"), false);
+    writeFromConfig(s3Config("s3"), true);
+    writeFromConfig(s3ConfigWithSSEAlgorithm("s3"), false);
+    writeFromConfig(s3ConfigWithSSECustomerKey("s3"), false);
+    writeFromConfig(s3ConfigWithSSEAwsKeyManagementParams("s3"), false);
     expected.expect(IllegalArgumentException.class);
-    writeFromConfig(s3ConfigWithMultipleSSEOptions("s3"));
+    writeFromConfig(s3ConfigWithMultipleSSEOptions("s3"), false);
   }
 
   @Test
   public void writeWithS3Options() throws IOException {
-    writeFromOptions(s3Options());
-    writeFromOptions(s3OptionsWithSSEAlgorithm());
-    writeFromOptions(s3OptionsWithSSECustomerKey());
-    writeFromOptions(s3OptionsWithSSEAwsKeyManagementParams());
+    writeFromOptions(s3Options(), false);
+    writeFromOptions(s3Options(), true);
+    writeFromOptions(s3OptionsWithSSEAlgorithm(), false);
+    writeFromOptions(s3OptionsWithSSECustomerKey(), false);
+    writeFromOptions(s3OptionsWithSSEAwsKeyManagementParams(), false);
     expected.expect(IllegalArgumentException.class);
-    writeFromOptions(s3OptionsWithMultipleSSEOptions());
+    writeFromOptions(s3OptionsWithMultipleSSEOptions(), false);
   }
 
   @FunctionalInterface
@@ -89,7 +91,7 @@ public class S3WritableByteChannelTest {
     S3WritableByteChannel get() throws IOException;
   }
 
-  private void writeFromOptions(S3Options options) throws IOException {
+  private void writeFromOptions(S3Options options, boolean writeReadOnlyBuffer) throws IOException {
     AmazonS3 mockAmazonS3 = mock(AmazonS3.class, withSettings().defaultAnswer(RETURNS_SMART_NULLS));
     S3ResourceId path = S3ResourceId.fromUri("s3://bucket/dir/file");
     Supplier channel =
@@ -107,10 +109,12 @@ public class S3WritableByteChannelTest {
         toMd5(options.getSSECustomerKey()),
         options.getSSEAwsKeyManagementParams(),
         options.getS3UploadBufferSizeBytes(),
-        options.getBucketKeyEnabled());
+        options.getBucketKeyEnabled(),
+        writeReadOnlyBuffer);
   }
 
-  private void writeFromConfig(S3FileSystemConfiguration config) throws IOException {
+  private void writeFromConfig(S3FileSystemConfiguration config, boolean writeReadOnlyBuffer)
+      throws IOException {
     AmazonS3 mockAmazonS3 = mock(AmazonS3.class, withSettings().defaultAnswer(RETURNS_SMART_NULLS));
     S3ResourceId path = S3ResourceId.fromUri("s3://bucket/dir/file");
     Supplier channel = () -> new S3WritableByteChannel(mockAmazonS3, path, "text/plain", config);
@@ -122,7 +126,8 @@ public class S3WritableByteChannelTest {
         toMd5(config.getSSECustomerKey()),
         config.getSSEAwsKeyManagementParams(),
         config.getS3UploadBufferSizeBytes(),
-        config.getBucketKeyEnabled());
+        config.getBucketKeyEnabled(),
+        writeReadOnlyBuffer);
   }
 
   private void write(
@@ -133,7 +138,8 @@ public class S3WritableByteChannelTest {
       String sseCustomerKeyMd5,
       SSEAwsKeyManagementParams sseAwsKeyManagementParams,
       long s3UploadBufferSizeBytes,
-      boolean bucketKeyEnabled)
+      boolean bucketKeyEnabled,
+      boolean writeReadOnlyBuffer)
       throws IOException {
     InitiateMultipartUploadResult initiateMultipartUploadResult =
         new InitiateMultipartUploadResult();
@@ -178,7 +184,8 @@ public class S3WritableByteChannelTest {
     uploadContent.flip();
 
     S3WritableByteChannel channel = channelSupplier.get();
-    int uploadedSize = channel.write(uploadContent);
+    int uploadedSize =
+        channel.write(writeReadOnlyBuffer ? uploadContent.asReadOnlyBuffer() : uploadContent);
     assertEquals(contentSize, uploadedSize);
 
     CompleteMultipartUploadResult completeMultipartUploadResult =
diff --git a/sdks/java/io/amazon-web-services2/src/main/java/org/apache/beam/sdk/io/aws2/s3/S3WritableByteChannel.java b/sdks/java/io/amazon-web-services2/src/main/java/org/apache/beam/sdk/io/aws2/s3/S3WritableByteChannel.java
index 8aaf84bd3f9..91236bbf2f9 100644
--- a/sdks/java/io/amazon-web-services2/src/main/java/org/apache/beam/sdk/io/aws2/s3/S3WritableByteChannel.java
+++ b/sdks/java/io/amazon-web-services2/src/main/java/org/apache/beam/sdk/io/aws2/s3/S3WritableByteChannel.java
@@ -124,13 +124,25 @@ class S3WritableByteChannel implements WritableByteChannel {
 
     int totalBytesWritten = 0;
     while (sourceBuffer.hasRemaining()) {
+      int position = sourceBuffer.position();
       int bytesWritten = Math.min(sourceBuffer.remaining(), uploadBuffer.remaining());
       totalBytesWritten += bytesWritten;
 
-      byte[] copyBuffer = new byte[bytesWritten];
-      sourceBuffer.get(copyBuffer);
-      uploadBuffer.put(copyBuffer);
-      md5.update(copyBuffer);
+      if (sourceBuffer.hasArray()) {
+        // If the underlying array is accessible, direct access is the most efficient approach.
+        int start = sourceBuffer.arrayOffset() + position;
+        uploadBuffer.put(sourceBuffer.array(), start, bytesWritten);
+        md5.update(sourceBuffer.array(), start, bytesWritten);
+      } else {
+        // Otherwise, use a readonly copy with an appropriate mark to read the current range of the
+        // buffer twice.
+        ByteBuffer copyBuffer = sourceBuffer.asReadOnlyBuffer();
+        copyBuffer.mark().limit(position + bytesWritten);
+        uploadBuffer.put(copyBuffer);
+        copyBuffer.reset();
+        md5.update(copyBuffer);
+      }
+      sourceBuffer.position(position + bytesWritten); // move position forward by the bytes written
 
       if (!uploadBuffer.hasRemaining() || sourceBuffer.hasRemaining()) {
         flush();
@@ -142,7 +154,8 @@ class S3WritableByteChannel implements WritableByteChannel {
 
   private void flush() throws IOException {
     uploadBuffer.flip();
-    ByteArrayInputStream inputStream = new ByteArrayInputStream(uploadBuffer.array());
+    ByteArrayInputStream inputStream =
+        new ByteArrayInputStream(uploadBuffer.array(), 0, uploadBuffer.limit());
 
     UploadPartRequest request =
         UploadPartRequest.builder()
@@ -150,7 +163,7 @@ class S3WritableByteChannel implements WritableByteChannel {
             .key(path.getKey())
             .uploadId(uploadId)
             .partNumber(partNumber++)
-            .contentLength((long) uploadBuffer.remaining())
+            .contentLength((long) uploadBuffer.limit())
             .sseCustomerKey(options.getSSECustomerKey().getKey())
             .sseCustomerAlgorithm(options.getSSECustomerKey().getAlgorithm())
             .sseCustomerKeyMD5(options.getSSECustomerKey().getMD5())
diff --git a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/s3/S3FileSystemIT.java b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/s3/S3FileSystemIT.java
index 4088982f245..521df9781fd 100644
--- a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/s3/S3FileSystemIT.java
+++ b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/s3/S3FileSystemIT.java
@@ -41,7 +41,6 @@ import org.junit.rules.ExternalResource;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
 import software.amazon.awssdk.services.s3.S3Client;
-import software.amazon.awssdk.services.s3.S3ClientBuilder;
 
 /**
  * Integration test to write and read from a S3 compatible file system.
@@ -61,8 +60,7 @@ public class S3FileSystemIT {
   public interface S3ITOptions extends ITEnvironment.ITOptions, S3Options {}
 
   @ClassRule
-  public static ITEnvironment<S3ITOptions> env =
-      new ITEnvironment<>(S3, S3ITOptions.class, S3ClientFixFix::set);
+  public static ITEnvironment<S3ITOptions> env = new ITEnvironment<>(S3, S3ITOptions.class);
 
   @Rule public TestPipeline pipelineWrite = env.createTestPipeline();
   @Rule public TestPipeline pipelineRead = env.createTestPipeline();
@@ -102,18 +100,4 @@ public class S3FileSystemIT {
       }
     }
   }
-
-  // Disable chunkedEncoding to prevent localstack bug, see
-  // https://github.com/localstack/localstack/issues/4987
-  private static class S3ClientFixFix extends DefaultS3ClientBuilderFactory {
-    private static void set(S3Options s3Options) {
-      s3Options.setS3ClientFactoryClass(S3ClientFixFix.class);
-    }
-
-    @Override
-    public S3ClientBuilder createBuilder(S3Options s3Options) {
-      return super.createBuilder(s3Options)
-          .serviceConfiguration(c -> c.chunkedEncodingEnabled(false));
-    }
-  }
 }
diff --git a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/s3/S3WritableByteChannelTest.java b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/s3/S3WritableByteChannelTest.java
index 9a8deee7c74..e77dca7f1a6 100644
--- a/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/s3/S3WritableByteChannelTest.java
+++ b/sdks/java/io/amazon-web-services2/src/test/java/org/apache/beam/sdk/io/aws2/s3/S3WritableByteChannelTest.java
@@ -64,15 +64,17 @@ public class S3WritableByteChannelTest {
 
   @Test
   public void write() throws IOException {
-    writeFromOptions(s3Options());
-    writeFromOptions(s3OptionsWithSSEAlgorithm());
-    writeFromOptions(s3OptionsWithSSECustomerKey());
-    writeFromOptions(s3OptionsWithSSEKMSKeyId());
+    writeFromOptions(s3Options(), false);
+    writeFromOptions(s3Options(), true);
+    writeFromOptions(s3OptionsWithSSEAlgorithm(), false);
+    writeFromOptions(s3OptionsWithSSECustomerKey(), false);
+    writeFromOptions(s3OptionsWithSSEKMSKeyId(), false);
     assertThrows(
-        IllegalArgumentException.class, () -> writeFromOptions(s3OptionsWithMultipleSSEOptions()));
+        IllegalArgumentException.class,
+        () -> writeFromOptions(s3OptionsWithMultipleSSEOptions(), false));
   }
 
-  private void writeFromOptions(S3Options options) throws IOException {
+  private void writeFromOptions(S3Options options, boolean writeReadOnlyBuffer) throws IOException {
     S3Client mockS3Client = mock(S3Client.class, withSettings().defaultAnswer(RETURNS_SMART_NULLS));
     S3ResourceId path = S3ResourceId.fromUri("s3://bucket/dir/file");
 
@@ -126,7 +128,8 @@ public class S3WritableByteChannelTest {
     }
     uploadContent.flip();
 
-    int uploadedSize = channel.write(uploadContent);
+    int uploadedSize =
+        channel.write(writeReadOnlyBuffer ? uploadContent.asReadOnlyBuffer() : uploadContent);
     assertEquals(contentSize, uploadedSize);
 
     CompleteMultipartUploadResponse completeMultipartUploadResponse =
