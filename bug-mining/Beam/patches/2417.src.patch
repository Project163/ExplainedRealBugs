diff --git a/sdks/python/apache_beam/dataframe/frames.py b/sdks/python/apache_beam/dataframe/frames.py
index c62570a7477..b2df80c0ac2 100644
--- a/sdks/python/apache_beam/dataframe/frames.py
+++ b/sdks/python/apache_beam/dataframe/frames.py
@@ -1985,13 +1985,14 @@ class DeferredDataFrame(DeferredDataFrameOrSeries):
 
       if not isinstance(func, dict):
         col_names = list(projected._expr.proxy().columns)
-        func = {col: func for col in col_names}
+        func_by_col = {col: func for col in col_names}
       else:
+        func_by_col = func
         col_names = list(func.keys())
       aggregated_cols = []
-      has_lists = any(isinstance(f, list) for f in func.values())
+      has_lists = any(isinstance(f, list) for f in func_by_col.values())
       for col in col_names:
-        funcs = func[col]
+        funcs = func_by_col[col]
         if has_lists and not isinstance(funcs, list):
           # If any of the columns do multiple aggregations, they all must use
           # "list" style output
@@ -2007,8 +2008,7 @@ class DeferredDataFrame(DeferredDataFrameOrSeries):
                   lambda *cols: pd.Series(
                       {col: value for col, value in zip(col_names, cols)}),
                 [col._expr for col in aggregated_cols],
-                requires_partition_by=partitionings.Singleton(),
-                proxy=projected._expr.proxy().agg(func, *args, **kwargs)))
+                requires_partition_by=partitionings.Singleton()))
         elif isinstance(proxy, pd.DataFrame):
           return frame_base.DeferredFrame.wrap(
               expressions.ComputedExpression(
@@ -2022,7 +2022,6 @@ class DeferredDataFrame(DeferredDataFrameOrSeries):
                                f"DataFrame.aggregate!: proxy={proxy!r}, "
                                f"type(proxy)={type(proxy)!r}")
 
-
   agg = aggregate
 
   applymap = frame_base._elementwise_method('applymap', base=pd.DataFrame)
@@ -3468,6 +3467,14 @@ class _DeferredStringMethods(frame_base.DeferredBase):
       pd.core.strings.StringMethods, 'get_dummies',
       reason='non-deferred-columns')
 
+  split = frame_base.wont_implement_method(
+      pd.core.strings.StringMethods, 'split',
+      reason='non-deferred-columns')
+
+  rsplit = frame_base.wont_implement_method(
+      pd.core.strings.StringMethods, 'rsplit',
+      reason='non-deferred-columns')
+
 
 ELEMENTWISE_STRING_METHODS = [
             'capitalize',
@@ -3498,11 +3505,9 @@ ELEMENTWISE_STRING_METHODS = [
             'partition',
             'replace',
             'rpartition',
-            'rsplit',
             'rstrip',
             'slice',
             'slice_replace',
-            'split',
             'startswith',
             'strip',
             'swapcase',
diff --git a/sdks/python/apache_beam/dataframe/frames_test.py b/sdks/python/apache_beam/dataframe/frames_test.py
index ac5d730472f..ab1c16c952a 100644
--- a/sdks/python/apache_beam/dataframe/frames_test.py
+++ b/sdks/python/apache_beam/dataframe/frames_test.py
@@ -111,7 +111,8 @@ class _AbstractFrameTest(unittest.TestCase):
 
     self._run_test(wrapper, arg, **kwargs)
 
-  def _run_test(self, func, *args, distributed=True, nonparallel=False):
+  def _run_test(
+      self, func, *args, distributed=True, nonparallel=False, check_proxy=True):
     """Verify that func(*args) produces the same result in pandas and in Beam.
 
     Args:
@@ -122,7 +123,13 @@ class _AbstractFrameTest(unittest.TestCase):
             generated twice, once outside of an allow_non_parallel_operations
             block (to verify NonParallelOperation is raised), and again inside
             of an allow_non_parallel_operations block to actually generate an
-            expression to verify."""
+            expression to verify.
+        check_proxy (bool): Whether or not to check that the proxy of the
+            generated expression matches the actual result, defaults to True.
+            This option should NOT be set to False in tests added for new
+            operations if at all possible. Instead make sure the new operation
+            produces the correct proxy. This flag only exists as an escape hatch
+            until existing failures can be addressed (BEAM-12379)."""
     # Compute expected value
     expected = func(*args)
 
@@ -170,6 +177,7 @@ class _AbstractFrameTest(unittest.TestCase):
         raise ValueError(
             f"Expected value is a {type(expected)},"
             "not a Series or DataFrame.")
+
     else:
       # Expectation is not a pandas object
       if isinstance(expected, float):
@@ -182,6 +190,33 @@ class _AbstractFrameTest(unittest.TestCase):
       self.assertTrue(
           cmp(actual), 'Expected:\n\n%r\n\nActual:\n\n%r' % (expected, actual))
 
+    if check_proxy:
+      # Verify that the actual result agrees with the proxy
+      proxy = expr.proxy()
+
+      if type(actual) in (np.float32, np.float64):
+        self.assertTrue(type(actual) == type(proxy) or np.isnan(proxy))
+      else:
+        self.assertEqual(type(actual), type(proxy))
+
+      if isinstance(expected, pd.core.generic.NDFrame):
+        if isinstance(expected, pd.Series):
+          self.assertEqual(actual.dtype, proxy.dtype)
+          self.assertEqual(actual.name, proxy.name)
+        elif isinstance(expected, pd.DataFrame):
+          pd.testing.assert_series_equal(actual.dtypes, proxy.dtypes)
+
+        else:
+          raise ValueError(
+              f"Expected value is a {type(expected)},"
+              "not a Series or DataFrame.")
+
+        self.assertEqual(actual.index.names, proxy.index.names)
+        for i in range(actual.index.nlevels):
+          self.assertEqual(
+              actual.index.get_level_values(i).dtype,
+              proxy.index.get_level_values(i).dtype)
+
 
 class DeferredFrameTest(_AbstractFrameTest):
   """Miscellaneous tessts for DataFrame operations."""
@@ -208,22 +243,6 @@ class DeferredFrameTest(_AbstractFrameTest):
     })
     self._run_inplace_test(new_column, df)
 
-  def test_str_split(self):
-    s = pd.Series([
-        "this is a regular sentence",
-        "https://docs.python.org/3/tutorial/index.html",
-        np.nan
-    ])
-
-    # TODO(BEAM-11931): pandas produces None for empty values with expand=True,
-    # while we produce NaN (from pd.concat). This replicates some doctests that
-    # verify that behavior, but with a replace call to ignore the difference.
-    self._run_test(
-        lambda s: s.str.split(expand=True).replace({None: np.nan}), s)
-    self._run_test(
-        lambda s: s.str.rsplit("/", n=1, expand=True).replace({None: np.nan}),
-        s)
-
   def test_set_column_from_index(self):
     def new_column(df):
       df['NewCol'] = df.index
@@ -265,13 +284,15 @@ class DeferredFrameTest(_AbstractFrameTest):
     self._run_test(lambda df: df.sort_index(axis=1, na_position='first'), df)
 
   def test_where_callable_args(self):
-    df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
+    df = pd.DataFrame(
+        np.arange(10, dtype=np.int64).reshape(-1, 2), columns=['A', 'B'])
 
     self._run_test(
         lambda df: df.where(lambda df: df % 2 == 0, lambda df: df * 10), df)
 
   def test_where_concrete_args(self):
-    df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=['A', 'B'])
+    df = pd.DataFrame(
+        np.arange(10, dtype=np.int64).reshape(-1, 2), columns=['A', 'B'])
 
     self._run_test(
         lambda df: df.where(
@@ -337,10 +358,8 @@ class DeferredFrameTest(_AbstractFrameTest):
   def test_set_index(self):
     df = pd.DataFrame({
         # [19, 18, ..]
-        'index1': reversed(range(20)),
-        # [15, 16, .., 0, 1, .., 13, 14]
-        'index2': np.roll(range(20), 5),
-        # ['', 'a', 'bb', ...]
+        'index1': reversed(range(20)),  # [15, 16, .., 0, 1, .., 13, 14]
+        'index2': np.roll(range(20), 5),  # ['', 'a', 'bb', ...]
         'values': [chr(ord('a') + i) * i for i in range(20)],
     })
 
@@ -402,7 +421,8 @@ class DeferredFrameTest(_AbstractFrameTest):
             index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
     self._run_test(
         lambda df1,
         df2: df1.merge(
@@ -410,7 +430,8 @@ class DeferredFrameTest(_AbstractFrameTest):
         rename(index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
 
   def test_merge_left_join(self):
     # This is from the pandas doctests, but fails due to re-indexing being
@@ -423,7 +444,8 @@ class DeferredFrameTest(_AbstractFrameTest):
         df2: df1.merge(df2, how='left', on='a').rename(index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
 
   def test_merge_on_index(self):
     # This is from the pandas doctests, but fails due to re-indexing being
@@ -439,7 +461,8 @@ class DeferredFrameTest(_AbstractFrameTest):
         lambda df1,
         df2: df1.merge(df2, left_index=True, right_index=True),
         df1,
-        df2)
+        df2,
+        check_proxy=False)
 
   def test_merge_same_key(self):
     df1 = pd.DataFrame({
@@ -453,14 +476,16 @@ class DeferredFrameTest(_AbstractFrameTest):
         df2: df1.merge(df2, on='key').rename(index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
     self._run_test(
         lambda df1,
         df2: df1.merge(df2, on='key', suffixes=('_left', '_right')).rename(
             index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
 
   def test_merge_same_key_doctest(self):
     df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})
@@ -471,14 +496,16 @@ class DeferredFrameTest(_AbstractFrameTest):
         df2: df1.merge(df2, how='left', on='a').rename(index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
     # Test without specifying 'on'
     self._run_test(
         lambda df1,
         df2: df1.merge(df2, how='left').rename(index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
 
   def test_merge_same_key_suffix_collision(self):
     df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2], 'a_lsuffix': [5, 6]})
@@ -491,7 +518,8 @@ class DeferredFrameTest(_AbstractFrameTest):
                 index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
     # Test without specifying 'on'
     self._run_test(
         lambda df1,
@@ -499,7 +527,8 @@ class DeferredFrameTest(_AbstractFrameTest):
         rename(index=lambda x: '*'),
         df1,
         df2,
-        nonparallel=True)
+        nonparallel=True,
+        check_proxy=False)
 
   def test_value_counts_with_nans(self):
     # similar to doctests that verify value_counts, but include nan values to
@@ -603,7 +632,8 @@ class DeferredFrameTest(_AbstractFrameTest):
     self._run_test(lambda df: df[['a', 'b']].corrwith(df[['b', 'c']]), df)
 
     df2 = pd.DataFrame(np.random.randn(20, 3), columns=['a', 'b', 'c'])
-    self._run_test(lambda df, df2: df.corrwith(df2, axis=1), df, df2)
+    self._run_test(
+        lambda df, df2: df.corrwith(df2, axis=1), df, df2, check_proxy=False)
 
   def test_corrwith_bad_axis(self):
     df = pd.DataFrame({'a': range(3), 'b': range(3, 6), 'c': range(6, 9)})
@@ -616,7 +646,10 @@ class DeferredFrameTest(_AbstractFrameTest):
     # doctest framework
     df = pd.DataFrame([[pd.NA, 2.12], [3.356, 4.567]])
     self._run_test(
-        lambda df: df.applymap(lambda x: len(str(x)), na_action='ignore'), df)
+        lambda df: df.applymap(lambda x: len(str(x)), na_action='ignore'),
+        df,
+        # TODO: generate proxy using naive type inference on fn
+        check_proxy=False)
 
   def test_dataframe_eval_query(self):
     df = pd.DataFrame(np.random.randn(20, 3), columns=['a', 'b', 'c'])
@@ -646,10 +679,11 @@ class DeferredFrameTest(_AbstractFrameTest):
     df = pd.DataFrame(
         np.array([[1, 1], [2, 10], [3, 100], [4, 100]]), columns=['a', 'b'])
 
-    self._run_test(lambda df: df.quantile(0.1), df, nonparallel=True)
-    self._run_test(lambda df: df.quantile([0.1, 0.9]), df, nonparallel=True)
+    self._run_test(
+        lambda df: df.quantile(0.1, axis='columns'), df, check_proxy=False)
 
-    self._run_test(lambda df: df.quantile(0.1, axis='columns'), df)
+    self._run_test(
+        lambda df: df.quantile(0.1, axis='columns'), df, check_proxy=False)
     with self.assertRaisesRegex(frame_base.WontImplementError,
                                 r"df\.quantile\(q=0\.1, axis='columns'\)"):
       self._run_test(lambda df: df.quantile([0.1, 0.5], axis='columns'), df)
@@ -757,7 +791,9 @@ class DeferredFrameTest(_AbstractFrameTest):
 
     self._run_inplace_test(lambda df: df.insert(1, 'C', df.A * 2), df)
     self._run_inplace_test(
-        lambda df: df.insert(0, 'foo', pd.Series([8], index=[1])), df)
+        lambda df: df.insert(0, 'foo', pd.Series([8], index=[1])),
+        df,
+        check_proxy=False)
     self._run_inplace_test(lambda df: df.insert(2, 'bar', value='q'), df)
 
   def test_drop_duplicates(self):
@@ -795,7 +831,10 @@ class GroupByTest(_AbstractFrameTest):
       self.skipTest(
           "BEAM-12366: proxy generation of DataFrameGroupBy.describe "
           "fails in pandas < 1.2")
-    self._run_test(lambda df: df.groupby('group').agg(agg_type), GROUPBY_DF)
+    self._run_test(
+        lambda df: df.groupby('group').agg(agg_type),
+        GROUPBY_DF,
+        check_proxy=False)
 
   @parameterized.expand(frames.ALL_AGGREGATIONS)
   def test_groupby_with_filter(self, agg_type):
@@ -805,7 +844,8 @@ class GroupByTest(_AbstractFrameTest):
           "fails in pandas < 1.2")
     self._run_test(
         lambda df: getattr(df[df.foo > 30].groupby('group'), agg_type)(),
-        GROUPBY_DF)
+        GROUPBY_DF,
+        check_proxy=False)
 
   @parameterized.expand(frames.ALL_AGGREGATIONS)
   def test_groupby(self, agg_type):
@@ -865,7 +905,8 @@ class GroupByTest(_AbstractFrameTest):
           "fails in pandas < 1.2")
     self._run_test(
         lambda df: getattr(df.groupby('group')[['bar', 'baz']], agg_type)(),
-        GROUPBY_DF)
+        GROUPBY_DF,
+        check_proxy=False)
 
   def test_groupby_errors_bad_projection(self):
     df = GROUPBY_DF
@@ -1003,7 +1044,14 @@ class AggregationTest(_AbstractFrameTest):
 
     nonparallel = agg_method in ('quantile', 'mean', 'describe', 'median')
 
-    self._run_test(lambda s: s.agg(agg_method), s, nonparallel=nonparallel)
+    # TODO(BEAM-12379): max and min produce the wrong proxy
+    check_proxy = agg_method not in ('max', 'min')
+
+    self._run_test(
+        lambda s: s.agg(agg_method),
+        s,
+        nonparallel=nonparallel,
+        check_proxy=check_proxy)
 
   @parameterized.expand(frames.ALL_AGGREGATIONS)
   def test_dataframe_agg(self, agg_method):
@@ -1011,7 +1059,14 @@ class AggregationTest(_AbstractFrameTest):
 
     nonparallel = agg_method in ('quantile', 'mean', 'describe', 'median')
 
-    self._run_test(lambda df: df.agg(agg_method), df, nonparallel=nonparallel)
+    # TODO(BEAM-12379): max and min produce the wrong proxy
+    check_proxy = agg_method not in ('max', 'min')
+
+    self._run_test(
+        lambda df: df.agg(agg_method),
+        df,
+        nonparallel=nonparallel,
+        check_proxy=check_proxy)
 
   def test_series_agg_modes(self):
     s = pd.Series(list(range(16)))
@@ -1068,7 +1123,8 @@ class AggregationTest(_AbstractFrameTest):
     self._run_test(
         lambda df: df.set_index(['group', 'foo']).max(
             level=0, numeric_only=False),
-        GROUPBY_DF)
+        GROUPBY_DF,
+        check_proxy=False)
     # pandas implementation doesn't respect numeric_only argument here
     # (https://github.com/pandas-dev/pandas/issues/40788), it
     # always acts as if numeric_only=True. Our implmentation respects it so we
@@ -1086,7 +1142,8 @@ class AggregationTest(_AbstractFrameTest):
     self._run_test(
         lambda df: df.set_index(['group', 'foo']).max(
             level=1, numeric_only=False),
-        GROUPBY_DF)
+        GROUPBY_DF,
+        check_proxy=False)
     # sum with str columns is order-sensitive
     self._run_test(
         lambda df: df.set_index(['group', 'foo']).sum(
@@ -1113,7 +1170,8 @@ class AggregationTest(_AbstractFrameTest):
     # level= is ignored for multiple agg fns
     self._run_test(
         lambda df: df.set_index(['group', 'foo']).agg(['min', 'max'], level=0),
-        GROUPBY_DF)
+        GROUPBY_DF,
+        check_proxy=False)
 
   @parameterized.expand([(True, ), (False, )])
   @unittest.skipIf(
@@ -1123,8 +1181,14 @@ class AggregationTest(_AbstractFrameTest):
     # Note other aggregation functions can fail on this input with
     # numeric_only={False,None}. These are the only ones that actually work for
     # the string inputs.
-    self._run_test(lambda df: df.max(numeric_only=numeric_only), GROUPBY_DF)
-    self._run_test(lambda df: df.min(numeric_only=numeric_only), GROUPBY_DF)
+    self._run_test(
+        lambda df: df.max(numeric_only=numeric_only),
+        GROUPBY_DF,
+        check_proxy=False)
+    self._run_test(
+        lambda df: df.min(numeric_only=numeric_only),
+        GROUPBY_DF,
+        check_proxy=False)
 
   @unittest.skip(
       "pandas implementation doesn't respect numeric_only= with "
@@ -1177,7 +1241,9 @@ class AggregationTest(_AbstractFrameTest):
 
   def test_series_agg_np_size(self):
     self._run_test(
-        lambda df: df.set_index(['group', 'foo']).agg(np.size), GROUPBY_DF)
+        lambda df: df.set_index(['group', 'foo']).agg(np.size),
+        GROUPBY_DF,
+        check_proxy=False)
 
   def test_df_agg_invalid_kwarg_raises(self):
     self._run_error_test(lambda df: df.agg('mean', bool_only=True), GROUPBY_DF)
diff --git a/sdks/python/apache_beam/dataframe/pandas_doctests_test.py b/sdks/python/apache_beam/dataframe/pandas_doctests_test.py
index 8a92afdc8a0..397e0bc3795 100644
--- a/sdks/python/apache_beam/dataframe/pandas_doctests_test.py
+++ b/sdks/python/apache_beam/dataframe/pandas_doctests_test.py
@@ -512,6 +512,9 @@ class DoctestTest(unittest.TestCase):
             f'{module_name}.str_repeat': ['s.str.repeat(repeats=[1, 2, 3])'],
             f'{module_name}.StringMethods.get_dummies': ['*'],
             f'{module_name}.str_get_dummies': ['*'],
+            f'{module_name}.StringMethods': ['s.str.split("_")'],
+            f'{module_name}.StringMethods.rsplit': ['*'],
+            f'{module_name}.StringMethods.split': ['*'],
         },
         skip={
             # count() on Series with a NaN produces mismatched type if we
@@ -519,17 +522,6 @@ class DoctestTest(unittest.TestCase):
             f'{module_name}.StringMethods.count': ["s.str.count('a')"],
             f'{module_name}.str_count': ["s.str.count('a')"],
 
-            # Produce None instead of NaN, see
-            # frames_test.py::DeferredFrameTest::test_str_split
-            f'{module_name}.StringMethods.rsplit': [
-                's.str.split(expand=True)',
-                's.str.rsplit("/", n=1, expand=True)',
-            ],
-            f'{module_name}.StringMethods.split': [
-                's.str.split(expand=True)',
-                's.str.rsplit("/", n=1, expand=True)',
-            ],
-
             # Bad test strings in pandas 1.1.x
             f'{module_name}.str_replace': [
                 "pd.Series(['foo', 'fuz', np.nan]).str.replace('f', repr)"
diff --git a/sdks/python/apache_beam/examples/dataframe/taxiride_test.py b/sdks/python/apache_beam/examples/dataframe/taxiride_test.py
index 517bb067510..46b2ca509df 100644
--- a/sdks/python/apache_beam/examples/dataframe/taxiride_test.py
+++ b/sdks/python/apache_beam/examples/dataframe/taxiride_test.py
@@ -85,7 +85,7 @@ class TaxiRideExampleTest(unittest.TestCase):
         beam.Pipeline(), self.input_path, self.output_path)
 
     # Parse result file and compare.
-    # TODO(BEAM-XXXX): taxiride examples should produce int sums, not floats
+    # TODO(BEAM-12379): taxiride examples should produce int sums, not floats
     results = []
     with open_shards(f'{self.output_path}-*') as result_file:
       for line in result_file:
