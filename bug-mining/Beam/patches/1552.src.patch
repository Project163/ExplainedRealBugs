diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineOptions.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineOptions.java
index f043f83c609..d2244bcbcfe 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineOptions.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineOptions.java
@@ -159,15 +159,6 @@ public interface FlinkPipelineOptions
 
   void setDisableMetrics(Boolean enableMetrics);
 
-  @Description(
-      "By default, uses Flink accumulators to store the metrics which allows to query metrics from the PipelineResult. "
-          + "If set to true, metrics will still be reported but can't be queried via PipelineResult. "
-          + "This saves network and memory.")
-  @Default.Boolean(false)
-  Boolean getDisableMetricAccumulator();
-
-  void setDisableMetricAccumulator(Boolean disableMetricAccumulator);
-
   /** Enables or disables externalized checkpoints. */
   @Description(
       "Enables or disables externalized checkpoints. "
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/metrics/FlinkMetricContainer.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/metrics/FlinkMetricContainer.java
index 9690da401ea..e389be5f153 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/metrics/FlinkMetricContainer.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/metrics/FlinkMetricContainer.java
@@ -61,42 +61,43 @@ public class FlinkMetricContainer {
   private static final String METRIC_KEY_SEPARATOR =
       GlobalConfiguration.loadConfiguration().getString(MetricOptions.SCOPE_DELIMITER);
 
+  private final MetricsContainerStepMap metricsContainers;
   private final RuntimeContext runtimeContext;
   private final Map<String, Counter> flinkCounterCache;
   private final Map<String, FlinkDistributionGauge> flinkDistributionGaugeCache;
   private final Map<String, FlinkGauge> flinkGaugeCache;
-  private final MetricsAccumulator metricsAccumulator;
 
-  public FlinkMetricContainer(RuntimeContext runtimeContext, boolean accumulatorDisabled) {
+  public FlinkMetricContainer(RuntimeContext runtimeContext) {
     this.runtimeContext = runtimeContext;
     this.flinkCounterCache = new HashMap<>();
     this.flinkDistributionGaugeCache = new HashMap<>();
     this.flinkGaugeCache = new HashMap<>();
+    this.metricsContainers = new MetricsContainerStepMap();
+  }
 
-    Accumulator<MetricsContainerStepMap, MetricsContainerStepMap> metricsAccumulator;
-    if (accumulatorDisabled) {
-      // Do not register the accumulator with Flink
+  public MetricsContainerImpl getMetricsContainer(String stepName) {
+    return metricsContainers.getContainer(stepName);
+  }
+
+  /**
+   * This should be called at the end of the Flink job and sets up an accumulator to push the
+   * metrics to the PipelineResult. This should not be called beforehand, to avoid the overhead
+   * which accumulators cause at runtime.
+   */
+  public void registerMetricsForPipelineResult() {
+    Accumulator<MetricsContainerStepMap, MetricsContainerStepMap> metricsAccumulator =
+        runtimeContext.getAccumulator(ACCUMULATOR_NAME);
+    if (metricsAccumulator == null) {
       metricsAccumulator = new MetricsAccumulator();
-    } else {
-      metricsAccumulator = runtimeContext.getAccumulator(ACCUMULATOR_NAME);
-      if (metricsAccumulator == null) {
-        metricsAccumulator = new MetricsAccumulator();
-        try {
-          runtimeContext.addAccumulator(ACCUMULATOR_NAME, metricsAccumulator);
-        } catch (UnsupportedOperationException e) {
-          // Not supported in all environments, e.g. tests
-        } catch (Exception e) {
-          LOG.error("Failed to create metrics accumulator.", e);
-        }
+      try {
+        runtimeContext.addAccumulator(ACCUMULATOR_NAME, metricsAccumulator);
+      } catch (UnsupportedOperationException e) {
+        // Not supported in all environments, e.g. tests
+      } catch (Exception e) {
+        LOG.error("Failed to create metrics accumulator.", e);
       }
     }
-    this.metricsAccumulator = (MetricsAccumulator) metricsAccumulator;
-  }
-
-  public MetricsContainerImpl getMetricsContainer(String stepName) {
-    return metricsAccumulator != null
-        ? metricsAccumulator.getLocalValue().getContainer(stepName)
-        : null;
+    metricsAccumulator.add(metricsContainers);
   }
 
   /**
@@ -113,7 +114,7 @@ public class FlinkMetricContainer {
    * given step.
    */
   void updateMetrics(String stepName) {
-    MetricResults metricResults = asAttemptedOnlyMetricResults(metricsAccumulator.getLocalValue());
+    MetricResults metricResults = asAttemptedOnlyMetricResults(metricsContainers);
     MetricQueryResults metricQueryResults =
         metricResults.queryMetrics(MetricsFilter.builder().addStep(stepName).build());
     updateCounters(metricQueryResults.getCounters());
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/metrics/MetricsAccumulator.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/metrics/MetricsAccumulator.java
index 09966c026f3..d4f2c48c815 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/metrics/MetricsAccumulator.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/metrics/MetricsAccumulator.java
@@ -21,7 +21,11 @@ import org.apache.beam.runners.core.metrics.MetricsContainerStepMap;
 import org.apache.flink.api.common.accumulators.Accumulator;
 import org.apache.flink.api.common.accumulators.SimpleAccumulator;
 
-/** Accumulator of {@link MetricsContainerStepMap}. */
+/**
+ * Accumulator of {@link MetricsContainerStepMap}. This accumulator will only be reported to Flink
+ * when the job ends. This avoids the runtime overhead for accumulators which are continously sent
+ * to the job manager.
+ */
 public class MetricsAccumulator implements SimpleAccumulator<MetricsContainerStepMap> {
 
   private MetricsContainerStepMap metricsContainers = new MetricsContainerStepMap();
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkDoFnFunction.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkDoFnFunction.java
index cfdcf891c95..fa6867f3dc5 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkDoFnFunction.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkDoFnFunction.java
@@ -72,6 +72,7 @@ public class FlinkDoFnFunction<InputT, OutputT>
   private final Map<String, PCollectionView<?>> sideInputMapping;
 
   private transient DoFnInvoker<InputT, OutputT> doFnInvoker;
+  private transient FlinkMetricContainer metricContainer;
 
   public FlinkDoFnFunction(
       DoFn<InputT, OutputT> doFn,
@@ -133,12 +134,7 @@ public class FlinkDoFnFunction<InputT, OutputT>
 
     FlinkPipelineOptions pipelineOptions = serializedOptions.get().as(FlinkPipelineOptions.class);
     if (!pipelineOptions.getDisableMetrics()) {
-      doFnRunner =
-          new DoFnRunnerWithMetricsUpdate<>(
-              stepName,
-              doFnRunner,
-              new FlinkMetricContainer(
-                  getRuntimeContext(), pipelineOptions.getDisableMetricAccumulator()));
+      doFnRunner = new DoFnRunnerWithMetricsUpdate<>(stepName, doFnRunner, metricContainer);
     }
 
     doFnRunner.startBundle();
@@ -157,11 +153,13 @@ public class FlinkDoFnFunction<InputT, OutputT>
     // options where they are needed.
     FileSystems.setDefaultPipelineOptions(serializedOptions.get());
     doFnInvoker = DoFnInvokers.tryInvokeSetupFor(doFn);
+    metricContainer = new FlinkMetricContainer(getRuntimeContext());
   }
 
   @Override
   public void close() throws Exception {
     try {
+      metricContainer.registerMetricsForPipelineResult();
       Optional.ofNullable(doFnInvoker).ifPresent(DoFnInvoker::invokeTeardown);
     } finally {
       FlinkClassloading.deleteStaticCaches();
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkExecutableStageFunction.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkExecutableStageFunction.java
index c1260eb7215..4e1c709ebcc 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkExecutableStageFunction.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkExecutableStageFunction.java
@@ -96,7 +96,7 @@ public class FlinkExecutableStageFunction<InputT> extends AbstractRichFunction
 
   // Worker-local fields. These should only be constructed and consumed on Flink TaskManagers.
   private transient RuntimeContext runtimeContext;
-  private transient FlinkMetricContainer container;
+  private transient FlinkMetricContainer metricContainer;
   private transient StateRequestHandler stateRequestHandler;
   private transient ExecutableStageContext stageContext;
   private transient StageBundleFactory stageBundleFactory;
@@ -131,7 +131,7 @@ public class FlinkExecutableStageFunction<InputT> extends AbstractRichFunction
     FileSystems.setDefaultPipelineOptions(options);
     executableStage = ExecutableStage.fromPayload(stagePayload);
     runtimeContext = getRuntimeContext();
-    container = new FlinkMetricContainer(runtimeContext, options.getDisableMetricAccumulator());
+    metricContainer = new FlinkMetricContainer(runtimeContext);
     // TODO: Wire this into the distributed cache and make it pluggable.
     stageContext = contextFactory.get(jobInfo);
     stageBundleFactory = stageContext.getStageBundleFactory(executableStage);
@@ -145,12 +145,12 @@ public class FlinkExecutableStageFunction<InputT> extends AbstractRichFunction
         new BundleProgressHandler() {
           @Override
           public void onProgress(ProcessBundleProgressResponse progress) {
-            container.updateMetrics(stepName, progress.getMonitoringInfosList());
+            metricContainer.updateMetrics(stepName, progress.getMonitoringInfosList());
           }
 
           @Override
           public void onCompleted(ProcessBundleResponse response) {
-            container.updateMetrics(stepName, response.getMonitoringInfosList());
+            metricContainer.updateMetrics(stepName, response.getMonitoringInfosList());
           }
         };
   }
@@ -283,6 +283,7 @@ public class FlinkExecutableStageFunction<InputT> extends AbstractRichFunction
 
   @Override
   public void close() throws Exception {
+    metricContainer.registerMetricsForPipelineResult();
     // close may be called multiple times when an exception is thrown
     if (stageContext != null) {
       try (AutoCloseable bundleFactoryCloser = stageBundleFactory;
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkStatefulDoFnFunction.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkStatefulDoFnFunction.java
index baffed33642..6aee09f0bb3 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkStatefulDoFnFunction.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/FlinkStatefulDoFnFunction.java
@@ -72,7 +72,9 @@ public class FlinkStatefulDoFnFunction<K, V, OutputT>
   private final Map<TupleTag<?>, Coder<?>> outputCoderMap;
   private final DoFnSchemaInformation doFnSchemaInformation;
   private final Map<String, PCollectionView<?>> sideInputMapping;
+
   private transient DoFnInvoker doFnInvoker;
+  private transient FlinkMetricContainer metricContainer;
 
   public FlinkStatefulDoFnFunction(
       DoFn<KV<K, V>, OutputT> dofn,
@@ -159,12 +161,7 @@ public class FlinkStatefulDoFnFunction<K, V, OutputT>
 
     FlinkPipelineOptions pipelineOptions = serializedOptions.get().as(FlinkPipelineOptions.class);
     if (!pipelineOptions.getDisableMetrics()) {
-      doFnRunner =
-          new DoFnRunnerWithMetricsUpdate<>(
-              stepName,
-              doFnRunner,
-              new FlinkMetricContainer(
-                  getRuntimeContext(), pipelineOptions.getDisableMetricAccumulator()));
+      doFnRunner = new DoFnRunnerWithMetricsUpdate<>(stepName, doFnRunner, metricContainer);
     }
 
     doFnRunner.startBundle();
@@ -227,12 +224,14 @@ public class FlinkStatefulDoFnFunction<K, V, OutputT>
     // deserialization method. However, this is a hack, and we want to properly initialize the
     // options where they are needed.
     FileSystems.setDefaultPipelineOptions(serializedOptions.get());
+    metricContainer = new FlinkMetricContainer(getRuntimeContext());
     doFnInvoker = DoFnInvokers.tryInvokeSetupFor(dofn);
   }
 
   @Override
   public void close() throws Exception {
     try {
+      metricContainer.registerMetricsForPipelineResult();
       Optional.ofNullable(doFnInvoker).ifPresent(DoFnInvoker::invokeTeardown);
     } finally {
       FlinkClassloading.deleteStaticCaches();
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/SourceInputFormat.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/SourceInputFormat.java
index 850c9c57aa3..b22fd8814d1 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/SourceInputFormat.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/SourceInputFormat.java
@@ -20,7 +20,6 @@ package org.apache.beam.runners.flink.translation.wrappers;
 import java.io.IOException;
 import java.util.List;
 import org.apache.beam.runners.core.construction.SerializablePipelineOptions;
-import org.apache.beam.runners.flink.FlinkPipelineOptions;
 import org.apache.beam.runners.flink.metrics.FlinkMetricContainer;
 import org.apache.beam.runners.flink.metrics.ReaderInvocationUtil;
 import org.apache.beam.sdk.io.BoundedSource;
@@ -53,6 +52,7 @@ public class SourceInputFormat<T> extends RichInputFormat<WindowedValue<T>, Sour
   private boolean inputAvailable = false;
 
   private transient ReaderInvocationUtil<T, BoundedSource.BoundedReader<T>> readerInvoker;
+  private transient FlinkMetricContainer metricContainer;
 
   public SourceInputFormat(
       String stepName, BoundedSource<T> initialSource, PipelineOptions options) {
@@ -68,10 +68,7 @@ public class SourceInputFormat<T> extends RichInputFormat<WindowedValue<T>, Sour
 
   @Override
   public void open(SourceInputSplit<T> sourceInputSplit) throws IOException {
-    FlinkMetricContainer metricContainer =
-        new FlinkMetricContainer(
-            getRuntimeContext(),
-            options.as(FlinkPipelineOptions.class).getDisableMetricAccumulator());
+    metricContainer = new FlinkMetricContainer(getRuntimeContext());
 
     readerInvoker = new ReaderInvocationUtil<>(stepName, serializedOptions.get(), metricContainer);
 
@@ -149,6 +146,7 @@ public class SourceInputFormat<T> extends RichInputFormat<WindowedValue<T>, Sour
 
   @Override
   public void close() throws IOException {
+    metricContainer.registerMetricsForPipelineResult();
     // TODO null check can be removed once FLINK-3796 is fixed
     if (reader != null) {
       reader.close();
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java
index d1866dc6d32..822c15cb032 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java
@@ -439,8 +439,7 @@ public class DoFnOperator<InputT, OutputT> extends AbstractStreamOperator<Window
     doFnRunner = createWrappingDoFnRunner(doFnRunner);
 
     if (!options.getDisableMetrics()) {
-      flinkMetricContainer =
-          new FlinkMetricContainer(getRuntimeContext(), options.getDisableMetricAccumulator());
+      flinkMetricContainer = new FlinkMetricContainer(getRuntimeContext());
       doFnRunner = new DoFnRunnerWithMetricsUpdate<>(stepName, doFnRunner, flinkMetricContainer);
     }
 
@@ -481,6 +480,7 @@ public class DoFnOperator<InputT, OutputT> extends AbstractStreamOperator<Window
   @Override
   public void close() throws Exception {
     try {
+      flinkMetricContainer.registerMetricsForPipelineResult();
       // This is our last change to block shutdown of this operator while
       // there are still remaining processing-time timers. Flink will ignore pending
       // processing-time timers when upstream operators have shut down and will also
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/io/UnboundedSourceWrapper.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/io/UnboundedSourceWrapper.java
index 57eed1a37b2..2539687c1e7 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/io/UnboundedSourceWrapper.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/io/UnboundedSourceWrapper.java
@@ -136,6 +136,9 @@ public class UnboundedSourceWrapper<OutputT, CheckpointMarkT extends UnboundedSo
   /** false if checkpointCoder is null or no restore state by starting first. */
   private transient boolean isRestored = false;
 
+  /** Metrics container which will be reported as Flink accumulators at the end of the job. */
+  private transient FlinkMetricContainer metricContainer;
+
   @SuppressWarnings("unchecked")
   public UnboundedSourceWrapper(
       String stepName,
@@ -177,6 +180,7 @@ public class UnboundedSourceWrapper<OutputT, CheckpointMarkT extends UnboundedSo
   public void open(Configuration parameters) throws Exception {
     FileSystems.setDefaultPipelineOptions(serializedOptions.get());
     runtimeContext = (StreamingRuntimeContext) getRuntimeContext();
+    metricContainer = new FlinkMetricContainer(runtimeContext);
 
     // figure out which split sources we're responsible for
     int subtaskIndex = runtimeContext.getIndexOfThisSubtask();
@@ -220,10 +224,6 @@ public class UnboundedSourceWrapper<OutputT, CheckpointMarkT extends UnboundedSo
 
     context = ctx;
 
-    FlinkPipelineOptions options = serializedOptions.get().as(FlinkPipelineOptions.class);
-    FlinkMetricContainer metricContainer =
-        new FlinkMetricContainer(getRuntimeContext(), options.getDisableMetricAccumulator());
-
     ReaderInvocationUtil<OutputT, UnboundedSource.UnboundedReader<OutputT>> readerInvoker =
         new ReaderInvocationUtil<>(stepName, serializedOptions.get(), metricContainer);
 
@@ -349,6 +349,7 @@ public class UnboundedSourceWrapper<OutputT, CheckpointMarkT extends UnboundedSo
 
   @Override
   public void close() throws Exception {
+    metricContainer.registerMetricsForPipelineResult();
     try {
       super.close();
       if (localReaders != null) {
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineOptionsTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineOptionsTest.java
index 6c7c96585fe..c0d6ceb8b87 100644
--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineOptionsTest.java
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineOptionsTest.java
@@ -92,7 +92,6 @@ public class FlinkPipelineOptionsTest {
     assertThat(options.getSavepointPath(), is(nullValue()));
     assertThat(options.getAllowNonRestoredState(), is(false));
     assertThat(options.getDisableMetrics(), is(false));
-    assertThat(options.getDisableMetricAccumulator(), is(false));
   }
 
   @Test(expected = Exception.class)
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/metrics/FlinkMetricContainerTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/metrics/FlinkMetricContainerTest.java
index 6df49985500..a85ad65446d 100644
--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/metrics/FlinkMetricContainerTest.java
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/metrics/FlinkMetricContainerTest.java
@@ -21,8 +21,6 @@ import static org.apache.beam.runners.flink.metrics.FlinkMetricContainer.getFlin
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.Assert.assertNotNull;
-import static org.junit.runners.Parameterized.Parameter;
-import static org.junit.runners.Parameterized.Parameters;
 import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Matchers.anyObject;
 import static org.mockito.Matchers.argThat;
@@ -59,28 +57,18 @@ import org.apache.flink.metrics.MetricGroup;
 import org.apache.flink.metrics.SimpleCounter;
 import org.junit.Before;
 import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
 import org.mockito.ArgumentMatcher;
 import org.mockito.Mock;
 import org.mockito.MockitoAnnotations;
 
 /** Tests for {@link FlinkMetricContainer}. */
-@RunWith(Parameterized.class)
 public class FlinkMetricContainerTest {
 
-  @Parameter public boolean useMetricAccumulator;
-
   @Mock private RuntimeContext runtimeContext;
   @Mock private MetricGroup metricGroup;
 
   FlinkMetricContainer container;
 
-  @Parameters(name = "useMetricAccumulator: {0}")
-  public static Object[] data() {
-    return new Object[] {true, false};
-  }
-
   @Before
   public void beforeTest() {
     MockitoAnnotations.initMocks(this);
@@ -88,7 +76,7 @@ public class FlinkMetricContainerTest {
             anyString()))
         .thenReturn(new MetricsAccumulator());
     when(runtimeContext.getMetricGroup()).thenReturn(metricGroup);
-    container = new FlinkMetricContainer(runtimeContext, !useMetricAccumulator);
+    container = new FlinkMetricContainer(runtimeContext);
   }
 
   @Test
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkDoFnFunctionTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkDoFnFunctionTest.java
new file mode 100644
index 00000000000..779f9c179f4
--- /dev/null
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkDoFnFunctionTest.java
@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.runners.flink.translation.functions;
+
+import java.util.Collections;
+import java.util.Map;
+import org.apache.beam.runners.flink.metrics.FlinkMetricContainer;
+import org.apache.beam.sdk.coders.Coder;
+import org.apache.beam.sdk.options.PipelineOptions;
+import org.apache.beam.sdk.options.PipelineOptionsFactory;
+import org.apache.beam.sdk.transforms.DoFn;
+import org.apache.beam.sdk.transforms.DoFnSchemaInformation;
+import org.apache.beam.sdk.values.TupleTag;
+import org.apache.beam.sdk.values.WindowingStrategy;
+import org.apache.flink.api.common.functions.RuntimeContext;
+import org.apache.flink.configuration.Configuration;
+import org.junit.Test;
+import org.mockito.Mockito;
+import org.powermock.reflect.Whitebox;
+
+/** Tests for {@link FlinkDoFnFunction}. */
+public class FlinkDoFnFunctionTest {
+
+  @Test
+  public void testAccumulatorRegistrationOnOperatorClose() throws Exception {
+    FlinkDoFnFunction doFnFunction =
+        new TestDoFnFunction(
+            "step",
+            WindowingStrategy.globalDefault(),
+            Collections.emptyMap(),
+            PipelineOptionsFactory.create(),
+            Collections.emptyMap(),
+            new TupleTag<>(),
+            null,
+            Collections.emptyMap(),
+            DoFnSchemaInformation.create(),
+            Collections.emptyMap());
+
+    doFnFunction.open(new Configuration());
+
+    String metricContainerFieldName = "metricContainer";
+    FlinkMetricContainer monitoredContainer =
+        Mockito.spy(
+            (FlinkMetricContainer)
+                Whitebox.getInternalState(doFnFunction, metricContainerFieldName));
+    Whitebox.setInternalState(doFnFunction, metricContainerFieldName, monitoredContainer);
+
+    doFnFunction.close();
+    Mockito.verify(monitoredContainer).registerMetricsForPipelineResult();
+  }
+
+  private static class TestDoFnFunction extends FlinkDoFnFunction {
+
+    public TestDoFnFunction(
+        String stepName,
+        WindowingStrategy windowingStrategy,
+        Map sideInputs,
+        PipelineOptions options,
+        Map outputMap,
+        TupleTag mainOutputTag,
+        Coder inputCoder,
+        Map outputCoderMap,
+        DoFnSchemaInformation doFnSchemaInformation,
+        Map sideInputMapping) {
+      super(
+          new IdentityFn(),
+          stepName,
+          windowingStrategy,
+          sideInputs,
+          options,
+          outputMap,
+          mainOutputTag,
+          inputCoder,
+          outputCoderMap,
+          doFnSchemaInformation,
+          sideInputMapping);
+    }
+
+    @Override
+    public RuntimeContext getRuntimeContext() {
+      return Mockito.mock(RuntimeContext.class);
+    }
+
+    private static class IdentityFn<T> extends DoFn<T, T> {
+      @ProcessElement
+      public void processElement(ProcessContext c) {
+        c.output(c.element());
+      }
+    }
+  }
+}
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkExecutableStageFunctionTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkExecutableStageFunctionTest.java
index 93f7cd2bcaa..89af4d3022c 100644
--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkExecutableStageFunctionTest.java
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkExecutableStageFunctionTest.java
@@ -32,6 +32,7 @@ import org.apache.beam.model.pipeline.v1.RunnerApi;
 import org.apache.beam.model.pipeline.v1.RunnerApi.Components;
 import org.apache.beam.model.pipeline.v1.RunnerApi.ExecutableStagePayload;
 import org.apache.beam.model.pipeline.v1.RunnerApi.PCollection;
+import org.apache.beam.runners.flink.metrics.FlinkMetricContainer;
 import org.apache.beam.runners.fnexecution.control.BundleProgressHandler;
 import org.apache.beam.runners.fnexecution.control.ExecutableStageContext;
 import org.apache.beam.runners.fnexecution.control.OutputReceiverFactory;
@@ -248,6 +249,21 @@ public class FlinkExecutableStageFunctionTest {
     verifyNoMoreInteractions(stageBundleFactory);
   }
 
+  @Test
+  public void testAccumulatorRegistrationOnOperatorClose() throws Exception {
+    FlinkExecutableStageFunction<Integer> function = getFunction(Collections.emptyMap());
+    function.open(new Configuration());
+
+    String metricContainerFieldName = "metricContainer";
+    FlinkMetricContainer monitoredContainer =
+        Mockito.spy(
+            (FlinkMetricContainer) Whitebox.getInternalState(function, metricContainerFieldName));
+    Whitebox.setInternalState(function, metricContainerFieldName, monitoredContainer);
+
+    function.close();
+    Mockito.verify(monitoredContainer).registerMetricsForPipelineResult();
+  }
+
   /**
    * Creates a {@link FlinkExecutableStageFunction}. Sets the runtime context to {@link
    * #runtimeContext}. The context factory is mocked to return {@link #stageContext} every time. The
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkStatefulDoFnFunctionTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkStatefulDoFnFunctionTest.java
new file mode 100644
index 00000000000..4f9707cf729
--- /dev/null
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/functions/FlinkStatefulDoFnFunctionTest.java
@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.runners.flink.translation.functions;
+
+import java.util.Collections;
+import java.util.Map;
+import org.apache.beam.runners.flink.metrics.FlinkMetricContainer;
+import org.apache.beam.sdk.coders.Coder;
+import org.apache.beam.sdk.options.PipelineOptions;
+import org.apache.beam.sdk.options.PipelineOptionsFactory;
+import org.apache.beam.sdk.transforms.DoFn;
+import org.apache.beam.sdk.transforms.DoFnSchemaInformation;
+import org.apache.beam.sdk.values.TupleTag;
+import org.apache.beam.sdk.values.WindowingStrategy;
+import org.apache.flink.api.common.functions.RuntimeContext;
+import org.apache.flink.configuration.Configuration;
+import org.junit.Test;
+import org.mockito.Mockito;
+import org.powermock.reflect.Whitebox;
+
+/** Tests for {@link FlinkStatefulDoFnFunction}. */
+public class FlinkStatefulDoFnFunctionTest {
+
+  @Test
+  public void testAccumulatorRegistrationOnOperatorClose() throws Exception {
+    FlinkStatefulDoFnFunction doFnFunction =
+        new TestDoFnFunction(
+            "step",
+            WindowingStrategy.globalDefault(),
+            Collections.emptyMap(),
+            PipelineOptionsFactory.create(),
+            Collections.emptyMap(),
+            new TupleTag<>(),
+            null,
+            Collections.emptyMap(),
+            DoFnSchemaInformation.create(),
+            Collections.emptyMap());
+
+    doFnFunction.open(new Configuration());
+
+    String metricContainerFieldName = "metricContainer";
+    FlinkMetricContainer monitoredContainer =
+        Mockito.spy(
+            (FlinkMetricContainer)
+                Whitebox.getInternalState(doFnFunction, metricContainerFieldName));
+    Whitebox.setInternalState(doFnFunction, metricContainerFieldName, monitoredContainer);
+
+    doFnFunction.close();
+    Mockito.verify(monitoredContainer).registerMetricsForPipelineResult();
+  }
+
+  private static class TestDoFnFunction extends FlinkStatefulDoFnFunction {
+
+    public TestDoFnFunction(
+        String stepName,
+        WindowingStrategy windowingStrategy,
+        Map sideInputs,
+        PipelineOptions options,
+        Map outputMap,
+        TupleTag mainOutputTag,
+        Coder inputCoder,
+        Map outputCoderMap,
+        DoFnSchemaInformation doFnSchemaInformation,
+        Map sideInputMapping) {
+      super(
+          new IdentityFn(),
+          stepName,
+          windowingStrategy,
+          sideInputs,
+          options,
+          outputMap,
+          mainOutputTag,
+          inputCoder,
+          outputCoderMap,
+          doFnSchemaInformation,
+          sideInputMapping);
+    }
+
+    @Override
+    public RuntimeContext getRuntimeContext() {
+      return Mockito.mock(RuntimeContext.class);
+    }
+
+    private static class IdentityFn<T> extends DoFn<T, T> {
+      @ProcessElement
+      public void processElement(ProcessContext c) {
+        c.output(c.element());
+      }
+    }
+  }
+}
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/SourceInputFormatTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/SourceInputFormatTest.java
new file mode 100644
index 00000000000..4e8affd3c25
--- /dev/null
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/SourceInputFormatTest.java
@@ -0,0 +1,64 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.runners.flink.translation.wrappers;
+
+import org.apache.beam.runners.flink.metrics.FlinkMetricContainer;
+import org.apache.beam.sdk.io.BoundedSource;
+import org.apache.beam.sdk.io.CountingSource;
+import org.apache.beam.sdk.options.PipelineOptions;
+import org.apache.beam.sdk.options.PipelineOptionsFactory;
+import org.apache.flink.api.common.functions.RuntimeContext;
+import org.junit.Test;
+import org.mockito.Mockito;
+import org.powermock.reflect.Whitebox;
+
+/** Tests for {@link SourceInputFormat}. */
+public class SourceInputFormatTest {
+
+  @Test
+  public void testAccumulatorRegistrationOnOperatorClose() throws Exception {
+    SourceInputFormat<Long> sourceInputFormat =
+        new TestSourceInputFormat<>(
+            "step", CountingSource.upTo(10), PipelineOptionsFactory.create());
+
+    sourceInputFormat.open(sourceInputFormat.createInputSplits(1)[0]);
+
+    String metricContainerFieldName = "metricContainer";
+    FlinkMetricContainer monitoredContainer =
+        Mockito.spy(
+            (FlinkMetricContainer)
+                Whitebox.getInternalState(sourceInputFormat, metricContainerFieldName));
+    Whitebox.setInternalState(sourceInputFormat, metricContainerFieldName, monitoredContainer);
+
+    sourceInputFormat.close();
+    Mockito.verify(monitoredContainer).registerMetricsForPipelineResult();
+  }
+
+  private static class TestSourceInputFormat<T> extends SourceInputFormat<T> {
+
+    public TestSourceInputFormat(
+        String stepName, BoundedSource initialSource, PipelineOptions options) {
+      super(stepName, initialSource, options);
+    }
+
+    @Override
+    public RuntimeContext getRuntimeContext() {
+      return Mockito.mock(RuntimeContext.class);
+    }
+  }
+}
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperatorTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperatorTest.java
index 220ffc92ee1..235a2e3b204 100644
--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperatorTest.java
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperatorTest.java
@@ -39,6 +39,7 @@ import java.util.stream.Collectors;
 import javax.annotation.Nullable;
 import org.apache.beam.runners.core.StatefulDoFnRunner;
 import org.apache.beam.runners.flink.FlinkPipelineOptions;
+import org.apache.beam.runners.flink.metrics.FlinkMetricContainer;
 import org.apache.beam.runners.flink.translation.types.CoderTypeInformation;
 import org.apache.beam.runners.flink.translation.types.CoderTypeSerializer;
 import org.apache.beam.sdk.Pipeline;
@@ -94,6 +95,7 @@ import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
+import org.mockito.Mockito;
 import org.powermock.reflect.Whitebox;
 
 /** Tests for {@link DoFnOperator}. */
@@ -1874,13 +1876,43 @@ public class DoFnOperatorTest {
     assertThrows(Error.class, () -> testHarness.snapshot(0, 0));
   }
 
+  @Test
+  public void testAccumulatorRegistrationOnOperatorClose() throws Exception {
+    DoFnOperator doFnOperator = getOperatorForCleanupInspection();
+    OneInputStreamOperatorTestHarness<WindowedValue<String>, WindowedValue<String>> testHarness =
+        new OneInputStreamOperatorTestHarness<>(doFnOperator);
+
+    testHarness.open();
+
+    String metricContainerFieldName = "flinkMetricContainer";
+    FlinkMetricContainer monitoredContainer =
+        Mockito.spy(
+            (FlinkMetricContainer)
+                Whitebox.getInternalState(doFnOperator, metricContainerFieldName));
+    Whitebox.setInternalState(doFnOperator, metricContainerFieldName, monitoredContainer);
+
+    testHarness.close();
+    Mockito.verify(monitoredContainer).registerMetricsForPipelineResult();
+  }
+
   /**
    * Ensures Jackson cache is cleaned to get rid of any references to the Flink Classloader. See
    * https://jira.apache.org/jira/browse/BEAM-6460
    */
   @Test
   public void testRemoveCachedClassReferences() throws Exception {
+    OneInputStreamOperatorTestHarness<WindowedValue<String>, WindowedValue<String>> testHarness =
+        new OneInputStreamOperatorTestHarness<>(getOperatorForCleanupInspection());
+
+    LRUMap typeCache =
+        (LRUMap) Whitebox.getInternalState(TypeFactory.defaultInstance(), "_typeCache");
+    assertThat(typeCache.size(), greaterThan(0));
+    testHarness.open();
+    testHarness.close();
+    assertThat(typeCache.size(), is(0));
+  }
 
+  private static DoFnOperator getOperatorForCleanupInspection() {
     FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);
     options.setParallelism(4);
 
@@ -1901,34 +1933,23 @@ public class DoFnOperatorTest {
             outputTag,
             WindowedValue.getFullCoder(StringUtf8Coder.of(), GlobalWindow.Coder.INSTANCE));
 
-    DoFnOperator<String, String> doFnOperator =
-        new DoFnOperator<>(
-            doFn,
-            "stepName",
-            windowedValueCoder,
-            null,
-            Collections.emptyMap(),
-            outputTag,
-            Collections.emptyList(),
-            outputManagerFactory,
-            WindowingStrategy.globalDefault(),
-            new HashMap<>(), /* side-input mapping */
-            Collections.emptyList(), /* side inputs */
-            options,
-            null,
-            null,
-            DoFnSchemaInformation.create(),
-            Collections.emptyMap());
-
-    OneInputStreamOperatorTestHarness<WindowedValue<String>, WindowedValue<String>> testHarness =
-        new OneInputStreamOperatorTestHarness<>(doFnOperator);
-
-    LRUMap typeCache =
-        (LRUMap) Whitebox.getInternalState(TypeFactory.defaultInstance(), "_typeCache");
-    assertThat(typeCache.size(), greaterThan(0));
-    testHarness.open();
-    testHarness.close();
-    assertThat(typeCache.size(), is(0));
+    return new DoFnOperator<>(
+        doFn,
+        "stepName",
+        windowedValueCoder,
+        null,
+        Collections.emptyMap(),
+        outputTag,
+        Collections.emptyList(),
+        outputManagerFactory,
+        WindowingStrategy.globalDefault(),
+        new HashMap<>(), /* side-input mapping */
+        Collections.emptyList(), /* side inputs */
+        options,
+        null,
+        null,
+        DoFnSchemaInformation.create(),
+        Collections.emptyMap());
   }
 
   private Iterable<WindowedValue<String>> stripStreamRecord(Iterable<?> input) {
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/streaming/io/UnboundedSourceWrapperTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/streaming/io/UnboundedSourceWrapperTest.java
index 7b0f9b89e31..5a04f7ecdad 100644
--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/streaming/io/UnboundedSourceWrapperTest.java
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/translation/wrappers/streaming/io/UnboundedSourceWrapperTest.java
@@ -36,6 +36,7 @@ import java.util.concurrent.CountDownLatch;
 import java.util.stream.LongStream;
 import org.apache.beam.runners.core.construction.UnboundedReadFromBoundedSource;
 import org.apache.beam.runners.flink.FlinkPipelineOptions;
+import org.apache.beam.runners.flink.metrics.FlinkMetricContainer;
 import org.apache.beam.runners.flink.streaming.StreamSources;
 import org.apache.beam.sdk.coders.Coder;
 import org.apache.beam.sdk.io.CountingSource;
@@ -71,6 +72,7 @@ import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
 import org.junit.runners.Parameterized;
 import org.mockito.Mockito;
+import org.powermock.reflect.Whitebox;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -775,6 +777,34 @@ public class UnboundedSourceWrapperTest {
                   .boxed()
                   .toArray()));
     }
+
+    @Test
+    public void testAccumulatorRegistrationOnOperatorClose() throws Exception {
+      FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);
+
+      TestCountingSource source = new TestCountingSource(20).withoutSplitting();
+
+      UnboundedSourceWrapper<KV<Integer, Integer>, TestCountingSource.CounterMark> sourceWrapper =
+          new UnboundedSourceWrapper<>("noReader", options, source, 2);
+
+      StreamingRuntimeContext mock = Mockito.mock(StreamingRuntimeContext.class);
+      Mockito.when(mock.getNumberOfParallelSubtasks()).thenReturn(1);
+      Mockito.when(mock.getExecutionConfig()).thenReturn(new ExecutionConfig());
+      Mockito.when(mock.getIndexOfThisSubtask()).thenReturn(0);
+      sourceWrapper.setRuntimeContext(mock);
+
+      sourceWrapper.open(new Configuration());
+
+      String metricContainerFieldName = "metricContainer";
+      FlinkMetricContainer monitoredContainer =
+          Mockito.spy(
+              (FlinkMetricContainer)
+                  Whitebox.getInternalState(sourceWrapper, metricContainerFieldName));
+      Whitebox.setInternalState(sourceWrapper, metricContainerFieldName, monitoredContainer);
+
+      sourceWrapper.close();
+      Mockito.verify(monitoredContainer).registerMetricsForPipelineResult();
+    }
   }
 
   private static final class TestStreamStatusMaintainer implements StreamStatusMaintainer {
diff --git a/website/src/_includes/flink_java_pipeline_options.html b/website/src/_includes/flink_java_pipeline_options.html
index 943f2f16473..4495a33ba58 100644
--- a/website/src/_includes/flink_java_pipeline_options.html
+++ b/website/src/_includes/flink_java_pipeline_options.html
@@ -47,11 +47,6 @@ which should be called before running the tests.
   <td>The checkpointing mode that defines consistency guarantee.</td>
   <td>Default: <code>EXACTLY_ONCE</code></td>
 </tr>
-<tr>
-  <td><code>disableMetricAccumulator</code></td>
-  <td>By default, uses Flink accumulators to store the metrics which allows to query metrics from the PipelineResult. If set to true, metrics will still be reported but can't be queried via PipelineResult. This saves network and memory.</td>
-  <td>Default: <code>false</code></td>
-</tr>
 <tr>
   <td><code>disableMetrics</code></td>
   <td>Disable Beam metrics in Flink Runner</td>
diff --git a/website/src/_includes/flink_python_pipeline_options.html b/website/src/_includes/flink_python_pipeline_options.html
index 6052477e9d1..b57c4330f4e 100644
--- a/website/src/_includes/flink_python_pipeline_options.html
+++ b/website/src/_includes/flink_python_pipeline_options.html
@@ -47,11 +47,6 @@ which should be called before running the tests.
   <td>The checkpointing mode that defines consistency guarantee.</td>
   <td>Default: <code>EXACTLY_ONCE</code></td>
 </tr>
-<tr>
-  <td><code>disable_metric_accumulator</code></td>
-  <td>By default, uses Flink accumulators to store the metrics which allows to query metrics from the PipelineResult. If set to true, metrics will still be reported but can't be queried via PipelineResult. This saves network and memory.</td>
-  <td>Default: <code>false</code></td>
-</tr>
 <tr>
   <td><code>disable_metrics</code></td>
   <td>Disable Beam metrics in Flink Runner</td>
