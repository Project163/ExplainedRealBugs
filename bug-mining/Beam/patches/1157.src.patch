diff --git a/sdks/java/io/kafka/build.gradle b/sdks/java/io/kafka/build.gradle
index 5e825d4dfd5..830fb9cc086 100644
--- a/sdks/java/io/kafka/build.gradle
+++ b/sdks/java/io/kafka/build.gradle
@@ -37,6 +37,7 @@ dependencies {
   testCompile library.java.hamcrest_core
   testCompile library.java.hamcrest_library
   testCompile library.java.junit
+  testCompile library.java.powermock
   testCompile library.java.slf4j_jdk14
   testRuntimeOnly project(path: ":beam-runners-direct-java")
 }
diff --git a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ConsumerSpEL.java b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ConsumerSpEL.java
index a1bbac9cbc1..16fda1e53ae 100644
--- a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ConsumerSpEL.java
+++ b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ConsumerSpEL.java
@@ -53,12 +53,12 @@ class ConsumerSpEL {
 
   private boolean hasRecordTimestamp = false;
   private boolean hasOffsetsForTimes = false;
-  static boolean hasHeaders = false;
 
-  static {
+  static boolean hasHeaders() {
+    boolean clientHasHeaders = false;
     try {
       // It is supported by Kafka Client 0.11.0.0 onwards.
-      hasHeaders =
+      clientHasHeaders =
           "org.apache.kafka.common.header.Headers"
               .equals(
                   ConsumerRecord.class
@@ -68,6 +68,7 @@ class ConsumerSpEL {
     } catch (NoSuchMethodException | SecurityException e) {
       LOG.debug("Headers is not available");
     }
+    return clientHasHeaders;
   }
 
   public ConsumerSpEL() {
diff --git a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaRecord.java b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaRecord.java
index 18c34362835..b59d3faac36 100644
--- a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaRecord.java
+++ b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaRecord.java
@@ -82,7 +82,7 @@ public class KafkaRecord<K, V> {
   }
 
   public Headers getHeaders() {
-    if (!ConsumerSpEL.hasHeaders) {
+    if (!ConsumerSpEL.hasHeaders()) {
       throw new RuntimeException(
           "The version kafka-clients does not support record headers, "
               + "please use version 0.11.0.0 or newer");
diff --git a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaRecordCoder.java b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaRecordCoder.java
index bd46f711cf4..c7f40abbf4f 100644
--- a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaRecordCoder.java
+++ b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaRecordCoder.java
@@ -79,7 +79,7 @@ public class KafkaRecordCoder<K, V> extends StructuredCoder<KafkaRecord<K, V>> {
   }
 
   private Object toHeaders(Iterable<KV<String, byte[]>> records) {
-    if (!ConsumerSpEL.hasHeaders) {
+    if (!ConsumerSpEL.hasHeaders()) {
       return null;
     }
 
@@ -90,7 +90,7 @@ public class KafkaRecordCoder<K, V> extends StructuredCoder<KafkaRecord<K, V>> {
   }
 
   private Iterable<KV<String, byte[]>> toIterable(KafkaRecord record) {
-    if (!ConsumerSpEL.hasHeaders) {
+    if (!ConsumerSpEL.hasHeaders()) {
       return Collections.emptyList();
     }
 
@@ -129,7 +129,7 @@ public class KafkaRecordCoder<K, V> extends StructuredCoder<KafkaRecord<K, V>> {
           value.getOffset(),
           value.getTimestamp(),
           value.getTimestampType(),
-          !ConsumerSpEL.hasHeaders ? null : value.getHeaders(),
+          !ConsumerSpEL.hasHeaders() ? null : value.getHeaders(),
           (KV<Object, Object>) kvCoder.structuralValue(value.getKV()));
     }
   }
diff --git a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaUnboundedReader.java b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaUnboundedReader.java
index 580b0bcfda9..a0a7d941c3c 100644
--- a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaUnboundedReader.java
+++ b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaUnboundedReader.java
@@ -208,7 +208,7 @@ class KafkaUnboundedReader<K, V> extends UnboundedReader<KafkaRecord<K, V>> {
                 rawRecord.offset(),
                 consumerSpEL.getRecordTimestamp(rawRecord),
                 consumerSpEL.getRecordTimestampType(rawRecord),
-                ConsumerSpEL.hasHeaders ? rawRecord.headers() : null,
+                ConsumerSpEL.hasHeaders() ? rawRecord.headers() : null,
                 keyDeserializerInstance.deserialize(rawRecord.topic(), rawRecord.key()),
                 valueDeserializerInstance.deserialize(rawRecord.topic(), rawRecord.value()));
 
diff --git a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ProducerRecordCoder.java b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ProducerRecordCoder.java
index 48a50276cd1..b2f8a6929d4 100644
--- a/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ProducerRecordCoder.java
+++ b/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/ProducerRecordCoder.java
@@ -79,14 +79,14 @@ public class ProducerRecordCoder<K, V> extends StructuredCoder<ProducerRecord<K,
 
     Headers headers = (Headers) toHeaders(headerCoder.decode(inStream));
     KV<K, V> kv = kvCoder.decode(inStream);
-    if (ConsumerSpEL.hasHeaders) {
+    if (ConsumerSpEL.hasHeaders()) {
       return new ProducerRecord<>(topic, partition, timestamp, kv.getKey(), kv.getValue(), headers);
     }
     return new ProducerRecord<>(topic, partition, timestamp, kv.getKey(), kv.getValue());
   }
 
   private Object toHeaders(Iterable<KV<String, byte[]>> records) {
-    if (!ConsumerSpEL.hasHeaders) {
+    if (!ConsumerSpEL.hasHeaders()) {
       return null;
     }
 
@@ -97,7 +97,7 @@ public class ProducerRecordCoder<K, V> extends StructuredCoder<ProducerRecord<K,
   }
 
   private Iterable<KV<String, byte[]>> toIterable(ProducerRecord record) {
-    if (!ConsumerSpEL.hasHeaders) {
+    if (!ConsumerSpEL.hasHeaders()) {
       return Collections.emptyList();
     }
     List<KV<String, byte[]>> vals = new ArrayList<>();
@@ -128,13 +128,18 @@ public class ProducerRecordCoder<K, V> extends StructuredCoder<ProducerRecord<K,
     if (consistentWithEquals()) {
       return value;
     } else {
-      return new ProducerRecord<>(
-          value.topic(),
-          value.partition(),
-          value.timestamp(),
-          value.key(),
-          value.value(),
-          value.headers());
+      if (!ConsumerSpEL.hasHeaders()) {
+        return new ProducerRecord<>(
+            value.topic(), value.partition(), value.timestamp(), value.key(), value.value());
+      } else {
+        return new ProducerRecord<>(
+            value.topic(),
+            value.partition(),
+            value.timestamp(),
+            value.key(),
+            value.value(),
+            value.headers());
+      }
     }
   }
 
diff --git a/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/ProducerRecordCoderTest.java b/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/ProducerRecordCoderTest.java
index 760d0f92d0a..5b489ead47b 100644
--- a/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/ProducerRecordCoderTest.java
+++ b/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/ProducerRecordCoderTest.java
@@ -17,13 +17,16 @@
  */
 package org.apache.beam.sdk.io.kafka;
 
+import static java.nio.charset.StandardCharsets.UTF_8;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNull;
+import static org.mockito.Mockito.when;
+import static org.powermock.api.mockito.PowerMockito.mockStatic;
 
 import java.io.ByteArrayInputStream;
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
-import java.nio.charset.StandardCharsets;
+import org.apache.beam.sdk.coders.ByteArrayCoder;
 import org.apache.beam.sdk.coders.StringUtf8Coder;
 import org.apache.beam.sdk.testing.CoderProperties;
 import org.apache.beam.sdk.transforms.windowing.GlobalWindow;
@@ -33,10 +36,12 @@ import org.apache.kafka.common.header.Headers;
 import org.apache.kafka.common.header.internals.RecordHeaders;
 import org.junit.Test;
 import org.junit.runner.RunWith;
-import org.junit.runners.JUnit4;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
 
 /** Tests for {@link ProducerRecordCoder}. */
-@RunWith(JUnit4.class)
+@RunWith(PowerMockRunner.class)
+@PrepareForTest(ConsumerSpEL.class)
 public class ProducerRecordCoderTest {
   @Test
   public void testCoderIsSerializableWithWellKnownCoderType() {
@@ -47,7 +52,7 @@ public class ProducerRecordCoderTest {
   @Test
   public void testProducerRecordSerializableWithHeaders() throws IOException {
     RecordHeaders headers = new RecordHeaders();
-    headers.add("headerKey", "headerVal".getBytes(StandardCharsets.UTF_8));
+    headers.add("headerKey", "headerVal".getBytes(UTF_8));
     verifySerialization(headers, 0, System.currentTimeMillis());
   }
 
@@ -84,6 +89,37 @@ public class ProducerRecordCoderTest {
     assertNull(decodedRecord.timestamp());
   }
 
+  @Test
+  public void testProducerRecordStructuralValueWithHeadersApi() throws IOException {
+    RecordHeaders headers = new RecordHeaders();
+    headers.add("headerKey", "headerVal".getBytes(UTF_8));
+    ProducerRecordCoder producerRecordCoder =
+        ProducerRecordCoder.of(ByteArrayCoder.of(), ByteArrayCoder.of());
+    ProducerRecord<byte[], byte[]> producerRecord =
+        new ProducerRecord<>(
+            "topic", 1, null, "key".getBytes(UTF_8), "value".getBytes(UTF_8), headers);
+
+    ProducerRecord testProducerRecord =
+        (ProducerRecord) producerRecordCoder.structuralValue(producerRecord);
+    assertEquals(testProducerRecord.headers(), headers);
+  }
+
+  @Test
+  public void testProducerRecordStructuralValueWithoutHeadersApi() throws IOException {
+    RecordHeaders headers = new RecordHeaders();
+    headers.add("headerKey", "headerVal".getBytes(UTF_8));
+    ProducerRecordCoder producerRecordCoder =
+        ProducerRecordCoder.of(ByteArrayCoder.of(), ByteArrayCoder.of());
+    ProducerRecord<byte[], byte[]> producerRecord =
+        new ProducerRecord<>(
+            "topic", 1, null, "key".getBytes(UTF_8), "value".getBytes(UTF_8), headers);
+    mockStatic(ConsumerSpEL.class);
+    when(ConsumerSpEL.hasHeaders()).thenReturn(false);
+    ProducerRecord testProducerRecord =
+        (ProducerRecord) producerRecordCoder.structuralValue(producerRecord);
+    assertEquals(testProducerRecord.headers(), new RecordHeaders());
+  }
+
   private ProducerRecord<String, String> verifySerialization(Integer partition, Long timestamp)
       throws IOException {
     return verifySerialization(null, partition, timestamp);
