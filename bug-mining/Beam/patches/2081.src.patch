diff --git a/sdks/python/apache_beam/runners/dataflow/dataflow_metrics.py b/sdks/python/apache_beam/runners/dataflow/dataflow_metrics.py
index 0b242bcd63b..9bb1170ea9c 100644
--- a/sdks/python/apache_beam/runners/dataflow/dataflow_metrics.py
+++ b/sdks/python/apache_beam/runners/dataflow/dataflow_metrics.py
@@ -97,16 +97,34 @@ class DataflowMetrics(MetricResults):
   def _translate_step_name(self, internal_name):
     """Translate between internal step names (e.g. "s1") and user step names."""
     if not self._job_graph:
-      raise ValueError('Could not translate the internal step name.')
-
-    try:
-      step = _get_match(
-          self._job_graph.proto.steps, lambda x: x.name == internal_name)
-      user_step_name = _get_match(
-          step.properties.additionalProperties,
-          lambda x: x.key == 'user_name').value.string_value
-    except ValueError:
-      raise ValueError('Could not translate the internal step name.')
+      raise ValueError(
+          'Could not translate the internal step name %r since job graph is '
+          'not available.' % internal_name)
+    user_step_name = None
+    # pylint: disable=wrong-import-order, wrong-import-position
+    from apache_beam.runners.dataflow.internal import apiclient
+    if apiclient._use_unified_worker_portable_job(self._job_graph.options):
+      # Dataflow Runner v2 with portable job submission uses proto transform map
+      # IDs for step names. Also PTransform.unique_name maps to user step names.
+      # Hence we lookup user step names based on the proto.
+      proto_pipeline = self._job_graph.proto_pipeline
+      for transform_id in proto_pipeline.components.transforms.keys():
+        if internal_name == transform_id:
+          user_step_name = proto_pipeline.components.transforms[
+              transform_id].unique_name
+          break
+    else:
+      try:
+        step = _get_match(
+            self._job_graph.proto.steps, lambda x: x.name == internal_name)
+        user_step_name = _get_match(
+            step.properties.additionalProperties,
+            lambda x: x.key == 'user_name').value.string_value
+      except ValueError:
+        pass  # Exception is handled below.
+    if not user_step_name:
+      raise ValueError(
+          'Could not translate the internal step name %r.' % internal_name)
     return user_step_name
 
   def _get_metric_key(self, metric):
diff --git a/sdks/python/apache_beam/runners/dataflow/dataflow_metrics_test.py b/sdks/python/apache_beam/runners/dataflow/dataflow_metrics_test.py
index 52c334ccbd0..daa01b77162 100644
--- a/sdks/python/apache_beam/runners/dataflow/dataflow_metrics_test.py
+++ b/sdks/python/apache_beam/runners/dataflow/dataflow_metrics_test.py
@@ -30,14 +30,28 @@ from builtins import object
 
 import mock
 
+from apache_beam import DoFn
+from apache_beam import ParDo
 from apache_beam.metrics.cells import DistributionData
 from apache_beam.metrics.cells import DistributionResult
 from apache_beam.metrics.execution import MetricKey
 from apache_beam.metrics.execution import MetricResult
 from apache_beam.metrics.metricbase import MetricName
+from apache_beam.options.pipeline_options import PipelineOptions
+from apache_beam.pipeline import Pipeline
 from apache_beam.runners.dataflow import dataflow_metrics
 from apache_beam.testing import metric_result_matchers
 from apache_beam.testing.metric_result_matchers import MetricResultMatcher
+from apache_beam.transforms import Create
+from apache_beam.transforms.environments import DockerEnvironment
+
+# Protect against environments where apitools library is not available.
+# pylint: disable=wrong-import-order, wrong-import-position
+try:
+  from apache_beam.runners.dataflow.internal import apiclient
+except ImportError:
+  apiclient = None  # type: ignore
+# pylint: enable=wrong-import-order, wrong-import-position
 
 
 class DictToObject(object):
@@ -486,6 +500,31 @@ class TestDataflowMetrics(unittest.TestCase):
     ]
     self.assertEqual(query_result['distributions'], expected_distributions)
 
+  @unittest.skipIf(apiclient is None, 'GCP dependencies are not installed')
+  def test_translate_portable_job_step_name(self):
+    mock_client, mock_job_result = self.setup_mock_client_result(
+        self.ONLY_COUNTERS_LIST)
+
+    pipeline_options = PipelineOptions([
+        '--experiments=use_runner_v2',
+        '--experiments=use_portable_job_submission',
+        '--temp_location=gs://any-location/temp',
+        '--project=dummy_project',
+    ])
+
+    pipeline = Pipeline(options=pipeline_options)
+    pipeline | Create([1, 2, 3]) | 'MyTestParDo' >> ParDo(DoFn())  # pylint:disable=expression-not-assigned
+
+    test_environment = DockerEnvironment(container_image='test_default_image')
+    proto_pipeline, _ = pipeline.to_runner_api(
+        return_context=True, default_environment=test_environment)
+
+    job = apiclient.Job(pipeline_options, proto_pipeline)
+    dm = dataflow_metrics.DataflowMetrics(mock_client, mock_job_result, job)
+    self.assertEqual(
+        'MyTestParDo',
+        dm._translate_step_name('ref_AppliedPTransform_MyTestParDo_14'))
+
   def test_query_counters(self):
     mock_client, mock_job_result = self.setup_mock_client_result(
         self.ONLY_COUNTERS_LIST)
diff --git a/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py b/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py
index b9de09bab37..1dadcb50064 100644
--- a/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py
+++ b/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py
@@ -1048,6 +1048,14 @@ def _use_unified_worker(pipeline_options):
   return debug_options.lookup_experiment(use_unified_worker_flag)
 
 
+def _use_unified_worker_portable_job(pipeline_options):
+  portable_job_flag = 'use_portable_job_submission'
+  debug_options = pipeline_options.view_as(DebugOptions)
+  return (
+      _use_unified_worker(pipeline_options) and
+      debug_options.lookup_experiment(portable_job_flag))
+
+
 def _get_container_image_tag():
   base_version = pkg_resources.parse_version(
       beam_version.__version__).base_version
