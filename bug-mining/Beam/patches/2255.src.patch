diff --git a/sdks/python/apache_beam/dataframe/doctests.py b/sdks/python/apache_beam/dataframe/doctests.py
index 2480578ff7c..8cb2d8f7572 100644
--- a/sdks/python/apache_beam/dataframe/doctests.py
+++ b/sdks/python/apache_beam/dataframe/doctests.py
@@ -193,7 +193,7 @@ class _DeferrredDataframeOutputChecker(doctest.OutputChecker):
   def compute_using_session(self, to_compute):
     session = expressions.PartitioningSession(self._env._inputs)
     return {
-        name: frame._expr.evaluate_at(session)
+        name: session.evaluate(frame._expr)
         for name,
         frame in to_compute.items()
     }
@@ -238,6 +238,50 @@ class _DeferrredDataframeOutputChecker(doctest.OutputChecker):
         for name, frame in computed.items():
           got = got.replace(name, repr(frame))
 
+        # If a multiindex is used, compensate for it
+        if any(isinstance(frame, pd.core.generic.NDFrame) and
+               frame.index.nlevels > 1 for frame in computed.values()):
+
+          def fill_multiindex(text):
+            """An awful hack to work around the fact that pandas omits repeated
+            elements in a multi-index.
+            For example:
+
+              Series name  Row ID
+              s1           0         a
+                           1         b
+              s2           0         c
+                           1         d
+              dtype: object
+
+            The s1 and s2 are implied for the 2nd and 4th rows. However if we
+            re-order this Series it might be printed this way:
+
+              Series name  Row ID
+              s1           0         a
+              s2           1         d
+              s2           0         c
+              s1           1         b
+              dtype: object
+
+            In our model these are equivalent, but when we sort the lines and
+            check equality they are not. This method fills in any omitted
+            multiindex values, so that we can successfully sort and compare."""
+            lines = [list(line) for line in text.split('\n')]
+            for prev, line in zip(lines[:-1], lines[1:]):
+              if all(l == ' ' for l in line):
+                continue
+
+              for i, l in enumerate(line):
+                if l != ' ':
+                  break
+                line[i] = prev[i]
+
+            return '\n'.join(''.join(line) for line in lines)
+
+          got = fill_multiindex(got)
+          want = fill_multiindex(want)
+
         def sort_and_normalize(text):
           return '\n'.join(
               sorted(
diff --git a/sdks/python/apache_beam/dataframe/frames.py b/sdks/python/apache_beam/dataframe/frames.py
index 6ee0c0eee65..994048e13bf 100644
--- a/sdks/python/apache_beam/dataframe/frames.py
+++ b/sdks/python/apache_beam/dataframe/frames.py
@@ -116,13 +116,21 @@ class DeferredDataFrameOrSeries(frame_base.DeferredFrame):
   @frame_base.args_to_kwargs(pd.DataFrame)
   @frame_base.populate_defaults(pd.DataFrame)
   @frame_base.maybe_inplace
-  def fillna(self, value, method, axis, **kwargs):
+  def fillna(self, value, method, axis, limit, **kwargs):
+    # Default value is None, but is overriden with index.
+    axis = axis or 'index'
     if method is not None and axis in (0, 'index'):
       raise frame_base.WontImplementError('order-sensitive')
     if isinstance(value, frame_base.DeferredBase):
       value_expr = value._expr
     else:
       value_expr = expressions.ConstantExpression(value)
+
+    if limit is not None and method is None:
+      # If method is not None (and axis is 'columns'), we can do limit in
+      # a distributed way. Else, it is order sensitive.
+      raise frame_base.WontImplementError('order-sensitive')
+
     return frame_base.DeferredFrame.wrap(
         # yapf: disable
         expressions.ComputedExpression(
@@ -646,7 +654,14 @@ class DeferredSeries(DeferredDataFrameOrSeries):
   @frame_base.args_to_kwargs(pd.Series)
   @frame_base.populate_defaults(pd.Series)
   @frame_base.maybe_inplace
-  def replace(self, limit, **kwargs):
+  def replace(self, to_replace, value, limit, method, **kwargs):
+    if method is not None and not isinstance(to_replace,
+                                             dict) and value is None:
+      # Can't rely on method for replacement, it's order-sensitive
+      # pandas only relies on method if to_replace is not a dictionary, and
+      # value is None
+      raise frame_base.WontImplementError("order-sensitive")
+
     if limit is None:
       requires_partition_by = partitionings.Nothing()
     else:
@@ -654,7 +669,12 @@ class DeferredSeries(DeferredDataFrameOrSeries):
     return frame_base.DeferredFrame.wrap(
         expressions.ComputedExpression(
             'replace',
-            lambda df: df.replace(limit=limit, **kwargs), [self._expr],
+            lambda df: df.replace(
+                to_replace=to_replace,
+                value=value,
+                limit=limit,
+                method=method,
+                **kwargs), [self._expr],
             preserves_partition_by=partitionings.Singleton(),
             requires_partition_by=requires_partition_by))
 
@@ -1396,12 +1416,14 @@ class DeferredDataFrame(DeferredDataFrameOrSeries):
 
   def pop(self, item):
     result = self[item]
+
     self._expr = expressions.ComputedExpression(
             'popped',
-            lambda df: (df.pop(item), df)[-1],
+            lambda df: df.drop(columns=[item]),
             [self._expr],
             preserves_partition_by=partitionings.Singleton(),
             requires_partition_by=partitionings.Nothing())
+
     return result
 
   @frame_base.args_to_kwargs(pd.DataFrame)
@@ -1501,7 +1523,27 @@ class DeferredDataFrame(DeferredDataFrameOrSeries):
             preserves_partition_by=partitionings.Nothing(),
             requires_partition_by=requires_partition_by))
 
-  round = frame_base._elementwise_method('round')
+  @frame_base.args_to_kwargs(pd.DataFrame)
+  @frame_base.populate_defaults(pd.DataFrame)
+  def round(self, decimals, *args, **kwargs):
+
+    if isinstance(decimals, frame_base.DeferredFrame):
+      # Disallow passing a deferred Series in, our current partitioning model
+      # prevents us from using it correctly.
+      raise NotImplementedError("Passing a deferred series to round() is not "
+                                "supported, please use a concrete pd.Series "
+                                "instance or a dictionary")
+
+    return frame_base.DeferredFrame.wrap(
+        expressions.ComputedExpression(
+            'round',
+            lambda df: df.round(decimals, *args, **kwargs),
+            [self._expr],
+            requires_partition_by=partitionings.Nothing(),
+            preserves_partition_by=partitionings.Index()
+        )
+    )
+
   select_dtypes = frame_base._elementwise_method('select_dtypes')
 
   @frame_base.args_to_kwargs(pd.DataFrame)
@@ -1979,6 +2021,8 @@ class _DeferredStringMethods(frame_base.DeferredBase):
       raise frame_base.WontImplementError("repeats must be an integer or a "
                                           "Series.")
 
+  get_dummies = frame_base.wont_implement_method('non-deferred column values')
+
 
 ELEMENTWISE_STRING_METHODS = [
             'capitalize',
@@ -1991,7 +2035,6 @@ ELEMENTWISE_STRING_METHODS = [
             'findall',
             'fullmatch',
             'get',
-            'get_dummies',
             'isalnum',
             'isalpha',
             'isdecimal',
@@ -2027,7 +2070,22 @@ ELEMENTWISE_STRING_METHODS = [
 
 def make_str_func(method):
   def func(df, *args, **kwargs):
-    return getattr(df.str, method)(*args, **kwargs)
+    try:
+      df_str = df.str
+    except AttributeError:
+      # If there's a non-string value in a Series passed to .str method, pandas
+      # will generally just replace it with NaN in the result. However if
+      # there are _only_ non-string values, pandas will raise:
+      #
+      #   AttributeError: Can only use .str accessor with string values!
+      #
+      # This can happen to us at execution time if we split a partition that is
+      # only non-strings. This branch just replaces all those values with NaN
+      # in that case.
+      return df.map(lambda _: np.nan)
+    else:
+      return getattr(df_str, method)(*args, **kwargs)
+
   return func
 
 for method in ELEMENTWISE_STRING_METHODS:
diff --git a/sdks/python/apache_beam/dataframe/frames_test.py b/sdks/python/apache_beam/dataframe/frames_test.py
index 7bd6ad1899c..7b888d1bf82 100644
--- a/sdks/python/apache_beam/dataframe/frames_test.py
+++ b/sdks/python/apache_beam/dataframe/frames_test.py
@@ -124,6 +124,22 @@ class DeferredFrameTest(unittest.TestCase):
     })
     self._run_test(new_column, df)
 
+  def test_str_split(self):
+    s = pd.Series([
+        "this is a regular sentence",
+        "https://docs.python.org/3/tutorial/index.html",
+        np.nan
+    ])
+
+    # TODO(BEAM-11931): pandas produces None for empty values with expand=True,
+    # while we produce NaN (from pd.concat). This replicates some doctests that
+    # verify that behavior, but with a replace call to ignore the difference.
+    self._run_test(
+        lambda s: s.str.split(expand=True).replace({None: np.nan}), s)
+    self._run_test(
+        lambda s: s.str.rsplit("/", n=1, expand=True).replace({None: np.nan}),
+        s)
+
   def test_set_column_from_index(self):
     def new_column(df):
       df['NewCol'] = df.index
diff --git a/sdks/python/apache_beam/dataframe/pandas_doctests_test.py b/sdks/python/apache_beam/dataframe/pandas_doctests_test.py
index 61bfd9e3a7c..1144d425815 100644
--- a/sdks/python/apache_beam/dataframe/pandas_doctests_test.py
+++ b/sdks/python/apache_beam/dataframe/pandas_doctests_test.py
@@ -39,6 +39,10 @@ class DoctestTest(unittest.TestCase):
             'pandas.core.frame.DataFrame.cumsum': ['*'],
             'pandas.core.frame.DataFrame.cumprod': ['*'],
             'pandas.core.frame.DataFrame.diff': ['*'],
+            'pandas.core.frame.DataFrame.fillna': [
+                "df.fillna(method='ffill')",
+                'df.fillna(value=values, limit=1)',
+            ],
             'pandas.core.frame.DataFrame.items': ['*'],
             'pandas.core.frame.DataFrame.itertuples': ['*'],
             'pandas.core.frame.DataFrame.iterrows': ['*'],
@@ -55,6 +59,11 @@ class DoctestTest(unittest.TestCase):
                 "df.nsmallest(3, 'population', keep='last')",
             ],
             'pandas.core.frame.DataFrame.nunique': ['*'],
+            'pandas.core.frame.DataFrame.replace': [
+                "s.replace([1, 2], method='bfill')",
+                # Relies on method='pad'
+                "s.replace('a', None)",
+            ],
             'pandas.core.frame.DataFrame.to_records': ['*'],
             'pandas.core.frame.DataFrame.to_dict': ['*'],
             'pandas.core.frame.DataFrame.to_numpy': ['*'],
@@ -88,6 +97,10 @@ class DoctestTest(unittest.TestCase):
             'pandas.core.frame.DataFrame.reindex': ['*'],
             'pandas.core.frame.DataFrame.reindex_axis': ['*'],
 
+            'pandas.core.frame.DataFrame.round': [
+                'df.round(decimals)',
+            ],
+
             # We should be able to support pivot and pivot_table for categorical
             # columns
             'pandas.core.frame.DataFrame.pivot': ['*'],
@@ -238,6 +251,10 @@ class DoctestTest(unittest.TestCase):
             'pandas.core.series.Series.dot': [
                 's.dot(arr)',  # non-deferred result
             ],
+            'pandas.core.series.Series.fillna': [
+                "df.fillna(method='ffill')",
+                'df.fillna(value=values, limit=1)',
+            ],
             'pandas.core.series.Series.items': ['*'],
             'pandas.core.series.Series.iteritems': ['*'],
             # default keep is 'first'
@@ -324,31 +341,59 @@ class DoctestTest(unittest.TestCase):
     self.assertEqual(result.failed, 0)
 
   def test_string_tests(self):
+    PD_VERSION = tuple(int(v) for v in pd.__version__.split('.'))
+    if PD_VERSION < (1, 2, 0):
+      module = pd.core.strings
+    else:
+      # Definitions were moved to accessor in pandas 1.2.0
+      module = pd.core.strings.accessor
+
+    module_name = module.__name__
+
     result = doctests.testmod(
-        pd.core.strings,
+        module,
         use_beam=False,
         wont_implement_ok={
             # These methods can accept deferred series objects, but not lists
-            'pandas.core.strings.StringMethods.cat': [
+            f'{module_name}.StringMethods.cat': [
                 "s.str.cat(['A', 'B', 'C', 'D'], sep=',')",
                 "s.str.cat(['A', 'B', 'C', 'D'], sep=',', na_rep='-')",
                 "s.str.cat(['A', 'B', 'C', 'D'], na_rep='-')"
             ],
-            'pandas.core.strings.StringMethods.repeat': [
-                's.str.repeat(repeats=[1, 2, 3])'
-            ],
-            'pandas.core.strings.str_repeat': [
+            f'{module_name}.StringMethods.repeat': [
                 's.str.repeat(repeats=[1, 2, 3])'
             ],
+            f'{module_name}.str_repeat': ['s.str.repeat(repeats=[1, 2, 3])'],
+            f'{module_name}.StringMethods.get_dummies': ['*'],
+            f'{module_name}.str_get_dummies': ['*'],
         },
         skip={
-            # Bad test strings
-            'pandas.core.strings.str_replace': [
+            # count() on Series with a NaN produces mismatched type if we
+            # have a NaN-only partition.
+            f'{module_name}.StringMethods.count': ["s.str.count('a')"],
+            f'{module_name}.str_count': ["s.str.count('a')"],
+
+            # Produce None instead of NaN, see
+            # frames_test.py::DeferredFrameTest::test_str_split
+            f'{module_name}.StringMethods.rsplit': [
+                's.str.split(expand=True)',
+                's.str.rsplit("/", n=1, expand=True)',
+            ],
+            f'{module_name}.StringMethods.split': [
+                's.str.split(expand=True)',
+                's.str.rsplit("/", n=1, expand=True)',
+            ],
+
+            # Bad test strings in pandas 1.1.x
+            f'{module_name}.str_replace': [
                 "pd.Series(['foo', 'fuz', np.nan]).str.replace('f', repr)"
             ],
-            'pandas.core.strings.StringMethods.replace': [
+            f'{module_name}.StringMethods.replace': [
                 "pd.Series(['foo', 'fuz', np.nan]).str.replace('f', repr)"
             ],
+
+            # output has incorrect formatting in 1.2.x
+            f'{module_name}.StringMethods.extractall': ['*']
         })
     self.assertEqual(result.failed, 0)
 
@@ -471,6 +516,14 @@ class DoctestTest(unittest.TestCase):
             'pandas.core.groupby.generic.DataFrameGroupBy.diff': ['*'],
             'pandas.core.groupby.generic.SeriesGroupBy.diff': ['*'],
             'pandas.core.groupby.generic.DataFrameGroupBy.hist': ['*'],
+            'pandas.core.groupby.generic.DataFrameGroupBy.fillna': [
+                "df.fillna(method='ffill')",
+                'df.fillna(value=values, limit=1)',
+            ],
+            'pandas.core.groupby.generic.SeriesGroupBy.fillna': [
+                "df.fillna(method='ffill')",
+                'df.fillna(value=values, limit=1)',
+            ],
         },
         not_implemented_ok={
             'pandas.core.groupby.generic.DataFrameGroupBy.transform': ['*'],
diff --git a/sdks/python/apache_beam/dataframe/partitionings.py b/sdks/python/apache_beam/dataframe/partitionings.py
index 9baf9c9a1cd..a67bbacdf13 100644
--- a/sdks/python/apache_beam/dataframe/partitionings.py
+++ b/sdks/python/apache_beam/dataframe/partitionings.py
@@ -174,7 +174,7 @@ class Nothing(Partitioning):
     return isinstance(other, Nothing)
 
   def test_partition_fn(self, df):
-    num_partitions = max(min(df.size, 10), 1)
+    num_partitions = 10
 
     def shuffled(seq):
       seq = list(seq)
