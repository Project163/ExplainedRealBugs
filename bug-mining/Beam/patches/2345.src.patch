diff --git a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java
index bb5eccd14e4..154414fc390 100644
--- a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java
+++ b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java
@@ -419,7 +419,7 @@ public class StreamingDataflowWorker {
   private final ConcurrentMap<String, String> systemNameToComputationIdMap =
       new ConcurrentHashMap<>();
 
-  private final WindmillStateCache stateCache;
+  final WindmillStateCache stateCache;
 
   private final ThreadFactory threadFactory;
   private DataflowMapTaskExecutorFactory mapTaskExecutorFactory;
diff --git a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingModeExecutionContext.java b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingModeExecutionContext.java
index 48b78a3a758..23c34aee771 100644
--- a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingModeExecutionContext.java
+++ b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingModeExecutionContext.java
@@ -24,6 +24,7 @@ import com.google.api.services.dataflow.model.CounterUpdate;
 import com.google.api.services.dataflow.model.SideInputInfo;
 import java.io.Closeable;
 import java.io.IOException;
+import java.util.Collection;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
@@ -240,13 +241,21 @@ public class StreamingModeExecutionContext extends DataflowExecutionContext<Step
       }
     }
 
-    for (StepContext stepContext : getAllStepContexts()) {
-      stepContext.start(
-          stateReader,
-          inputDataWatermark,
-          processingTime,
-          outputDataWatermark,
-          synchronizedProcessingTime);
+    Collection<? extends StepContext> stepContexts = getAllStepContexts();
+    if (!stepContexts.isEmpty()) {
+      // This must be only created once for the workItem as token validation will fail if the same
+      // work token is reused.
+      WindmillStateCache.ForKey cacheForKey =
+          stateCache.forKey(getComputationKey(), getWork().getCacheToken(), getWorkToken());
+      for (StepContext stepContext : stepContexts) {
+        stepContext.start(
+            stateReader,
+            inputDataWatermark,
+            processingTime,
+            cacheForKey,
+            outputDataWatermark,
+            synchronizedProcessingTime);
+      }
     }
   }
 
@@ -500,6 +509,7 @@ public class StreamingModeExecutionContext extends DataflowExecutionContext<Step
         WindmillStateReader stateReader,
         Instant inputDataWatermark,
         Instant processingTime,
+        WindmillStateCache.ForKey cacheForKey,
         @Nullable Instant outputDataWatermark,
         @Nullable Instant synchronizedProcessingTime) {
       this.stateInternals =
@@ -508,8 +518,7 @@ public class StreamingModeExecutionContext extends DataflowExecutionContext<Step
               stateFamily,
               stateReader,
               work.getIsNewKey(),
-              stateCache.forKey(
-                  getComputationKey(), stateFamily, getWork().getCacheToken(), getWorkToken()),
+              cacheForKey.forFamily(stateFamily),
               scopedReadStateSupplier);
 
       this.systemTimerInternals =
diff --git a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/WindmillStateCache.java b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/WindmillStateCache.java
index 0706b221f8d..f8eff5c80df 100644
--- a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/WindmillStateCache.java
+++ b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/WindmillStateCache.java
@@ -64,13 +64,13 @@ public class WindmillStateCache implements StatusDataProvider {
   private static final int PER_CACHE_ENTRY_OVERHEAD =
       8 + HASH_MAP_ENTRY_OVERHEAD * INITIAL_HASH_MAP_CAPACITY;
 
-  private Cache<StateId, StateCacheEntry> stateCache;
+  private final Cache<StateId, StateCacheEntry> stateCache;
   // Contains the current valid ForKey object. Entries in the cache are keyed by ForKey with pointer
   // equality so entries may be invalidated by creating a new key object, rendering the previous
   // entries inaccessible. They will be evicted through normal cache operation.
-  private ConcurrentMap<WindmillComputationKey, ForKey> keyIndex =
+  private final ConcurrentMap<WindmillComputationKey, ForKey> keyIndex =
       new MapMaker().weakValues().concurrencyLevel(4).makeMap();
-  private long workerCacheBytes; // Copy workerCacheMb and convert to bytes.
+  private final long workerCacheBytes; // Copy workerCacheMb and convert to bytes.
 
   public WindmillStateCache(long workerCacheMb) {
     final Weigher<Weighted, Weighted> weigher = Weighers.weightedKeysAndValues();
@@ -115,6 +115,10 @@ public class WindmillStateCache implements StatusDataProvider {
     return workerCacheBytes;
   }
 
+  public CacheStats getCacheStats() {
+    return stateCache.stats();
+  }
+
   /** Per-computation view of the state cache. */
   public class ForComputation {
 
@@ -134,16 +138,11 @@ public class WindmillStateCache implements StatusDataProvider {
     }
 
     /**
-     * Returns a per-computation, per-key, per-state-family view of the state cache. Access to the
-     * cached data for this key is not thread-safe. Callers should ensure that there is only a
-     * single ForKeyAndFamily object in use at a time and that access to it is synchronized or
-     * single-threaded.
+     * Returns a per-computation, per-key view of the state cache. Access to the cached data for
+     * this key is not thread-safe. Callers should ensure that there is only a single ForKey object
+     * in use at a time and that access to it is synchronized or single-threaded.
      */
-    public ForKeyAndFamily forKey(
-        WindmillComputationKey computationKey,
-        String stateFamily,
-        long cacheToken,
-        long workToken) {
+    public ForKey forKey(WindmillComputationKey computationKey, long cacheToken, long workToken) {
       ForKey forKey = keyIndex.get(computationKey);
       if (forKey == null || !forKey.updateTokens(cacheToken, workToken)) {
         forKey = new ForKey(computationKey, cacheToken, workToken);
@@ -152,14 +151,14 @@ public class WindmillStateCache implements StatusDataProvider {
         // values as well.
         keyIndex.put(computationKey, forKey);
       }
-      return new ForKeyAndFamily(forKey, stateFamily);
+      return forKey;
     }
   }
 
   /** Per-computation, per-key view of the state cache. */
   // Note that we utilize the default equality and hashCode for this class based upon the instance
   // (instead of the fields) to optimize cache invalidation.
-  private static class ForKey {
+  public class ForKey {
     private final WindmillComputationKey computationKey;
     // Cache token must be consistent for the key for the cache to be valid.
     private final long cacheToken;
@@ -169,6 +168,16 @@ public class WindmillStateCache implements StatusDataProvider {
     // for stale processing.
     private long workToken;
 
+    /**
+     * Returns a per-computation, per-key, per-family view of the state cache. Access to the cached
+     * data for this key is not thread-safe. Callers should ensure that there is only a single
+     * ForKeyAndFamily object in use at a time for a given computation, key, family tuple and that
+     * access to it is synchronized or single-threaded.
+     */
+    public ForKeyAndFamily forFamily(String stateFamily) {
+      return new ForKeyAndFamily(this, stateFamily);
+    }
+
     private ForKey(WindmillComputationKey computationKey, long cacheToken, long workToken) {
       this.computationKey = computationKey;
       this.cacheToken = cacheToken;
@@ -191,7 +200,7 @@ public class WindmillStateCache implements StatusDataProvider {
   public class ForKeyAndFamily {
     final ForKey forKey;
     final String stateFamily;
-    private HashMap<StateId, StateCacheEntry> localCache;
+    private final HashMap<StateId, StateCacheEntry> localCache;
 
     private ForKeyAndFamily(ForKey forKey, String stateFamily) {
       this.forKey = forKey;
@@ -331,7 +340,7 @@ public class WindmillStateCache implements StatusDataProvider {
 
       NamespacedTag(StateNamespace namespace, StateTag<T> tag) {
         this.namespace = namespace;
-        this.tag = StateTags.ID_EQUIVALENCE.wrap((StateTag) tag);
+        this.tag = StateTags.ID_EQUIVALENCE.wrap(tag);
       }
 
       @Override
diff --git a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorkerTest.java b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorkerTest.java
index d68f9fe4a7e..6512ef26de6 100644
--- a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorkerTest.java
+++ b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorkerTest.java
@@ -146,6 +146,7 @@ import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;
 import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString.Output;
 import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.TextFormat;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Optional;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.CacheStats;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;
@@ -1722,6 +1723,308 @@ public class StreamingDataflowWorkerTest {
     assertEquals(0L, splitIntToLong(getCounter(counters, "WindmillShuffleBytesRead").getInteger()));
   }
 
+  static class PassthroughDoFn
+      extends DoFn<KV<String, Iterable<String>>, KV<String, Iterable<String>>> {
+
+    @ProcessElement
+    public void processElement(ProcessContext c) {
+      c.output(c.element());
+    }
+  }
+
+  @Test
+  // Runs a merging windows test verifying stored state, holds and timers with caching due to
+  // the first processing having is_new_key set.
+  public void testMergeWindowsCaching() throws Exception {
+    Coder<KV<String, String>> kvCoder = KvCoder.of(StringUtf8Coder.of(), StringUtf8Coder.of());
+    Coder<WindowedValue<KV<String, String>>> windowedKvCoder =
+        FullWindowedValueCoder.of(kvCoder, IntervalWindow.getCoder());
+    KvCoder<String, List<String>> groupedCoder =
+        KvCoder.of(StringUtf8Coder.of(), ListCoder.of(StringUtf8Coder.of()));
+    Coder<WindowedValue<KV<String, List<String>>>> windowedGroupedCoder =
+        FullWindowedValueCoder.of(groupedCoder, IntervalWindow.getCoder());
+
+    CloudObject spec = CloudObject.forClassName("MergeWindowsDoFn");
+    SdkComponents sdkComponents = SdkComponents.create();
+    sdkComponents.registerEnvironment(Environments.JAVA_SDK_HARNESS_ENVIRONMENT);
+    addString(
+        spec,
+        PropertyNames.SERIALIZED_FN,
+        StringUtils.byteArrayToJsonString(
+            WindowingStrategyTranslation.toMessageProto(
+                    WindowingStrategy.of(FixedWindows.of(Duration.standardSeconds(1)))
+                        .withTimestampCombiner(TimestampCombiner.EARLIEST),
+                    sdkComponents)
+                .toByteArray()));
+    addObject(
+        spec,
+        WorkerPropertyNames.INPUT_CODER,
+        CloudObjects.asCloudObject(windowedKvCoder, /*sdkComponents=*/ null));
+
+    ParallelInstruction mergeWindowsInstruction =
+        new ParallelInstruction()
+            .setSystemName("MergeWindows-System")
+            .setName("MergeWindowsStep")
+            .setOriginalName("MergeWindowsOriginal")
+            .setParDo(
+                new ParDoInstruction()
+                    .setInput(new InstructionInput().setProducerInstructionIndex(0).setOutputNum(0))
+                    .setNumOutputs(1)
+                    .setUserFn(spec))
+            .setOutputs(
+                Arrays.asList(
+                    new InstructionOutput()
+                        .setOriginalName(DEFAULT_OUTPUT_ORIGINAL_NAME)
+                        .setSystemName(DEFAULT_OUTPUT_SYSTEM_NAME)
+                        .setName("output")
+                        .setCodec(
+                            CloudObjects.asCloudObject(
+                                windowedGroupedCoder, /*sdkComponents=*/ null))));
+
+    List<ParallelInstruction> instructions =
+        Arrays.asList(
+            makeWindowingSourceInstruction(kvCoder),
+            mergeWindowsInstruction,
+            // Use multiple stages in the maptask to test caching with multiple stages.
+            makeDoFnInstruction(new PassthroughDoFn(), 1, groupedCoder),
+            makeSinkInstruction(groupedCoder, 2));
+
+    FakeWindmillServer server = new FakeWindmillServer(errorCollector);
+
+    StreamingDataflowWorker worker =
+        makeWorker(instructions, createTestingPipelineOptions(server), false /* publishCounters */);
+    Map<String, String> nameMap = new HashMap<>();
+    nameMap.put("MergeWindowsStep", "MergeWindows");
+    worker.addStateNameMappings(nameMap);
+    worker.start();
+
+    server.addWorkToOffer(
+        buildInput(
+            "work {"
+                + "  computation_id: \""
+                + DEFAULT_COMPUTATION_ID
+                + "\""
+                + "  input_data_watermark: 0"
+                + "  work {"
+                + "    key: \""
+                + DEFAULT_KEY_STRING
+                + "\""
+                + "    sharding_key: "
+                + DEFAULT_SHARDING_KEY
+                + "    cache_token: 1"
+                + "    work_token: 1"
+                + "    is_new_key: 1"
+                + "    message_bundles {"
+                + "      source_computation_id: \""
+                + DEFAULT_SOURCE_COMPUTATION_ID
+                + "\""
+                + "      messages {"
+                + "        timestamp: 0"
+                + "        data: \""
+                + dataStringForIndex(0)
+                + "\""
+                + "      }"
+                + "    }"
+                + "  }"
+                + "}",
+            intervalWindowBytes(WINDOW_AT_ZERO)));
+
+    Map<Long, Windmill.WorkItemCommitRequest> result = server.waitForAndGetCommits(1);
+    Iterable<CounterUpdate> counters = worker.buildCounters();
+
+    // These tags and data are opaque strings and this is a change detector test.
+    // The "/u" indicates the user's namespace, versus "/s" for system namespace
+    String window = "/gAAAAAAAA-joBw/";
+    String timerTagPrefix = "/s" + window + "+0";
+    ByteString bufferTag = ByteString.copyFromUtf8(window + "+ubuf");
+    ByteString paneInfoTag = ByteString.copyFromUtf8(window + "+upane");
+    String watermarkDataHoldTag = window + "+uhold";
+    String watermarkExtraHoldTag = window + "+uextra";
+    String stateFamily = "MergeWindows";
+    ByteString bufferData = ByteString.copyFromUtf8("data0");
+    // Encoded form for Iterable<String>: -1, true, 'data0', false
+    ByteString outputData =
+        ByteString.copyFrom(
+            new byte[] {
+              (byte) 0xff,
+              (byte) 0xff,
+              (byte) 0xff,
+              (byte) 0xff,
+              0x01,
+              0x05,
+              0x64,
+              0x61,
+              0x74,
+              0x61,
+              0x30,
+              0x00
+            });
+
+    // These values are not essential to the change detector test
+    long timerTimestamp = 999000L;
+
+    WorkItemCommitRequest actualOutput = result.get(1L);
+
+    // Set timer
+    verifyTimers(actualOutput, buildWatermarkTimer(timerTagPrefix, 999));
+
+    assertThat(
+        actualOutput.getBagUpdatesList(),
+        Matchers.contains(
+            Matchers.equalTo(
+                Windmill.TagBag.newBuilder()
+                    .setTag(bufferTag)
+                    .setStateFamily(stateFamily)
+                    .addValues(bufferData)
+                    .build())));
+
+    verifyHolds(actualOutput, buildHold(watermarkDataHoldTag, 0, false));
+
+    // No state reads
+    assertEquals(0L, splitIntToLong(getCounter(counters, "WindmillStateBytesRead").getInteger()));
+    // Timer + buffer + watermark hold
+    assertEquals(
+        Windmill.WorkItemCommitRequest.newBuilder(actualOutput)
+            .clearCounterUpdates()
+            .clearOutputMessages()
+            .build()
+            .getSerializedSize(),
+        splitIntToLong(getCounter(counters, "WindmillStateBytesWritten").getInteger()));
+    // Input messages
+    assertEquals(
+        VarInt.getLength(0L)
+            + dataStringForIndex(0).length()
+            + addPaneTag(PaneInfo.NO_FIRING, intervalWindowBytes(WINDOW_AT_ZERO)).size()
+            + 5L // proto overhead
+        ,
+        splitIntToLong(getCounter(counters, "WindmillShuffleBytesRead").getInteger()));
+
+    Windmill.GetWorkResponse.Builder getWorkResponse = Windmill.GetWorkResponse.newBuilder();
+    getWorkResponse
+        .addWorkBuilder()
+        .setComputationId(DEFAULT_COMPUTATION_ID)
+        .setInputDataWatermark(timerTimestamp + 1000)
+        .addWorkBuilder()
+        .setKey(ByteString.copyFromUtf8(DEFAULT_KEY_STRING))
+        .setShardingKey(DEFAULT_SHARDING_KEY)
+        .setWorkToken(2)
+        .setCacheToken(1)
+        .getTimersBuilder()
+        .addTimers(buildWatermarkTimer(timerTagPrefix, timerTimestamp));
+    server.addWorkToOffer(getWorkResponse.build());
+
+    long expectedBytesRead = 0L;
+
+    Windmill.GetDataResponse.Builder dataResponse = Windmill.GetDataResponse.newBuilder();
+    Windmill.KeyedGetDataResponse.Builder dataBuilder =
+        dataResponse
+            .addDataBuilder()
+            .setComputationId(DEFAULT_COMPUTATION_ID)
+            .addDataBuilder()
+            .setKey(ByteString.copyFromUtf8(DEFAULT_KEY_STRING))
+            .setShardingKey(DEFAULT_SHARDING_KEY);
+    // These reads are skipped due to being cached from accesses in the first work item processing.
+    // dataBuilder
+    //     .addBagsBuilder()
+    //     .setTag(bufferTag)
+    //     .setStateFamily(stateFamily)
+    //     .addValues(bufferData);
+    // dataBuilder
+    //     .addWatermarkHoldsBuilder()
+    //     .setTag(ByteString.copyFromUtf8(watermarkDataHoldTag))
+    //     .setStateFamily(stateFamily)
+    //     .addTimestamps(0);
+    dataBuilder
+        .addWatermarkHoldsBuilder()
+        .setTag(ByteString.copyFromUtf8(watermarkExtraHoldTag))
+        .setStateFamily(stateFamily)
+        .addTimestamps(0);
+    dataBuilder
+        .addValuesBuilder()
+        .setTag(paneInfoTag)
+        .setStateFamily(stateFamily)
+        .getValueBuilder()
+        .setTimestamp(0)
+        .setData(ByteString.EMPTY);
+    server.addDataToOffer(dataResponse.build());
+
+    expectedBytesRead += dataBuilder.build().getSerializedSize();
+
+    result = server.waitForAndGetCommits(1);
+    counters = worker.buildCounters();
+    actualOutput = result.get(2L);
+
+    assertEquals(1, actualOutput.getOutputMessagesCount());
+    assertEquals(
+        DEFAULT_DESTINATION_STREAM_ID, actualOutput.getOutputMessages(0).getDestinationStreamId());
+    assertEquals(
+        DEFAULT_KEY_STRING,
+        actualOutput.getOutputMessages(0).getBundles(0).getKey().toStringUtf8());
+    assertEquals(0, actualOutput.getOutputMessages(0).getBundles(0).getMessages(0).getTimestamp());
+    assertEquals(
+        outputData, actualOutput.getOutputMessages(0).getBundles(0).getMessages(0).getData());
+
+    ByteString metadata =
+        actualOutput.getOutputMessages(0).getBundles(0).getMessages(0).getMetadata();
+    InputStream inStream = metadata.newInput();
+    assertEquals(
+        PaneInfo.createPane(true, true, Timing.ON_TIME), PaneInfoCoder.INSTANCE.decode(inStream));
+    assertEquals(
+        Arrays.asList(WINDOW_AT_ZERO),
+        DEFAULT_WINDOW_COLLECTION_CODER.decode(inStream, Coder.Context.OUTER));
+
+    // Data was deleted
+    assertThat(
+        "" + actualOutput.getValueUpdatesList(),
+        actualOutput.getValueUpdatesList(),
+        Matchers.contains(
+            Matchers.equalTo(
+                Windmill.TagValue.newBuilder()
+                    .setTag(paneInfoTag)
+                    .setStateFamily(stateFamily)
+                    .setValue(
+                        Windmill.Value.newBuilder()
+                            .setTimestamp(Long.MAX_VALUE)
+                            .setData(ByteString.EMPTY))
+                    .build())));
+
+    assertThat(
+        "" + actualOutput.getBagUpdatesList(),
+        actualOutput.getBagUpdatesList(),
+        Matchers.contains(
+            Matchers.equalTo(
+                Windmill.TagBag.newBuilder()
+                    .setTag(bufferTag)
+                    .setStateFamily(stateFamily)
+                    .setDeleteAll(true)
+                    .build())));
+
+    verifyHolds(
+        actualOutput,
+        buildHold(watermarkDataHoldTag, -1, true),
+        buildHold(watermarkExtraHoldTag, -1, true));
+
+    // State reads for windowing
+    assertEquals(
+        expectedBytesRead,
+        splitIntToLong(getCounter(counters, "WindmillStateBytesRead").getInteger()));
+    // State updates to clear state
+    assertEquals(
+        Windmill.WorkItemCommitRequest.newBuilder(actualOutput)
+            .clearCounterUpdates()
+            .clearOutputMessages()
+            .build()
+            .getSerializedSize(),
+        splitIntToLong(getCounter(counters, "WindmillStateBytesWritten").getInteger()));
+    // No input messages
+    assertEquals(0L, splitIntToLong(getCounter(counters, "WindmillShuffleBytesRead").getInteger()));
+
+    CacheStats stats = worker.stateCache.getCacheStats();
+    LOG.info("cache stats {}", stats);
+    assertEquals(1, stats.hitCount());
+    assertEquals(4, stats.missCount());
+  }
+
   static class Action {
 
     public Action(GetWorkResponse response) {
diff --git a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WindmillStateCacheTest.java b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WindmillStateCacheTest.java
index 210c2f73394..02ed76ede9f 100644
--- a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WindmillStateCacheTest.java
+++ b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WindmillStateCacheTest.java
@@ -141,7 +141,6 @@ public class WindmillStateCacheTest {
   }
 
   WindmillStateCache cache;
-  WindmillStateCache.ForKeyAndFamily keyCache;
 
   @Before
   public void setUp() {
@@ -152,7 +151,8 @@ public class WindmillStateCacheTest {
 
   @Test
   public void testBasic() throws Exception {
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 1L);
+    WindmillStateCache.ForKeyAndFamily keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 1L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(StateNamespaces.global(), new TestStateTag("tag1")));
     assertNull(keyCache.get(windowNamespace(0), new TestStateTag("tag2")));
     assertNull(keyCache.get(triggerNamespace(0, 0), new TestStateTag("tag3")));
@@ -174,7 +174,8 @@ public class WindmillStateCacheTest {
     keyCache.persist();
     assertEquals(290, cache.getWeight());
 
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 2L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 2L).forFamily(STATE_FAMILY);
     assertEquals(
         new TestState("g1"), keyCache.get(StateNamespaces.global(), new TestStateTag("tag1")));
     assertEquals(new TestState("w2"), keyCache.get(windowNamespace(0), new TestStateTag("tag2")));
@@ -193,17 +194,20 @@ public class WindmillStateCacheTest {
   /** Verifies that values are cached in the appropriate namespaces. */
   @Test
   public void testInvalidation() throws Exception {
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 1L);
+    WindmillStateCache.ForKeyAndFamily keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 1L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(StateNamespaces.global(), new TestStateTag("tag1")));
     keyCache.put(StateNamespaces.global(), new TestStateTag("tag1"), new TestState("g1"), 2);
     keyCache.persist();
 
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 2L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 2L).forFamily(STATE_FAMILY);
     assertEquals(127, cache.getWeight());
     assertEquals(
         new TestState("g1"), keyCache.get(StateNamespaces.global(), new TestStateTag("tag1")));
 
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 1L, 3L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 1L, 3L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(StateNamespaces.global(), new TestStateTag("tag1")));
     assertEquals(127, cache.getWeight());
   }
@@ -211,14 +215,16 @@ public class WindmillStateCacheTest {
   /** Verifies that the cache is invalidated when the cache token changes. */
   @Test
   public void testEviction() throws Exception {
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 1L);
+    WindmillStateCache.ForKeyAndFamily keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 1L).forFamily(STATE_FAMILY);
     keyCache.put(windowNamespace(0), new TestStateTag("tag2"), new TestState("w2"), 2);
     keyCache.put(triggerNamespace(0, 0), new TestStateTag("tag3"), new TestState("t3"), 2000000000);
     keyCache.persist();
     assertEquals(0, cache.getWeight());
 
     // Eviction is atomic across the whole window.
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 2L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 2L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(windowNamespace(0), new TestStateTag("tag2")));
     assertNull(keyCache.get(triggerNamespace(0, 0), new TestStateTag("tag3")));
   }
@@ -228,7 +234,8 @@ public class WindmillStateCacheTest {
   public void testStaleWorkItem() throws Exception {
     TestStateTag tag = new TestStateTag("tag2");
 
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 2L);
+    WindmillStateCache.ForKeyAndFamily keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 2L).forFamily(STATE_FAMILY);
     keyCache.put(windowNamespace(0), tag, new TestState("w2"), 2);
 
     // Same cache.
@@ -239,22 +246,27 @@ public class WindmillStateCacheTest {
     assertEquals(new TestState("w2"), keyCache.get(windowNamespace(0), tag));
 
     // Previous work token.
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 1L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 1L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(windowNamespace(0), tag));
 
     // Retry of work token that inserted.
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 2L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 2L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(windowNamespace(0), tag));
 
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 10L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 10L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(windowNamespace(0), tag));
     keyCache.put(windowNamespace(0), tag, new TestState("w3"), 2);
 
     // Ensure that second put updated work token.
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 5L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 5L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(windowNamespace(0), tag));
 
-    keyCache = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 15L);
+    keyCache =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 15L).forFamily(STATE_FAMILY);
     assertNull(keyCache.get(windowNamespace(0), tag));
   }
 
@@ -266,15 +278,18 @@ public class WindmillStateCacheTest {
     WindmillStateCache.ForKeyAndFamily keyCache1 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key1", SHARDING_KEY), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey("comp1", "key1", SHARDING_KEY), 0L, 0L)
+            .forFamily(STATE_FAMILY);
     WindmillStateCache.ForKeyAndFamily keyCache2 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key2", SHARDING_KEY), STATE_FAMILY, 0L, 10L);
+            .forKey(computationKey("comp1", "key2", SHARDING_KEY), 0L, 10L)
+            .forFamily(STATE_FAMILY);
     WindmillStateCache.ForKeyAndFamily keyCache3 =
         cache
             .forComputation("comp2")
-            .forKey(computationKey("comp2", "key1", SHARDING_KEY), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey("comp2", "key1", SHARDING_KEY), 0L, 0L)
+            .forFamily(STATE_FAMILY);
 
     TestState state1 = new TestState("g1");
     keyCache1.put(StateNamespaces.global(), tag, state1, 2);
@@ -284,7 +299,8 @@ public class WindmillStateCacheTest {
     keyCache1 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key1", SHARDING_KEY), STATE_FAMILY, 0L, 1L);
+            .forKey(computationKey("comp1", "key1", SHARDING_KEY), 0L, 1L)
+            .forFamily(STATE_FAMILY);
     assertEquals(state1, keyCache1.get(StateNamespaces.global(), tag));
     assertNull(keyCache2.get(StateNamespaces.global(), tag));
     assertNull(keyCache3.get(StateNamespaces.global(), tag));
@@ -296,7 +312,8 @@ public class WindmillStateCacheTest {
     keyCache2 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key2", SHARDING_KEY), STATE_FAMILY, 0L, 20L);
+            .forKey(computationKey("comp1", "key2", SHARDING_KEY), 0L, 20L)
+            .forFamily(STATE_FAMILY);
     assertEquals(state2, keyCache2.get(StateNamespaces.global(), tag));
     assertEquals(state1, keyCache1.get(StateNamespaces.global(), tag));
     assertNull(keyCache3.get(StateNamespaces.global(), tag));
@@ -310,15 +327,18 @@ public class WindmillStateCacheTest {
     WindmillStateCache.ForKeyAndFamily key1CacheShard1 =
         cache
             .forComputation(COMPUTATION)
-            .forKey(computationKey(COMPUTATION, "key1", 1), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey(COMPUTATION, "key1", 1), 0L, 0L)
+            .forFamily(STATE_FAMILY);
     WindmillStateCache.ForKeyAndFamily key1CacheShard2 =
         cache
             .forComputation(COMPUTATION)
-            .forKey(computationKey(COMPUTATION, "key1", 2), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey(COMPUTATION, "key1", 2), 0L, 0L)
+            .forFamily(STATE_FAMILY);
     WindmillStateCache.ForKeyAndFamily key2CacheShard1 =
         cache
             .forComputation(COMPUTATION)
-            .forKey(computationKey(COMPUTATION, "key2", 1), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey(COMPUTATION, "key2", 1), 0L, 0L)
+            .forFamily(STATE_FAMILY);
 
     TestState state1 = new TestState("g1");
     key1CacheShard1.put(StateNamespaces.global(), tag, state1, 2);
@@ -327,7 +347,8 @@ public class WindmillStateCacheTest {
     key1CacheShard1 =
         cache
             .forComputation(COMPUTATION)
-            .forKey(computationKey(COMPUTATION, "key1", 1), STATE_FAMILY, 0L, 1L);
+            .forKey(computationKey(COMPUTATION, "key1", 1), 0L, 1L)
+            .forFamily(STATE_FAMILY);
     assertEquals(state1, key1CacheShard1.get(StateNamespaces.global(), tag));
     assertNull(key1CacheShard2.get(StateNamespaces.global(), tag));
     assertNull(key2CacheShard1.get(StateNamespaces.global(), tag));
@@ -339,31 +360,67 @@ public class WindmillStateCacheTest {
     key1CacheShard2 =
         cache
             .forComputation(COMPUTATION)
-            .forKey(computationKey(COMPUTATION, "key1", 2), STATE_FAMILY, 0L, 20L);
+            .forKey(computationKey(COMPUTATION, "key1", 2), 0L, 20L)
+            .forFamily(STATE_FAMILY);
     assertEquals(state2, key1CacheShard2.get(StateNamespaces.global(), tag));
     assertEquals(state1, key1CacheShard1.get(StateNamespaces.global(), tag));
     assertNull(key2CacheShard1.get(StateNamespaces.global(), tag));
   }
 
+  /** Verifies that caches are kept independently per-family. */
+  @Test
+  public void testMultipleFamilies() throws Exception {
+    TestStateTag tag = new TestStateTag("tag1");
+
+    WindmillStateCache.ForKey keyCache =
+        cache.forComputation("comp1").forKey(computationKey("comp1", "key1", SHARDING_KEY), 0L, 0L);
+    WindmillStateCache.ForKeyAndFamily family1 = keyCache.forFamily("family1");
+    WindmillStateCache.ForKeyAndFamily family2 = keyCache.forFamily("family2");
+    WindmillStateCache.ForKeyAndFamily family3 = keyCache.forFamily("family3");
+
+    TestState state1 = new TestState("g1");
+    family1.put(StateNamespaces.global(), tag, state1, 2);
+    assertEquals(state1, family1.get(StateNamespaces.global(), tag));
+    family1.persist();
+
+    TestState state2 = new TestState("g2");
+    family2.put(StateNamespaces.global(), tag, state2, 2);
+    family2.persist();
+    assertEquals(state2, family2.get(StateNamespaces.global(), tag));
+
+    keyCache =
+        cache.forComputation("comp1").forKey(computationKey("comp1", "key1", SHARDING_KEY), 0L, 1L);
+    family1 = keyCache.forFamily("family1");
+    family2 = keyCache.forFamily("family2");
+    family3 = keyCache.forFamily("family3");
+    assertEquals(state1, family1.get(StateNamespaces.global(), tag));
+    assertEquals(state2, family2.get(StateNamespaces.global(), tag));
+    assertNull(family3.get(StateNamespaces.global(), tag));
+  }
+
   /** Verifies explicit invalidation does indeed invalidate the correct entries. */
   @Test
   public void testExplicitInvalidation() throws Exception {
     WindmillStateCache.ForKeyAndFamily keyCache1 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key1", 1), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey("comp1", "key1", 1), 0L, 0L)
+            .forFamily(STATE_FAMILY);
     WindmillStateCache.ForKeyAndFamily keyCache2 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key2", SHARDING_KEY), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey("comp1", "key2", SHARDING_KEY), 0L, 0L)
+            .forFamily(STATE_FAMILY);
     WindmillStateCache.ForKeyAndFamily keyCache3 =
         cache
             .forComputation("comp2")
-            .forKey(computationKey("comp2", "key1", SHARDING_KEY), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey("comp2", "key1", SHARDING_KEY), 0L, 0L)
+            .forFamily(STATE_FAMILY);
     WindmillStateCache.ForKeyAndFamily keyCache4 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key1", 2), STATE_FAMILY, 0L, 0L);
+            .forKey(computationKey("comp1", "key1", 2), 0L, 0L)
+            .forFamily(STATE_FAMILY);
 
     keyCache1.put(StateNamespaces.global(), new TestStateTag("tag1"), new TestState("g1"), 1);
     keyCache1.persist();
@@ -376,19 +433,23 @@ public class WindmillStateCacheTest {
     keyCache1 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key1", 1), STATE_FAMILY, 0L, 1L);
+            .forKey(computationKey("comp1", "key1", 1), 0L, 1L)
+            .forFamily(STATE_FAMILY);
     keyCache2 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key2", SHARDING_KEY), STATE_FAMILY, 0L, 1L);
+            .forKey(computationKey("comp1", "key2", SHARDING_KEY), 0L, 1L)
+            .forFamily(STATE_FAMILY);
     keyCache3 =
         cache
             .forComputation("comp2")
-            .forKey(computationKey("comp2", "key1", SHARDING_KEY), STATE_FAMILY, 0L, 1L);
+            .forKey(computationKey("comp2", "key1", SHARDING_KEY), 0L, 1L)
+            .forFamily(STATE_FAMILY);
     keyCache4 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key1", 2), STATE_FAMILY, 0L, 1L);
+            .forKey(computationKey("comp1", "key1", 2), 0L, 1L)
+            .forFamily(STATE_FAMILY);
     assertEquals(
         new TestState("g1"), keyCache1.get(StateNamespaces.global(), new TestStateTag("tag1")));
     assertEquals(
@@ -403,7 +464,8 @@ public class WindmillStateCacheTest {
     keyCache1 =
         cache
             .forComputation("comp1")
-            .forKey(computationKey("comp1", "key1", 1), STATE_FAMILY, 0L, 2L);
+            .forKey(computationKey("comp1", "key1", 1), 0L, 2L)
+            .forFamily(STATE_FAMILY);
 
     assertNull(keyCache1.get(StateNamespaces.global(), new TestStateTag("tag1")));
     assertEquals(
@@ -448,13 +510,14 @@ public class WindmillStateCacheTest {
   @Test
   public void testBadCoderEquality() throws Exception {
     WindmillStateCache.ForKeyAndFamily keyCache1 =
-        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 0L);
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 0L).forFamily(STATE_FAMILY);
 
     StateTag<TestState> tag = new TestStateTagWithBadEquality("tag1");
     keyCache1.put(StateNamespaces.global(), tag, new TestState("g1"), 1);
     keyCache1.persist();
 
-    keyCache1 = cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, STATE_FAMILY, 0L, 1L);
+    keyCache1 =
+        cache.forComputation(COMPUTATION).forKey(COMPUTATION_KEY, 0L, 1L).forFamily(STATE_FAMILY);
     assertEquals(new TestState("g1"), keyCache1.get(StateNamespaces.global(), tag));
     assertEquals(
         new TestState("g1"),
diff --git a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WindmillStateInternalsTest.java b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WindmillStateInternalsTest.java
index 8366797784b..bef96aa19cb 100644
--- a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WindmillStateInternalsTest.java
+++ b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WindmillStateInternalsTest.java
@@ -146,9 +146,9 @@ public class WindmillStateInternalsTest {
                 .forKey(
                     WindmillComputationKey.create(
                         "comp", ByteString.copyFrom("dummyKey", Charsets.UTF_8), 123),
-                    STATE_FAMILY,
                     17L,
-                    workToken),
+                    workToken)
+                .forFamily(STATE_FAMILY),
             readStateSupplier);
     underTestNewKey =
         new WindmillStateInternals<String>(
@@ -161,9 +161,9 @@ public class WindmillStateInternalsTest {
                 .forKey(
                     WindmillComputationKey.create(
                         "comp", ByteString.copyFrom("dummyNewKey", Charsets.UTF_8), 123),
-                    STATE_FAMILY,
                     17L,
-                    workToken),
+                    workToken)
+                .forFamily(STATE_FAMILY),
             readStateSupplier);
   }
 
