diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironment.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironment.java
index daddcd5e223..ab1831bdd28 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironment.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironment.java
@@ -19,9 +19,9 @@ package org.apache.beam.runners.flink;
 
 import static org.apache.beam.vendor.guava.v20_0.com.google.common.base.Preconditions.checkNotNull;
 
-import com.google.common.annotations.VisibleForTesting;
 import org.apache.beam.runners.core.construction.PipelineResources;
 import org.apache.beam.sdk.Pipeline;
+import org.apache.beam.vendor.guava.v20_0.com.google.common.annotations.VisibleForTesting;
 import org.apache.flink.api.common.JobExecutionResult;
 import org.apache.flink.api.java.ExecutionEnvironment;
 import org.apache.flink.runtime.jobgraph.JobGraph;
@@ -86,6 +86,9 @@ class FlinkPipelineExecutionEnvironment {
     PipelineTranslationModeOptimizer optimizer = new PipelineTranslationModeOptimizer(options);
     optimizer.translate(pipeline);
 
+    // Needs to be done before creating the Flink ExecutionEnvironments
+    prepareFilesToStageForRemoteClusterExecution(options);
+
     FlinkPipelineTranslator translator;
     if (options.isStreaming()) {
       this.flinkStreamEnv =
@@ -104,8 +107,6 @@ class FlinkPipelineExecutionEnvironment {
       translator = new FlinkBatchPipelineTranslator(flinkBatchEnv, options);
     }
 
-    prepareFilesToStageForRemoteClusterExecution(options);
-
     translator.translate(pipeline);
   }
 
@@ -144,4 +145,14 @@ class FlinkPipelineExecutionEnvironment {
     translate(p);
     return flinkStreamEnv.getStreamGraph().getJobGraph();
   }
+
+  @VisibleForTesting
+  ExecutionEnvironment getBatchExecutionEnvironment() {
+    return flinkBatchEnv;
+  }
+
+  @VisibleForTesting
+  StreamExecutionEnvironment getStreamExecutionEnvironment() {
+    return flinkStreamEnv;
+  }
 }
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java
index f86a0dd57b4..78de5b78fff 100644
--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java
@@ -20,6 +20,7 @@ package org.apache.beam.runners.flink;
 import static java.util.Arrays.asList;
 import static org.apache.beam.sdk.testing.RegexMatcher.matches;
 import static org.hamcrest.CoreMatchers.containsString;
+import static org.hamcrest.CoreMatchers.instanceOf;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.CoreMatchers.not;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -32,7 +33,10 @@ import java.io.File;
 import java.io.IOException;
 import java.io.PrintStream;
 import java.io.Serializable;
+import java.net.MalformedURLException;
+import java.net.URL;
 import java.util.List;
+import java.util.stream.Collectors;
 import org.apache.beam.sdk.Pipeline;
 import org.apache.beam.sdk.io.GenerateSequence;
 import org.apache.beam.sdk.io.TextIO;
@@ -43,6 +47,10 @@ import org.apache.beam.sdk.transforms.ParDo;
 import org.apache.beam.sdk.transforms.windowing.FixedWindows;
 import org.apache.beam.sdk.transforms.windowing.Window;
 import org.apache.beam.vendor.guava.v20_0.com.google.common.collect.ImmutableList;
+import org.apache.flink.api.java.ExecutionEnvironment;
+import org.apache.flink.api.java.RemoteEnvironment;
+import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;
+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.joda.time.Duration;
 import org.junit.Rule;
 import org.junit.Test;
@@ -51,6 +59,7 @@ import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
 import org.mockito.ArgumentCaptor;
 import org.mockito.Mockito;
+import org.mockito.internal.util.reflection.Whitebox;
 
 /** Tests for {@link FlinkPipelineExecutionEnvironment}. */
 @RunWith(JUnit4.class)
@@ -118,6 +127,53 @@ public class FlinkPipelineExecutionEnvironmentTest implements Serializable {
     assertThat(options.getFilesToStage(), everyItem(not(matches(".*\\.jar"))));
   }
 
+  @Test
+  public void shouldUsePreparedFilesOnRemoteEnvironment() throws Exception {
+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);
+    options.setRunner(TestFlinkRunner.class);
+    options.setFlinkMaster("clusterAddress");
+
+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);
+
+    Pipeline pipeline = Pipeline.create(options);
+    flinkEnv.translate(pipeline);
+
+    ExecutionEnvironment executionEnvironment = flinkEnv.getBatchExecutionEnvironment();
+    assertThat(executionEnvironment, instanceOf(RemoteEnvironment.class));
+
+    @SuppressWarnings("unchecked")
+    List<URL> jarFiles = (List<URL>) Whitebox.getInternalState(executionEnvironment, "jarFiles");
+
+    List<URL> urlConvertedStagedFiles = convertFilesToURLs(options.getFilesToStage());
+
+    assertThat(jarFiles, is(urlConvertedStagedFiles));
+  }
+
+  @Test
+  public void shouldUsePreparedFilesOnRemoteStreamEnvironment() throws Exception {
+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);
+    options.setRunner(TestFlinkRunner.class);
+    options.setFlinkMaster("clusterAddress");
+    options.setStreaming(true);
+
+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);
+
+    Pipeline pipeline = Pipeline.create(options);
+    flinkEnv.translate(pipeline);
+
+    StreamExecutionEnvironment streamExecutionEnvironment =
+        flinkEnv.getStreamExecutionEnvironment();
+    assertThat(streamExecutionEnvironment, instanceOf(RemoteStreamEnvironment.class));
+
+    @SuppressWarnings("unchecked")
+    List<URL> jarFiles =
+        (List<URL>) Whitebox.getInternalState(streamExecutionEnvironment, "jarFiles");
+
+    List<URL> urlConvertedStagedFiles = convertFilesToURLs(options.getFilesToStage());
+
+    assertThat(jarFiles, is(urlConvertedStagedFiles));
+  }
+
   @Test
   public void shouldUseTransformOverrides() {
     boolean[] testParameters = {true, false};
@@ -203,4 +259,17 @@ public class FlinkPipelineExecutionEnvironmentTest implements Serializable {
     options.setFilesToStage(filesToStage);
     return options;
   }
+
+  private static List<URL> convertFilesToURLs(List<String> filePaths) {
+    return filePaths.stream()
+        .map(
+            file -> {
+              try {
+                return new File(file).getAbsoluteFile().toURI().toURL();
+              } catch (MalformedURLException e) {
+                throw new RuntimeException("Failed to convert to URL", e);
+              }
+            })
+        .collect(Collectors.toList());
+  }
 }
