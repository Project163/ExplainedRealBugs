diff --git a/sdks/python/apache_beam/io/parquetio.py b/sdks/python/apache_beam/io/parquetio.py
index 2df72029dfd..eaf3b55cf3b 100644
--- a/sdks/python/apache_beam/io/parquetio.py
+++ b/sdks/python/apache_beam/io/parquetio.py
@@ -29,11 +29,10 @@ Parquet file.
 """
 from __future__ import absolute_import
 
+import platform
+import sys
 from functools import partial
 
-import pyarrow as pa
-import pyarrow.parquet as pq
-
 from apache_beam.io import filebasedsink
 from apache_beam.io import filebasedsource
 from apache_beam.io.filesystem import CompressionTypes
@@ -42,6 +41,10 @@ from apache_beam.io.iobase import Read
 from apache_beam.io.iobase import Write
 from apache_beam.transforms import PTransform
 
+if not (platform.system() == 'Windows' and sys.version_info[0] == 2):
+  import pyarrow as pa
+  import pyarrow.parquet as pq
+
 __all__ = ['ReadFromParquet', 'ReadAllFromParquet', 'WriteToParquet']
 
 
diff --git a/sdks/python/apache_beam/io/parquetio_it_test.py b/sdks/python/apache_beam/io/parquetio_it_test.py
index 19344e8881f..ba4204cc4a5 100644
--- a/sdks/python/apache_beam/io/parquetio_it_test.py
+++ b/sdks/python/apache_beam/io/parquetio_it_test.py
@@ -18,12 +18,12 @@ from __future__ import absolute_import
 from __future__ import division
 
 import logging
+import platform
 import string
 import sys
 import unittest
 from collections import Counter
 
-import pyarrow as pa
 from nose.plugins.attrib import attr
 
 from apache_beam import Create
@@ -41,7 +41,14 @@ from apache_beam.testing.util import BeamAssertException
 from apache_beam.transforms import CombineGlobally
 from apache_beam.transforms.combiners import Count
 
+if not (platform.system() == 'Windows' and sys.version_info[0] == 2):
+  import pyarrow as pa
 
+
+@unittest.skipIf(
+    platform.system() == 'Windows' and sys.version_info[0] == 2,
+    "pyarrow doesn't support Windows Python 2."
+)
 class TestParquetIT(unittest.TestCase):
 
   @classmethod
@@ -56,12 +63,6 @@ class TestParquetIT(unittest.TestCase):
   def tearDown(self):
     pass
 
-  SCHEMA = pa.schema([
-      ('name', pa.binary()),
-      ('favorite_number', pa.int64()),
-      ('favorite_color', pa.binary())
-  ])
-
   @attr('IT')
   def test_parquetio_it(self):
     file_prefix = "parquet_it_test"
diff --git a/sdks/python/apache_beam/io/parquetio_test.py b/sdks/python/apache_beam/io/parquetio_test.py
index 1615834fc99..8f65c34de1c 100644
--- a/sdks/python/apache_beam/io/parquetio_test.py
+++ b/sdks/python/apache_beam/io/parquetio_test.py
@@ -19,6 +19,7 @@ from __future__ import absolute_import
 import json
 import logging
 import os
+import platform
 import shutil
 import sys
 import tempfile
@@ -26,9 +27,6 @@ import unittest
 
 import hamcrest as hc
 import pandas
-import pyarrow as pa
-import pyarrow.lib as pl
-import pyarrow.parquet as pq
 from parameterized import param
 from parameterized import parameterized
 
@@ -48,7 +46,16 @@ from apache_beam.testing.util import equal_to
 from apache_beam.transforms.display import DisplayData
 from apache_beam.transforms.display_test import DisplayDataItemMatcher
 
+if not (platform.system() == 'Windows' and sys.version_info[0] == 2):
+  import pyarrow as pa
+  import pyarrow.lib as pl
+  import pyarrow.parquet as pq
 
+
+@unittest.skipIf(
+    platform.system() == 'Windows' and sys.version_info[0] == 2,
+    "pyarrow doesn't support Windows Python 2."
+)
 class TestParquet(unittest.TestCase):
 
   @classmethod
@@ -63,37 +70,36 @@ class TestParquet(unittest.TestCase):
     filebasedsource.MAX_NUM_THREADS_FOR_SIZE_ESTIMATION = 2
     self.temp_dir = tempfile.mkdtemp()
 
+    self.RECORDS = [{'name': 'Thomas',
+                     'favorite_number': 1,
+                     'favorite_color': 'blue'}, {'name': 'Henry',
+                                                 'favorite_number': 3,
+                                                 'favorite_color': 'green'},
+                    {'name': 'Toby',
+                     'favorite_number': 7,
+                     'favorite_color': 'brown'}, {'name': 'Gordon',
+                                                  'favorite_number': 4,
+                                                  'favorite_color': 'blue'},
+                    {'name': 'Emily',
+                     'favorite_number': -1,
+                     'favorite_color': 'Red'}, {'name': 'Percy',
+                                                'favorite_number': 6,
+                                                'favorite_color': 'Green'}]
+    self.SCHEMA = pa.schema([
+        ('name', pa.binary()),
+        ('favorite_number', pa.int64()),
+        ('favorite_color', pa.binary())
+    ])
+
+    self.SCHEMA96 = pa.schema([
+        ('name', pa.binary()),
+        ('favorite_number', pa.timestamp('ns')),
+        ('favorite_color', pa.binary())
+    ])
+
   def tearDown(self):
     shutil.rmtree(self.temp_dir)
 
-  RECORDS = [{'name': 'Thomas',
-              'favorite_number': 1,
-              'favorite_color': 'blue'}, {'name': 'Henry',
-                                          'favorite_number': 3,
-                                          'favorite_color': 'green'},
-             {'name': 'Toby',
-              'favorite_number': 7,
-              'favorite_color': 'brown'}, {'name': 'Gordon',
-                                           'favorite_number': 4,
-                                           'favorite_color': 'blue'},
-             {'name': 'Emily',
-              'favorite_number': -1,
-              'favorite_color': 'Red'}, {'name': 'Percy',
-                                         'favorite_number': 6,
-                                         'favorite_color': 'Green'}]
-
-  SCHEMA = pa.schema([
-      ('name', pa.binary()),
-      ('favorite_number', pa.int64()),
-      ('favorite_color', pa.binary())
-  ])
-
-  SCHEMA96 = pa.schema([
-      ('name', pa.binary()),
-      ('favorite_number', pa.timestamp('ns')),
-      ('favorite_color', pa.binary())
-  ])
-
   def _record_to_columns(self, records, schema):
     col_list = []
     for n in schema.names:
@@ -109,13 +115,16 @@ class TestParquet(unittest.TestCase):
                   prefix=tempfile.template,
                   row_group_size=1000,
                   codec='none',
-                  count=len(RECORDS)):
+                  count=None):
     if schema is None:
       schema = self.SCHEMA
 
     if directory is None:
       directory = self.temp_dir
 
+    if count is None:
+      count = len(self.RECORDS)
+
     with tempfile.NamedTemporaryFile(
         delete=False, dir=directory, prefix=prefix) as f:
       len_records = len(self.RECORDS)
diff --git a/sdks/python/setup.py b/sdks/python/setup.py
index 4813e08704f..bdc91f738e6 100644
--- a/sdks/python/setup.py
+++ b/sdks/python/setup.py
@@ -159,6 +159,12 @@ elif sys.version_info[0] >= 3:
                       '@7a73fbe3d6aa445f93f58f266687b7315d14a3ac'
                       '#egg=dill-0.2.9.dev0']
 
+# pyarrow is not supported on Windows Python 2 [BEAM-6287]
+if platform.system() == 'Windows' and sys.version_info[0] == 2:
+  REQUIRED_PACKAGES = [
+      x for x in REQUIRED_PACKAGES if not x.startswith("pyarrow")
+  ]
+
 
 # We must generate protos after setup_requires are installed.
 def generate_protos_first(original_cmd):
