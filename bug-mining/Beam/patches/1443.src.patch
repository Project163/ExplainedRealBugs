diff --git a/runners/apex/build.gradle b/runners/apex/build.gradle
index 06a3d3390ab..739fd9d565b 100644
--- a/runners/apex/build.gradle
+++ b/runners/apex/build.gradle
@@ -98,12 +98,8 @@ task validatesRunnerBatch(type: Test) {
     excludeCategories 'org.apache.beam.sdk.testing.UsesMetricsPusher'
     excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedSplittableParDo'
     excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedPCollections'
-    // TODO[BEAM-8204]: figure out if we can make the test work on Apex runner, or maybe create a
-    // more meaningful category tag.
+    // TODO[BEAM-8304]: Support multiple side inputs with different coders.
     excludeCategories 'org.apache.beam.sdk.testing.UsesSideInputsWithDifferentCoders'
-    // TODO[BEAM-8204]: figure out if we can make the test work on Apex runner, or maybe create a
-    // new category tag and change the following line to: excludeCategories '<category tag>'.
-    exclude '**/AvroSchemaTest.class'
   }
 
   // apex runner is run in embedded mode. Increase default HeapSize
diff --git a/runners/flink/flink_runner.gradle b/runners/flink/flink_runner.gradle
index 1ffcaf6c54e..3254a857d61 100644
--- a/runners/flink/flink_runner.gradle
+++ b/runners/flink/flink_runner.gradle
@@ -205,9 +205,6 @@ def createValidatesRunnerTask(Map m) {
         excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedSplittableParDo'
         excludeCategories 'org.apache.beam.sdk.testing.UsesTestStream'
       }
-      // TODO[BEAM-8205]: figure out if we can make the test work on Flink runner, or maybe create a
-      // new category tag and change the following line to: excludeCategories '<category tag>'.
-      exclude '**/AvroSchemaTest.class'
     }
   }
 }
diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/SchemaCoderCloudObjectTranslator.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/SchemaCoderCloudObjectTranslator.java
index 2ff8c771f79..8ea562b36af 100644
--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/SchemaCoderCloudObjectTranslator.java
+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/SchemaCoderCloudObjectTranslator.java
@@ -26,10 +26,12 @@ import org.apache.beam.sdk.schemas.SchemaCoder;
 import org.apache.beam.sdk.transforms.SerializableFunction;
 import org.apache.beam.sdk.util.SerializableUtils;
 import org.apache.beam.sdk.util.StringUtils;
+import org.apache.beam.sdk.values.TypeDescriptor;
 
 /** Translator for Schema coders. */
 public class SchemaCoderCloudObjectTranslator implements CloudObjectTranslator<SchemaCoder> {
   private static final String SCHEMA = "schema";
+  private static final String TYPE_DESCRIPTOR = "typeDescriptor";
   private static final String TO_ROW_FUNCTION = "toRowFunction";
   private static final String FROM_ROW_FUNCTION = "fromRowFunction";
 
@@ -38,6 +40,11 @@ public class SchemaCoderCloudObjectTranslator implements CloudObjectTranslator<S
   public CloudObject toCloudObject(SchemaCoder target, SdkComponents sdkComponents) {
     CloudObject base = CloudObject.forClass(SchemaCoder.class);
 
+    Structs.addString(
+        base,
+        TYPE_DESCRIPTOR,
+        StringUtils.byteArrayToJsonString(
+            SerializableUtils.serializeToByteArray(target.getEncodedTypeDescriptor())));
     Structs.addString(
         base,
         TO_ROW_FUNCTION,
@@ -60,6 +67,12 @@ public class SchemaCoderCloudObjectTranslator implements CloudObjectTranslator<S
   @Override
   public SchemaCoder fromCloudObject(CloudObject cloudObject) {
     try {
+      TypeDescriptor typeDescriptor =
+          (TypeDescriptor)
+              SerializableUtils.deserializeFromByteArray(
+                  StringUtils.jsonStringToByteArray(
+                      Structs.getString(cloudObject, TYPE_DESCRIPTOR)),
+                  "typeDescriptor");
       SerializableFunction toRowFunction =
           (SerializableFunction)
               SerializableUtils.deserializeFromByteArray(
@@ -76,7 +89,7 @@ public class SchemaCoderCloudObjectTranslator implements CloudObjectTranslator<S
           SchemaApi.Schema.parseFrom(
               StringUtils.jsonStringToByteArray(Structs.getString(cloudObject, SCHEMA)));
       Schema schema = SchemaTranslation.fromProto(protoSchema);
-      return SchemaCoder.of(schema, toRowFunction, fromRowFunction);
+      return SchemaCoder.of(schema, typeDescriptor, toRowFunction, fromRowFunction);
     } catch (IOException e) {
       throw new RuntimeException(e);
     }
diff --git a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/CloudObjectsTest.java b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/CloudObjectsTest.java
index 7f10d926a03..09f9fa9835a 100644
--- a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/CloudObjectsTest.java
+++ b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/CloudObjectsTest.java
@@ -65,6 +65,7 @@ import org.apache.beam.sdk.util.InstanceBuilder;
 import org.apache.beam.sdk.util.WindowedValue;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TupleTag;
+import org.apache.beam.sdk.values.TypeDescriptors;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList.Builder;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;
@@ -165,8 +166,15 @@ public class CloudObjectsTest {
                       CoGbkResultSchema.of(
                           ImmutableList.of(new TupleTag<Long>(), new TupleTag<byte[]>())),
                       UnionCoder.of(ImmutableList.of(VarLongCoder.of(), ByteArrayCoder.of()))))
-              .add(SchemaCoder.of(Schema.builder().build(), new RowIdentity(), new RowIdentity()))
-              .add(SchemaCoder.of(TEST_SCHEMA, new RowIdentity(), new RowIdentity()));
+              .add(
+                  SchemaCoder.of(
+                      Schema.builder().build(),
+                      TypeDescriptors.rows(),
+                      new RowIdentity(),
+                      new RowIdentity()))
+              .add(
+                  SchemaCoder.of(
+                      TEST_SCHEMA, TypeDescriptors.rows(), new RowIdentity(), new RowIdentity()));
       for (Class<? extends Coder> atomicCoder :
           DefaultCoderCloudObjectTranslatorRegistrar.KNOWN_ATOMIC_CODERS) {
         dataBuilder.add(InstanceBuilder.ofType(atomicCoder).fromFactoryMethod("of").build());
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/coders/RowCoder.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/coders/RowCoder.java
index b94f30ff4da..03259ff4c96 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/coders/RowCoder.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/coders/RowCoder.java
@@ -23,6 +23,7 @@ import org.apache.beam.sdk.schemas.Schema;
 import org.apache.beam.sdk.schemas.SchemaCoder;
 import org.apache.beam.sdk.transforms.SerializableFunctions;
 import org.apache.beam.sdk.values.Row;
+import org.apache.beam.sdk.values.TypeDescriptors;
 
 /** A sub-class of SchemaCoder that can only encode {@link Row} instances. */
 @Experimental
@@ -32,7 +33,11 @@ public class RowCoder extends SchemaCoder<Row> {
   }
 
   private RowCoder(Schema schema) {
-    super(schema, SerializableFunctions.identity(), SerializableFunctions.identity());
+    super(
+        schema,
+        TypeDescriptors.rows(),
+        SerializableFunctions.identity(),
+        SerializableFunctions.identity());
   }
 
   @Override
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroIO.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroIO.java
index bb0e062bdfc..ac48848f6a4 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroIO.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroIO.java
@@ -59,6 +59,7 @@ import org.apache.beam.sdk.transforms.display.DisplayData;
 import org.apache.beam.sdk.values.PBegin;
 import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.PDone;
+import org.apache.beam.sdk.values.TypeDescriptor;
 import org.apache.beam.sdk.values.TypeDescriptors;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Function;
@@ -569,6 +570,7 @@ public class AvroIO {
     if (beamSchema != null) {
       pc.setSchema(
           beamSchema,
+          TypeDescriptor.of(clazz),
           org.apache.beam.sdk.schemas.utils.AvroUtils.getToRowFunction(clazz, schema),
           org.apache.beam.sdk.schemas.utils.AvroUtils.getFromRowFunction(clazz));
     }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/AutoValueSchema.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/AutoValueSchema.java
index 1a11a62ab34..dc8092209aa 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/AutoValueSchema.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/AutoValueSchema.java
@@ -60,47 +60,42 @@ public class AutoValueSchema extends GetterBasedSchemaProvider {
   }
 
   @Override
-  FieldValueGetterFactory fieldValueGetterFactory() {
-    return (Class<?> targetClass, Schema schema) ->
-        JavaBeanUtils.getGetters(targetClass, schema, AbstractGetterTypeSupplier.INSTANCE);
+  List<FieldValueGetter> fieldValueGetters(Class<?> targetClass, Schema schema) {
+    return JavaBeanUtils.getGetters(targetClass, schema, AbstractGetterTypeSupplier.INSTANCE);
   }
 
   @Override
-  FieldValueTypeInformationFactory fieldValueTypeInformationFactory() {
-    return (Class<?> targetClass, Schema schema) ->
-        JavaBeanUtils.getFieldTypes(targetClass, schema, AbstractGetterTypeSupplier.INSTANCE);
+  List<FieldValueTypeInformation> fieldValueTypeInformations(Class<?> targetClass, Schema schema) {
+    return JavaBeanUtils.getFieldTypes(targetClass, schema, AbstractGetterTypeSupplier.INSTANCE);
   }
 
   @Override
-  UserTypeCreatorFactory schemaTypeCreatorFactory() {
-    return (Class<?> targetClass, Schema schema) -> {
-      // If a static method is marked with @SchemaCreate, use that.
-      Method annotated = ReflectUtils.getAnnotatedCreateMethod(targetClass);
-      if (annotated != null) {
-        return JavaBeanUtils.getStaticCreator(
-            targetClass, annotated, schema, AbstractGetterTypeSupplier.INSTANCE);
-      }
+  SchemaUserTypeCreator schemaTypeCreator(Class<?> targetClass, Schema schema) {
+    // If a static method is marked with @SchemaCreate, use that.
+    Method annotated = ReflectUtils.getAnnotatedCreateMethod(targetClass);
+    if (annotated != null) {
+      return JavaBeanUtils.getStaticCreator(
+          targetClass, annotated, schema, AbstractGetterTypeSupplier.INSTANCE);
+    }
 
-      // Try to find a generated builder class. If one exists, use that to generate a
-      // SchemaTypeCreator for creating AutoValue objects.
-      SchemaUserTypeCreator creatorFactory =
-          AutoValueUtils.getBuilderCreator(
-              targetClass, schema, AbstractGetterTypeSupplier.INSTANCE);
-      if (creatorFactory != null) {
-        return creatorFactory;
-      }
+    // Try to find a generated builder class. If one exists, use that to generate a
+    // SchemaTypeCreator for creating AutoValue objects.
+    SchemaUserTypeCreator creatorFactory =
+        AutoValueUtils.getBuilderCreator(targetClass, schema, AbstractGetterTypeSupplier.INSTANCE);
+    if (creatorFactory != null) {
+      return creatorFactory;
+    }
 
-      // If there is no builder, there should be a package-private constructor in the generated
-      // class. Use that for creating AutoValue objects.
-      creatorFactory =
-          AutoValueUtils.getConstructorCreator(
-              targetClass, schema, AbstractGetterTypeSupplier.INSTANCE);
-      if (creatorFactory == null) {
-        throw new RuntimeException("Could not find a way to create AutoValue class " + targetClass);
-      }
+    // If there is no builder, there should be a package-private constructor in the generated
+    // class. Use that for creating AutoValue objects.
+    creatorFactory =
+        AutoValueUtils.getConstructorCreator(
+            targetClass, schema, AbstractGetterTypeSupplier.INSTANCE);
+    if (creatorFactory == null) {
+      throw new RuntimeException("Could not find a way to create AutoValue class " + targetClass);
+    }
 
-      return creatorFactory;
-    };
+    return creatorFactory;
   }
 
   @Nullable
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/AvroRecordSchema.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/AvroRecordSchema.java
index 0025864fc56..e1993549410 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/AvroRecordSchema.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/AvroRecordSchema.java
@@ -19,6 +19,7 @@ package org.apache.beam.sdk.schemas;
 
 import static org.apache.beam.sdk.schemas.utils.AvroUtils.toBeamSchema;
 
+import java.util.List;
 import org.apache.avro.reflect.ReflectData;
 import org.apache.beam.sdk.schemas.utils.AvroUtils;
 import org.apache.beam.sdk.values.TypeDescriptor;
@@ -37,17 +38,17 @@ public class AvroRecordSchema extends GetterBasedSchemaProvider {
   }
 
   @Override
-  public FieldValueGetterFactory fieldValueGetterFactory() {
-    return AvroUtils::getGetters;
+  List<FieldValueGetter> fieldValueGetters(Class<?> targetClass, Schema schema) {
+    return AvroUtils.getGetters(targetClass, schema);
   }
 
   @Override
-  public UserTypeCreatorFactory schemaTypeCreatorFactory() {
-    return AvroUtils::getCreator;
+  List<FieldValueTypeInformation> fieldValueTypeInformations(Class<?> targetClass, Schema schema) {
+    return AvroUtils.getFieldTypes(targetClass, schema);
   }
 
   @Override
-  public FieldValueTypeInformationFactory fieldValueTypeInformationFactory() {
-    return AvroUtils::getFieldTypes;
+  SchemaUserTypeCreator schemaTypeCreator(Class<?> targetClass, Schema schema) {
+    return AvroUtils.getCreator(targetClass, schema);
   }
 }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/CachingFactory.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/CachingFactory.java
index ee6713e358c..64f02d9f651 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/CachingFactory.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/CachingFactory.java
@@ -17,6 +17,7 @@
  */
 package org.apache.beam.sdk.schemas;
 
+import java.util.Objects;
 import java.util.concurrent.ConcurrentHashMap;
 import javax.annotation.Nullable;
 
@@ -52,4 +53,21 @@ class CachingFactory<CreatedT> implements Factory<CreatedT> {
     cache.put(clazz, cached);
     return cached;
   }
+
+  @Override
+  public boolean equals(Object o) {
+    if (this == o) {
+      return true;
+    }
+    if (o == null || getClass() != o.getClass()) {
+      return false;
+    }
+    CachingFactory<?> that = (CachingFactory<?>) o;
+    return innerFactory.equals(that.innerFactory);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hash(innerFactory);
+  }
 }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/FromRowUsingCreator.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/FromRowUsingCreator.java
index 2f731dc2593..e87386b8faa 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/FromRowUsingCreator.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/FromRowUsingCreator.java
@@ -23,6 +23,7 @@ import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Prec
 import java.lang.reflect.Type;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import javax.annotation.Nullable;
 import org.apache.beam.sdk.schemas.Schema.FieldType;
 import org.apache.beam.sdk.schemas.Schema.TypeName;
@@ -35,16 +36,16 @@ import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Maps;
 /** Function to convert a {@link Row} to a user type using a creator factory. */
 class FromRowUsingCreator<T> implements SerializableFunction<Row, T> {
   private final Class<T> clazz;
+  private final GetterBasedSchemaProvider schemaProvider;
   private final Factory<SchemaUserTypeCreator> schemaTypeCreatorFactory;
   private final Factory<List<FieldValueTypeInformation>> fieldValueTypeInformationFactory;
 
-  public FromRowUsingCreator(
-      Class<T> clazz,
-      UserTypeCreatorFactory schemaTypeUserTypeCreatorFactory,
-      FieldValueTypeInformationFactory fieldValueTypeInformationFactory) {
+  public FromRowUsingCreator(Class<T> clazz, GetterBasedSchemaProvider schemaProvider) {
     this.clazz = clazz;
-    this.schemaTypeCreatorFactory = new CachingFactory<>(schemaTypeUserTypeCreatorFactory);
-    this.fieldValueTypeInformationFactory = new CachingFactory<>(fieldValueTypeInformationFactory);
+    this.schemaProvider = schemaProvider;
+    this.schemaTypeCreatorFactory = new CachingFactory<>(schemaProvider::schemaTypeCreator);
+    this.fieldValueTypeInformationFactory =
+        new CachingFactory<>(schemaProvider::fieldValueTypeInformations);
   }
 
   @Override
@@ -173,4 +174,21 @@ class FromRowUsingCreator<T> implements SerializableFunction<Row, T> {
     }
     return newMap;
   }
+
+  @Override
+  public boolean equals(Object o) {
+    if (this == o) {
+      return true;
+    }
+    if (o == null || getClass() != o.getClass()) {
+      return false;
+    }
+    FromRowUsingCreator<?> that = (FromRowUsingCreator<?>) o;
+    return clazz.equals(that.clazz) && schemaProvider.equals(that.schemaProvider);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hash(clazz, schemaProvider);
+  }
 }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/GetterBasedSchemaProvider.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/GetterBasedSchemaProvider.java
index 677823f9c0d..1d18d639f0c 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/GetterBasedSchemaProvider.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/GetterBasedSchemaProvider.java
@@ -18,6 +18,7 @@
 package org.apache.beam.sdk.schemas;
 
 import java.util.List;
+import java.util.Objects;
 import org.apache.beam.sdk.annotations.Experimental;
 import org.apache.beam.sdk.annotations.Experimental.Kind;
 import org.apache.beam.sdk.transforms.SerializableFunction;
@@ -30,14 +31,55 @@ import org.apache.beam.sdk.values.TypeDescriptor;
  */
 @Experimental(Kind.SCHEMAS)
 public abstract class GetterBasedSchemaProvider implements SchemaProvider {
-  /** Implementing class should override to return a getter factory. */
-  abstract FieldValueGetterFactory fieldValueGetterFactory();
+  /** Implementing class should override to return FieldValueGetters. */
+  abstract List<FieldValueGetter> fieldValueGetters(Class<?> targetClass, Schema schema);
 
-  /** Implementing class should override to return a type-information factory. */
-  abstract FieldValueTypeInformationFactory fieldValueTypeInformationFactory();
+  /** Implementing class should override to return a list of type-informations. */
+  abstract List<FieldValueTypeInformation> fieldValueTypeInformations(
+      Class<?> targetClass, Schema schema);
 
-  /** Implementing class should override to return a constructor factory. */
-  abstract UserTypeCreatorFactory schemaTypeCreatorFactory();
+  /** Implementing class should override to return a constructor. */
+  abstract SchemaUserTypeCreator schemaTypeCreator(Class<?> targetClass, Schema schema);
+
+  private class ToRowWithValueGetters<T> implements SerializableFunction<T, Row> {
+    private final Schema schema;
+    private final Factory<List<FieldValueGetter>> getterFactory;
+
+    public ToRowWithValueGetters(Schema schema) {
+      this.schema = schema;
+      // Since we know that this factory is always called from inside the lambda with the same
+      // schema,
+      // return a caching factory that caches the first value seen for each class. This prevents
+      // having to lookup the getter list each time createGetters is called.
+      this.getterFactory = new CachingFactory<>(GetterBasedSchemaProvider.this::fieldValueGetters);
+    }
+
+    @Override
+    public Row apply(T input) {
+      return Row.withSchema(schema).withFieldValueGetters(getterFactory, input).build();
+    }
+
+    private GetterBasedSchemaProvider getOuter() {
+      return GetterBasedSchemaProvider.this;
+    }
+
+    @Override
+    public boolean equals(Object o) {
+      if (this == o) {
+        return true;
+      }
+      if (o == null || getClass() != o.getClass()) {
+        return false;
+      }
+      ToRowWithValueGetters<?> that = (ToRowWithValueGetters<?>) o;
+      return getOuter().equals(that.getOuter()) && schema.equals(that.schema);
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(GetterBasedSchemaProvider.this, schema);
+    }
+  }
 
   @Override
   public <T> SerializableFunction<T, Row> toRowFunction(TypeDescriptor<T> typeDescriptor) {
@@ -49,18 +91,23 @@ public abstract class GetterBasedSchemaProvider implements SchemaProvider {
     // workers would see different versions of the schema.
     Schema schema = schemaFor(typeDescriptor);
 
-    // Since we know that this factory is always called from inside the lambda with the same schema,
-    // return a caching factory that caches the first value seen for each class. This prevents
-    // having to lookup the getter list each time createGetters is called.
-    Factory<List<FieldValueGetter>> getterFactory = new CachingFactory<>(fieldValueGetterFactory());
-    return o -> Row.withSchema(schema).withFieldValueGetters(getterFactory, o).build();
+    return new ToRowWithValueGetters<>(schema);
   }
 
   @Override
   @SuppressWarnings("unchecked")
   public <T> SerializableFunction<Row, T> fromRowFunction(TypeDescriptor<T> typeDescriptor) {
     Class<T> clazz = (Class<T>) typeDescriptor.getType();
-    return new FromRowUsingCreator<>(
-        clazz, schemaTypeCreatorFactory(), fieldValueTypeInformationFactory());
+    return new FromRowUsingCreator<>(clazz, this);
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode();
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    return obj != null && this.getClass() == obj.getClass();
   }
 }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/JavaBeanSchema.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/JavaBeanSchema.java
index 8540b3d683b..6a6eb84c16f 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/JavaBeanSchema.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/JavaBeanSchema.java
@@ -64,6 +64,16 @@ public class JavaBeanSchema extends GetterBasedSchemaProvider {
               })
           .collect(Collectors.toList());
     }
+
+    @Override
+    public int hashCode() {
+      return System.identityHashCode(this);
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      return obj != null && this.getClass() == obj.getClass();
+    }
   }
 
   /** {@link FieldValueTypeSupplier} that's based on setter methods. */
@@ -79,6 +89,16 @@ public class JavaBeanSchema extends GetterBasedSchemaProvider {
           .map(FieldValueTypeInformation::forSetter)
           .collect(Collectors.toList());
     }
+
+    @Override
+    public int hashCode() {
+      return System.identityHashCode(this);
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      return obj != null && this.getClass() == obj.getClass();
+    }
   }
 
   @Override
@@ -99,39 +119,35 @@ public class JavaBeanSchema extends GetterBasedSchemaProvider {
   }
 
   @Override
-  public FieldValueGetterFactory fieldValueGetterFactory() {
-    return (Class<?> targetClass, Schema schema) ->
-        JavaBeanUtils.getGetters(targetClass, schema, GetterTypeSupplier.INSTANCE);
+  List<FieldValueGetter> fieldValueGetters(Class<?> targetClass, Schema schema) {
+    return JavaBeanUtils.getGetters(targetClass, schema, GetterTypeSupplier.INSTANCE);
   }
 
   @Override
-  UserTypeCreatorFactory schemaTypeCreatorFactory() {
-    UserTypeCreatorFactory setterBasedFactory =
-        new SetterBasedCreatorFactory(new JavaBeanSetterFactory());
-
-    return (Class<?> targetClass, Schema schema) -> {
-      // If a static method is marked with @SchemaCreate, use that.
-      Method annotated = ReflectUtils.getAnnotatedCreateMethod(targetClass);
-      if (annotated != null) {
-        return JavaBeanUtils.getStaticCreator(
-            targetClass, annotated, schema, GetterTypeSupplier.INSTANCE);
-      }
-
-      // If a Constructor was tagged with @SchemaCreate, invoke that constructor.
-      Constructor<?> constructor = ReflectUtils.getAnnotatedConstructor(targetClass);
-      if (constructor != null) {
-        return JavaBeanUtils.getConstructorCreator(
-            targetClass, constructor, schema, GetterTypeSupplier.INSTANCE);
-      }
-
-      return setterBasedFactory.create(targetClass, schema);
-    };
+  List<FieldValueTypeInformation> fieldValueTypeInformations(Class<?> targetClass, Schema schema) {
+    return JavaBeanUtils.getFieldTypes(targetClass, schema, GetterTypeSupplier.INSTANCE);
   }
 
   @Override
-  public FieldValueTypeInformationFactory fieldValueTypeInformationFactory() {
-    return (Class<?> targetClass, Schema schema) ->
-        JavaBeanUtils.getFieldTypes(targetClass, schema, GetterTypeSupplier.INSTANCE);
+  SchemaUserTypeCreator schemaTypeCreator(Class<?> targetClass, Schema schema) {
+    // If a static method is marked with @SchemaCreate, use that.
+    Method annotated = ReflectUtils.getAnnotatedCreateMethod(targetClass);
+    if (annotated != null) {
+      return JavaBeanUtils.getStaticCreator(
+          targetClass, annotated, schema, GetterTypeSupplier.INSTANCE);
+    }
+
+    // If a Constructor was tagged with @SchemaCreate, invoke that constructor.
+    Constructor<?> constructor = ReflectUtils.getAnnotatedConstructor(targetClass);
+    if (constructor != null) {
+      return JavaBeanUtils.getConstructorCreator(
+          targetClass, constructor, schema, GetterTypeSupplier.INSTANCE);
+    }
+
+    // Else try to make a setter-based creator
+    UserTypeCreatorFactory setterBasedFactory =
+        new SetterBasedCreatorFactory(new JavaBeanSetterFactory());
+    return setterBasedFactory.create(targetClass, schema);
   }
 
   /** A factory for creating {@link FieldValueSetter} objects for a JavaBean object. */
@@ -141,4 +157,14 @@ public class JavaBeanSchema extends GetterBasedSchemaProvider {
       return JavaBeanUtils.getSetters(targetClass, schema, SetterTypeSupplier.INSTANCE);
     }
   }
+
+  @Override
+  public int hashCode() {
+    return System.identityHashCode(this);
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    return obj != null && this.getClass() == obj.getClass();
+  }
 }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/JavaFieldSchema.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/JavaFieldSchema.java
index 1d63cd7d03e..9c84a4e6fc7 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/JavaFieldSchema.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/JavaFieldSchema.java
@@ -96,35 +96,31 @@ public class JavaFieldSchema extends GetterBasedSchemaProvider {
   }
 
   @Override
-  public FieldValueGetterFactory fieldValueGetterFactory() {
-    return (Class<?> targetClass, Schema schema) ->
-        POJOUtils.getGetters(targetClass, schema, JavaFieldTypeSupplier.INSTANCE);
+  List<FieldValueGetter> fieldValueGetters(Class<?> targetClass, Schema schema) {
+    return POJOUtils.getGetters(targetClass, schema, JavaFieldTypeSupplier.INSTANCE);
   }
 
   @Override
-  public FieldValueTypeInformationFactory fieldValueTypeInformationFactory() {
-    return (Class<?> targetClass, Schema schema) ->
-        POJOUtils.getFieldTypes(targetClass, schema, JavaFieldTypeSupplier.INSTANCE);
+  List<FieldValueTypeInformation> fieldValueTypeInformations(Class<?> targetClass, Schema schema) {
+    return POJOUtils.getFieldTypes(targetClass, schema, JavaFieldTypeSupplier.INSTANCE);
   }
 
   @Override
-  UserTypeCreatorFactory schemaTypeCreatorFactory() {
-    return (Class<?> targetClass, Schema schema) -> {
-      // If a static method is marked with @SchemaCreate, use that.
-      Method annotated = ReflectUtils.getAnnotatedCreateMethod(targetClass);
-      if (annotated != null) {
-        return POJOUtils.getStaticCreator(
-            targetClass, annotated, schema, JavaFieldTypeSupplier.INSTANCE);
-      }
+  SchemaUserTypeCreator schemaTypeCreator(Class<?> targetClass, Schema schema) {
+    // If a static method is marked with @SchemaCreate, use that.
+    Method annotated = ReflectUtils.getAnnotatedCreateMethod(targetClass);
+    if (annotated != null) {
+      return POJOUtils.getStaticCreator(
+          targetClass, annotated, schema, JavaFieldTypeSupplier.INSTANCE);
+    }
 
-      // If a Constructor was tagged with @SchemaCreate, invoke that constructor.
-      Constructor<?> constructor = ReflectUtils.getAnnotatedConstructor(targetClass);
-      if (constructor != null) {
-        return POJOUtils.getConstructorCreator(
-            targetClass, constructor, schema, JavaFieldTypeSupplier.INSTANCE);
-      }
+    // If a Constructor was tagged with @SchemaCreate, invoke that constructor.
+    Constructor<?> constructor = ReflectUtils.getAnnotatedConstructor(targetClass);
+    if (constructor != null) {
+      return POJOUtils.getConstructorCreator(
+          targetClass, constructor, schema, JavaFieldTypeSupplier.INSTANCE);
+    }
 
-      return POJOUtils.getSetFieldCreator(targetClass, schema, JavaFieldTypeSupplier.INSTANCE);
-    };
+    return POJOUtils.getSetFieldCreator(targetClass, schema, JavaFieldTypeSupplier.INSTANCE);
   }
 }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/SchemaCoder.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/SchemaCoder.java
index 8b2e126f36a..e4aabbf4215 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/SchemaCoder.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/SchemaCoder.java
@@ -17,6 +17,8 @@
  */
 package org.apache.beam.sdk.schemas;
 
+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;
+
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
@@ -48,13 +50,13 @@ import org.apache.beam.sdk.schemas.Schema.TypeName;
 import org.apache.beam.sdk.transforms.SerializableFunction;
 import org.apache.beam.sdk.util.SerializableUtils;
 import org.apache.beam.sdk.values.Row;
+import org.apache.beam.sdk.values.TypeDescriptor;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
 
 /** {@link SchemaCoder} is used as the coder for types that have schemas registered. */
 @Experimental(Kind.SCHEMAS)
 public class SchemaCoder<T> extends CustomCoder<T> {
-
   // This contains a map of primitive types to their coders.
   public static final ImmutableMap<TypeName, Coder> CODER_MAP =
       ImmutableMap.<TypeName, Coder>builder()
@@ -72,14 +74,20 @@ public class SchemaCoder<T> extends CustomCoder<T> {
           .build();
 
   protected final Schema schema;
+  private final TypeDescriptor<T> typeDescriptor;
   private final SerializableFunction<T, Row> toRowFunction;
   private final SerializableFunction<Row, T> fromRowFunction;
   @Nullable private transient Coder<Row> delegateCoder;
 
   protected SchemaCoder(
       Schema schema,
+      TypeDescriptor<T> typeDescriptor,
       SerializableFunction<T, Row> toRowFunction,
       SerializableFunction<Row, T> fromRowFunction) {
+    checkArgument(
+        !typeDescriptor.hasUnresolvedParameters(),
+        "Cannot create SchemaCoder with a TypeDescriptor that has unresolved parameters: %s",
+        typeDescriptor);
     if (schema.getUUID() == null) {
       // Clone the schema before modifying the Java object.
       schema = SerializableUtils.clone(schema);
@@ -87,6 +95,7 @@ public class SchemaCoder<T> extends CustomCoder<T> {
     }
     this.toRowFunction = toRowFunction;
     this.fromRowFunction = fromRowFunction;
+    this.typeDescriptor = typeDescriptor;
     this.schema = schema;
   }
 
@@ -96,9 +105,10 @@ public class SchemaCoder<T> extends CustomCoder<T> {
    */
   public static <T> SchemaCoder<T> of(
       Schema schema,
+      TypeDescriptor<T> typeDescriptor,
       SerializableFunction<T, Row> toRowFunction,
       SerializableFunction<Row, T> fromRowFunction) {
-    return new SchemaCoder<>(schema, toRowFunction, fromRowFunction);
+    return new SchemaCoder<>(schema, typeDescriptor, toRowFunction, fromRowFunction);
   }
 
   /** Returns a {@link SchemaCoder} for {@link Row} instances with the given {@code schema}. */
@@ -232,12 +242,42 @@ public class SchemaCoder<T> extends CustomCoder<T> {
     }
     SchemaCoder<?> that = (SchemaCoder<?>) o;
     return schema.equals(that.schema)
+        && typeDescriptor.equals(that.typeDescriptor)
         && toRowFunction.equals(that.toRowFunction)
         && fromRowFunction.equals(that.fromRowFunction);
   }
 
   @Override
   public int hashCode() {
-    return Objects.hash(schema, toRowFunction, fromRowFunction);
+    return Objects.hash(schema, typeDescriptor, toRowFunction, fromRowFunction);
+  }
+
+  private static RowIdentity identity() {
+    return new RowIdentity();
+  }
+
+  private static class RowIdentity implements SerializableFunction<Row, Row> {
+    @Override
+    public Row apply(Row input) {
+      return input;
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(getClass());
+    }
+
+    @Override
+    public boolean equals(Object o) {
+      if (this == o) {
+        return true;
+      }
+      return o != null && getClass() == o.getClass();
+    }
+  }
+
+  @Override
+  public TypeDescriptor<T> getEncodedTypeDescriptor() {
+    return this.typeDescriptor;
   }
 }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/UserTypeCreatorFactory.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/UserTypeCreatorFactory.java
index 1e4c902de2d..637caed2e28 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/UserTypeCreatorFactory.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/UserTypeCreatorFactory.java
@@ -17,7 +17,10 @@
  */
 package org.apache.beam.sdk.schemas;
 
-/** A factory for {@link SchemaUserTypeCreator} objects. */
+/**
+ * A factory for creating {@link SchemaUserTypeCreator} objects from a user class and its inferred
+ * schema.
+ */
 public interface UserTypeCreatorFactory extends Factory<SchemaUserTypeCreator> {
   @Override
   SchemaUserTypeCreator create(Class<?> clazz, Schema schema);
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/transforms/Convert.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/transforms/Convert.java
index 1625cf27db7..fc5e21c328c 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/transforms/Convert.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/transforms/Convert.java
@@ -145,6 +145,7 @@ public class Convert {
         output =
             output.setSchema(
                 converted.outputSchemaCoder.getSchema(),
+                outputTypeDescriptor,
                 converted.outputSchemaCoder.getToRowFunction(),
                 converted.outputSchemaCoder.getFromRowFunction());
       } else {
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/transforms/SchemaAggregateFn.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/transforms/SchemaAggregateFn.java
index b82ecaf4be9..82169e7eddd 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/transforms/SchemaAggregateFn.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/transforms/SchemaAggregateFn.java
@@ -38,7 +38,6 @@ import org.apache.beam.sdk.transforms.CombineFns;
 import org.apache.beam.sdk.transforms.CombineFns.CoCombineResult;
 import org.apache.beam.sdk.transforms.CombineFns.ComposedCombineFn;
 import org.apache.beam.sdk.transforms.SerializableFunction;
-import org.apache.beam.sdk.transforms.SerializableFunctions;
 import org.apache.beam.sdk.transforms.SimpleFunction;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TupleTag;
@@ -297,8 +296,7 @@ class SchemaAggregateFn {
 
     @Override
     public Coder<Row> getDefaultOutputCoder(CoderRegistry registry, Coder<T> inputCoder) {
-      return SchemaCoder.of(
-          getOutputSchema(), SerializableFunctions.identity(), SerializableFunctions.identity());
+      return SchemaCoder.of(getOutputSchema());
     }
 
     @Override
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/AvroUtils.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/AvroUtils.java
index 7b43961437c..2f72475776d 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/AvroUtils.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/AvroUtils.java
@@ -245,7 +245,7 @@ public class AvroUtils {
 
   /**
    * Convert from a Beam Row to an AVRO GenericRecord. If a Schema is not provided, one is inferred
-   * from the Beam schema on the orw.
+   * from the Beam schema on the row.
    */
   public static GenericRecord toGenericRecord(
       Row row, @Nullable org.apache.avro.Schema avroSchema) {
@@ -329,7 +329,10 @@ public class AvroUtils {
   public static <T> SchemaCoder<T> schemaCoder(TypeDescriptor<T> type) {
     @SuppressWarnings("unchecked")
     Class<T> clazz = (Class<T>) type.getRawType();
-    return schemaCoder(clazz);
+    org.apache.avro.Schema avroSchema = new ReflectData(clazz.getClassLoader()).getSchema(clazz);
+    Schema beamSchema = toBeamSchema(avroSchema);
+    return SchemaCoder.of(
+        beamSchema, type, getToRowFunction(clazz, avroSchema), getFromRowFunction(clazz));
   }
 
   /**
@@ -338,7 +341,7 @@ public class AvroUtils {
    * @param <T> the element type
    */
   public static <T> SchemaCoder<T> schemaCoder(Class<T> clazz) {
-    return schemaCoder(clazz, new ReflectData(clazz.getClassLoader()).getSchema(clazz));
+    return schemaCoder(TypeDescriptor.of(clazz));
   }
 
   /**
@@ -346,7 +349,12 @@ public class AvroUtils {
    * GenericRecord.
    */
   public static SchemaCoder<GenericRecord> schemaCoder(org.apache.avro.Schema schema) {
-    return schemaCoder(GenericRecord.class, schema);
+    Schema beamSchema = toBeamSchema(schema);
+    return SchemaCoder.of(
+        beamSchema,
+        TypeDescriptor.of(GenericRecord.class),
+        getGenericRecordToRowFunction(beamSchema),
+        getRowToGenericRecordFunction(schema));
   }
 
   /**
@@ -360,7 +368,10 @@ public class AvroUtils {
    */
   public static <T> SchemaCoder<T> schemaCoder(Class<T> clazz, org.apache.avro.Schema schema) {
     return SchemaCoder.of(
-        getSchema(clazz, schema), getToRowFunction(clazz, schema), getFromRowFunction(clazz));
+        getSchema(clazz, schema),
+        TypeDescriptor.of(clazz),
+        getToRowFunction(clazz, schema),
+        getFromRowFunction(clazz));
   }
 
   /**
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/ConvertHelpers.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/ConvertHelpers.java
index 259d6f3e5b6..231faae2189 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/ConvertHelpers.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/ConvertHelpers.java
@@ -30,7 +30,6 @@ import org.apache.beam.sdk.schemas.SchemaRegistry;
 import org.apache.beam.sdk.schemas.utils.ByteBuddyUtils.ConvertType;
 import org.apache.beam.sdk.schemas.utils.ByteBuddyUtils.ConvertValueForSetter;
 import org.apache.beam.sdk.transforms.SerializableFunction;
-import org.apache.beam.sdk.transforms.SerializableFunctions;
 import org.apache.beam.sdk.util.common.ReflectHelpers;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TypeDescriptor;
@@ -76,13 +75,7 @@ public class ConvertHelpers {
       // If the output is of type Row, then just forward the schema of the input type to the
       // output.
       convertedSchema =
-          new ConvertedSchemaInformation<>(
-              (SchemaCoder<T>)
-                  SchemaCoder.of(
-                      inputSchema,
-                      SerializableFunctions.identity(),
-                      SerializableFunctions.identity()),
-              null);
+          new ConvertedSchemaInformation<>((SchemaCoder<T>) SchemaCoder.of(inputSchema), null);
     } else {
       // Otherwise, try to find a schema for the output type in the schema registry.
       Schema outputSchema = null;
@@ -92,6 +85,7 @@ public class ConvertHelpers {
         outputSchemaCoder =
             SchemaCoder.of(
                 outputSchema,
+                outputType,
                 schemaRegistry.getToRowFunction(outputType),
                 schemaRegistry.getFromRowFunction(outputType));
       } catch (NoSuchSchemaException e) {
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/testing/TestStream.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/testing/TestStream.java
index 41a46abce9c..3015745934c 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/testing/TestStream.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/testing/TestStream.java
@@ -46,6 +46,7 @@ import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.PCollection.IsBounded;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TimestampedValue;
+import org.apache.beam.sdk.values.TypeDescriptor;
 import org.apache.beam.sdk.values.WindowingStrategy;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;
@@ -80,9 +81,10 @@ public final class TestStream<T> extends PTransform<PBegin, PCollection<T>> {
 
   public static <T> Builder<T> create(
       Schema schema,
+      TypeDescriptor<T> typeDescriptor,
       SerializableFunction<T, Row> toRowFunction,
       SerializableFunction<Row, T> fromRowFunction) {
-    return create(SchemaCoder.of(schema, toRowFunction, fromRowFunction));
+    return create(SchemaCoder.of(schema, typeDescriptor, toRowFunction, fromRowFunction));
   }
 
   private TestStream(Coder<T> coder, List<Event<T>> events) {
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Create.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Create.java
index 09fa26094e1..05fa1d259eb 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Create.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Create.java
@@ -151,11 +151,7 @@ public class Create<T> {
    */
   public static Values<Row> empty(Schema schema) {
     return new Values<Row>(
-        new ArrayList<>(),
-        Optional.of(
-            SchemaCoder.of(
-                schema, SerializableFunctions.identity(), SerializableFunctions.identity())),
-        Optional.absent());
+        new ArrayList<>(), Optional.of(SchemaCoder.of(schema)), Optional.absent());
   }
 
   /**
@@ -295,9 +291,10 @@ public class Create<T> {
     @Experimental(Kind.SCHEMAS)
     public Values<T> withSchema(
         Schema schema,
+        TypeDescriptor<T> typeDescriptor,
         SerializableFunction<T, Row> toRowFunction,
         SerializableFunction<Row, T> fromRowFunction) {
-      return withCoder(SchemaCoder.of(schema, toRowFunction, fromRowFunction));
+      return withCoder(SchemaCoder.of(schema, typeDescriptor, toRowFunction, fromRowFunction));
     }
 
     /**
@@ -306,11 +303,7 @@ public class Create<T> {
      */
     @Experimental(Kind.SCHEMAS)
     public Values<T> withRowSchema(Schema schema) {
-      return withCoder(
-          SchemaCoder.of(
-              schema,
-              (SerializableFunction<T, Row>) SerializableFunctions.<Row>identity(),
-              (SerializableFunction<Row, T>) SerializableFunctions.<Row>identity()));
+      return withCoder((SchemaCoder<T>) SchemaCoder.of(schema));
     }
 
     /**
@@ -347,6 +340,7 @@ public class Create<T> {
               coder =
                   SchemaCoder.of(
                       schemaRegistry.getSchema(typeDescriptor.get()),
+                      typeDescriptor.get(),
                       schemaRegistry.getToRowFunction(typeDescriptor.get()),
                       schemaRegistry.getFromRowFunction(typeDescriptor.get()));
             } catch (NoSuchSchemaException e) {
@@ -584,9 +578,10 @@ public class Create<T> {
     @Experimental(Kind.SCHEMAS)
     public TimestampedValues<T> withSchema(
         Schema schema,
+        TypeDescriptor<T> typeDescriptor,
         SerializableFunction<T, Row> toRowFunction,
         SerializableFunction<Row, T> fromRowFunction) {
-      return withCoder(SchemaCoder.of(schema, toRowFunction, fromRowFunction));
+      return withCoder(SchemaCoder.of(schema, typeDescriptor, toRowFunction, fromRowFunction));
     }
 
     /**
@@ -620,6 +615,7 @@ public class Create<T> {
             coder =
                 SchemaCoder.of(
                     schemaRegistry.getSchema(typeDescriptor.get()),
+                    typeDescriptor.get(),
                     schemaRegistry.getToRowFunction(typeDescriptor.get()),
                     schemaRegistry.getFromRowFunction(typeDescriptor.get()));
           } catch (NoSuchSchemaException e) {
@@ -710,6 +706,7 @@ public class Create<T> {
         Coder<T> coder =
             SchemaCoder.of(
                 schemaRegistry.getSchema(typeDescriptor),
+                typeDescriptor,
                 schemaRegistry.getToRowFunction(typeDescriptor),
                 schemaRegistry.getFromRowFunction(typeDescriptor));
         return coder;
@@ -780,8 +777,9 @@ public class Create<T> {
     try {
       return SchemaCoder.of(
           schemaRegistry.getSchema(o.getClass()),
+          TypeDescriptor.of(o.getClass()),
           (SerializableFunction) schemaRegistry.getToRowFunction(o.getClass()),
-          schemaRegistry.getFromRowFunction(o.getClass()));
+          (SerializableFunction) schemaRegistry.getFromRowFunction(o.getClass()));
     } catch (NoSuchSchemaException e) {
       // No schema.
     }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/ParDo.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/ParDo.java
index ac266d1caef..aec80c45ad1 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/ParDo.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/ParDo.java
@@ -735,16 +735,18 @@ public class ParDo {
       PCollection<OutputT> res =
           input.apply(withOutputTags(mainOutput, TupleTagList.empty())).get(mainOutput);
 
+      TypeDescriptor<OutputT> outputTypeDescriptor = getFn().getOutputTypeDescriptor();
       try {
         res.setSchema(
-            schemaRegistry.getSchema(getFn().getOutputTypeDescriptor()),
-            schemaRegistry.getToRowFunction(getFn().getOutputTypeDescriptor()),
-            schemaRegistry.getFromRowFunction(getFn().getOutputTypeDescriptor()));
+            schemaRegistry.getSchema(outputTypeDescriptor),
+            outputTypeDescriptor,
+            schemaRegistry.getToRowFunction(outputTypeDescriptor),
+            schemaRegistry.getFromRowFunction(outputTypeDescriptor));
       } catch (NoSuchSchemaException e) {
         try {
           res.setCoder(
               registry.getCoder(
-                  getFn().getOutputTypeDescriptor(),
+                  outputTypeDescriptor,
                   getFn().getInputTypeDescriptor(),
                   ((PCollection<InputT>) input).getCoder()));
         } catch (CannotProvideCoderException e2) {
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/util/SerializableUtils.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/util/SerializableUtils.java
index 2e06f3c4bad..46c16e56afa 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/util/SerializableUtils.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/util/SerializableUtils.java
@@ -75,6 +75,19 @@ public class SerializableUtils {
     }
   }
 
+  public static <T extends Serializable> T ensureSerializableRoundTrip(T value) {
+    T copy = ensureSerializable(value);
+
+    checkState(
+        value.equals(copy),
+        "Value not equal to original after serialization, indicating that its type may not "
+            + "implement serialization or equals correctly.  Before: %s, after: %s",
+        value,
+        copy);
+
+    return copy;
+  }
+
   public static <T extends Serializable> T ensureSerializable(T value) {
     return clone(value);
   }
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/values/PCollection.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/values/PCollection.java
index fe37364fdf8..cba18cdb71d 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/values/PCollection.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/values/PCollection.java
@@ -43,7 +43,6 @@ import org.apache.beam.sdk.transforms.Create;
 import org.apache.beam.sdk.transforms.PTransform;
 import org.apache.beam.sdk.transforms.ParDo;
 import org.apache.beam.sdk.transforms.SerializableFunction;
-import org.apache.beam.sdk.transforms.SerializableFunctions;
 import org.apache.beam.sdk.transforms.windowing.GlobalWindows;
 import org.apache.beam.sdk.transforms.windowing.Window;
 import org.apache.beam.sdk.transforms.windowing.WindowFn;
@@ -158,6 +157,7 @@ public class PCollection<T> extends PValueBase implements PValue {
         SchemaCoder<T> schemaCoder =
             SchemaCoder.of(
                 schemaRegistry.getSchema(token),
+                token,
                 schemaRegistry.getToRowFunction(token),
                 schemaRegistry.getFromRowFunction(token));
         return new CoderOrFailure<>(schemaCoder, null);
@@ -300,19 +300,17 @@ public class PCollection<T> extends PValueBase implements PValue {
    */
   @Experimental(Kind.SCHEMAS)
   public PCollection<T> setRowSchema(Schema schema) {
-    return setSchema(
-        schema,
-        (SerializableFunction<T, Row>) SerializableFunctions.<Row>identity(),
-        (SerializableFunction<Row, T>) SerializableFunctions.<Row>identity());
+    return setCoder((SchemaCoder<T>) SchemaCoder.of(schema));
   }
 
   /** Sets a {@link Schema} on this {@link PCollection}. */
   @Experimental(Kind.SCHEMAS)
   public PCollection<T> setSchema(
       Schema schema,
+      TypeDescriptor<T> typeDescriptor,
       SerializableFunction<T, Row> toRowFunction,
       SerializableFunction<Row, T> fromRowFunction) {
-    return setCoder(SchemaCoder.of(schema, toRowFunction, fromRowFunction));
+    return setCoder(SchemaCoder.of(schema, typeDescriptor, toRowFunction, fromRowFunction));
   }
 
   /** Returns whether this {@link PCollection} has an attached schema. */
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/AutoValueSchemaTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/AutoValueSchemaTest.java
index 06b2f9ac7e7..7bbceb05255 100644
--- a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/AutoValueSchemaTest.java
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/AutoValueSchemaTest.java
@@ -29,12 +29,16 @@ import org.apache.beam.sdk.schemas.AutoValueSchemaTest.SimpleAutoValueWithBuilde
 import org.apache.beam.sdk.schemas.annotations.DefaultSchema;
 import org.apache.beam.sdk.schemas.annotations.SchemaCreate;
 import org.apache.beam.sdk.schemas.utils.SchemaTestUtils;
+import org.apache.beam.sdk.util.SerializableUtils;
 import org.apache.beam.sdk.values.Row;
 import org.joda.time.DateTime;
 import org.joda.time.Instant;
 import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.JUnit4;
 
 /** Tests for {@link AutoValueSchema}. */
+@RunWith(JUnit4.class)
 public class AutoValueSchemaTest {
   static final DateTime DATE = DateTime.parse("1979-03-14");
   static final byte[] BYTE_ARRAY = "bytearray".getBytes(Charset.defaultCharset());
@@ -280,6 +284,19 @@ public class AutoValueSchemaTest {
     verifyAutoValue(value);
   }
 
+  @Test
+  public void testToRowSerializable() throws NoSuchSchemaException {
+    SchemaRegistry registry = SchemaRegistry.createDefault();
+    SerializableUtils.ensureSerializableRoundTrip(registry.getToRowFunction(SimpleAutoValue.class));
+  }
+
+  @Test
+  public void testFromRowSerializable() throws NoSuchSchemaException {
+    SchemaRegistry registry = SchemaRegistry.createDefault();
+    SerializableUtils.ensureSerializableRoundTrip(
+        registry.getFromRowFunction(SimpleAutoValue.class));
+  }
+
   @Test
   public void testToRowBuilder() throws NoSuchSchemaException {
     SchemaRegistry registry = SchemaRegistry.createDefault();
@@ -312,6 +329,20 @@ public class AutoValueSchemaTest {
     verifyAutoValue(value);
   }
 
+  @Test
+  public void testToRowBuilderSerializable() throws NoSuchSchemaException {
+    SchemaRegistry registry = SchemaRegistry.createDefault();
+    SerializableUtils.ensureSerializableRoundTrip(
+        registry.getToRowFunction(SimpleAutoValueWithBuilder.class));
+  }
+
+  @Test
+  public void testFromRowBuilderSerializable() throws NoSuchSchemaException {
+    SchemaRegistry registry = SchemaRegistry.createDefault();
+    SerializableUtils.ensureSerializableRoundTrip(
+        registry.getFromRowFunction(SimpleAutoValueWithBuilder.class));
+  }
+
   // Test nested classes.
   @AutoValue
   @DefaultSchema(AutoValueSchema.class)
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/AvroSchemaTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/AvroSchemaTest.java
index f10733237fa..ccbd3bb7a43 100644
--- a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/AvroSchemaTest.java
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/AvroSchemaTest.java
@@ -41,6 +41,7 @@ import org.apache.beam.sdk.testing.TestPipeline;
 import org.apache.beam.sdk.testing.ValidatesRunner;
 import org.apache.beam.sdk.transforms.Create;
 import org.apache.beam.sdk.transforms.SerializableFunction;
+import org.apache.beam.sdk.util.SerializableUtils;
 import org.apache.beam.sdk.values.KV;
 import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.Row;
@@ -50,6 +51,7 @@ import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Immutabl
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 import org.joda.time.Days;
+import org.joda.time.Instant;
 import org.joda.time.LocalDate;
 import org.junit.Rule;
 import org.junit.Test;
@@ -412,11 +414,25 @@ public class AvroSchemaTest {
 
   @Test
   public void testRowToPojo() {
+
+    LocalDate test = new LocalDate(((Instant) ROW_FOR_POJO.getValue(8)).getMillis());
     SerializableFunction<Row, AvroPojo> fromRow =
         new AvroRecordSchema().fromRowFunction(TypeDescriptor.of(AvroPojo.class));
     assertEquals(AVRO_POJO, fromRow.apply(ROW_FOR_POJO));
   }
 
+  @Test
+  public void testPojoRecordToRowSerializable() {
+    SerializableUtils.ensureSerializableRoundTrip(
+        new AvroRecordSchema().toRowFunction(TypeDescriptor.of(AvroPojo.class)));
+  }
+
+  @Test
+  public void testPojoRecordFromRowSerializable() {
+    SerializableUtils.ensureSerializableRoundTrip(
+        new AvroRecordSchema().fromRowFunction(TypeDescriptor.of(AvroPojo.class)));
+  }
+
   @Rule public final transient TestPipeline pipeline = TestPipeline.create();
 
   @Test
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/JavaBeanSchemaTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/JavaBeanSchemaTest.java
index 08422015753..369e90bb31e 100644
--- a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/JavaBeanSchemaTest.java
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/JavaBeanSchemaTest.java
@@ -42,6 +42,7 @@ import org.apache.beam.sdk.schemas.utils.TestJavaBeans.NestedMapBean;
 import org.apache.beam.sdk.schemas.utils.TestJavaBeans.PrimitiveArrayBean;
 import org.apache.beam.sdk.schemas.utils.TestJavaBeans.SimpleBean;
 import org.apache.beam.sdk.schemas.utils.TestJavaBeans.SimpleBeanWithAnnotations;
+import org.apache.beam.sdk.util.SerializableUtils;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
@@ -153,6 +154,18 @@ public class JavaBeanSchemaTest {
     assertEquals("stringbuilder", bean.getStringBuilder().toString());
   }
 
+  @Test
+  public void testToRowSerializable() throws NoSuchSchemaException {
+    SchemaRegistry registry = SchemaRegistry.createDefault();
+    SerializableUtils.ensureSerializableRoundTrip(registry.getToRowFunction(SimpleBean.class));
+  }
+
+  @Test
+  public void testFromRowSerializable() throws NoSuchSchemaException {
+    SchemaRegistry registry = SchemaRegistry.createDefault();
+    SerializableUtils.ensureSerializableRoundTrip(registry.getFromRowFunction(SimpleBean.class));
+  }
+
   @Test
   public void testFromRowWithGetters() throws NoSuchSchemaException {
     SchemaRegistry registry = SchemaRegistry.createDefault();
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/JavaFieldSchemaTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/JavaFieldSchemaTest.java
index a907defc685..09eaaf5e96d 100644
--- a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/JavaFieldSchemaTest.java
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/JavaFieldSchemaTest.java
@@ -50,6 +50,7 @@ import org.apache.beam.sdk.schemas.utils.TestPOJOs.PojoWithNestedArray;
 import org.apache.beam.sdk.schemas.utils.TestPOJOs.PrimitiveArrayPOJO;
 import org.apache.beam.sdk.schemas.utils.TestPOJOs.SimplePOJO;
 import org.apache.beam.sdk.schemas.utils.TestPOJOs.StaticCreationSimplePojo;
+import org.apache.beam.sdk.util.SerializableUtils;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
@@ -181,6 +182,18 @@ public class JavaFieldSchemaTest {
     assertEquals("stringbuilder", pojo.stringBuilder.toString());
   }
 
+  @Test
+  public void testToRowSerializable() throws NoSuchSchemaException {
+    SchemaRegistry registry = SchemaRegistry.createDefault();
+    SerializableUtils.ensureSerializableRoundTrip(registry.getToRowFunction(SimplePOJO.class));
+  }
+
+  @Test
+  public void testFromRowSerializable() throws NoSuchSchemaException {
+    SchemaRegistry registry = SchemaRegistry.createDefault();
+    SerializableUtils.ensureSerializableRoundTrip(registry.getFromRowFunction(SimplePOJO.class));
+  }
+
   @Test
   public void testFromRowWithGetters() throws NoSuchSchemaException {
     SchemaRegistry registry = SchemaRegistry.createDefault();
@@ -415,7 +428,7 @@ public class JavaFieldSchemaTest {
   }
 
   @Test
-  public void testNNestedullValuesSetters() throws NoSuchSchemaException {
+  public void testNestedNullValuesSetters() throws NoSuchSchemaException {
     SchemaRegistry registry = SchemaRegistry.createDefault();
 
     Row row = Row.withSchema(NESTED_NULLABLE_SCHEMA).addValue(null).build();
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/SchemaCoderTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/SchemaCoderTest.java
new file mode 100644
index 00000000000..65747ba1848
--- /dev/null
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/SchemaCoderTest.java
@@ -0,0 +1,293 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.sdk.schemas;
+
+import static org.junit.Assert.assertNotEquals;
+
+import com.google.auto.value.AutoValue;
+import java.util.Collection;
+import java.util.Objects;
+import org.apache.avro.reflect.AvroSchema;
+import org.apache.beam.sdk.schemas.annotations.DefaultSchema;
+import org.apache.beam.sdk.schemas.utils.SchemaTestUtils;
+import org.apache.beam.sdk.testing.CoderProperties;
+import org.apache.beam.sdk.values.Row;
+import org.apache.beam.sdk.values.TypeDescriptor;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
+import org.joda.time.DateTime;
+import org.junit.Test;
+import org.junit.experimental.runners.Enclosed;
+import org.junit.runner.RunWith;
+import org.junit.runners.JUnit4;
+import org.junit.runners.Parameterized;
+
+/** Unit tests for {@link Schema}. */
+@RunWith(Enclosed.class)
+public class SchemaCoderTest {
+  private static final Schema INT32_SCHEMA =
+      Schema.builder().addInt32Field("a").addInt32Field("b").build();
+
+  @RunWith(JUnit4.class)
+  public static class SingletonTests {
+    @Test
+    public void equals_sameSchemaDifferentType_returnsFalse() throws NoSuchSchemaException {
+      SchemaCoder autovalueCoder = coderFrom(TypeDescriptor.of(SimpleAutoValue.class));
+      SchemaCoder javabeanCoder = coderFrom(TypeDescriptor.of(SimpleBean.class));
+
+      // These coders are *not* the same
+      assertNotEquals(autovalueCoder, javabeanCoder);
+
+      // These coders have equivalent schemas, but toRow and fromRow are not equal
+      SchemaTestUtils.assertSchemaEquivalent(autovalueCoder.getSchema(), javabeanCoder.getSchema());
+      assertNotEquals(autovalueCoder.getToRowFunction(), javabeanCoder.getToRowFunction());
+      assertNotEquals(autovalueCoder.getFromRowFunction(), javabeanCoder.getFromRowFunction());
+    }
+  }
+
+  @AutoValue
+  @DefaultSchema(AutoValueSchema.class)
+  public abstract static class SimpleAutoValue {
+    public abstract String getString();
+
+    public abstract Integer getInt32();
+
+    public abstract Long getInt64();
+
+    public abstract DateTime getDatetime();
+
+    public static SimpleAutoValue of(String string, Integer int32, Long int64, DateTime datetime) {
+      return new AutoValue_SchemaCoderTest_SimpleAutoValue(string, int32, int64, datetime);
+    }
+  }
+
+  @DefaultSchema(JavaBeanSchema.class)
+  private static class SimpleBean {
+    private String string;
+    private Integer int32;
+    private Long int64;
+    private DateTime datetime;
+
+    public SimpleBean(String string, Integer int32, Long int64, DateTime datetime) {
+      this.string = string;
+      this.int32 = int32;
+      this.int64 = int64;
+      this.datetime = datetime;
+    }
+
+    public String getString() {
+      return string;
+    }
+
+    public void setString(String string) {
+      this.string = string;
+    }
+
+    public Integer getInt32() {
+      return int32;
+    }
+
+    public void setInt32(Integer int32) {
+      this.int32 = int32;
+    }
+
+    public Long getInt64() {
+      return int64;
+    }
+
+    public void setInt64(Long int64) {
+      this.int64 = int64;
+    }
+
+    public DateTime getDatetime() {
+      return datetime;
+    }
+
+    public void setDatetime(DateTime datetime) {
+      this.datetime = datetime;
+    }
+
+    @Override
+    public boolean equals(Object o) {
+      if (this == o) {
+        return true;
+      }
+      if (o == null || getClass() != o.getClass()) {
+        return false;
+      }
+      SimpleBean that = (SimpleBean) o;
+      return string.equals(that.string)
+          && int32.equals(that.int32)
+          && int64.equals(that.int64)
+          && datetime.equals(that.datetime);
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(string, int32, int64, datetime);
+    }
+  }
+
+  @DefaultSchema(JavaFieldSchema.class)
+  private static class SimplePojo {
+    public String string;
+    public Integer int32;
+    public Long int64;
+    public DateTime datetime;
+
+    public SimplePojo(String string, Integer int32, Long int64, DateTime datetime) {
+      this.string = string;
+      this.int32 = int32;
+      this.int64 = int64;
+      this.datetime = datetime;
+    }
+
+    @Override
+    public boolean equals(Object o) {
+      if (this == o) {
+        return true;
+      }
+      if (o == null || getClass() != o.getClass()) {
+        return false;
+      }
+      SimplePojo that = (SimplePojo) o;
+      return string.equals(that.string)
+          && int32.equals(that.int32)
+          && int64.equals(that.int64)
+          && datetime.equals(that.datetime);
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(string, int32, int64, datetime);
+    }
+  }
+
+  @DefaultSchema(AvroRecordSchema.class)
+  private static class SimpleAvro {
+    public String string;
+    public Integer int32;
+    public Long int64;
+
+    @AvroSchema("{\"type\": \"long\", \"logicalType\": \"timestamp-millis\"}")
+    public DateTime datetime;
+
+    public SimpleAvro(String string, Integer int32, Long int64, DateTime datetime) {
+      this.string = string;
+      this.int32 = int32;
+      this.int64 = int64;
+      this.datetime = datetime;
+    }
+
+    @Override
+    public boolean equals(Object o) {
+      if (this == o) {
+        return true;
+      }
+      if (o == null || getClass() != o.getClass()) {
+        return false;
+      }
+      SimpleAvro that = (SimpleAvro) o;
+      return string.equals(that.string)
+          && int32.equals(that.int32)
+          && int64.equals(that.int64)
+          && datetime.equals(that.datetime);
+    }
+
+    @Override
+    public int hashCode() {
+      return Objects.hash(string, int32, int64, datetime);
+    }
+  }
+
+  private static final SchemaRegistry REGISTRY = SchemaRegistry.createDefault();
+
+  private static SchemaCoder coderFrom(TypeDescriptor typeDescriptor) throws NoSuchSchemaException {
+    return SchemaCoder.of(
+        REGISTRY.getSchema(typeDescriptor),
+        typeDescriptor,
+        REGISTRY.getToRowFunction(typeDescriptor),
+        REGISTRY.getFromRowFunction(typeDescriptor));
+  }
+
+  @RunWith(Parameterized.class)
+  @DefaultSchema(AutoValueSchema.class)
+  public static class SchemaProviderTests {
+    @Parameterized.Parameter(0)
+    public SchemaCoder coder;
+
+    @Parameterized.Parameter(1)
+    public ImmutableList<Object> testValues;
+
+    @Parameterized.Parameters(name = "{index}: coder = {0}")
+    public static Collection<Object[]> data() throws NoSuchSchemaException {
+      return ImmutableList.of(
+          new Object[] {
+            SchemaCoder.of(INT32_SCHEMA),
+            ImmutableList.of(
+                Row.withSchema(INT32_SCHEMA).addValues(9001, 9002).build(),
+                Row.withSchema(INT32_SCHEMA).addValues(3, 4).build())
+          },
+          new Object[] {
+            coderFrom(TypeDescriptor.of(SimpleAutoValue.class)),
+            ImmutableList.of(
+                SimpleAutoValue.of(
+                    "foo", 9001, 0L, new DateTime().withDate(1979, 3, 14).withTime(10, 30, 0, 0)),
+                SimpleAutoValue.of(
+                    "bar", 9002, 1L, new DateTime().withDate(1989, 3, 14).withTime(10, 30, 0, 0)))
+          },
+          new Object[] {
+            coderFrom(TypeDescriptor.of(SimpleBean.class)),
+            ImmutableList.of(
+                new SimpleBean(
+                    "foo", 9001, 0L, new DateTime().withDate(1979, 3, 14).withTime(10, 30, 0, 0)),
+                new SimpleBean(
+                    "bar", 9002, 1L, new DateTime().withDate(1989, 3, 14).withTime(10, 30, 0, 0)))
+          },
+          new Object[] {
+            coderFrom(TypeDescriptor.of(SimplePojo.class)),
+            ImmutableList.of(
+                new SimplePojo(
+                    "foo", 9001, 0L, new DateTime().withDate(1979, 3, 14).withTime(10, 30, 0, 0)),
+                new SimplePojo(
+                    "bar", 9002, 1L, new DateTime().withDate(1989, 3, 14).withTime(10, 30, 0, 0)))
+          },
+          new Object[] {
+            coderFrom(TypeDescriptor.of(SimpleAvro.class)),
+            ImmutableList.of(
+                new SimpleAvro(
+                    "foo", 9001, 0L, new DateTime().withDate(1979, 3, 14).withTime(10, 30, 0, 0)),
+                new SimpleAvro(
+                    "bar", 9002, 1L, new DateTime().withDate(1989, 3, 14).withTime(10, 30, 0, 0)))
+          });
+    }
+
+    @Test
+    public void coderSerializable() {
+      CoderProperties.coderSerializable(coder);
+    }
+
+    @Test
+    public void coderConsistentWithEquals() throws Exception {
+      for (Object testValueA : testValues) {
+        for (Object testValueB : testValues) {
+          CoderProperties.coderConsistentWithEquals(coder, testValueA, testValueB);
+        }
+      }
+    }
+  }
+}
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/transforms/ConvertTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/transforms/ConvertTest.java
index 5320f6b1322..f2489fe6f4e 100644
--- a/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/transforms/ConvertTest.java
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/schemas/transforms/ConvertTest.java
@@ -29,7 +29,6 @@ import org.apache.beam.sdk.testing.PAssert;
 import org.apache.beam.sdk.testing.TestPipeline;
 import org.apache.beam.sdk.testing.UsesSchema;
 import org.apache.beam.sdk.transforms.Create;
-import org.apache.beam.sdk.transforms.SerializableFunctions;
 import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TypeDescriptor;
@@ -204,12 +203,7 @@ public class ConvertTest {
   public void testFromRows() {
     PCollection<POJO1> pojos =
         pipeline
-            .apply(
-                Create.of(EXPECTED_ROW1)
-                    .withSchema(
-                        EXPECTED_SCHEMA1,
-                        SerializableFunctions.identity(),
-                        SerializableFunctions.identity()))
+            .apply(Create.of(EXPECTED_ROW1).withRowSchema(EXPECTED_SCHEMA1))
             .apply(Convert.fromRows(POJO1.class));
     PAssert.that(pojos).containsInAnyOrder(new POJO1());
     pipeline.run();
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/CreateTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/CreateTest.java
index 0cfb3fcb814..9407a28a8f2 100644
--- a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/CreateTest.java
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/CreateTest.java
@@ -63,6 +63,7 @@ import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TimestampedValue;
 import org.apache.beam.sdk.values.TypeDescriptor;
+import org.apache.beam.sdk.values.TypeDescriptors;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;
 import org.hamcrest.Matchers;
@@ -418,6 +419,7 @@ public class CreateTest {
             Create.of("a", "b", "c", "d")
                 .withSchema(
                     STRING_SCHEMA,
+                    TypeDescriptors.strings(),
                     s -> Row.withSchema(STRING_SCHEMA).addValue(s).build(),
                     r -> r.getString("field")));
     assertThat(out.getCoder(), instanceOf(SchemaCoder.class));
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/ParDoSchemaTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/ParDoSchemaTest.java
index 2c03a048e62..7c2fdd5963e 100644
--- a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/ParDoSchemaTest.java
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/ParDoSchemaTest.java
@@ -39,6 +39,7 @@ import org.apache.beam.sdk.values.PCollectionTuple;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TupleTag;
 import org.apache.beam.sdk.values.TupleTagList;
+import org.apache.beam.sdk.values.TypeDescriptor;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;
 import org.junit.Rule;
 import org.junit.Test;
@@ -79,6 +80,7 @@ public class ParDoSchemaTest implements Serializable {
                 Create.of(pojoList)
                     .withSchema(
                         schema,
+                        TypeDescriptor.of(MyPojo.class),
                         o ->
                             Row.withSchema(schema).addValues(o.stringField, o.integerField).build(),
                         r -> new MyPojo(r.getString("string_field"), r.getInt32("integer_field"))))
@@ -112,6 +114,7 @@ public class ParDoSchemaTest implements Serializable {
                 Create.of(pojoList)
                     .withSchema(
                         schema1,
+                        TypeDescriptor.of(MyPojo.class),
                         o ->
                             Row.withSchema(schema1)
                                 .addValues(o.stringField, o.integerField)
@@ -131,6 +134,7 @@ public class ParDoSchemaTest implements Serializable {
                     }))
             .setSchema(
                 schema2,
+                TypeDescriptor.of(MyPojo.class),
                 o -> Row.withSchema(schema2).addValues(o.stringField, o.integerField).build(),
                 r -> new MyPojo(r.getString("string2_field"), r.getInt32("integer2_field")))
             .apply(
@@ -170,6 +174,7 @@ public class ParDoSchemaTest implements Serializable {
                 Create.of(pojoList)
                     .withSchema(
                         schema1,
+                        TypeDescriptor.of(MyPojo.class),
                         o ->
                             Row.withSchema(schema1)
                                 .addValues(o.stringField, o.integerField)
@@ -198,12 +203,14 @@ public class ParDoSchemaTest implements Serializable {
         .get(firstOutput)
         .setSchema(
             schema2,
+            TypeDescriptor.of(MyPojo.class),
             o -> Row.withSchema(schema2).addValues(o.stringField, o.integerField).build(),
             r -> new MyPojo(r.getString("string2_field"), r.getInt32("integer2_field")));
     tuple
         .get(secondOutput)
         .setSchema(
             schema3,
+            TypeDescriptor.of(MyPojo.class),
             o -> Row.withSchema(schema3).addValues(o.stringField, o.integerField).build(),
             r -> new MyPojo(r.getString("string3_field"), r.getInt32("integer3_field")));
 
@@ -300,6 +307,7 @@ public class ParDoSchemaTest implements Serializable {
                 Create.of(pojoList)
                     .withSchema(
                         schema,
+                        TypeDescriptor.of(MyPojo.class),
                         o ->
                             Row.withSchema(schema).addValues(o.stringField, o.integerField).build(),
                         r -> new MyPojo(r.getString("string_field"), r.getInt32("integer_field"))))
@@ -349,6 +357,7 @@ public class ParDoSchemaTest implements Serializable {
             Create.of(pojoList)
                 .withSchema(
                     schema,
+                    TypeDescriptor.of(MyPojo.class),
                     o -> Row.withSchema(schema).addValues(o.stringField, o.integerField).build(),
                     r -> new MyPojo(r.getString("string_field"), r.getInt32("integer_field"))))
         .apply(
diff --git a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.java b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.java
index 06bf8c1cc83..6899af3baa4 100644
--- a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.java
+++ b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.java
@@ -107,6 +107,7 @@ import org.apache.beam.sdk.values.PCollectionView;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TupleTag;
 import org.apache.beam.sdk.values.TupleTagList;
+import org.apache.beam.sdk.values.TypeDescriptor;
 import org.apache.beam.sdk.values.TypeDescriptors;
 import org.apache.beam.sdk.values.ValueInSingleWindow;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;
@@ -497,7 +498,9 @@ public class BigQueryIO {
     return read(new TableRowParser())
         .withCoder(TableRowJsonCoder.of())
         .withBeamRowConverters(
-            BigQueryUtils.tableRowToBeamRow(), BigQueryUtils.tableRowFromBeamRow());
+            TypeDescriptor.of(TableRow.class),
+            BigQueryUtils.tableRowToBeamRow(),
+            BigQueryUtils.tableRowFromBeamRow());
   }
 
   /**
@@ -741,6 +744,9 @@ public class BigQueryIO {
 
       abstract Builder<T> setKmsKey(String kmsKey);
 
+      @Experimental(Experimental.Kind.SCHEMAS)
+      abstract Builder<T> setTypeDescriptor(TypeDescriptor<T> typeDescriptor);
+
       @Experimental(Experimental.Kind.SCHEMAS)
       abstract Builder<T> setToBeamRowFn(ToBeamRowFunction<T> toRowFn);
 
@@ -797,6 +803,10 @@ public class BigQueryIO {
     @Nullable
     abstract String getKmsKey();
 
+    @Nullable
+    @Experimental(Experimental.Kind.SCHEMAS)
+    abstract TypeDescriptor<T> getTypeDescriptor();
+
     @Nullable
     @Experimental(Experimental.Kind.SCHEMAS)
     abstract ToBeamRowFunction<T> getToBeamRowFn();
@@ -973,7 +983,7 @@ public class BigQueryIO {
 
       // if both toRowFn and fromRowFn values are set, enable Beam schema support
       boolean beamSchemaEnabled = false;
-      if (getToBeamRowFn() != null && getFromBeamRowFn() != null) {
+      if (getTypeDescriptor() != null && getToBeamRowFn() != null && getFromBeamRowFn() != null) {
         beamSchemaEnabled = true;
       }
 
@@ -1128,7 +1138,7 @@ public class BigQueryIO {
         SerializableFunction<T, Row> toBeamRow = getToBeamRowFn().apply(beamSchema);
         SerializableFunction<Row, T> fromBeamRow = getFromBeamRowFn().apply(beamSchema);
 
-        rows.setSchema(beamSchema, toBeamRow, fromBeamRow);
+        rows.setSchema(beamSchema, getTypeDescriptor(), toBeamRow, fromBeamRow);
       }
       return rows;
     }
@@ -1394,8 +1404,14 @@ public class BigQueryIO {
      */
     @Experimental(Experimental.Kind.SCHEMAS)
     public TypedRead<T> withBeamRowConverters(
-        ToBeamRowFunction<T> toRowFn, FromBeamRowFunction<T> fromRowFn) {
-      return toBuilder().setToBeamRowFn(toRowFn).setFromBeamRowFn(fromRowFn).build();
+        TypeDescriptor<T> typeDescriptor,
+        ToBeamRowFunction<T> toRowFn,
+        FromBeamRowFunction<T> fromRowFn) {
+      return toBuilder()
+          .setTypeDescriptor(typeDescriptor)
+          .setToBeamRowFn(toRowFn)
+          .setFromBeamRowFn(fromRowFn)
+          .build();
     }
 
     /** See {@link Read#from(String)}. */
diff --git a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.java b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.java
index 3212b3b0bbf..77dd858b68e 100644
--- a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.java
+++ b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubIO.java
@@ -71,6 +71,7 @@ import org.apache.beam.sdk.values.PBegin;
 import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.PDone;
 import org.apache.beam.sdk.values.Row;
+import org.apache.beam.sdk.values.TypeDescriptor;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.MoreObjects;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
@@ -595,6 +596,7 @@ public class PubsubIO {
         .setNeedsMessageId(false)
         .setPubsubClientFactory(FACTORY)
         .setBeamSchema(schema)
+        .setTypeDescriptor(TypeDescriptor.of(GenericRecord.class))
         .setToRowFn(AvroUtils.getToRowFunction(GenericRecord.class, avroSchema))
         .setFromRowFn(AvroUtils.getFromRowFunction(GenericRecord.class))
         .setParseFn(new ParsePayloadUsingCoder<>(coder))
@@ -621,6 +623,7 @@ public class PubsubIO {
         .setNeedsMessageId(false)
         .setPubsubClientFactory(FACTORY)
         .setBeamSchema(schema)
+        .setTypeDescriptor(TypeDescriptor.of(clazz))
         .setToRowFn(AvroUtils.getToRowFunction(clazz, avroSchema))
         .setFromRowFn(AvroUtils.getFromRowFunction(clazz))
         .setParseFn(new ParsePayloadUsingCoder<>(coder))
@@ -695,6 +698,9 @@ public class PubsubIO {
     @Nullable
     abstract Schema getBeamSchema();
 
+    @Nullable
+    abstract TypeDescriptor<T> getTypeDescriptor();
+
     @Nullable
     abstract SerializableFunction<T, Row> getToRowFn();
 
@@ -729,6 +735,8 @@ public class PubsubIO {
 
       abstract Builder<T> setBeamSchema(@Nullable Schema beamSchema);
 
+      abstract Builder<T> setTypeDescriptor(@Nullable TypeDescriptor<T> typeDescriptor);
+
       abstract Builder<T> setToRowFn(@Nullable SerializableFunction<T, Row> toRowFn);
 
       abstract Builder<T> setFromRowFn(@Nullable SerializableFunction<Row, T> fromRowFn);
@@ -981,7 +989,7 @@ public class PubsubIO {
               getNeedsMessageId());
       PCollection<T> read = input.apply(source).apply(MapElements.via(getParseFn()));
       return (getBeamSchema() != null)
-          ? read.setSchema(getBeamSchema(), getToRowFn(), getFromRowFn())
+          ? read.setSchema(getBeamSchema(), getTypeDescriptor(), getToRowFn(), getFromRowFn())
           : read.setCoder(getCoder());
     }
 
diff --git a/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOWriteTest.java b/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOWriteTest.java
index cd0312d3e1e..a5a44a3d10e 100644
--- a/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOWriteTest.java
+++ b/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOWriteTest.java
@@ -98,6 +98,7 @@ import org.apache.beam.sdk.values.PCollectionView;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.ShardedKey;
 import org.apache.beam.sdk.values.TupleTag;
+import org.apache.beam.sdk.values.TypeDescriptors;
 import org.apache.beam.sdk.values.ValueInSingleWindow;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ArrayListMultimap;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;
@@ -260,6 +261,7 @@ public class BigQueryIOWriteTest implements Serializable {
       users =
           users.setSchema(
               schema,
+              TypeDescriptors.strings(),
               user -> {
                 Matcher matcher = userPattern.matcher(user);
                 checkState(matcher.matches());
diff --git a/sdks/java/io/jdbc/src/main/java/org/apache/beam/sdk/io/jdbc/JdbcIO.java b/sdks/java/io/jdbc/src/main/java/org/apache/beam/sdk/io/jdbc/JdbcIO.java
index 91624487506..9d0acc0fbe5 100644
--- a/sdks/java/io/jdbc/src/main/java/org/apache/beam/sdk/io/jdbc/JdbcIO.java
+++ b/sdks/java/io/jdbc/src/main/java/org/apache/beam/sdk/io/jdbc/JdbcIO.java
@@ -828,7 +828,10 @@ public class JdbcIO {
         SchemaRegistry registry = input.getPipeline().getSchemaRegistry();
         Schema schema = registry.getSchema(typeDesc);
         output.setSchema(
-            schema, registry.getToRowFunction(typeDesc), registry.getFromRowFunction(typeDesc));
+            schema,
+            typeDesc,
+            registry.getToRowFunction(typeDesc),
+            registry.getFromRowFunction(typeDesc));
       } catch (NoSuchSchemaException e) {
         // ignore
       }
diff --git a/sdks/java/testing/nexmark/src/main/java/org/apache/beam/sdk/nexmark/queries/sql/SqlBoundedSideInputJoin.java b/sdks/java/testing/nexmark/src/main/java/org/apache/beam/sdk/nexmark/queries/sql/SqlBoundedSideInputJoin.java
index 806b0dbad9e..f0a9e4ba9d3 100644
--- a/sdks/java/testing/nexmark/src/main/java/org/apache/beam/sdk/nexmark/queries/sql/SqlBoundedSideInputJoin.java
+++ b/sdks/java/testing/nexmark/src/main/java/org/apache/beam/sdk/nexmark/queries/sql/SqlBoundedSideInputJoin.java
@@ -34,6 +34,7 @@ import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.PCollectionTuple;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.sdk.values.TupleTag;
+import org.apache.beam.sdk.values.TypeDescriptors;
 
 /** Basic stream enrichment: join a stream to a bounded side input. */
 public class SqlBoundedSideInputJoin extends NexmarkQueryTransform<Bid> {
@@ -88,6 +89,7 @@ public class SqlBoundedSideInputJoin extends NexmarkQueryTransform<Bid> {
         getSideInput()
             .setSchema(
                 schema,
+                TypeDescriptors.kvs(TypeDescriptors.longs(), TypeDescriptors.strings()),
                 kv -> Row.withSchema(schema).addValues(kv.getKey(), kv.getValue()).build(),
                 row -> KV.of(row.getInt64("id"), row.getString("extra")))
             .apply("SideToRows", Convert.toRows());
diff --git a/sdks/java/testing/nexmark/src/test/java/org/apache/beam/sdk/nexmark/queries/sql/SqlQuery0Test.java b/sdks/java/testing/nexmark/src/test/java/org/apache/beam/sdk/nexmark/queries/sql/SqlQuery0Test.java
index 644a6ff5040..cd6611c1c15 100644
--- a/sdks/java/testing/nexmark/src/test/java/org/apache/beam/sdk/nexmark/queries/sql/SqlQuery0Test.java
+++ b/sdks/java/testing/nexmark/src/test/java/org/apache/beam/sdk/nexmark/queries/sql/SqlQuery0Test.java
@@ -24,6 +24,7 @@ import org.apache.beam.sdk.testing.PAssert;
 import org.apache.beam.sdk.testing.TestPipeline;
 import org.apache.beam.sdk.testing.TestStream;
 import org.apache.beam.sdk.values.PCollection;
+import org.apache.beam.sdk.values.TypeDescriptor;
 import org.joda.time.Instant;
 import org.junit.Rule;
 import org.junit.Test;
@@ -45,6 +46,7 @@ public class SqlQuery0Test {
         testPipeline.apply(
             TestStream.create(
                     registry.getSchema(Event.class),
+                    TypeDescriptor.of(Event.class),
                     registry.getToRowFunction(Event.class),
                     registry.getFromRowFunction(Event.class))
                 .addElements(new Event(BID1))
diff --git a/sdks/java/testing/nexmark/src/test/java/org/apache/beam/sdk/nexmark/queries/sql/SqlQuery1Test.java b/sdks/java/testing/nexmark/src/test/java/org/apache/beam/sdk/nexmark/queries/sql/SqlQuery1Test.java
index 2a2fcc7af47..47723fef9de 100644
--- a/sdks/java/testing/nexmark/src/test/java/org/apache/beam/sdk/nexmark/queries/sql/SqlQuery1Test.java
+++ b/sdks/java/testing/nexmark/src/test/java/org/apache/beam/sdk/nexmark/queries/sql/SqlQuery1Test.java
@@ -26,6 +26,7 @@ import org.apache.beam.sdk.testing.PAssert;
 import org.apache.beam.sdk.testing.TestPipeline;
 import org.apache.beam.sdk.testing.TestStream;
 import org.apache.beam.sdk.values.PCollection;
+import org.apache.beam.sdk.values.TypeDescriptor;
 import org.joda.time.Instant;
 import org.junit.Rule;
 import org.junit.Test;
@@ -56,6 +57,7 @@ public class SqlQuery1Test {
         testPipeline.apply(
             TestStream.create(
                     registry.getSchema(Event.class),
+                    TypeDescriptor.of(Event.class),
                     registry.getToRowFunction(Event.class),
                     registry.getFromRowFunction(Event.class))
                 .addElements(new Event(BID1_USD))
