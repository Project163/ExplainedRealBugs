diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java
index 790bcf26359..a399aeb7499 100644
--- a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java
+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java
@@ -386,24 +386,41 @@ public class BeamCalcRel extends Calc implements BeamRelNode {
       }
       Expression field = Expressions.call(expression, getter, Expressions.constant(index));
       if (fromType.getTypeName().isLogicalType()) {
-        field = Expressions.call(field, "getMillis");
+        Expression millisField = Expressions.call(field, "getMillis");
         String logicalId = fromType.getLogicalType().getIdentifier();
         if (logicalId.equals(TimeType.IDENTIFIER)) {
-          field = Expressions.convert_(field, int.class);
+          field =
+              Expressions.condition(
+                  Expressions.equal(field, Expressions.constant(null)),
+                  Expressions.constant(null),
+                  Expressions.box(Expressions.convert_(millisField, int.class)));
         } else if (logicalId.equals(DateType.IDENTIFIER)) {
           field =
-              Expressions.convert_(
-                  Expressions.modulo(field, Expressions.constant(MILLIS_PER_DAY)), int.class);
+              Expressions.condition(
+                  Expressions.equal(field, Expressions.constant(null)),
+                  Expressions.constant(null),
+                  Expressions.box(
+                      Expressions.convert_(
+                          Expressions.divide(millisField, Expressions.constant(MILLIS_PER_DAY)),
+                          int.class)));
         } else if (!logicalId.equals(CharType.IDENTIFIER)) {
           throw new IllegalArgumentException(
               "Unknown LogicalType " + fromType.getLogicalType().getIdentifier());
         }
       } else if (CalciteUtils.isDateTimeType(fromType)) {
-        field = Expressions.call(field, "getMillis");
+        field =
+            Expressions.condition(
+                Expressions.equal(field, Expressions.constant(null)),
+                Expressions.constant(null),
+                Expressions.box(Expressions.call(field, "getMillis")));
       } else if (fromType.getTypeName().isCompositeType()
           || (fromType.getTypeName().isCollectionType()
               && fromType.getCollectionElementType().getTypeName().isCompositeType())) {
-        field = Expressions.call(WrappedList.class, "of", field);
+        field =
+            Expressions.condition(
+                Expressions.equal(field, Expressions.constant(null)),
+                Expressions.constant(null),
+                Expressions.call(WrappedList.class, "of", field));
       }
       return field;
     }
diff --git a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java
index 1e6eaf3e1d3..f0c8799c180 100644
--- a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java
+++ b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java
@@ -26,10 +26,13 @@ import org.apache.beam.sdk.schemas.Schema;
 import org.apache.beam.sdk.schemas.Schema.FieldType;
 import org.apache.beam.sdk.testing.PAssert;
 import org.apache.beam.sdk.testing.TestPipeline;
+import org.apache.beam.sdk.transforms.Create;
 import org.apache.beam.sdk.values.PCollection;
 import org.apache.beam.sdk.values.Row;
 import org.apache.beam.vendor.guava.v20_0.com.google.common.collect.ImmutableMap;
+import org.joda.time.DateTime;
 import org.joda.time.Duration;
+import org.joda.time.Instant;
 import org.junit.Ignore;
 import org.junit.Rule;
 import org.junit.Test;
@@ -45,6 +48,12 @@ public class BeamComplexTypeTest {
           .addArrayField("array_field", FieldType.INT64)
           .build();
 
+  private static final Schema nullableInnerRowSchema =
+      Schema.builder()
+          .addNullableField("inner_row_field", FieldType.row(innerRowSchema))
+          .addNullableField("array_field", FieldType.array(FieldType.row(innerRowSchema)))
+          .build();
+
   private static final Schema nestedRowWithArraySchema =
       Schema.builder()
           .addStringField("field1")
@@ -53,6 +62,13 @@ public class BeamComplexTypeTest {
           .addArrayField("field4", FieldType.array(FieldType.STRING))
           .build();
 
+  private static final Schema nullableNestedRowWithArraySchema =
+      Schema.builder()
+          .addNullableField("field1", FieldType.row(innerRowWithArraySchema))
+          .addNullableField("field2", FieldType.array(FieldType.row(innerRowWithArraySchema)))
+          .addNullableField("field3", FieldType.row(nullableInnerRowSchema))
+          .build();
+
   private static final Schema nestedRowSchema =
       Schema.builder()
           .addStringField("nonRowfield1")
@@ -246,4 +262,172 @@ public class BeamComplexTypeTest {
                 .build());
     pipeline.run().waitUntilFinish(Duration.standardMinutes(2));
   }
+
+  @Test
+  public void testNullRows() {
+
+    Row nullRow = Row.nullRow(nullableNestedRowWithArraySchema);
+
+    PCollection<Row> outputRow =
+        pipeline
+            .apply(Create.of(nullRow))
+            .setRowSchema(nullableNestedRowWithArraySchema)
+            .apply(
+                SqlTransform.query(
+                    "select PCOLLECTION.field1.string_field as row_string_field, PCOLLECTION.field2[2].string_field as array_string_field from PCOLLECTION"));
+
+    PAssert.that(outputRow)
+        .containsInAnyOrder(
+            Row.nullRow(
+                Schema.builder()
+                    .addNullableField("row_string_field", FieldType.STRING)
+                    .addNullableField("array_string_field", FieldType.STRING)
+                    .build()));
+
+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));
+  }
+
+  @Test
+  public void testNullInnerRow() {
+
+    Row nestedInnerRow = Row.withSchema(innerRowSchema).addValues("str", 1000L).build();
+
+    Row innerRow =
+        Row.withSchema(nullableInnerRowSchema)
+            .addValues(null, Arrays.asList(nestedInnerRow))
+            .build();
+
+    Row row =
+        Row.withSchema(nullableNestedRowWithArraySchema).addValues(null, null, innerRow).build();
+
+    PCollection<Row> outputRow =
+        pipeline
+            .apply(Create.of(row))
+            .setRowSchema(nullableNestedRowWithArraySchema)
+            .apply(
+                SqlTransform.query(
+                    "select PCOLLECTION.field3.inner_row_field.string_field as string_field, PCOLLECTION.field3.array_field[1].long_field as long_field from PCOLLECTION"));
+
+    PAssert.that(outputRow)
+        .containsInAnyOrder(
+            Row.withSchema(
+                    Schema.builder()
+                        .addNullableField("string_field", FieldType.STRING)
+                        .addInt64Field("long_field")
+                        .build())
+                .addValues(null, 1000L)
+                .build());
+
+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));
+  }
+
+  private static class DummySqlTimeType implements Schema.LogicalType<Long, Instant> {
+    @Override
+    public String getIdentifier() {
+      return "SqlTimeType";
+    }
+
+    @Override
+    public Schema.FieldType getBaseType() {
+      return Schema.FieldType.DATETIME;
+    }
+
+    @Override
+    public Instant toBaseType(Long input) {
+      return new Instant((long) input);
+    }
+
+    @Override
+    public Long toInputType(Instant base) {
+      return base.getMillis();
+    }
+  }
+
+  private static class DummySqlDateType implements Schema.LogicalType<Long, Instant> {
+    @Override
+    public String getIdentifier() {
+      return "SqlDateType";
+    }
+
+    @Override
+    public Schema.FieldType getBaseType() {
+      return Schema.FieldType.DATETIME;
+    }
+
+    @Override
+    public Instant toBaseType(Long input) {
+      return new Instant((long) input);
+    }
+
+    @Override
+    public Long toInputType(Instant base) {
+      return base.getMillis();
+    }
+  }
+
+  @Test
+  public void testNullDatetimeFields() {
+    Instant current = new Instant(1561671380000L); // Long value corresponds to 27/06/2019
+    DateTime date = new DateTime(3600000);
+
+    Schema dateTimeFieldSchema =
+        Schema.builder()
+            .addField("dateTimeField", FieldType.DATETIME)
+            .addNullableField("nullableDateTimeField", FieldType.DATETIME)
+            .addField("timeTypeField", FieldType.logicalType(new DummySqlTimeType()))
+            .addNullableField(
+                "nullableTimeTypeField", FieldType.logicalType(new DummySqlTimeType()))
+            .addField("dateTypeField", FieldType.logicalType(new DummySqlDateType()))
+            .addNullableField(
+                "nullableDateTypeField", FieldType.logicalType(new DummySqlDateType()))
+            .build();
+
+    Row dateTimeRow =
+        Row.withSchema(dateTimeFieldSchema)
+            .addValues(current, null, date.getMillis(), null, current.getMillis(), null)
+            .build();
+
+    PCollection<Row> outputRow =
+        pipeline
+            .apply(Create.of(dateTimeRow))
+            .setRowSchema(dateTimeFieldSchema)
+            .apply(
+                SqlTransform.query(
+                    "select EXTRACT(YEAR from dateTimeField) as yyyy, "
+                        + " EXTRACT(YEAR from nullableDateTimeField) as year_with_null, "
+                        + " EXTRACT(MONTH from dateTimeField) as mm, "
+                        + " EXTRACT(MONTH from nullableDateTimeField) as month_with_null, "
+                        + " timeTypeField + interval '1' hour as time_with_hour_added, "
+                        + " nullableTimeTypeField + interval '1' hour as hour_added_with_null,  "
+                        + " timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, "
+                        + " nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null,  "
+                        + " EXTRACT(DAY from dateTypeField) as dd, "
+                        + " EXTRACT(DAY from nullableDateTypeField) as day_with_null  "
+                        + " from PCOLLECTION"));
+
+    Schema outputRowSchema =
+        Schema.builder()
+            .addField("yyyy", FieldType.INT64)
+            .addNullableField("year_with_null", FieldType.INT64)
+            .addField("mm", FieldType.INT64)
+            .addNullableField("month_with_null", FieldType.INT64)
+            .addField("time_with_hour_added", FieldType.DATETIME)
+            .addNullableField("hour_added_with_null", FieldType.DATETIME)
+            .addField("time_with_seconds_added", FieldType.DATETIME)
+            .addNullableField("seconds_added_with_null", FieldType.DATETIME)
+            .addField("dd", FieldType.INT64)
+            .addNullableField("day_with_null", FieldType.INT64)
+            .build();
+
+    Instant futureTime = date.toInstant().plus(3600 * 1000);
+    Instant pastTime = date.toInstant().minus(60 * 1000);
+
+    PAssert.that(outputRow)
+        .containsInAnyOrder(
+            Row.withSchema(outputRowSchema)
+                .addValues(2019L, null, 06L, null, futureTime, null, pastTime, null, 27L, null)
+                .build());
+
+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));
+  }
 }
