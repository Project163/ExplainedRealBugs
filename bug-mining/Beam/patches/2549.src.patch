diff --git a/sdks/python/apache_beam/transforms/trigger.py b/sdks/python/apache_beam/transforms/trigger.py
index 452f2c28371..e16cc54f558 100644
--- a/sdks/python/apache_beam/transforms/trigger.py
+++ b/sdks/python/apache_beam/transforms/trigger.py
@@ -30,9 +30,7 @@ from abc import ABCMeta
 from abc import abstractmethod
 from enum import Flag
 from enum import auto
-from functools import reduce
 from itertools import zip_longest
-from operator import or_
 
 from apache_beam.coders import coder_impl
 from apache_beam.coders import observable
@@ -161,12 +159,42 @@ class _WatermarkHoldStateTag(_StateTag):
 
 
 class DataLossReason(Flag):
-  """Enum defining potential reasons that a trigger may cause data loss."""
+  """Enum defining potential reasons that a trigger may cause data loss.
+
+  These flags should only cover when the trigger is the cause, though windowing
+  can be taken into account. For instance, AfterWatermark may not flag itself
+  as finishing if the windowing doesn't allow lateness.
+  """
+
+  # Trigger will never be the source of data loss.
   NO_POTENTIAL_LOSS = 0
+
+  # Trigger may finish. In this case, data that comes in after the trigger may
+  # be lost. Example: AfterCount(1) will stop firing after the first element.
   MAY_FINISH = auto()
+
+  # Trigger has a condition that is not guaranteed to ever be met. In this
+  # case, data that comes in may be lost. Example: AfterCount(42) will lose
+  # 20 records if only 20 come in, since the condition to fire was never met.
   CONDITION_NOT_GUARANTEED = auto()
 
 
+# Convenience functions for checking if a flag is included. Each is equivalent
+# to `reason & flag == flag`
+
+
+def _IncludesMayFinish(reason):
+  # type: (DataLossReason) -> bool
+  return reason & DataLossReason.MAY_FINISH == DataLossReason.MAY_FINISH
+
+
+def _IncludesConditionNotGuaranteed(reason):
+  # type: (DataLossReason) -> bool
+  return (
+      reason & DataLossReason.CONDITION_NOT_GUARANTEED ==
+      DataLossReason.CONDITION_NOT_GUARANTEED)
+
+
 # pylint: disable=unused-argument
 # TODO(robertwb): Provisional API, Java likely to change as well.
 class TriggerFn(metaclass=ABCMeta):
@@ -260,12 +288,11 @@ class TriggerFn(metaclass=ABCMeta):
           scenario is only accounted for if the windowing strategy allows
           late data. Otherwise, the trigger is not responsible for the data
           loss.
-        * The trigger condition may not be met. For instance,
-          Repeatedly(AfterCount(N)) may not fire due to N not being met. This
-          is only accounted for if the condition itself led to data loss.
-          Repeatedly(AfterCount(1)) is safe, since it would only not fire if
-          there is no data to lose, but Repeatedly(AfterCount(2)) can cause
-          data loss if there is only one record.
+        * The trigger condition may not be met. For instance, AfterCount(N)
+          may not fire due to N not being met. This is only accounted for if
+          the condition itself led to data loss. Repeatedly(AfterCount(1)) is
+          safe, since it would only not fire if there is no data to lose, but
+          AfterCount(2) can cause data loss if there is only one record.
 
     Note that this only returns the potential for loss. It does not mean that
     there will be data loss. It also only accounts for loss related to the
@@ -390,7 +417,15 @@ class AfterProcessingTime(TriggerFn):
     pass
 
   def may_lose_data(self, unused_windowing):
-    return DataLossReason.MAY_FINISH
+    """AfterProcessingTime may finish.
+
+    It is also possible, if the delay is greater than zero, that data loss
+    could result from not enough seconds passing after processing time.
+    """
+    reason = DataLossReason.MAY_FINISH
+    if self.delay > 0:
+      reason |= DataLossReason.CONDITION_NOT_GUARANTEED
+    return reason
 
   @staticmethod
   def from_runner_api(proto, context):
@@ -444,6 +479,7 @@ class Always(TriggerFn):
     return False
 
   def may_lose_data(self, unused_windowing):
+    """No potential loss, since the trigger always fires."""
     return DataLossReason.NO_POTENTIAL_LOSS
 
   @staticmethod
@@ -591,13 +627,7 @@ class AfterWatermark(TriggerFn):
       self.late.reset(window, NestedContext(context, 'late'))
 
   def may_lose_data(self, windowing):
-    """May cause data loss if the windowing allows lateness and either:
-
-      * The late trigger is not set
-      * The late trigger may cause data loss.
-
-    The second case is equivalent to Repeatedly(late).may_lose_data(windowing)
-    """
+    """May cause data loss if lateness allowed and no late trigger set."""
     if windowing.allowed_lateness == 0:
       return DataLossReason.NO_POTENTIAL_LOSS
     if self.late is None:
@@ -833,12 +863,21 @@ class AfterAny(_ParallelTriggerFn):
   combine_op = any
 
   def may_lose_data(self, windowing):
+    """May be flagged as unsafe under certain conditions.
+
+    If any sub-trigger may finish, this one may finish. If all sub-triggers
+    have unguaranteed conditions, then this one has an unguaranteed condition.
+    """
     reason = DataLossReason.NO_POTENTIAL_LOSS
+    unguaranteed_conditions = 0
     for trigger in self.triggers:
       t_reason = trigger.may_lose_data(windowing)
-      if t_reason == DataLossReason.NO_POTENTIAL_LOSS:
-        return t_reason
-      reason |= t_reason
+      if _IncludesMayFinish(t_reason):
+        reason |= DataLossReason.MAY_FINISH
+      if _IncludesConditionNotGuaranteed(t_reason):
+        unguaranteed_conditions += 1
+    if unguaranteed_conditions == len(self.triggers):
+      reason |= DataLossReason.CONDITION_NOT_GUARANTEED
     return reason
 
 
@@ -850,7 +889,22 @@ class AfterAll(_ParallelTriggerFn):
   combine_op = all
 
   def may_lose_data(self, windowing):
-    return reduce(or_, (t.may_lose_data(windowing) for t in self.triggers))
+    """May be flagged as unsafe under certain conditions.
+
+    If all sub-triggers may finish, then this may finish. If any sub-trigger
+    has an unguaranteed condition, this has an unguaranteed condition.
+    """
+    reason = DataLossReason.NO_POTENTIAL_LOSS
+    may_finish = 0
+    for trigger in self.triggers:
+      t_reason = trigger.may_lose_data(windowing)
+      if _IncludesMayFinish(t_reason):
+        may_finish += 1
+      if _IncludesConditionNotGuaranteed(t_reason):
+        reason |= DataLossReason.CONDITION_NOT_GUARANTEED
+    if may_finish == len(self.triggers):
+      reason |= DataLossReason.MAY_FINISH
+    return reason
 
 
 class AfterEach(TriggerFn):
@@ -908,7 +962,19 @@ class AfterEach(TriggerFn):
       trigger.reset(window, self._sub_context(context, ix))
 
   def may_lose_data(self, windowing):
-    return reduce(or_, (t.may_lose_data(windowing) for t in self.triggers))
+    """May be flagged as unsafe under certain conditions.
+
+    If any sub-trigger has NO_POTENTIAL_LOSS or CONDITION_NOT_GUARANTEED, then
+    this will return the same based on the first encountered one. If none of
+    the sub-triggers have either of these, then it will return MAY_FINISH.
+    """
+    for t in self.triggers:
+      reason = t.may_lose_data(windowing)
+      if reason == DataLossReason.NO_POTENTIAL_LOSS:
+        return DataLossReason.NO_POTENTIAL_LOSS
+      if _IncludesConditionNotGuaranteed(reason):
+        return DataLossReason.CONDITION_NOT_GUARANTEED
+    return DataLossReason.MAY_FINISH
 
   @staticmethod
   def _sub_context(context, index):
diff --git a/sdks/python/apache_beam/transforms/trigger_test.py b/sdks/python/apache_beam/transforms/trigger_test.py
index f0f4902901d..f75711ca262 100644
--- a/sdks/python/apache_beam/transforms/trigger_test.py
+++ b/sdks/python/apache_beam/transforms/trigger_test.py
@@ -449,8 +449,14 @@ class MayLoseDataTest(unittest.TestCase):
   def test_default_trigger(self):
     self._test(DefaultTrigger(), 0, DataLossReason.NO_POTENTIAL_LOSS)
 
-  def test_after_processing_time(self):
-    self._test(AfterProcessingTime(), 0, DataLossReason.MAY_FINISH)
+  def test_after_processing_time_zero(self):
+    self._test(AfterProcessingTime(0), 0, DataLossReason.MAY_FINISH)
+
+  def test_after_processing_time_non_zero(self):
+    self._test(
+        AfterProcessingTime(10),
+        0,
+        DataLossReason.MAY_FINISH | DataLossReason.CONDITION_NOT_GUARANTEED)
 
   def test_always(self):
     self._test(Always(), 0, DataLossReason.NO_POTENTIAL_LOSS)
@@ -461,7 +467,7 @@ class MayLoseDataTest(unittest.TestCase):
   def test_after_watermark_no_allowed_lateness(self):
     self._test(AfterWatermark(), 0, DataLossReason.NO_POTENTIAL_LOSS)
 
-  def test_after_watermark_late_none(self):
+  def test_after_watermark_no_late_trigger(self):
     self._test(AfterWatermark(), 60, DataLossReason.MAY_FINISH)
 
   def test_after_watermark_no_allowed_lateness_safe_late(self):
@@ -470,7 +476,7 @@ class MayLoseDataTest(unittest.TestCase):
         0,
         DataLossReason.NO_POTENTIAL_LOSS)
 
-  def test_after_watermark_safe_late(self):
+  def test_after_watermark_allowed_lateness_safe_late(self):
     self._test(
         AfterWatermark(late=DefaultTrigger()),
         60,
@@ -484,8 +490,9 @@ class MayLoseDataTest(unittest.TestCase):
 
   def test_after_watermark_may_finish_late(self):
     self._test(
-        AfterWatermark(late=AfterProcessingTime()),
+        AfterWatermark(late=AfterProcessingTime(0)),
         60,
+        #  No loss, since it is wrapped in Repeatedly
         DataLossReason.NO_POTENTIAL_LOSS)
 
   def test_after_watermark_no_allowed_lateness_condition_late(self):
@@ -496,6 +503,7 @@ class MayLoseDataTest(unittest.TestCase):
     self._test(
         AfterWatermark(late=AfterCount(5)),
         60,
+        # No loss, since it is wrapped in Repeatedly
         DataLossReason.NO_POTENTIAL_LOSS)
 
   def test_after_count_one(self):
@@ -517,45 +525,57 @@ class MayLoseDataTest(unittest.TestCase):
   def test_repeatedly_condition_underlying(self):
     self._test(Repeatedly(AfterCount(2)), 0, DataLossReason.NO_POTENTIAL_LOSS)
 
-  def test_after_any_some_unsafe(self):
+  def test_after_any_one_may_finish(self):
     self._test(
-        AfterAny(AfterCount(1), DefaultTrigger()),
+        AfterAny(AfterCount(1), DefaultTrigger()), 0, DataLossReason.MAY_FINISH)
+
+  def test_after_any_one_condition_not_guaranteed(self):
+    self._test(
+        AfterAny(AfterCount(2), AfterWatermark()), 0, DataLossReason.MAY_FINISH)
+
+  def test_after_any_all_conditions_not_guaranteed(self):
+    self._test(
+        AfterAny(AfterCount(2), AfterProcessingTime(1)),
         0,
-        DataLossReason.NO_POTENTIAL_LOSS)
+        DataLossReason.MAY_FINISH | DataLossReason.CONDITION_NOT_GUARANTEED)
 
-  def test_after_any_same_reason(self):
+  def test_after_all_some_may_finish(self):
     self._test(
-        AfterAny(AfterCount(1), AfterProcessingTime()),
+        AfterAll(AfterCount(1), DefaultTrigger()),
         0,
-        DataLossReason.MAY_FINISH)
+        DataLossReason.NO_POTENTIAL_LOSS)
 
-  def test_after_any_different_reasons(self):
+  def test_afer_all_all_may_finish(self):
     self._test(
-        AfterAny(AfterCount(2), AfterProcessingTime()),
+        AfterAll(AfterCount(1), AfterProcessingTime(0)),
         0,
-        DataLossReason.MAY_FINISH | DataLossReason.CONDITION_NOT_GUARANTEED)
+        DataLossReason.MAY_FINISH)
 
-  def test_after_all_some_unsafe(self):
+  def test_after_all_any_condition_not_guaranteed(self):
     self._test(
-        AfterAll(AfterCount(1), DefaultTrigger()), 0, DataLossReason.MAY_FINISH)
+        AfterAll(AfterCount(2), DefaultTrigger()),
+        0,
+        DataLossReason.CONDITION_NOT_GUARANTEED)
 
-  def test_after_all_safe(self):
+  def test_after_each_safe_comes_first(self):
+    # Note: Safe comes first in relation to CONDITIOON_NOT_GUARANTEED
     self._test(
-        AfterAll(Repeatedly(AfterCount(1)), DefaultTrigger()),
+        AfterEach(AfterCount(1), DefaultTrigger(), AfterCount(2)),
         0,
         DataLossReason.NO_POTENTIAL_LOSS)
 
-  def test_after_each_some_unsafe(self):
+  def test_after_each_safe_comes_second(self):
+    # Note: Safe comes second in relation to CONDITIOON_NOT_GUARANTEED
     self._test(
-        AfterEach(AfterCount(1), DefaultTrigger()),
+        AfterEach(AfterCount(1), AfterCount(2), DefaultTrigger()),
         0,
-        DataLossReason.MAY_FINISH)
+        DataLossReason.CONDITION_NOT_GUARANTEED)
 
-  def test_after_each_all_safe(self):
+  def test_after_each_all_may_finish(self):
     self._test(
-        AfterEach(Repeatedly(AfterCount(1)), DefaultTrigger()),
+        AfterEach(AfterCount(1), AfterCount(1), AfterCount(1)),
         0,
-        DataLossReason.NO_POTENTIAL_LOSS)
+        DataLossReason.MAY_FINISH)
 
 
 class RunnerApiTest(unittest.TestCase):
@@ -714,7 +734,8 @@ class TriggerPipelineTest(unittest.TestCase):
     test_stream.advance_processing_time(START_TIMESTAMP + 2)
     test_stream.advance_watermark_to(START_TIMESTAMP + 2)
 
-    with TestPipeline(options=PipelineOptions(['--streaming'])) as p:
+    with TestPipeline(options=PipelineOptions(
+        ['--streaming', '--allow_unsafe_triggers'])) as p:
       # pylint: disable=expression-not-assigned
       (
           p
