diff --git a/runners/direct-java/src/main/java/org/apache/beam/runners/direct/ExecutorServiceParallelExecutor.java b/runners/direct-java/src/main/java/org/apache/beam/runners/direct/ExecutorServiceParallelExecutor.java
index a43afe6118c..44f29748ca5 100644
--- a/runners/direct-java/src/main/java/org/apache/beam/runners/direct/ExecutorServiceParallelExecutor.java
+++ b/runners/direct-java/src/main/java/org/apache/beam/runners/direct/ExecutorServiceParallelExecutor.java
@@ -22,8 +22,8 @@ import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Map;
 import java.util.Optional;
+import java.util.Queue;
 import java.util.concurrent.BlockingQueue;
-import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.LinkedBlockingQueue;
@@ -44,6 +44,7 @@ import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.CacheLoade
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.LoadingCache;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.cache.RemovalListener;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;
+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Queues;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.MoreExecutors;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.ThreadFactoryBuilder;
 import org.checkerframework.checker.nullness.qual.Nullable;
@@ -150,10 +151,10 @@ final class ExecutorServiceParallelExecutor
   @SuppressWarnings("FutureReturnValueIgnored")
   public void start(DirectGraph graph, RootProviderRegistry rootProviderRegistry) {
     int numTargetSplits = Math.max(3, targetParallelism);
-    ImmutableMap.Builder<AppliedPTransform<?, ?, ?>, ConcurrentLinkedQueue<CommittedBundle<?>>>
-        pendingRootBundles = ImmutableMap.builder();
+    ImmutableMap.Builder<AppliedPTransform<?, ?, ?>, Queue<CommittedBundle<?>>> pendingRootBundles =
+        ImmutableMap.builder();
     for (AppliedPTransform<?, ?, ?> root : graph.getRootTransforms()) {
-      ConcurrentLinkedQueue<CommittedBundle<?>> pending = new ConcurrentLinkedQueue<>();
+      Queue<CommittedBundle<?>> pending = Queues.newArrayDeque();
       try {
         Collection<CommittedBundle<?>> initialInputs =
             rootProviderRegistry.getInitialInputs(root, numTargetSplits);
diff --git a/runners/direct-java/src/main/java/org/apache/beam/runners/direct/QuiescenceDriver.java b/runners/direct-java/src/main/java/org/apache/beam/runners/direct/QuiescenceDriver.java
index dfd3ee486cd..b5e5736baf7 100644
--- a/runners/direct-java/src/main/java/org/apache/beam/runners/direct/QuiescenceDriver.java
+++ b/runners/direct-java/src/main/java/org/apache/beam/runners/direct/QuiescenceDriver.java
@@ -60,7 +60,7 @@ class QuiescenceDriver implements ExecutionDriver {
       BundleProcessor<PCollection<?>, CommittedBundle<?>, AppliedPTransform<?, ?, ?>>
           bundleProcessor,
       PipelineMessageReceiver messageReceiver,
-      Map<AppliedPTransform<?, ?, ?>, ConcurrentLinkedQueue<CommittedBundle<?>>> initialBundles) {
+      Map<AppliedPTransform<?, ?, ?>, Queue<CommittedBundle<?>>> initialBundles) {
     return new QuiescenceDriver(context, graph, bundleProcessor, messageReceiver, initialBundles);
   }
 
@@ -73,8 +73,7 @@ class QuiescenceDriver implements ExecutionDriver {
   private final CompletionCallback defaultCompletionCallback =
       new TimerIterableCompletionCallback(Collections.emptyList());
 
-  private final Map<AppliedPTransform<?, ?, ?>, ConcurrentLinkedQueue<CommittedBundle<?>>>
-      pendingRootBundles;
+  private final Map<AppliedPTransform<?, ?, ?>, Queue<CommittedBundle<?>>> pendingRootBundles;
   private final Queue<WorkUpdate> pendingWork = new ConcurrentLinkedQueue<>();
   // We collect here bundles and AppliedPTransforms that have started to process bundle, but have
   // not completed it yet. The reason for that is that the bundle processing might change output
@@ -94,8 +93,7 @@ class QuiescenceDriver implements ExecutionDriver {
       BundleProcessor<PCollection<?>, CommittedBundle<?>, AppliedPTransform<?, ?, ?>>
           bundleProcessor,
       PipelineMessageReceiver pipelineMessageReceiver,
-      Map<AppliedPTransform<?, ?, ?>, ConcurrentLinkedQueue<CommittedBundle<?>>>
-          pendingRootBundles) {
+      Map<AppliedPTransform<?, ?, ?>, Queue<CommittedBundle<?>>> pendingRootBundles) {
     this.evaluationContext = evaluationContext;
     this.graph = graph;
     this.bundleProcessor = bundleProcessor;
@@ -222,19 +220,21 @@ class QuiescenceDriver implements ExecutionDriver {
   private void addWorkIfNecessary() {
     // If any timers have fired, they will add more work; We don't need to add more
     if (state.get() == ExecutorState.QUIESCENT) {
-      // All current TransformExecutors are blocked; add more work from the roots.
-      for (Map.Entry<AppliedPTransform<?, ?, ?>, ConcurrentLinkedQueue<CommittedBundle<?>>>
-          pendingRootEntry : pendingRootBundles.entrySet()) {
-        Collection<CommittedBundle<?>> bundles = new ArrayList<>();
-        // Pull all available work off of the queue, then schedule it all, so this loop
-        // terminates
-        while (!pendingRootEntry.getValue().isEmpty()) {
-          CommittedBundle<?> bundle = pendingRootEntry.getValue().poll();
-          bundles.add(bundle);
-        }
-        for (CommittedBundle<?> bundle : bundles) {
-          processBundle(bundle, pendingRootEntry.getKey());
-          state.set(ExecutorState.ACTIVE);
+      synchronized (pendingRootBundles) {
+        // All current TransformExecutors are blocked; add more work from the roots.
+        for (Map.Entry<AppliedPTransform<?, ?, ?>, Queue<CommittedBundle<?>>> pendingRootEntry :
+            pendingRootBundles.entrySet()) {
+          Collection<CommittedBundle<?>> bundles = new ArrayList<>();
+          // Pull all available work off of the queue, then schedule it all, so this loop
+          // terminates
+          while (!pendingRootEntry.getValue().isEmpty()) {
+            CommittedBundle<?> bundle = pendingRootEntry.getValue().poll();
+            bundles.add(bundle);
+          }
+          for (CommittedBundle<?> bundle : bundles) {
+            processBundle(bundle, pendingRootEntry.getKey());
+            state.set(ExecutorState.ACTIVE);
+          }
         }
       }
     }
@@ -306,7 +306,9 @@ class QuiescenceDriver implements ExecutionDriver {
       if (unprocessedInputs.isPresent()) {
         if (inputBundle.getPCollection() == null) {
           // TODO: Split this logic out of an if statement
-          pendingRootBundles.get(result.getTransform()).offer(unprocessedInputs.get());
+          synchronized (pendingRootBundles) {
+            pendingRootBundles.get(result.getTransform()).offer(unprocessedInputs.get());
+          }
         } else {
           pendingWork.offer(
               WorkUpdate.fromBundle(
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/ParDoLifecycleTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/ParDoLifecycleTest.java
index a8f5489584e..337b9315b99 100644
--- a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/ParDoLifecycleTest.java
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/ParDoLifecycleTest.java
@@ -32,9 +32,9 @@ import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
+import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
@@ -182,7 +182,7 @@ public class ParDoLifecycleTest implements Serializable {
       p.run();
       fail("Pipeline should have failed with an exception");
     } catch (Exception e) {
-      validate(CallState.SETUP, CallState.TEARDOWN);
+      ExceptionThrowingFn.validate(CallState.SETUP, CallState.TEARDOWN);
     }
   }
 
@@ -195,7 +195,7 @@ public class ParDoLifecycleTest implements Serializable {
       p.run();
       fail("Pipeline should have failed with an exception");
     } catch (Exception e) {
-      validate(CallState.SETUP, CallState.START_BUNDLE, CallState.TEARDOWN);
+      ExceptionThrowingFn.validate(CallState.SETUP, CallState.START_BUNDLE, CallState.TEARDOWN);
     }
   }
 
@@ -208,7 +208,7 @@ public class ParDoLifecycleTest implements Serializable {
       p.run();
       fail("Pipeline should have failed with an exception");
     } catch (Exception e) {
-      validate(
+      ExceptionThrowingFn.validate(
           CallState.SETUP, CallState.START_BUNDLE, CallState.PROCESS_ELEMENT, CallState.TEARDOWN);
     }
   }
@@ -222,7 +222,7 @@ public class ParDoLifecycleTest implements Serializable {
       p.run();
       fail("Pipeline should have failed with an exception");
     } catch (Exception e) {
-      validate(
+      ExceptionThrowingFn.validate(
           CallState.SETUP,
           CallState.START_BUNDLE,
           CallState.PROCESS_ELEMENT,
@@ -240,7 +240,7 @@ public class ParDoLifecycleTest implements Serializable {
       p.run();
       fail("Pipeline should have failed with an exception");
     } catch (Exception e) {
-      validate(CallState.SETUP, CallState.TEARDOWN);
+      ExceptionThrowingFn.validate(CallState.SETUP, CallState.TEARDOWN);
     }
   }
 
@@ -253,7 +253,7 @@ public class ParDoLifecycleTest implements Serializable {
       p.run();
       fail("Pipeline should have failed with an exception");
     } catch (Exception e) {
-      validate(CallState.SETUP, CallState.START_BUNDLE, CallState.TEARDOWN);
+      ExceptionThrowingFn.validate(CallState.SETUP, CallState.START_BUNDLE, CallState.TEARDOWN);
     }
   }
 
@@ -266,7 +266,7 @@ public class ParDoLifecycleTest implements Serializable {
       p.run();
       fail("Pipeline should have failed with an exception");
     } catch (Exception e) {
-      validate(
+      ExceptionThrowingFn.validate(
           CallState.SETUP, CallState.START_BUNDLE, CallState.PROCESS_ELEMENT, CallState.TEARDOWN);
     }
   }
@@ -280,7 +280,7 @@ public class ParDoLifecycleTest implements Serializable {
       p.run();
       fail("Pipeline should have failed with an exception");
     } catch (Exception e) {
-      validate(
+      ExceptionThrowingFn.validate(
           CallState.SETUP,
           CallState.START_BUNDLE,
           CallState.PROCESS_ELEMENT,
@@ -289,33 +289,9 @@ public class ParDoLifecycleTest implements Serializable {
     }
   }
 
-  private void validate(CallState... requiredCallStates) {
-    assertThat(ExceptionThrowingFn.callStateMap, is(not(anEmptyMap())));
-    // assert that callStateMap contains only TEARDOWN as a value. Note: We do not expect
-    // teardown to be called on fn itself, but on any deserialized instance on which any other
-    // lifecycle method was called
-    ExceptionThrowingFn.callStateMap
-        .values()
-        .forEach(
-            value ->
-                assertThat(
-                    "Function should have been torn down after exception",
-                    value.finalState(),
-                    is(CallState.TEARDOWN)));
-
-    List<CallState> states = Arrays.stream(requiredCallStates).collect(Collectors.toList());
-    assertThat(
-        "At least one bundle should contain "
-            + states
-            + ", got "
-            + ExceptionThrowingFn.callStateMap.values(),
-        ExceptionThrowingFn.callStateMap.values().stream()
-            .anyMatch(tracker -> tracker.callStateVisited.equals(states)));
-  }
-
   @Before
   public void setup() {
-    ExceptionThrowingFn.callStateMap = new ConcurrentHashMap<>();
+    ExceptionThrowingFn.callStateMap = new HashMap<>();
     ExceptionThrowingFn.exceptionWasThrown.set(false);
   }
 
@@ -350,11 +326,13 @@ public class ParDoLifecycleTest implements Serializable {
 
     @Override
     public String toString() {
-      return MoreObjects.toStringHelper(this)
-          .add("latch", latch)
-          .add("callState", callState)
-          .add("callStateVisited", callStateVisited)
-          .toString();
+      synchronized (callStateVisited) {
+        return MoreObjects.toStringHelper(this)
+            .add("latch", latch)
+            .add("callState", callState)
+            .add("callStateVisited", callStateVisited)
+            .toString();
+      }
     }
 
     CallState callState() {
@@ -365,7 +343,9 @@ public class ParDoLifecycleTest implements Serializable {
       try {
         // call to tearDown might be delayed on other thread (happens on direct runner)
         // so lets wait a while if not yet called to give a chance to catch up
-        latch.await(1, TimeUnit.SECONDS);
+        if (!latch.await(60, TimeUnit.SECONDS)) {
+          throw new RuntimeException("Timed out waiting for tearDown");
+        }
       } catch (InterruptedException e) {
         Thread.currentThread().interrupt();
       }
@@ -374,7 +354,7 @@ public class ParDoLifecycleTest implements Serializable {
   }
 
   private static class ExceptionThrowingFn<T> extends DoFn<T, T> {
-    static Map<Integer, DelayedCallStateTracker> callStateMap = new ConcurrentHashMap<>();
+    static HashMap<Integer, DelayedCallStateTracker> callStateMap = new HashMap<>();
     // exception is not necessarily thrown on every instance. But we expect at least
     // one during tests
     static AtomicBoolean exceptionWasThrown = new AtomicBoolean(false);
@@ -387,43 +367,84 @@ public class ParDoLifecycleTest implements Serializable {
       this.toThrow = toThrow;
     }
 
+    private static void validate(CallState... requiredCallStates) {
+      Map<Integer, DelayedCallStateTracker> callStates;
+      synchronized (ExceptionThrowingFn.class) {
+        callStates =
+            (Map<Integer, DelayedCallStateTracker>) ExceptionThrowingFn.callStateMap.clone();
+      }
+      assertThat(callStates, is(not(anEmptyMap())));
+      // assert that callStateMap contains only TEARDOWN as a value. Note: We do not expect
+      // teardown to be called on fn itself, but on any deserialized instance on which any other
+      // lifecycle method was called
+      callStates.forEach(
+          (key, value) ->
+              assertThat(
+                  "Function should have been torn down after exception for id() " + key,
+                  value.finalState(),
+                  is(CallState.TEARDOWN)));
+
+      List<CallState> states = Arrays.stream(requiredCallStates).collect(Collectors.toList());
+      assertThat(
+          "At least one bundle should contain "
+              + states
+              + ", got "
+              + ExceptionThrowingFn.callStateMap.values(),
+          callStates.values().stream()
+              .anyMatch(tracker -> tracker.callStateVisited.equals(states)));
+    }
+
     @Setup
     public void before() throws Exception {
-      assertThat(
-          "lifecycle methods should not have been called", callStateMap.get(id()), is(nullValue()));
-      initCallState();
+      synchronized (ExceptionThrowingFn.class) {
+        assertThat(
+            "lifecycle methods should not have been called",
+            callStateMap.get(id()),
+            is(nullValue()));
+        DelayedCallStateTracker previousTracker =
+            callStateMap.put(id(), new DelayedCallStateTracker(CallState.SETUP));
+        if (previousTracker != null) {
+          fail(CallState.SETUP + " method called multiple times");
+        }
+      }
       noOfInstancesToTearDown.incrementAndGet();
       throwIfNecessary(MethodForException.SETUP);
     }
 
     @StartBundle
     public void preBundle() throws Exception {
-      assertThat(
-          "lifecycle method should have been called before start bundle",
-          getCallState(),
-          anyOf(equalTo(CallState.SETUP), equalTo(CallState.FINISH_BUNDLE)));
-      updateCallState(CallState.START_BUNDLE);
-      throwIfNecessary(MethodForException.START_BUNDLE);
+      synchronized (ExceptionThrowingFn.class) {
+        assertThat(
+            "lifecycle method should have been called before start bundle",
+            callStateMap.get(id()).callState(),
+            anyOf(equalTo(CallState.SETUP), equalTo(CallState.FINISH_BUNDLE)));
+        callStateMap.get(id()).update(CallState.START_BUNDLE);
+        throwIfNecessary(MethodForException.START_BUNDLE);
+      }
     }
 
     @ProcessElement
     public void perElement(ProcessContext c) throws Exception {
-      assertThat(
-          "lifecycle method should have been called before processing bundle",
-          getCallState(),
-          anyOf(equalTo(CallState.START_BUNDLE), equalTo(CallState.PROCESS_ELEMENT)));
-      updateCallState(CallState.PROCESS_ELEMENT);
-      throwIfNecessary(MethodForException.PROCESS_ELEMENT);
+      synchronized (ExceptionThrowingFn.class) {
+        assertThat(
+            "lifecycle method should have been called before processing bundle",
+            callStateMap.get(id()).callState(),
+            anyOf(equalTo(CallState.START_BUNDLE), equalTo(CallState.PROCESS_ELEMENT)));
+        callStateMap.get(id()).update(CallState.PROCESS_ELEMENT);
+        throwIfNecessary(MethodForException.PROCESS_ELEMENT);
+      }
     }
 
     @FinishBundle
     public void postBundle() throws Exception {
-      assertThat(
-          "processing bundle or start bundle should have been called before finish bundle",
-          getCallState(),
-          anyOf(equalTo(CallState.PROCESS_ELEMENT), equalTo(CallState.START_BUNDLE)));
-      updateCallState(CallState.FINISH_BUNDLE);
-      throwIfNecessary(MethodForException.FINISH_BUNDLE);
+      synchronized (ExceptionThrowingFn.class) {
+        assertThat(
+            "processing bundle or start bundle should have been called before finish bundle",
+            callStateMap.get(id()).callState(),
+            anyOf(equalTo(CallState.PROCESS_ELEMENT), equalTo(CallState.START_BUNDLE)));
+        callStateMap.get(id()).update(CallState.FINISH_BUNDLE);
+        throwIfNecessary(MethodForException.FINISH_BUNDLE);
+      }
     }
 
     private void throwIfNecessary(MethodForException method) throws Exception {
@@ -439,32 +460,18 @@ public class ParDoLifecycleTest implements Serializable {
       if (noOfInstancesToTearDown.decrementAndGet() == 0 && !exceptionWasThrown.get()) {
         fail("Expected to have a processing method throw an exception");
       }
-      assertThat(
-          "some lifecycle method should have been called",
-          callStateMap.get(id()),
-          is(notNullValue()));
-      updateCallState(CallState.TEARDOWN);
-    }
-
-    private void initCallState() {
-      DelayedCallStateTracker previousTracker =
-          callStateMap.put(id(), new DelayedCallStateTracker(CallState.SETUP));
-      if (previousTracker != null) {
-        fail(CallState.SETUP + " method called multiple times");
+      synchronized (ExceptionThrowingFn.class) {
+        assertThat(
+            "some lifecycle method should have been called",
+            callStateMap.get(id()),
+            is(notNullValue()));
+        callStateMap.get(id()).update(CallState.TEARDOWN);
       }
     }
 
     private int id() {
       return System.identityHashCode(this);
     }
-
-    private void updateCallState(CallState state) {
-      callStateMap.get(id()).update(state);
-    }
-
-    private CallState getCallState() {
-      return callStateMap.get(id()).callState();
-    }
   }
 
   private static class ExceptionThrowingStatefulFn<K, V> extends ExceptionThrowingFn<KV<K, V>> {
