diff --git a/.test-infra/jenkins/job_PerformanceTests_FileBasedIO_IT.groovy b/.test-infra/jenkins/job_PerformanceTests_FileBasedIO_IT.groovy
index b7952e5d983..c33a3b448a8 100644
--- a/.test-infra/jenkins/job_PerformanceTests_FileBasedIO_IT.groovy
+++ b/.test-infra/jenkins/job_PerformanceTests_FileBasedIO_IT.groovy
@@ -43,6 +43,22 @@ def testsConfigurations = [
                         compressionType: 'GZIP'
                 ]
         ],
+        [
+                jobName           : 'beam_PerformanceTests_ManyFiles_TextIOIT',
+                jobDescription    : 'Runs PerfKit tests for TextIOIT with many output files',
+                itClass           : 'org.apache.beam.sdk.io.text.TextIOIT',
+                bqTable           : 'beam_performance.many_files_textioit_pkb_results',
+                prCommitStatusName: 'Java ManyFilesTextIO Performance Test',
+                prTriggerPhase    : 'Run Java ManyFilesTextIO Performance Test',
+                extraPipelineArgs: [
+                        bigQueryDataset: 'beam_performance',
+                        bigQueryTable: 'many_files_textioit_results',
+                        gcsPerformanceMetrics: 'true',
+                        numberOfRecords: '1000000',
+                        numberOfShards: '1000'
+                ]
+
+        ],
         [
                 jobName           : 'beam_PerformanceTests_AvroIOIT',
                 jobDescription    : 'Runs PerfKit tests for AvroIOIT',
diff --git a/.test-infra/jenkins/job_PerformanceTests_FileBasedIO_IT_HDFS.groovy b/.test-infra/jenkins/job_PerformanceTests_FileBasedIO_IT_HDFS.groovy
index cac06a2115f..e25d675650a 100644
--- a/.test-infra/jenkins/job_PerformanceTests_FileBasedIO_IT_HDFS.groovy
+++ b/.test-infra/jenkins/job_PerformanceTests_FileBasedIO_IT_HDFS.groovy
@@ -43,6 +43,19 @@ def testsConfigurations = [
                         compressionType: 'GZIP'
                 ]
         ],
+        [
+                jobName           : 'beam_PerformanceTests_ManyFiles_TextIOIT_HDFS',
+                jobDescription    : 'Runs PerfKit tests for TextIOIT with many output files on HDFS',
+                itClass           : 'org.apache.beam.sdk.io.text.TextIOIT',
+                bqTable           : 'beam_performance.many_files_textioit_hdfs_pkb_results',
+                prCommitStatusName: 'Java ManyFilesTextIO Performance Test on HDFS',
+                prTriggerPhase    : 'Run Java ManyFilesTextIO Performance Test HDFS',
+                extraPipelineArgs: [
+                        numberOfRecords: '1000000',
+                        numberOfShards: '1000'
+                ]
+
+        ],
         [
                 jobName           : 'beam_PerformanceTests_AvroIOIT_HDFS',
                 jobDescription    : 'Runs PerfKit tests for AvroIOIT on HDFS',
diff --git a/.test-infra/jenkins/job_beam_PerformanceTests_Analysis.groovy b/.test-infra/jenkins/job_beam_PerformanceTests_Analysis.groovy
index d718ee9230c..59c347d5366 100644
--- a/.test-infra/jenkins/job_beam_PerformanceTests_Analysis.groovy
+++ b/.test-infra/jenkins/job_beam_PerformanceTests_Analysis.groovy
@@ -26,11 +26,13 @@ def testConfiguration = [
                 bqTables: [
                         "beam_performance.textioit_pkb_results",
                         "beam_performance.compressed_textioit_pkb_results",
+                        "beam_performance.many_files_textioit_pkb_results",
                         "beam_performance.avroioit_pkb_results",
                         "beam_performance.tfrecordioit_pkb_results",
                         "beam_performance.xmlioit_pkb_results",
                         "beam_performance.textioit_hdfs_pkb_results",
                         "beam_performance.compressed_textioit_hdfs_pkb_results",
+                        "beam_performance.many_files_textioit_hdfs_pkb_results",
                         "beam_performance.avroioit_hdfs_pkb_results",
                         "beam_performance.xmlioit_hdfs_pkb_results",
                         "beam_performance.hadoopinputformatioit_pkb_results",
diff --git a/sdks/java/extensions/google-cloud-platform-core/src/main/java/org/apache/beam/sdk/extensions/gcp/options/GcsOptions.java b/sdks/java/extensions/google-cloud-platform-core/src/main/java/org/apache/beam/sdk/extensions/gcp/options/GcsOptions.java
index d18e70509b4..926879f03a5 100644
--- a/sdks/java/extensions/google-cloud-platform-core/src/main/java/org/apache/beam/sdk/extensions/gcp/options/GcsOptions.java
+++ b/sdks/java/extensions/google-cloud-platform-core/src/main/java/org/apache/beam/sdk/extensions/gcp/options/GcsOptions.java
@@ -26,6 +26,8 @@ import java.util.concurrent.SynchronousQueue;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 import javax.annotation.Nullable;
+import org.apache.beam.sdk.annotations.Experimental;
+import org.apache.beam.sdk.annotations.Experimental.Kind;
 import org.apache.beam.sdk.extensions.gcp.storage.GcsPathValidator;
 import org.apache.beam.sdk.extensions.gcp.storage.PathValidator;
 import org.apache.beam.sdk.options.ApplicationNameOptions;
@@ -119,6 +121,14 @@ public interface GcsOptions extends ApplicationNameOptions, GcpOptions, Pipeline
 
   void setPathValidator(PathValidator validator);
 
+  /** If true, reports metrics of certain operations, such as batch copies. */
+  @Description("Experimental. Whether to report performance metrics of certain GCS operations.")
+  @Default.Boolean(false)
+  @Experimental(Kind.FILESYSTEM)
+  Boolean getGcsPerformanceMetrics();
+
+  void setGcsPerformanceMetrics(Boolean reportPerformanceMetrics);
+
   /**
    * Returns the default {@link ExecutorService} to use within the Apache Beam SDK. The {@link
    * ExecutorService} is compatible with AppEngine.
diff --git a/sdks/java/extensions/google-cloud-platform-core/src/main/java/org/apache/beam/sdk/extensions/gcp/storage/GcsFileSystem.java b/sdks/java/extensions/google-cloud-platform-core/src/main/java/org/apache/beam/sdk/extensions/gcp/storage/GcsFileSystem.java
index d38a96fa942..604808f7c9d 100644
--- a/sdks/java/extensions/google-cloud-platform-core/src/main/java/org/apache/beam/sdk/extensions/gcp/storage/GcsFileSystem.java
+++ b/sdks/java/extensions/google-cloud-platform-core/src/main/java/org/apache/beam/sdk/extensions/gcp/storage/GcsFileSystem.java
@@ -25,6 +25,7 @@ import static com.google.common.base.Preconditions.checkState;
 import com.google.api.services.storage.model.Objects;
 import com.google.api.services.storage.model.StorageObject;
 import com.google.common.annotations.VisibleForTesting;
+import com.google.common.base.Stopwatch;
 import com.google.common.collect.FluentIterable;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Lists;
@@ -37,6 +38,7 @@ import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 import java.util.regex.Pattern;
 import javax.annotation.Nullable;
 import org.apache.beam.sdk.extensions.gcp.options.GcsOptions;
@@ -45,6 +47,8 @@ import org.apache.beam.sdk.io.fs.CreateOptions;
 import org.apache.beam.sdk.io.fs.MatchResult;
 import org.apache.beam.sdk.io.fs.MatchResult.Metadata;
 import org.apache.beam.sdk.io.fs.MatchResult.Status;
+import org.apache.beam.sdk.metrics.Counter;
+import org.apache.beam.sdk.metrics.Metrics;
 import org.apache.beam.sdk.util.GcsUtil;
 import org.apache.beam.sdk.util.GcsUtil.StorageObjectOrIOException;
 import org.apache.beam.sdk.util.gcsfs.GcsPath;
@@ -57,8 +61,18 @@ class GcsFileSystem extends FileSystem<GcsResourceId> {
 
   private final GcsOptions options;
 
+  /** Number of copy operations performed. */
+  private Counter numCopies;
+
+  /** Time spent performing copies. */
+  private Counter copyTimeMsec;
+
   GcsFileSystem(GcsOptions options) {
     this.options = checkNotNull(options, "options");
+    if (options.getGcsPerformanceMetrics()) {
+      numCopies = Metrics.counter(GcsFileSystem.class, "num_copies");
+      copyTimeMsec = Metrics.counter(GcsFileSystem.class, "copy_time_msec");
+    }
   }
 
   @Override
@@ -149,7 +163,13 @@ class GcsFileSystem extends FileSystem<GcsResourceId> {
   @Override
   protected void copy(List<GcsResourceId> srcResourceIds, List<GcsResourceId> destResourceIds)
       throws IOException {
+    Stopwatch stopwatch = Stopwatch.createStarted();
     options.getGcsUtil().copy(toFilenames(srcResourceIds), toFilenames(destResourceIds));
+    stopwatch.stop();
+    if (options.getGcsPerformanceMetrics()) {
+      numCopies.inc(srcResourceIds.size());
+      copyTimeMsec.inc(stopwatch.elapsed(TimeUnit.MILLISECONDS));
+    }
   }
 
   @Override
diff --git a/sdks/java/io/file-based-io-tests/build.gradle b/sdks/java/io/file-based-io-tests/build.gradle
index c22b6c8da31..8b271a7c3f5 100644
--- a/sdks/java/io/file-based-io-tests/build.gradle
+++ b/sdks/java/io/file-based-io-tests/build.gradle
@@ -29,6 +29,7 @@ dependencies {
   shadowTest project(path: ":beam-sdks-java-io-common", configuration: "shadowTest")
   shadowTest project(path: ":beam-sdks-java-io-xml", configuration: "shadowTest")
   shadowTest project(path: ":beam-sdks-java-io-parquet", configuration: "shadowTest")
+  shadowTest project(path: ":beam-sdks-java-test-utils", configuration: "shadowTest")
   shadowTest library.java.guava
   shadowTest library.java.junit
   shadowTest library.java.hamcrest_core
diff --git a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/common/FileBasedIOTestPipelineOptions.java b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/common/FileBasedIOTestPipelineOptions.java
index f78ab6fd6c3..153d848e0a2 100644
--- a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/common/FileBasedIOTestPipelineOptions.java
+++ b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/common/FileBasedIOTestPipelineOptions.java
@@ -17,6 +17,7 @@
  */
 package org.apache.beam.sdk.io.common;
 
+import javax.annotation.Nullable;
 import org.apache.beam.sdk.options.Default;
 import org.apache.beam.sdk.options.Description;
 import org.apache.beam.sdk.options.Validation;
@@ -35,4 +36,22 @@ public interface FileBasedIOTestPipelineOptions extends IOTestPipelineOptions {
   String getCompressionType();
 
   void setCompressionType(String compressionType);
+
+  @Description("Number of files this test will create during the write phase.")
+  @Nullable
+  Integer getNumberOfShards();
+
+  void setNumberOfShards(@Nullable Integer value);
+
+  @Description("BigQuery dataset to publish results to.")
+  @Nullable
+  String getBigQueryDataset();
+
+  void setBigQueryDataset(@Nullable String dataset);
+
+  @Description("BigQuery table to publish results to.")
+  @Nullable
+  String getBigQueryTable();
+
+  void setBigQueryTable(@Nullable String tableName);
 }
diff --git a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/text/TextIOIT.java b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/text/TextIOIT.java
index 7c11d0c5a33..d0d0e188cc7 100644
--- a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/text/TextIOIT.java
+++ b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/text/TextIOIT.java
@@ -22,6 +22,9 @@ import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.appendTimestampS
 import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.getExpectedHashForLineCount;
 import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.readFileBasedIOITPipelineOptions;
 
+import com.google.cloud.Timestamp;
+import java.util.UUID;
+import org.apache.beam.sdk.PipelineResult;
 import org.apache.beam.sdk.io.Compression;
 import org.apache.beam.sdk.io.GenerateSequence;
 import org.apache.beam.sdk.io.TextIO;
@@ -31,6 +34,9 @@ import org.apache.beam.sdk.io.common.FileBasedIOTestPipelineOptions;
 import org.apache.beam.sdk.io.common.HashingFn;
 import org.apache.beam.sdk.testing.PAssert;
 import org.apache.beam.sdk.testing.TestPipeline;
+import org.apache.beam.sdk.testutils.NamedTestResult;
+import org.apache.beam.sdk.testutils.metrics.MetricsReader;
+import org.apache.beam.sdk.testutils.publishing.BigQueryResultsPublisher;
 import org.apache.beam.sdk.transforms.Combine;
 import org.apache.beam.sdk.transforms.ParDo;
 import org.apache.beam.sdk.transforms.Values;
@@ -41,6 +47,8 @@ import org.junit.Rule;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 /**
  * Integration tests for {@link org.apache.beam.sdk.io.TextIO}.
@@ -63,10 +71,14 @@ import org.junit.runners.JUnit4;
  */
 @RunWith(JUnit4.class)
 public class TextIOIT {
+  private static final Logger LOG = LoggerFactory.getLogger(TextIOIT.class);
 
   private static String filenamePrefix;
   private static Integer numberOfTextLines;
   private static Compression compressionType;
+  private static Integer numShards;
+  private static String bigQueryDataset;
+  private static String bigQueryTable;
 
   @Rule public TestPipeline pipeline = TestPipeline.create();
 
@@ -77,12 +89,40 @@ public class TextIOIT {
     numberOfTextLines = options.getNumberOfRecords();
     filenamePrefix = appendTimestampSuffix(options.getFilenamePrefix());
     compressionType = Compression.valueOf(options.getCompressionType());
+    numShards = options.getNumberOfShards();
+    bigQueryDataset = options.getBigQueryDataset();
+    bigQueryTable = options.getBigQueryTable();
+  }
+
+  private void publishGcsResults(PipelineResult result) {
+    MetricsReader metricsReader =
+        new MetricsReader(result, "org.apache.beam.sdk.extensions.gcp.storage.GcsFileSystem");
+    long numCopies = metricsReader.getCounterMetric("num_copies");
+    long copyTimeMsec = metricsReader.getCounterMetric("copy_time_msec");
+    if (numCopies < 0 || copyTimeMsec < 0) {
+      return;
+    }
+    double copiesPerSec = numCopies / (copyTimeMsec / 1e3);
+    LOG.info("GCS copies / sec: {}", copiesPerSec);
+
+    if (bigQueryDataset != null && bigQueryTable != null) {
+      Timestamp timestamp = Timestamp.now();
+      String uuid = UUID.randomUUID().toString();
+      BigQueryResultsPublisher publisher =
+          BigQueryResultsPublisher.create(bigQueryDataset, NamedTestResult.getSchema());
+      publisher.publish(
+          NamedTestResult.create(uuid, timestamp.toString(), "copies_per_sec", copiesPerSec),
+          bigQueryTable);
+    }
   }
 
   @Test
   public void writeThenReadAll() {
     TextIO.TypedWrite<String, Object> write =
         TextIO.write().to(filenamePrefix).withOutputFilenames().withCompression(compressionType);
+    if (numShards != null) {
+      write = write.withNumShards(numShards);
+    }
 
     PCollection<String> testFilenames =
         pipeline
@@ -107,6 +147,8 @@ public class TextIOIT {
         ParDo.of(new DeleteFileFn())
             .withSideInputs(consolidatedHashcode.apply(View.asSingleton())));
 
-    pipeline.run().waitUntilFinish();
+    PipelineResult result = pipeline.run();
+    result.waitUntilFinish();
+    publishGcsResults(result);
   }
 }
diff --git a/sdks/java/testing/test-utils/src/main/java/org/apache/beam/sdk/testutils/NamedTestResult.java b/sdks/java/testing/test-utils/src/main/java/org/apache/beam/sdk/testutils/NamedTestResult.java
new file mode 100644
index 00000000000..89e77269376
--- /dev/null
+++ b/sdks/java/testing/test-utils/src/main/java/org/apache/beam/sdk/testutils/NamedTestResult.java
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.beam.sdk.testutils;
+
+import com.google.cloud.bigquery.LegacySQLTypeName;
+import com.google.common.collect.ImmutableMap;
+import java.util.Map;
+
+/**
+ * Represents a schema and corresponding test result. Each test may have multiple named results
+ * published.
+ */
+public class NamedTestResult implements TestResult {
+
+  private final String testID;
+  private final String timestamp;
+  private final String metric;
+  private final double value;
+  private static final Map<String, String> schema =
+      ImmutableMap.<String, String>builder()
+          .put("test_id", LegacySQLTypeName.STRING.name())
+          .put("timestamp", LegacySQLTypeName.TIMESTAMP.name())
+          .put("metric", LegacySQLTypeName.STRING.name())
+          .put("value", LegacySQLTypeName.FLOAT.name())
+          .build();
+
+  private NamedTestResult(String testID, String timestamp, String metric, double value) {
+    this.testID = testID;
+    this.timestamp = timestamp;
+    this.metric = metric;
+    this.value = value;
+  }
+
+  /**
+   * Creates a NamedTestResult.
+   *
+   * @param testID Unique identifier for the test run this result belongs to.
+   * @param timestamp Time at which this result was sampled. Should be in a BigQuery supported
+   *     timestamp format.
+   * @param metric Name of this result's value.
+   * @param value The actual sampled value.
+   */
+  public static NamedTestResult create(
+      String testID, String timestamp, String metric, double value) {
+    return new NamedTestResult(testID, timestamp, metric, value);
+  }
+
+  @Override
+  public Map<String, Object> toMap() {
+    return ImmutableMap.<String, Object>builder()
+        .put("test_id", testID)
+        .put("timestamp", timestamp)
+        .put("metric", metric)
+        .put("value", value)
+        .build();
+  }
+
+  public static Map<String, String> getSchema() {
+    return schema;
+  }
+}
