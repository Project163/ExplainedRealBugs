diff --git a/sdks/python/apache_beam/transforms/stats.py b/sdks/python/apache_beam/transforms/stats.py
index ec86cb05c65..7a541acb899 100644
--- a/sdks/python/apache_beam/transforms/stats.py
+++ b/sdks/python/apache_beam/transforms/stats.py
@@ -15,15 +15,26 @@
 # limitations under the License.
 #
 
-"""This module has all statistic related transforms."""
+"""This module has all statistic related transforms.
+
+This ApproximateUnique class will be deprecated [1]. PLease look into using
+HLLCount in the zetasketch extension module [2].
+
+[1] https://lists.apache.org/thread.html/501605df5027567099b81f18c080469661fb426
+4a002615fa1510502%40%3Cdev.beam.apache.org%3E
+[2] https://beam.apache.org/releases/javadoc/2.16.0/org/apache/beam/sdk/extensio
+ns/zetasketch/HllCount.html
+"""
 
 # pytype: skip-file
 
 from __future__ import absolute_import
 from __future__ import division
 
+import hashlib
 import heapq
 import itertools
+import logging
 import math
 import sys
 import typing
@@ -46,6 +57,31 @@ K = typing.TypeVar('K')
 V = typing.TypeVar('V')
 
 
+def _get_default_hash_fn():
+  """Returns either murmurhash or md5 based on installation."""
+  try:
+    import mmh3  # pylint: disable=import-error
+
+    def _mmh3_hash(value):
+      # mmh3.hash64 returns two 64-bit unsigned integers
+      return mmh3.hash64(value, seed=0, signed=False)[0]
+
+    return _mmh3_hash
+
+  except ImportError:
+    logging.warning(
+        'Couldn\'t find murmurhash. Install mmh3 for a faster implementation of'
+        'ApproximateUnique.')
+
+    def _md5_hash(value):
+      # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32
+      # hexadecimal digits) to 16 digits and convert to int to get the 64-bit
+      # integer fingerprint.
+      return int(hashlib.md5(value).hexdigest()[:16], 16)
+
+    return _md5_hash
+
+
 class ApproximateUnique(object):
   """
   Hashes input elements and uses those to extrapolate the size of the entire
@@ -137,11 +173,12 @@ class _LargestUnique(object):
   An object to keep samples and calculate sample hash space. It is an
   accumulator of a combine function.
   """
-  _HASH_SPACE_SIZE = 2.0 * sys.maxsize
+  # We use unsigned 64-bit integer hashes.
+  _HASH_SPACE_SIZE = 2.0**64
 
   def __init__(self, sample_size):
     self._sample_size = sample_size
-    self._min_hash = sys.maxsize
+    self._min_hash = 2.0**64
     self._sample_heap = []
     self._sample_set = set()
 
@@ -166,7 +203,6 @@ class _LargestUnique(object):
         self._min_hash = self._sample_heap[0]
       elif element < self._min_hash:
         self._min_hash = element
-
     return True
 
   def get_estimate(self):
@@ -188,16 +224,14 @@ class _LargestUnique(object):
     est = log1p(-sample_size/sample_space) / log1p(-1/sample_space)
       * hash_space / sample_space
     """
-
     if len(self._sample_heap) < self._sample_size:
       return len(self._sample_heap)
     else:
-      sample_space_size = sys.maxsize - 1.0 * self._min_hash
+      sample_space_size = self._HASH_SPACE_SIZE - 1.0 * self._min_hash
       est = (
           math.log1p(-self._sample_size / sample_space_size) /
           math.log1p(-1 / sample_space_size) * self._HASH_SPACE_SIZE /
           sample_space_size)
-
       return round(est)
 
 
@@ -208,17 +242,22 @@ class ApproximateUniqueCombineFn(CombineFn):
   """
   def __init__(self, sample_size, coder):
     self._sample_size = sample_size
+    coder = coders.typecoders.registry.verify_deterministic(
+        coder, 'ApproximateUniqueCombineFn')
+
     self._coder = coder
+    self._hash_fn = _get_default_hash_fn()
 
   def create_accumulator(self, *args, **kwargs):
     return _LargestUnique(self._sample_size)
 
   def add_input(self, accumulator, element, *args, **kwargs):
     try:
-      accumulator.add(hash(self._coder.encode(element)))
+      hashed_value = self._hash_fn(self._coder.encode(element))
+      accumulator.add(hashed_value)
       return accumulator
     except Exception as e:
-      raise RuntimeError("Runtime exception: %s", e)
+      raise RuntimeError("Runtime exception: %s" % e)
 
   # created an issue https://issues.apache.org/jira/browse/BEAM-7285 to speed up
   # merge process.
diff --git a/sdks/python/apache_beam/transforms/stats_test.py b/sdks/python/apache_beam/transforms/stats_test.py
index 57870a5c1c0..860594f7fd4 100644
--- a/sdks/python/apache_beam/transforms/stats_test.py
+++ b/sdks/python/apache_beam/transforms/stats_test.py
@@ -23,16 +23,17 @@ from __future__ import division
 
 import math
 import random
+import sys
 import unittest
 from builtins import range
 from collections import defaultdict
 
 import hamcrest as hc
 from parameterized import parameterized
-from tenacity import retry
-from tenacity import stop_after_attempt
+from parameterized import parameterized_class
 
 import apache_beam as beam
+from apache_beam.coders import coders
 from apache_beam.testing.test_pipeline import TestPipeline
 from apache_beam.testing.util import BeamAssertException
 from apache_beam.testing.util import assert_that
@@ -41,355 +42,88 @@ from apache_beam.transforms.core import Create
 from apache_beam.transforms.display import DisplayData
 from apache_beam.transforms.display_test import DisplayDataItemMatcher
 from apache_beam.transforms.stats import ApproximateQuantilesCombineFn
+from apache_beam.transforms.stats import ApproximateUniqueCombineFn
 
+try:
+  import mmh3
+  mmh3_options = [(mmh3, ), (None, )]
+except ImportError:
+  mmh3_options = [(None, )]
 
-class ApproximateUniqueTest(unittest.TestCase):
-  """Unit tests for ApproximateUnique.Globally and ApproximateUnique.PerKey.
-  Hash() with Python3 is nondeterministic, so Approximation algorithm generates
-  different result each time and sometimes error rate is out of range, so add
-  retries for all tests who actually running approximation algorithm."""
-  def test_approximate_unique_global_by_invalid_size(self):
-    # test if the transformation throws an error as expected with an invalid
-    # small input size (< 16).
-    sample_size = 10
-    test_input = [random.randint(0, 1000) for _ in range(100)]
-
-    with self.assertRaises(ValueError) as e:
-      with TestPipeline() as pipeline:
-        _ = (
-            pipeline
-            | 'create' >> beam.Create(test_input)
-            |
-            'get_estimate' >> beam.ApproximateUnique.Globally(size=sample_size))
-
-    expected_msg = beam.ApproximateUnique._INPUT_SIZE_ERR_MSG % (sample_size)
-
-    assert e.exception.args[0] == expected_msg
-
-  def test_approximate_unique_global_by_invalid_type_size(self):
-    # test if the transformation throws an error as expected with an invalid
-    # type of input size (not int).
-    sample_size = 100.0
-    test_input = [random.randint(0, 1000) for _ in range(100)]
-
-    with self.assertRaises(ValueError) as e:
-      with TestPipeline() as pipeline:
-        _ = (
-            pipeline
-            | 'create' >> beam.Create(test_input)
-            |
-            'get_estimate' >> beam.ApproximateUnique.Globally(size=sample_size))
-
-    expected_msg = beam.ApproximateUnique._INPUT_SIZE_ERR_MSG % (sample_size)
-
-    assert e.exception.args[0] == expected_msg
-
-  def test_approximate_unique_global_by_invalid_small_error(self):
-    # test if the transformation throws an error as expected with an invalid
-    # small input error (< 0.01).
-    est_err = 0.0
-    test_input = [random.randint(0, 1000) for _ in range(100)]
-
-    with self.assertRaises(ValueError) as e:
-      with TestPipeline() as pipeline:
-        _ = (
-            pipeline
-            | 'create' >> beam.Create(test_input)
-            | 'get_estimate' >> beam.ApproximateUnique.Globally(error=est_err))
-
-    expected_msg = beam.ApproximateUnique._INPUT_ERROR_ERR_MSG % (est_err)
-
-    assert e.exception.args[0] == expected_msg
-
-  def test_approximate_unique_global_by_invalid_big_error(self):
-    # test if the transformation throws an error as expected with an invalid
-    # big input error (> 0.50).
-    est_err = 0.6
-    test_input = [random.randint(0, 1000) for _ in range(100)]
-
-    with self.assertRaises(ValueError) as e:
-      with TestPipeline() as pipeline:
-        _ = (
-            pipeline
-            | 'create' >> beam.Create(test_input)
-            | 'get_estimate' >> beam.ApproximateUnique.Globally(error=est_err))
-
-    expected_msg = beam.ApproximateUnique._INPUT_ERROR_ERR_MSG % (est_err)
-
-    assert e.exception.args[0] == expected_msg
-
-  def test_approximate_unique_global_by_invalid_no_input(self):
-    # test if the transformation throws an error as expected with no input.
-    test_input = [random.randint(0, 1000) for _ in range(100)]
-
-    with self.assertRaises(ValueError) as e:
-      with TestPipeline() as pipeline:
-        _ = (
-            pipeline
-            | 'create' >> beam.Create(test_input)
-            | 'get_estimate' >> beam.ApproximateUnique.Globally())
-
-    expected_msg = beam.ApproximateUnique._NO_VALUE_ERR_MSG
-    assert e.exception.args[0] == expected_msg
-
-  def test_approximate_unique_global_by_invalid_both_input(self):
-    # test if the transformation throws an error as expected with multi input.
-    test_input = [random.randint(0, 1000) for _ in range(100)]
-    est_err = 0.2
-    sample_size = 30
-
-    with self.assertRaises(ValueError) as e:
-      with TestPipeline() as pipeline:
-        _ = (
-            pipeline
-            | 'create' >> beam.Create(test_input)
-            | 'get_estimate' >> beam.ApproximateUnique.Globally(
-                size=sample_size, error=est_err))
-
-    expected_msg = beam.ApproximateUnique._MULTI_VALUE_ERR_MSG % (
-        sample_size, est_err)
-
-    assert e.exception.args[0] == expected_msg
-
-  def test_get_sample_size_from_est_error(self):
-    # test if get correct sample size from input error.
-    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.5) == 16
-    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.4) == 25
-    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.2) == 100
-    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.1) == 400
-    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.05) == 1600
-    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.01) == 40000
-
-  @unittest.skip(
-      'Skip it because hash function is not good enough. '
-      'TODO: BEAM-7654')
-  def test_approximate_unique_global_by_sample_size(self):
-    # test if estimation error with a given sample size is not greater than
-    # expected max error.
-    sample_size = 16
-    max_err = 2 / math.sqrt(sample_size)
-    test_input = [
-        4,
-        34,
-        29,
-        46,
-        80,
-        66,
-        51,
-        81,
-        31,
-        9,
-        26,
-        36,
-        10,
-        41,
-        90,
-        35,
-        33,
-        19,
-        88,
-        86,
-        28,
-        93,
-        38,
-        76,
-        15,
-        87,
-        12,
-        39,
-        84,
-        13,
-        32,
-        49,
-        65,
-        100,
-        16,
-        27,
-        23,
-        30,
-        96,
-        54
-    ]
-
-    actual_count = len(set(test_input))
-
-    with TestPipeline() as pipeline:
-      result = (
-          pipeline
-          | 'create' >> beam.Create(test_input)
-          | 'get_estimate' >> beam.ApproximateUnique.Globally(size=sample_size)
-          | 'compare' >> beam.FlatMap(
-              lambda x: [abs(x - actual_count) * 1.0 / actual_count <= max_err])
-      )
-
-      assert_that(result, equal_to([True]), label='assert:global_by_size')
-
-  @retry(reraise=True, stop=stop_after_attempt(5))
-  def test_approximate_unique_global_by_sample_size_with_duplicates(self):
-    # test if estimation error with a given sample size is not greater than
-    # expected max error with duplicated input.
-    sample_size = 30
-    max_err = 2 / math.sqrt(sample_size)
-    test_input = [10] * 50 + [20] * 50
-    actual_count = len(set(test_input))
-
-    with TestPipeline() as pipeline:
-      result = (
-          pipeline
-          | 'create' >> beam.Create(test_input)
-          | 'get_estimate' >> beam.ApproximateUnique.Globally(size=sample_size)
-          | 'compare' >> beam.FlatMap(
-              lambda x: [abs(x - actual_count) * 1.0 / actual_count <= max_err])
-      )
-
-      assert_that(
-          result,
-          equal_to([True]),
-          label='assert:global_by_size_with_duplicates')
-
-  @retry(reraise=True, stop=stop_after_attempt(5))
-  def test_approximate_unique_global_by_sample_size_with_small_population(self):
-    # test if estimation is exactly same to actual value when sample size is
-    # not smaller than population size (sample size > 100% of population).
-    sample_size = 31
-    test_input = [
-        144,
-        160,
-        229,
-        923,
-        390,
-        756,
-        674,
-        769,
-        145,
-        888,
-        809,
-        159,
-        222,
-        101,
-        943,
-        901,
-        876,
-        194,
-        232,
-        631,
-        221,
-        829,
-        965,
-        729,
-        35,
-        33,
-        115,
-        894,
-        827,
-        364
-    ]
-    actual_count = len(set(test_input))
-
-    with TestPipeline() as pipeline:
-      result = (
-          pipeline
-          | 'create' >> beam.Create(test_input)
-          | 'get_estimate' >> beam.ApproximateUnique.Globally(size=sample_size))
 
-      assert_that(
-          result,
-          equal_to([actual_count]),
-          label='assert:global_by_sample_size_with_small_population')
-
-  @unittest.skip(
-      'Skip because hash function is not good enough. '
-      'TODO: BEAM-7654')
-  def test_approximate_unique_global_by_error(self):
-    # test if estimation error from input error is not greater than input error.
-    est_err = 0.3
-    test_input = [
-        291,
-        371,
-        271,
-        126,
-        762,
-        391,
-        222,
-        565,
-        428,
-        786,
-        801,
-        867,
-        337,
-        690,
-        261,
-        436,
-        311,
-        568,
-        946,
-        722,
-        973,
-        386,
-        506,
-        546,
-        991,
-        450,
-        226,
-        889,
-        514,
-        693
-    ]
+@parameterized_class(('mmh3_option', ), mmh3_options)
+class ApproximateUniqueTest(unittest.TestCase):
+  """Unit tests for ApproximateUnique.Globally and ApproximateUnique.PerKey."""
+  random.seed(0)
+
+  def setUp(self):
+    sys.modules['mmh3'] = self.mmh3_option
+
+  @parameterized.expand([
+      (
+          'small_population_by_size',
+          list(range(30)),
+          32,
+          None,
+          'assert:global_by_sample_size_with_small_population'),
+      (
+          'large_population_by_size',
+          list(range(100)),
+          16,
+          None,
+          'assert:global_by_sample_size_with_large_population'),
+      (
+          'with_duplicates_by_size', [10] * 50 + [20] * 50,
+          30,
+          None,
+          'assert:global_by_sample_size_with_duplicates'),
+      (
+          'small_population_by_error',
+          list(range(30)),
+          None,
+          0.3,
+          'assert:global_by_error_with_small_population'),
+      (
+          'large_population_by_error',
+          [random.randint(1, 1000) for _ in range(500)],
+          None,
+          0.1,
+          'assert:global_by_error_with_large_population'),
+  ])
+  def test_approximate_unique_global(
+      self, name, test_input, sample_size, est_error, label):
+    # check that only either sample_size or est_error is not None
+    assert bool(sample_size) != bool(est_error)
+    if sample_size:
+      error = 2 / math.sqrt(sample_size)
+    else:
+      error = est_error
+    random.shuffle(test_input)
     actual_count = len(set(test_input))
 
     with TestPipeline() as pipeline:
       result = (
           pipeline
           | 'create' >> beam.Create(test_input)
-          | 'get_estimate' >> beam.ApproximateUnique.Globally(error=est_err)
+          | 'get_estimate' >> beam.ApproximateUnique.Globally(
+              size=sample_size, error=est_error)
           | 'compare' >> beam.FlatMap(
-              lambda x: [abs(x - actual_count) * 1.0 / actual_count <= est_err])
-      )
-
-      assert_that(result, equal_to([True]), label='assert:global_by_error')
-
-  @retry(reraise=True, stop=stop_after_attempt(5))
-  def test_approximate_unique_global_by_error_with_small_population(self):
-    # test if estimation error from input error of a small dataset is not
-    # greater than input error. Sample size is always not smaller than 16, so
-    # when population size is smaller than 16, estimation should be exactly
-    # same to actual value.
-    est_err = 0.01
-    test_input = [
-        585,
-        104,
-        613,
-        503,
-        658,
-        640,
-        118,
-        492,
-        189,
-        798,
-        756,
-        755,
-        839,
-        79,
-        393
-    ]
-    actual_count = len(set(test_input))
+              lambda x: [abs(x - actual_count) * 1.0 / actual_count <= error]))
+
+      assert_that(result, equal_to([True]), label=label)
+
+  @parameterized.expand([
+      ('by_size', 20, None, 'assert:unique_perkey_by_sample_size'),
+      ('by_error', None, 0.02, 'assert:unique_perkey_by_error')
+  ])
+  def test_approximate_unique_perkey(self, name, sample_size, est_error, label):
+    # check that only either sample_size or est_error is set
+    assert bool(sample_size) != bool(est_error)
+    if sample_size:
+      error = 2 / math.sqrt(sample_size)
+    else:
+      error = est_error
 
-    with TestPipeline() as pipeline:
-      result = (
-          pipeline
-          | 'create' >> beam.Create(test_input)
-          | 'get_estimate' >> beam.ApproximateUnique.Globally(error=est_err))
-
-      assert_that(
-          result,
-          equal_to([actual_count]),
-          label='assert:global_by_error_with_small_population')
-
-  @retry(reraise=True, stop=stop_after_attempt(5))
-  def test_approximate_unique_perkey_by_size(self):
-    # test if est error per key from sample size is in a expected range.
-    sample_size = 20
-    max_err = 2 / math.sqrt(sample_size)
     test_input = [(8, 73), (6, 724), (7, 70), (1, 576), (10, 120), (2, 662),
                   (7, 115), (3, 731), (6, 340), (6, 623), (1, 74), (9, 280),
                   (8, 298), (6, 440), (10, 243), (1, 125), (9, 754), (8, 833),
@@ -405,96 +139,98 @@ class ApproximateUniqueTest(unittest.TestCase):
       result = (
           pipeline
           | 'create' >> beam.Create(test_input)
-          | 'get_estimate' >> beam.ApproximateUnique.PerKey(size=sample_size)
+          | 'get_estimate' >> beam.ApproximateUnique.PerKey(
+              size=sample_size, error=est_error)
           | 'compare' >> beam.FlatMap(
               lambda x: [
                   abs(x[1] - len(actual_count_dict[x[0]])) * 1.0 / len(
-                      actual_count_dict[x[0]]) <= max_err
+                      actual_count_dict[x[0]]) <= error
               ]))
 
       assert_that(
-          result,
-          equal_to([True] * len(actual_count_dict)),
-          label='assert:perkey_by_size')
-
-  @retry(reraise=True, stop=stop_after_attempt(5))
-  def test_approximate_unique_perkey_by_error(self):
-    # test if estimation error per key from input err is in the expected range.
-    est_err = 0.01
-    test_input = [(9, 6), (5, 5), (6, 9), (2, 4), (8, 3), (9, 0), (6, 10),
-                  (8, 8), (9, 7), (2, 0), (9, 2), (1, 3), (4, 0), (7, 6),
-                  (10, 6), (4, 7), (5, 8), (7, 2), (7, 10), (5, 10)]
-    actual_count_dict = defaultdict(set)
-    for (x, y) in test_input:
-      actual_count_dict[x].add(y)
+          result, equal_to([True] * len(actual_count_dict)), label=label)
+
+  @parameterized.expand([
+      (
+          'invalid_input_size',
+          list(range(30)),
+          10,
+          None,
+          beam.ApproximateUnique._INPUT_SIZE_ERR_MSG % 10),
+      (
+          'invalid_type_size',
+          list(range(30)),
+          100.0,
+          None,
+          beam.ApproximateUnique._INPUT_SIZE_ERR_MSG % 100.0),
+      (
+          'invalid_small_error',
+          list(range(30)),
+          None,
+          0.0,
+          beam.ApproximateUnique._INPUT_ERROR_ERR_MSG % 0.0),
+      (
+          'invalid_big_error',
+          list(range(30)),
+          None,
+          0.6,
+          beam.ApproximateUnique._INPUT_ERROR_ERR_MSG % 0.6),
+      (
+          'no_input',
+          list(range(30)),
+          None,
+          None,
+          beam.ApproximateUnique._NO_VALUE_ERR_MSG),
+      (
+          'both_input',
+          list(range(30)),
+          30,
+          0.2,
+          beam.ApproximateUnique._MULTI_VALUE_ERR_MSG % (30, 0.2)),
+  ])
+  def test_approximate_unique_global_value_error(
+      self, name, test_input, sample_size, est_error, expected_msg):
+    with self.assertRaises(ValueError) as e:
+      with TestPipeline() as pipeline:
+        _ = (
+            pipeline
+            | 'create' >> beam.Create(test_input)
+            | 'get_estimate' >> beam.ApproximateUnique.Globally(
+                size=sample_size, error=est_error))
 
-    with TestPipeline() as pipeline:
-      result = (
-          pipeline
-          | 'create' >> beam.Create(test_input)
-          | 'get_estimate' >> beam.ApproximateUnique.PerKey(error=est_err)
-          | 'compare' >> beam.FlatMap(
-              lambda x: [
-                  abs(x[1] - len(actual_count_dict[x[0]])) * 1.0 / len(
-                      actual_count_dict[x[0]]) <= est_err
-              ]))
+    assert e.exception.args[0] == expected_msg
 
-      assert_that(
-          result,
-          equal_to([True] * len(actual_count_dict)),
-          label='assert:perkey_by_error')
-
-  @retry(reraise=True, stop=stop_after_attempt(5))
-  def test_approximate_unique_globally_by_error_with_skewed_data(self):
-    # test if estimation error is within the expected range with skewed data.
-    est_err = 0.01
-    test_input = [
-        19,
-        21,
-        32,
-        29,
-        5,
-        31,
-        52,
-        50,
-        59,
-        80,
-        7,
-        3,
-        34,
-        19,
-        13,
-        6,
-        55,
-        1,
-        13,
-        90,
-        4,
-        18,
-        52,
-        33,
-        0,
-        77,
-        21,
-        26,
-        5,
-        18
-    ]
-    actual_count = len(set(test_input))
+  def test_approximate_unique_combine_fn_requires_nondeterministic_coder(self):
+    sample_size = 30
+    coder = coders.Base64PickleCoder()
 
-    with TestPipeline() as pipeline:
-      result = (
-          pipeline
-          | 'create' >> beam.Create(test_input)
-          | 'get_estimate' >> beam.ApproximateUnique.Globally(error=est_err)
-          | 'compare' >> beam.FlatMap(
-              lambda x: [abs(x - actual_count) * 1.0 / actual_count <= est_err])
-      )
+    with self.assertRaises(ValueError) as e:
+      _ = ApproximateUniqueCombineFn(sample_size, coder)
 
-      assert_that(
-          result,
-          equal_to([True]),
-          label='assert:globally_by_error_with_skewed_data')
+    self.assertRegex(
+        e.exception.args[0],
+        'The key coder "Base64PickleCoder" '
+        'for ApproximateUniqueCombineFn is not deterministic.')
+
+  def test_approximate_unique_combine_fn_requires_compatible_coder(self):
+    test_input = 'a'
+    sample_size = 30
+    coder = coders.FloatCoder()
+    combine_fn = ApproximateUniqueCombineFn(sample_size, coder)
+    accumulator = combine_fn.create_accumulator()
+    with self.assertRaises(RuntimeError) as e:
+      accumulator = combine_fn.add_input(accumulator, test_input)
+
+    self.assertRegex(e.exception.args[0], 'Runtime exception')
+
+  def test_get_sample_size_from_est_error(self):
+    # test if get correct sample size from input error.
+    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.5) == 16
+    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.4) == 25
+    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.2) == 100
+    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.1) == 400
+    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.05) == 1600
+    assert beam.ApproximateUnique._get_sample_size_from_est_error(0.01) == 40000
 
 
 class ApproximateQuantilesTest(unittest.TestCase):
@@ -647,24 +383,24 @@ class ApproximateQuantilesTest(unittest.TestCase):
     with TestPipeline() as p:
       data = [389]
       pc = p | Create(data)
-      qunatiles = pc | beam.ApproximateQuantiles.Globally(5)
-      assert_that(qunatiles, equal_to([[389, 389, 389, 389, 389]]))
+      quantiles = pc | beam.ApproximateQuantiles.Globally(5)
+      assert_that(quantiles, equal_to([[389, 389, 389, 389, 389]]))
 
   def test_uneven_quantiles(self):
     with TestPipeline() as p:
       pc = p | Create(list(range(5000)))
-      qunatiles = pc | beam.ApproximateQuantiles.Globally(37)
-      aprox_quantiles = self._approx_quantile_generator(
+      quantiles = pc | beam.ApproximateQuantiles.Globally(37)
+      approx_quantiles = self._approx_quantile_generator(
           size=5000, num_of_quantiles=37, absoluteError=20)
-      assert_that(qunatiles, self._quantiles_matcher(aprox_quantiles))
+      assert_that(quantiles, self._quantiles_matcher(approx_quantiles))
 
   def test_large_quantiles(self):
     with TestPipeline() as p:
       pc = p | Create(list(range(10001)))
-      qunatiles = pc | beam.ApproximateQuantiles.Globally(50)
-      aprox_quantiles = self._approx_quantile_generator(
+      quantiles = pc | beam.ApproximateQuantiles.Globally(50)
+      approx_quantiles = self._approx_quantile_generator(
           size=10001, num_of_quantiles=50, absoluteError=20)
-      assert_that(qunatiles, self._quantiles_matcher(aprox_quantiles))
+      assert_that(quantiles, self._quantiles_matcher(approx_quantiles))
 
   def test_random_quantiles(self):
     with TestPipeline() as p:
diff --git a/sdks/python/container/base_image_requirements.txt b/sdks/python/container/base_image_requirements.txt
index 45ff2557260..c0bbf1a3210 100644
--- a/sdks/python/container/base_image_requirements.txt
+++ b/sdks/python/container/base_image_requirements.txt
@@ -57,6 +57,7 @@ google-cloud-datastore==1.7.4
 cython==0.29.13
 guppy==0.1.11;python_version<="2.7"
 guppy3==3.0.9;python_version>="3.5"
+mmh3==2.5.1
 
 # These are additional packages likely to be used by customers.
 numpy==1.16.5;python_version<="2.7"
diff --git a/sdks/python/container/license_scripts/dep_urls_py.yaml b/sdks/python/container/license_scripts/dep_urls_py.yaml
index 1fdb824bb6e..7b61c1a4993 100644
--- a/sdks/python/container/license_scripts/dep_urls_py.yaml
+++ b/sdks/python/container/license_scripts/dep_urls_py.yaml
@@ -77,6 +77,8 @@ pip_dependencies:
     license: "https://raw.githubusercontent.com/mtth/hdfs/master/LICENSE"
   httplib2:
     license: "https://raw.githubusercontent.com/httplib2/httplib2/master/LICENSE"
+  mmh3:
+    license: "https://raw.githubusercontent.com/hajimes/mmh3/master/LICENSE"
   mock:
     license: "https://raw.githubusercontent.com/testing-cabal/mock/master/LICENSE.txt"
   monotonic:
