diff --git a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryAvroUtils.java b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryAvroUtils.java
index 382705f119a..fb0e68eb20e 100644
--- a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryAvroUtils.java
+++ b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryAvroUtils.java
@@ -36,6 +36,8 @@ import java.time.LocalTime;
 import java.time.format.DateTimeFormatterBuilder;
 import java.util.ArrayList;
 import java.util.List;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
 import javax.annotation.Nullable;
 import org.apache.avro.Conversions;
 import org.apache.avro.LogicalType;
@@ -165,6 +167,41 @@ class BigQueryAvroUtils {
     return LocalTime.ofNanoOfDay(timeMicros * 1000).format(formatter);
   }
 
+  static TableSchema trimBigQueryTableSchema(TableSchema inputSchema, Schema avroSchema) {
+    List<TableFieldSchema> subSchemas =
+        inputSchema.getFields().stream()
+            .flatMap(fieldSchema -> mapTableFieldSchema(fieldSchema, avroSchema))
+            .collect(Collectors.toList());
+
+    return new TableSchema().setFields(subSchemas);
+  }
+
+  private static Stream<TableFieldSchema> mapTableFieldSchema(
+      TableFieldSchema fieldSchema, Schema avroSchema) {
+    Field avroFieldSchema = avroSchema.getField(fieldSchema.getName());
+    if (avroFieldSchema == null) {
+      return Stream.empty();
+    } else if (avroFieldSchema.schema().getType() != Type.RECORD) {
+      return Stream.of(fieldSchema);
+    }
+
+    List<TableFieldSchema> subSchemas =
+        fieldSchema.getFields().stream()
+            .flatMap(subSchema -> mapTableFieldSchema(subSchema, avroFieldSchema.schema()))
+            .collect(Collectors.toList());
+
+    TableFieldSchema output =
+        new TableFieldSchema()
+            .setCategories(fieldSchema.getCategories())
+            .setDescription(fieldSchema.getDescription())
+            .setFields(subSchemas)
+            .setMode(fieldSchema.getMode())
+            .setName(fieldSchema.getName())
+            .setType(fieldSchema.getType());
+
+    return Stream.of(output);
+  }
+
   /**
    * Utility function to convert from an Avro {@link GenericRecord} to a BigQuery {@link TableRow}.
    *
diff --git a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryStorageSourceBase.java b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryStorageSourceBase.java
index 25d9f95c9d2..10ec6744917 100644
--- a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryStorageSourceBase.java
+++ b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryStorageSourceBase.java
@@ -21,6 +21,7 @@ import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Prec
 import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;
 
 import com.google.api.services.bigquery.model.Table;
+import com.google.api.services.bigquery.model.TableSchema;
 import com.google.cloud.bigquery.storage.v1beta1.ReadOptions.TableReadOptions;
 import com.google.cloud.bigquery.storage.v1beta1.Storage.CreateReadSessionRequest;
 import com.google.cloud.bigquery.storage.v1beta1.Storage.ReadSession;
@@ -29,6 +30,7 @@ import com.google.cloud.bigquery.storage.v1beta1.Storage.Stream;
 import java.io.IOException;
 import java.util.List;
 import javax.annotation.Nullable;
+import org.apache.avro.Schema;
 import org.apache.beam.sdk.annotations.Experimental;
 import org.apache.beam.sdk.annotations.Experimental.Kind;
 import org.apache.beam.sdk.coders.Coder;
@@ -149,11 +151,14 @@ abstract class BigQueryStorageSourceBase<T> extends BoundedSource<T> {
       return ImmutableList.of();
     }
 
+    Schema sessionSchema = new Schema.Parser().parse(readSession.getAvroSchema().getSchema());
+    TableSchema trimmedSchema =
+        BigQueryAvroUtils.trimBigQueryTableSchema(targetTable.getSchema(), sessionSchema);
     List<BigQueryStorageStreamSource<T>> sources = Lists.newArrayList();
     for (Stream stream : readSession.getStreamsList()) {
       sources.add(
           BigQueryStorageStreamSource.create(
-              readSession, stream, targetTable.getSchema(), parseFn, outputCoder, bqServices));
+              readSession, stream, trimmedSchema, parseFn, outputCoder, bqServices));
     }
 
     return ImmutableList.copyOf(sources);
diff --git a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryStorageTableSource.java b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryStorageTableSource.java
index ecd42cfd340..0e79a29b470 100644
--- a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryStorageTableSource.java
+++ b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryStorageTableSource.java
@@ -115,20 +115,10 @@ public class BigQueryStorageTableSource<T> extends BigQueryStorageSourceBase<T>
             BigQueryOptions.class.getSimpleName());
         tableReference.setProjectId(options.getProject());
       }
-      Table table =
-          bqServices.getDatasetService(options).getTable(tableReference, getSelectedFields());
+      Table table = bqServices.getDatasetService(options).getTable(tableReference);
       cachedTable.compareAndSet(null, table);
     }
 
     return cachedTable.get();
   }
-
-  private List<String> getSelectedFields() {
-    if (selectedFieldsProvider != null) {
-      return selectedFieldsProvider.get();
-    } else if (tableReadOptions != null && !tableReadOptions.getSelectedFieldsList().isEmpty()) {
-      return tableReadOptions.getSelectedFieldsList();
-    }
-    return null;
-  }
 }
diff --git a/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOStorageQueryTest.java b/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOStorageQueryTest.java
index a96abad675d..1b5584334ac 100644
--- a/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOStorageQueryTest.java
+++ b/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOStorageQueryTest.java
@@ -56,6 +56,7 @@ import java.util.List;
 import java.util.Optional;
 import java.util.Set;
 import org.apache.avro.Schema;
+import org.apache.avro.SchemaBuilder;
 import org.apache.avro.generic.GenericData.Record;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.apache.avro.generic.GenericRecord;
@@ -394,7 +395,24 @@ public class BigQueryIOStorageQueryTest {
             .setShardingStrategy(ShardingStrategy.BALANCED)
             .build();
 
-    ReadSession.Builder builder = ReadSession.newBuilder();
+    Schema sessionSchema =
+        SchemaBuilder.record("__root__")
+            .fields()
+            .name("name")
+            .type()
+            .nullable()
+            .stringType()
+            .noDefault()
+            .name("number")
+            .type()
+            .nullable()
+            .longType()
+            .noDefault()
+            .endRecord();
+
+    ReadSession.Builder builder =
+        ReadSession.newBuilder()
+            .setAvroSchema(AvroSchema.newBuilder().setSchema(sessionSchema.toString()));
     for (int i = 0; i < expectedStreamCount; i++) {
       builder.addStreams(Stream.newBuilder().setName("stream-" + i));
     }
@@ -468,7 +486,24 @@ public class BigQueryIOStorageQueryTest {
             .setShardingStrategy(ShardingStrategy.BALANCED)
             .build();
 
-    ReadSession.Builder builder = ReadSession.newBuilder();
+    Schema sessionSchema =
+        SchemaBuilder.record("__root__")
+            .fields()
+            .name("name")
+            .type()
+            .nullable()
+            .stringType()
+            .noDefault()
+            .name("number")
+            .type()
+            .nullable()
+            .longType()
+            .noDefault()
+            .endRecord();
+
+    ReadSession.Builder builder =
+        ReadSession.newBuilder()
+            .setAvroSchema(AvroSchema.newBuilder().setSchema(sessionSchema.toString()));
     for (int i = 0; i < 1024; i++) {
       builder.addStreams(Stream.newBuilder().setName("stream-" + i));
     }
@@ -502,8 +537,8 @@ public class BigQueryIOStorageQueryTest {
           + " \"type\": \"record\",\n"
           + " \"name\": \"RowRecord\",\n"
           + " \"fields\": [\n"
-          + "     {\"name\": \"name\", \"type\": \"string\"},\n"
-          + "     {\"name\": \"number\", \"type\": \"long\"}\n"
+          + "     {\"name\": \"name\", \"type\": [\"null\", \"string\"]},\n"
+          + "     {\"name\": \"number\", \"type\": [\"null\", \"long\"]}\n"
           + " ]\n"
           + "}";
 
@@ -513,8 +548,8 @@ public class BigQueryIOStorageQueryTest {
       new TableSchema()
           .setFields(
               ImmutableList.of(
-                  new TableFieldSchema().setName("name").setType("STRING").setMode("REQUIRED"),
-                  new TableFieldSchema().setName("number").setType("INTEGER").setMode("REQUIRED")));
+                  new TableFieldSchema().setName("name").setType("STRING"),
+                  new TableFieldSchema().setName("number").setType("INTEGER")));
 
   private static GenericRecord createRecord(String name, long number, Schema schema) {
     GenericRecord genericRecord = new Record(schema);
@@ -570,15 +605,7 @@ public class BigQueryIOStorageQueryTest {
     fakeDatasetService.createTable(
         new Table().setTableReference(sourceTableRef).setLocation("asia-northeast1"));
 
-    Table queryResultTable =
-        new Table()
-            .setSchema(
-                new TableSchema()
-                    .setFields(
-                        ImmutableList.of(
-                            new TableFieldSchema().setName("name").setType("STRING"),
-                            new TableFieldSchema().setName("number").setType("INTEGER"))))
-            .setNumBytes(0L);
+    Table queryResultTable = new Table().setSchema(TABLE_SCHEMA).setNumBytes(0L);
 
     String encodedQuery = FakeBigQueryServices.encodeQueryResult(queryResultTable);
 
@@ -677,15 +704,7 @@ public class BigQueryIOStorageQueryTest {
     fakeDatasetService.createTable(
         new Table().setTableReference(sourceTableRef).setLocation("asia-northeast1"));
 
-    Table queryResultTable =
-        new Table()
-            .setSchema(
-                new TableSchema()
-                    .setFields(
-                        ImmutableList.of(
-                            new TableFieldSchema().setName("name").setType("STRING"),
-                            new TableFieldSchema().setName("number").setType("INTEGER"))))
-            .setNumBytes(0L);
+    Table queryResultTable = new Table().setSchema(TABLE_SCHEMA).setNumBytes(0L);
 
     String encodedQuery = FakeBigQueryServices.encodeQueryResult(queryResultTable);
 
diff --git a/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOStorageReadTest.java b/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOStorageReadTest.java
index 8a0f4486de7..118d994f566 100644
--- a/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOStorageReadTest.java
+++ b/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIOStorageReadTest.java
@@ -400,15 +400,43 @@ public class BigQueryIOStorageReadTest {
     doTableSourceInitialSplitTest(10L, 10_000);
   }
 
+  private static final String AVRO_SCHEMA_STRING =
+      "{\"namespace\": \"example.avro\",\n"
+          + " \"type\": \"record\",\n"
+          + " \"name\": \"RowRecord\",\n"
+          + " \"fields\": [\n"
+          + "     {\"name\": \"name\", \"type\": \"string\"},\n"
+          + "     {\"name\": \"number\", \"type\": \"long\"}\n"
+          + " ]\n"
+          + "}";
+
+  private static final Schema AVRO_SCHEMA = new Schema.Parser().parse(AVRO_SCHEMA_STRING);
+
+  private static final String TRIMMED_AVRO_SCHEMA_STRING =
+      "{\"namespace\": \"example.avro\",\n"
+          + "\"type\": \"record\",\n"
+          + "\"name\": \"RowRecord\",\n"
+          + "\"fields\": [\n"
+          + "    {\"name\": \"name\", \"type\": \"string\"}\n"
+          + " ]\n"
+          + "}";
+
+  private static final Schema TRIMMED_AVRO_SCHEMA =
+      new Schema.Parser().parse(TRIMMED_AVRO_SCHEMA_STRING);
+
+  private static final TableSchema TABLE_SCHEMA =
+      new TableSchema()
+          .setFields(
+              ImmutableList.of(
+                  new TableFieldSchema().setName("name").setType("STRING").setMode("REQUIRED"),
+                  new TableFieldSchema().setName("number").setType("INTEGER").setMode("REQUIRED")));
+
   private void doTableSourceInitialSplitTest(long bundleSize, int streamCount) throws Exception {
     fakeDatasetService.createDataset("foo.com:project", "dataset", "", "", null);
     TableReference tableRef = BigQueryHelpers.parseTableSpec("foo.com:project:dataset.table");
 
     Table table =
-        new Table()
-            .setTableReference(tableRef)
-            .setNumBytes(1024L * 1024L)
-            .setSchema(new TableSchema());
+        new Table().setTableReference(tableRef).setNumBytes(1024L * 1024L).setSchema(TABLE_SCHEMA);
 
     fakeDatasetService.createTable(table);
 
@@ -420,7 +448,9 @@ public class BigQueryIOStorageReadTest {
             .setShardingStrategy(ShardingStrategy.BALANCED)
             .build();
 
-    ReadSession.Builder builder = ReadSession.newBuilder();
+    ReadSession.Builder builder =
+        ReadSession.newBuilder()
+            .setAvroSchema(AvroSchema.newBuilder().setSchema(AVRO_SCHEMA_STRING));
     for (int i = 0; i < streamCount; i++) {
       builder.addStreams(Stream.newBuilder().setName("stream-" + i));
     }
@@ -449,23 +479,13 @@ public class BigQueryIOStorageReadTest {
     fakeDatasetService.createDataset("foo.com:project", "dataset", "", "", null);
     TableReference tableRef = BigQueryHelpers.parseTableSpec("foo.com:project:dataset.table");
 
-    Table table =
-        new Table()
-            .setTableReference(tableRef)
-            .setNumBytes(100L)
-            .setSchema(
-                new TableSchema()
-                    .setFields(
-                        ImmutableList.of(
-                            new TableFieldSchema().setName("name").setType("STRING"),
-                            new TableFieldSchema().setName("number").setType("INTEGER"))));
+    Table table = new Table().setTableReference(tableRef).setNumBytes(100L).setSchema(TABLE_SCHEMA);
 
     fakeDatasetService.createTable(table);
 
     TableReadOptions readOptions =
         TableReadOptions.newBuilder()
             .addSelectedFields("name")
-            .addSelectedFields("number")
             .setRowRestriction("number > 5")
             .build();
 
@@ -478,7 +498,9 @@ public class BigQueryIOStorageReadTest {
             .setShardingStrategy(ShardingStrategy.BALANCED)
             .build();
 
-    ReadSession.Builder builder = ReadSession.newBuilder();
+    ReadSession.Builder builder =
+        ReadSession.newBuilder()
+            .setAvroSchema(AvroSchema.newBuilder().setSchema(TRIMMED_AVRO_SCHEMA_STRING));
     for (int i = 0; i < 10; i++) {
       builder.addStreams(Stream.newBuilder().setName("stream-" + i));
     }
@@ -507,23 +529,13 @@ public class BigQueryIOStorageReadTest {
     fakeDatasetService.createDataset("foo.com:project", "dataset", "", "", null);
     TableReference tableRef = BigQueryHelpers.parseTableSpec("foo.com:project:dataset.table");
 
-    Table table =
-        new Table()
-            .setTableReference(tableRef)
-            .setNumBytes(100L)
-            .setSchema(
-                new TableSchema()
-                    .setFields(
-                        ImmutableList.of(
-                            new TableFieldSchema().setName("name").setType("STRING"),
-                            new TableFieldSchema().setName("number").setType("INTEGER"))));
+    Table table = new Table().setTableReference(tableRef).setNumBytes(100L).setSchema(TABLE_SCHEMA);
 
     fakeDatasetService.createTable(table);
 
     TableReadOptions readOptions =
         TableReadOptions.newBuilder()
             .addSelectedFields("name")
-            .addSelectedFields("number")
             .setRowRestriction("number > 5")
             .build();
 
@@ -536,7 +548,9 @@ public class BigQueryIOStorageReadTest {
             .setShardingStrategy(ShardingStrategy.BALANCED)
             .build();
 
-    ReadSession.Builder builder = ReadSession.newBuilder();
+    ReadSession.Builder builder =
+        ReadSession.newBuilder()
+            .setAvroSchema(AvroSchema.newBuilder().setSchema(TRIMMED_AVRO_SCHEMA_STRING));
     for (int i = 0; i < 10; i++) {
       builder.addStreams(Stream.newBuilder().setName("stream-" + i));
     }
@@ -548,7 +562,7 @@ public class BigQueryIOStorageReadTest {
         BigQueryStorageTableSource.create(
             ValueProvider.StaticValueProvider.of(tableRef),
             null,
-            StaticValueProvider.of(Lists.newArrayList("name", "number")),
+            StaticValueProvider.of(Lists.newArrayList("name")),
             StaticValueProvider.of("number > 5"),
             new TableRowParser(),
             TableRowJsonCoder.of(),
@@ -566,10 +580,7 @@ public class BigQueryIOStorageReadTest {
     TableReference tableRef = BigQueryHelpers.parseTableSpec("project-id:dataset.table");
 
     Table table =
-        new Table()
-            .setTableReference(tableRef)
-            .setNumBytes(1024L * 1024L)
-            .setSchema(new TableSchema());
+        new Table().setTableReference(tableRef).setNumBytes(1024L * 1024L).setSchema(TABLE_SCHEMA);
 
     fakeDatasetService.createTable(table);
 
@@ -581,7 +592,9 @@ public class BigQueryIOStorageReadTest {
             .setShardingStrategy(ShardingStrategy.BALANCED)
             .build();
 
-    ReadSession.Builder builder = ReadSession.newBuilder();
+    ReadSession.Builder builder =
+        ReadSession.newBuilder()
+            .setAvroSchema(AvroSchema.newBuilder().setSchema(AVRO_SCHEMA_STRING));
     for (int i = 0; i < 50; i++) {
       builder.addStreams(Stream.newBuilder().setName("stream-" + i));
     }
@@ -664,24 +677,11 @@ public class BigQueryIOStorageReadTest {
     tableSource.createReader(options);
   }
 
-  private static final String AVRO_SCHEMA_STRING =
-      "{\"namespace\": \"example.avro\",\n"
-          + " \"type\": \"record\",\n"
-          + " \"name\": \"RowRecord\",\n"
-          + " \"fields\": [\n"
-          + "     {\"name\": \"name\", \"type\": \"string\"},\n"
-          + "     {\"name\": \"number\", \"type\": \"long\"}\n"
-          + " ]\n"
-          + "}";
-
-  private static final Schema AVRO_SCHEMA = new Schema.Parser().parse(AVRO_SCHEMA_STRING);
-
-  private static final TableSchema TABLE_SCHEMA =
-      new TableSchema()
-          .setFields(
-              ImmutableList.of(
-                  new TableFieldSchema().setName("name").setType("STRING").setMode("REQUIRED"),
-                  new TableFieldSchema().setName("number").setType("INTEGER").setMode("REQUIRED")));
+  private static GenericRecord createRecord(String name, Schema schema) {
+    GenericRecord genericRecord = new Record(schema);
+    genericRecord.put("name", name);
+    return genericRecord;
+  }
 
   private static GenericRecord createRecord(String name, long number, Schema schema) {
     GenericRecord genericRecord = new Record(schema);
@@ -1368,10 +1368,7 @@ public class BigQueryIOStorageReadTest {
   public void testReadFromBigQueryIO() throws Exception {
     fakeDatasetService.createDataset("foo.com:project", "dataset", "", "", null);
     TableReference tableRef = BigQueryHelpers.parseTableSpec("foo.com:project:dataset.table");
-
-    Table table =
-        new Table().setTableReference(tableRef).setNumBytes(10L).setSchema(new TableSchema());
-
+    Table table = new Table().setTableReference(tableRef).setNumBytes(10L).setSchema(TABLE_SCHEMA);
     fakeDatasetService.createTable(table);
 
     CreateReadSessionRequest expectedCreateReadSessionRequest =
@@ -1379,8 +1376,6 @@ public class BigQueryIOStorageReadTest {
             .setParent("projects/project-id")
             .setTableReference(BigQueryHelpers.toTableRefProto(tableRef))
             .setRequestedStreams(10)
-            .setReadOptions(
-                TableReadOptions.newBuilder().addSelectedFields("name").addSelectedFields("number"))
             .setShardingStrategy(ShardingStrategy.BALANCED)
             .build();
 
@@ -1420,7 +1415,6 @@ public class BigQueryIOStorageReadTest {
             BigQueryIO.read(new ParseKeyValue())
                 .from("foo.com:project:dataset.table")
                 .withMethod(Method.DIRECT_READ)
-                .withSelectedFields(p.newProvider(Lists.newArrayList("name", "number")))
                 .withTestServices(
                     new FakeBigQueryServices()
                         .withDatasetService(fakeDatasetService)
@@ -1432,4 +1426,73 @@ public class BigQueryIOStorageReadTest {
 
     p.run();
   }
+
+  @Test
+  public void testReadFromBigQueryIOWithTrimmedSchema() throws Exception {
+    fakeDatasetService.createDataset("foo.com:project", "dataset", "", "", null);
+    TableReference tableRef = BigQueryHelpers.parseTableSpec("foo.com:project:dataset.table");
+    Table table = new Table().setTableReference(tableRef).setNumBytes(10L).setSchema(TABLE_SCHEMA);
+    fakeDatasetService.createTable(table);
+
+    CreateReadSessionRequest expectedCreateReadSessionRequest =
+        CreateReadSessionRequest.newBuilder()
+            .setParent("projects/project-id")
+            .setTableReference(BigQueryHelpers.toTableRefProto(tableRef))
+            .setRequestedStreams(10)
+            .setReadOptions(TableReadOptions.newBuilder().addSelectedFields("name"))
+            .setShardingStrategy(ShardingStrategy.BALANCED)
+            .build();
+
+    ReadSession readSession =
+        ReadSession.newBuilder()
+            .setName("readSessionName")
+            .setAvroSchema(AvroSchema.newBuilder().setSchema(TRIMMED_AVRO_SCHEMA_STRING))
+            .addStreams(Stream.newBuilder().setName("streamName"))
+            .build();
+
+    ReadRowsRequest expectedReadRowsRequest =
+        ReadRowsRequest.newBuilder()
+            .setReadPosition(
+                StreamPosition.newBuilder().setStream(Stream.newBuilder().setName("streamName")))
+            .build();
+
+    List<GenericRecord> records =
+        Lists.newArrayList(
+            createRecord("A", TRIMMED_AVRO_SCHEMA),
+            createRecord("B", TRIMMED_AVRO_SCHEMA),
+            createRecord("C", TRIMMED_AVRO_SCHEMA),
+            createRecord("D", TRIMMED_AVRO_SCHEMA));
+
+    List<ReadRowsResponse> readRowsResponses =
+        Lists.newArrayList(
+            createResponse(TRIMMED_AVRO_SCHEMA, records.subList(0, 2), 0.50),
+            createResponse(TRIMMED_AVRO_SCHEMA, records.subList(2, 4), 0.75));
+
+    StorageClient fakeStorageClient = mock(StorageClient.class, withSettings().serializable());
+    when(fakeStorageClient.createReadSession(expectedCreateReadSessionRequest))
+        .thenReturn(readSession);
+    when(fakeStorageClient.readRows(expectedReadRowsRequest))
+        .thenReturn(new FakeBigQueryServerStream<>(readRowsResponses));
+
+    PCollection<TableRow> output =
+        p.apply(
+            BigQueryIO.readTableRows()
+                .from("foo.com:project:dataset.table")
+                .withMethod(Method.DIRECT_READ)
+                .withSelectedFields(Lists.newArrayList("name"))
+                .withTestServices(
+                    new FakeBigQueryServices()
+                        .withDatasetService(fakeDatasetService)
+                        .withStorageClient(fakeStorageClient)));
+
+    PAssert.that(output)
+        .containsInAnyOrder(
+            ImmutableList.of(
+                new TableRow().set("name", "A"),
+                new TableRow().set("name", "B"),
+                new TableRow().set("name", "C"),
+                new TableRow().set("name", "D")));
+
+    p.run();
+  }
 }
