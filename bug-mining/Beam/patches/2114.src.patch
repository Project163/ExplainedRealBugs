diff --git a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py
index 2d6dd29aaeb..8f12779d67f 100644
--- a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py
+++ b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py
@@ -174,7 +174,7 @@ class Stage(object):
         union(self.must_follow, other.must_follow),
         environment=self._merge_environments(
             self.environment, other.environment),
-        parent=_lowest_common_ancestor(self.name, other.name, context),
+        parent=_parent_for_fused_stages([self.name, other.name], context),
         forced_root=self.forced_root or other.forced_root)
 
   def is_runner_urn(self, context):
@@ -492,6 +492,7 @@ class TransformContext(object):
         for child in transform.subtransforms
     }
 
+
 def leaf_transform_stages(
     root_ids,  # type: Iterable[str]
     components,  # type: beam_runner_api_pb2.Components
@@ -792,10 +793,7 @@ def eliminate_common_key_with_none(stages, context):
         only_element(stage.transforms[0].outputs.values())
         for stage in sibling_stages
     ]
-    parent = functools.reduce(
-        lambda a,
-        b: _lowest_common_ancestor(a, b, context),
-        [s.name for s in sibling_stages])
+    parent = _parent_for_fused_stages([s.name for s in sibling_stages], context)
     for to_delete_pcoll_id in output_pcoll_ids[1:]:
       pcoll_id_remap[to_delete_pcoll_id] = output_pcoll_ids[0]
       del context.components.pcollections[to_delete_pcoll_id]
@@ -1212,6 +1210,27 @@ def _lowest_common_ancestor(a, b, context):
   return None
 
 
+def _parent_for_fused_stages(stages, context):
+  # type: (Iterable[Optional[str]], TransformContext) -> Optional[str]
+
+  '''Returns the name of the new parent for the fused stages.
+
+  The new parent is the lowest common ancestor of the fused stages that is not
+  contained in the set of stages to be fused. The provided context is used to
+  compute ancestors of stages.
+  '''
+  def reduce_fn(a, b):
+    # type: (Optional[str], Optional[str]) -> Optional[str]
+    if a is None or b is None:
+      return None
+    return _lowest_common_ancestor(a, b, context)
+
+  result = functools.reduce(reduce_fn, stages)
+  if result in stages:
+    result = context.parents_map().get(result)
+  return result
+
+
 def expand_sdf(stages, context):
   # type: (Iterable[Stage], TransformContext) -> Iterator[Stage]
 
diff --git a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
index 4627c05c506..0ce11bda45c 100644
--- a/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
+++ b/sdks/python/apache_beam/runners/portability/fn_api_runner/translations_test.py
@@ -143,6 +143,45 @@ class TranslationsTest(unittest.TestCase):
     pipeline_proto = pipeline.to_runner_api()
     optimized_pipeline_proto = translations.optimize_pipeline(
         pipeline_proto, [], known_runner_urns=frozenset(), partial=True)
+    # Tests that Pipeline.from_runner_api() does not throw an exception.
+    runner = runners.DirectRunner()
+    beam.Pipeline.from_runner_api(
+        optimized_pipeline_proto, runner, pipeline_options.PipelineOptions())
+
+  def test_optimize_single_combine_globally(self):
+    pipeline = beam.Pipeline()
+    vals = [6, 3, 1, 1, 9, 1, 5, 2, 0, 6]
+    _ = pipeline | Create(vals) | combiners.Count.Globally()
+    pipeline_proto = pipeline.to_runner_api()
+    optimized_pipeline_proto = translations.optimize_pipeline(
+        pipeline_proto,
+        [
+            translations.eliminate_common_key_with_none,
+            translations.pack_combiners,
+        ],
+        known_runner_urns=frozenset(),
+        partial=True)
+    # Tests that Pipeline.from_runner_api() does not throw an exception.
+    runner = runners.DirectRunner()
+    beam.Pipeline.from_runner_api(
+        optimized_pipeline_proto, runner, pipeline_options.PipelineOptions())
+
+  def test_optimize_multiple_combine_globally(self):
+    pipeline = beam.Pipeline()
+    vals = [6, 3, 1, 1, 9, 1, 5, 2, 0, 6]
+    pcoll = pipeline | Create(vals)
+    _ = pcoll | 'mean-globally' >> combiners.Mean.Globally()
+    _ = pcoll | 'count-globally' >> combiners.Count.Globally()
+    pipeline_proto = pipeline.to_runner_api()
+    optimized_pipeline_proto = translations.optimize_pipeline(
+        pipeline_proto,
+        [
+            translations.eliminate_common_key_with_none,
+            translations.pack_combiners,
+        ],
+        known_runner_urns=frozenset(),
+        partial=True)
+    # Tests that Pipeline.from_runner_api() does not throw an exception.
     runner = runners.DirectRunner()
     beam.Pipeline.from_runner_api(
         optimized_pipeline_proto, runner, pipeline_options.PipelineOptions())
