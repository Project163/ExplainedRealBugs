diff --git a/sdks/go/pkg/beam/core/runtime/exec/datasink.go b/sdks/go/pkg/beam/core/runtime/exec/datasink.go
index 473ac38aac5..36f2a5195ca 100644
--- a/sdks/go/pkg/beam/core/runtime/exec/datasink.go
+++ b/sdks/go/pkg/beam/core/runtime/exec/datasink.go
@@ -20,41 +20,54 @@ import (
 	"context"
 	"fmt"
 	"io"
+	"sync/atomic"
 
 	"github.com/apache/beam/sdks/v2/go/pkg/beam/core/graph/coder"
 	"github.com/apache/beam/sdks/v2/go/pkg/beam/internal/errors"
 )
 
-// DataSink is a Node.
+// DataSink is a Node that writes element data to the data service..
 type DataSink struct {
 	UID   UnitID
 	SID   StreamID
 	Coder *coder.Coder
+	PCol  *PCollection // Handles size metrics.
 
 	enc  ElementEncoder
 	wEnc WindowEncoder
 	w    io.WriteCloser
 }
 
+// ID returns the debug ID.
 func (n *DataSink) ID() UnitID {
 	return n.UID
 }
 
+// Up initializes the element and window encoders.
 func (n *DataSink) Up(ctx context.Context) error {
 	n.enc = MakeElementEncoder(coder.SkipW(n.Coder))
 	n.wEnc = MakeWindowEncoder(n.Coder.Window)
 	return nil
 }
 
+// StartBundle opens the writer to the data service.
 func (n *DataSink) StartBundle(ctx context.Context, id string, data DataContext) error {
 	w, err := data.Data.OpenWrite(ctx, n.SID)
 	if err != nil {
 		return err
 	}
 	n.w = w
+	// TODO[BEAM-6374): Properly handle the multiplex and flatten cases.
+	// Right now we just stop datasink collection.
+	if n.PCol != nil {
+		atomic.StoreInt64(&n.PCol.elementCount, 0)
+		n.PCol.resetSize()
+	}
 	return nil
 }
 
+// ProcessElement encodes the windowed value header for the element, followed by the element,
+// emitting it to the data service.
 func (n *DataSink) ProcessElement(ctx context.Context, value *FullValue, values ...ReStream) error {
 	// Marshal the pieces into a temporary buffer since they must be transmitted on FnAPI as a single
 	// unit.
@@ -66,16 +79,25 @@ func (n *DataSink) ProcessElement(ctx context.Context, value *FullValue, values
 	if err := n.enc.Encode(value, &b); err != nil {
 		return errors.WithContextf(err, "encoding element %v with coder %v", value, n.enc)
 	}
-	if _, err := n.w.Write(b.Bytes()); err != nil {
+	byteCount, err := n.w.Write(b.Bytes())
+	if err != nil {
 		return err
 	}
+	// TODO[BEAM-6374): Properly handle the multiplex and flatten cases.
+	// Right now we just stop datasink collection.
+	if n.PCol != nil {
+		atomic.AddInt64(&n.PCol.elementCount, 1)
+		n.PCol.addSize(int64(byteCount))
+	}
 	return nil
 }
 
+// FinishBundle closes the write to the data channel.
 func (n *DataSink) FinishBundle(ctx context.Context) error {
 	return n.w.Close()
 }
 
+// Down is a no-op.
 func (n *DataSink) Down(ctx context.Context) error {
 	return nil
 }
diff --git a/sdks/go/pkg/beam/core/runtime/exec/translate.go b/sdks/go/pkg/beam/core/runtime/exec/translate.go
index 6c8f75bc76f..61809dff1fa 100644
--- a/sdks/go/pkg/beam/core/runtime/exec/translate.go
+++ b/sdks/go/pkg/beam/core/runtime/exec/translate.go
@@ -89,6 +89,8 @@ func UnmarshalPlan(desc *fnpb.ProcessBundleDescriptor) (*Plan, error) {
 			}
 			// Elide the PCollection Node for DataSources
 			// DataSources can get byte samples directly, and can handle CoGBKs.
+			// Copying the PCollection here is fine, as the PCollection will never
+			// have used it's mutex yet.
 			u.PCol = *u.Out.(*PCollection)
 			u.Out = u.PCol.Out
 			b.units = b.units[:len(b.units)-1]
@@ -234,7 +236,22 @@ func (b *builder) makePCollections(out []string) ([]Node, error) {
 		if err != nil {
 			return nil, err
 		}
-		ret = append(ret, n)
+		// This is the cleanest place to do this check and filtering,
+		// since DataSinks don't know their inputs, due to the construction
+		// call stack.
+		// A Source->Sink is both uncommon and inefficent, with the Source eliding the
+		// collection anyway.
+		// TODO[BEAM-6374): Properly handle the multiplex and flatten cases.
+		// Right now we just stop datasink collection.
+		switch out := n.Out.(type) {
+		case *DataSink:
+			// We don't remove the PCollection from units here, since we
+			// want to ensure it's included in snapshots.
+			out.PCol = n
+			ret = append(ret, out)
+		default:
+			ret = append(ret, n)
+		}
 	}
 	return ret, nil
 }
@@ -465,7 +482,14 @@ func (b *builder) makeLink(from string, id linkID) (Node, error) {
 					}
 					u = &LiftedCombine{Combine: cn, KeyCoder: ec.Components[0], WindowCoder: wc}
 				case urnPerKeyCombineMerge:
-					u = &MergeAccumulators{Combine: cn}
+					ma := &MergeAccumulators{Combine: cn}
+					if eo, ok := ma.Out.(*PCollection).Out.(*ExtractOutput); ok {
+						// Strip PCollections from between MergeAccumulators and ExtractOutputs
+						// as it's a synthetic PCollection.
+						b.units = b.units[:len(b.units)-1]
+						ma.Out = eo
+					}
+					u = ma
 				case urnPerKeyCombineExtract:
 					u = &ExtractOutput{Combine: cn}
 				case urnPerKeyCombineConvert:
@@ -644,7 +668,7 @@ func inputIdToIndex(id string) (int, error) {
 	return strconv.Atoi(strings.TrimPrefix(id, "i"))
 }
 
-// inputIdToIndex converts an index into a local input ID for a transform. Use
+// indexToInputId converts an index into a local input ID for a transform. Use
 // this to avoid relying on format details for input IDs.
 func indexToInputId(i int) string {
 	return "i" + strconv.Itoa(i)
