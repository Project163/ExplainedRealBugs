diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPortablePipelineTranslator.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPortablePipelineTranslator.java
index 9fe2b2b2de2..9f73817385c 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPortablePipelineTranslator.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPortablePipelineTranslator.java
@@ -43,6 +43,7 @@ import org.apache.beam.runners.core.construction.graph.PipelineNode;
 import org.apache.beam.runners.core.construction.graph.QueryablePipeline;
 import org.apache.beam.runners.flink.translation.functions.FlinkAssignWindows;
 import org.apache.beam.runners.flink.translation.functions.FlinkExecutableStageContext;
+import org.apache.beam.runners.flink.translation.functions.ImpulseSourceFunction;
 import org.apache.beam.runners.flink.translation.types.CoderTypeInformation;
 import org.apache.beam.runners.flink.translation.utils.FlinkPipelineTranslatorUtils;
 import org.apache.beam.runners.flink.translation.wrappers.streaming.DoFnOperator;
@@ -137,8 +138,8 @@ public class FlinkStreamingPortablePipelineTranslator
       return executionEnvironment;
     }
 
-    public <T> void addDataStream(String pCollectionId, DataStream<T> dataSet) {
-      dataStreams.put(pCollectionId, dataSet);
+    public <T> void addDataStream(String pCollectionId, DataStream<T> dataStream) {
+      dataStreams.put(pCollectionId, dataStream);
     }
 
     public <T> DataStream<T> getDataStreamOrThrow(String pCollectionId) {
@@ -219,8 +220,9 @@ public class FlinkStreamingPortablePipelineTranslator
       // create an empty dummy source to satisfy downstream operations
       // we cannot create an empty source in Flink, therefore we have to
       // add the flatMap that simply never forwards the single element
-      DataStreamSource<String> dummySource =
-          context.getExecutionEnvironment().fromElements("dummy");
+      boolean keepSourceAlive = !context.getPipelineOptions().isShutdownSourcesOnFinalWatermark();
+      DataStreamSource<WindowedValue<byte[]>> dummySource =
+          context.getExecutionEnvironment().addSource(new ImpulseSourceFunction(keepSourceAlive));
 
       DataStream<WindowedValue<T>> result =
           dummySource
@@ -397,11 +399,12 @@ public class FlinkStreamingPortablePipelineTranslator
         new CoderTypeInformation<>(
             WindowedValue.getFullCoder(ByteArrayCoder.of(), GlobalWindow.Coder.INSTANCE));
 
-    DataStreamSource<WindowedValue<byte[]>> source =
+    boolean keepSourceAlive = !context.getPipelineOptions().isShutdownSourcesOnFinalWatermark();
+    SingleOutputStreamOperator<WindowedValue<byte[]>> source =
         context
             .getExecutionEnvironment()
-            .fromCollection(
-                Collections.singleton(WindowedValue.valueInGlobalWindow(new byte[0])), typeInfo);
+            .addSource(new ImpulseSourceFunction(keepSourceAlive))
+            .returns(typeInfo);
 
     context.addDataStream(Iterables.getOnlyElement(pTransform.getOutputsMap().values()), source);
   }
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/ImpulseSourceFunction.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/ImpulseSourceFunction.java
new file mode 100644
index 00000000000..420d90e749a
--- /dev/null
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/functions/ImpulseSourceFunction.java
@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.beam.runners.flink.translation.functions;
+
+import org.apache.beam.sdk.util.WindowedValue;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
+
+/**
+ * Source function which sends an impulse to a downstream operator. It may keep the source alive
+ * although its work is already done. It will only shutdown when requested by the JobManager.
+ */
+public class ImpulseSourceFunction implements SourceFunction<WindowedValue<byte[]>> {
+
+  /** Keep source running even after it has done all the work. */
+  private final boolean keepSourceAlive;
+
+  /** Indicates the streaming job is running and the source can produce elements. */
+  private volatile boolean running;
+
+  public ImpulseSourceFunction(boolean keepSourceAlive) {
+    this.keepSourceAlive = keepSourceAlive;
+    this.running = true;
+  }
+
+  @Override
+  public void run(SourceContext<WindowedValue<byte[]>> sourceContext) throws Exception {
+    // emit single impulse element
+    sourceContext.collect(WindowedValue.valueInGlobalWindow(new byte[0]));
+    // Do nothing, but still look busy ...
+    // we can't return here since Flink requires that all operators stay up,
+    // otherwise checkpointing would not work correctly anymore
+    //
+    // See https://issues.apache.org/jira/browse/FLINK-2491 for progress on this issue
+    if (keepSourceAlive) {
+      // wait until this is canceled
+      final Object waitLock = new Object();
+      while (running) {
+        try {
+          // Flink will interrupt us at some point
+          //noinspection SynchronizationOnLocalVariableOrMethodParameter
+          synchronized (waitLock) {
+            // don't wait indefinitely, in case something goes horribly wrong
+            waitLock.wait(1000);
+          }
+        } catch (InterruptedException e) {
+          if (!running) {
+            // restore the interrupted state, and fall through the loop
+            Thread.currentThread().interrupt();
+          }
+        }
+      }
+    }
+  }
+
+  @Override
+  public void cancel() {
+    this.running = false;
+  }
+}
