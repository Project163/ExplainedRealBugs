diff --git a/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/SparkContextFactory.java b/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/SparkContextFactory.java
index 67839a80824..326838a26a3 100644
--- a/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/SparkContextFactory.java
+++ b/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/SparkContextFactory.java
@@ -40,17 +40,21 @@ public final class SparkContextFactory {
    */
   static final String TEST_REUSE_SPARK_CONTEXT = "beam.spark.test.reuseSparkContext";
 
+  // Spark allows only one context for JVM so this can be static.
   private static JavaSparkContext sparkContext;
   private static String sparkMaster;
+  private static boolean usesProvidedSparkContext;
 
   private SparkContextFactory() {
   }
 
   public static synchronized JavaSparkContext getSparkContext(SparkPipelineOptions options) {
     SparkContextOptions contextOptions = options.as(SparkContextOptions.class);
+    usesProvidedSparkContext = contextOptions.getUsesProvidedSparkContext();
     // reuse should be ignored if the context is provided.
     if (Boolean.getBoolean(TEST_REUSE_SPARK_CONTEXT)
-        && !contextOptions.getUsesProvidedSparkContext()) {
+        && !usesProvidedSparkContext) {
+
       // if the context is null or stopped for some reason, re-create it.
       if (sparkContext == null || sparkContext.sc().isStopped()) {
         sparkContext = createSparkContext(contextOptions);
@@ -67,13 +71,14 @@ public final class SparkContextFactory {
   }
 
   public static synchronized void stopSparkContext(JavaSparkContext context) {
-    if (!Boolean.getBoolean(TEST_REUSE_SPARK_CONTEXT)) {
+    if (!Boolean.getBoolean(TEST_REUSE_SPARK_CONTEXT)
+            && !usesProvidedSparkContext) {
       context.stop();
     }
   }
 
   private static JavaSparkContext createSparkContext(SparkContextOptions contextOptions) {
-    if (contextOptions.getUsesProvidedSparkContext()) {
+    if (usesProvidedSparkContext) {
       LOG.info("Using a provided Spark Context");
       JavaSparkContext jsc = contextOptions.getProvidedSparkContext();
       if (jsc == null || jsc.sc().isStopped()){
diff --git a/runners/spark/src/test/java/org/apache/beam/runners/spark/ProvidedSparkContextTest.java b/runners/spark/src/test/java/org/apache/beam/runners/spark/ProvidedSparkContextTest.java
index 00c894d6d99..a4190a9dcae 100644
--- a/runners/spark/src/test/java/org/apache/beam/runners/spark/ProvidedSparkContextTest.java
+++ b/runners/spark/src/test/java/org/apache/beam/runners/spark/ProvidedSparkContextTest.java
@@ -57,6 +57,8 @@ public class ProvidedSparkContextTest {
     public void testWithProvidedContext() throws Exception {
         JavaSparkContext jsc = new JavaSparkContext("local[*]", "Existing_Context");
         testWithValidProvidedContext(jsc);
+        // A provided context must not be stopped after execution
+        assertFalse(jsc.sc().isStopped());
         jsc.stop();
     }
 
