diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironment.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironment.java
index 8e15808a558..7f0389f0a59 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironment.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironment.java
@@ -89,10 +89,7 @@ class FlinkPipelineExecutionEnvironment {
       options.setStreaming(true);
     }
 
-    // Replace transforms only after determining the execution mode (batch/streaming)
-    pipeline.replaceAll(FlinkTransformOverrides.getDefaultOverrides(options));
-
-    // Needs to be done before creating the Flink ExecutionEnvironments
+    // Staged files need to be set before initializing the execution environments
     prepareFilesToStageForRemoteClusterExecution(options);
 
     FlinkPipelineTranslator translator;
@@ -112,6 +109,10 @@ class FlinkPipelineExecutionEnvironment {
       translator = new FlinkBatchPipelineTranslator(flinkBatchEnv, options);
     }
 
+    // Transform replacements need to receive the finalized PipelineOptions
+    // including execution mode (batch/streaming) and parallelism.
+    pipeline.replaceAll(FlinkTransformOverrides.getDefaultOverrides(options));
+
     translator.translate(pipeline);
   }
 
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPipelineTranslator.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPipelineTranslator.java
index 83776e17086..f4c21ad34ad 100644
--- a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPipelineTranslator.java
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPipelineTranslator.java
@@ -196,7 +196,7 @@ class FlinkStreamingPipelineTranslator extends FlinkPipelineTranslator {
 
       Preconditions.checkArgument(
           jobParallelism > 0,
-          "Parallelism of a job should be greater than 0. Currently set: {}",
+          "Parallelism of a job should be greater than 0. Currently set: %s",
           jobParallelism);
       int numShards = jobParallelism * 2;
 
diff --git a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java
index 838a880f31c..74e979ab8bc 100644
--- a/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java
+++ b/runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java
@@ -45,6 +45,8 @@ import org.apache.beam.sdk.io.GenerateSequence;
 import org.apache.beam.sdk.io.TextIO;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;
 import org.apache.beam.sdk.runners.PTransformOverride;
+import org.apache.beam.sdk.runners.PTransformOverrideFactory;
+import org.apache.beam.sdk.transforms.Create;
 import org.apache.beam.sdk.transforms.DoFn;
 import org.apache.beam.sdk.transforms.ParDo;
 import org.apache.beam.sdk.transforms.windowing.FixedWindows;
@@ -55,6 +57,8 @@ import org.apache.flink.api.java.ExecutionEnvironment;
 import org.apache.flink.api.java.RemoteEnvironment;
 import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+import org.hamcrest.BaseMatcher;
+import org.hamcrest.Description;
 import org.hamcrest.Matchers;
 import org.joda.time.Duration;
 import org.junit.Rule;
@@ -217,6 +221,50 @@ public class FlinkPipelineExecutionEnvironmentTest implements Serializable {
     }
   }
 
+  @Test
+  public void shouldProvideParallelismToTransformOverrides() {
+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);
+    options.setStreaming(true);
+    options.setRunner(FlinkRunner.class);
+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);
+    Pipeline p = Pipeline.create(options);
+    // Create a transform applicable for PTransformMatchers.writeWithRunnerDeterminedSharding()
+    // which requires parallelism
+    p.apply(Create.of("test")).apply(TextIO.write().to("/tmp"));
+    p = Mockito.spy(p);
+
+    // If this succeeds we're ok
+    flinkEnv.translate(p);
+
+    // Verify we were using desired replacement transform
+    ArgumentCaptor<ImmutableList> captor = ArgumentCaptor.forClass(ImmutableList.class);
+    Mockito.verify(p).replaceAll(captor.capture());
+    ImmutableList<PTransformOverride> overridesList = captor.getValue();
+    assertThat(
+        overridesList,
+        hasItem(
+            new BaseMatcher<PTransformOverride>() {
+              @Override
+              public void describeTo(Description description) {}
+
+              @Override
+              public boolean matches(Object actual) {
+                if (actual instanceof PTransformOverride) {
+                  PTransformOverrideFactory overrideFactory =
+                      ((PTransformOverride) actual).getOverrideFactory();
+                  if (overrideFactory
+                      instanceof FlinkStreamingPipelineTranslator.StreamingShardedWriteFactory) {
+                    FlinkStreamingPipelineTranslator.StreamingShardedWriteFactory factory =
+                        (FlinkStreamingPipelineTranslator.StreamingShardedWriteFactory)
+                            overrideFactory;
+                    return factory.options.getParallelism() > 0;
+                  }
+                }
+                return false;
+              }
+            }));
+  }
+
   @Test
   public void shouldUseStreamingTransformOverridesWithUnboundedSources() {
     FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);
