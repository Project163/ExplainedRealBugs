diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/options/DataflowPipelineDebugOptions.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/options/DataflowPipelineDebugOptions.java
index 4811ec00818..f0c16ff0aa4 100644
--- a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/options/DataflowPipelineDebugOptions.java
+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/options/DataflowPipelineDebugOptions.java
@@ -220,6 +220,16 @@ public interface DataflowPipelineDebugOptions extends ExperimentalOptions, Pipel
 
   void setWorkerCacheMb(Integer value);
 
+  /**
+   * The amount of time before UnboundedReaders are considered idle and closed during streaming
+   * execution.
+   */
+  @Description("The amount of time before UnboundedReaders are uncached, in seconds.")
+  @Default.Integer(60)
+  Integer getReaderCacheTimeoutSec();
+
+  void setReaderCacheTimeoutSec(Integer value);
+
   /**
    * CAUTION: This option implies dumpHeapOnOOM, and has similar caveats. Specifically, heap dumps
    * can of comparable size to the default boot disk. Consider increasing the boot disk size before
diff --git a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/ReaderCache.java b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/ReaderCache.java
index bf65cfac1d4..58f3abfc66a 100644
--- a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/ReaderCache.java
+++ b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/ReaderCache.java
@@ -18,6 +18,7 @@
 package org.apache.beam.runners.dataflow.worker;
 
 import java.io.IOException;
+import java.util.concurrent.Executor;
 import java.util.concurrent.TimeUnit;
 import javax.annotation.concurrent.ThreadSafe;
 import org.apache.beam.sdk.io.UnboundedSource;
@@ -41,6 +42,7 @@ import org.slf4j.LoggerFactory;
 class ReaderCache {
 
   private static final Logger LOG = LoggerFactory.getLogger(ReaderCache.class);
+  private final Executor invalidationExecutor;
 
   // Note on thread safety. This class is thread safe because:
   //   - Guava Cache is thread safe.
@@ -64,33 +66,36 @@ class ReaderCache {
 
   private final Cache<WindmillComputationKey, CacheEntry> cache;
 
-  /** ReaderCache with default 1 minute expiration for readers. */
-  ReaderCache() {
-    this(Duration.standardMinutes(1));
-  }
-
-  /** Cache reader for {@code cacheDuration}. */
-  ReaderCache(Duration cacheDuration) {
+  /** Cache reader for {@code cacheDuration}. Readers will be closed on {@code executor}. */
+  ReaderCache(Duration cacheDuration, Executor invalidationExecutor) {
+    this.invalidationExecutor = invalidationExecutor;
     this.cache =
         CacheBuilder.newBuilder()
             .expireAfterWrite(cacheDuration.getMillis(), TimeUnit.MILLISECONDS)
             .removalListener(
                 (RemovalNotification<WindmillComputationKey, CacheEntry> notification) -> {
                   if (notification.getCause() != RemovalCause.EXPLICIT) {
-                    LOG.info("Closing idle reader for {}", notification.getKey());
-                    closeReader(notification.getKey(), notification.getValue());
+                    LOG.info(
+                        "Asynchronously closing reader for {} as it has been idle for over {}",
+                        notification.getKey(),
+                        cacheDuration);
+                    asyncCloseReader(notification.getKey(), notification.getValue());
                   }
                 })
             .build();
   }
 
   /** Close the reader and log a warning if close fails. */
-  private void closeReader(WindmillComputationKey key, CacheEntry entry) {
-    try {
-      entry.reader.close();
-    } catch (IOException e) {
-      LOG.warn("Failed to close UnboundedReader for {}", key, e);
-    }
+  private void asyncCloseReader(WindmillComputationKey key, CacheEntry entry) {
+    invalidationExecutor.execute(
+        () -> {
+          try {
+            entry.reader.close();
+            LOG.info("Finished closing reader for {}", key);
+          } catch (IOException e) {
+            LOG.warn("Failed to close UnboundedReader for {}", key, e);
+          }
+        });
   }
 
   /**
@@ -112,7 +117,8 @@ class ReaderCache {
       } else {
         // new cacheToken invalidates old one or this is a retried or stale request,
         // close the reader.
-        closeReader(computationKey, entry);
+        LOG.info("Asynchronously closing reader for {} as it is no longer valid", computationKey);
+        asyncCloseReader(computationKey, entry);
       }
     }
     return null;
diff --git a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java
index 6c127c84f84..b10cebcd454 100644
--- a/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java
+++ b/runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java
@@ -54,6 +54,7 @@ import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Executors;
 import java.util.concurrent.LinkedBlockingQueue;
 import java.util.concurrent.Semaphore;
 import java.util.concurrent.ThreadFactory;
@@ -467,7 +468,7 @@ public class StreamingDataflowWorker {
   private final EvictingQueue<String> pendingFailuresToReport =
       EvictingQueue.<String>create(MAX_FAILURES_TO_REPORT_IN_UPDATE);
 
-  private final ReaderCache readerCache = new ReaderCache();
+  private final ReaderCache readerCache;
 
   private final WorkUnitClient workUnitClient;
   private final CompletableFuture<Void> isDoneFuture;
@@ -597,6 +598,10 @@ public class StreamingDataflowWorker {
       HotKeyLogger hotKeyLogger)
       throws IOException {
     this.stateCache = new WindmillStateCache(options.getWorkerCacheMb());
+    this.readerCache =
+        new ReaderCache(
+            Duration.standardSeconds(options.getReaderCacheTimeoutSec()),
+            Executors.newCachedThreadPool());
     this.mapTaskExecutorFactory = mapTaskExecutorFactory;
     this.workUnitClient = workUnitClient;
     this.options = options;
diff --git a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/ReaderCacheTest.java b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/ReaderCacheTest.java
index f9ab12c41b0..25e5ecf3190 100644
--- a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/ReaderCacheTest.java
+++ b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/ReaderCacheTest.java
@@ -61,7 +61,7 @@ public class ReaderCacheTest {
 
   @Before
   public void setUp() {
-    readerCache = new ReaderCache();
+    readerCache = new ReaderCache(Duration.standardMinutes(1), Runnable::run);
     MockitoAnnotations.initMocks(this);
   }
 
@@ -152,7 +152,7 @@ public class ReaderCacheTest {
     Duration cacheDuration = Duration.millis(10);
 
     // Create a cache with short expiry period.
-    ReaderCache readerCache = new ReaderCache(cacheDuration);
+    ReaderCache readerCache = new ReaderCache(cacheDuration, Runnable::run);
 
     readerCache.cacheReader(
         WindmillComputationKey.create(C_ID, KEY_1, SHARDING_KEY), 1, 0, reader1);
@@ -172,7 +172,7 @@ public class ReaderCacheTest {
 
   @Test
   public void testReaderCacheRetries() throws IOException, InterruptedException {
-    ReaderCache readerCache = new ReaderCache();
+    ReaderCache readerCache = new ReaderCache(Duration.standardMinutes(1), Runnable::run);
 
     readerCache.cacheReader(
         WindmillComputationKey.create(C_ID, KEY_1, SHARDING_KEY), 1, 1, reader1);
diff --git a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/StreamingModeExecutionContextTest.java b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/StreamingModeExecutionContextTest.java
index 89ac7580b73..8d86c1a3343 100644
--- a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/StreamingModeExecutionContextTest.java
+++ b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/StreamingModeExecutionContextTest.java
@@ -69,6 +69,7 @@ import org.apache.beam.sdk.values.TupleTag;
 import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;
 import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;
 import org.hamcrest.Matchers;
+import org.joda.time.Duration;
 import org.joda.time.Instant;
 import org.junit.Before;
 import org.junit.Test;
@@ -104,7 +105,7 @@ public class StreamingModeExecutionContextTest {
         new StreamingModeExecutionContext(
             counterSet,
             "computationId",
-            new ReaderCache(),
+            new ReaderCache(Duration.standardMinutes(1), Executors.newCachedThreadPool()),
             stateNameMap,
             new WindmillStateCache(options.getWorkerCacheMb()).forComputation("comp"),
             StreamingStepMetricsContainer.createRegistry(),
diff --git a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WorkerCustomSourcesTest.java b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WorkerCustomSourcesTest.java
index cf12da5230b..2f749da3503 100644
--- a/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WorkerCustomSourcesTest.java
+++ b/runners/google-cloud-dataflow-java/worker/src/test/java/org/apache/beam/runners/dataflow/worker/WorkerCustomSourcesTest.java
@@ -502,7 +502,7 @@ public class WorkerCustomSourcesTest {
     CounterSet counterSet = new CounterSet();
     StreamingModeExecutionStateRegistry executionStateRegistry =
         new StreamingModeExecutionStateRegistry(null);
-    ReaderCache readerCache = new ReaderCache();
+    ReaderCache readerCache = new ReaderCache(Duration.standardMinutes(1), Runnable::run);
     StreamingModeExecutionContext context =
         new StreamingModeExecutionContext(
             counterSet,
