<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 11:12:27 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-7463] BigQueryQueryToTableIT is flaky on Direct runner in PostCommit suites: incorrect checksum </title>
                <link>https://issues.apache.org/jira/browse/BEAM-7463</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;15:03:38 FAIL: test_big_query_new_types (apache_beam.io.gcp.big_query_query_to_table_it_test.BigQueryQueryToTableIT)
15:03:38 ----------------------------------------------------------------------
15:03:38 Traceback (most recent call last):
15:03:38   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify/src/sdks/python/apache_beam/io/gcp/big_query_query_to_table_it_test.py&quot;, line 211, in test_big_query_new_types
15:03:38     big_query_query_to_table_pipeline.run_bq_pipeline(options)
15:03:38   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify/src/sdks/python/apache_beam/io/gcp/big_query_query_to_table_pipeline.py&quot;, line 82, in run_bq_pipeline
15:03:38     result = p.run()
15:03:38   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify/src/sdks/python/apache_beam/testing/test_pipeline.py&quot;, line 107, in run
15:03:38     else test_runner_api))
15:03:38   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify/src/sdks/python/apache_beam/pipeline.py&quot;, line 406, in run
15:03:38     self._options).run(False)
15:03:38   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify/src/sdks/python/apache_beam/pipeline.py&quot;, line 419, in run
15:03:38     return self.runner.run_pipeline(self, self._options)
15:03:38   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python3_Verify/src/sdks/python/apache_beam/runners/direct/test_direct_runner.py&quot;, line 51, in run_pipeline
15:03:38     hc_assert_that(self.result, pickler.loads(on_success_matcher))
15:03:38 AssertionError: 
15:03:38 Expected: (Test pipeline expected terminated in state: DONE and Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214)
15:03:38      but: Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214 Actual checksum is da39a3ee5e6b4b0d3255bfef95601890afd80709
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Juta&quot; class=&quot;user-hover&quot; rel=&quot;Juta&quot;&gt;Juta&lt;/a&gt; could this be caused by changes to Bigquery matcher? &lt;a href=&quot;https://github.com/apache/beam/pull/8621/files#diff-f1ec7e3a3e7e2e5082ddb7043954c108R134&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/8621/files#diff-f1ec7e3a3e7e2e5082ddb7043954c108R134&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;cc: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pabloem&quot; class=&quot;user-hover&quot; rel=&quot;pabloem&quot;&gt;pabloem&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=chamikara&quot; class=&quot;user-hover&quot; rel=&quot;chamikara&quot;&gt;chamikara&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=apilloud&quot; class=&quot;user-hover&quot; rel=&quot;apilloud&quot;&gt;apilloud&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A recent postcommit run has BQ failures in other tests as well: &lt;a href=&quot;https://builds.apache.org/job/beam_PostCommit_Python3_Verify/1000/consoleFull&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/beam_PostCommit_Python3_Verify/1000/consoleFull&lt;/a&gt;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13236723">BEAM-7463</key>
            <summary>BigQueryQueryToTableIT is flaky on Direct runner in PostCommit suites: incorrect checksum </summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10101" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">P1</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="udim">Udi Meiri</assignee>
                                    <reporter username="tvalentyn">Valentyn Tymofieiev</reporter>
                        <labels>
                            <label>currently-failing</label>
                            <label>flake</label>
                    </labels>
                <created>Fri, 31 May 2019 00:11:02 +0000</created>
                <updated>Wed, 24 Mar 2021 21:15:17 +0000</updated>
                            <resolved>Fri, 19 Mar 2021 17:20:32 +0000</resolved>
                                                    <fixVersion>Not applicable</fixVersion>
                                    <component>io-py-gcp</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>5</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="25200">7h</timespent>
                                <comments>
                            <comment id="16855510" author="juta" created="Tue, 4 Jun 2019 09:43:42 +0000"  >&lt;p&gt;I might know what causes the flakyness:&lt;/p&gt;

&lt;p&gt;When the tests are run in parallel with nose they share class variables. The setup and tear down methods&#160;are called once for each test case in a class. Many big query test classes create a unique dataset name in the setup and delete this dataset in the tear down. Some of the tests share the same output table name&lt;/p&gt;

&lt;p&gt;This can lead to the following executions:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;when data is written with WRITE_EMPTY, it is possible that a second test already empties the table and right after this the data is checked in the first test. This would cause this checksum error&lt;/li&gt;
	&lt;li&gt;when the tear down method is called this deleted the dataset and it is possible that after deleting a dataset, the data is checked in another test. This would cause&#160;&lt;br/&gt;
not found: Table apache-beam-testing:python_bq_file_loads_15595843114095.beam_load_2019_06_03_175817_9_5b3b6196cef9fd926078ec31862c8d0b_0 was not found in location US&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;I added a pr&#160;&lt;a href=&quot;https://github.com/apache/beam/pull/8751&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/8751&lt;/a&gt;&#160;to make sure that variables are not shared among different test executions.&lt;/p&gt;</comment>
                            <comment id="16868810" author="ardagan" created="Thu, 20 Jun 2019 18:02:22 +0000"  >&lt;p&gt;Sumilar repro, but &quot;but&quot; field is empty:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/job/beam_PostCommit_Python3_Verify/1189/consoleFull&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/beam_PostCommit_Python3_Verify/1189/consoleFull&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16883391" author="tvalentyn" created="Thu, 11 Jul 2019 23:05:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pabloem&quot; class=&quot;user-hover&quot; rel=&quot;pabloem&quot;&gt;pabloem&lt;/a&gt; could you please take a look into BQ  suites? your expertise in BQ connector may help us track this down faster. &lt;br/&gt;
&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Juta&quot; class=&quot;user-hover&quot; rel=&quot;Juta&quot;&gt;Juta&lt;/a&gt;, Do you remember why we removed sorting in Bigquery matcher? See: &lt;a href=&quot;https://github.com/apache/beam/pull/8621/files#diff-f1ec7e3a3e7e2e5082ddb7043954c108R134&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/8621/files#diff-f1ec7e3a3e7e2e5082ddb7043954c108R134&lt;/a&gt;. Does BQ guarantee some order of returned result? if not, then that may very well cause the checksum errors, but there are also other errors with this test like table not found and  but &quot;but&quot; field is empty, perhaps we should investigate these separately.&lt;/p&gt;

&lt;p&gt;Also, to echo some points from conversation on &lt;a href=&quot;https://github.com/apache/beam/pull/8751&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/8751&lt;/a&gt; for visibility:  class attributes assigned in setup/teardown method are not shared between  execution of different tests cases defined in the same test class, so the race of table cleanup is not obvious to me.&lt;/p&gt;</comment>
                            <comment id="16883398" author="pabloem" created="Thu, 11 Jul 2019 23:25:53 +0000"  >&lt;p&gt;taking a look...&lt;/p&gt;</comment>
                            <comment id="16883624" author="juta" created="Fri, 12 Jul 2019 08:31:23 +0000"  >&lt;p&gt;I remember removing the sorting from the BigqueryFullResultMatcher because I think the order of the elements within a row should not be sorted. I updated the tests using the BigqueryFullResultMatcher to include the order in the query (and thus have a deterministic order for the elements within one row). The outer dimension is then still sorted.&lt;/p&gt;

&lt;p&gt;I looked at the tests that are failing due to the checksum error and they seem to be using the BigqueryMatcher which also does not sort the elements within a row and when computing the checksum it does sort the outer dimension. However the checksum in sometimes incorrect even for test that include an order in the query (e.g. for this test: &lt;a href=&quot;https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/gcp/big_query_query_to_table_it_test.py#L196&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/gcp/big_query_query_to_table_it_test.py#L196&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16884202" author="pabloem" created="Fri, 12 Jul 2019 22:16:34 +0000"  >&lt;p&gt;I&apos;ve been running this over an over about 20 times, and I have not been able to reproduce an error with the matcher: apache_beam.io.gcp.bigquery_write_it_test:BigQueryWriteIntegrationTests.test_big_query_write_new_types&lt;/p&gt;

&lt;p&gt;I am wondering if it could have to do with the machine where the tests run...&lt;/p&gt;</comment>
                            <comment id="16884789" author="tvalentyn" created="Mon, 15 Jul 2019 00:06:39 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pabloem&quot; class=&quot;user-hover&quot; rel=&quot;pabloem&quot;&gt;pabloem&lt;/a&gt; Which runner did you use? Seeing this DirectRunner failure on apache-beam-jenkins-11:&lt;/p&gt;


&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;14:21:16 &amp;gt; Task :sdks:python:directRunnerIT
14:21:16 test_big_query_legacy_sql (apache_beam.io.gcp.big_query_query_to_table_it_test.BigQueryQueryToTableIT) ... ok
14:21:16 test_big_query_new_types (apache_beam.io.gcp.big_query_query_to_table_it_test.BigQueryQueryToTableIT) ... FAIL
14:21:16 test_big_query_standard_sql (apache_beam.io.gcp.big_query_query_to_table_it_test.BigQueryQueryToTableIT) ... ok
14:21:16 test_big_query_standard_sql_kms_key_native (apache_beam.io.gcp.big_query_query_to_table_it_test.BigQueryQueryToTableIT) ... SKIP: This test doesn&apos;t work on DirectRunner.
14:21:19 test_streaming_data_only (apache_beam.io.gcp.pubsub_integration_test.PubSubIntegrationTest) ... ok
14:21:19 test_streaming_with_attributes (apache_beam.io.gcp.pubsub_integration_test.PubSubIntegrationTest) ... ok
14:21:20 test_wordcount_it (apache_beam.examples.wordcount_it_test.WordCountIT) ... ok
14:21:20 
14:21:20 ======================================================================
14:21:20 FAIL: test_big_query_new_types (apache_beam.io.gcp.big_query_query_to_table_it_test.BigQueryQueryToTableIT)
14:21:20 ----------------------------------------------------------------------
14:21:20 Traceback (most recent call last):
14:21:20   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python_Verify_PR/src/sdks/python/apache_beam/io/gcp/big_query_query_to_table_it_test.py&quot;, line 211, in test_big_query_new_types
14:21:20     big_query_query_to_table_pipeline.run_bq_pipeline(options)
14:21:20   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python_Verify_PR/src/sdks/python/apache_beam/io/gcp/big_query_query_to_table_pipeline.py&quot;, line 82, in run_bq_pipeline
14:21:20     result = p.run()
14:21:20   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python_Verify_PR/src/sdks/python/apache_beam/testing/test_pipeline.py&quot;, line 107, in run
14:21:20     else test_runner_api))
14:21:20   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python_Verify_PR/src/sdks/python/apache_beam/pipeline.py&quot;, line 406, in run
14:21:20     self._options).run(False)
14:21:20   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python_Verify_PR/src/sdks/python/apache_beam/pipeline.py&quot;, line 419, in run
14:21:20     return self.runner.run_pipeline(self, self._options)
14:21:20   File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python_Verify_PR/src/sdks/python/apache_beam/runners/direct/test_direct_runner.py&quot;, line 51, in run_pipeline
14:21:20     hc_assert_that(self.result, pickler.loads(on_success_matcher))
14:21:20 AssertionError: 
14:21:20 Expected: (Test pipeline expected terminated in state: DONE and Expected checksum is 1631ca7060b89a01760c81874b988c46156e18b5)
14:21:20      but: 
14:21:20 
14:21:20 -------------------- &amp;gt;&amp;gt; begin captured logging &amp;lt;&amp;lt; --------------------
14:21:20 root: DEBUG: Connecting using Google Application Default Credentials.
14:21:20 oauth2client.transport: INFO: Attempting refresh to obtain initial access_token
14:21:20 root: INFO: Running pipeline with DirectRunner.
14:21:20 root: DEBUG: Connecting using Google Application Default Credentials.
14:21:20 oauth2client.transport: INFO: Attempting refresh to obtain initial access_token
14:21:20 root: INFO: Using location u&apos;US&apos; from table &amp;lt;TableReference
14:21:20  datasetId: u&apos;python_query_to_table_15626208616472&apos;
14:21:20  projectId: u&apos;apache-beam-testing&apos;
14:21:20  tableId: u&apos;python_new_types_table&apos;&amp;gt; referenced by query SELECT bytes, date, time FROM [python_query_to_table_15626208616472.python_new_types_table]
14:21:20 root: WARNING: Dataset apache-beam-testing:temp_dataset_f7ed13498f964c5888d607bd200e0e62 does not exist so we will create it as temporary with location=US
14:21:20 root: DEBUG: Connecting using Google Application Default Credentials.
14:21:20 root: DEBUG: Creating or getting table &amp;lt;TableReference
14:21:20  datasetId: &apos;python_query_to_table_15626208616472&apos;
14:21:20  projectId: &apos;apache-beam-testing&apos;
14:21:20  tableId: &apos;output_table&apos;&amp;gt; with schema {&apos;fields&apos;: [{&apos;type&apos;: u&apos;BYTES&apos;, &apos;name&apos;: u&apos;bytes&apos;, &apos;mode&apos;: &apos;NULLABLE&apos;}, {&apos;type&apos;: u&apos;DATE&apos;, &apos;name&apos;: u&apos;date&apos;, &apos;mode&apos;: &apos;NULLABLE&apos;}, {&apos;type&apos;: u&apos;TIME&apos;, &apos;name&apos;: u&apos;time&apos;, &apos;mode&apos;: &apos;NULLABLE&apos;}]}.
14:21:20 oauth2client.transport: INFO: Attempting refresh to obtain initial access_token
14:21:20 root: DEBUG: Created the table with id output_table
14:21:20 root: INFO: Created table apache-beam-testing.python_query_to_table_15626208616472.output_table with schema &amp;lt;TableSchema
14:21:20  fields: [&amp;lt;TableFieldSchema
14:21:20  fields: []
14:21:20  mode: u&apos;NULLABLE&apos;
14:21:20  name: u&apos;bytes&apos;
14:21:20  type: u&apos;BYTES&apos;&amp;gt;, &amp;lt;TableFieldSchema
14:21:20  fields: []
14:21:20  mode: u&apos;NULLABLE&apos;
14:21:20  name: u&apos;date&apos;
14:21:20  type: u&apos;DATE&apos;&amp;gt;, &amp;lt;TableFieldSchema
14:21:20  fields: []
14:21:20  mode: u&apos;NULLABLE&apos;
14:21:20  name: u&apos;time&apos;
14:21:20  type: u&apos;TIME&apos;&amp;gt;]&amp;gt;. Result: &amp;lt;Table
14:21:20  creationTime: 1562620866768
14:21:20  etag: u&apos;qVCmDaC3dDohfi+Eh7thdw==&apos;
14:21:20  id: u&apos;apache-beam-testing:python_query_to_table_15626208616472.output_table&apos;
14:21:20  kind: u&apos;bigquery#table&apos;
14:21:20  lastModifiedTime: 1562620866835
14:21:20  location: u&apos;US&apos;
14:21:20  numBytes: 0
14:21:20  numLongTermBytes: 0
14:21:20  numRows: 0
14:21:20  schema: &amp;lt;TableSchema
14:21:20  fields: [&amp;lt;TableFieldSchema
14:21:20  fields: []
14:21:20  mode: u&apos;NULLABLE&apos;
14:21:20  name: u&apos;bytes&apos;
14:21:20  type: u&apos;BYTES&apos;&amp;gt;, &amp;lt;TableFieldSchema
14:21:20  fields: []
14:21:20  mode: u&apos;NULLABLE&apos;
14:21:20  name: u&apos;date&apos;
14:21:20  type: u&apos;DATE&apos;&amp;gt;, &amp;lt;TableFieldSchema
14:21:20  fields: []
14:21:20  mode: u&apos;NULLABLE&apos;
14:21:20  name: u&apos;time&apos;
14:21:20  type: u&apos;TIME&apos;&amp;gt;]&amp;gt;
14:21:20  selfLink: u&apos;https://www.googleapis.com/bigquery/v2/projects/apache-beam-testing/datasets/python_query_to_table_15626208616472/tables/output_table&apos;
14:21:20  tableReference: &amp;lt;TableReference
14:21:20  datasetId: u&apos;python_query_to_table_15626208616472&apos;
14:21:20  projectId: u&apos;apache-beam-testing&apos;
14:21:20  tableId: u&apos;output_table&apos;&amp;gt;
14:21:20  type: u&apos;TABLE&apos;&amp;gt;.
14:21:20 root: DEBUG: Attempting to flush to all destinations. Total buffered: 4
14:21:20 root: DEBUG: Flushing data to apache-beam-testing:python_query_to_table_15626208616472.output_table. Total 4 rows.
14:21:20 root: DEBUG: Passed: True. Errors are []
14:21:20 root: INFO: Start verify Bigquery data.
14:21:20 google.auth.transport._http_client: DEBUG: Making request: GET http://169.254.169.254
14:21:20 google.auth.transport._http_client: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/project/project-id
14:21:20 urllib3.util.retry: DEBUG: Converted retries value: 3 -&amp;gt; Retry(total=3, connect=None, read=None, redirect=None, status=None)
14:21:20 google.auth.transport.requests: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true
14:21:20 urllib3.connectionpool: DEBUG: Starting new HTTP connection (1): metadata.google.internal:80
14:21:20 urllib3.connectionpool: DEBUG: http://metadata.google.internal:80 &quot;GET /computeMetadata/v1/instance/service-accounts/default/?recursive=true HTTP/1.1&quot; 200 144
14:21:20 google.auth.transport.requests: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/844138762903-compute@developer.gserviceaccount.com/token
14:21:20 urllib3.connectionpool: DEBUG: http://metadata.google.internal:80 &quot;GET /computeMetadata/v1/instance/service-accounts/844138762903-compute@developer.gserviceaccount.com/token HTTP/1.1&quot; 200 176
14:21:20 urllib3.connectionpool: DEBUG: Starting new HTTPS connection (1): www.googleapis.com:443
14:21:20 urllib3.connectionpool: DEBUG: https://www.googleapis.com:443 &quot;POST /bigquery/v2/projects/apache-beam-testing/jobs HTTP/1.1&quot; 200 None
14:21:20 urllib3.connectionpool: DEBUG: https://www.googleapis.com:443 &quot;GET /bigquery/v2/projects/apache-beam-testing/queries/6882e326-23ab-4624-8d80-732b2bd6e108?location=US&amp;amp;maxResults=0 HTTP/1.1&quot; 200 None
14:21:20 urllib3.connectionpool: DEBUG: https://www.googleapis.com:443 &quot;GET /bigquery/v2/projects/apache-beam-testing/jobs/6882e326-23ab-4624-8d80-732b2bd6e108?location=US HTTP/1.1&quot; 200 None
14:21:20 urllib3.connectionpool: DEBUG: https://www.googleapis.com:443 &quot;GET /bigquery/v2/projects/apache-beam-testing/datasets/_7357fab0f784d2a7327ddbe81cdd1f4ca7e429cd/tables/anon90739891049f0700f371e74e94b02d37a805a270/data HTTP/1.1&quot; 200 None
14:21:20 root: INFO: Read from given query (SELECT bytes, date, time FROM `python_query_to_table_15626208616472.output_table`;), total rows 0
14:21:20 root: INFO: Generate checksum: da39a3ee5e6b4b0d3255bfef95601890afd80709
14:21:20 root: INFO: Start verify Bigquery data.
14:21:20 google.auth.transport._http_client: DEBUG: Making request: GET http://169.254.169.254
14:21:20 google.auth.transport._http_client: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/project/project-id
14:21:20 urllib3.util.retry: DEBUG: Converted retries value: 3 -&amp;gt; Retry(total=3, connect=None, read=None, redirect=None, status=None)
14:21:20 google.auth.transport.requests: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true
14:21:20 urllib3.connectionpool: DEBUG: Starting new HTTP connection (1): metadata.google.internal:80
14:21:20 urllib3.connectionpool: DEBUG: http://metadata.google.internal:80 &quot;GET /computeMetadata/v1/instance/service-accounts/default/?recursive=true HTTP/1.1&quot; 200 144
14:21:20 google.auth.transport.requests: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/844138762903-compute@developer.gserviceaccount.com/token
14:21:20 urllib3.connectionpool: DEBUG: http://metadata.google.internal:80 &quot;GET /computeMetadata/v1/instance/service-accounts/844138762903-compute@developer.gserviceaccount.com/token HTTP/1.1&quot; 200 176
14:21:20 urllib3.connectionpool: DEBUG: Starting new HTTPS connection (1): www.googleapis.com:443
14:21:20 urllib3.connectionpool: DEBUG: https://www.googleapis.com:443 &quot;POST /bigquery/v2/projects/apache-beam-testing/jobs HTTP/1.1&quot; 200 None
14:21:20 urllib3.connectionpool: DEBUG: https://www.googleapis.com:443 &quot;GET /bigquery/v2/projects/apache-beam-testing/queries/d08af240-f21f-4d3e-a4d6-123520bd483a?location=US&amp;amp;maxResults=0 HTTP/1.1&quot; 200 None
14:21:20 urllib3.connectionpool: DEBUG: https://www.googleapis.com:443 &quot;GET /bigquery/v2/projects/apache-beam-testing/jobs/d08af240-f21f-4d3e-a4d6-123520bd483a?location=US HTTP/1.1&quot; 200 None
14:21:20 urllib3.connectionpool: DEBUG: https://www.googleapis.com:443 &quot;GET /bigquery/v2/projects/apache-beam-testing/datasets/_7357fab0f784d2a7327ddbe81cdd1f4ca7e429cd/tables/anon99c42be2_6544_4f73_a75e_cef6d47d7c8e/data HTTP/1.1&quot; 200 None
14:21:20 root: INFO: Read from given query (SELECT bytes, date, time FROM `python_query_to_table_15626208616472.output_table`;), total rows 4
14:21:20 root: INFO: Generate checksum: 1631ca7060b89a01760c81874b988c46156e18b5
14:21:20 --------------------- &amp;gt;&amp;gt; end captured logging &amp;lt;&amp;lt; ---------------------
14:21:20 
14:21:20 ----------------------------------------------------------------------
14:21:20 XML: /home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python_Verify_PR/src/sdks/python/nosetests.xml
14:21:20 ----------------------------------------------------------------------
14:21:20 Ran 9 tests in 24.097s
14:21:20 
14:21:20 FAILED (SKIP=1, failures=1)
14:21:20 
14:21:20 &amp;gt; Task :sdks:python:directRunnerIT FAILED
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
</comment>
                            <comment id="16884796" author="tvalentyn" created="Mon, 15 Jul 2019 00:47:25 +0000"  >&lt;p&gt;Renamed the issue to clarify that the failure is in DirectRunner. Also, the error may have to do with the fact that we run this test in parallel in 3 suites on Jenkins. We may be able to reproduce it by running a gradle command that starts all postcommit direct runner suites. If the feedback loop is too long we can try to remove all tests from the suite except for BigQueryQueryToTableIT and retry.&lt;/p&gt;</comment>
                            <comment id="16885306" author="tvalentyn" created="Mon, 15 Jul 2019 14:57:54 +0000"  >&lt;p&gt;I think we should investigate separately the incorrect checksum error and empty assertion error, until we have a reason to believe that the rootcause is the same. &lt;br/&gt;
Let&apos;s use &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-5874&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/BEAM-5874&lt;/a&gt; to track failures due to an incomplete assertion a la&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;13:35:13 Expected: (Test pipeline expected terminated in state: DONE and Expected checksum is e1fbcb5ca479a5ca5f9ecf444d6998beee4d44c6)
13:35:13      but: &quot;
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16885310" author="tvalentyn" created="Mon, 15 Jul 2019 15:01:17 +0000"  >&lt;p&gt;For incorrect checksum error, if we cannot reproduce it, let&apos;s make the error message more informative, so that we can have more information when the issue reoccurs: perhaps print raw table data or don&apos;t clean up the bigquery table so that it can be inspected manually after test execution completes.&lt;br/&gt;
Note that we can configure a TTL on Bigquery tables &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;, so keeping them around after test execution should not be a concern.&lt;br/&gt;
&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://cloud.google.com/bigquery/docs/managing-tables#updating_a_tables_expiration_time&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cloud.google.com/bigquery/docs/managing-tables#updating_a_tables_expiration_time&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16885465" author="pabloem" created="Mon, 15 Jul 2019 18:11:26 +0000"  >&lt;p&gt;gah - I was running on dataflow. &lt;br/&gt;
What&apos;s the best command to run these tests on direct runner?&lt;br/&gt;
I am trying  `./scripts/run_integration_test.sh --runner TestDirectRunner --sdk_location dist/apache-beam-2.15.0.dev0.tar.gz --test_opts --tests=apache_beam.io.gcp.bigquery_write_it_test:BigQueryWriteIntegrationTests.test_big_query_write_new_types` - but it doesn&apos;t look like it&apos;s working properly.&lt;/p&gt;</comment>
                            <comment id="16885473" author="tvalentyn" created="Mon, 15 Jul 2019 18:18:44 +0000"  >&lt;p&gt;We don&apos;t need to pass SDK location.&lt;/p&gt;

&lt;p&gt;This is where the command that runs on Jenkins is evaluated, overall it looks similar to yours:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/beam/blob/5fb21e38d9d0e73db514e13a93c15578302c11fa/sdks/python/test-suites/direct/py35/build.gradle#L50&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/5fb21e38d9d0e73db514e13a93c15578302c11fa/sdks/python/test-suites/direct/py35/build.gradle#L50&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16885665" author="pabloem" created="Mon, 15 Jul 2019 22:40:23 +0000"  >&lt;p&gt;This tests is running in 4s, but they do seem to perform all of the actions that they&apos;re supposed to be performing. I&apos;ve ran it a bunch of times &amp;gt;20, and I&apos;m not seeing any problems.&lt;br/&gt;
It may really be about a specific machine? I&apos;ll investigate further.&lt;/p&gt;</comment>
                            <comment id="16885686" author="pabloem" created="Mon, 15 Jul 2019 23:11:44 +0000"  >&lt;p&gt;FWIW I&apos;m running with Py3.5&lt;/p&gt;</comment>
                            <comment id="16892405" author="tvalentyn" created="Thu, 25 Jul 2019 04:30:50 +0000"  >&lt;p&gt;&lt;a href=&quot;https://github.com/apache/beam/pull/8991&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/8991&lt;/a&gt; may have fixed this.&lt;br/&gt;
CC: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=udim&quot; class=&quot;user-hover&quot; rel=&quot;udim&quot;&gt;udim&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16917294" author="tvalentyn" created="Wed, 28 Aug 2019 00:08:37 +0000"  >&lt;p&gt;Another instance: &lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Expected: (Test pipeline expected terminated in state: DONE and Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214)
     but: Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214 Actual checksum is da39a3ee5e6b4b0d3255bfef95601890afd80709
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/job/beam_PostCommit_Python35/331/testReport/junit/apache_beam.io.gcp.big_query_query_to_table_it_test/BigQueryQueryToTableIT/test_big_query_new_types/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/beam_PostCommit_Python35/331/testReport/junit/apache_beam.io.gcp.big_query_query_to_table_it_test/BigQueryQueryToTableIT/test_big_query_new_types/&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16922814" author="pabloem" created="Wed, 4 Sep 2019 20:01:08 +0000"  >&lt;p&gt;resolved by &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=udim&quot; class=&quot;user-hover&quot; rel=&quot;udim&quot;&gt;udim&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17034991" author="tvalentyn" created="Wed, 12 Feb 2020 02:33:03 +0000"  >&lt;p&gt;Looks like this is still failing, or failing again:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://builds.apache.org/job/beam_PostCommit_Python37_PR/77/testReport/junit/apache_beam.io.gcp.big_query_query_to_table_it_test/BigQueryQueryToTableIT/test_big_query_new_types_native/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://builds.apache.org/job/beam_PostCommit_Python37_PR/77/testReport/junit/apache_beam.io.gcp.big_query_query_to_table_it_test/BigQueryQueryToTableIT/test_big_query_new_types_native/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Expected: (Test pipeline expected terminated in state: DONE and Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214)&lt;br/&gt;
     but: Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214 Actual checksum is da39a3ee5e6b4b0d3255bfef95601890afd80709&lt;/p&gt;</comment>
                            <comment id="17198011" author="tvalentyn" created="Thu, 17 Sep 2020 22:17:52 +0000"  >&lt;p&gt;This is still happening and is one of the top source of flakiness in postcommits.&lt;br/&gt;
Reopening in case any of the prior work provides useful context.&lt;/p&gt;

&lt;p&gt; Sample: &lt;a href=&quot;https://ci-beam.apache.org/job/beam_PostCommit_Python37/2805/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci-beam.apache.org/job/beam_PostCommit_Python37/2805/&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Error Message
Expected: (Test pipeline expected terminated in state: DONE and Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214)
     but: Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214 Actual checksum is da39a3ee5e6b4b0d3255bfef95601890afd80709

-------------------- &amp;gt;&amp;gt; begin captured logging &amp;lt;&amp;lt; --------------------
apache_beam.runners.direct.direct_runner: INFO: Running pipeline with DirectRunner.
apache_beam.io.gcp.bigquery_tools: INFO: Using location &apos;US&apos; from table &amp;lt;TableReference
 datasetId: &apos;python_query_to_table_15998907212925&apos;
 projectId: &apos;apache-beam-testing&apos;
 tableId: &apos;python_new_types_table&apos;&amp;gt; referenced by query SELECT bytes, date, time FROM [python_query_to_table_15998907212925.python_new_types_table]
apache_beam.io.gcp.bigquery_tools: WARNING: Dataset apache-beam-testing:temp_dataset_17c640c2cdb346ea8955d86ad3e60786 does not exist so we will create it as temporary with location=US
urllib3.connectionpool: DEBUG: Starting new HTTP connection (1): metadata:80
urllib3.connectionpool: DEBUG: http://metadata:80 &quot;GET /computeMetadata/v1/instance/attributes/job_id HTTP/1.1&quot; 404 1606
apache_beam.io.gcp.bigquery_tools: DEBUG: Created the table with id output_table
apache_beam.io.gcp.bigquery_tools: INFO: Created table apache-beam-testing.python_query_to_table_15998907212925.output_table with schema &amp;lt;TableSchema
 fields: [&amp;lt;TableFieldSchema
 fields: []
 mode: &apos;NULLABLE&apos;
 name: &apos;bytes&apos;
 type: &apos;BYTES&apos;&amp;gt;, &amp;lt;TableFieldSchema
 fields: []
 mode: &apos;NULLABLE&apos;
 name: &apos;date&apos;
 type: &apos;DATE&apos;&amp;gt;, &amp;lt;TableFieldSchema
 fields: []
 mode: &apos;NULLABLE&apos;
 name: &apos;time&apos;
 type: &apos;TIME&apos;&amp;gt;]&amp;gt;. Result: &amp;lt;Table
 creationTime: 1599890727293
 etag: &apos;tQbsuXVPNUn0ygeb3OnTug==&apos;
 id: &apos;apache-beam-testing:python_query_to_table_15998907212925.output_table&apos;
 kind: &apos;bigquery#table&apos;
 lastModifiedTime: 1599890727421
 location: &apos;US&apos;
 numBytes: 0
 numLongTermBytes: 0
 numRows: 0
 schema: &amp;lt;TableSchema
 fields: [&amp;lt;TableFieldSchema
 fields: []
 mode: &apos;NULLABLE&apos;
 name: &apos;bytes&apos;
 type: &apos;BYTES&apos;&amp;gt;, &amp;lt;TableFieldSchema
 fields: []
 mode: &apos;NULLABLE&apos;
 name: &apos;date&apos;
 type: &apos;DATE&apos;&amp;gt;, &amp;lt;TableFieldSchema
 fields: []
 mode: &apos;NULLABLE&apos;
 name: &apos;time&apos;
 type: &apos;TIME&apos;&amp;gt;]&amp;gt;
 selfLink: &apos;https://bigquery.googleapis.com/bigquery/v2/projects/apache-beam-testing/datasets/python_query_to_table_15998907212925/tables/output_table&apos;
 tableReference: &amp;lt;TableReference
 datasetId: &apos;python_query_to_table_15998907212925&apos;
 projectId: &apos;apache-beam-testing&apos;
 tableId: &apos;output_table&apos;&amp;gt;
 type: &apos;TABLE&apos;&amp;gt;.
apache_beam.io.gcp.bigquery_tools: INFO: Writing 4 rows to apache-beam-testing:python_query_to_table_15998907212925.output_table table.
apache_beam.io.gcp.tests.bigquery_matcher: INFO: Attempting to perform query SELECT bytes, date, time FROM `python_query_to_table_15998907212925.output_table`; to BQ
google.auth._default: DEBUG: Checking None for explicit credentials as part of auth process...
google.auth._default: DEBUG: Checking Cloud SDK credentials as part of auth process...
google.auth._default: DEBUG: Cloud SDK credentials not found on disk; not using them
google.auth._default: DEBUG: Checking for App Engine runtime as part of auth process...
google.auth._default: DEBUG: No App Engine library was found so cannot authentication via App Engine Identity Credentials.
google.auth.transport._http_client: DEBUG: Making request: GET http://169.254.169.254
google.auth.transport._http_client: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/project/project-id
urllib3.util.retry: DEBUG: Converted retries value: 3 -&amp;gt; Retry(total=3, connect=None, read=None, redirect=None, status=None)
google.auth.transport.requests: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true
urllib3.connectionpool: DEBUG: Starting new HTTP connection (1): metadata.google.internal:80
urllib3.connectionpool: DEBUG: http://metadata.google.internal:80 &quot;GET /computeMetadata/v1/instance/service-accounts/default/?recursive=true HTTP/1.1&quot; 200 144
google.auth.transport.requests: DEBUG: Making request: GET http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/844138762903-compute@developer.gserviceaccount.com/token
urllib3.connectionpool: DEBUG: http://metadata.google.internal:80 &quot;GET /computeMetadata/v1/instance/service-accounts/844138762903-compute@developer.gserviceaccount.com/token HTTP/1.1&quot; 200 221
urllib3.connectionpool: DEBUG: Starting new HTTPS connection (1): bigquery.googleapis.com:443
urllib3.connectionpool: DEBUG: https://bigquery.googleapis.com:443 &quot;POST /bigquery/v2/projects/apache-beam-testing/jobs HTTP/1.1&quot; 200 None
urllib3.connectionpool: DEBUG: https://bigquery.googleapis.com:443 &quot;GET /bigquery/v2/projects/apache-beam-testing/queries/ccb82856-c480-43ea-a4f9-1120813ebdaf?maxResults=0&amp;amp;location=US HTTP/1.1&quot; 200 None
urllib3.connectionpool: DEBUG: https://bigquery.googleapis.com:443 &quot;GET /bigquery/v2/projects/apache-beam-testing/datasets/_7357fab0f784d2a7327ddbe81cdd1f4ca7e429cd/tables/anona6eb3fbe74d882a4011ceed2377d0a2ca1258820/data HTTP/1.1&quot; 200 None
apache_beam.io.gcp.tests.bigquery_matcher: INFO: Read from given query (SELECT bytes, date, time FROM `python_query_to_table_15998907212925.output_table`;), total rows 0
apache_beam.io.gcp.tests.bigquery_matcher: INFO: Generate checksum: da39a3ee5e6b4b0d3255bfef95601890afd80709
--------------------- &amp;gt;&amp;gt; end captured logging &amp;lt;&amp;lt; ---------------------
Stacktrace
  File &quot;/usr/lib/python3.7/unittest/case.py&quot;, line 59, in testPartExecutor
    yield
  File &quot;/usr/lib/python3.7/unittest/case.py&quot;, line 615, in run
    testMethod()
  File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python37/src/sdks/python/apache_beam/io/gcp/big_query_query_to_table_it_test.py&quot;, line 310, in test_big_query_new_types_native
    big_query_query_to_table_pipeline.run_bq_pipeline(options)
  File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python37/src/sdks/python/apache_beam/io/gcp/big_query_query_to_table_pipeline.py&quot;, line 113, in run_bq_pipeline
    result = p.run()
  File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python37/src/sdks/python/apache_beam/testing/test_pipeline.py&quot;, line 112, in run
    False if self.not_use_test_runner_api else test_runner_api))
  File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python37/src/sdks/python/apache_beam/pipeline.py&quot;, line 546, in run
    return self.runner.run_pipeline(self, self._options)
  File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python37/src/sdks/python/apache_beam/runners/direct/test_direct_runner.py&quot;, line 53, in run_pipeline
    hc_assert_that(self.result, pickler.loads(on_success_matcher))
  File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python37/src/build/gradleenv/1398941891/lib/python3.7/site-packages/hamcrest/core/assert_that.py&quot;, line 44, in assert_that
    _assert_match(actual=arg1, matcher=arg2, reason=arg3)
  File &quot;/home/jenkins/jenkins-slave/workspace/beam_PostCommit_Python37/src/build/gradleenv/1398941891/lib/python3.7/site-packages/hamcrest/core/assert_that.py&quot;, line 60, in _assert_match
    raise AssertionError(description)

Expected: (Test pipeline expected terminated in state: DONE and Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214)
     but: Expected checksum is 24de460c4d344a4b77ccc4cc1acb7b7ffc11a214 Actual checksum is da39a3ee5e6b4b0d3255bfef95601890afd80709

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="17198519" author="udim" created="Fri, 18 Sep 2020 20:40:01 +0000"  >&lt;p&gt;2805 doesn&apos;t seem to have that error message&lt;/p&gt;</comment>
                            <comment id="17198561" author="tvalentyn" created="Fri, 18 Sep 2020 22:03:45 +0000"  >&lt;p&gt;Sorry, must have copied from a different  suite, here&apos;s a sample: &lt;a href=&quot;https://ci-beam.apache.org/job/beam_PostCommit_Python36/2919&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://ci-beam.apache.org/job/beam_PostCommit_Python36/2919&lt;/a&gt;.&lt;/p&gt;</comment>
                            <comment id="17201184" author="udim" created="Thu, 24 Sep 2020 00:38:19 +0000"  >&lt;p&gt;The verifier is reading back 0 rows. The table seems to be delete only after the verifier has had a chance to read. The logs also say &quot;writing 4 rows&quot;, which implies that the write to output_table either doesn&apos;t happen or is happening asynchronously.&lt;/p&gt;

&lt;p&gt;It seems that writing using direct runner in native mode (BigQuerySink) falls back to using streaming inserts. (BigQueryWriter)&lt;br/&gt;
The more maintained version of streaming inserts is in BigQueryWriteFn (via WriteToBigQuery).&lt;br/&gt;
Both use BigQueryWrapper.insert_rows() however as the implementation.&lt;/p&gt;

&lt;p&gt;Note that the other tests in this class use BQ Load jobs to write. (95% sure)&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Streaming inserts reside temporarily in the streaming buffer, which has different availability characteristics than managed storage.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/bigquery/docs/error-messages#missingunavailable-data&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cloud.google.com/bigquery/docs/error-messages#missingunavailable-data&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Also: &lt;a href=&quot;https://cloud.google.com/bigquery/streaming-data-into-bigquery#dataavailability&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://cloud.google.com/bigquery/streaming-data-into-bigquery#dataavailability&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My conclusion is that this test is depending on streamed data to be immediately available, but that is not guaranteed.&lt;br/&gt;
Suggested solution is to modify the matcher to retry for a few seconds until the streaming buffer has been processed (like BigqueryFullResultStreamingMatcher).&lt;/p&gt;</comment>
                            <comment id="17210453" author="udim" created="Thu, 8 Oct 2020 21:04:40 +0000"  >&lt;p&gt;Seems to be resolved&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 5 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z039rs:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>