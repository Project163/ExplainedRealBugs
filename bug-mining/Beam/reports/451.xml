<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 10:47:22 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-981] Not possible to directly submit a pipeline on spark cluster</title>
                <link>https://issues.apache.org/jira/browse/BEAM-981</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>&lt;p&gt;It&apos;s not possible to directly run a pipeline on the spark runner (for instance using &lt;tt&gt;mvn exec:java&lt;/tt&gt;. It fails with:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;[appclient-register-master-threadpool-0] INFO org.apache.spark.deploy.client.AppClient$ClientEndpoint - Connecting to master spark:&lt;span class=&quot;code-comment&quot;&gt;//10.200.118.197:7077...
&lt;/span&gt;[shuffle-client-0] ERROR org.apache.spark.network.client.TransportClient - Failed to send RPC 6813731522650020739 to /10.200.118.197:7077: java.lang.AbstractMethodError: org.apache.spark.network.protocol.MessageWithHeader.touch(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)Lio/netty/util/ReferenceCounted;
java.lang.AbstractMethodError: org.apache.spark.network.protocol.MessageWithHeader.touch(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)Lio/netty/util/ReferenceCounted;
        at io.netty.util.ReferenceCountUtil.touch(ReferenceCountUtil.java:73)
        at io.netty.channel.DefaultChannelPipeline.touch(DefaultChannelPipeline.java:107)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:820)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:733)
        at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:111)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:748)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:740)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:826)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:733)
        at io.netty.handler.timeout.IdleStateHandler.write(IdleStateHandler.java:284)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:748)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:740)
        at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
        at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1101)
        at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1148)
        at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1090)
        at io.netty.util.concurrent.SingleThreadEventExecutor.safeExecute(SingleThreadEventExecutor.java:451)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:418)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:401)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:877)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
[appclient-register-master-threadpool-0] WARN org.apache.spark.deploy.client.AppClient$ClientEndpoint - Failed to connect to master 10.200.118.197:7077
java.io.IOException: Failed to send RPC 6813731522650020739 to /10.200.118.197:7077: java.lang.AbstractMethodError: org.apache.spark.network.protocol.MessageWithHeader.touch(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)Lio/netty/util/ReferenceCounted;
        at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:239)
        at org.apache.spark.network.client.TransportClient$3.operationComplete(TransportClient.java:226)
        at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:514)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:507)
        at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:486)
        at io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:427)
        at io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:129)
        at io.netty.channel.AbstractChannelHandlerContext.notifyOutboundHandlerException(AbstractChannelHandlerContext.java:845)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:750)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:740)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:826)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:733)
        at io.netty.handler.timeout.IdleStateHandler.write(IdleStateHandler.java:284)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:748)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite(AbstractChannelHandlerContext.java:740)
        at io.netty.channel.AbstractChannelHandlerContext.access$1900(AbstractChannelHandlerContext.java:38)
        at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.write(AbstractChannelHandlerContext.java:1101)
        at io.netty.channel.AbstractChannelHandlerContext$WriteAndFlushTask.write(AbstractChannelHandlerContext.java:1148)
        at io.netty.channel.AbstractChannelHandlerContext$AbstractWriteTask.run(AbstractChannelHandlerContext.java:1090)
        at io.netty.util.concurrent.SingleThreadEventExecutor.safeExecute(SingleThreadEventExecutor.java:451)
        at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:418)
        at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:401)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:877)
        at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:745)
Caused by: java.lang.AbstractMethodError: org.apache.spark.network.protocol.MessageWithHeader.touch(Ljava/lang/&lt;span class=&quot;code-object&quot;&gt;Object&lt;/span&gt;;)Lio/netty/util/ReferenceCounted;
        at io.netty.util.ReferenceCountUtil.touch(ReferenceCountUtil.java:73)
        at io.netty.channel.DefaultChannelPipeline.touch(DefaultChannelPipeline.java:107)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:820)
        at io.netty.channel.AbstractChannelHandlerContext.write(AbstractChannelHandlerContext.java:733)
        at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:111)
        at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:748)
        ... 15 more
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It looks like a conflict between the Netty version used in Spark and the one in Beam (just guessing).&lt;/p&gt;

&lt;p&gt;The workaround is to use &lt;tt&gt;spark-submit&lt;/tt&gt;.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13020847">BEAM-981</key>
            <summary>Not possible to directly submit a pipeline on spark cluster</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10102" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">P2</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="5">Cannot Reproduce</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="jbonofre">Jean-Baptiste Onofr&#233;</reporter>
                        <labels>
                    </labels>
                <created>Tue, 15 Nov 2016 16:52:57 +0000</created>
                <updated>Sat, 16 May 2020 14:18:29 +0000</updated>
                            <resolved>Thu, 5 Mar 2020 12:05:05 +0000</resolved>
                                    <version>0.6.0</version>
                                    <fixVersion>Not applicable</fixVersion>
                                    <component>runner-spark</component>
                        <due></due>
                            <votes>1</votes>
                                    <watches>12</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="1200">20m</timespent>
                                                        <aggregatetimeremainingestimate seconds="0">0h</aggregatetimeremainingestimate>
                                        <aggregatetimespent seconds="1200">20m</aggregatetimespent>
                                    <comments>
                            <comment id="15689574" author="amitsela" created="Wed, 23 Nov 2016 09:52:10 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbonofre&quot; class=&quot;user-hover&quot; rel=&quot;jbonofre&quot;&gt;jbonofre&lt;/a&gt; you&apos;ve encountered this again lately, no ? any new input ? thanks.&lt;/p&gt;</comment>
                            <comment id="15689580" author="amitsela" created="Wed, 23 Nov 2016 09:54:11 +0000"  >&lt;p&gt;Anyway, I&apos;ll add that &lt;tt&gt;spark-submit&lt;/tt&gt; is considered to be the &quot;right way&quot; to submit to cluster with YARN for example: &lt;a href=&quot;http://spark.apache.org/docs/latest/running-on-yarn.html#launching-spark-on-yarn&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://spark.apache.org/docs/latest/running-on-yarn.html#launching-spark-on-yarn&lt;/a&gt; &lt;/p&gt;</comment>
                            <comment id="15689618" author="jbonofre" created="Wed, 23 Nov 2016 10:05:19 +0000"  >&lt;p&gt;Agree: I also prefer &lt;tt&gt;spark-submit&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;However, it would be great to fix the issue. I got this issue with SNAPSHOT from last week. Let me try to reproduce with the latest SNAPSHOT.&lt;/p&gt;</comment>
                            <comment id="15883644" author="amitsela" created="Fri, 24 Feb 2017 22:32:02 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbonofre&quot; class=&quot;user-hover&quot; rel=&quot;jbonofre&quot;&gt;jbonofre&lt;/a&gt; any news on this one ?&lt;/p&gt;</comment>
                            <comment id="15957480" author="amitsela" created="Wed, 5 Apr 2017 19:18:08 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iemejia&quot; class=&quot;user-hover&quot; rel=&quot;iemejia&quot;&gt;iemejia&lt;/a&gt; wold you mind taking a look at this one ? we should be able to submit programatically to a Spark cluster.&lt;/p&gt;</comment>
                            <comment id="15992305" author="holdenk" created="Tue, 2 May 2017 04:05:26 +0000"  >&lt;p&gt;I can take a look at this later on this week if no one else is.&lt;/p&gt;</comment>
                            <comment id="15993369" author="ksalant" created="Tue, 2 May 2017 17:38:40 +0000"  >&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;I will try to finish it till end of the week. I will let you know if it&lt;br/&gt;
doesn&apos;t happen.&lt;/p&gt;

&lt;p&gt;Thanks for the suggestion&lt;br/&gt;
Kobi&lt;/p&gt;

</comment>
                            <comment id="15999608" author="holdenk" created="Sat, 6 May 2017 22:05:47 +0000"  >&lt;p&gt;Sure thing, no mean to pressure - but let me know if I can help or answer any questions on the Spark side of things &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;</comment>
                            <comment id="16001072" author="davor" created="Mon, 8 May 2017 16:49:00 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=ksalant&quot; class=&quot;user-hover&quot; rel=&quot;ksalant&quot;&gt;ksalant&lt;/a&gt;, any updated ETA? For the first stable release, this would need to get in in the next 1-2 days.&lt;/p&gt;</comment>
                            <comment id="16001091" author="ksalant" created="Mon, 8 May 2017 17:00:40 +0000"  >&lt;p&gt;I will try to finish it by tomorrow. If not i will ask for help&lt;/p&gt;

</comment>
                            <comment id="16003407" author="ksalant" created="Tue, 9 May 2017 19:49:34 +0000"  >&lt;p&gt;The error shown in the description is caused by conflicting netty dependencies between spark and beam-sdks-java-io-google-cloud-platform module.&lt;br/&gt;
io.netty.util.ReferenceCounted is included in netty-all version 4.0.29.final from spark dependency.&lt;br/&gt;
The same class is also brought by beam-sdks-java-io-google-cloud-platform from its grpc-netty dependency, this time from netty-common version 4.1.8.final.&lt;br/&gt;
The two classes have different abstract methods and org.apache.spark.network.protocol.MessageWithHeader implements only the 4.0.29.final version. &lt;br/&gt;
I have created a PR &lt;a href=&quot;https://github.com/apache/beam/pull/2997&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/2997&lt;/a&gt; not to handle the conflict which is simply a matter of fixing the application&apos;s dependencies but to add the ability to pass jars via the SparkPipelineOptions to SparkConf so all the needed classes will be available to the application.&lt;br/&gt;
I have tested this on the archetype using the shaded packaged jar on a remote cluster  &lt;/p&gt;</comment>
                            <comment id="16004990" author="aviemzur" created="Wed, 10 May 2017 16:42:25 +0000"  >&lt;p&gt;Moving this to version 2.1.0 as it is not a blocker for 2.0.0 and can be added later without breaking existing APIs.&lt;/p&gt;</comment>
                            <comment id="16014562" author="kenn" created="Wed, 17 May 2017 18:29:07 +0000"  >&lt;p&gt;I think we should drop the fix version for work that is ongoing, and set it up when it gets fixed. The first stable release needed an explicit burndown, but going forward releases should be mostly time based.&lt;/p&gt;

&lt;p&gt;If the version helps your own tracking, or you want to be sure the release manager for 2.1.0 tracks it, please feel free to re-add a fix version.&lt;/p&gt;</comment>
                            <comment id="16020933" author="p.wojcik" created="Tue, 23 May 2017 09:23:04 +0000"  >&lt;p&gt;Hello, I&apos;ve also encountered the error, do I gather correctly that the fix wasn&apos;t delivered in 2.1.1?&lt;/p&gt;</comment>
                            <comment id="16021025" author="ksalant" created="Tue, 23 May 2017 10:49:40 +0000"  >&lt;p&gt;Hi Piotr,&lt;/p&gt;

&lt;p&gt;The fix was not merged yet&lt;/p&gt;

</comment>
                            <comment id="16068139" author="p.wojcik" created="Thu, 29 Jun 2017 10:34:36 +0000"  >&lt;p&gt;Hello, are you going to merge the fix into the new release?&lt;/p&gt;</comment>
                            <comment id="16287942" author="githubbot" created="Tue, 12 Dec 2017 17:23:17 +0000"  >&lt;p&gt;lgajowy opened a new pull request #4246: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-981&quot; title=&quot;Not possible to directly submit a pipeline on spark cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-981&quot;&gt;&lt;del&gt;BEAM-981&lt;/del&gt;&lt;/a&gt; Add parameter allowing adding jars to spark context&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/beam/pull/4246&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/4246&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Follow this checklist to help us incorporate your contribution quickly and easily:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;[ ] Make sure there is a &lt;span class=&quot;error&quot;&gt;&amp;#91;JIRA issue&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://issues.apache.org/jira/projects/BEAM/issues/&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/projects/BEAM/issues/&lt;/a&gt;) filed for the change (usually before you start working on it).  Trivial changes like typos do not require a JIRA issue.  Your pull request should address just this issue, without pulling in other changes.&lt;/li&gt;
	&lt;li&gt;[ ] Each commit in the pull request should have a meaningful subject line and body.&lt;/li&gt;
	&lt;li&gt;[ ] Format the pull request title like `&lt;span class=&quot;error&quot;&gt;&amp;#91;BEAM-XXX&amp;#93;&lt;/span&gt; Fixes bug in ApproximateQuantiles`, where you replace `BEAM-XXX` with the appropriate JIRA issue.&lt;/li&gt;
	&lt;li&gt;[ ] Write a pull request description that is detailed enough to understand what the pull request does, how, and why.&lt;/li&gt;
	&lt;li&gt;[ ] Run `mvn clean verify` to make sure basic checks pass. A more thorough check will be performed on your pull request automatically.&lt;/li&gt;
	&lt;li&gt;[ ] If this contribution is large, please file an Apache &lt;span class=&quot;error&quot;&gt;&amp;#91;Individual Contributor License Agreement&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://www.apache.org/licenses/icla.pdf&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://www.apache.org/licenses/icla.pdf&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   &amp;#8212;&lt;/p&gt;

&lt;p&gt;   This is a PR for &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-981&quot; title=&quot;Not possible to directly submit a pipeline on spark cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-981&quot;&gt;&lt;del&gt;BEAM-981&lt;/del&gt;&lt;/a&gt;. I hope that&apos;s ok to submit this PR because the 981 issue seems to be abandoned. Another reason to post this is that this PR also (partially) solves &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-1603&quot; title=&quot;Enable programmatic execution of spark pipelines.&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-1603&quot;&gt;&lt;del&gt;BEAM-1603&lt;/del&gt;&lt;/a&gt;: by adding appropriate test.jar and shaded.jar file to Spark&apos;s classpath (using SparkConfs `addJar()`) we are able to run the IOITs on Spark cluster without the spark-submit tool. This in turn makes it possible to run the tests using PerfKit Benchmarker Tool easily, so it&apos;s quite crucial to us. &lt;/p&gt;

&lt;p&gt;   @lukecwik could you review this, as you seem to know the topic well?&lt;br/&gt;
   @jbonofre does this change interfere in any way with migrating spark to 2.x version?&lt;br/&gt;
   @jasonkuster fyi &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;&lt;/p&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16300313" author="githubbot" created="Thu, 21 Dec 2017 17:24:24 +0000"  >&lt;p&gt;asfgit closed pull request #4246: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-981&quot; title=&quot;Not possible to directly submit a pipeline on spark cluster&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-981&quot;&gt;&lt;del&gt;BEAM-981&lt;/del&gt;&lt;/a&gt; Add parameter allowing adding jars to spark context&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/beam/pull/4246&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/4246&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/PipelineResources.java b/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/PipelineResources.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..ae6b076acf2&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/PipelineResources.java&lt;br/&gt;
@@ -0,0 +1,57 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.beam.runners.core.construction;&lt;br/&gt;
+&lt;br/&gt;
+import java.io.File;&lt;br/&gt;
+import java.net.URISyntaxException;&lt;br/&gt;
+import java.net.URL;&lt;br/&gt;
+import java.net.URLClassLoader;&lt;br/&gt;
+import java.util.ArrayList;&lt;br/&gt;
+import java.util.List;&lt;br/&gt;
+&lt;br/&gt;
+/** Utilities for working with classpath resources for pipelines. */&lt;br/&gt;
+public class PipelineResources {&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Attempts to detect all the resources the class loader has access to. This does not recurse&lt;br/&gt;
+   * to class loader parents stopping it from pulling in resources from the system class loader.&lt;br/&gt;
+   *&lt;br/&gt;
+   * @param classLoader The URLClassLoader to use to detect resources to stage.&lt;br/&gt;
+   * @throws IllegalArgumentException  If either the class loader is not a URLClassLoader or one&lt;br/&gt;
+   * of the resources the class loader exposes is not a file resource.&lt;br/&gt;
+   * @return A list of absolute paths to the resources the class loader uses.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static List&amp;lt;String&amp;gt; detectClassPathResourcesToStage(ClassLoader classLoader) {&lt;br/&gt;
+    if (!(classLoader instanceof URLClassLoader)) &lt;/p&gt;
{
+      String message = String.format(&quot;Unable to use ClassLoader to detect classpath elements. &quot;
+          + &quot;Current ClassLoader is %s, only URLClassLoaders are supported.&quot;, classLoader);
+      throw new IllegalArgumentException(message);
+    }
&lt;p&gt;+&lt;br/&gt;
+    List&amp;lt;String&amp;gt; files = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
+    for (URL url : ((URLClassLoader) classLoader).getURLs()) {&lt;br/&gt;
+      try &lt;/p&gt;
{
+        files.add(new File(url.toURI()).getAbsolutePath());
+      }
&lt;p&gt; catch (IllegalArgumentException | URISyntaxException e) &lt;/p&gt;
{
+        String message = String.format(&quot;Unable to convert url (%s) to file.&quot;, url);
+        throw new IllegalArgumentException(message, e);
+      }
&lt;p&gt;+    }&lt;br/&gt;
+    return files;&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/runners/core-construction-java/src/test/java/org/apache/beam/runners/core/construction/PipelineResourcesTest.java b/runners/core-construction-java/src/test/java/org/apache/beam/runners/core/construction/PipelineResourcesTest.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..633df01246f&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/runners/core-construction-java/src/test/java/org/apache/beam/runners/core/construction/PipelineResourcesTest.java&lt;br/&gt;
@@ -0,0 +1,76 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.beam.runners.core.construction;&lt;br/&gt;
+&lt;br/&gt;
+import static org.junit.Assert.assertEquals;&lt;br/&gt;
+&lt;br/&gt;
+import com.google.common.collect.ImmutableList;&lt;br/&gt;
+import java.io.File;&lt;br/&gt;
+import java.net.URL;&lt;br/&gt;
+import java.net.URLClassLoader;&lt;br/&gt;
+import org.junit.Rule;&lt;br/&gt;
+import org.junit.Test;&lt;br/&gt;
+import org.junit.rules.ExpectedException;&lt;br/&gt;
+import org.junit.rules.TemporaryFolder;&lt;br/&gt;
+import org.junit.runner.RunWith;&lt;br/&gt;
+import org.junit.runners.JUnit4;&lt;br/&gt;
+import org.mockito.Mockito;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Tests for PipelineResources.&lt;br/&gt;
+ */&lt;br/&gt;
+@RunWith(JUnit4.class)&lt;br/&gt;
+public class PipelineResourcesTest {&lt;br/&gt;
+&lt;br/&gt;
+  @Rule public transient TemporaryFolder tmpFolder = new TemporaryFolder();&lt;br/&gt;
+  @Rule public transient ExpectedException thrown = ExpectedException.none();&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void detectClassPathResourceWithFileResources() throws Exception {&lt;br/&gt;
+    File file = tmpFolder.newFile(&quot;file&quot;);&lt;br/&gt;
+    File file2 = tmpFolder.newFile(&quot;file2&quot;);&lt;br/&gt;
+    URLClassLoader classLoader = new URLClassLoader(new URL[] &lt;/p&gt;
{
+        file.toURI().toURL(),
+        file2.toURI().toURL()
+    }
&lt;p&gt;);&lt;br/&gt;
+&lt;br/&gt;
+    assertEquals(ImmutableList.of(file.getAbsolutePath(), file2.getAbsolutePath()),&lt;br/&gt;
+        PipelineResources.detectClassPathResourcesToStage(classLoader));&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void detectClassPathResourcesWithUnsupportedClassLoader() &lt;/p&gt;
{
+    ClassLoader mockClassLoader = Mockito.mock(ClassLoader.class);
+    thrown.expect(IllegalArgumentException.class);
+    thrown.expectMessage(&quot;Unable to use ClassLoader to detect classpath elements.&quot;);
+
+    PipelineResources.detectClassPathResourcesToStage(mockClassLoader);
+  }
&lt;p&gt;+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void detectClassPathResourceWithNonFileResources() throws Exception {&lt;br/&gt;
+    String url = &quot;http://www.google.com/all-the-secrets.jar&quot;;&lt;br/&gt;
+    URLClassLoader classLoader = new URLClassLoader(new URL[] &lt;/p&gt;
{
+        new URL(url)
+    }
&lt;p&gt;);&lt;br/&gt;
+    thrown.expect(IllegalArgumentException.class);&lt;br/&gt;
+    thrown.expectMessage(&quot;Unable to convert url (&quot; + url + &quot;) to file.&quot;);&lt;br/&gt;
+&lt;br/&gt;
+    PipelineResources.detectClassPathResourcesToStage(classLoader);&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineOptions.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineOptions.java&lt;br/&gt;
index 2432394f464..01f78473ed0 100644&lt;br/&gt;
&amp;#8212; a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineOptions.java&lt;br/&gt;
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkPipelineOptions.java&lt;br/&gt;
@@ -43,7 +43,6 @@&lt;br/&gt;
    */&lt;br/&gt;
   @Description(&quot;Jar-Files to send to all workers and put on the classpath. &quot;&lt;br/&gt;
       + &quot;The default value is all files from the classpath.&quot;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@JsonIgnore&lt;br/&gt;
   List&amp;lt;String&amp;gt; getFilesToStage();&lt;br/&gt;
   void setFilesToStage(List&amp;lt;String&amp;gt; value);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkRunner.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkRunner.java&lt;br/&gt;
index ca12615be03..5fdcdcec121 100644&lt;br/&gt;
&amp;#8212; a/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkRunner.java&lt;br/&gt;
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkRunner.java&lt;br/&gt;
@@ -17,14 +17,11 @@&lt;br/&gt;
  */&lt;br/&gt;
 package org.apache.beam.runners.flink;&lt;/p&gt;

&lt;p&gt;+import static org.apache.beam.runners.core.construction.PipelineResources.detectClassPathResourcesToStage;&lt;br/&gt;
+&lt;br/&gt;
 import com.google.common.base.Joiner;&lt;br/&gt;
-import java.io.File;&lt;br/&gt;
-import java.net.URISyntaxException;&lt;br/&gt;
-import java.net.URL;&lt;br/&gt;
-import java.net.URLClassLoader;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.HashSet;&lt;br/&gt;
-import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
 import java.util.SortedSet;&lt;br/&gt;
@@ -150,36 +147,7 @@ public String toString() &lt;/p&gt;
{
     return &quot;FlinkRunner#&quot; + hashCode();
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Attempts to detect all the resources the class loader has access to. This does not recurse&lt;/li&gt;
	&lt;li&gt;* to class loader parents stopping it from pulling in resources from the system class loader.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @param classLoader The URLClassLoader to use to detect resources to stage.&lt;/li&gt;
	&lt;li&gt;* @return A list of absolute paths to the resources the class loader uses.&lt;/li&gt;
	&lt;li&gt;* @throws IllegalArgumentException If either the class loader is not a URLClassLoader or one&lt;/li&gt;
	&lt;li&gt;*   of the resources the class loader exposes is not a file resource.&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;protected static List&amp;lt;String&amp;gt; detectClassPathResourcesToStage(&lt;/li&gt;
	&lt;li&gt;ClassLoader classLoader) {&lt;/li&gt;
	&lt;li&gt;if (!(classLoader instanceof URLClassLoader)) 
{
-      String message = String.format(&quot;Unable to use ClassLoader to detect classpath elements. &quot;
-          + &quot;Current ClassLoader is %s, only URLClassLoaders are supported.&quot;, classLoader);
-      LOG.error(message);
-      throw new IllegalArgumentException(message);
-    }&lt;br/&gt;
 &lt;br/&gt;
-    List&amp;lt;String&amp;gt; files = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
-    for (URL url : ((URLClassLoader) classLoader).getURLs()) {&lt;br/&gt;
-      try {
-        files.add(new File(url.toURI()).getAbsolutePath());
-      } catch (IllegalArgumentException | URISyntaxException e) {
-        String message = String.format(&quot;Unable to convert url (%s) to file.&quot;, url);
-        LOG.error(message);
-        throw new IllegalArgumentException(message, e);
-      }&lt;br/&gt;
-    }&lt;br/&gt;
-    return files;&lt;br/&gt;
-  }&lt;br/&gt;
 &lt;br/&gt;
   /** A set of {@link View}s with non-deterministic key coders. */&lt;br/&gt;
   Set&amp;lt;PTransform&amp;lt;?, ?&amp;gt;&amp;gt; ptransformViewsWithNonDeterministicKeyCoders;&lt;br/&gt;
diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java&lt;br/&gt;
index a6500924149..025134477ed 100644&lt;br/&gt;
&amp;#8212; a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java&lt;br/&gt;
+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java&lt;br/&gt;
@@ -21,6 +21,7 @@&lt;br/&gt;
 import static com.google.common.base.Preconditions.checkArgument;&lt;br/&gt;
 import static com.google.common.base.Preconditions.checkState;&lt;br/&gt;
 import static com.google.common.base.Strings.isNullOrEmpty;&lt;br/&gt;
+import static org.apache.beam.runners.core.construction.PipelineResources.detectClassPathResourcesToStage;&lt;br/&gt;
 import static org.apache.beam.sdk.util.SerializableUtils.serializeToByteArray;&lt;br/&gt;
 import static org.apache.beam.sdk.util.StringUtils.byteArrayToJsonString;&lt;br/&gt;
 &lt;br/&gt;
@@ -40,12 +41,8 @@&lt;br/&gt;
 import com.google.common.collect.ImmutableList;&lt;br/&gt;
 import com.google.common.collect.ImmutableMap;&lt;br/&gt;
 import com.google.common.collect.Iterables;&lt;br/&gt;
-import java.io.File;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.io.PrintWriter;&lt;br/&gt;
-import java.net.URISyntaxException;&lt;br/&gt;
-import java.net.URL;&lt;br/&gt;
-import java.net.URLClassLoader;&lt;br/&gt;
 import java.nio.channels.Channels;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
@@ -253,9 +250,9 @@ public static DataflowRunner fromOptions(PipelineOptions options) {
         throw new IllegalArgumentException(&quot;No files to stage has been found.&quot;);
       } else {&lt;br/&gt;
         LOG.info(&quot;PipelineOptions.filesToStage was not specified. &quot;&lt;br/&gt;
-                        + &quot;Defaulting to files from the classpath: will stage {} files. &quot;&lt;br/&gt;
-                        + &quot;Enable logging at DEBUG level to see which files will be staged.&quot;,&lt;br/&gt;
-                dataflowOptions.getFilesToStage().size());&lt;br/&gt;
+                + &quot;Defaulting to files from the classpath: will stage {} files. &quot;&lt;br/&gt;
+                + &quot;Enable logging at DEBUG level to see which files will be staged.&quot;,&lt;br/&gt;
+            dataflowOptions.getFilesToStage().size());&lt;br/&gt;
         LOG.debug(&quot;Classpath elements: {}&quot;, dataflowOptions.getFilesToStage());&lt;br/&gt;
       }&lt;br/&gt;
     }&lt;br/&gt;
@@ -1478,36 +1475,6 @@ public String toString() {
     return &quot;DataflowRunner#&quot; + options.getJobName();
   }&lt;br/&gt;
 &lt;br/&gt;
-  /**&lt;br/&gt;
-   * Attempts to detect all the resources the class loader has access to. This does not recurse&lt;br/&gt;
-   * to class loader parents stopping it from pulling in resources from the system class loader.&lt;br/&gt;
-   *&lt;br/&gt;
-   * @param classLoader The URLClassLoader to use to detect resources to stage.&lt;br/&gt;
-   * @throws IllegalArgumentException  If either the class loader is not a URLClassLoader or one&lt;br/&gt;
-   * of the resources the class loader exposes is not a file resource.&lt;br/&gt;
-   * @return A list of absolute paths to the resources the class loader uses.&lt;br/&gt;
-   */&lt;br/&gt;
-  protected static List&amp;lt;String&amp;gt; detectClassPathResourcesToStage(ClassLoader classLoader) {&lt;br/&gt;
-    if (!(classLoader instanceof URLClassLoader)) {-      String message = String.format(&quot;Unable to use ClassLoader to detect classpath elements. &quot;-          + &quot;Current ClassLoader is %s, only URLClassLoaders are supported.&quot;, classLoader);-      LOG.error(message);-      throw new IllegalArgumentException(message);-    }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;List&amp;lt;String&amp;gt; files = new ArrayList&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;for (URL url : ((URLClassLoader) classLoader).getURLs()) {&lt;/li&gt;
	&lt;li&gt;try 
{
-        files.add(new File(url.toURI()).getAbsolutePath());
-      }
&lt;p&gt; catch (IllegalArgumentException | URISyntaxException e) &lt;/p&gt;
{
-        String message = String.format(&quot;Unable to convert url (%s) to file.&quot;, url);
-        LOG.error(message);
-        throw new IllegalArgumentException(message, e);
-      }&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;return files;&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
   /**&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Finds the id for the running job of the given name.&lt;br/&gt;
    */&lt;br/&gt;
diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/options/DataflowPipelineWorkerPoolOptions.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/options/DataflowPipelineWorkerPoolOptions.java&lt;br/&gt;
index 2239462ac2e..b02869b45de 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/options/DataflowPipelineWorkerPoolOptions.java&lt;br/&gt;
+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/options/DataflowPipelineWorkerPoolOptions.java&lt;br/&gt;
@@ -199,7 +199,6 @@ public String create(PipelineOptions options) {&lt;br/&gt;
   @Description(&quot;Files to stage on GCS and make available to workers. &quot;&lt;br/&gt;
       + &quot;Files are placed on the worker&apos;s classpath. &quot;&lt;br/&gt;
       + &quot;The default value is all files from the classpath.&quot;)&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@JsonIgnore&lt;br/&gt;
   List&amp;lt;String&amp;gt; getFilesToStage();&lt;br/&gt;
   void setFilesToStage(List&amp;lt;String&amp;gt; value);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java&lt;br/&gt;
index edf513b7c94..90748aff329 100644&lt;br/&gt;
&amp;#8212; a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java&lt;br/&gt;
+++ b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java&lt;br/&gt;
@@ -53,8 +53,6 @@&lt;br/&gt;
 import java.io.FileNotFoundException;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.io.Serializable;&lt;br/&gt;
-import java.net.URL;&lt;br/&gt;
-import java.net.URLClassLoader;&lt;br/&gt;
 import java.nio.channels.FileChannel;&lt;br/&gt;
 import java.nio.channels.SeekableByteChannel;&lt;br/&gt;
 import java.nio.file.Files;&lt;br/&gt;
@@ -627,40 +625,6 @@ public void runWithDefaultFilesToStage() throws Exception &lt;/p&gt;
{
     assertTrue(!options.getFilesToStage().isEmpty());
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void detectClassPathResourceWithFileResources() throws Exception {&lt;/li&gt;
	&lt;li&gt;File file = tmpFolder.newFile(&quot;file&quot;);&lt;/li&gt;
	&lt;li&gt;File file2 = tmpFolder.newFile(&quot;file2&quot;);&lt;/li&gt;
	&lt;li&gt;URLClassLoader classLoader = new URLClassLoader(new URL[] 
{
-        file.toURI().toURL(),
-        file2.toURI().toURL()
-    }
&lt;p&gt;);&lt;br/&gt;
-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;assertEquals(ImmutableList.of(file.getAbsolutePath(), file2.getAbsolutePath()),&lt;/li&gt;
	&lt;li&gt;DataflowRunner.detectClassPathResourcesToStage(classLoader));&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void detectClassPathResourcesWithUnsupportedClassLoader() 
{
-    ClassLoader mockClassLoader = Mockito.mock(ClassLoader.class);
-    thrown.expect(IllegalArgumentException.class);
-    thrown.expectMessage(&quot;Unable to use ClassLoader to detect classpath elements.&quot;);
-
-    DataflowRunner.detectClassPathResourcesToStage(mockClassLoader);
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Test&lt;/li&gt;
	&lt;li&gt;public void detectClassPathResourceWithNonFileResources() throws Exception {&lt;/li&gt;
	&lt;li&gt;String url = &quot;http://www.google.com/all-the-secrets.jar&quot;;&lt;/li&gt;
	&lt;li&gt;URLClassLoader classLoader = new URLClassLoader(new URL[] 
{
-        new URL(url)
-    }
&lt;p&gt;);&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;thrown.expect(IllegalArgumentException.class);&lt;/li&gt;
	&lt;li&gt;thrown.expectMessage(&quot;Unable to convert url (&quot; + url + &quot;) to file.&quot;);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;DataflowRunner.detectClassPathResourcesToStage(classLoader);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testGcsStagingLocationInitialization() throws Exception {&lt;br/&gt;
     // Set temp location (required), and check that staging location is set.&lt;br/&gt;
diff --git a/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkContextOptions.java b/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkContextOptions.java&lt;br/&gt;
index 98f74923931..0a7995f744f 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkContextOptions.java&lt;br/&gt;
+++ b/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkContextOptions.java&lt;br/&gt;
@@ -54,7 +54,7 @@&lt;br/&gt;
   List&amp;lt;JavaStreamingListener&amp;gt; getListeners();&lt;br/&gt;
   void setListeners(List&amp;lt;JavaStreamingListener&amp;gt; listeners);&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/** Returns an empty list, top avoid handling null. */&lt;br/&gt;
+  /** Returns an empty list, to avoid handling null. */&lt;br/&gt;
   class EmptyListenersList implements DefaultValueFactory&amp;lt;List&amp;lt;JavaStreamingListener&amp;gt;&amp;gt; {&lt;br/&gt;
     @Override&lt;br/&gt;
     public List&amp;lt;JavaStreamingListener&amp;gt; create(PipelineOptions options) {&lt;br/&gt;
diff --git a/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkPipelineOptions.java b/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkPipelineOptions.java&lt;br/&gt;
index 26b549baa2e..2db82090cad 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkPipelineOptions.java&lt;br/&gt;
+++ b/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkPipelineOptions.java&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; package org.apache.beam.runners.spark;&lt;/p&gt;

&lt;p&gt;+import java.util.List;&lt;br/&gt;
 import org.apache.beam.sdk.options.ApplicationNameOptions;&lt;br/&gt;
 import org.apache.beam.sdk.options.Default;&lt;br/&gt;
 import org.apache.beam.sdk.options.DefaultValueFactory;&lt;br/&gt;
@@ -25,8 +26,6 @@&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.options.StreamingOptions;&lt;/p&gt;

&lt;p&gt;-&lt;br/&gt;
-&lt;br/&gt;
 /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Spark runner 
{@link PipelineOptions}
&lt;p&gt; handles Spark execution-related configurations,&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;such as the master address, batch-interval, and other user-related knobs.&lt;br/&gt;
@@ -101,4 +100,15 @@ public String create(PipelineOptions options) 
{
   boolean getUsesProvidedSparkContext();
   void setUsesProvidedSparkContext(boolean value);
 
+  /**
+   * List of local files to make available to workers.
+   *
+   * &amp;lt;p&amp;gt;Jars are placed on the worker&apos;s classpath.
+   *
+   * &amp;lt;p&amp;gt;The default value is the list of jars from the main program&apos;s classpath.
+   */
+  @Description(&quot;Jar-Files to send to all workers and put on the classpath. &quot;
+      + &quot;The default value is all files from the classpath.&quot;)
+  List&amp;lt;String&amp;gt; getFilesToStage();
+  void setFilesToStage(List&amp;lt;String&amp;gt; value);
 }
&lt;p&gt;diff --git a/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkRunner.java b/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkRunner.java&lt;br/&gt;
index 4a409cb9005..3495382e921 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkRunner.java&lt;br/&gt;
+++ b/runners/spark/src/main/java/org/apache/beam/runners/spark/SparkRunner.java&lt;br/&gt;
@@ -18,6 +18,8 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; package org.apache.beam.runners.spark;&lt;/p&gt;

&lt;p&gt;+import static org.apache.beam.runners.core.construction.PipelineResources.detectClassPathResourcesToStage;&lt;br/&gt;
+&lt;br/&gt;
 import com.google.common.collect.Iterables;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
@@ -121,6 +123,17 @@ public static SparkRunner create(SparkPipelineOptions options) {&lt;br/&gt;
   public static SparkRunner fromOptions(PipelineOptions options) {&lt;br/&gt;
     SparkPipelineOptions sparkOptions =&lt;br/&gt;
         PipelineOptionsValidator.validate(SparkPipelineOptions.class, options);&lt;br/&gt;
+&lt;br/&gt;
+    if (sparkOptions.getFilesToStage() == null) {&lt;br/&gt;
+      sparkOptions.setFilesToStage(detectClassPathResourcesToStage(&lt;br/&gt;
+          SparkRunner.class.getClassLoader()));&lt;br/&gt;
+      LOG.info(&quot;PipelineOptions.filesToStage was not specified. &quot;&lt;br/&gt;
+              + &quot;Defaulting to files from the classpath: will stage {} files. &quot;&lt;br/&gt;
+              + &quot;Enable logging at DEBUG level to see which files will be staged.&quot;,&lt;br/&gt;
+          sparkOptions.getFilesToStage().size());&lt;br/&gt;
+      LOG.debug(&quot;Classpath elements: {}&quot;, sparkOptions.getFilesToStage());&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
     return new SparkRunner(sparkOptions);&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;diff --git a/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/SparkContextFactory.java b/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/SparkContextFactory.java&lt;br/&gt;
index 0132de3dc12..5a8ad2d4d2d 100644&lt;br/&gt;
&amp;#8212; a/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/SparkContextFactory.java&lt;br/&gt;
+++ b/runners/spark/src/main/java/org/apache/beam/runners/spark/translation/SparkContextFactory.java&lt;br/&gt;
@@ -92,6 +92,11 @@ private static JavaSparkContext createSparkContext(SparkContextOptions contextOp&lt;br/&gt;
         // set master if not set.&lt;br/&gt;
         conf.setMaster(contextOptions.getSparkMaster());&lt;br/&gt;
       }&lt;br/&gt;
+&lt;br/&gt;
+      if (contextOptions.getFilesToStage() != null &amp;amp;&amp;amp; !contextOptions.getFilesToStage().isEmpty()) &lt;/p&gt;
{
+        conf.setJars(contextOptions.getFilesToStage().toArray(new String[0]));
+      }
&lt;p&gt;+&lt;br/&gt;
       conf.setAppName(contextOptions.getAppName());&lt;br/&gt;
       // register immutable collections serializers because the SDK uses them.&lt;br/&gt;
       conf.set(&quot;spark.kryo.registrator&quot;, BeamSparkRunnerRegistrator.class.getName());&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16309819" author="&#322;ukaszg" created="Wed, 3 Jan 2018 15:47:09 +0000"  >&lt;p&gt;After &lt;a href=&quot;https://github.com/apache/beam/pull/4246&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/4246&lt;/a&gt; was merged, we are able to do what Kobi suggested - stage jars using sparkConf.setJars() method. Should we close this issue then &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbonofre&quot; class=&quot;user-hover&quot; rel=&quot;jbonofre&quot;&gt;jbonofre&lt;/a&gt;? Should I be assigned to this issue, since I provided the PR?&lt;/p&gt;</comment>
                            <comment id="16312082" author="iemejia" created="Thu, 4 Jan 2018 21:46:57 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=%C5%81ukaszG&quot; class=&quot;user-hover&quot; rel=&quot;&#321;ukaszG&quot;&gt;&#321;ukaszG&lt;/a&gt; excellent work ! Are you planning to work on &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3371&quot; title=&quot;Add ability to stage directories with compiled classes to Spark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3371&quot;&gt;&lt;del&gt;BEAM-3371&lt;/del&gt;&lt;/a&gt; too ?&lt;br/&gt;
I have noticed that after this change I get exceptions like this one:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ERROR org.apache.spark.SparkContext  - Failed to add /home/ismael/workspace/beam2/runners/spark/target/test-classes to Spark environment&lt;br/&gt;
java.lang.IllegalArgumentException: Directory /home/ismael/workspace/beam2/runners/spark/target/test-classes is not allowed for addJar&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Do you think that it would make sense to filter the list returned on `PipelineResources#detectClassPathResourcesToStage` in the SparkRunner to include only the jar files and avoid this error message at least until &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3371&quot; title=&quot;Add ability to stage directories with compiled classes to Spark&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3371&quot;&gt;&lt;del&gt;BEAM-3371&lt;/del&gt;&lt;/a&gt; is done ?&lt;/p&gt;</comment>
                            <comment id="16312595" author="jbonofre" created="Fri, 5 Jan 2018 07:22:57 +0000"  >&lt;p&gt;Let me take a look on the PR. And yes, agree to assign the Jira to you.&lt;/p&gt;</comment>
                            <comment id="16312910" author="&#322;ukaszg" created="Fri, 5 Jan 2018 10:42:54 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iemejia&quot; class=&quot;user-hover&quot; rel=&quot;iemejia&quot;&gt;iemejia&lt;/a&gt; Thanks! I have other stuff on my plate now so anyone can feel free to take it.&lt;/p&gt;

&lt;p&gt;I think its best to have directories transformed to jars as proposed in 3371. This way we would get rid of the error (and others of this kind) and allow IOITs on spark so that would be great if its done. Is using the --filesToStage to stage already packaged jars instead of detecting them not an option in your case?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jbonofre&quot; class=&quot;user-hover&quot; rel=&quot;jbonofre&quot;&gt;jbonofre&lt;/a&gt; Thanks for taking the 3371 issue. I really look forward for the solution! Feel free to contact me if something is unclear. &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/smile.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; &lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13047789">BEAM-1603</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="12310040">
                    <name>Required</name>
                                                                <inwardlinks description="is required by">
                                        <issuelink>
            <issuekey id="13125956">BEAM-3371</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                            <subtask id="13076469">BEAM-2396</subtask>
                            <subtask id="13076470">BEAM-2397</subtask>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 45 weeks, 4 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i36cl3:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>