<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 10:59:52 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-7144] Job re-scale fails on Flink &gt;= 1.6 with certain values of maxParallelism</title>
                <link>https://issues.apache.org/jira/browse/BEAM-7144</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>&lt;p&gt;I am unable to rescale job after moving it to flink runner 1.7. What I am doing is:&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;Recompile job code just with swapped flink runner version 1.5 -&amp;gt; 1.7&lt;/li&gt;
	&lt;li&gt;Run streaming job with parallelism 112 and maxParallelism 448&lt;/li&gt;
	&lt;li&gt;Wait until checkpoint&#160;is taken&lt;/li&gt;
	&lt;li&gt;Stop job&lt;/li&gt;
	&lt;li&gt;Run job again with parallelims 224 and checpooint path to restore from&lt;/li&gt;
	&lt;li&gt;Job fails&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;The same happens if I try to increase parallelims. This procedure works for the same job compiled with flink runner 1.5 and run on 1.5.0. Fails with runner 1.7 on flink 1.7.2&lt;/p&gt;

&lt;p&gt;Exception is:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.Exception: Exception while creating StreamOperatorStateContext.
at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:195)
at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:250)
at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeState(StreamTask.java:738)
at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:289)
at org.apache.flink.runtime.taskmanager.Task.run(Task.java:704)
at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.flink.util.FlinkException: Could not restore keyed state backend for WindowDoFnOperator_2b6af61dc418f10e82551367a7e7f78e_(83/224) from any of the 1 provided restore options.
at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:137)
at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:284)
at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:135)
... 5 more
Caused by: java.lang.IndexOutOfBoundsException: Index: 101, Size: 0
at java.util.ArrayList.rangeCheck(ArrayList.java:653)
at java.util.ArrayList.get(ArrayList.java:429)
at com.esotericsoftware.kryo.util.MapReferenceResolver.getReadObject(MapReferenceResolver.java:42)
at com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:805)
at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:759)
at org.apache.flink.api.java.typeutils.runtime.kryo.KryoSerializer.deserialize(KryoSerializer.java:315)
at org.apache.flink.runtime.state.heap.StateTableByKeyGroupReaders.lambda$createV2PlusReader$0(StateTableByKeyGroupReaders.java:73)
at org.apache.flink.runtime.state.KeyGroupPartitioner$PartitioningResultKeyGroupReader.readMappingsInKeyGroup(KeyGroupPartitioner.java:297)
at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.readKeyGroupStateData(HeapKeyedStateBackend.java:492)
at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.readStateHandleStateData(HeapKeyedStateBackend.java:453)
at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.restorePartitionedState(HeapKeyedStateBackend.java:410)
at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.restore(HeapKeyedStateBackend.java:358)
at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.restore(HeapKeyedStateBackend.java:104)
at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:151)
at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:123)
... 7 more&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment></environment>
        <key id="13230096">BEAM-7144</key>
            <summary>Job re-scale fails on Flink &gt;= 1.6 with certain values of maxParallelism</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10102" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">P2</priority>
                        <status id="10722" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Triage Needed</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mxm">Maximilian Michels</assignee>
                                    <reporter username="JozoVilcek">Jozef Vilcek</reporter>
                        <labels>
                    </labels>
                <created>Thu, 25 Apr 2019 13:46:09 +0000</created>
                <updated>Thu, 13 Apr 2023 10:55:48 +0000</updated>
                            <resolved>Sat, 15 Jun 2019 10:11:09 +0000</resolved>
                                    <version>2.11.0</version>
                                    <fixVersion>2.14.0</fixVersion>
                                    <component>runner-flink</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="10800">3h</timespent>
                                <comments>
                            <comment id="16826095" author="mxm" created="Thu, 25 Apr 2019 14:02:16 +0000"  >&lt;p&gt;Thanks for reporting. On this note, we have a test (FlinkSavepointTest) that checks checkpointing and restore, we might have to add one for rescaling.&lt;/p&gt;</comment>
                            <comment id="16833350" author="jozovilcek" created="Sun, 5 May 2019 11:55:36 +0000"  >&lt;p&gt;I tried similar test on 1.6. Pipeline reading Kafka topic and dumping data to file. Restore job from checkpoint with changing parallelism fails. I did a bit of debugging and operator ID &lt;b&gt;4e2a4ea6f15b077f5eaf61854e18682f&lt;/b&gt; from exeption bellow seems to come from beam step name&#160;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;HadoopDFSWrite/write-avro/WriteFiles/GatherTempFileResults/Reshuffle/GroupByKey&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&#160;&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;java.lang.Exception: Exception while creating StreamOperatorStateContext.
	at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:192)
	at org.apache.flink.streaming.api.operators.AbstractStreamOperator.initializeState(AbstractStreamOperator.java:250)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.initializeState(StreamTask.java:738)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:289)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.flink.util.FlinkException: Could not restore keyed state backend for WindowDoFnOperator_4e2a4ea6f15b077f5eaf61854e18682f_(4/16) from any of the 1 provided restore options.
	at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:137)
	at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.keyedStatedBackend(StreamTaskStateInitializerImpl.java:279)
	at org.apache.flink.streaming.api.operators.StreamTaskStateInitializerImpl.streamOperatorStateContext(StreamTaskStateInitializerImpl.java:133)
	... 5 more
Caused by: java.io.EOFException
	at java.io.DataInputStream.readUnsignedByte(DataInputStream.java:290)
	at org.apache.flink.types.StringValue.readString(StringValue.java:769)
	at org.apache.flink.api.common.typeutils.base.StringSerializer.deserialize(StringSerializer.java:69)
	at org.apache.flink.api.common.typeutils.base.StringSerializer.deserialize(StringSerializer.java:28)
	at org.apache.flink.runtime.state.heap.StateTableByKeyGroupReaders.lambda$createV2PlusReader$0(StateTableByKeyGroupReaders.java:71)
	at org.apache.flink.runtime.state.KeyGroupPartitioner$PartitioningResultKeyGroupReader.readMappingsInKeyGroup(KeyGroupPartitioner.java:297)
	at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.readKeyGroupStateData(HeapKeyedStateBackend.java:513)
	at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.readStateHandleStateData(HeapKeyedStateBackend.java:474)
	at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.restorePartitionedState(HeapKeyedStateBackend.java:431)
	at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.restore(HeapKeyedStateBackend.java:370)
	at org.apache.flink.runtime.state.heap.HeapKeyedStateBackend.restore(HeapKeyedStateBackend.java:105)
	at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.attemptCreateAndRestore(BackendRestorerProcedure.java:151)
	at org.apache.flink.streaming.api.operators.BackendRestorerProcedure.createAndRestore(BackendRestorerProcedure.java:123)
	... 7 more&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</comment>
                            <comment id="16833353" author="jozovilcek" created="Sun, 5 May 2019 12:00:41 +0000"  >&lt;p&gt;It is sort of bad news for me. Can not run on newer Flink versions due to this and Flink 1.5.x&#160;suffers from&#160;&lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-9423&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-9423&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16837341" author="mxm" created="Fri, 10 May 2019 14:55:34 +0000"  >&lt;p&gt;I&apos;ve done some testing and found rescaling works on Flink 1.6/1.7, at least for a simple pipeline. I think I need a bit more information what&apos;s going on in your pipeline.&lt;/p&gt;</comment>
                            <comment id="16837382" author="jozovilcek" created="Fri, 10 May 2019 15:26:58 +0000"  >&lt;p&gt;Hm, I was afraid of this. Pipeline I was testing is like&lt;/p&gt;

&lt;p&gt;&#160; &#160;KafkaRead -&amp;gt; Filter -&amp;gt; WriteFiles -&amp;gt;&#160;Stateful map of written files (until accumulate required size) -&amp;gt; Map file name list per Key&lt;/p&gt;

&lt;p&gt;List to files is taken as WriteFilesResult.getPerDestinationOutputFilenames(). Pipeline is written in Scio.&lt;/p&gt;</comment>
                            <comment id="16837705" author="angoenka" created="Fri, 10 May 2019 23:56:46 +0000"  >&lt;p&gt;Can we move this to 2.14.0?&lt;/p&gt;</comment>
                            <comment id="16837793" author="jozovilcek" created="Sat, 11 May 2019 08:59:00 +0000"  >&lt;p&gt;I did a bit of dissecting at my end. Pure kafka read can rescale all right. Then, it fails, if I add then a simple write to text file like this&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;val stringKeys = kafkaKv
    .map { case (k, v) =&amp;gt; k }
    .withGlobalWindow(WindowOptions(
      trigger = Repeatedly.forever(AfterProcessingTime.pastFirstElementInPane().plusDelayOf(Duration.millis(60 * 1000))),
      accumulationMode = AccumulationMode.DISCARDING_FIRED_PANES,
      allowedLateness = Duration.ZERO
))


val writer = FileIO.write().via(TextIO.sink())
    .to(config.getString(&quot;output-dir&quot;))
    .withTempDirectory(sc.options.getTempLocation)
    .withNumShards(14)

stringKeys.internal.apply(writer)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</comment>
                            <comment id="16839316" author="mxm" created="Tue, 14 May 2019 10:55:32 +0000"  >&lt;p&gt;That&apos;s interesting. Actually, could you re-test this with &lt;tt&gt;beam-runners-flink-1.8&lt;/tt&gt;?&lt;/p&gt;</comment>
                            <comment id="16841178" author="jozovilcek" created="Thu, 16 May 2019 10:06:05 +0000"  >&lt;p&gt;Yes,&#160;rescale on 1.8 works for me&lt;/p&gt;</comment>
                            <comment id="16841303" author="mxm" created="Thu, 16 May 2019 12:55:07 +0000"  >&lt;p&gt;Thanks for testing. That&apos;s very helpful!&lt;/p&gt;</comment>
                            <comment id="16847370" author="mxm" created="Fri, 24 May 2019 08:57:20 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=angoenka&quot; class=&quot;user-hover&quot; rel=&quot;angoenka&quot;&gt;angoenka&lt;/a&gt; Moved to 2.14.0&lt;/p&gt;</comment>
                            <comment id="16847917" author="mxm" created="Fri, 24 May 2019 21:46:57 +0000"  >&lt;p&gt;I had a look into this. I&apos;ve adapted &lt;tt&gt;FlinkSavepointTest&lt;/tt&gt; to include rescaling. For me, it runs fine with Flink 1.5 but fails for 1.6, 1.7, and 1.8. As of now it looks like a Flink bug but I&apos;ll have to investigate further.&lt;/p&gt;</comment>
                            <comment id="16848841" author="mxm" created="Mon, 27 May 2019 11:08:03 +0000"  >&lt;p&gt;Also works fine for some values of &lt;tt&gt;maxParallelism&lt;/tt&gt;, e.g. 100 works, 63 works. 64 or 128 (default) do no work. The issue is caused by a corrupt serialization of the keyed state. So far investigating Beam serializer issues has not brought up anything.&lt;/p&gt;</comment>
                            <comment id="16860339" author="kedin" created="Mon, 10 Jun 2019 21:21:13 +0000"  >&lt;p&gt;If this&#160;is present&#160;in all Beam releases since few versions back, do we still want to target/block a specific Beam release and keep pushing it out?&lt;/p&gt;</comment>
                            <comment id="16861048" author="mxm" created="Tue, 11 Jun 2019 13:40:15 +0000"  >&lt;p&gt;IMHO should be fixed ASAP, but no need to block the release since this affects only the rescale of a job under certain conditions. It may also have to be fixed upstream. &lt;/p&gt;</comment>
                            <comment id="16861049" author="mxm" created="Tue, 11 Jun 2019 13:41:31 +0000"  >&lt;p&gt;More details here: &lt;a href=&quot;https://issues.apache.org/jira/browse/FLINK-12653&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/FLINK-12653&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16862077" author="jozovilcek" created="Wed, 12 Jun 2019 13:04:04 +0000"  >&lt;p&gt;I did try to re-run my test on 1.8 with default and non-default parallelism to check if it makes any difference. It is failing on me in both cases. I do not know how could I see it previously running OK. So I call off my previous statement to see it working on 1.8. Sorry for confusion :/&lt;/p&gt;</comment>
                            <comment id="16862784" author="mxm" created="Thu, 13 Jun 2019 07:17:17 +0000"  >&lt;p&gt;After a decent amount of debugging of the checkpoint/restore/rescale code, I managed to find the culprit. The issue here is the lazy state creation that Beam uses by default. State is created in Flink&apos;s state backend upon first &quot;binding&quot; of the state. Binding is only performed when &lt;tt&gt;processElement&lt;/tt&gt; is called. Now, it can happen that an operator does not receive elements before checkpointed. In this case the state won&apos;t be initialized. &lt;/p&gt;

&lt;p&gt;Depending on the &lt;tt&gt;maxParallelism&lt;/tt&gt;, this can lead to the state being partitioned such that an operator attempts to restore from a keygroup that did not have the state in its meta data. However, the actual data ends up containing the state which looks like a bug in the Flink key group partitioner. &lt;/p&gt;

&lt;p&gt;The workaround is to ensure that all user state is registered before checkpointing is first attempted. This resolves all issues with rescaling Beam jobs.  &lt;/p&gt;</comment>
                            <comment id="16864651" author="mxm" created="Sat, 15 Jun 2019 10:11:10 +0000"  >&lt;p&gt;We have worked around the Flink bug in the linked PR. Rescaling works properly now.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="13236019">FLINK-12653</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 22 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z024wo:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>