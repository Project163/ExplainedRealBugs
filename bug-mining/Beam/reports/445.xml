<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 10:46:46 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-3361] Go SDK needs to increase gRPC receive buffer size</title>
                <link>https://issues.apache.org/jira/browse/BEAM-3361</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>&lt;p&gt;The Java gRPC server allows for sending messages larger than the default 4M gRPC limit. The Go SDK needs to handle these messages. I propose increasing the limit to 50M based on empirical observations, and we can tune this value in the future if needed.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13125292">BEAM-3361</key>
            <summary>Go SDK needs to increase gRPC receive buffer size</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10103" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">P3</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="wcn3">Bill Neubauer</assignee>
                                    <reporter username="wcn3">Bill Neubauer</reporter>
                        <labels>
                    </labels>
                <created>Fri, 15 Dec 2017 18:06:57 +0000</created>
                <updated>Sat, 16 May 2020 13:17:05 +0000</updated>
                            <resolved>Mon, 26 Feb 2018 21:36:07 +0000</resolved>
                                                    <fixVersion>Not applicable</fixVersion>
                                    <component>sdk-go</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                    <workratio workratioPercent="0"/>
                                    <progress percentage="0">
                                    <originalProgress>
                                                    <row percentage="100" backgroundColor="#89afd7"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="0" backgroundColor="#51a825"/>
                                                    <row percentage="100" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="0">
                                    <originalProgress>
                                                    <row percentage="100" backgroundColor="#89afd7"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="0" backgroundColor="#51a825"/>
                                                    <row percentage="100" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                    <timeoriginalestimate seconds="3600">1h</timeoriginalestimate>
                            <timeestimate seconds="3600">1h</timeestimate>
                                        <comments>
                            <comment id="16292964" author="githubbot" created="Fri, 15 Dec 2017 18:17:30 +0000"  >&lt;p&gt;wcn3 opened a new pull request #4270: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3361&quot; title=&quot;Go SDK needs to increase gRPC receive buffer size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3361&quot;&gt;&lt;del&gt;BEAM-3361&lt;/del&gt;&lt;/a&gt; Increase Go gRPC message size&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/beam/pull/4270&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/4270&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Increases the buffer for gRPC messages from 4M to 50M.&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16295604" author="githubbot" created="Mon, 18 Dec 2017 20:03:51 +0000"  >&lt;p&gt;wcn3 closed pull request #4270: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3361&quot; title=&quot;Go SDK needs to increase gRPC receive buffer size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3361&quot;&gt;&lt;del&gt;BEAM-3361&lt;/del&gt;&lt;/a&gt; Increase Go gRPC message size&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/beam/pull/4270&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/4270&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/.test-infra/jenkins/job_beam_PostCommit_Java_ValidatesRunner_Spark.groovy b/.test-infra/jenkins/job_beam_PostCommit_Java_ValidatesRunner_Spark.groovy&lt;br/&gt;
index 9fbc219a910..2ec4cd54142 100644&lt;br/&gt;
&amp;#8212; a/.test-infra/jenkins/job_beam_PostCommit_Java_ValidatesRunner_Spark.groovy&lt;br/&gt;
+++ b/.test-infra/jenkins/job_beam_PostCommit_Java_ValidatesRunner_Spark.groovy&lt;br/&gt;
@@ -25,7 +25,7 @@ mavenJob(&apos;beam_PostCommit_Java_ValidatesRunner_Spark&apos;) {&lt;br/&gt;
   previousNames(&apos;beam_PostCommit_Java_RunnableOnService_Spark&apos;)&lt;/p&gt;

&lt;p&gt;   // Set common parameters.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;common_job_properties.setTopLevelMainJobProperties(delegate)&lt;br/&gt;
+  common_job_properties.setTopLevelMainJobProperties(delegate, &apos;master&apos;, 120)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   // Set maven parameters.&lt;br/&gt;
   common_job_properties.setMavenConfig(delegate)&lt;br/&gt;
diff --git a/examples/java/src/main/java/org/apache/beam/examples/WindowedWordCount.java b/examples/java/src/main/java/org/apache/beam/examples/WindowedWordCount.java&lt;br/&gt;
index 21cfed8be01..b31ce4aaa45 100644&lt;br/&gt;
&amp;#8212; a/examples/java/src/main/java/org/apache/beam/examples/WindowedWordCount.java&lt;br/&gt;
+++ b/examples/java/src/main/java/org/apache/beam/examples/WindowedWordCount.java&lt;br/&gt;
@@ -162,9 +162,8 @@ public Long create(PipelineOptions options) &lt;/p&gt;
{
     void setMaxTimestampMillis(Long value);
 
     @Description(&quot;Fixed number of shards to produce per window&quot;)
-    @Default.Integer(3)
-    int getNumShards();
-    void setNumShards(int numShards);
+    Integer getNumShards();
+    void setNumShards(Integer numShards);
   }

&lt;p&gt;   public static void main(String[] args) throws IOException {&lt;br/&gt;
diff --git a/examples/java/src/main/java/org/apache/beam/examples/common/WriteOneFilePerWindow.java b/examples/java/src/main/java/org/apache/beam/examples/common/WriteOneFilePerWindow.java&lt;br/&gt;
index a5c84f67c28..abd14b70118 100644&lt;br/&gt;
&amp;#8212; a/examples/java/src/main/java/org/apache/beam/examples/common/WriteOneFilePerWindow.java&lt;br/&gt;
+++ b/examples/java/src/main/java/org/apache/beam/examples/common/WriteOneFilePerWindow.java&lt;br/&gt;
@@ -19,6 +19,7 @@&lt;/p&gt;

&lt;p&gt; import static com.google.common.base.MoreObjects.firstNonNull;&lt;/p&gt;

&lt;p&gt;+import javax.annotation.Nullable;&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink;&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink.FilenamePolicy;&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink.OutputFileHints;&lt;br/&gt;
@@ -45,9 +46,10 @@&lt;br/&gt;
 public class WriteOneFilePerWindow extends PTransform&amp;lt;PCollection&amp;lt;String&amp;gt;, PDone&amp;gt; {&lt;br/&gt;
   private static final DateTimeFormatter FORMATTER = ISODateTimeFormat.hourMinute();&lt;br/&gt;
   private String filenamePrefix;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private int numShards;&lt;br/&gt;
+  @Nullable&lt;br/&gt;
+  private Integer numShards;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public WriteOneFilePerWindow(String filenamePrefix, int numShards) {&lt;br/&gt;
+  public WriteOneFilePerWindow(String filenamePrefix, Integer numShards) 
{
     this.filenamePrefix = filenamePrefix;
     this.numShards = numShards;
   }
&lt;p&gt;@@ -59,8 +61,10 @@ public PDone expand(PCollection&amp;lt;String&amp;gt; input) {&lt;br/&gt;
         TextIO.write()&lt;br/&gt;
             .to(new PerWindowFiles(resource))&lt;br/&gt;
             .withTempDirectory(resource.getCurrentDirectory())&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;.withWindowedWrites()&lt;/li&gt;
	&lt;li&gt;.withNumShards(numShards);&lt;br/&gt;
+            .withWindowedWrites();&lt;br/&gt;
+    if (numShards != null) 
{
+      write = write.withNumShards(numShards);
+    }
&lt;p&gt;     return input.apply(write);&lt;br/&gt;
   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/examples/java/src/test/java/org/apache/beam/examples/WindowedWordCountIT.java b/examples/java/src/test/java/org/apache/beam/examples/WindowedWordCountIT.java&lt;br/&gt;
index 279de535adb..2f4ef34faab 100644&lt;br/&gt;
&amp;#8212; a/examples/java/src/test/java/org/apache/beam/examples/WindowedWordCountIT.java&lt;br/&gt;
+++ b/examples/java/src/test/java/org/apache/beam/examples/WindowedWordCountIT.java&lt;br/&gt;
@@ -86,6 +86,14 @@ public static void setUp() &lt;/p&gt;
{
     PipelineOptionsFactory.register(TestPipelineOptions.class);
   }

&lt;p&gt;+  @Test&lt;br/&gt;
+  public void testWindowedWordCountInBatchDynamicSharding() throws Exception &lt;/p&gt;
{
+    WindowedWordCountITOptions options = batchOptions();
+    // This is the default value, but make it explicit.
+    options.setNumShards(null);
+    testWindowedWordCountPipeline(options);
+  }
&lt;p&gt;+&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testWindowedWordCountInBatchStaticSharding() throws Exception {&lt;br/&gt;
     WindowedWordCountITOptions options = batchOptions();&lt;br/&gt;
diff --git a/model/fn-execution/src/main/proto/beam_fn_api.proto b/model/fn-execution/src/main/proto/beam_fn_api.proto&lt;br/&gt;
index a2d0eb47942..ca23c619f33 100644&lt;br/&gt;
&amp;#8212; a/model/fn-execution/src/main/proto/beam_fn_api.proto&lt;br/&gt;
+++ b/model/fn-execution/src/main/proto/beam_fn_api.proto&lt;br/&gt;
@@ -707,23 +707,3 @@ service BeamFnLogging {&lt;br/&gt;
   ) {}&lt;br/&gt;
 }&lt;/p&gt;

&lt;p&gt;-/*&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Environment types&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-// A Docker container configuration for launching the SDK harness to execute&lt;br/&gt;
-// user specified functions.&lt;br/&gt;
-message DockerContainer 
{
-  // (Required) A pipeline level unique id which can be used as a reference to
-  // refer to this.
-  string id = 1;
-
-  // (Required) The Docker container URI
-  // For example &quot;dataflow.gcr.io/v1beta3/java-batch:1.5.1&quot;
-  string uri = 2;
-
-  // (Optional) Docker registry specification.
-  // If unspecified, the uri is expected to be able to be fetched without
-  // requiring additional configuration by a runner.
-  string registry_reference = 3;
-}
&lt;p&gt;-&lt;br/&gt;
diff --git a/model/fn-execution/src/main/proto/beam_provision_api.proto b/model/fn-execution/src/main/proto/beam_provision_api.proto&lt;br/&gt;
index 9c198164807..84df80bf14e 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/model/fn-execution/src/main/proto/beam_provision_api.proto&lt;br/&gt;
+++ b/model/fn-execution/src/main/proto/beam_provision_api.proto&lt;br/&gt;
@@ -54,6 +54,8 @@ message ProvisionInfo {&lt;br/&gt;
     string job_id = 1;&lt;br/&gt;
     // (required) The job name.&lt;br/&gt;
     string job_name = 2;&lt;br/&gt;
+    // (required) The worker ID.&lt;br/&gt;
+    string worker_id = 5;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // (required) Pipeline options. For non-template jobs, the options are&lt;br/&gt;
     // identical to what is passed to job submission.&lt;br/&gt;
diff --git a/pom.xml b/pom.xml&lt;br/&gt;
index 2662a1e70bc..a06dbed6a9c 100644&lt;br/&gt;
&amp;#8212; a/pom.xml&lt;br/&gt;
+++ b/pom.xml&lt;br/&gt;
@@ -92,6 +92,7 @@&lt;/p&gt;

&lt;p&gt;   &amp;lt;properties&amp;gt;&lt;br/&gt;
     &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt;&lt;br/&gt;
+    &amp;lt;external.build.directory&amp;gt;${project.basedir}/target&amp;lt;/external.build.directory&amp;gt;&lt;br/&gt;
     &amp;lt;beam.javadoc_opts /&amp;gt;&lt;/p&gt;

&lt;p&gt;     &amp;lt;!-- Disable integration tests by default --&amp;gt;&lt;br/&gt;
@@ -694,6 +695,12 @@&lt;br/&gt;
         &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;&lt;br/&gt;
       &amp;lt;/dependency&amp;gt;&lt;/p&gt;

&lt;p&gt;+      &amp;lt;dependency&amp;gt;&lt;br/&gt;
+        &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+        &amp;lt;artifactId&amp;gt;beam-runners-reference-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+        &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;&lt;br/&gt;
+      &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
       &amp;lt;dependency&amp;gt;&lt;br/&gt;
         &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
         &amp;lt;artifactId&amp;gt;beam-runners-reference-job-orchestrator&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
@@ -1448,7 +1455,7 @@&lt;br/&gt;
         &amp;lt;plugin&amp;gt;&lt;br/&gt;
           &amp;lt;groupId&amp;gt;org.xolstice.maven.plugins&amp;lt;/groupId&amp;gt;&lt;br/&gt;
           &amp;lt;artifactId&amp;gt;protobuf-maven-plugin&amp;lt;/artifactId&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;version&amp;gt;0.5.0&amp;lt;/version&amp;gt;&lt;br/&gt;
+          &amp;lt;version&amp;gt;0.5.1&amp;lt;/version&amp;gt;&lt;br/&gt;
         &amp;lt;/plugin&amp;gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;         &amp;lt;plugin&amp;gt;&lt;br/&gt;
@@ -2194,6 +2201,7 @@&lt;br/&gt;
         &amp;lt;/executions&amp;gt;&lt;br/&gt;
       &amp;lt;/plugin&amp;gt;&lt;br/&gt;
     &amp;lt;/plugins&amp;gt;&lt;br/&gt;
+    &amp;lt;directory&amp;gt;${external.build.directory}&amp;lt;/directory&amp;gt;&lt;br/&gt;
   &amp;lt;/build&amp;gt;&lt;/p&gt;

&lt;p&gt;   &amp;lt;reporting&amp;gt;&lt;br/&gt;
diff --git a/runners/apex/src/test/java/org/apache/beam/runners/apex/examples/WordCountTest.java b/runners/apex/src/test/java/org/apache/beam/runners/apex/examples/WordCountTest.java&lt;br/&gt;
index e050c15115e..ba757468b03 100644&lt;br/&gt;
&amp;#8212; a/runners/apex/src/test/java/org/apache/beam/runners/apex/examples/WordCountTest.java&lt;br/&gt;
+++ b/runners/apex/src/test/java/org/apache/beam/runners/apex/examples/WordCountTest.java&lt;br/&gt;
@@ -108,7 +108,7 @@ public static void main(String[] args) &lt;/p&gt;
{
       .apply(ParDo.of(new ExtractWordsFn()))
       .apply(Count.&amp;lt;String&amp;gt;perElement())
       .apply(ParDo.of(new FormatAsStringFn()))
-      .apply(&quot;WriteCounts&quot;, TextIO.write().to(options.getOutput()).withNumShards(2))
+      .apply(&quot;WriteCounts&quot;, TextIO.write().to(options.getOutput()))
       ;
     p.run().waitUntilFinish();
   }
&lt;p&gt;diff --git a/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/WriteFilesTranslation.java b/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/WriteFilesTranslation.java&lt;br/&gt;
index d0b2182618f..90f645373a1 100644&lt;br/&gt;
&amp;#8212; a/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/WriteFilesTranslation.java&lt;br/&gt;
+++ b/runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/WriteFilesTranslation.java&lt;br/&gt;
@@ -85,12 +85,13 @@ public SdkFunctionSpec translateSink(SdkComponents newComponents) {&lt;/p&gt;

&lt;p&gt;           @Override&lt;br/&gt;
           public boolean isWindowedWrites() &lt;/p&gt;
{
-            return transform.isWindowedWrites();
+            return transform.getWindowedWrites();
           }

&lt;p&gt;           @Override&lt;br/&gt;
           public boolean isRunnerDeterminedSharding() &lt;/p&gt;
{
-            return transform.getNumShards() == null &amp;amp;&amp;amp; transform.getSharding() == null;
+            return transform.getNumShardsProvider() == null
+                &amp;amp;&amp;amp; transform.getComputeNumShards() == null;
           }
&lt;p&gt;         },&lt;br/&gt;
         components);&lt;br/&gt;
@@ -302,7 +303,7 @@ public FunctionSpec translate(&lt;br/&gt;
     public Map&amp;lt;Class&amp;lt;? extends PTransform&amp;gt;, TransformPayloadTranslator&amp;gt;&lt;br/&gt;
         getTransformPayloadTranslators() &lt;/p&gt;
{
       return Collections.&amp;lt;Class&amp;lt;? extends PTransform&amp;gt;, TransformPayloadTranslator&amp;gt;singletonMap(
-          WriteFiles.class, new WriteFilesTranslator());
+          WriteFiles.CONCRETE_CLASS, new WriteFilesTranslator());
     }

&lt;p&gt;     @Override&lt;br/&gt;
diff --git a/runners/core-construction-java/src/test/java/org/apache/beam/runners/core/construction/WriteFilesTranslationTest.java b/runners/core-construction-java/src/test/java/org/apache/beam/runners/core/construction/WriteFilesTranslationTest.java&lt;br/&gt;
index ccb366ec861..038653d37cb 100644&lt;br/&gt;
&amp;#8212; a/runners/core-construction-java/src/test/java/org/apache/beam/runners/core/construction/WriteFilesTranslationTest.java&lt;br/&gt;
+++ b/runners/core-construction-java/src/test/java/org/apache/beam/runners/core/construction/WriteFilesTranslationTest.java&lt;br/&gt;
@@ -64,6 +64,7 @@&lt;br/&gt;
     public static Iterable&amp;lt;WriteFiles&amp;lt;Object, Void, Object&amp;gt;&amp;gt; data() &lt;/p&gt;
{
       return ImmutableList.of(
           WriteFiles.to(new DummySink()),
+          WriteFiles.to(new DummySink()).withWindowedWrites(),
           WriteFiles.to(new DummySink()).withNumShards(17),
           WriteFiles.to(new DummySink()).withWindowedWrites().withNumShards(42));
     }
&lt;p&gt;@@ -80,9 +81,11 @@ public void testEncodedProto() throws Exception {&lt;/p&gt;

&lt;p&gt;       assertThat(&lt;br/&gt;
           payload.getRunnerDeterminedSharding(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;equalTo(writeFiles.getNumShards() == null &amp;amp;&amp;amp; writeFiles.getSharding() == null));&lt;br/&gt;
+          equalTo(&lt;br/&gt;
+              writeFiles.getNumShardsProvider() == null&lt;br/&gt;
+                  &amp;amp;&amp;amp; writeFiles.getComputeNumShards() == null));&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;assertThat(payload.getWindowedWrites(), equalTo(writeFiles.isWindowedWrites()));&lt;br/&gt;
+      assertThat(payload.getWindowedWrites(), equalTo(writeFiles.getWindowedWrites()));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       assertThat(&lt;br/&gt;
           (FileBasedSink&amp;lt;String, Void, String&amp;gt;)&lt;br/&gt;
@@ -102,11 +105,13 @@ public void testExtractionDirectFromTransform() throws Exception {&lt;/p&gt;

&lt;p&gt;       assertThat(&lt;br/&gt;
           WriteFilesTranslation.isRunnerDeterminedSharding(appliedPTransform),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;equalTo(writeFiles.getNumShards() == null &amp;amp;&amp;amp; writeFiles.getSharding() == null));&lt;br/&gt;
+          equalTo(&lt;br/&gt;
+              writeFiles.getNumShardsProvider() == null&lt;br/&gt;
+                  &amp;amp;&amp;amp; writeFiles.getComputeNumShards() == null));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       assertThat(&lt;br/&gt;
           WriteFilesTranslation.isWindowedWrites(appliedPTransform),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;equalTo(writeFiles.isWindowedWrites()));&lt;br/&gt;
+          equalTo(writeFiles.getWindowedWrites()));&lt;br/&gt;
       assertThat(&lt;br/&gt;
           WriteFilesTranslation.&amp;lt;String, Void, String&amp;gt;getSink(appliedPTransform),&lt;br/&gt;
           equalTo(writeFiles.getSink()));&lt;br/&gt;
diff --git a/runners/core-java/pom.xml b/runners/core-java/pom.xml&lt;br/&gt;
index 48111348ff5..86acf826288 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/runners/core-java/pom.xml&lt;br/&gt;
+++ b/runners/core-java/pom.xml&lt;br/&gt;
@@ -67,11 +67,6 @@&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;beam-sdks-java-core&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;dependency&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;artifactId&amp;gt;beam-model-fn-execution&amp;lt;/artifactId&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/dependency&amp;gt;&lt;br/&gt;
-&lt;br/&gt;
     &amp;lt;dependency&amp;gt;&lt;br/&gt;
       &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;beam-runners-core-construction-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
@@ -100,26 +95,11 @@&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;guava&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;dependency&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;groupId&amp;gt;io.grpc&amp;lt;/groupId&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;artifactId&amp;gt;grpc-core&amp;lt;/artifactId&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/dependency&amp;gt;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;&amp;lt;dependency&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;groupId&amp;gt;io.grpc&amp;lt;/groupId&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;artifactId&amp;gt;grpc-stub&amp;lt;/artifactId&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/dependency&amp;gt;&lt;br/&gt;
-&lt;br/&gt;
     &amp;lt;dependency&amp;gt;&lt;br/&gt;
       &amp;lt;groupId&amp;gt;joda-time&amp;lt;/groupId&amp;gt;&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;joda-time&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;dependency&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;artifactId&amp;gt;slf4j-api&amp;lt;/artifactId&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/dependency&amp;gt;&lt;br/&gt;
-&lt;br/&gt;
     &amp;lt;!-- test dependencies --&amp;gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     &amp;lt;!-- Utilities such as WindowMatchers --&amp;gt;&lt;br/&gt;
diff --git a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnApiControlClient.java b/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnApiControlClient.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 811444c96ce..00000000000&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnApiControlClient.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,152 +0,0 @@&lt;br/&gt;
-/*&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Licensed to the Apache Software Foundation (ASF) under one&lt;/li&gt;
	&lt;li&gt;* or more contributor license agreements.  See the NOTICE file&lt;/li&gt;
	&lt;li&gt;* distributed with this work for additional information&lt;/li&gt;
	&lt;li&gt;* regarding copyright ownership.  The ASF licenses this file&lt;/li&gt;
	&lt;li&gt;* to you under the Apache License, Version 2.0 (the&lt;/li&gt;
	&lt;li&gt;* &quot;License&quot;); you may not use this file except in compliance&lt;/li&gt;
	&lt;li&gt;* with the License.  You may obtain a copy of the License at&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;*     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* Unless required by applicable law or agreed to in writing, software&lt;/li&gt;
	&lt;li&gt;* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;/li&gt;
	&lt;li&gt;* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/li&gt;
	&lt;li&gt;* See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;* limitations under the License.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import com.google.common.util.concurrent.ListenableFuture;&lt;br/&gt;
-import com.google.common.util.concurrent.SettableFuture;&lt;br/&gt;
-import io.grpc.Status;&lt;br/&gt;
-import io.grpc.StatusRuntimeException;&lt;br/&gt;
-import io.grpc.stub.StreamObserver;&lt;br/&gt;
-import java.io.Closeable;&lt;br/&gt;
-import java.util.Map;&lt;br/&gt;
-import java.util.concurrent.ConcurrentHashMap;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
-import org.slf4j.Logger;&lt;br/&gt;
-import org.slf4j.LoggerFactory;&lt;br/&gt;
-&lt;br/&gt;
-/**&lt;/li&gt;
	&lt;li&gt;* A client for the control plane of an SDK harness, which can issue requests to it over the Fn API.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* &amp;lt;p&amp;gt;This class presents a low-level Java API de-inverting the Fn API&apos;s gRPC layer.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* &amp;lt;p&amp;gt;The Fn API is inverted so the runner is the server and the SDK harness is the client, for&lt;/li&gt;
	&lt;li&gt;* firewalling reasons (the runner may execute in a more privileged environment forbidding outbound&lt;/li&gt;
	&lt;li&gt;* connections).&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* &amp;lt;p&amp;gt;This low-level client is responsible only for correlating requests with responses.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* @deprecated Runners should depend on the beam-runners-java-fn-execution module for this&lt;/li&gt;
	&lt;li&gt;*     functionality.&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
-@Deprecated&lt;br/&gt;
-class FnApiControlClient implements Closeable {&lt;/li&gt;
	&lt;li&gt;private static final Logger LOG = LoggerFactory.getLogger(FnApiControlClient.class);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// All writes to this StreamObserver need to be synchronized.&lt;/li&gt;
	&lt;li&gt;private final StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt; requestReceiver;&lt;/li&gt;
	&lt;li&gt;private final ResponseStreamObserver responseObserver = new ResponseStreamObserver();&lt;/li&gt;
	&lt;li&gt;private final Map&amp;lt;String, SettableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt;&amp;gt; outstandingRequests;&lt;/li&gt;
	&lt;li&gt;private volatile boolean isClosed;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private FnApiControlClient(StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt; requestReceiver) 
{
-    this.requestReceiver = requestReceiver;
-    this.outstandingRequests = new ConcurrentHashMap&amp;lt;&amp;gt;();
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Returns a 
{@link FnApiControlClient} which will submit its requests to the provided&lt;br/&gt;
-   * observer.&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;It is the responsibility of the caller to register this object as an observer of incoming&lt;br/&gt;
-   * responses (this will generally be done as part of fulfilling the contract of a gRPC service).&lt;br/&gt;
-   */&lt;br/&gt;
-  public static FnApiControlClient forRequestObserver(&lt;br/&gt;
-      StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt; requestObserver) {
-    return new FnApiControlClient(requestObserver);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  public synchronized ListenableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; handle(&lt;br/&gt;
-      BeamFnApi.InstructionRequest request) {&lt;br/&gt;
-    LOG.debug(&quot;Sending InstructionRequest {}&quot;, request);&lt;br/&gt;
-    SettableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; resultFuture = SettableFuture.create();&lt;br/&gt;
-    outstandingRequests.put(request.getInstructionId(), resultFuture);&lt;br/&gt;
-    requestReceiver.onNext(request);&lt;br/&gt;
-    return resultFuture;&lt;br/&gt;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  StreamObserver&amp;lt;BeamFnApi.InstructionResponse&amp;gt; asResponseObserver() {
-    return responseObserver;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Override&lt;br/&gt;
-  public void close() {
-    closeAndTerminateOutstandingRequests(new IllegalStateException(&quot;Runner closed connection&quot;));
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /** Closes this client and terminates any outstanding requests exceptionally. */&lt;br/&gt;
-  private synchronized void closeAndTerminateOutstandingRequests(Throwable cause) {&lt;br/&gt;
-    if (isClosed) {
-      return;
-    }&lt;br/&gt;
-&lt;br/&gt;
-    // Make a copy of the map to make the view of the outstanding requests consistent.&lt;br/&gt;
-    Map&amp;lt;String, SettableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt;&amp;gt; outstandingRequestsCopy =&lt;br/&gt;
-        new ConcurrentHashMap&amp;lt;&amp;gt;(outstandingRequests);&lt;br/&gt;
-    outstandingRequests.clear();&lt;br/&gt;
-    isClosed = true;&lt;br/&gt;
-&lt;br/&gt;
-    if (outstandingRequestsCopy.isEmpty()) {
-      requestReceiver.onCompleted();
-      return;
-    }&lt;br/&gt;
-    requestReceiver.onError(&lt;br/&gt;
-        new StatusRuntimeException(Status.CANCELLED.withDescription(cause.getMessage())));&lt;br/&gt;
-&lt;br/&gt;
-    LOG.error(&lt;br/&gt;
-        &quot;{} closed, clearing outstanding requests {}&quot;,&lt;br/&gt;
-        FnApiControlClient.class.getSimpleName(),&lt;br/&gt;
-        outstandingRequestsCopy);&lt;br/&gt;
-    for (SettableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; outstandingRequest :&lt;br/&gt;
-        outstandingRequestsCopy.values()) {
-      outstandingRequest.setException(cause);
-    }&lt;br/&gt;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * A private view of this class as a {@link StreamObserver} for connecting as a gRPC listener.&lt;br/&gt;
-   */&lt;br/&gt;
-  private class ResponseStreamObserver implements StreamObserver&amp;lt;BeamFnApi.InstructionResponse&amp;gt; {&lt;br/&gt;
-    /**&lt;br/&gt;
-     * Processes an incoming {@link BeamFnApi.InstructionResponse} by correlating it with the&lt;br/&gt;
-     * corresponding {@link BeamFnApi.InstructionRequest} and completes the future that was returned&lt;br/&gt;
-     * by {@link #handle}.&lt;br/&gt;
-     */&lt;br/&gt;
-    @Override&lt;br/&gt;
-    public void onNext(BeamFnApi.InstructionResponse response) {&lt;br/&gt;
-      LOG.debug(&quot;Received InstructionResponse {}&quot;, response);&lt;br/&gt;
-      SettableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; completableFuture =&lt;br/&gt;
-          outstandingRequests.remove(response.getInstructionId());&lt;br/&gt;
-      if (completableFuture != null) {
-        completableFuture.set(response);
-      }&lt;br/&gt;
-    }&lt;br/&gt;
-&lt;br/&gt;
-    /** */&lt;br/&gt;
-    @Override&lt;br/&gt;
-    public void onCompleted() {
-      closeAndTerminateOutstandingRequests(
-          new IllegalStateException(&quot;SDK harness closed connection&quot;));
-    }&lt;br/&gt;
-&lt;br/&gt;
-    @Override&lt;br/&gt;
-    public void onError(Throwable cause) {&lt;br/&gt;
-      LOG.error(&quot;{} received error {}&quot;, FnApiControlClient.class.getSimpleName(), cause);&lt;br/&gt;
-      closeAndTerminateOutstandingRequests(cause);&lt;br/&gt;
-    }&lt;br/&gt;
-  }&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnApiControlClientPoolService.java b/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnApiControlClientPoolService.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 21fc4f73fd0..00000000000&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnApiControlClientPoolService.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,72 +0,0 @@&lt;br/&gt;
-/*&lt;br/&gt;
- * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
- * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
- * distributed with this work for additional information&lt;br/&gt;
- * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
- * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
- * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
- * with the License.  You may obtain a copy of the License at&lt;br/&gt;
- *&lt;br/&gt;
- *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
- *&lt;br/&gt;
- * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
- * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
- * See the License for the specific language governing permissions and&lt;br/&gt;
- * limitations under the License.&lt;br/&gt;
- */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import io.grpc.stub.StreamObserver;&lt;br/&gt;
-import java.util.concurrent.BlockingQueue;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnControlGrpc;&lt;br/&gt;
-import org.slf4j.Logger;&lt;br/&gt;
-import org.slf4j.LoggerFactory;&lt;br/&gt;
-&lt;br/&gt;
-/**&lt;br/&gt;
- * A Fn API control service which adds incoming SDK harness connections to a pool.&lt;br/&gt;
- *&lt;br/&gt;
- * @deprecated Runners should depend on the beam-runners-java-fn-execution module for this&lt;br/&gt;
- *     functionality.&lt;br/&gt;
- */&lt;br/&gt;
-@Deprecated&lt;br/&gt;
-public class FnApiControlClientPoolService extends BeamFnControlGrpc.BeamFnControlImplBase {&lt;br/&gt;
-  private static final Logger LOGGER = LoggerFactory.getLogger(FnApiControlClientPoolService.class);&lt;br/&gt;
-&lt;br/&gt;
-  private final BlockingQueue&amp;lt;FnApiControlClient&amp;gt; clientPool;&lt;br/&gt;
-&lt;br/&gt;
-  private FnApiControlClientPoolService(BlockingQueue&amp;lt;FnApiControlClient&amp;gt; clientPool) {
-    this.clientPool = clientPool;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * Creates a new {@link FnApiControlClientPoolService} which will enqueue and vend new SDK harness&lt;br/&gt;
-   * connections.&lt;br/&gt;
-   */&lt;br/&gt;
-  public static FnApiControlClientPoolService offeringClientsToPool(&lt;br/&gt;
-      BlockingQueue&amp;lt;FnApiControlClient&amp;gt; clientPool) {
-    return new FnApiControlClientPoolService(clientPool);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * Called by gRPC for each incoming connection from an SDK harness, and enqueue an available SDK&lt;br/&gt;
-   * harness client.&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;Note: currently does not distinguish what sort of SDK it is, so a separate instance is&lt;br/&gt;
-   * required for each.&lt;br/&gt;
-   */&lt;br/&gt;
-  @Override&lt;br/&gt;
-  public StreamObserver&amp;lt;BeamFnApi.InstructionResponse&amp;gt; control(&lt;br/&gt;
-      StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt; requestObserver) {&lt;br/&gt;
-    LOGGER.info(&quot;Beam Fn Control client connected.&quot;);&lt;br/&gt;
-    FnApiControlClient newClient = FnApiControlClient.forRequestObserver(requestObserver);&lt;br/&gt;
-    try {
-      clientPool.put(newClient);
-    } catch (InterruptedException e) {
-      Thread.currentThread().interrupt();
-      throw new RuntimeException(e);
-    }&lt;br/&gt;
-    return newClient.asResponseObserver();&lt;br/&gt;
-  }&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/SdkHarnessClient.java b/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/SdkHarnessClient.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 091dea14168..00000000000&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/SdkHarnessClient.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,176 +0,0 @@&lt;br/&gt;
-/*&lt;br/&gt;
- * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
- * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
- * distributed with this work for additional information&lt;br/&gt;
- * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
- * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
- * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
- * with the License.  You may obtain a copy of the License at&lt;br/&gt;
- *&lt;br/&gt;
- *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
- *&lt;br/&gt;
- * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
- * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
- * See the License for the specific language governing permissions and&lt;br/&gt;
- * limitations under the License.&lt;br/&gt;
- */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import com.google.auto.value.AutoValue;&lt;br/&gt;
-import com.google.common.base.Function;&lt;br/&gt;
-import com.google.common.util.concurrent.Futures;&lt;br/&gt;
-import com.google.common.util.concurrent.ListenableFuture;&lt;br/&gt;
-import java.io.IOException;&lt;br/&gt;
-import java.util.concurrent.Future;&lt;br/&gt;
-import java.util.concurrent.atomic.AtomicLong;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
-&lt;br/&gt;
-/**&lt;br/&gt;
- * A high-level client for an SDK harness.&lt;br/&gt;
- *&lt;br/&gt;
- * &amp;lt;p&amp;gt;This provides a Java-friendly wrapper around {@link FnApiControlClient}
&lt;p&gt; and &lt;/p&gt;
{@link
- * FnDataReceiver}, which handle lower-level gRPC message wrangling.&lt;br/&gt;
- *&lt;br/&gt;
- * @deprecated Runners should depend on the beam-runners-java-fn-execution module for this&lt;br/&gt;
- *     functionality.&lt;br/&gt;
- */&lt;br/&gt;
-@Deprecated&lt;br/&gt;
-public class SdkHarnessClient {&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * A supply of unique identifiers, used internally. These must be unique across all Fn API&lt;br/&gt;
-   * clients.&lt;br/&gt;
-   */&lt;br/&gt;
-  public interface IdGenerator {
-    String getId();
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /** A supply of unique identifiers that are simply incrementing longs. */&lt;br/&gt;
-  private static class CountingIdGenerator implements IdGenerator {&lt;br/&gt;
-    private final AtomicLong nextId = new AtomicLong(0L);&lt;br/&gt;
-&lt;br/&gt;
-    @Override&lt;br/&gt;
-    public String getId() {
-      return String.valueOf(nextId.incrementAndGet());
-    }&lt;br/&gt;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * An active bundle for a particular {@link
-   * BeamFnApi.ProcessBundleDescriptor}.&lt;br/&gt;
-   */&lt;br/&gt;
-  @AutoValue&lt;br/&gt;
-  public abstract static class ActiveBundle&amp;lt;InputT&amp;gt; {&lt;br/&gt;
-    public abstract String getBundleId();&lt;br/&gt;
-&lt;br/&gt;
-    public abstract Future&amp;lt;BeamFnApi.ProcessBundleResponse&amp;gt; getBundleResponse();&lt;br/&gt;
-&lt;br/&gt;
-    public abstract FnDataReceiver&amp;lt;InputT&amp;gt; getInputReceiver();&lt;br/&gt;
-&lt;br/&gt;
-    public static &amp;lt;InputT&amp;gt; ActiveBundle&amp;lt;InputT&amp;gt; create(&lt;br/&gt;
-        String bundleId,&lt;br/&gt;
-        Future&amp;lt;BeamFnApi.ProcessBundleResponse&amp;gt; response,&lt;br/&gt;
-        FnDataReceiver&amp;lt;InputT&amp;gt; dataReceiver) {
-      return new AutoValue_SdkHarnessClient_ActiveBundle(bundleId, response, dataReceiver);
-    }&lt;br/&gt;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  private final IdGenerator idGenerator;&lt;br/&gt;
-  private final FnApiControlClient fnApiControlClient;&lt;br/&gt;
-&lt;br/&gt;
-  private SdkHarnessClient(&lt;br/&gt;
-      FnApiControlClient fnApiControlClient,&lt;br/&gt;
-      IdGenerator idGenerator) {
-    this.idGenerator = idGenerator;
-    this.fnApiControlClient = fnApiControlClient;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * Creates a client for a particular SDK harness. It is the responsibility of the caller to ensure&lt;br/&gt;
-   * that these correspond to the same SDK harness, so control plane and data plane messages can be&lt;br/&gt;
-   * correctly associated.&lt;br/&gt;
-   */&lt;br/&gt;
-  public static SdkHarnessClient usingFnApiClient(FnApiControlClient fnApiControlClient) {
-    return new SdkHarnessClient(fnApiControlClient, new CountingIdGenerator());
-  }&lt;br/&gt;
-&lt;br/&gt;
-  public SdkHarnessClient withIdGenerator(IdGenerator idGenerator) {
-    return new SdkHarnessClient(fnApiControlClient, idGenerator);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * Registers a {@link BeamFnApi.ProcessBundleDescriptor} for future&lt;br/&gt;
-   * processing.&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;A client may block on the result future, but may also proceed without blocking.&lt;br/&gt;
-   */&lt;br/&gt;
-  public Future&amp;lt;BeamFnApi.RegisterResponse&amp;gt; register(&lt;br/&gt;
-      Iterable&amp;lt;BeamFnApi.ProcessBundleDescriptor&amp;gt; processBundleDescriptors) {&lt;br/&gt;
-&lt;br/&gt;
-    // TODO: validate that all the necessary data endpoints are known&lt;br/&gt;
-&lt;br/&gt;
-    ListenableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; genericResponse =&lt;br/&gt;
-        fnApiControlClient.handle(&lt;br/&gt;
-            BeamFnApi.InstructionRequest.newBuilder()&lt;br/&gt;
-                .setInstructionId(idGenerator.getId())&lt;br/&gt;
-                .setRegister(&lt;br/&gt;
-                    BeamFnApi.RegisterRequest.newBuilder()&lt;br/&gt;
-                        .addAllProcessBundleDescriptor(processBundleDescriptors)&lt;br/&gt;
-                        .build())&lt;br/&gt;
-                .build());&lt;br/&gt;
-&lt;br/&gt;
-    return Futures.transform(&lt;br/&gt;
-        genericResponse,&lt;br/&gt;
-        new Function&amp;lt;BeamFnApi.InstructionResponse, BeamFnApi.RegisterResponse&amp;gt;() {&lt;br/&gt;
-          @Override&lt;br/&gt;
-          public BeamFnApi.RegisterResponse apply(BeamFnApi.InstructionResponse input) {
-            return input.getRegister();
-          }&lt;br/&gt;
-        });&lt;br/&gt;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * Start a new bundle for the given {@link-   * BeamFnApi.ProcessBundleDescriptor} identifier.&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;The input channels for the returned {@link ActiveBundle} are derived from the&lt;br/&gt;
-   * instructions in the {@link BeamFnApi.ProcessBundleDescriptor}.&lt;br/&gt;
-   */&lt;br/&gt;
-  public ActiveBundle newBundle(String processBundleDescriptorId) {&lt;br/&gt;
-    String bundleId = idGenerator.getId();&lt;br/&gt;
-&lt;br/&gt;
-    // TODO: acquire an input receiver from appropriate FnDataService&lt;br/&gt;
-    FnDataReceiver dataReceiver = new FnDataReceiver() {&lt;br/&gt;
-      @Override&lt;br/&gt;
-      public void accept(Object input) throws Exception {
-        throw new UnsupportedOperationException(&quot;Placeholder FnDataReceiver cannot accept data.&quot;);
-      }&lt;br/&gt;
-&lt;br/&gt;
-      @Override&lt;br/&gt;
-      public void close() throws IOException {
-        // noop
-      }&lt;br/&gt;
-    };&lt;br/&gt;
-&lt;br/&gt;
-    ListenableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; genericResponse =&lt;br/&gt;
-        fnApiControlClient.handle(&lt;br/&gt;
-            BeamFnApi.InstructionRequest.newBuilder()&lt;br/&gt;
-                .setProcessBundle(&lt;br/&gt;
-                    BeamFnApi.ProcessBundleRequest.newBuilder()&lt;br/&gt;
-                        .setProcessBundleDescriptorReference(processBundleDescriptorId))&lt;br/&gt;
-                .build());&lt;br/&gt;
-&lt;br/&gt;
-    ListenableFuture&amp;lt;BeamFnApi.ProcessBundleResponse&amp;gt; specificResponse =&lt;br/&gt;
-        Futures.transform(&lt;br/&gt;
-            genericResponse,&lt;br/&gt;
-            new Function&amp;lt;BeamFnApi.InstructionResponse, BeamFnApi.ProcessBundleResponse&amp;gt;() {&lt;br/&gt;
-              @Override&lt;br/&gt;
-              public BeamFnApi.ProcessBundleResponse apply(BeamFnApi.InstructionResponse input) {
-                return input.getProcessBundle();
-              }&lt;br/&gt;
-            });&lt;br/&gt;
-&lt;br/&gt;
-    return ActiveBundle.create(bundleId, specificResponse, dataReceiver);&lt;br/&gt;
-  }&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/SdkHarnessDoFnRunner.java b/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/SdkHarnessDoFnRunner.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index d27077fdde3..00000000000&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/SdkHarnessDoFnRunner.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,108 +0,0 @@&lt;br/&gt;
-/*&lt;br/&gt;
- * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
- * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
- * distributed with this work for additional information&lt;br/&gt;
- * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
- * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
- * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
- * with the License.  You may obtain a copy of the License at&lt;br/&gt;
- *&lt;br/&gt;
- *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
- *&lt;br/&gt;
- * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
- * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
- * See the License for the specific language governing permissions and&lt;br/&gt;
- * limitations under the License.&lt;br/&gt;
- */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import static com.google.common.base.Preconditions.checkState;&lt;br/&gt;
-&lt;br/&gt;
-import java.util.concurrent.ExecutionException;&lt;br/&gt;
-import javax.annotation.Nullable;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi.ProcessBundleDescriptor;&lt;br/&gt;
-import org.apache.beam.runners.core.DoFnRunner;&lt;br/&gt;
-import org.apache.beam.sdk.state.TimeDomain;&lt;br/&gt;
-import org.apache.beam.sdk.transforms.windowing.BoundedWindow;&lt;br/&gt;
-import org.apache.beam.sdk.util.UserCodeException;&lt;br/&gt;
-import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.joda.time.Instant;&lt;br/&gt;
-&lt;br/&gt;
-/**&lt;br/&gt;
- * Processes a bundle by sending it to an SDK harness over the Fn API.&lt;br/&gt;
- *&lt;br/&gt;
- * @deprecated Runners should interact with the Control and Data plane directly, rather than through&lt;br/&gt;
- *     a {@link DoFnRunner}. Consider the beam-runners-java-fn-execution artifact instead.&lt;br/&gt;
- */&lt;br/&gt;
-@Deprecated&lt;br/&gt;
-public class SdkHarnessDoFnRunner&amp;lt;InputT, OutputT&amp;gt; implements DoFnRunner&amp;lt;InputT, OutputT&amp;gt; {&lt;br/&gt;
-&lt;br/&gt;
-  private final SdkHarnessClient sdkHarnessClient;&lt;br/&gt;
-  private final String processBundleDescriptorId;&lt;br/&gt;
-&lt;br/&gt;
-  /** {@code null} between bundles. */&lt;br/&gt;
-  @Nullable private SdkHarnessClient.ActiveBundle activeBundle;&lt;br/&gt;
-&lt;br/&gt;
-  private SdkHarnessDoFnRunner(&lt;br/&gt;
-      SdkHarnessClient sdkHarnessClient,&lt;br/&gt;
-      String processBundleDescriptorId) {
-    this.sdkHarnessClient = sdkHarnessClient;
-    this.processBundleDescriptorId = processBundleDescriptorId;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  /**&lt;br/&gt;
-   * Returns a new {@link SdkHarnessDoFnRunner} suitable for just a particular {@link
-   * ProcessBundleDescriptor} (referenced by id here).&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;The {@link FnDataReceiver} must be the correct data plane service referenced&lt;br/&gt;
-   * in the primitive instructions in the&lt;br/&gt;
-   * {@link ProcessBundleDescriptor}.&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;Also outside of this class, the appropriate receivers must be registered with the&lt;br/&gt;
-   * output data plane channels of the descriptor.&lt;br/&gt;
-   */&lt;br/&gt;
-  public static &amp;lt;InputT, OutputT&amp;gt; SdkHarnessDoFnRunner&amp;lt;InputT, OutputT&amp;gt; create(&lt;br/&gt;
-      SdkHarnessClient sdkHarnessClient,&lt;br/&gt;
-      String processBundleDescriptorId) {
-    return new SdkHarnessDoFnRunner(sdkHarnessClient, processBundleDescriptorId);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Override&lt;br/&gt;
-  public void startBundle() {
-    this.activeBundle =
-        sdkHarnessClient.newBundle(processBundleDescriptorId);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Override&lt;br/&gt;
-  public void processElement(WindowedValue&amp;lt;InputT&amp;gt; elem) {&lt;br/&gt;
-    checkState(&lt;br/&gt;
-        activeBundle != null,&lt;br/&gt;
-        &quot;%s attempted to process an element without an active bundle&quot;,&lt;br/&gt;
-        SdkHarnessDoFnRunner.class.getSimpleName());&lt;br/&gt;
-&lt;br/&gt;
-    try {
-      activeBundle.getInputReceiver().accept(elem);
-    } catch (Exception exc) {
-      throw new RuntimeException(exc);
-    }&lt;br/&gt;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Override&lt;br/&gt;
-  public void onTimer(&lt;br/&gt;
-      String timerId, BoundedWindow window, Instant timestamp, TimeDomain timeDomain) {
-    throw new UnsupportedOperationException(&quot;Timers are not supported over the Fn API&quot;);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Override&lt;br/&gt;
-  public void finishBundle() {&lt;br/&gt;
-    try {
-      activeBundle.getBundleResponse().get();
-    } catch (InterruptedException interrupted) {
-      Thread.interrupted();
-      return;
-    } catch (ExecutionException exc) {
-      throw UserCodeException.wrap(exc);
-    }&lt;br/&gt;
-  }&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/FnApiControlClientPoolServiceTest.java b/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/FnApiControlClientPoolServiceTest.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index da02d924eef..00000000000&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/FnApiControlClientPoolServiceTest.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,65 +0,0 @@&lt;br/&gt;
-/*&lt;br/&gt;
- * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
- * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
- * distributed with this work for additional information&lt;br/&gt;
- * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
- * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
- * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
- * with the License.  You may obtain a copy of the License at&lt;br/&gt;
- *&lt;br/&gt;
- *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
- *&lt;br/&gt;
- * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
- * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
- * See the License for the specific language governing permissions and&lt;br/&gt;
- * limitations under the License.&lt;br/&gt;
- */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import static org.hamcrest.Matchers.is;&lt;br/&gt;
-import static org.junit.Assert.assertThat;&lt;br/&gt;
-import static org.mockito.Matchers.any;&lt;br/&gt;
-import static org.mockito.Mockito.mock;&lt;br/&gt;
-import static org.mockito.Mockito.verify;&lt;br/&gt;
-&lt;br/&gt;
-import com.google.common.util.concurrent.ListenableFuture;&lt;br/&gt;
-import io.grpc.stub.StreamObserver;&lt;br/&gt;
-import java.util.concurrent.BlockingQueue;&lt;br/&gt;
-import java.util.concurrent.LinkedBlockingQueue;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
-import org.junit.Test;&lt;br/&gt;
-import org.junit.runner.RunWith;&lt;br/&gt;
-import org.junit.runners.JUnit4;&lt;br/&gt;
-&lt;br/&gt;
-/** Unit tests for {@link FnApiControlClientPoolService}. */&lt;br/&gt;
-@RunWith(JUnit4.class)&lt;br/&gt;
-public class FnApiControlClientPoolServiceTest {&lt;br/&gt;
-&lt;br/&gt;
-  // For ease of straight-line testing, we use a LinkedBlockingQueue; in practice a SynchronousQueue&lt;br/&gt;
-  // for matching incoming connections and server threads is likely.&lt;br/&gt;
-  private final BlockingQueue&amp;lt;FnApiControlClient&amp;gt; pool = new LinkedBlockingQueue&amp;lt;&amp;gt;();&lt;br/&gt;
-  private FnApiControlClientPoolService controlService =&lt;br/&gt;
-      FnApiControlClientPoolService.offeringClientsToPool(pool);&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testIncomingConnection() throws Exception {
-    StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt; requestObserver = mock(StreamObserver.class);
-    StreamObserver&amp;lt;BeamFnApi.InstructionResponse&amp;gt; responseObserver =
-        controlService.control(requestObserver);
-
-    FnApiControlClient client = pool.take();
-
-    // Check that the client is wired up to the request channel
-    String id = &quot;fakeInstruction&quot;;
-    ListenableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; responseFuture =
-        client.handle(BeamFnApi.InstructionRequest.newBuilder().setInstructionId(id).build());
-    verify(requestObserver).onNext(any(BeamFnApi.InstructionRequest.class));
-    assertThat(responseFuture.isDone(), is(false));
-
-    // Check that the response channel really came from the client
-    responseObserver.onNext(
-        BeamFnApi.InstructionResponse.newBuilder().setInstructionId(id).build());
-    responseFuture.get();
-  }&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/FnApiControlClientTest.java b/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/FnApiControlClientTest.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 279e974cc31..00000000000&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/FnApiControlClientTest.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,139 +0,0 @@&lt;br/&gt;
-/*&lt;br/&gt;
- * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
- * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
- * distributed with this work for additional information&lt;br/&gt;
- * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
- * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
- * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
- * with the License.  You may obtain a copy of the License at&lt;br/&gt;
- *&lt;br/&gt;
- *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
- *&lt;br/&gt;
- * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
- * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
- * See the License for the specific language governing permissions and&lt;br/&gt;
- * limitations under the License.&lt;br/&gt;
- */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import static org.hamcrest.Matchers.equalTo;&lt;br/&gt;
-import static org.hamcrest.Matchers.is;&lt;br/&gt;
-import static org.hamcrest.Matchers.isA;&lt;br/&gt;
-import static org.junit.Assert.assertThat;&lt;br/&gt;
-import static org.mockito.Matchers.any;&lt;br/&gt;
-import static org.mockito.Mockito.verify;&lt;br/&gt;
-&lt;br/&gt;
-import com.google.common.util.concurrent.ListenableFuture;&lt;br/&gt;
-import io.grpc.stub.StreamObserver;&lt;br/&gt;
-import java.util.concurrent.ExecutionException;&lt;br/&gt;
-import java.util.concurrent.Future;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
-import org.junit.Before;&lt;br/&gt;
-import org.junit.Rule;&lt;br/&gt;
-import org.junit.Test;&lt;br/&gt;
-import org.junit.rules.ExpectedException;&lt;br/&gt;
-import org.junit.runner.RunWith;&lt;br/&gt;
-import org.junit.runners.JUnit4;&lt;br/&gt;
-import org.mockito.Mock;&lt;br/&gt;
-import org.mockito.MockitoAnnotations;&lt;br/&gt;
-&lt;br/&gt;
-/** Unit tests for {@link FnApiControlClient}. */&lt;br/&gt;
-@RunWith(JUnit4.class)&lt;br/&gt;
-public class FnApiControlClientTest {&lt;br/&gt;
-&lt;br/&gt;
-  @Rule public ExpectedException thrown = ExpectedException.none();&lt;br/&gt;
-&lt;br/&gt;
-  @Mock public StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt; mockObserver;&lt;br/&gt;
-  private FnApiControlClient client;&lt;br/&gt;
-&lt;br/&gt;
-  @Before&lt;br/&gt;
-  public void setup() {
-    MockitoAnnotations.initMocks(this);
-    client = FnApiControlClient.forRequestObserver(mockObserver);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testRequestSent() {
-    String id = &quot;instructionId&quot;;
-    client.handle(BeamFnApi.InstructionRequest.newBuilder().setInstructionId(id).build());
-
-    verify(mockObserver).onNext(any(BeamFnApi.InstructionRequest.class));
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testRequestSuccess() throws Exception {
-    String id = &quot;successfulInstruction&quot;;
-
-    Future&amp;lt;BeamFnApi.InstructionResponse&amp;gt; responseFuture =
-        client.handle(BeamFnApi.InstructionRequest.newBuilder().setInstructionId(id).build());
-    client
-        .asResponseObserver()
-        .onNext(BeamFnApi.InstructionResponse.newBuilder().setInstructionId(id).build());
-
-    BeamFnApi.InstructionResponse response = responseFuture.get();
-
-    assertThat(response.getInstructionId(), equalTo(id));
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testUnknownResponseIgnored() throws Exception {
-    String id = &quot;actualInstruction&quot;;
-    String unknownId = &quot;unknownInstruction&quot;;
-
-    ListenableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; responseFuture =
-        client.handle(BeamFnApi.InstructionRequest.newBuilder().setInstructionId(id).build());
-
-    client
-        .asResponseObserver()
-        .onNext(BeamFnApi.InstructionResponse.newBuilder().setInstructionId(unknownId).build());
-
-    assertThat(responseFuture.isDone(), is(false));
-    assertThat(responseFuture.isCancelled(), is(false));
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testOnCompletedCancelsOutstanding() throws Exception {
-    String id = &quot;clientHangUpInstruction&quot;;
-
-    Future&amp;lt;BeamFnApi.InstructionResponse&amp;gt; responseFuture =
-        client.handle(BeamFnApi.InstructionRequest.newBuilder().setInstructionId(id).build());
-
-    client.asResponseObserver().onCompleted();
-
-    thrown.expect(ExecutionException.class);
-    thrown.expectCause(isA(IllegalStateException.class));
-    thrown.expectMessage(&quot;closed&quot;);
-    responseFuture.get();
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testOnErrorCancelsOutstanding() throws Exception {&lt;br/&gt;
-    String id = &quot;errorInstruction&quot;;&lt;br/&gt;
-&lt;br/&gt;
-    Future&amp;lt;BeamFnApi.InstructionResponse&amp;gt; responseFuture =&lt;br/&gt;
-        client.handle(BeamFnApi.InstructionRequest.newBuilder().setInstructionId(id).build());&lt;br/&gt;
-&lt;br/&gt;
-    class FrazzleException extends Exception {}&lt;br/&gt;
-    client.asResponseObserver().onError(new FrazzleException());&lt;br/&gt;
-&lt;br/&gt;
-    thrown.expect(ExecutionException.class);&lt;br/&gt;
-    thrown.expectCause(isA(FrazzleException.class));&lt;br/&gt;
-    responseFuture.get();&lt;br/&gt;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testCloseCancelsOutstanding() throws Exception {
-    String id = &quot;serverCloseInstruction&quot;;
-
-    Future&amp;lt;BeamFnApi.InstructionResponse&amp;gt; responseFuture =
-        client.handle(BeamFnApi.InstructionRequest.newBuilder().setInstructionId(id).build());
-
-    client.close();
-
-    thrown.expect(ExecutionException.class);
-    thrown.expectCause(isA(IllegalStateException.class));
-    thrown.expectMessage(&quot;closed&quot;);
-    responseFuture.get();
-  }&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/SdkHarnessClientTest.java b/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/SdkHarnessClientTest.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 7783b2f2f88..00000000000&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/SdkHarnessClientTest.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,96 +0,0 @@&lt;br/&gt;
-/*&lt;br/&gt;
- * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
- * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
- * distributed with this work for additional information&lt;br/&gt;
- * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
- * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
- * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
- * with the License.  You may obtain a copy of the License at&lt;br/&gt;
- *&lt;br/&gt;
- *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
- *&lt;br/&gt;
- * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
- * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
- * See the License for the specific language governing permissions and&lt;br/&gt;
- * limitations under the License.&lt;br/&gt;
- */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import static org.mockito.Matchers.any;&lt;br/&gt;
-import static org.mockito.Mockito.when;&lt;br/&gt;
-&lt;br/&gt;
-import com.google.common.collect.ImmutableList;&lt;br/&gt;
-import com.google.common.util.concurrent.SettableFuture;&lt;br/&gt;
-import java.util.concurrent.Future;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
-import org.junit.Before;&lt;br/&gt;
-import org.junit.Test;&lt;br/&gt;
-import org.junit.runner.RunWith;&lt;br/&gt;
-import org.junit.runners.JUnit4;&lt;br/&gt;
-import org.mockito.Mock;&lt;br/&gt;
-import org.mockito.MockitoAnnotations;&lt;br/&gt;
-&lt;br/&gt;
-/** Unit tests for {@link SdkHarnessClient}. */&lt;br/&gt;
-@RunWith(JUnit4.class)&lt;br/&gt;
-public class SdkHarnessClientTest {&lt;br/&gt;
-&lt;br/&gt;
-  @Mock public FnApiControlClient fnApiControlClient;&lt;br/&gt;
-&lt;br/&gt;
-  private SdkHarnessClient sdkHarnessClient;&lt;br/&gt;
-&lt;br/&gt;
-  @Before&lt;br/&gt;
-  public void setup() {
-    MockitoAnnotations.initMocks(this);
-    sdkHarnessClient = SdkHarnessClient.usingFnApiClient(fnApiControlClient);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testRegisterDoesNotCrash() throws Exception {
-    String descriptorId1 = &quot;descriptor1&quot;;
-    String descriptorId2 = &quot;descriptor2&quot;;
-
-    SettableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; registerResponseFuture = SettableFuture.create();
-    when(fnApiControlClient.handle(any(BeamFnApi.InstructionRequest.class)))
-        .thenReturn(registerResponseFuture);
-
-    Future&amp;lt;BeamFnApi.RegisterResponse&amp;gt; responseFuture = sdkHarnessClient.register(
-        ImmutableList.of(
-            BeamFnApi.ProcessBundleDescriptor.newBuilder().setId(descriptorId1).build(),
-            BeamFnApi.ProcessBundleDescriptor.newBuilder().setId(descriptorId2).build()));
-
-    // Correlating the RegisterRequest and RegisterResponse is owned by the underlying
-    // FnApiControlClient. The SdkHarnessClient owns just wrapping the request and unwrapping
-    // the response.
-    //
-    // Currently there are no fields so there&apos;s nothing to check. This test is formulated
-    // to match the pattern it should have if/when the response is meaningful.
-    BeamFnApi.RegisterResponse response = BeamFnApi.RegisterResponse.getDefaultInstance();
-    registerResponseFuture.set(
-        BeamFnApi.InstructionResponse.newBuilder().setRegister(response).build());
-    responseFuture.get();
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testNewBundleNoDataDoesNotCrash() throws Exception {
-    String descriptorId1 = &quot;descriptor1&quot;;
-
-    SettableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; processBundleResponseFuture =
-        SettableFuture.create();
-    when(fnApiControlClient.handle(any(BeamFnApi.InstructionRequest.class)))
-        .thenReturn(processBundleResponseFuture);
-
-    SdkHarnessClient.ActiveBundle activeBundle = sdkHarnessClient.newBundle(descriptorId1);
-
-    // Correlating the ProcessBundleRequest and ProcessBundleReponse is owned by the underlying
-    // FnApiControlClient. The SdkHarnessClient owns just wrapping the request and unwrapping
-    // the response.
-    //
-    // Currently there are no fields so there&apos;s nothing to check. This test is formulated
-    // to match the pattern it should have if/when the response is meaningful.
-    BeamFnApi.ProcessBundleResponse response = BeamFnApi.ProcessBundleResponse.getDefaultInstance();
-    processBundleResponseFuture.set(
-        BeamFnApi.InstructionResponse.newBuilder().setProcessBundle(response).build());
-    activeBundle.getBundleResponse().get();
-  }&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/SdkHarnessDoFnRunnerTest.java b/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/SdkHarnessDoFnRunnerTest.java&lt;br/&gt;
deleted file mode 100644&lt;br/&gt;
index 8f160049e05..00000000000&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/test/java/org/apache/beam/runners/core/fn/SdkHarnessDoFnRunnerTest.java&lt;br/&gt;
+++ /dev/null&lt;br/&gt;
@@ -1,73 +0,0 @@&lt;br/&gt;
-/*&lt;br/&gt;
- * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
- * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
- * distributed with this work for additional information&lt;br/&gt;
- * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
- * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
- * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
- * with the License.  You may obtain a copy of the License at&lt;br/&gt;
- *&lt;br/&gt;
- *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
- *&lt;br/&gt;
- * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
- * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
- * See the License for the specific language governing permissions and&lt;br/&gt;
- * limitations under the License.&lt;br/&gt;
- */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import static org.junit.Assert.fail;&lt;br/&gt;
-import static org.mockito.Matchers.anyString;&lt;br/&gt;
-import static org.mockito.Mockito.when;&lt;br/&gt;
-&lt;br/&gt;
-import com.google.common.util.concurrent.SettableFuture;&lt;br/&gt;
-import java.io.IOException;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
-import org.junit.Before;&lt;br/&gt;
-import org.junit.Test;&lt;br/&gt;
-import org.junit.runner.RunWith;&lt;br/&gt;
-import org.junit.runners.JUnit4;&lt;br/&gt;
-import org.mockito.Mock;&lt;br/&gt;
-import org.mockito.MockitoAnnotations;&lt;br/&gt;
-&lt;br/&gt;
-/** Unit tests for {@link SdkHarnessDoFnRunner}. */&lt;br/&gt;
-@RunWith(JUnit4.class)&lt;br/&gt;
-public class SdkHarnessDoFnRunnerTest {&lt;br/&gt;
-  @Mock private SdkHarnessClient mockClient;&lt;br/&gt;
-&lt;br/&gt;
-  @Before&lt;br/&gt;
-  public void setUp() {
-    MockitoAnnotations.initMocks(this);
-  }&lt;br/&gt;
-&lt;br/&gt;
-  @Test&lt;br/&gt;
-  public void testStartAndFinishBundleDoesNotCrash() {&lt;br/&gt;
-    String processBundleDescriptorId = &quot;testDescriptor&quot;;&lt;br/&gt;
-    String bundleId = &quot;testBundle&quot;;&lt;br/&gt;
-    SdkHarnessDoFnRunner&amp;lt;Void, Void&amp;gt; underTest =&lt;br/&gt;
-        SdkHarnessDoFnRunner.&amp;lt;Void, Void&amp;gt;create(mockClient, processBundleDescriptorId);&lt;br/&gt;
-&lt;br/&gt;
-    SettableFuture&amp;lt;BeamFnApi.ProcessBundleResponse&amp;gt; processBundleResponseFuture =&lt;br/&gt;
-        SettableFuture.create();&lt;br/&gt;
-    FnDataReceiver dummyInputReceiver = new FnDataReceiver() {&lt;br/&gt;
-      @Override&lt;br/&gt;
-      public void accept(Object input) throws Exception {
-        fail(&quot;Dummy input receiver should not have received data&quot;);
-      }&lt;br/&gt;
-&lt;br/&gt;
-      @Override&lt;br/&gt;
-      public void close() throws IOException {-        // noop-      }&lt;br/&gt;
-    };&lt;br/&gt;
-    SdkHarnessClient.ActiveBundle activeBundle =&lt;br/&gt;
-        SdkHarnessClient.ActiveBundle.create(&lt;br/&gt;
-            bundleId, processBundleResponseFuture, dummyInputReceiver);&lt;br/&gt;
-&lt;br/&gt;
-    when(mockClient.newBundle(anyString())).thenReturn(activeBundle);&lt;br/&gt;
-    underTest.startBundle();&lt;br/&gt;
-    processBundleResponseFuture.set(BeamFnApi.ProcessBundleResponse.getDefaultInstance());&lt;br/&gt;
-    underTest.finishBundle();&lt;br/&gt;
-  }&lt;br/&gt;
-}&lt;br/&gt;
diff --git a/runners/flink/pom.xml b/runners/flink/pom.xml&lt;br/&gt;
index a6ab44bcea5..7840c328c9a 100644&lt;br/&gt;
&amp;#8212; a/runners/flink/pom.xml&lt;br/&gt;
+++ b/runners/flink/pom.xml&lt;br/&gt;
@@ -87,10 +87,6 @@&lt;br/&gt;
                   &amp;lt;goal&amp;gt;test&amp;lt;/goal&amp;gt;&lt;br/&gt;
                 &amp;lt;/goals&amp;gt;&lt;br/&gt;
                 &amp;lt;configuration&amp;gt;&lt;br/&gt;
-                  &amp;lt;!-- &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3244&quot; title=&quot;Flink runner does not respect ParDo&amp;#39;s lifecycle on case of exceptions&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3244&quot;&gt;&lt;del&gt;BEAM-3244&lt;/del&gt;&lt;/a&gt; --&amp;gt;&lt;br/&gt;
-                  &amp;lt;excludes&amp;gt;&lt;br/&gt;
-                    &amp;lt;exclude&amp;gt;org.apache.beam.sdk.transforms.ParDoLifecycleTest&amp;lt;/exclude&amp;gt;&lt;br/&gt;
-                  &amp;lt;/excludes&amp;gt;&lt;br/&gt;
                   &amp;lt;groups&amp;gt;org.apache.beam.sdk.testing.ValidatesRunner&amp;lt;/groups&amp;gt;&lt;br/&gt;
                   &amp;lt;excludedGroups&amp;gt;&lt;br/&gt;
                     org.apache.beam.sdk.testing.FlattenWithHeterogeneousCoders,&lt;br/&gt;
diff --git a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java&lt;br/&gt;
index d203ffb67dc..fcee0549706 100644&lt;br/&gt;
&amp;#8212; a/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java&lt;br/&gt;
+++ b/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java&lt;br/&gt;
@@ -361,6 +361,16 @@ public void onProcessingTime(long timestamp) throws Exception {
         SimplePushbackSideInputDoFnRunner.create(doFnRunner, sideInputs, sideInputHandler);
   }&lt;br/&gt;
 &lt;br/&gt;
+  @Override&lt;br/&gt;
+  public void dispose() throws Exception {&lt;br/&gt;
+    try {
+      super.dispose();
+      checkFinishBundleTimer.cancel(true);
+    } finally {
+      doFnInvoker.invokeTeardown();
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   @Override&lt;br/&gt;
   public void close() throws Exception {&lt;br/&gt;
     super.close();&lt;br/&gt;
@@ -379,8 +389,6 @@ public void close() throws Exception {&lt;br/&gt;
         }&lt;br/&gt;
       }&lt;br/&gt;
     }&lt;br/&gt;
-    checkFinishBundleTimer.cancel(true);&lt;br/&gt;
-    doFnInvoker.invokeTeardown();&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   private long getPushbackWatermarkHold() {&lt;br/&gt;
diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java&lt;br/&gt;
index a6500924149..ddad43fe6ec 100644&lt;br/&gt;
&amp;#8212; a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java&lt;br/&gt;
+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java&lt;br/&gt;
@@ -21,6 +21,7 @@&lt;br/&gt;
 import static com.google.common.base.Preconditions.checkArgument;&lt;br/&gt;
 import static com.google.common.base.Preconditions.checkState;&lt;br/&gt;
 import static com.google.common.base.Strings.isNullOrEmpty;&lt;br/&gt;
+import static org.apache.beam.sdk.util.CoderUtils.encodeToByteArray;&lt;br/&gt;
 import static org.apache.beam.sdk.util.SerializableUtils.serializeToByteArray;&lt;br/&gt;
 import static org.apache.beam.sdk.util.StringUtils.byteArrayToJsonString;&lt;br/&gt;
 &lt;br/&gt;
@@ -91,6 +92,7 @@&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder.NonDeterministicException;&lt;br/&gt;
 import org.apache.beam.sdk.coders.KvCoder;&lt;br/&gt;
+import org.apache.beam.sdk.coders.SerializableCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.VoidCoder;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.gcp.storage.PathValidator;&lt;br/&gt;
 import org.apache.beam.sdk.io.BoundedSource;&lt;br/&gt;
@@ -132,6 +134,7 @@&lt;br/&gt;
 import org.apache.beam.sdk.transforms.reflect.DoFnSignature;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.reflect.DoFnSignatures;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.BoundedWindow;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.windowing.GlobalWindow;&lt;br/&gt;
 import org.apache.beam.sdk.util.CoderUtils;&lt;br/&gt;
 import org.apache.beam.sdk.util.InstanceBuilder;&lt;br/&gt;
 import org.apache.beam.sdk.util.MimeTypes;&lt;br/&gt;
@@ -420,6 +423,13 @@ public static DataflowRunner fromOptions(PipelineOptions options) {
                   new ReflectiveViewOverrideFactory(
                       BatchViewOverrides.BatchViewAsIterable.class, this)));
     }&lt;br/&gt;
+    // Expands into Reshuffle and single-output ParDo, so has to be before the overrides below.&lt;br/&gt;
+    if (hasExperiment(options, &quot;beam_fn_api&quot;)) {
+      overridesBuilder.add(
+          PTransformOverride.of(
+              PTransformMatchers.classEqualTo(Read.Bounded.class),
+              new FnApiBoundedReadOverrideFactory()));
+    }&lt;br/&gt;
     overridesBuilder&lt;br/&gt;
         .add(&lt;br/&gt;
             PTransformOverride.of(&lt;br/&gt;
@@ -1185,7 +1195,7 @@ private StreamingFnApiCreate(&lt;br/&gt;
     public final PCollection&amp;lt;T&amp;gt; expand(PBegin input) {&lt;br/&gt;
       try {&lt;br/&gt;
         PCollection&amp;lt;T&amp;gt; pc = Pipeline&lt;br/&gt;
-            .applyTransform(input, new Impulse(IsBounded.BOUNDED))&lt;br/&gt;
+            .applyTransform(input, new Impulse())&lt;br/&gt;
             .apply(ParDo.of(DecodeAndEmitDoFn&lt;br/&gt;
                 .fromIterable(transform.getElements(), originalOutput.getCoder())));&lt;br/&gt;
         pc.setCoder(originalOutput.getCoder());&lt;br/&gt;
@@ -1206,7 +1216,7 @@ private StreamingFnApiCreate(&lt;br/&gt;
           throws IOException {&lt;br/&gt;
         ImmutableList.Builder&amp;lt;byte[]&amp;gt; allElementsBytes = ImmutableList.builder();&lt;br/&gt;
         for (T element : elements) {
-          byte[] bytes = CoderUtils.encodeToByteArray(elemCoder, element);
+          byte[] bytes = encodeToByteArray(elemCoder, element);
           allElementsBytes.add(bytes);
         }&lt;br/&gt;
         return new DecodeAndEmitDoFn&amp;lt;&amp;gt;(allElementsBytes.build(), elemCoder);&lt;br/&gt;
@@ -1244,16 +1254,16 @@ public void processElement(ProcessContext context) throws IOException {&lt;br/&gt;
 &lt;br/&gt;
   /** The Dataflow specific override for the impulse primitive. */&lt;br/&gt;
   private static class Impulse extends PTransform&amp;lt;PBegin, PCollection&amp;lt;byte[]&amp;gt;&amp;gt; {&lt;br/&gt;
-    private final IsBounded isBounded;&lt;br/&gt;
-&lt;br/&gt;
-    private Impulse(IsBounded isBounded) {&lt;br/&gt;
-      this.isBounded = isBounded;&lt;br/&gt;
+    private Impulse() {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
     public PCollection&amp;lt;byte[]&amp;gt; expand(PBegin input) {
       return PCollection.createPrimitiveOutputInternal(
-          input.getPipeline(), WindowingStrategy.globalDefault(), isBounded, ByteArrayCoder.of());
+          input.getPipeline(),
+          WindowingStrategy.globalDefault(),
+          IsBounded.BOUNDED,
+          ByteArrayCoder.of());
     }&lt;br/&gt;
 &lt;br/&gt;
     private static class Translator implements TransformTranslator&amp;lt;Impulse&amp;gt; {&lt;br/&gt;
@@ -1265,8 +1275,21 @@ public void translate(Impulse transform, TranslationContext context) {
           stepContext.addInput(PropertyNames.PUBSUB_SUBSCRIPTION, &quot;_starting_signal/&quot;);
           stepContext.addOutput(context.getOutput(transform));
         } else {&lt;br/&gt;
-          throw new UnsupportedOperationException(&lt;br/&gt;
-              &quot;Impulse source for batch pipelines has not been defined.&quot;);&lt;br/&gt;
+          StepTranslationContext stepContext = context.addStep(transform, &quot;ParallelRead&quot;);&lt;br/&gt;
+          stepContext.addInput(PropertyNames.FORMAT, &quot;impulse&quot;);&lt;br/&gt;
+          WindowedValue.FullWindowedValueCoder&amp;lt;byte[]&amp;gt; coder =&lt;br/&gt;
+              WindowedValue.getFullCoder(&lt;br/&gt;
+                  context.getOutput(transform).getCoder(), GlobalWindow.Coder.INSTANCE);&lt;br/&gt;
+          byte[] encodedImpulse;&lt;br/&gt;
+          try {
+            encodedImpulse =
+                encodeToByteArray(coder, WindowedValue.valueInGlobalWindow(new byte[0]));
+          } catch (Exception e) {
+            throw new RuntimeException(e);
+          }&lt;br/&gt;
+          stepContext.addInput(&lt;br/&gt;
+              PropertyNames.IMPULSE_ELEMENT, byteArrayToJsonString(encodedImpulse));&lt;br/&gt;
+          stepContext.addOutput(context.getOutput(transform));&lt;br/&gt;
         }&lt;br/&gt;
       }&lt;br/&gt;
     }&lt;br/&gt;
@@ -1438,6 +1461,65 @@ public StreamingBoundedRead(Read.Bounded&amp;lt;T&amp;gt; transform) {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
+  private static class FnApiBoundedReadOverrideFactory&amp;lt;T&amp;gt;&lt;br/&gt;
+      implements PTransformOverrideFactory&amp;lt;PBegin, PCollection&amp;lt;T&amp;gt;, Read.Bounded&amp;lt;T&amp;gt;&amp;gt; {&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public PTransformReplacement&amp;lt;PBegin, PCollection&amp;lt;T&amp;gt;&amp;gt; getReplacementTransform(&lt;br/&gt;
+        AppliedPTransform&amp;lt;PBegin, PCollection&amp;lt;T&amp;gt;, Read.Bounded&amp;lt;T&amp;gt;&amp;gt; transform) {
+      return PTransformReplacement.of(
+          transform.getPipeline().begin(), new FnApiBoundedRead&amp;lt;&amp;gt;(transform.getTransform()));
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public Map&amp;lt;PValue, ReplacementOutput&amp;gt; mapOutputs(&lt;br/&gt;
+        Map&amp;lt;TupleTag&amp;lt;?&amp;gt;, PValue&amp;gt; outputs, PCollection&amp;lt;T&amp;gt; newOutput) {
+      return ReplacementOutputs.singleton(outputs, newOutput);
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Specialized implementation for {@link org.apache.beam.sdk.io.Read.Bounded Read.Bounded} for the&lt;br/&gt;
+   * Dataflow runner in streaming mode.&lt;br/&gt;
+   */&lt;br/&gt;
+  private static class FnApiBoundedRead&amp;lt;T&amp;gt; extends PTransform&amp;lt;PBegin, PCollection&amp;lt;T&amp;gt;&amp;gt; {&lt;br/&gt;
+    private final BoundedSource&amp;lt;T&amp;gt; source;&lt;br/&gt;
+&lt;br/&gt;
+    public FnApiBoundedRead(Read.Bounded&amp;lt;T&amp;gt; transform) {
+      this.source = transform.getSource();
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public final PCollection&amp;lt;T&amp;gt; expand(PBegin input) {&lt;br/&gt;
+      return input&lt;br/&gt;
+          .apply(new Impulse())&lt;br/&gt;
+          .apply(&lt;br/&gt;
+              ParDo.of(&lt;br/&gt;
+                  new DoFn&amp;lt;byte[], BoundedSource&amp;lt;T&amp;gt;&amp;gt;() {&lt;br/&gt;
+                    @ProcessElement&lt;br/&gt;
+                    public void process(ProcessContext c) throws Exception {&lt;br/&gt;
+                      for (BoundedSource&amp;lt;T&amp;gt; split :&lt;br/&gt;
+                          source.split(64L &amp;lt;&amp;lt; 20, c.getPipelineOptions())) {
+                        c.output(split);
+                      }&lt;br/&gt;
+                    }&lt;br/&gt;
+                  }))&lt;br/&gt;
+          .setCoder((Coder&amp;lt;BoundedSource&amp;lt;T&amp;gt;&amp;gt;) SerializableCoder.of((Class) BoundedSource.class))&lt;br/&gt;
+          .apply(Reshuffle.&amp;lt;BoundedSource&amp;lt;T&amp;gt;&amp;gt;viaRandomKey())&lt;br/&gt;
+          .apply(&lt;br/&gt;
+              ParDo.of(&lt;br/&gt;
+                  new DoFn&amp;lt;BoundedSource&amp;lt;T&amp;gt;, T&amp;gt;() {&lt;br/&gt;
+                    @ProcessElement&lt;br/&gt;
+                    public void process(ProcessContext c) throws Exception {&lt;br/&gt;
+                      BoundedSource.BoundedReader&amp;lt;T&amp;gt; reader =&lt;br/&gt;
+                          c.element().createReader(c.getPipelineOptions());&lt;br/&gt;
+                      for (boolean more = reader.start(); more; more = reader.advance()) {
+                        c.outputWithTimestamp(reader.getCurrent(), reader.getCurrentTimestamp());
+                      }&lt;br/&gt;
+                    }&lt;br/&gt;
+                  }))&lt;br/&gt;
+          .setCoder(source.getOutputCoder());&lt;br/&gt;
+    }&lt;br/&gt;
+  }&lt;br/&gt;
   /**&lt;br/&gt;
    * A marker {@link DoFn} for writing the contents of a {@link PCollection} to a streaming&lt;br/&gt;
    * {@link PCollectionView} backend implementation.&lt;br/&gt;
diff --git a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PropertyNames.java b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PropertyNames.java&lt;br/&gt;
index 55e0c4ebff9..cdc87bf9343 100644&lt;br/&gt;
&amp;#8212; a/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PropertyNames.java&lt;br/&gt;
+++ b/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PropertyNames.java&lt;br/&gt;
@@ -64,4 +64,5 @@&lt;br/&gt;
   public static final String VALUE = &quot;value&quot;;&lt;br/&gt;
   public static final String DISPLAY_DATA = &quot;display_data&quot;;&lt;br/&gt;
   public static final String RESTRICTION_CODER = &quot;restriction_coder&quot;;&lt;br/&gt;
+  public static final String IMPULSE_ELEMENT = &quot;impulse_element&quot;;&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java&lt;br/&gt;
index 3467d53df99..edf513b7c94 100644&lt;br/&gt;
&amp;#8212; a/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java&lt;br/&gt;
+++ b/runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowRunnerTest.java&lt;br/&gt;
@@ -1344,7 +1344,7 @@ private void testStreamingWriteOverride(PipelineOptions options, int expectedNum&lt;br/&gt;
         (WriteFiles&amp;lt;Object, Void, Object&amp;gt;)&lt;br/&gt;
             factory.getReplacementTransform(originalApplication).getTransform();&lt;br/&gt;
     assertThat(replacement, not(equalTo((Object) original)));&lt;br/&gt;
-    assertThat(replacement.getNumShards().get(), equalTo(expectedNumShards));&lt;br/&gt;
+    assertThat(replacement.getNumShardsProvider().get(), equalTo(expectedNumShards));&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   private static class TestSink extends FileBasedSink&amp;lt;Object, Void, Object&amp;gt; {&lt;br/&gt;
diff --git a/runners/java-fn-execution/build.gradle b/runners/java-fn-execution/build.gradle&lt;br/&gt;
index dd4eaaed47d..e948c7ce625 100644&lt;br/&gt;
&amp;#8212; a/runners/java-fn-execution/build.gradle&lt;br/&gt;
+++ b/runners/java-fn-execution/build.gradle&lt;br/&gt;
@@ -1,5 +1,4 @@&lt;br/&gt;
-/*&lt;br/&gt;
- * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+/* * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
  * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
  * distributed with this work for additional information&lt;br/&gt;
  * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
@@ -30,18 +29,11 @@ description = &quot;Apache Beam :: Runners :: Java Fn Execution&quot;&lt;br/&gt;
  */&lt;br/&gt;
 evaluationDependsOn(&quot;:beam-sdks-parent:beam-sdks-java-parent:beam-sdks-java-fn-execution&quot;)&lt;br/&gt;
 &lt;br/&gt;
-configurations.all {
-  // Fn Execution contains shared utilities for Runners and Harnesses which use            
-  // the Portability framework. Runner-side interactions must not require a
-  // dependency on any particular SDK, so this library must not introduce such an
-  // edge.
-  exclude group: &quot;org.apache.beam&quot;, module: &quot;beam-sdks-java-core&quot;
-}&lt;br/&gt;
-&lt;br/&gt;
 dependencies {&lt;br/&gt;
   compile library.java.guava&lt;br/&gt;
   shadow project(path: &quot;:beam-model-parent:beam-model-pipeline&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
   shadow project(path: &quot;:beam-model-parent:beam-model-fn-execution&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
+  shadow project(path: &quot;:beam-sdks-parent:beam-sdks-java-parent:beam-sdks-java-core&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
   shadow project(path: &quot;:beam-sdks-parent:beam-sdks-java-parent:beam-sdks-java-fn-execution&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
   shadow library.java.grpc_core&lt;br/&gt;
   shadow library.java.grpc_stub&lt;br/&gt;
diff --git a/runners/java-fn-execution/pom.xml b/runners/java-fn-execution/pom.xml&lt;br/&gt;
index f275d69207e..f3881649eda 100644&lt;br/&gt;
&amp;#8212; a/runners/java-fn-execution/pom.xml&lt;br/&gt;
+++ b/runners/java-fn-execution/pom.xml&lt;br/&gt;
@@ -48,6 +48,11 @@&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;beam-sdks-java-fn-execution&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;br/&gt;
 &lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;beam-sdks-java-core&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
     &amp;lt;dependency&amp;gt;&lt;br/&gt;
       &amp;lt;groupId&amp;gt;io.grpc&amp;lt;/groupId&amp;gt;&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;grpc-core&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
@@ -109,5 +114,12 @@&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;mockito-all&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
       &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;slf4j-jdk14&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+      &amp;lt;version&amp;gt;${slf4j.version}&amp;lt;/version&amp;gt;&lt;br/&gt;
+      &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
   &amp;lt;/dependencies&amp;gt;&lt;br/&gt;
 &amp;lt;/project&amp;gt;&lt;br/&gt;
diff --git a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/GrpcFnServer.java b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/GrpcFnServer.java&lt;br/&gt;
index e6a057b7bf5..2b0d17ec616 100644&lt;br/&gt;
&amp;#8212; a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/GrpcFnServer.java&lt;br/&gt;
+++ b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/GrpcFnServer.java&lt;br/&gt;
@@ -57,7 +57,6 @@ private GrpcFnServer(Server server, ServiceT service, ApiServiceDescriptor apiSe&lt;br/&gt;
     this.server = server;&lt;br/&gt;
     this.service = service;&lt;br/&gt;
     this.apiServiceDescriptor = apiServiceDescriptor;&lt;br/&gt;
-    server.start();&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
diff --git a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/InProcessServerFactory.java b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/InProcessServerFactory.java&lt;br/&gt;
index 9fe4a5fa07c..535de68922d 100644&lt;br/&gt;
&amp;#8212; a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/InProcessServerFactory.java&lt;br/&gt;
+++ b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/InProcessServerFactory.java&lt;br/&gt;
@@ -43,12 +43,15 @@ public Server allocatePortAndCreate(BindableService service, ApiServiceDescripto&lt;br/&gt;
       throws IOException {
     String name = String.format(&quot;InProcessServer_%s&quot;, serviceNameUniqifier.getAndIncrement());
     builder.setUrl(name);
-    return InProcessServerBuilder.forName(name).addService(service).build();
+    return InProcessServerBuilder.forName(name).addService(service).build().start();
   }&lt;br/&gt;
 &lt;br/&gt;
   @Override&lt;br/&gt;
-  public Server create(&lt;br/&gt;
-      BindableService service, ApiServiceDescriptor serviceDescriptor) throws IOException {&lt;br/&gt;
-    return InProcessServerBuilder.forName(serviceDescriptor.getUrl()).addService(service).build();&lt;br/&gt;
+  public Server create(BindableService service, ApiServiceDescriptor serviceDescriptor)&lt;br/&gt;
+      throws IOException {
+    return InProcessServerBuilder.forName(serviceDescriptor.getUrl())
+        .addService(service)
+        .build()
+        .start();
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/SdkHarnessClient.java b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/SdkHarnessClient.java&lt;br/&gt;
index 5b47a581804..efbfe19760f 100644&lt;br/&gt;
&amp;#8212; a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/SdkHarnessClient.java&lt;br/&gt;
+++ b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/SdkHarnessClient.java&lt;br/&gt;
@@ -21,17 +21,16 @@&lt;br/&gt;
 import com.google.common.base.Function;&lt;br/&gt;
 import com.google.common.util.concurrent.Futures;&lt;br/&gt;
 import com.google.common.util.concurrent.ListenableFuture;&lt;br/&gt;
-import java.io.IOException;&lt;br/&gt;
 import java.util.concurrent.Future;&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicLong;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
-import org.apache.beam.runners.fnexecution.data.FnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
  * A high-level client for an SDK harness.&lt;br/&gt;
  *&lt;br/&gt;
  * &amp;lt;p&amp;gt;This provides a Java-friendly wrapper around {@link FnApiControlClient} and {@link- * FnDataReceiver}
&lt;p&gt;, which handle lower-level gRPC message wrangling.&lt;br/&gt;
+ * CloseableFnDataReceiver}, which handle lower-level gRPC message wrangling.&lt;br/&gt;
  */&lt;br/&gt;
 public class SdkHarnessClient {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -53,22 +52,19 @@ public String getId() {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* An active bundle for a particular 
{@link
-   * BeamFnApi.ProcessBundleDescriptor}
&lt;p&gt;.&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*/&lt;br/&gt;
+  /** An active bundle for a particular 
{@link BeamFnApi.ProcessBundleDescriptor}
&lt;p&gt;. */&lt;br/&gt;
   @AutoValue&lt;br/&gt;
   public abstract static class ActiveBundle&amp;lt;InputT&amp;gt; {&lt;br/&gt;
     public abstract String getBundleId();&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public abstract Future&amp;lt;BeamFnApi.ProcessBundleResponse&amp;gt; getBundleResponse();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public abstract FnDataReceiver&amp;lt;InputT&amp;gt; getInputReceiver();&lt;br/&gt;
+    public abstract CloseableFnDataReceiver&amp;lt;InputT&amp;gt; getInputReceiver();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public static &amp;lt;InputT&amp;gt; ActiveBundle&amp;lt;InputT&amp;gt; create(&lt;br/&gt;
         String bundleId,&lt;br/&gt;
         Future&amp;lt;BeamFnApi.ProcessBundleResponse&amp;gt; response,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FnDataReceiver&amp;lt;InputT&amp;gt; dataReceiver) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+        CloseableFnDataReceiver&amp;lt;InputT&amp;gt; dataReceiver) {
       return new AutoValue_SdkHarnessClient_ActiveBundle(bundleId, response, dataReceiver);
     }   }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;@@ -138,17 +134,24 @@ public ActiveBundle newBundle(String processBundleDescriptorId) {&lt;br/&gt;
     String bundleId = idGenerator.getId();&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // TODO: acquire an input receiver from appropriate FnDataService&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;FnDataReceiver dataReceiver = new FnDataReceiver() {&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void accept(Object input) throws Exception 
{
-        throw new UnsupportedOperationException(&quot;Placeholder FnDataReceiver cannot accept data.&quot;);
-      }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public void close() throws IOException 
{
-        // noop
-      }&lt;/li&gt;
	&lt;li&gt;};&lt;br/&gt;
+    CloseableFnDataReceiver dataReceiver =&lt;br/&gt;
+        new CloseableFnDataReceiver() 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+          @Override+          public void close() throws Exception {
+            throw new UnsupportedOperationException(
+                String.format(
+                    &quot;Placeholder %s cannot be closed.&quot;,
+                    CloseableFnDataReceiver.class.getSimpleName()));
+          }++          @Override+          public void accept(Object input) throws Exception {
+            throw new UnsupportedOperationException(
+                String.format(
+                    &quot;Placeholder %s cannot accept data.&quot;,
+                    CloseableFnDataReceiver.class.getSimpleName()));
+          }+        }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     ListenableFuture&amp;lt;BeamFnApi.InstructionResponse&amp;gt; genericResponse =&lt;br/&gt;
         fnApiControlClient.handle(&lt;br/&gt;
diff --git a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnDataService.java b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/data/FnDataService.java&lt;br/&gt;
similarity index 70%&lt;br/&gt;
rename from runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnDataService.java&lt;br/&gt;
rename to runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/data/FnDataService.java&lt;br/&gt;
index 2a6777e4bcd..d74bdda8cac 100644&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnDataService.java&lt;br/&gt;
+++ b/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/data/FnDataService.java&lt;br/&gt;
@@ -15,43 +15,23 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
  */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-import com.google.auto.value.AutoValue;&lt;br/&gt;
+package org.apache.beam.runners.fnexecution.data;&lt;br/&gt;
+&lt;br/&gt;
 import com.google.common.util.concurrent.ListenableFuture;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;/p&gt;

&lt;p&gt; /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;The 
{@link FnDataService} is able to forward inbound elements to a consumer and is also a&lt;br/&gt;
  * consumer of outbound elements. Callers can register themselves as consumers for inbound elements&lt;br/&gt;
  * or can get a handle for a consumer for outbound elements.&lt;br/&gt;
- *&lt;br/&gt;
- * @deprecated Runners should depend on the beam-runners-java-fn-execution module for this&lt;br/&gt;
- *     functionality.&lt;br/&gt;
  */&lt;br/&gt;
-@Deprecated&lt;br/&gt;
 public interface FnDataService {&lt;br/&gt;
 &lt;br/&gt;
-  /**&lt;br/&gt;
-   * A logical endpoint is a pair of an instruction ID corresponding to the {@link
-   * BeamFnApi.ProcessBundleRequest} and the {@link
-   * BeamFnApi.Target} within the processing graph. This enables the same&lt;br/&gt;
-   * {@link FnDataService}
&lt;p&gt; to be re-used across multiple bundles.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;@AutoValue&lt;/li&gt;
	&lt;li&gt;abstract class LogicalEndpoint {&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public abstract String getInstructionId();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public abstract BeamFnApi.Target getTarget();&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public static LogicalEndpoint of(String instructionId, BeamFnApi.Target target) 
{
-      return new AutoValue_FnDataService_LogicalEndpoint(instructionId, target);
-    }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;br/&gt;
   /**&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Registers a receiver to be notified upon any incoming elements.&lt;br/&gt;
    *&lt;br/&gt;
@@ -64,7 +44,7 @@ public static LogicalEndpoint of(String instructionId, BeamFnApi.Target target)&lt;br/&gt;
    *&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;The provided receiver is not required to be thread safe.&lt;br/&gt;
    */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;T&amp;gt; ListenableFuture&amp;lt;Void&amp;gt; listen(&lt;br/&gt;
+  &amp;lt;T&amp;gt; ListenableFuture&amp;lt;Void&amp;gt; receive(&lt;br/&gt;
       LogicalEndpoint inputLocation,&lt;br/&gt;
       Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder,&lt;br/&gt;
       FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; listener)&lt;br/&gt;
@@ -80,6 +60,7 @@ public static LogicalEndpoint of(String instructionId, BeamFnApi.Target target)&lt;br/&gt;
    *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;The returned receiver is not thread safe.&lt;br/&gt;
    */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;T&amp;gt; FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; send(&lt;br/&gt;
+  &amp;lt;T&amp;gt; CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; send(&lt;br/&gt;
       LogicalEndpoint outputLocation, Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder) throws Exception;&lt;br/&gt;
+&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/runners/reference/java/build.gradle b/runners/reference/java/build.gradle&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..a256d32d44b
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;/dev/null&lt;br/&gt;
+++ b/runners/reference/java/build.gradle&lt;br/&gt;
@@ -0,0 +1,38 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+apply from: project(&quot;:&quot;).file(&quot;build_rules.gradle&quot;)&lt;br/&gt;
+applyJavaNature()&lt;br/&gt;
+&lt;br/&gt;
+description = &quot;Apache Beam :: Runners :: Reference :: Java&quot;&lt;br/&gt;
+&lt;br/&gt;
+dependencies 
{
+  shadow project(path: &quot;:beam-model-parent:beam-model-pipeline&quot;, configuration: &quot;shadow&quot;)
+  shadow project(path: &quot;:beam-runners-parent:beam-runners-core-construction-java&quot;, configuration: &quot;shadow&quot;)
+  shadow library.java.slf4j_api
+  testCompile library.java.junit
+  testCompile library.java.hamcrest_core
+  testCompile library.java.slf4j_jdk14
+}
&lt;p&gt;+&lt;br/&gt;
+task packageTests(type: Jar) &lt;/p&gt;
{
+  from sourceSets.test.output
+  classifier = &quot;tests&quot;
+}
&lt;p&gt;+&lt;br/&gt;
+artifacts.archives packageTests&lt;br/&gt;
diff --git a/runners/reference/java/pom.xml b/runners/reference/java/pom.xml&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..4b535f7f8c6&lt;/p&gt;&lt;/li&gt;
			&lt;li&gt;/dev/null&lt;br/&gt;
+++ b/runners/reference/java/pom.xml&lt;br/&gt;
@@ -0,0 +1,81 @@&lt;br/&gt;
+&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;br/&gt;
+&amp;lt;!--&lt;br/&gt;
+    Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
+    contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
+    this work for additional information regarding copyright ownership.&lt;br/&gt;
+    The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
+    (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
+    the License.  You may obtain a copy of the License at&lt;br/&gt;
+&lt;br/&gt;
+       &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+&lt;br/&gt;
+    Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+    distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+    See the License for the specific language governing permissions and&lt;br/&gt;
+    limitations under the License.&lt;br/&gt;
+--&amp;gt;&lt;br/&gt;
+&amp;lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 &lt;a href=&quot;http://maven.apache.org/xsd/maven-4.0.0.xsd&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://maven.apache.org/xsd/maven-4.0.0.xsd&lt;/a&gt;&quot;&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+  &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+  &amp;lt;parent&amp;gt;&lt;br/&gt;
+    &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+    &amp;lt;artifactId&amp;gt;beam-runners-reference-parent&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+    &amp;lt;version&amp;gt;2.3.0-SNAPSHOT&amp;lt;/version&amp;gt;&lt;br/&gt;
+    &amp;lt;relativePath&amp;gt;../pom.xml&amp;lt;/relativePath&amp;gt;&lt;br/&gt;
+  &amp;lt;/parent&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+  &amp;lt;artifactId&amp;gt;beam-runners-reference-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+  &amp;lt;name&amp;gt;Apache Beam :: Runners :: Reference :: Java&amp;lt;/name&amp;gt;&lt;br/&gt;
+  &amp;lt;description&amp;gt;&lt;br/&gt;
+    A Java implementation of the Beam Model which utilizes the portability&lt;br/&gt;
+    framework to execute user-definied functions.&lt;br/&gt;
+  &amp;lt;/description&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+  &amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+  &amp;lt;dependencies&amp;gt;&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;beam-model-pipeline&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;beam-runners-core-construction-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;com.google.protobuf&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;protobuf-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;!-- build dependencies --&amp;gt;&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;com.google.auto.value&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;auto-value&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+      &amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;!-- test dependencies --&amp;gt;&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.hamcrest&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;hamcrest-all&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+      &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+      &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;slf4j-jdk14&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+      &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+  &amp;lt;/dependencies&amp;gt;&lt;br/&gt;
+&amp;lt;/project&amp;gt;&lt;br/&gt;
diff --git a/runners/reference/java/src/main/java/org/apache/beam/runners/reference/ReferenceRunner.java b/runners/reference/java/src/main/java/org/apache/beam/runners/reference/ReferenceRunner.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..ea80d0bfaa6&lt;/li&gt;
			&lt;li&gt;/dev/null&lt;br/&gt;
+++ b/runners/reference/java/src/main/java/org/apache/beam/runners/reference/ReferenceRunner.java&lt;br/&gt;
@@ -0,0 +1,35 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.beam.runners.reference;&lt;br/&gt;
+&lt;br/&gt;
+import com.google.protobuf.Struct;&lt;br/&gt;
+import java.nio.file.Path;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.Pipeline;&lt;br/&gt;
+import org.apache.beam.runners.core.construction.PipelineTranslation;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * A 
{@code PipelineRunner}
&lt;p&gt; that executes a job via the Beam portability framework.&lt;br/&gt;
+ */&lt;br/&gt;
+public class ReferenceRunner &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+  public static void run(Pipeline p, Struct options, Path stagingLocation) throws Exception {
+    // Validate that the pipeline is well-formed.
+    PipelineTranslation.fromProto(p);
+    throw new UnsupportedOperationException(&quot;Not implemented&quot;);
+  }+}&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;diff --git a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/package-info.java b/runners/reference/java/src/main/java/org/apache/beam/runners/reference/package-info.java&lt;br/&gt;
similarity index 75%&lt;br/&gt;
rename from runners/core-java/src/main/java/org/apache/beam/runners/core/fn/package-info.java&lt;br/&gt;
rename to runners/reference/java/src/main/java/org/apache/beam/runners/reference/package-info.java&lt;br/&gt;
index bea8051c49d..d15cf635709 100644&lt;/p&gt;&lt;/li&gt;
			&lt;li&gt;a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/package-info.java&lt;br/&gt;
+++ b/runners/reference/java/src/main/java/org/apache/beam/runners/reference/package-info.java&lt;br/&gt;
@@ -17,10 +17,6 @@&lt;br/&gt;
  */&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Provides utilities for a Beam runner to interact with a client using the Fn API.&lt;br/&gt;
+ * Support for executing a pipeline locally over the Beam fn API.&lt;br/&gt;
  */&lt;br/&gt;
-@DefaultAnnotation(NonNull.class)&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
-&lt;br/&gt;
-import edu.umd.cs.findbugs.annotations.DefaultAnnotation;&lt;br/&gt;
-import edu.umd.cs.findbugs.annotations.NonNull;&lt;br/&gt;
+package org.apache.beam.runners.reference;&lt;br/&gt;
diff --git a/runners/reference/job-server/build.gradle b/runners/reference/job-server/build.gradle&lt;br/&gt;
index 1eaee9bf29f..f5bc864e3cf 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/runners/reference/job-server/build.gradle&lt;br/&gt;
+++ b/runners/reference/job-server/build.gradle&lt;br/&gt;
@@ -25,6 +25,7 @@ dependencies {&lt;br/&gt;
   shadow library.java.grpc_netty&lt;br/&gt;
   shadow project(path: &quot;:beam-model-parent:beam-model-job-management&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
   shadow project(path: &quot;:beam-runners-parent:beam-java-fn-execution&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
+  shadow project(path: &quot;:beam-runners-parent:beam-runners-reference-parent:beam-runners-reference-java&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
   shadow project(path: &quot;:beam-runners-parent:beam-local-artifact-service-java&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
   shadow library.java.grpc_core&lt;br/&gt;
   shadow library.java.grpc_stub&lt;br/&gt;
@@ -32,6 +33,7 @@ dependencies 
{
   shadow library.java.args4j
   testCompile library.java.junit
   shadowTest project(path: &quot;:beam-runners-parent:beam-runners-core-construction-java&quot;, configuration: &quot;shadow&quot;)
+  shadowTest library.java.hamcrest_core
   shadowTest library.java.slf4j_jdk14
 }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/runners/reference/job-server/pom.xml b/runners/reference/job-server/pom.xml&lt;br/&gt;
index 184b959fe95..3d77872a782 100644&lt;br/&gt;
&amp;#8212; a/runners/reference/job-server/pom.xml&lt;br/&gt;
+++ b/runners/reference/job-server/pom.xml&lt;br/&gt;
@@ -62,6 +62,11 @@&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;beam-local-artifact-service-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;/p&gt;

&lt;p&gt;+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;beam-runners-reference-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
     &amp;lt;dependency&amp;gt;&lt;br/&gt;
       &amp;lt;groupId&amp;gt;com.google.protobuf&amp;lt;/groupId&amp;gt;&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;protobuf-java&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
@@ -122,5 +127,18 @@&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;slf4j-jdk14&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
       &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;!-- Stops the Maven Dependency Plugin from failing --&amp;gt;&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.hamcrest&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;hamcrest-core&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+      &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.hamcrest&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;hamcrest-all&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+      &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
   &amp;lt;/dependencies&amp;gt;&lt;br/&gt;
 &amp;lt;/project&amp;gt;&lt;br/&gt;
diff --git a/runners/reference/job-server/src/main/java/org/apache/beam/runners/reference/job/PreparingJob.java b/runners/reference/job-server/src/main/java/org/apache/beam/runners/reference/job/PreparingJob.java&lt;br/&gt;
index 80505cafecf..5d441fed0df 100644&lt;br/&gt;
&amp;#8212; a/runners/reference/job-server/src/main/java/org/apache/beam/runners/reference/job/PreparingJob.java&lt;br/&gt;
+++ b/runners/reference/job-server/src/main/java/org/apache/beam/runners/reference/job/PreparingJob.java&lt;br/&gt;
@@ -20,6 +20,7 @@&lt;/p&gt;

&lt;p&gt; import com.google.auto.value.AutoValue;&lt;br/&gt;
 import com.google.protobuf.Struct;&lt;br/&gt;
+import java.nio.file.Path;&lt;br/&gt;
 import org.apache.beam.artifact.local.LocalFileSystemArtifactStagerService;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi.Pipeline;&lt;br/&gt;
 import org.apache.beam.runners.fnexecution.GrpcFnServer;&lt;br/&gt;
@@ -33,6 +34,7 @@ public static Builder builder() {&lt;/p&gt;

&lt;p&gt;   abstract Pipeline getPipeline();&lt;br/&gt;
   abstract Struct getOptions();&lt;br/&gt;
+  abstract Path getStagingLocation();&lt;br/&gt;
   abstract GrpcFnServer&amp;lt;LocalFileSystemArtifactStagerService&amp;gt; getArtifactStagingServer();&lt;/p&gt;

&lt;p&gt;   @Override&lt;br/&gt;
@@ -46,6 +48,8 @@ public void close() throws Exception {&lt;/p&gt;

&lt;p&gt;     abstract Builder setOptions(Struct options);&lt;/p&gt;

&lt;p&gt;+    abstract Builder setStagingLocation(Path stagingLocation);&lt;br/&gt;
+&lt;br/&gt;
     abstract Builder setArtifactStagingServer(&lt;br/&gt;
         GrpcFnServer&amp;lt;LocalFileSystemArtifactStagerService&amp;gt; server);&lt;/p&gt;

&lt;p&gt;diff --git a/runners/reference/job-server/src/main/java/org/apache/beam/runners/reference/job/ReferenceRunnerJobService.java b/runners/reference/job-server/src/main/java/org/apache/beam/runners/reference/job/ReferenceRunnerJobService.java&lt;br/&gt;
index 33ccbd7b8d8..4a5d7e8024e 100644&lt;br/&gt;
&amp;#8212; a/runners/reference/job-server/src/main/java/org/apache/beam/runners/reference/job/ReferenceRunnerJobService.java&lt;br/&gt;
+++ b/runners/reference/job-server/src/main/java/org/apache/beam/runners/reference/job/ReferenceRunnerJobService.java&lt;br/&gt;
@@ -22,10 +22,12 @@&lt;/p&gt;

&lt;p&gt; import com.google.common.collect.ImmutableList;&lt;br/&gt;
 import io.grpc.Status;&lt;br/&gt;
+import io.grpc.StatusRuntimeException;&lt;br/&gt;
 import io.grpc.stub.StreamObserver;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.nio.file.Files;&lt;br/&gt;
 import java.nio.file.Path;&lt;br/&gt;
+import java.util.concurrent.Callable;&lt;br/&gt;
 import java.util.concurrent.ConcurrentHashMap;&lt;br/&gt;
 import java.util.concurrent.ConcurrentMap;&lt;br/&gt;
 import java.util.concurrent.ThreadLocalRandom;&lt;br/&gt;
@@ -37,10 +39,12 @@&lt;br/&gt;
 import org.apache.beam.model.jobmanagement.v1.JobApi.GetJobStateResponse;&lt;br/&gt;
 import org.apache.beam.model.jobmanagement.v1.JobApi.PrepareJobResponse;&lt;br/&gt;
 import org.apache.beam.model.jobmanagement.v1.JobApi.RunJobRequest;&lt;br/&gt;
+import org.apache.beam.model.jobmanagement.v1.JobApi.RunJobResponse;&lt;br/&gt;
 import org.apache.beam.model.jobmanagement.v1.JobServiceGrpc.JobServiceImplBase;&lt;br/&gt;
 import org.apache.beam.runners.fnexecution.FnService;&lt;br/&gt;
 import org.apache.beam.runners.fnexecution.GrpcFnServer;&lt;br/&gt;
 import org.apache.beam.runners.fnexecution.ServerFactory;&lt;br/&gt;
+import org.apache.beam.runners.reference.ReferenceRunner;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;/p&gt;

&lt;p&gt;@@ -48,18 +52,27 @@&lt;br/&gt;
 public class ReferenceRunnerJobService extends JobServiceImplBase implements FnService {&lt;br/&gt;
   private static final Logger LOG = LoggerFactory.getLogger(ReferenceRunnerJobService.class);&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public static ReferenceRunnerJobService create(ServerFactory serverFactory) {&lt;/li&gt;
	&lt;li&gt;return new ReferenceRunnerJobService(serverFactory);&lt;br/&gt;
+  public static ReferenceRunnerJobService create(final ServerFactory serverFactory) 
{
+    return new ReferenceRunnerJobService(
+        serverFactory, filesTempDirectory());
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private final ServerFactory serverFactory;&lt;br/&gt;
+  private final Callable&amp;lt;Path&amp;gt; stagingPathSupplier;&lt;br/&gt;
+&lt;br/&gt;
   private final ConcurrentMap&amp;lt;String, PreparingJob&amp;gt; unpreparedJobs;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private ReferenceRunnerJobService(ServerFactory serverFactory) {&lt;br/&gt;
+  private ReferenceRunnerJobService(&lt;br/&gt;
+      ServerFactory serverFactory, Callable&amp;lt;Path&amp;gt; stagingPathSupplier) 
{
     this.serverFactory = serverFactory;
+    this.stagingPathSupplier = stagingPathSupplier;
     unpreparedJobs = new ConcurrentHashMap&amp;lt;&amp;gt;();
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  public ReferenceRunnerJobService withStagingPathSupplier(Callable&amp;lt;Path&amp;gt; supplier) &lt;/p&gt;
{
+    return new ReferenceRunnerJobService(serverFactory, supplier);
+  }
&lt;p&gt;+&lt;br/&gt;
   @Override&lt;br/&gt;
   public void prepare(&lt;br/&gt;
       JobApi.PrepareJobRequest request,&lt;br/&gt;
@@ -68,8 +81,9 @@ public void prepare(&lt;br/&gt;
       LOG.trace(&quot;{} {}&quot;, PrepareJobResponse.class.getSimpleName(), request);&lt;/p&gt;

&lt;p&gt;       String preparationId = request.getJobName() + ThreadLocalRandom.current().nextInt();&lt;br/&gt;
+      Path tempDir = Files.createTempDirectory(&quot;reference-runner-staging&quot;);&lt;br/&gt;
       GrpcFnServer&amp;lt;LocalFileSystemArtifactStagerService&amp;gt; artifactStagingService =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;createArtifactStagingService(preparationId);&lt;br/&gt;
+          createArtifactStagingService();&lt;br/&gt;
       PreparingJob previous =&lt;br/&gt;
           unpreparedJobs.putIfAbsent(&lt;br/&gt;
               preparationId,&lt;br/&gt;
@@ -77,6 +91,7 @@ public void prepare(&lt;br/&gt;
                   .setArtifactStagingServer(artifactStagingService)&lt;br/&gt;
                   .setPipeline(request.getPipeline())&lt;br/&gt;
                   .setOptions(request.getPipelineOptions())&lt;br/&gt;
+                  .setStagingLocation(tempDir)&lt;br/&gt;
                   .build());&lt;br/&gt;
       checkArgument(&lt;br/&gt;
           previous == null, &quot;Unexpected existing job with preparation ID %s&quot;, preparationId);&lt;br/&gt;
@@ -93,22 +108,44 @@ public void prepare(&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private GrpcFnServer&amp;lt;LocalFileSystemArtifactStagerService&amp;gt; createArtifactStagingService(&lt;/li&gt;
	&lt;li&gt;String preparationId) throws IOException {&lt;/li&gt;
	&lt;li&gt;Path tempDir = Files.createTempDirectory(&quot;reference-runner-staging&quot;);&lt;br/&gt;
+  private GrpcFnServer&amp;lt;LocalFileSystemArtifactStagerService&amp;gt; createArtifactStagingService()&lt;br/&gt;
+      throws Exception 
{
     LocalFileSystemArtifactStagerService service =
-        LocalFileSystemArtifactStagerService.withRootDirectory(tempDir.toFile());
-    GrpcFnServer&amp;lt;LocalFileSystemArtifactStagerService&amp;gt; server =
-        GrpcFnServer.allocatePortAndCreateFor(service, serverFactory);
-    return server;
+        LocalFileSystemArtifactStagerService.withRootDirectory(stagingPathSupplier.call().toFile());
+    return GrpcFnServer.allocatePortAndCreateFor(service, serverFactory);
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @Override&lt;br/&gt;
   public void run(&lt;br/&gt;
       JobApi.RunJobRequest request, StreamObserver&amp;lt;JobApi.RunJobResponse&amp;gt; responseObserver) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;LOG.trace(&quot;{} {}&quot;, RunJobRequest.class.getSimpleName(), request);&lt;/li&gt;
	&lt;li&gt;System.err.println(&quot;Run Job Blah&quot;);&lt;/li&gt;
	&lt;li&gt;responseObserver.onError(Status.UNIMPLEMENTED.asException());&lt;br/&gt;
+    try {&lt;br/&gt;
+      LOG.trace(&quot;{} {}&quot;, RunJobRequest.class.getSimpleName(), request);&lt;br/&gt;
+      String preparationId = request.getPreparationId();&lt;br/&gt;
+      PreparingJob preparingJob = unpreparedJobs.get(preparationId);&lt;br/&gt;
+      if (preparingJob == null) 
{
+        responseObserver.onError(
+            Status.INVALID_ARGUMENT
+                .withDescription(String.format(&quot;Unknown Preparation Id %s&quot;, preparationId))
+                .asException());
+        return;
+      }
&lt;p&gt;+      try &lt;/p&gt;
{
+        // Close any preparation-time only resources.
+        preparingJob.close();
+      }
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
+        responseObserver.onError(e);
+      }
&lt;p&gt;+      // TODO: Return a real java &apos;job handle&apos;; this gets used in getState, cancel, etc&lt;br/&gt;
+      ReferenceRunner.run(&lt;br/&gt;
+          preparingJob.getPipeline(), preparingJob.getOptions(), preparingJob.getStagingLocation());&lt;br/&gt;
+      String jobId = preparingJob + Integer.toString(ThreadLocalRandom.current().nextInt());&lt;br/&gt;
+      responseObserver.onNext(RunJobResponse.newBuilder().setJobId(jobId).build());&lt;br/&gt;
+      responseObserver.onCompleted();&lt;br/&gt;
+    } catch (StatusRuntimeException e) &lt;/p&gt;
{
+      responseObserver.onError(e);
+    }
&lt;p&gt; catch (Exception e) &lt;/p&gt;
{
+      responseObserver.onError(Status.INTERNAL.withCause(e).asException());
+    }
&lt;p&gt;   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @Override&lt;br/&gt;
@@ -140,4 +177,12 @@ public void close() throws Exception {&lt;br/&gt;
       }&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
+&lt;br/&gt;
+  private static Callable&amp;lt;Path&amp;gt; filesTempDirectory() {&lt;br/&gt;
+    return new Callable&amp;lt;Path&amp;gt;() {&lt;br/&gt;
+      public Path call() throws IOException &lt;/p&gt;
{
+        return Files.createTempDirectory(&quot;reference-runner-staging&quot;);
+      }
&lt;p&gt;+    };&lt;br/&gt;
+  }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/runners/reference/job-server/src/test/java/org/apache/beam/runners/reference/job/ReferenceRunnerJobServiceTest.java b/runners/reference/job-server/src/test/java/org/apache/beam/runners/reference/job/ReferenceRunnerJobServiceTest.java&lt;br/&gt;
index 62be932fc53..2c63615d110 100644&lt;br/&gt;
&amp;#8212; a/runners/reference/job-server/src/test/java/org/apache/beam/runners/reference/job/ReferenceRunnerJobServiceTest.java&lt;br/&gt;
+++ b/runners/reference/job-server/src/test/java/org/apache/beam/runners/reference/job/ReferenceRunnerJobServiceTest.java&lt;br/&gt;
@@ -18,6 +18,9 @@&lt;/p&gt;

&lt;p&gt; package org.apache.beam.runners.reference.job;&lt;/p&gt;

&lt;p&gt;+import static org.hamcrest.Matchers.hasItems;&lt;br/&gt;
+import static org.junit.Assert.assertThat;&lt;br/&gt;
+&lt;br/&gt;
 import com.google.common.collect.ImmutableList;&lt;br/&gt;
 import com.google.protobuf.Struct;&lt;br/&gt;
 import io.grpc.inprocess.InProcessChannelBuilder;&lt;br/&gt;
@@ -25,6 +28,13 @@&lt;br/&gt;
 import java.io.FileOutputStream;&lt;br/&gt;
 import java.nio.ByteBuffer;&lt;br/&gt;
 import java.nio.channels.FileChannel;&lt;br/&gt;
+import java.nio.file.Files;&lt;br/&gt;
+import java.nio.file.Path;&lt;br/&gt;
+import java.util.ArrayList;&lt;br/&gt;
+import java.util.Arrays;&lt;br/&gt;
+import java.util.Collections;&lt;br/&gt;
+import java.util.List;&lt;br/&gt;
+import java.util.concurrent.Callable;&lt;br/&gt;
 import org.apache.beam.model.jobmanagement.v1.JobApi.PrepareJobRequest;&lt;br/&gt;
 import org.apache.beam.model.jobmanagement.v1.JobApi.PrepareJobResponse;&lt;br/&gt;
 import org.apache.beam.model.jobmanagement.v1.JobServiceGrpc;&lt;br/&gt;
@@ -34,6 +44,9 @@&lt;br/&gt;
 import org.apache.beam.runners.core.construction.ArtifactServiceStager;&lt;br/&gt;
 import org.apache.beam.runners.fnexecution.GrpcFnServer;&lt;br/&gt;
 import org.apache.beam.runners.fnexecution.InProcessServerFactory;&lt;br/&gt;
+import org.hamcrest.Description;&lt;br/&gt;
+import org.hamcrest.Matcher;&lt;br/&gt;
+import org.hamcrest.TypeSafeMatcher;&lt;br/&gt;
 import org.junit.After;&lt;br/&gt;
 import org.junit.Before;&lt;br/&gt;
 import org.junit.Rule;&lt;br/&gt;
@@ -47,7 +60,8 @@&lt;br/&gt;
  */&lt;br/&gt;
 @RunWith(JUnit4.class)&lt;br/&gt;
 public class ReferenceRunnerJobServiceTest {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Rule public TemporaryFolder temp = new TemporaryFolder();&lt;br/&gt;
+  @Rule public TemporaryFolder runnerTemp = new TemporaryFolder();&lt;br/&gt;
+  @Rule public TemporaryFolder clientTemp = new TemporaryFolder();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private InProcessServerFactory serverFactory = InProcessServerFactory.create();&lt;br/&gt;
   private ReferenceRunnerJobService service;&lt;br/&gt;
@@ -56,7 +70,15 @@&lt;/p&gt;

&lt;p&gt;   @Before&lt;br/&gt;
   public void setup() throws Exception {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;service = ReferenceRunnerJobService.create(serverFactory);&lt;br/&gt;
+    service =&lt;br/&gt;
+        ReferenceRunnerJobService.create(serverFactory)&lt;br/&gt;
+            .withStagingPathSupplier(&lt;br/&gt;
+                new Callable&amp;lt;Path&amp;gt;() 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+                  @Override+                  public Path call() throws Exception {
+                    return runnerTemp.getRoot().toPath();
+                  }+                }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;);&lt;br/&gt;
     server = GrpcFnServer.allocatePortAndCreateFor(service, serverFactory);&lt;br/&gt;
     stub =&lt;br/&gt;
         JobServiceGrpc.newBlockingStub(&lt;br/&gt;
@@ -85,12 +107,43 @@ public void testPrepareJob() throws Exception &lt;/p&gt;
{
     File foo = writeTempFile(&quot;foo&quot;, &quot;foo, bar, baz&quot;.getBytes());
     File bar = writeTempFile(&quot;spam&quot;, &quot;spam, ham, eggs&quot;.getBytes());
     stager.stage(ImmutableList.&amp;lt;File&amp;gt;of(foo, bar));
+    List&amp;lt;byte[]&amp;gt; tempDirFiles = readFlattendFiles(runnerTemp.getRoot());
+    assertThat(
+        tempDirFiles,
+        hasItems(
+            arrayEquals(Files.readAllBytes(foo.toPath())),
+            arrayEquals(Files.readAllBytes(bar.toPath()))));
     // TODO: &apos;run&apos; the job with some sort of noop backend, to verify state is cleaned up.
-    // TODO: Verify that the artifacts have been staged
+  }
&lt;p&gt;+&lt;br/&gt;
+  private Matcher&amp;lt;byte[]&amp;gt; arrayEquals(final byte[] expected) {&lt;br/&gt;
+    return new TypeSafeMatcher&amp;lt;byte[]&amp;gt;() &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      @Override+      protected boolean matchesSafely(byte[] actual) {
+        return Arrays.equals(actual, expected);
+      }++      @Override+      public void describeTo(Description description) {
+        description.appendText(&quot;an array equal to &quot;).appendValue(Arrays.toString(expected));
+      }+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;;&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private List&amp;lt;byte[]&amp;gt; readFlattendFiles(File root) throws Exception {&lt;br/&gt;
+    if (root.isDirectory()) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      List&amp;lt;byte[]&amp;gt; children = new ArrayList&amp;lt;&amp;gt;();+      for (File child }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; else &lt;/p&gt;
{
+      return Collections.singletonList(Files.readAllBytes(root.toPath()));
+    }
&lt;p&gt;   }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private File writeTempFile(String fileName, byte[] contents) throws Exception {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;File file = temp.newFile(fileName);&lt;br/&gt;
+    File file = clientTemp.newFile(fileName);&lt;br/&gt;
     try (FileOutputStream stream = new FileOutputStream(file);&lt;br/&gt;
         FileChannel channel = stream.getChannel()) {&lt;br/&gt;
       channel.write(ByteBuffer.wrap(contents));&lt;br/&gt;
diff --git a/runners/reference/pom.xml b/runners/reference/pom.xml&lt;br/&gt;
index 0c7f93922fd..66922f32080 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/runners/reference/pom.xml&lt;br/&gt;
+++ b/runners/reference/pom.xml&lt;br/&gt;
@@ -34,6 +34,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   &amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt;&lt;br/&gt;
   &amp;lt;modules&amp;gt;&lt;br/&gt;
+    &amp;lt;module&amp;gt;java&amp;lt;/module&amp;gt;&lt;br/&gt;
     &amp;lt;module&amp;gt;job-server&amp;lt;/module&amp;gt;&lt;br/&gt;
   &amp;lt;/modules&amp;gt;&lt;br/&gt;
 &amp;lt;/project&amp;gt;&lt;br/&gt;
diff --git a/runners/spark/src/test/java/org/apache/beam/runners/spark/io/AvroPipelineTest.java b/runners/spark/src/test/java/org/apache/beam/runners/spark/io/AvroPipelineTest.java&lt;br/&gt;
index e17a6b89b40..fc65aac8737 100644&lt;br/&gt;
&amp;#8212; a/runners/spark/src/test/java/org/apache/beam/runners/spark/io/AvroPipelineTest.java&lt;br/&gt;
+++ b/runners/spark/src/test/java/org/apache/beam/runners/spark/io/AvroPipelineTest.java&lt;br/&gt;
@@ -74,8 +74,7 @@ public void testGeneric() throws Exception {&lt;br/&gt;
         AvroIO.readGenericRecords(schema).from(inputFile.getAbsolutePath()));&lt;br/&gt;
     input.apply(&lt;br/&gt;
         AvroIO.writeGenericRecords(schema)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.to(outputFile.getAbsolutePath())&lt;/li&gt;
	&lt;li&gt;.withoutSharding());&lt;br/&gt;
+            .to(outputFile.getAbsolutePath()));&lt;br/&gt;
     pipeline.run();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     List&amp;lt;GenericRecord&amp;gt; records = readGenericFile();&lt;br/&gt;
@@ -100,7 +99,7 @@ private void populateGenericFile(List&amp;lt;GenericRecord&amp;gt; genericRecords,&lt;br/&gt;
     List&amp;lt;GenericRecord&amp;gt; records = Lists.newArrayList();&lt;br/&gt;
     GenericDatumReader&amp;lt;GenericRecord&amp;gt; genericDatumReader = new GenericDatumReader&amp;lt;&amp;gt;();&lt;br/&gt;
     try (DataFileReader&amp;lt;GenericRecord&amp;gt; dataFileReader =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;new DataFileReader&amp;lt;&amp;gt;(outputFile, genericDatumReader)) {&lt;br/&gt;
+        new DataFileReader&amp;lt;&amp;gt;(new File(outputFile + &quot;-00000-of-00001&quot;), genericDatumReader)) {&lt;br/&gt;
       for (GenericRecord record : dataFileReader) 
{
         records.add(record);
       }
&lt;p&gt;diff --git a/sdks/go/pkg/beam/core/runtime/harness/harness.go b/sdks/go/pkg/beam/core/runtime/harness/harness.go&lt;br/&gt;
index 76d516fba02..f16d571d285 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/go/pkg/beam/core/runtime/harness/harness.go&lt;br/&gt;
+++ b/sdks/go/pkg/beam/core/runtime/harness/harness.go&lt;br/&gt;
@@ -243,7 +243,7 @@ func fail(id, format string, args ...interface{}) *fnpb.InstructionResponse {&lt;br/&gt;
 func dial(ctx context.Context, endpoint string, timeout time.Duration) (*grpc.ClientConn, error) {&lt;br/&gt;
 	log.Infof(ctx, &quot;Connecting via grpc @ %s ...&quot;, endpoint)&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;opts := []grpc.DialOption
{grpc.WithInsecure(), grpc.WithBlock()}
&lt;p&gt;+	opts := []grpc.DialOption&lt;/p&gt;
{grpc.WithInsecure(), grpc.WithBlock(), grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(50 &amp;lt;&amp;lt; 20))}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	// TODO(wcn): Update this code to not use deprecated grpc.WithTimeout&lt;br/&gt;
 	if timeout &amp;gt; 0 {&lt;br/&gt;
diff --git a/sdks/go/pkg/beam/core/runtime/harness/session.go b/sdks/go/pkg/beam/core/runtime/harness/session.go&lt;br/&gt;
index b6eb70c458d..135f5899fd2 100644&lt;br/&gt;
&amp;#8212; a/sdks/go/pkg/beam/core/runtime/harness/session.go&lt;br/&gt;
+++ b/sdks/go/pkg/beam/core/runtime/harness/session.go&lt;br/&gt;
@@ -60,7 +60,7 @@ func setupDiagnosticRecording() error {&lt;/p&gt;

&lt;p&gt; 	var err error&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;storagePath := runtime.GlobalOptions.Get(&quot;storage_path&quot;)&lt;br/&gt;
+	storagePath = runtime.GlobalOptions.Get(&quot;storage_path&quot;)&lt;br/&gt;
 	// Any form of recording requires the destination directory to exist.&lt;br/&gt;
 	if err = os.MkdirAll(storagePath, 0755); err != nil {&lt;br/&gt;
 		return fmt.Errorf(&quot;Unable to create session directory: %v&quot;, err)&lt;br/&gt;
diff --git a/sdks/go/pkg/beam/core/runtime/symbols.go b/sdks/go/pkg/beam/core/runtime/symbols.go&lt;br/&gt;
index f9c839c948b..2659f4834eb 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/go/pkg/beam/core/runtime/symbols.go&lt;br/&gt;
+++ b/sdks/go/pkg/beam/core/runtime/symbols.go&lt;br/&gt;
@@ -17,6 +17,7 @@ package runtime&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import (&lt;br/&gt;
 	&quot;os&quot;&lt;br/&gt;
+	&quot;sync&quot;&lt;/p&gt;

&lt;p&gt; 	&quot;github.com/apache/beam/sdks/go/pkg/beam/core/util/symtab&quot;&lt;br/&gt;
 )&lt;br/&gt;
@@ -26,6 +27,7 @@ import (&lt;br/&gt;
 // SymbolResolution is the interface that should be implemented&lt;br/&gt;
 // in order to override the default behavior for symbol resolution.&lt;br/&gt;
 type SymbolResolution interface &lt;/p&gt;
{
+	// Sym2Addr returns the address pointer for a given symbol.
 	Sym2Addr(string) (uintptr, error)
 }

&lt;p&gt;@@ -37,21 +39,49 @@ type SymbolResolution interface {&lt;br/&gt;
 var SymbolResolver SymbolResolution&lt;/p&gt;

&lt;p&gt; func init() {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;var err error&lt;br/&gt;
 	// First try the Linux location, since it&apos;s the most reliable.&lt;/li&gt;
	&lt;li&gt;SymbolResolver, err = symtab.New(&quot;/proc/self/exe&quot;)&lt;/li&gt;
	&lt;li&gt;if err == nil 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+	if r, err }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+// SymbolCache added a caching layer over any SymbolResolution.&lt;br/&gt;
+type SymbolCache struct &lt;/p&gt;
{
+	resolver SymbolResolution
+	cache    map[string]uintptr
+	mu       sync.Mutex
+}
&lt;p&gt;+&lt;br/&gt;
+// NewSymbolCache adds caching to the given symbol resolver.&lt;br/&gt;
+func NewSymbolCache(r SymbolResolution) SymbolResolution {&lt;br/&gt;
+	return &amp;amp;SymbolCache&lt;/p&gt;
{resolver: r, cache: make(map[string]uintptr)}
&lt;p&gt;+}&lt;br/&gt;
+&lt;br/&gt;
+func (c *SymbolCache) Sym2Addr(sym string) (uintptr, error) {&lt;br/&gt;
+	c.mu.Lock()&lt;br/&gt;
+	defer c.mu.Unlock()&lt;br/&gt;
+&lt;br/&gt;
+	if p, exists := c.cache&lt;span class=&quot;error&quot;&gt;&amp;#91;sym&amp;#93;&lt;/span&gt;; exists &lt;/p&gt;
{
+		return p, nil
+	}
&lt;p&gt;+&lt;br/&gt;
+	p, err := c.resolver.Sym2Addr(sym)&lt;br/&gt;
+	if err != nil &lt;/p&gt;
{
+		return 0, err
+	}
&lt;p&gt;+&lt;br/&gt;
+	c.cache&lt;span class=&quot;error&quot;&gt;&amp;#91;sym&amp;#93;&lt;/span&gt; = p&lt;br/&gt;
+	return p, nil&lt;br/&gt;
+}&lt;br/&gt;
+&lt;br/&gt;
 type panicResolver bool&lt;/p&gt;

&lt;p&gt; func (p panicResolver) Sym2Addr(name string) (uintptr, error) {&lt;br/&gt;
diff --git a/sdks/go/pkg/beam/model/fnexecution_v1/beam_fn_api.pb.go b/sdks/go/pkg/beam/model/fnexecution_v1/beam_fn_api.pb.go&lt;br/&gt;
index 9a31a573906..442bdacb623 100644&lt;br/&gt;
&amp;#8212; a/sdks/go/pkg/beam/model/fnexecution_v1/beam_fn_api.pb.go&lt;br/&gt;
+++ b/sdks/go/pkg/beam/model/fnexecution_v1/beam_fn_api.pb.go&lt;br/&gt;
@@ -38,7 +38,6 @@ It has these top-level messages:&lt;br/&gt;
 	StateClearResponse&lt;br/&gt;
 	LogEntry&lt;br/&gt;
 	LogControl&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;DockerContainer&lt;br/&gt;
 	GetProvisionInfoRequest&lt;br/&gt;
 	GetProvisionInfoResponse&lt;br/&gt;
 	ProvisionInfo&lt;br/&gt;
@@ -72,9 +71,9 @@ const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package&lt;br/&gt;
 type LogEntry_Severity_Enum int32&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; const (&lt;br/&gt;
+	// Unspecified level information. Will be logged at the TRACE level.&lt;br/&gt;
 	LogEntry_Severity_UNSPECIFIED LogEntry_Severity_Enum = 0&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Trace level information, also the default log level unless&lt;/li&gt;
	&lt;li&gt;// another severity is specified.&lt;br/&gt;
+	// Trace level information.&lt;br/&gt;
 	LogEntry_Severity_TRACE LogEntry_Severity_Enum = 1&lt;br/&gt;
 	// Debugging information.&lt;br/&gt;
 	LogEntry_Severity_DEBUG LogEntry_Severity_Enum = 2&lt;br/&gt;
@@ -2084,47 +2083,6 @@ func (m *LogControl) String() string            { return proto.CompactTextString&lt;br/&gt;
 func (*LogControl) ProtoMessage()               {}&lt;br/&gt;
 func (*LogControl) Descriptor() ([]byte, []int) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: { return fileDescriptor0, []int{28} }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-// A Docker container configuration for launching the SDK harness to execute&lt;br/&gt;
-// user specified functions.&lt;br/&gt;
-type DockerContainer struct &lt;/p&gt;
{
-	// (Required) A pipeline level unique id which can be used as a reference to
-	// refer to this.
-	Id string `protobuf:&quot;bytes,1,opt,name=id&quot; json:&quot;id,omitempty&quot;`
-	// (Required) The Docker container URI
-	// For example &quot;dataflow.gcr.io/v1beta3/java-batch:1.5.1&quot;
-	Uri string `protobuf:&quot;bytes,2,opt,name=uri&quot; json:&quot;uri,omitempty&quot;`
-	// (Optional) Docker registry specification.
-	// If unspecified, the uri is expected to be able to be fetched without
-	// requiring additional configuration by a runner.
-	RegistryReference string `protobuf:&quot;bytes,3,opt,name=registry_reference,json=registryReference&quot; json:&quot;registry_reference,omitempty&quot;`
-}
&lt;p&gt;-&lt;br/&gt;
-func (m *DockerContainer) Reset()                    { *m = DockerContainer{} }&lt;br/&gt;
-func (m *DockerContainer) String() string            &lt;/p&gt;
{ return proto.CompactTextString(m) }
&lt;p&gt;-func (*DockerContainer) ProtoMessage()               {}&lt;br/&gt;
-func (*DockerContainer) Descriptor() ([]byte, []int) { return fileDescriptor0, []int&lt;/p&gt;
{29}
&lt;p&gt; }&lt;br/&gt;
-&lt;br/&gt;
-func (m *DockerContainer) GetId() string {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if m != nil 
{
-		return m.Id
-	}&lt;/li&gt;
	&lt;li&gt;return &quot;&quot;&lt;br/&gt;
-}&lt;br/&gt;
-&lt;br/&gt;
-func (m *DockerContainer) GetUri() string {&lt;/li&gt;
	&lt;li&gt;if m != nil 
{
-		return m.Uri
-	}&lt;/li&gt;
	&lt;li&gt;return &quot;&quot;&lt;br/&gt;
-}&lt;br/&gt;
-&lt;br/&gt;
-func (m *DockerContainer) GetRegistryReference() string {&lt;/li&gt;
	&lt;li&gt;if m != nil 
{
-		return m.RegistryReference
-	}&lt;/li&gt;
	&lt;li&gt;return &quot;&quot;&lt;br/&gt;
-}&lt;br/&gt;
-&lt;br/&gt;
 func init() {&lt;br/&gt;
 	proto.RegisterType((*Target)(nil), &quot;org.apache.beam.model.fn_execution.v1.Target&quot;)&lt;br/&gt;
 	proto.RegisterType((*Target_List)(nil), &quot;org.apache.beam.model.fn_execution.v1.Target.List&quot;)&lt;br/&gt;
@@ -2167,7 +2125,6 @@ func init() 
{
 	proto.RegisterType((*LogEntry_List)(nil), &quot;org.apache.beam.model.fn_execution.v1.LogEntry.List&quot;)
 	proto.RegisterType((*LogEntry_Severity)(nil), &quot;org.apache.beam.model.fn_execution.v1.LogEntry.Severity&quot;)
 	proto.RegisterType((*LogControl)(nil), &quot;org.apache.beam.model.fn_execution.v1.LogControl&quot;)
-	proto.RegisterType((*DockerContainer)(nil), &quot;org.apache.beam.model.fn_execution.v1.DockerContainer&quot;)
 	proto.RegisterEnum(&quot;org.apache.beam.model.fn_execution.v1.LogEntry_Severity_Enum&quot;, LogEntry_Severity_Enum_name, LogEntry_Severity_Enum_value)
 }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -2578,152 +2535,150 @@ var _BeamFnLogging_serviceDesc = grpc.ServiceDesc{&lt;br/&gt;
 func init() &lt;/p&gt;
{ proto.RegisterFile(&quot;beam_fn_api.proto&quot;, fileDescriptor0) }

&lt;p&gt; var fileDescriptor0 = []byte&lt;/p&gt;
{
-	// 2350 bytes of a gzipped FileDescriptorProto
-	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xb4, 0x59, 0x4d, 0x73, 0xdb, 0xc6,
-	0xf9, 0x37, 0x44, 0x8a, 0xa2, 0x1e, 0x52, 0x14, 0xb5, 0x92, 0x22, 0x1a, 0x71, 0x26, 0x0e, 0xf2,
-	0xcf, 0x8c, 0x2e, 0xa1, 0xfe, 0x7e, 0x99, 0xd8, 0x4e, 0x93, 0x34, 0x12, 0x45, 0x5b, 0xb4, 0x65,
-	0x5b, 0x05, 0xa5, 0xb8, 0x4d, 0x67, 0x8a, 0x81, 0x80, 0x15, 0xb3, 0x63, 0x12, 0x40, 0x16, 0x4b,
-	0xd9, 0xca, 0x64, 0x9a, 0xe9, 0x25, 0x7d, 0x99, 0x76, 0x72, 0xe8, 0x4c, 0xdb, 0x6b, 0xdb, 0x53,
-	0x4f, 0xfd, 0x0c, 0xfd, 0x08, 0x3d, 0xf7, 0xda, 0x43, 0xda, 0x4e, 0x3f, 0x41, 0x2f, 0x9d, 0x7d,
-	0x01, 0x08, 0x82, 0xa4, 0x4c, 0x50, 0xea, 0x0d, 0xd8, 0xdd, 0xe7, 0xf7, 0x7b, 0xf6, 0xd9, 0xe7,
-	0x0d, 0x0b, 0x58, 0x39, 0xc6, 0x76, 0xcf, 0x3a, 0xf1, 0x2c, 0x3b, 0x20, 0xf5, 0x80, 0xfa, 0xcc,
-	0x47, 0xef, 0xf8, 0xb4, 0x53, 0xb7, 0x03, 0xdb, 0xf9, 0x0c, 0xd7, 0xf9, 0x6c, 0xbd, 0xe7, 0xbb,
-	0xb8, 0x5b, 0x3f, 0xf1, 0x2c, 0xfc, 0x12, 0x3b, 0x7d, 0x46, 0x7c, 0xaf, 0x7e, 0x7a, 0x43, 0x5f,
-	0x17, 0x92, 0xb4, 0xef, 0x79, 0x98, 0x0e, 0xa4, 0xf5, 0x65, 0xec, 0xb9, 0x81, 0x4f, 0x3c, 0x16,
-	0xaa, 0x81, 0x37, 0x3b, 0xbe, 0xdf, 0xe9, 0xe2, 0x2d, 0xf1, 0x76, 0xdc, 0x3f, 0xd9, 0x62, 0xa4,
-	0x87, 0x43, 0x66, 0xf7, 0x02, 0xb9, 0xc0, 0xf8, 0xb3, 0x06, 0x85, 0x43, 0x9b, 0x76, 0x30, 0x43,
-	0x3b, 0xf0, 0x46, 0x40, 0x49, 0x8f, 0x30, 0x72, 0x8a, 0x2d, 0x46, 0x6d, 0x2f, 0x3c, 0xf1, 0x69,
-	0xcf, 0xa2, 0xf8, 0x04, 0x53, 0xec, 0x39, 0xb8, 0xa6, 0x5d, 0xd7, 0x36, 0x17, 0xcd, 0xd7, 0xe3,
-	0x45, 0x87, 0xd1, 0x1a, 0x33, 0x5a, 0x82, 0x10, 0xe4, 0x3d, 0xbb, 0x87, 0x6b, 0x73, 0x62, 0xa9,
-	0x78, 0xd6, 0x1f, 0x43, 0x7e, 0x9f, 0x84, 0x0c, 0x35, 0xa1, 0xc0, 0x04, 0x53, 0x4d, 0xbb, 0x9e,
-	0xdb, 0x2c, 0xdd, 0x7c, 0xb7, 0x3e, 0xd5, 0x5e, 0xeb, 0x52, 0x3d, 0x53, 0x09, 0x1b, 0x5f, 0x41,
-	0xc5, 0xc4, 0x3d, 0x9f, 0xe1, 0x07, 0x34, 0x70, 0x0e, 0x7c, 0xca, 0x50, 0x0f, 0x5e, 0xb3, 0x03,
-	0x62, 0x85, 0x98, 0x9e, 0x12, 0x07, 0x5b, 0x2e, 0x0e, 0x1d, 0x4a, 0x02, 0xe6, 0x53, 0xa1, 0x71,
-	0xe9, 0xe6, 0x9d, 0x09, 0x44, 0x01, 0x09, 0x70, 0x97, 0x78, 0x98, 0x93, 0x6c, 0x07, 0xa4, 0x2d,
-	0xe5, 0x77, 0x63, 0x71, 0x73, 0xcd, 0x1e, 0x33, 0x6a, 0xfc, 0x27, 0x07, 0xa8, 0xe5, 0x85, 0x8c,
-	0xf6, 0x1d, 0xae, 0xa2, 0x89, 0x3f, 0xef, 0xe3, 0x90, 0xa1, 0x77, 0xa0, 0x42, 0x06, 0xa3, 0x16,
-	0x71, 0x95, 0xbd, 0x96, 0x12, 0xa3, 0x2d, 0x17, 0x1d, 0x41, 0x91, 0xe2, 0x0e, 0x09, 0x19, 0xa6,
-	0xb5, 0x6f, 0x17, 0x84, 0x7e, 0xef, 0x4d, 0x69, 0x08, 0x53, 0xc9, 0x29, 0xc6, 0xbd, 0x2b, 0x66,
-	0x0c, 0x85, 0x30, 0x54, 0x02, 0xea, 0x3b, 0x38, 0x0c, 0xad, 0xe3, 0xbe, 0xe7, 0x76, 0x71, 0xed,
-	0x1f, 0x12, 0xfc, 0x3b, 0x53, 0x82, 0x1f, 0x48, 0xe9, 0x1d, 0x21, 0x3c, 0x60, 0x58, 0x0a, 0x92,
-	0xe3, 0xe8, 0xc7, 0xb0, 0x31, 0x4c, 0x63, 0x05, 0xd4, 0xef, 0x50, 0x1c, 0x86, 0xb5, 0x7f, 0x4a,
-	0xbe, 0xc6, 0x2c, 0x7c, 0x07, 0x0a, 0x64, 0xc0, 0xbb, 0x1e, 0x8c, 0x9b, 0x47, 0x7d, 0x58, 0x4b,
-	0xf1, 0x87, 0x41, 0x97, 0xb0, 0xda, 0xbf, 0x24, 0xf9, 0xc7, 0xb3, 0x90, 0xb7, 0x39, 0xc2, 0x80,
-	0x19, 0x05, 0x23, 0x93, 0x3b, 0x8b, 0xb0, 0x40, 0xe5, 0x02, 0xe3, 0xb7, 0x79, 0x58, 0x1d, 0x3a,
-	0xfd, 0x30, 0xf0, 0xbd, 0x10, 0x4f, 0x7b, 0xfc, 0x6b, 0x30, 0x8f, 0x29, 0xf5, 0xa9, 0x8a, 0x10,
-	0xf9, 0x82, 0x3e, 0x19, 0x75, 0x8a, 0x3b, 0x99, 0x9d, 0x42, 0x2a, 0x32, 0xe4, 0x15, 0x27, 0x93,
-	0xbc, 0xe2, 0x83, 0xd9, 0xbc, 0x22, 0xa6, 0x48, 0xb9, 0xc5, 0x57, 0xaf, 0x74, 0x8b, 0xdd, 0x8b,
-	0xb9, 0x45, 0x4c, 0x3c, 0xc1, 0x2f, 0x4e, 0xcf, 0xf7, 0x8b, 0xed, 0x0b, 0xf8, 0x45, 0x4c, 0x3d,
-	0xce, 0x31, 0x80, 0x1f, 0x9c, 0x5c, 0x61, 0xfc, 0x4a, 0x83, 0xe5, 0x54, 0x88, 0xa2, 0x2f, 0xe0,
-	0x6a, 0x4a, 0xaf, 0xa1, 0xec, 0xc4, 0xd3, 0xe0, 0x47, 0xb3, 0xe8, 0x96, 0x48, 0x52, 0x1b, 0xc1,
-	0xf8, 0x09, 0x03, 0x41, 0x35, 0xed, 0x1c, 0xc6, 0x1f, 0x01, 0x36, 0x26, 0x00, 0xa1, 0x0a, 0xcc,
-	0xc5, 0x5e, 0x3b, 0x47, 0x5c, 0xe4, 0x01, 0xc4, 0x55, 0x20, 0xac, 0xcd, 0x09, 0x65, 0x9f, 0x5c,
-	0x4c, 0xd9, 0x7a, 0x5c, 0x32, 0xc2, 0xa6, 0xc7, 0xe8, 0x99, 0x99, 0x60, 0x40, 0x0c, 0xca, 0x81,
-	0xe3, 0x77, 0xbb, 0x58, 0xc4, 0x4a, 0x58, 0xcb, 0x09, 0xc6, 0x83, 0x0b, 0x32, 0x1e, 0x24, 0x20,
-	0x25, 0xe7, 0x10, 0x0b, 0xfa, 0x85, 0x06, 0x6b, 0x2f, 0x88, 0xe7, 0xfa, 0x2f, 0x88, 0xd7, 0xb1,
-	0x42, 0x46, 0x6d, 0x86, 0x3b, 0x04, 0x87, 0xb5, 0xbc, 0xa0, 0x7f, 0x76, 0x41, 0xfa, 0x67, 0x11,
-	0x74, 0x3b, 0x46, 0x96, 0x5a, 0xac, 0xbe, 0x18, 0x9d, 0x41, 0xc7, 0x50, 0x70, 0x7c, 0x17, 0xd3,
-	0xb0, 0x36, 0x2f, 0xd8, 0x1f, 0x5e, 0x90, 0xbd, 0x21, 0xc0, 0x24, 0xa1, 0x42, 0xe6, 0x66, 0xc6,
-	0xde, 0x29, 0xa1, 0xbe, 0xd7, 0xc3, 0x1e, 0x0b, 0x6b, 0x85, 0x4b, 0x31, 0x73, 0x33, 0x01, 0xa9,
-	0xcc, 0x9c, 0x64, 0x41, 0x2f, 0xe1, 0x5a, 0xc8, 0x6c, 0x86, 0xad, 0x09, 0x95, 0x7a, 0xe1, 0x62,
-	0x95, 0xfa, 0xaa, 0x00, 0x1f, 0x37, 0xa5, 0x77, 0x61, 0x39, 0xe5, 0x75, 0xa8, 0x0a, 0xb9, 0xe7,
-	0xf8, 0x4c, 0xb9, 0x3a, 0x7f, 0x44, 0x0d, 0x98, 0x3f, 0xb5, 0xbb, 0x7d, 0xd9, 0xb8, 0x4c, 0x6e,
-	0x4d, 0x92, 0x7a, 0x1c, 0x0c, 0xda, 0x1f, 0x29, 0xfb, 0xfe, 0xdc, 0x5d, 0x4d, 0xf7, 0x61, 0x65,
-	0xc4, 0xe3, 0xc6, 0xf0, 0xed, 0x0e, 0xf3, 0xd5, 0xa7, 0xe1, 0x6b, 0xc4, 0xb0, 0x49, 0xc2, 0x2f,
+	// 2310 bytes of a gzipped FileDescriptorProto
+	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xb4, 0x59, 0x4b, 0x73, 0x1b, 0xc7,
+	0xf1, 0xd7, 0x12, 0x20, 0x08, 0x36, 0x40, 0x10, 0x1c, 0x92, 0x26, 0xb4, 0x96, 0xcb, 0xf2, 0xfa,
+	0xef, 0x2a, 0x5e, 0x0c, 0xfe, 0xf5, 0x28, 0x4b, 0x72, 0x6c, 0xc7, 0x24, 0x08, 0x89, 0x90, 0x28,
+	0x89, 0x59, 0x90, 0x56, 0xe2, 0x54, 0x65, 0x6b, 0x89, 0x1d, 0xc2, 0x53, 0x02, 0x76, 0xd7, 0x33,
+	0x03, 0x4a, 0x74, 0xb9, 0xe2, 0xca, 0xc5, 0x79, 0x54, 0x52, 0x3e, 0xa4, 0x2a, 0xc9, 0x35, 0xc9,
+	0x29, 0xa7, 0x7c, 0x86, 0x7c, 0x84, 0x9c, 0x73, 0xcd, 0xc1, 0x49, 0x2a, 0x9f, 0x20, 0x97, 0xd4,
+	0xce, 0xcc, 0x3e, 0xb0, 0x00, 0x28, 0x2c, 0xc8, 0xdc, 0x76, 0x1e, 0xfd, 0xfb, 0xf5, 0xf4, 0xf4,
+	0x74, 0xf7, 0xcc, 0xc2, 0xca, 0x31, 0xb6, 0xfb, 0xd6, 0x89, 0x6b, 0xd9, 0x3e, 0xa9, 0xfb, 0xd4,
+	0xe3, 0x1e, 0x7a, 0xc7, 0xa3, 0xdd, 0xba, 0xed, 0xdb, 0x9d, 0xcf, 0x70, 0x3d, 0x18, 0xad, 0xf7,
+	0x3d, 0x07, 0xf7, 0xea, 0x27, 0xae, 0x85, 0x5f, 0xe2, 0xce, 0x80, 0x13, 0xcf, 0xad, 0x9f, 0xde,
+	0xd0, 0xd7, 0x85, 0x24, 0x1d, 0xb8, 0x2e, 0xa6, 0xb1, 0xb4, 0xbe, 0x8c, 0x5d, 0xc7, 0xf7, 0x88,
+	0xcb, 0x99, 0xea, 0x78, 0xb3, 0xeb, 0x79, 0xdd, 0x1e, 0xde, 0x12, 0xad, 0xe3, 0xc1, 0xc9, 0x16,
+	0x27, 0x7d, 0xcc, 0xb8, 0xdd, 0xf7, 0xe5, 0x04, 0xe3, 0xcf, 0x1a, 0x14, 0x0e, 0x6d, 0xda, 0xc5,
+	0x1c, 0xed, 0xc0, 0x1b, 0x3e, 0x25, 0x7d, 0xc2, 0xc9, 0x29, 0xb6, 0x38, 0xb5, 0x5d, 0x76, 0xe2,
+	0xd1, 0xbe, 0x45, 0xf1, 0x09, 0xa6, 0xd8, 0xed, 0xe0, 0x9a, 0x76, 0x5d, 0xdb, 0x5c, 0x34, 0x5f,
+	0x8f, 0x26, 0x1d, 0x86, 0x73, 0xcc, 0x70, 0x0a, 0x42, 0x90, 0x77, 0xed, 0x3e, 0xae, 0xcd, 0x89,
+	0xa9, 0xe2, 0x5b, 0x7f, 0x0c, 0xf9, 0x7d, 0xc2, 0x38, 0x6a, 0x42, 0x81, 0x0b, 0xa6, 0x9a, 0x76,
+	0x3d, 0xb7, 0x59, 0xba, 0xf9, 0x6e, 0x7d, 0xaa, 0xb5, 0xd6, 0xa5, 0x7a, 0xa6, 0x12, 0x36, 0xbe,
+	0x82, 0x8a, 0x89, 0xfb, 0x1e, 0xc7, 0x0f, 0xa8, 0xdf, 0x39, 0xf0, 0x28, 0x47, 0x7d, 0x78, 0xcd,
+	0xf6, 0x89, 0xc5, 0x30, 0x3d, 0x25, 0x1d, 0x6c, 0x39, 0x98, 0x75, 0x28, 0xf1, 0xb9, 0x47, 0x85,
+	0xc6, 0xa5, 0x9b, 0x77, 0x26, 0x10, 0xf9, 0xc4, 0xc7, 0x3d, 0xe2, 0xe2, 0x80, 0x64, 0xdb, 0x27,
+	0x6d, 0x29, 0xbf, 0x1b, 0x89, 0x9b, 0x6b, 0xf6, 0x98, 0x5e, 0xe3, 0x3f, 0x39, 0x40, 0x2d, 0x97,
+	0x71, 0x3a, 0xe8, 0x04, 0x2a, 0x9a, 0xf8, 0xf3, 0x01, 0x66, 0x1c, 0xbd, 0x03, 0x15, 0x12, 0xf7,
+	0x5a, 0xc4, 0x51, 0xf6, 0x5a, 0x4a, 0xf4, 0xb6, 0x1c, 0x74, 0x04, 0x45, 0x8a, 0xbb, 0x84, 0x71,
+	0x4c, 0x6b, 0xdf, 0x2e, 0x08, 0xfd, 0xde, 0x9b, 0xd2, 0x10, 0xa6, 0x92, 0x53, 0x8c, 0x7b, 0x57,
+	0xcc, 0x08, 0x0a, 0x61, 0xa8, 0xf8, 0xd4, 0xeb, 0x60, 0xc6, 0xac, 0xe3, 0x81, 0xeb, 0xf4, 0x70,
+	0xed, 0x1f, 0x12, 0xfc, 0x3b, 0x53, 0x82, 0x1f, 0x48, 0xe9, 0x1d, 0x21, 0x1c, 0x33, 0x2c, 0xf9,
+	0xc9, 0x7e, 0xf4, 0x63, 0xd8, 0x18, 0xa6, 0xb1, 0x7c, 0xea, 0x75, 0x29, 0x66, 0xac, 0xf6, 0x4f,
+	0xc9, 0xd7, 0x98, 0x85, 0xef, 0x40, 0x81, 0xc4, 0xbc, 0xeb, 0xfe, 0xb8, 0x71, 0x34, 0x80, 0xb5,
+	0x14, 0x3f, 0xf3, 0x7b, 0x84, 0xd7, 0xfe, 0x25, 0xc9, 0x3f, 0x9e, 0x85, 0xbc, 0x1d, 0x20, 0xc4,
+	0xcc, 0xc8, 0x1f, 0x19, 0xdc, 0x59, 0x84, 0x05, 0x2a, 0x27, 0x18, 0xbf, 0xcd, 0xc3, 0xea, 0xd0,
+	0xee, 0x33, 0xdf, 0x73, 0x19, 0x9e, 0x76, 0xfb, 0xd7, 0x60, 0x1e, 0x53, 0xea, 0x51, 0x75, 0x42,
+	0x64, 0x03, 0x7d, 0x32, 0xea, 0x14, 0x77, 0x32, 0x3b, 0x85, 0x54, 0x64, 0xc8, 0x2b, 0x4e, 0x26,
+	0x79, 0xc5, 0x07, 0xb3, 0x79, 0x45, 0x44, 0x91, 0x72, 0x8b, 0xaf, 0x5e, 0xe9, 0x16, 0xbb, 0x17,
+	0x73, 0x8b, 0x88, 0x78, 0x82, 0x5f, 0x9c, 0x9e, 0xef, 0x17, 0xdb, 0x17, 0xf0, 0x8b, 0x88, 0x7a,
+	0x9c, 0x63, 0x40, 0xb0, 0x71, 0x72, 0x86, 0xf1, 0x2b, 0x0d, 0x96, 0x53, 0x47, 0x14, 0x7d, 0x01,
+	0x57, 0x53, 0x7a, 0x0d, 0x45, 0xa7, 0x20, 0x0c, 0x7e, 0x34, 0x8b, 0x6e, 0x89, 0x20, 0xb5, 0xe1,
+	0x8f, 0x1f, 0x30, 0x10, 0x54, 0xd3, 0xce, 0x61, 0xfc, 0x11, 0x60, 0x63, 0x02, 0x10, 0xaa, 0xc0,
+	0x5c, 0xe4, 0xb5, 0x73, 0xc4, 0x41, 0x2e, 0x40, 0x94, 0x05, 0x58, 0x6d, 0x4e, 0x28, 0xfb, 0xe4,
+	0x62, 0xca, 0xd6, 0xa3, 0x94, 0xc1, 0x9a, 0x2e, 0xa7, 0x67, 0x66, 0x82, 0x01, 0x71, 0x28, 0xfb,
+	0x1d, 0xaf, 0xd7, 0xc3, 0xe2, 0xac, 0xb0, 0x5a, 0x4e, 0x30, 0x1e, 0x5c, 0x90, 0xf1, 0x20, 0x01,
+	0x29, 0x39, 0x87, 0x58, 0xd0, 0x2f, 0x34, 0x58, 0x7b, 0x41, 0x5c, 0xc7, 0x7b, 0x41, 0xdc, 0xae,
+	0xc5, 0x38, 0xb5, 0x39, 0xee, 0x12, 0xcc, 0x6a, 0x79, 0x41, 0xff, 0xec, 0x82, 0xf4, 0xcf, 0x42,
+	0xe8, 0x76, 0x84, 0x2c, 0xb5, 0x58, 0x7d, 0x31, 0x3a, 0x82, 0x8e, 0xa1, 0xd0, 0xf1, 0x1c, 0x4c,
+	0x59, 0x6d, 0x5e, 0xb0, 0x3f, 0xbc, 0x20, 0x7b, 0x43, 0x80, 0x49, 0x42, 0x85, 0x1c, 0x98, 0x19,
+	0xbb, 0xa7, 0x84, 0x7a, 0x6e, 0x1f, 0xbb, 0x9c, 0xd5, 0x0a, 0x97, 0x62, 0xe6, 0x66, 0x02, 0x52,
+	0x99, 0x39, 0xc9, 0x82, 0x5e, 0xc2, 0x35, 0xc6, 0x6d, 0x8e, 0xad, 0x09, 0x99, 0x7a, 0xe1, 0x62,
+	0x99, 0xfa, 0xaa, 0x00, 0x1f, 0x37, 0xa4, 0xf7, 0x60, 0x39, 0xe5, 0x75, 0xa8, 0x0a, 0xb9, 0xe7,
+	0xf8, 0x4c, 0xb9, 0x7a, 0xf0, 0x89, 0x1a, 0x30, 0x7f, 0x6a, 0xf7, 0x06, 0xb2, 0x70, 0x99, 0x5c,
+	0x9a, 0x24, 0xf5, 0x38, 0x88, 0xcb, 0x1f, 0x29, 0xfb, 0xfe, 0xdc, 0x5d, 0x4d, 0xf7, 0x60, 0x65,
+	0xc4, 0xe3, 0xc6, 0xf0, 0xed, 0x0e, 0xf3, 0xd5, 0xa7, 0xe1, 0x6b, 0x44, 0xb0, 0x49, 0xc2, 0x2f,
 	0xa1, 0x36, 0xc9, 0xc7, 0xc6, 0xf0, 0x3e, 0x1c, 0xe6, 0xbd, 0x3d, 0x05, 0x6f, 0x1a, 0xfd, 0x2c,
-	0xc9, 0xee, 0x40, 0x29, 0xe1, 0x63, 0x63, 0x08, 0x3f, 0x1a, 0x26, 0xdc, 0x9c, 0x82, 0x50, 0x00,
-	0xa6, 0x6c, 0x3a, 0xe2, 0x5e, 0x97, 0x63, 0xd3, 0x04, 0x6c, 0x82, 0xd0, 0xf8, 0x99, 0x06, 0x6b,
-	0xe3, 0xfa, 0x21, 0xf4, 0x18, 0xde, 0x9e, 0x98, 0xce, 0x47, 0x1a, 0xe5, 0xeb, 0x13, 0x12, 0xf3,
-	0xa0, 0x5b, 0x7e, 0x0b, 0xca, 0x0e, 0x57, 0xcf, 0x62, 0xfe, 0x73, 0xec, 0xc9, 0x1c, 0x5b, 0x36,
-	0x4b, 0x62, 0xec, 0x50, 0x0c, 0x19, 0x36, 0xac, 0x8f, 0xad, 0xc1, 0x68, 0x0f, 0x16, 0x7a, 0x98,
-	0x51, 0xe2, 0x84, 0xaa, 0xcb, 0xad, 0x4f, 0x19, 0xc1, 0x8f, 0xa5, 0x94, 0x19, 0x89, 0x1b, 0x6d,
-	0xb8, 0x76, 0x5e, 0x33, 0x86, 0x6e, 0xc1, 0x7a, 0xb2, 0xb3, 0x49, 0x6f, 0x73, 0x8d, 0x24, 0xbb,
-	0x21, 0x35, 0x67, 0xfc, 0xa5, 0x02, 0x0b, 0x8a, 0x09, 0xd9, 0x50, 0x0a, 0x12, 0x95, 0x44, 0x96,
-	0xbd, 0xef, 0x66, 0x53, 0xb7, 0x7e, 0xc0, 0x52, 0xa5, 0x23, 0x89, 0x89, 0xf6, 0x21, 0xdf, 0x0f,
-	0x31, 0x55, 0x55, 0xea, 0x6e, 0x46, 0xec, 0xa3, 0x10, 0x53, 0x09, 0x2a, 0x50, 0xf4, 0x5f, 0x97,
-	0x00, 0x06, 0xe1, 0x8d, 0xbe, 0x80, 0xa8, 0xf4, 0x63, 0xd7, 0xc2, 0x5d, 0x2c, 0xf3, 0xa6, 0xb4,
-	0xfa, 0xa3, 0xac, 0xdb, 0x88, 0x61, 0xa3, 0x54, 0x8a, 0xdd, 0xa6, 0x82, 0x34, 0x57, 0x82, 0xf4,
-	0x10, 0xfa, 0x1c, 0x96, 0x6d, 0x47, 0x7c, 0x91, 0xc5, 0xc4, 0xd2, 0xbd, 0xf7, 0x66, 0x27, 0xde,
-	0x16, 0x80, 0x31, 0x6b, 0xc5, 0x1e, 0x7a, 0x47, 0x04, 0xe0, 0x85, 0xcd, 0x30, 0xed, 0xd9, 0xf4,
-	0x79, 0x54, 0x85, 0x5b, 0xb3, 0xb3, 0x3d, 0x8b, 0xb1, 0x54, 0xc9, 0x1f, 0x80, 0xeb, 0x7f, 0xcf,
-	0x41, 0xf1, 0x31, 0xb6, 0xc3, 0x3e, 0xc5, 0x2e, 0xfa, 0xa5, 0x06, 0x6b, 0xc4, 0x0b, 0xfa, 0x2c,
-	0xda, 0xaa, 0xe5, 0xf8, 0x7d, 0x69, 0x69, 0xae, 0xc2, 0xa7, 0xb3, 0xab, 0x10, 0x51, 0xd4, 0x5b,
-	0x1c, 0x5e, 0x6d, 0xb4, 0x21, 0xc0, 0xa5, 0x4e, 0x88, 0x8c, 0x4c, 0xa0, 0x6f, 0x34, 0x58, 0xf7,
-	0xfb, 0x6c, 0x8c, 0x3e, 0xd2, 0xc9, 0x7e, 0x78, 0x09, 0xfa, 0x3c, 0x15, 0xf8, 0x63, 0x14, 0x5a,
-	0xf5, 0x47, 0x67, 0xd0, 0x26, 0x54, 0x99, 0xcf, 0xec, 0xae, 0xc5, 0x3f, 0xe2, 0xad, 0x30, 0xc0,
-	0x1e, 0xab, 0xe5, 0xae, 0x6b, 0x9b, 0x9a, 0x59, 0x11, 0xe3, 0x87, 0xa4, 0x87, 0xdb, 0x7c, 0x54,
-	0x6f, 0xc2, 0xc6, 0x84, 0xad, 0x8e, 0xc9, 0x9b, 0x6b, 0xc9, 0xbc, 0x99, 0x4b, 0x26, 0xde, 0xfb,
-	0x50, 0x9b, 0xa4, 0x61, 0x26, 0x9c, 0x10, 0x56, 0x46, 0x9c, 0x1d, 0xfd, 0x08, 0x8a, 0x3d, 0x65,
-	0x07, 0x15, 0x4b, 0x3b, 0x17, 0xb7, 0xa8, 0x19, 0x63, 0xea, 0xdf, 0xe4, 0xa0, 0x32, 0xec, 0xe9,
-	0xff, 0x6b, 0x4a, 0xf4, 0x2e, 0xa0, 0x13, 0x6a, 0x47, 0x69, 0xb2, 0x67, 0x13, 0x8f, 0x78, 0x1d,
-	0x61, 0x0e, 0xcd, 0x5c, 0x89, 0x66, 0xcc, 0x68, 0x02, 0xfd, 0x5e, 0x83, 0xab, 0xc3, 0x1e, 0x16,
-	0x26, 0xc4, 0x64, 0xe0, 0xe1, 0xcb, 0x0a, 0xf3, 0x61, 0x5f, 0x0b, 0x63, 0x2d, 0xa4, 0xbf, 0x6d,
-	0xf8, 0xe3, 0x67, 0xf5, 0x87, 0x70, 0xed, 0x3c, 0xc1, 0x4c, 0x6e, 0xf0, 0x21, 0x2c, 0xa7, 0x92,
-	0x41, 0x26, 0xf1, 0x02, 0xe4, 0x79, 0xa2, 0xd6, 0xcf, 0xa0, 0x9a, 0x2e, 0x06, 0x63, 0x70, 0x9e,
-	0x0e, 0x77, 0x03, 0xf7, 0x66, 0xb6, 0x63, 0x52, 0x85, 0x2e, 0x2c, 0xc6, 0xb5, 0x62, 0x0c, 0x67,
-	0x6b, 0x98, 0xf3, 0xd6, 0x0c, 0x65, 0x28, 0xd9, 0x86, 0x10, 0x78, 0xe3, 0xdc, 0xcf, 0xe1, 0x4b,
-	0xec, 0x01, 0xba, 0x70, 0x75, 0xe2, 0x9d, 0xc8, 0x4c, 0x0d, 0x00, 0xd2, 0xa1, 0x18, 0x79, 0xbc,
-	0x8a, 0x80, 0xf8, 0xdd, 0xd8, 0x82, 0x8d, 0x64, 0x46, 0x31, 0x71, 0xc8, 0xb5, 0xe0, 0x53, 0xfc,
-	0xf8, 0x45, 0x96, 0x15, 0xd8, 0x39, 0x53, 0xbe, 0x18, 0xb7, 0xe0, 0xf5, 0xa4, 0x40, 0xfb, 0x39,
-	0x09, 0x5e, 0x2d, 0xf4, 0xa7, 0x39, 0xfe, 0xad, 0x9b, 0xbe, 0xab, 0x14, 0x3b, 0xbb, 0x94, 0xbb,
-	0x4e, 0x17, 0xd6, 0x1d, 0xbf, 0x17, 0x74, 0x31, 0xc3, 0xae, 0x45, 0x07, 0xea, 0xa8, 0xd3, 0xdf,
-	0x9a, 0xa2, 0xff, 0xbc, 0xdf, 0xf7, 0x84, 0x48, 0x3b, 0xc0, 0x8e, 0xb9, 0x16, 0xa3, 0x25, 0xf7,
-	0xe6, 0xc2, 0x7a, 0x9c, 0x13, 0x86, 0x58, 0x72, 0x33, 0xb2, 0xc4, 0x68, 0x09, 0x16, 0x83, 0x81,
-	0x3e, 0xf9, 0xee, 0x03, 0x7d, 0x02, 0x05, 0x71, 0x9d, 0x12, 0x66, 0xbe, 0xb2, 0x18, 0x6b, 0x7d,
-	0x53, 0xa1, 0x19, 0xff, 0xd6, 0xa0, 0x18, 0x27, 0xe7, 0x3d, 0xc8, 0xbb, 0x36, 0xb3, 0x15, 0xc5,
-	0xed, 0x29, 0x29, 0xe2, 0xf4, 0xb6, 0x6b, 0x33, 0xdb, 0x14, 0x08, 0xfa, 0x6f, 0x34, 0xc8, 0xf3,
-	0xd7, 0xd9, 0x1c, 0x77, 0x70, 0x4d, 0x7d, 0xfe, 0xb7, 0xe0, 0xf9, 0xd7, 0xd4, 0x08, 0xa9, 0xed,
-	0xf0, 0x63, 0x2a, 0x4b, 0xc5, 0x8c, 0x3f, 0xe4, 0xa0, 0xdc, 0xe6, 0x1f, 0xaa, 0x51, 0x64, 0xa5,
-	0xaf, 0x5c, 0x26, 0x2a, 0x3c, 0x77, 0x8e, 0xc2, 0xfb, 0xb0, 0x28, 0x3f, 0xad, 0x79, 0x36, 0x3a,
-	0xdf, 0x2b, 0xd2, 0x3a, 0x0b, 0x65, 0x1e, 0xe1, 0x33, 0xb3, 0x18, 0xaa, 0x27, 0xf4, 0x08, 0x72,
-	0x7c, 0xef, 0x19, 0xaf, 0xa6, 0x05, 0xd0, 0x03, 0x9c, 0xb8, 0x46, 0xe5, 0x28, 0xe8, 0x10, 0x0a,
-	0x76, 0x10, 0x60, 0xcf, 0x8d, 0xee, 0x1d, 0xef, 0x65, 0xc1, 0xdb, 0x16, 0xa2, 0x03, 0x48, 0x85,
-	0x85, 0xbe, 0x07, 0xf3, 0x4e, 0x17, 0xdb, 0x34, 0xba, 0x5b, 0xbc, 0x9b, 0x05, 0xb4, 0xc1, 0x25,
-	0x07, 0x98, 0x12, 0x29, 0x79, 0xc1, 0xfb, 0xb7, 0x39, 0x58, 0x52, 0x87, 0xa4, 0xdc, 0x3f, 0x7d,
-	0x4a, 0xe3, 0xef, 0x70, 0xdf, 0x84, 0x52, 0xe2, 0x63, 0x4e, 0x9d, 0x3b, 0x0c, 0xbe, 0xe5, 0xd0,
-	0xfe, 0x90, 0x65, 0xef, 0x64, 0xb6, 0x6c, 0x7c, 0x11, 0x29, 0x4c, 0x7b, 0x94, 0x36, 0xed, 0xfb,
-	0xb3, 0x98, 0x36, 0xc6, 0x8c, 0x6c, 0x6b, 0xa6, 0x6c, 0x7b, 0x6f, 0x06, 0xdb, 0xc6, 0xa0, 0xca,
-	0xb8, 0xc9, 0x4b, 0xd2, 0x6f, 0xf3, 0x50, 0x8c, 0xbc, 0x0e, 0x1d, 0x40, 0x41, 0xfe, 0xc2, 0x52,
-	0xe5, 0xeb, 0xbd, 0x8c, 0x6e, 0x5b, 0x37, 0x85, 0x34, 0x57, 0x5f, 0xe2, 0xa0, 0x10, 0x56, 0x7b,
-	0xfd, 0x2e, 0x23, 0x3d, 0x3b, 0xb0, 0x42, 0xe2, 0x62, 0x4b, 0x34, 0xf6, 0x2a, 0x92, 0xb7, 0xb3,
-	0xc2, 0x3f, 0x56, 0x50, 0x6d, 0xe2, 0x62, 0xd1, 0x4f, 0xef, 0x5d, 0x31, 0x57, 0x7a, 0xe9, 0x41,
-	0xe4, 0x42, 0xe5, 0xd8, 0xee, 0x58, 0xfc, 0xd3, 0xd1, 0x12, 0x71, 0xa4, 0xa2, 0xf0, 0x83, 0xac,
-	0x7c, 0x3b, 0x76, 0x87, 0xf7, 0x00, 0xe2, 0x7d, 0xef, 0x8a, 0x59, 0x3e, 0x4e, 0xbc, 0xeb, 0x3a,
-	0x14, 0xe4, 0x76, 0x93, 0x8d, 0x47, 0x59, 0x34, 0x1e, 0xfa, 0xd7, 0x1a, 0xac, 0x8c, 0x28, 0x8b,
-	0xde, 0x86, 0xa5, 0xc1, 0x37, 0xf2, 0xe0, 0x8f, 0x44, 0x79, 0x30, 0xd8, 0x72, 0x91, 0x01, 0x4b,
-	0x03, 0x43, 0xf1, 0x45, 0xd2, 0xa9, 0x4b, 0x61, 0x04, 0xd3, 0x72, 0xd1, 0x6b, 0x50, 0x90, 0xb7,
-	0x95, 0xca, 0xab, 0xd5, 0x5b, 0xa4, 0x48, 0x7e, 0xa0, 0xc8, 0x4f, 0x34, 0x28, 0x27, 0x77, 0x31,
-	0xb5, 0x0e, 0x03, 0xe3, 0x25, 0x74, 0xe8, 0x47, 0x30, 0x59, 0x74, 0xd8, 0x29, 0x40, 0x9e, 0x9d,
-	0x05, 0xd8, 0xf8, 0x18, 0x96, 0x53, 0x69, 0x89, 0x37, 0xe8, 0x8e, 0xef, 0x31, 0xe2, 0xf5, 0x6d,
-	0x91, 0x60, 0x65, 0xa8, 0x4a, 0x43, 0xae, 0x24, 0x67, 0x44, 0xc4, 0x1a, 0x47, 0x50, 0x4d, 0x87,
-	0x5f, 0x46, 0x88, 0xb8, 0x0c, 0xcc, 0x25, 0xca, 0xc0, 0x26, 0xa0, 0xd1, 0xfc, 0x16, 0xaf, 0xd4,
-	0x12, 0x2b, 0xd7, 0x61, 0x75, 0x4c, 0xb8, 0x1a, 0xab, 0xb0, 0x32, 0x92, 0xcb, 0x8c, 0x35, 0x85,
-	0x3a, 0x14, 0x84, 0xc6, 0x5f, 0xf3, 0x50, 0xdc, 0xf7, 0x55, 0xb3, 0xfe, 0x03, 0x28, 0x86, 0xf8,
-	0x14, 0x53, 0xc2, 0xa4, 0xf7, 0x54, 0x6e, 0x7e, 0x38, 0xa5, 0x8b, 0x46, 0x10, 0xf5, 0xb6, 0x92,
-	0xaf, 0x37, 0xbd, 0x7e, 0xcf, 0x8c, 0xe1, 0xd0, 0x5d, 0x58, 0x8c, 0x7f, 0x2d, 0xab, 0x70, 0xd3,
-	0xeb, 0xf2, 0xe7, 0x73, 0x3d, 0xfa, 0xf9, 0x5c, 0x3f, 0x8c, 0x56, 0x98, 0x83, 0xc5, 0xa8, 0xc6,
-	0x9b, 0xd8, 0x30, 0xb4, 0x3b, 0x32, 0x6c, 0x16, 0xcd, 0xe8, 0x95, 0xe7, 0x59, 0x46, 0x6d, 0x07,
-	0x8b, 0xc3, 0x5d, 0x34, 0xe5, 0xcb, 0xe4, 0x1a, 0x39, 0x7f, 0x4e, 0x8d, 0x7c, 0x65, 0xbf, 0x57,
-	0x78, 0x75, 0xbf, 0xf7, 0x16, 0x94, 0xbb, 0x7e, 0xc7, 0xea, 0xfa, 0x8e, 0x38, 0x5f, 0x71, 0x65,
-	0xbd, 0x68, 0x96, 0xba, 0x7e, 0x67, 0x5f, 0x0d, 0x71, 0x27, 0x65, 0x9f, 0x51, 0x6c, 0xbb, 0xb5,
-	0xa2, 0x98, 0x54, 0x6f, 0xfa, 0xf7, 0xd5, 0x2f, 0xf0, 0x03, 0xe0, 0xcb, 0x2d, 0xec, 0x31, 0x4a,
-	0x70, 0xd4, 0x4d, 0x6d, 0x65, 0x3c, 0x03, 0x13, 0xba, 0xf2, 0x89, 0xe0, 0x50, 0xa7, 0x50, 0x8c,
-	0x8e, 0xc4, 0x38, 0x81, 0x3c, 0x3f, 0x15, 0xb4, 0x0c, 0xa5, 0xa3, 0x27, 0xed, 0x83, 0x66, 0xa3,
-	0x75, 0xbf, 0xd5, 0xdc, 0xad, 0x5e, 0x41, 0x8b, 0x30, 0x7f, 0x68, 0x6e, 0x37, 0x9a, 0x55, 0x8d,
-	0x3f, 0xee, 0x36, 0x77, 0x8e, 0x1e, 0x54, 0xe7, 0x50, 0x11, 0xf2, 0xad, 0x27, 0xf7, 0x9f, 0x56,
-	0x73, 0x08, 0xa0, 0xf0, 0xe4, 0xe9, 0x61, 0xab, 0xd1, 0xac, 0xe6, 0xf9, 0xe8, 0xb3, 0x6d, 0xf3,
-	0x49, 0x75, 0x9e, 0x2f, 0x6d, 0x9a, 0xe6, 0x53, 0xb3, 0x5a, 0x40, 0x65, 0x28, 0x36, 0xcc, 0xd6,
-	0x61, 0xab, 0xb1, 0xbd, 0x5f, 0x5d, 0x30, 0xca, 0x00, 0xfb, 0x7e, 0xa7, 0xe1, 0x7b, 0x8c, 0xfa,
-	0x5d, 0xe3, 0x18, 0x96, 0x77, 0x7d, 0xe7, 0x39, 0xa6, 0x7c, 0xc0, 0x26, 0x3c, 0x41, 0xa5, 0x0b,
-	0x66, 0x15, 0x72, 0x7d, 0x4a, 0x54, 0x54, 0xf3, 0x47, 0x1e, 0x45, 0xf2, 0x27, 0x25, 0x3d, 0x4b,
-	0x1c, 0x82, 0x3c, 0xff, 0x95, 0x68, 0x26, 0x36, 0xfd, 0xcd, 0xdf, 0x69, 0xb0, 0xb4, 0x83, 0xed,
-	0xde, 0x7d, 0x4f, 0xb1, 0xa2, 0xaf, 0x35, 0x58, 0x88, 0x9e, 0xa7, 0xad, 0x7c, 0x63, 0x7e, 0xdb,
-	0xea, 0xf7, 0x66, 0x91, 0x95, 0x01, 0x77, 0x65, 0x53, 0xfb, 0x7f, 0xed, 0xe6, 0x97, 0x00, 0x52,
-	0x33, 0xd1, 0x71, 0x7a, 0xaa, 0xf3, 0xdc, 0xca, 0xd8, 0xbe, 0xea, 0x59, 0x05, 0x14, 0xfb, 0x4f,
-	0x35, 0x28, 0x49, 0x7a, 0x99, 0x6e, 0x5f, 0xc2, 0xbc, 0x7c, 0xb8, 0x95, 0xa5, 0xf6, 0xa8, 0x1d,
-	0xe9, 0xb7, 0xb3, 0x09, 0xa9, 0x14, 0x23, 0x35, 0xf9, 0x79, 0x7c, 0x44, 0xfb, 0x7e, 0xa7, 0x43,
-	0xbc, 0x0e, 0x7a, 0x09, 0x0b, 0xd1, 0xe3, 0xed, 0xac, 0x69, 0x86, 0x47, 0x8b, 0x7e, 0x63, 0x7a,
-	0xa9, 0xc8, 0x19, 0x85, 0x2e, 0x3b, 0xdb, 0xf0, 0x7f, 0x93, 0x24, 0x93, 0x82, 0x3b, 0x8b, 0x52,
-	0xe1, 0xed, 0x80, 0x7c, 0x5a, 0x49, 0x4c, 0x59, 0xa7, 0x37, 0x8e, 0x0b, 0x22, 0x69, 0xdd, 0xfa,
-	0x6f, 0x00, 0x00, 0x00, 0xff, 0xff, 0x15, 0x95, 0xf5, 0x69, 0xa3, 0x23, 0x00, 0x00,
+	0xc9, 0xde, 0x81, 0x52, 0xc2, 0xc7, 0xc6, 0x10, 0x7e, 0x34, 0x4c, 0xb8, 0x39, 0x05, 0xa1, 0x00,
+	0x4c, 0xd9, 0x74, 0xc4, 0xbd, 0x2e, 0xc7, 0xa6, 0x09, 0xd8, 0x04, 0xa1, 0xf1, 0x33, 0x0d, 0xd6,
+	0xc6, 0xd5, 0x43, 0xe8, 0x31, 0xbc, 0x3d, 0x31, 0x9c, 0x8f, 0x14, 0xca, 0xd7, 0x27, 0x04, 0xe6,
+	0xb8, 0x5a, 0x7e, 0x0b, 0xca, 0x9d, 0x40, 0x3d, 0x8b, 0x7b, 0xcf, 0xb1, 0x2b, 0x63, 0x6c, 0xd9,
+	0x2c, 0x89, 0xbe, 0x43, 0xd1, 0x65, 0xd8, 0xb0, 0x3e, 0x36, 0x07, 0xa3, 0x3d, 0x58, 0xe8, 0x63,
+	0x4e, 0x49, 0x87, 0xa9, 0x2a, 0xb7, 0x3e, 0xe5, 0x09, 0x7e, 0x2c, 0xa5, 0xcc, 0x50, 0xdc, 0x68,
+	0xc3, 0xb5, 0xf3, 0x8a, 0x31, 0x74, 0x0b, 0xd6, 0x93, 0x95, 0x4d, 0x7a, 0x99, 0x6b, 0x24, 0x59,
+	0x0d, 0xa9, 0x31, 0xe3, 0x2f, 0x15, 0x58, 0x50, 0x4c, 0xc8, 0x86, 0x92, 0x9f, 0xc8, 0x24, 0x32,
+	0xed, 0x7d, 0x37, 0x9b, 0xba, 0xf5, 0x03, 0x9e, 0x4a, 0x1d, 0x49, 0x4c, 0xb4, 0x0f, 0xf9, 0x01,
+	0xc3, 0x54, 0x65, 0xa9, 0xbb, 0x19, 0xb1, 0x8f, 0x18, 0xa6, 0x12, 0x54, 0xa0, 0xe8, 0xbf, 0x2e,
+	0x01, 0xc4, 0xc7, 0x1b, 0x7d, 0x01, 0x61, 0xea, 0xc7, 0x8e, 0x85, 0x7b, 0x58, 0xc6, 0x4d, 0x69,
+	0xf5, 0x47, 0x59, 0x97, 0x11, 0xc1, 0x86, 0xa1, 0x14, 0x3b, 0x4d, 0x05, 0x69, 0xae, 0xf8, 0xe9,
+	0x2e, 0xf4, 0x39, 0x2c, 0xdb, 0x1d, 0x71, 0x23, 0x8b, 0x88, 0xa5, 0x7b, 0xef, 0xcd, 0x4e, 0xbc,
+	0x2d, 0x00, 0x23, 0xd6, 0x8a, 0x3d, 0xd4, 0x46, 0x04, 0xe0, 0x85, 0xcd, 0x31, 0xed, 0xdb, 0xf4,
+	0x79, 0x98, 0x85, 0x5b, 0xb3, 0xb3, 0x3d, 0x8b, 0xb0, 0x54, 0xca, 0x8f, 0xc1, 0xf5, 0xbf, 0xe7,
+	0xa0, 0xf8, 0x18, 0xdb, 0x6c, 0x40, 0xb1, 0x83, 0x7e, 0xa9, 0xc1, 0x1a, 0x71, 0xfd, 0x01, 0x0f,
+	0x97, 0x6a, 0x75, 0xbc, 0x81, 0xb4, 0x74, 0xa0, 0xc2, 0xa7, 0xb3, 0xab, 0x10, 0x52, 0xd4, 0x5b,
+	0x01, 0xbc, 0x5a, 0x68, 0x43, 0x80, 0x4b, 0x9d, 0x10, 0x19, 0x19, 0x40, 0xdf, 0x68, 0xb0, 0xee,
+	0x0d, 0xf8, 0x18, 0x7d, 0xa4, 0x93, 0xfd, 0xf0, 0x12, 0xf4, 0x79, 0x2a, 0xf0, 0xc7, 0x28, 0xb4,
+	0xea, 0x8d, 0x8e, 0xa0, 0x4d, 0xa8, 0x72, 0x8f, 0xdb, 0x3d, 0x2b, 0xb8, 0xc4, 0x5b, 0xcc, 0xc7,
+	0x2e, 0xaf, 0xe5, 0xae, 0x6b, 0x9b, 0x9a, 0x59, 0x11, 0xfd, 0x87, 0xa4, 0x8f, 0xdb, 0x41, 0xaf,
+	0xde, 0x84, 0x8d, 0x09, 0x4b, 0x1d, 0x13, 0x37, 0xd7, 0x92, 0x71, 0x33, 0x97, 0x0c, 0xbc, 0xf7,
+	0xa1, 0x36, 0x49, 0xc3, 0x4c, 0x38, 0x0c, 0x56, 0x46, 0x9c, 0x1d, 0xfd, 0x08, 0x8a, 0x7d, 0x65,
+	0x07, 0x75, 0x96, 0x76, 0x2e, 0x6e, 0x51, 0x33, 0xc2, 0xd4, 0xbf, 0xc9, 0x41, 0x65, 0xd8, 0xd3,
+	0xff, 0xd7, 0x94, 0xe8, 0x5d, 0x40, 0x27, 0xd4, 0x0e, 0xc3, 0x64, 0xdf, 0x26, 0x2e, 0x71, 0xbb,
+	0xc2, 0x1c, 0x9a, 0xb9, 0x12, 0x8e, 0x98, 0xe1, 0x00, 0xfa, 0xbd, 0x06, 0x57, 0x87, 0x3d, 0x8c,
+	0x25, 0xc4, 0xe4, 0xc1, 0xc3, 0x97, 0x75, 0xcc, 0x87, 0x7d, 0x8d, 0x45, 0x5a, 0x48, 0x7f, 0xdb,
+	0xf0, 0xc6, 0x8f, 0xea, 0x0f, 0xe1, 0xda, 0x79, 0x82, 0x99, 0xdc, 0xe0, 0x43, 0x58, 0x4e, 0x05,
+	0x83, 0x4c, 0xe2, 0x05, 0xc8, 0x07, 0x81, 0x5a, 0x3f, 0x83, 0x6a, 0x3a, 0x19, 0x8c, 0xc1, 0x79,
+	0x3a, 0x5c, 0x0d, 0xdc, 0x9b, 0xd9, 0x8e, 0x49, 0x15, 0x7a, 0xb0, 0x18, 0xe5, 0x8a, 0x31, 0x9c,
+	0xad, 0x61, 0xce, 0x5b, 0x33, 0xa4, 0xa1, 0x64, 0x19, 0x42, 0xe0, 0x8d, 0x73, 0xaf, 0xc3, 0x97,
+	0x58, 0x03, 0xf4, 0xe0, 0xea, 0xc4, 0x37, 0x91, 0x99, 0x0a, 0x00, 0xa4, 0x43, 0x31, 0xf4, 0x78,
+	0x75, 0x02, 0xa2, 0xb6, 0xb1, 0x05, 0x1b, 0xc9, 0x88, 0x62, 0x62, 0x16, 0x68, 0x11, 0x0c, 0x05,
+	0xdb, 0x2f, 0xa2, 0xac, 0xc0, 0xce, 0x99, 0xb2, 0x61, 0xdc, 0x82, 0xd7, 0x93, 0x02, 0xed, 0xe7,
+	0xc4, 0x7f, 0xb5, 0xd0, 0x9f, 0xe6, 0x82, 0xbb, 0x6e, 0xfa, 0xad, 0x52, 0xac, 0xec, 0x52, 0xde,
+	0x3a, 0x1d, 0x58, 0xef, 0x78, 0x7d, 0xbf, 0x87, 0x39, 0x76, 0x2c, 0x1a, 0xab, 0xa3, 0x76, 0x7f,
+	0x6b, 0x8a, 0xfa, 0xf3, 0xfe, 0xc0, 0x15, 0x22, 0x6d, 0x1f, 0x77, 0xcc, 0xb5, 0x08, 0x2d, 0xb9,
+	0x36, 0x07, 0xd6, 0xa3, 0x98, 0x30, 0xc4, 0x92, 0x9b, 0x91, 0x25, 0x42, 0x4b, 0xb0, 0x18, 0x1c,
+	0xf4, 0xc9, 0x6f, 0x1f, 0xe8, 0x13, 0x28, 0x88, 0xe7, 0x14, 0x96, 0xf9, 0xc9, 0x62, 0xac, 0xf5,
+	0x4d, 0x85, 0x66, 0xfc, 0x5b, 0x83, 0x62, 0x14, 0x9c, 0xf7, 0x20, 0xef, 0xd8, 0xdc, 0x56, 0x14,
+	0xb7, 0xa7, 0xa4, 0x88, 0xc2, 0xdb, 0xae, 0xcd, 0x6d, 0x53, 0x20, 0xe8, 0xbf, 0xd1, 0x20, 0x1f,
+	0x34, 0x67, 0x73, 0xdc, 0xf8, 0x99, 0xfa, 0xfc, 0xbb, 0xe0, 0xf9, 0xcf, 0xd4, 0x08, 0xa9, 0xe5,
+	0x04, 0xdb, 0x54, 0x96, 0x8a, 0x19, 0x7f, 0xc8, 0x41, 0xb9, 0x1d, 0x5c, 0x54, 0xc3, 0x93, 0x95,
+	0x7e, 0x72, 0x99, 0xa8, 0xf0, 0xdc, 0x39, 0x0a, 0xef, 0xc3, 0xa2, 0xbc, 0x5a, 0x07, 0xd1, 0xe8,
+	0x7c, 0xaf, 0x48, 0xeb, 0x2c, 0x94, 0x79, 0x84, 0xcf, 0xcc, 0x22, 0x53, 0x5f, 0xe8, 0x11, 0xe4,
+	0x82, 0xb5, 0x67, 0x7c, 0x9a, 0x16, 0x40, 0x0f, 0x70, 0xe2, 0x19, 0x35, 0x40, 0x41, 0x87, 0x50,
+	0xb0, 0x7d, 0x1f, 0xbb, 0x4e, 0xf8, 0xee, 0x78, 0x2f, 0x0b, 0xde, 0xb6, 0x10, 0x8d, 0x21, 0x15,
+	0x16, 0xfa, 0x1e, 0xcc, 0x77, 0x7a, 0xd8, 0xa6, 0xe1, 0xdb, 0xe2, 0xdd, 0x2c, 0xa0, 0x8d, 0x40,
+	0x32, 0xc6, 0x94, 0x48, 0xc9, 0x07, 0xde, 0xbf, 0xcd, 0xc1, 0x92, 0xda, 0x24, 0xe5, 0xfe, 0xe9,
+	0x5d, 0x1a, 0xff, 0x86, 0xfb, 0x26, 0x94, 0x12, 0x97, 0x39, 0xb5, 0xef, 0x10, 0xdf, 0xe5, 0xd0,
+	0xfe, 0x90, 0x65, 0xef, 0x64, 0xb6, 0x6c, 0xf4, 0x10, 0x29, 0x4c, 0x7b, 0x94, 0x36, 0xed, 0xfb,
+	0xb3, 0x98, 0x36, 0xc2, 0x0c, 0x6d, 0x6b, 0xa6, 0x6c, 0x7b, 0x6f, 0x06, 0xdb, 0x46, 0xa0, 0xca,
+	0xb8, 0xc9, 0x47, 0xd2, 0x6f, 0xf3, 0x50, 0x0c, 0xbd, 0x0e, 0x1d, 0x40, 0x41, 0xfe, 0xc2, 0x52,
+	0xe9, 0xeb, 0xbd, 0x8c, 0x6e, 0x5b, 0x37, 0x85, 0x74, 0xa0, 0xbe, 0xc4, 0x41, 0x0c, 0x56, 0xfb,
+	0x83, 0x1e, 0x27, 0x7d, 0xdb, 0xb7, 0x18, 0x71, 0xb0, 0x25, 0x0a, 0x7b, 0x75, 0x92, 0xb7, 0xb3,
+	0xc2, 0x3f, 0x56, 0x50, 0x6d, 0xe2, 0x60, 0x51, 0x4f, 0xef, 0x5d, 0x31, 0x57, 0xfa, 0xe9, 0x4e,
+	0xe4, 0x40, 0xe5, 0xd8, 0xee, 0x5a, 0xc1, 0xd5, 0xd1, 0x12, 0xe7, 0x48, 0x9d, 0xc2, 0x0f, 0xb2,
+	0xf2, 0xed, 0xd8, 0xdd, 0xa0, 0x06, 0x10, 0xed, 0xbd, 0x2b, 0x66, 0xf9, 0x38, 0xd1, 0xd6, 0x75,
+	0x28, 0xc8, 0xe5, 0x26, 0x0b, 0x8f, 0xb2, 0x28, 0x3c, 0xf4, 0xaf, 0x35, 0x58, 0x19, 0x51, 0x16,
+	0xbd, 0x0d, 0x4b, 0xf1, 0x1d, 0x39, 0xfe, 0x23, 0x51, 0x8e, 0x3b, 0x5b, 0x0e, 0x32, 0x60, 0x29,
+	0x36, 0x54, 0x30, 0x49, 0x3a, 0x75, 0x89, 0x85, 0x30, 0x2d, 0x07, 0xbd, 0x06, 0x05, 0xf9, 0x5a,
+	0xa9, 0xbc, 0x5a, 0xb5, 0x42, 0x45, 0xf2, 0xb1, 0x22, 0x3f, 0xd1, 0xa0, 0x9c, 0x5c, 0xc5, 0xd4,
+	0x3a, 0xc4, 0xc6, 0x4b, 0xe8, 0x30, 0x08, 0x61, 0xb2, 0xe8, 0xb0, 0x53, 0x80, 0x3c, 0x3f, 0xf3,
+	0xb1, 0xf1, 0x31, 0x2c, 0xa7, 0xc2, 0x52, 0x50, 0xa0, 0x77, 0x3c, 0x97, 0x13, 0x77, 0x60, 0x8b,
+	0x00, 0x2b, 0x8f, 0xaa, 0x34, 0xe4, 0x4a, 0x72, 0x44, 0x9c, 0x58, 0xe3, 0x08, 0xaa, 0xe9, 0xe3,
+	0x97, 0x11, 0x22, 0x4a, 0x03, 0x73, 0x89, 0x34, 0xb0, 0x09, 0x68, 0x34, 0xbe, 0x45, 0x33, 0xb5,
+	0xc4, 0xcc, 0x75, 0x58, 0x1d, 0x73, 0x5c, 0x8d, 0x55, 0x58, 0x19, 0x89, 0x65, 0xc6, 0x9a, 0x42,
+	0x1d, 0x3a, 0x84, 0xc6, 0x5f, 0xf3, 0x50, 0xdc, 0xf7, 0x54, 0xb1, 0xfe, 0x03, 0x28, 0x32, 0x7c,
+	0x8a, 0x29, 0xe1, 0xd2, 0x7b, 0x2a, 0x37, 0x3f, 0x9c, 0xd2, 0x45, 0x43, 0x88, 0x7a, 0x5b, 0xc9,
+	0xd7, 0x9b, 0xee, 0xa0, 0x6f, 0x46, 0x70, 0xe8, 0x2e, 0x2c, 0x46, 0xbf, 0x96, 0xd5, 0x71, 0xd3,
+	0xeb, 0xf2, 0xe7, 0x73, 0x3d, 0xfc, 0xf9, 0x5c, 0x3f, 0x0c, 0x67, 0x98, 0xf1, 0x64, 0x54, 0x0b,
+	0x8a, 0x58, 0xc6, 0xec, 0xae, 0x3c, 0x36, 0x8b, 0x66, 0xd8, 0x0c, 0xe2, 0x2c, 0xa7, 0x76, 0x07,
+	0x8b, 0xcd, 0x5d, 0x34, 0x65, 0x63, 0x72, 0x8e, 0x9c, 0x3f, 0x27, 0x47, 0xbe, 0xb2, 0xde, 0x2b,
+	0xbc, 0xba, 0xde, 0x7b, 0x0b, 0xca, 0x3d, 0xaf, 0x6b, 0xf5, 0xbc, 0x8e, 0xd8, 0x5f, 0xf1, 0x64,
+	0xbd, 0x68, 0x96, 0x7a, 0x5e, 0x77, 0x5f, 0x75, 0x05, 0x4e, 0xca, 0x3f, 0xa3, 0xd8, 0x76, 0x6a,
+	0x45, 0x31, 0xa8, 0x5a, 0xfa, 0xf7, 0xd5, 0x2f, 0xf0, 0x03, 0x08, 0xa6, 0x5b, 0xd8, 0xe5, 0x94,
+	0xe0, 0xb0, 0x9a, 0xda, 0xca, 0xb8, 0x07, 0x26, 0xf4, 0xe4, 0x17, 0xc1, 0x4c, 0xa7, 0x50, 0x0c,
+	0xb7, 0xc4, 0x38, 0x81, 0x7c, 0xb0, 0x2b, 0x68, 0x19, 0x4a, 0x47, 0x4f, 0xda, 0x07, 0xcd, 0x46,
+	0xeb, 0x7e, 0xab, 0xb9, 0x5b, 0xbd, 0x82, 0x16, 0x61, 0xfe, 0xd0, 0xdc, 0x6e, 0x34, 0xab, 0x5a,
+	0xf0, 0xb9, 0xdb, 0xdc, 0x39, 0x7a, 0x50, 0x9d, 0x43, 0x45, 0xc8, 0xb7, 0x9e, 0xdc, 0x7f, 0x5a,
+	0xcd, 0x21, 0x80, 0xc2, 0x93, 0xa7, 0x87, 0xad, 0x46, 0xb3, 0x9a, 0x0f, 0x7a, 0x9f, 0x6d, 0x9b,
+	0x4f, 0xaa, 0xf3, 0xc1, 0xd4, 0xa6, 0x69, 0x3e, 0x35, 0xab, 0x05, 0x54, 0x86, 0x62, 0xc3, 0x6c,
+	0x1d, 0xb6, 0x1a, 0xdb, 0xfb, 0xd5, 0x05, 0xa3, 0x0c, 0xb0, 0xef, 0x75, 0x1b, 0x9e, 0xcb, 0xa9,
+	0xd7, 0xbb, 0xf9, 0x3b, 0x0d, 0x96, 0x76, 0xb0, 0xdd, 0xbf, 0xef, 0xaa, 0x1e, 0xf4, 0xb5, 0x06,
+	0x0b, 0xe1, 0xf7, 0xb4, 0x59, 0x69, 0xcc, 0x2f, 0x55, 0xfd, 0xde, 0x2c, 0xb2, 0xf2, 0x30, 0x5c,
+	0xd9, 0xd4, 0xfe, 0x5f, 0xbb, 0xf9, 0x25, 0x80, 0xd4, 0x4c, 0x54, 0x83, 0xae, 0xaa, 0x0a, 0xb7,
+	0x32, 0x96, 0x96, 0x7a, 0x56, 0x01, 0xc5, 0xfe, 0x53, 0x0d, 0x4a, 0x92, 0x5e, 0x86, 0xc2, 0x97,
+	0x30, 0x2f, 0x3f, 0x6e, 0x65, 0xc9, 0x0b, 0x6a, 0x45, 0xfa, 0xed, 0x6c, 0x42, 0xea, 0xf8, 0x4b,
+	0x4d, 0x7e, 0x1e, 0x6d, 0xd1, 0xbe, 0xd7, 0xed, 0x12, 0xb7, 0x8b, 0x5e, 0xc2, 0x42, 0xf8, 0x79,
+	0x3b, 0x6b, 0x08, 0x08, 0x3c, 0x59, 0xbf, 0x31, 0xbd, 0x94, 0x72, 0x05, 0xa9, 0xcb, 0xce, 0x36,
+	0xfc, 0xdf, 0x24, 0xc9, 0xa4, 0xe0, 0xce, 0xa2, 0x54, 0x78, 0xdb, 0x27, 0x9f, 0x56, 0x12, 0x43,
+	0xd6, 0xe9, 0x8d, 0xe3, 0x82, 0x08, 0x28, 0xb7, 0xfe, 0x1b, 0x00, 0x00, 0xff, 0xff, 0x70, 0x04,
+	0x9c, 0x6a, 0x3f, 0x23, 0x00, 0x00,
 }
&lt;p&gt;diff --git a/sdks/go/pkg/beam/model/fnexecution_v1/beam_provision_api.pb.go b/sdks/go/pkg/beam/model/fnexecution_v1/beam_provision_api.pb.go&lt;br/&gt;
index a4728854301..a1159d9f1e4 100644&lt;br/&gt;
&amp;#8212; a/sdks/go/pkg/beam/model/fnexecution_v1/beam_provision_api.pb.go&lt;br/&gt;
+++ b/sdks/go/pkg/beam/model/fnexecution_v1/beam_provision_api.pb.go&lt;br/&gt;
@@ -51,6 +51,8 @@ type ProvisionInfo struct {&lt;br/&gt;
 	JobId string `protobuf:&quot;bytes,1,opt,name=job_id,json=jobId&quot; json:&quot;job_id,omitempty&quot;`&lt;br/&gt;
 	// (required) The job name.&lt;br/&gt;
 	JobName string `protobuf:&quot;bytes,2,opt,name=job_name,json=jobName&quot; json:&quot;job_name,omitempty&quot;`&lt;br/&gt;
+	// (required) The worker ID.&lt;br/&gt;
+	WorkerId string `protobuf:&quot;bytes,5,opt,name=worker_id,json=workerId&quot; json:&quot;worker_id,omitempty&quot;`&lt;br/&gt;
 	// (required) Pipeline options. For non-template jobs, the options are&lt;br/&gt;
 	// identical to what is passed to job submission.&lt;br/&gt;
 	PipelineOptions *google_protobuf2.Struct `protobuf:&quot;bytes,3,opt,name=pipeline_options,json=pipelineOptions&quot; json:&quot;pipeline_options,omitempty&quot;`&lt;br/&gt;
@@ -78,6 +80,13 @@ func (m *ProvisionInfo) GetJobName() string &lt;/p&gt;
{
 	return &quot;&quot;
 }

&lt;p&gt;+func (m *ProvisionInfo) GetWorkerId() string {&lt;br/&gt;
+	if m != nil &lt;/p&gt;
{
+		return m.WorkerId
+	}
&lt;p&gt;+	return &quot;&quot;&lt;br/&gt;
+}&lt;br/&gt;
+&lt;br/&gt;
 func (m *ProvisionInfo) GetPipelineOptions() *google_protobuf2.Struct {&lt;br/&gt;
 	if m != nil {&lt;br/&gt;
 		return m.PipelineOptions&lt;br/&gt;
@@ -272,35 +281,36 @@ var _ProvisionService_serviceDesc = grpc.ServiceDesc{&lt;br/&gt;
 func init() &lt;/p&gt;
{ proto.RegisterFile(&quot;beam_provision_api.proto&quot;, fileDescriptor1) }

&lt;p&gt; var fileDescriptor1 = []byte&lt;/p&gt;
{
-	// 469 bytes of a gzipped FileDescriptorProto
-	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x9c, 0x93, 0xcf, 0x6e, 0xd3, 0x40,
-	0x10, 0xc6, 0xe5, 0xc6, 0x18, 0x3a, 0x40, 0x1b, 0xad, 0x80, 0xba, 0x56, 0x91, 0x50, 0x04, 0x12,
-	0xa7, 0x2d, 0x2d, 0x20, 0x6e, 0x20, 0xd2, 0x0a, 0xa8, 0x04, 0xb4, 0xda, 0x9e, 0xe0, 0x62, 0xf9,
-	0xcf, 0x24, 0xdd, 0x34, 0xde, 0x59, 0x76, 0xd7, 0x11, 0xf0, 0x1a, 0xbc, 0x04, 0x8f, 0xc5, 0x89,
-	0xe7, 0x40, 0x5e, 0x3b, 0xa1, 0x05, 0x2a, 0xa5, 0xdc, 0xec, 0xf9, 0xf6, 0xfb, 0x79, 0xbf, 0xf1,
-	0x0c, 0xc4, 0x39, 0x66, 0x55, 0xaa, 0x0d, 0xcd, 0xa4, 0x95, 0xa4, 0xd2, 0x4c, 0x4b, 0xae, 0x0d,
-	0x39, 0x62, 0x0f, 0xc8, 0x8c, 0x79, 0xa6, 0xb3, 0xe2, 0x04, 0x79, 0x73, 0x88, 0x57, 0x54, 0xe2,
-	0x94, 0x8f, 0x54, 0x8a, 0x9f, 0xb1, 0xa8, 0x9d, 0x24, 0xc5, 0x67, 0x3b, 0xc9, 0xd6, 0x98, 0x68,
-	0x3c, 0xc5, 0x6d, 0x6f, 0xca, 0xeb, 0xd1, 0xb6, 0x75, 0xa6, 0x2e, 0x5c, 0x0b, 0x19, 0x6c, 0xc2,
-	0xc6, 0x6b, 0x74, 0x47, 0x73, 0xfc, 0x81, 0x1a, 0x91, 0xc0, 0x4f, 0x35, 0x5a, 0x37, 0x28, 0x21,
-	0xfe, 0x5b, 0xb2, 0x9a, 0x94, 0x45, 0xf6, 0x06, 0x42, 0xa9, 0x46, 0x14, 0x07, 0xf7, 0x82, 0x87,
-	0xd7, 0x77, 0x9f, 0xf0, 0xa5, 0xae, 0xc2, 0xcf, 0xb3, 0x3c, 0x61, 0xf0, 0x23, 0x80, 0x9b, 0xe7,
-	0xea, 0xec, 0x36, 0x44, 0x13, 0xca, 0x53, 0x59, 0x7a, 0xfa, 0xaa, 0xb8, 0x32, 0xa1, 0xfc, 0xa0,
-	0x64, 0x9b, 0x70, 0xad, 0x29, 0xab, 0xac, 0xc2, 0x78, 0xc5, 0x0b, 0x57, 0x27, 0x94, 0xbf, 0xcf,
-	0x2a, 0x64, 0x43, 0xe8, 0x6b, 0xa9, 0x71, 0x2a, 0x15, 0xa6, 0xa4, 0x9b, 0xaf, 0xd9, 0xb8, 0xe7,
-	0x6f, 0xb6, 0xc1, 0xdb, 0xf4, 0x7c, 0x9e, 0x9e, 0x1f, 0xfb, 0xf4, 0x62, 0x7d, 0x6e, 0x38, 0x6c,
-	0xcf, 0xb3, 0x0f, 0xb0, 0x6e, 0xd0, 0x52, 0x6d, 0x0a, 0x4c, 0xa7, 0xb2, 0x92, 0xce, 0xc6, 0xa1,
-	0x47, 0x3c, 0x5a, 0x32, 0x9c, 0xe8, 0xdc, 0x56, 0xac, 0xcd, 0x41, 0x6f, 0x3d, 0x67, 0xf0, 0x73,
-	0x05, 0x56, 0x17, 0x2a, 0x3b, 0x84, 0xa8, 0xc2, 0x8a, 0xcc, 0x97, 0xae, 0x79, 0xcf, 0x2e, 0xcb,
-	0xe7, 0xef, 0xbc, 0x5d, 0x74, 0x18, 0xf6, 0x0a, 0x7a, 0x85, 0xae, 0x7d, 0x4f, 0x96, 0xff, 0x15,
-	0xbf, 0x69, 0x7b, 0xba, 0x16, 0x0d, 0x80, 0x8d, 0xe1, 0x96, 0xc5, 0x4a, 0xa6, 0x1a, 0x8d, 0x95,
-	0xd6, 0xa1, 0x72, 0x69, 0x29, 0xed, 0x69, 0xd7, 0xc9, 0xa7, 0x97, 0x06, 0xef, 0x4b, 0x7b, 0x2a,
-	0x58, 0x83, 0x3c, 0x5a, 0x10, 0x9b, 0x5a, 0xb2, 0x05, 0x51, 0x1b, 0x81, 0x31, 0x08, 0xad, 0xfc,
-	0x8a, 0xbe, 0x13, 0xa1, 0xf0, 0xcf, 0xc9, 0x5d, 0xe8, 0xed, 0xe9, 0x9a, 0xdd, 0x81, 0xc8, 0x9e,
-	0x64, 0x06, 0xad, 0x17, 0x57, 0x44, 0xf7, 0x96, 0x24, 0x10, 0x36, 0x90, 0x7f, 0x59, 0x77, 0xbf,
-	0x07, 0xd0, 0x5f, 0xcc, 0xd2, 0x31, 0x9a, 0x99, 0x2c, 0x90, 0x7d, 0x0b, 0xa0, 0xff, 0xe7, 0x1c,
-	0xb3, 0xe7, 0x4b, 0xa6, 0xb9, 0x60, 0x37, 0x92, 0x17, 0xff, 0xed, 0x6f, 0x17, 0x68, 0xb8, 0x0f,
-	0xf7, 0x2f, 0x22, 0x9c, 0x05, 0x0c, 0x6f, 0x2c, 0xec, 0x2f, 0xb5, 0xfc, 0xb8, 0x76, 0x46, 0x4d,
-	0x67, 0x3b, 0x79, 0xe4, 0xc7, 0xfa, 0xf1, 0xaf, 0x00, 0x00, 0x00, 0xff, 0xff, 0x47, 0x8e, 0xd3,
-	0xc2, 0x25, 0x04, 0x00, 0x00,
+	// 485 bytes of a gzipped FileDescriptorProto
+	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x9c, 0x93, 0xdd, 0x6e, 0xd3, 0x40,
+	0x10, 0x85, 0x95, 0xc4, 0x35, 0xcd, 0x00, 0x6d, 0xb4, 0x02, 0xea, 0x9a, 0x22, 0xa1, 0x08, 0x24,
+	0xae, 0xb6, 0xb4, 0x80, 0xb8, 0x03, 0x91, 0x56, 0x40, 0x24, 0xa0, 0xd5, 0xf6, 0x0a, 0x6e, 0x2c,
+	0xff, 0x4c, 0xd2, 0x4d, 0x62, 0xcf, 0xb2, 0xbb, 0x0e, 0x3f, 0xaf, 0xc1, 0x4b, 0xf0, 0x64, 0xbc,
+	0x05, 0x12, 0xf2, 0xda, 0x09, 0x2d, 0x50, 0x29, 0xe5, 0xce, 0x9e, 0xb3, 0xe7, 0xd3, 0xcc, 0xd9,
+	0x59, 0x08, 0x12, 0x8c, 0xf3, 0x48, 0x69, 0x9a, 0x4b, 0x23, 0xa9, 0x88, 0x62, 0x25, 0xb9, 0xd2,
+	0x64, 0x89, 0xdd, 0x27, 0x3d, 0xe6, 0xb1, 0x8a, 0xd3, 0x53, 0xe4, 0xd5, 0x21, 0x9e, 0x53, 0x86,
+	0x33, 0x3e, 0x2a, 0x22, 0xfc, 0x8c, 0x69, 0x69, 0x25, 0x15, 0x7c, 0xbe, 0x17, 0xee, 0x8c, 0x89,
+	0xc6, 0x33, 0xdc, 0x75, 0xa6, 0xa4, 0x1c, 0xed, 0x1a, 0xab, 0xcb, 0xd4, 0xd6, 0x90, 0xfe, 0x36,
+	0x6c, 0xbd, 0x42, 0x7b, 0xbc, 0xc0, 0x0f, 0x8b, 0x11, 0x09, 0xfc, 0x58, 0xa2, 0xb1, 0xfd, 0x0c,
+	0x82, 0xbf, 0x25, 0xa3, 0xa8, 0x30, 0xc8, 0x5e, 0x83, 0x27, 0x8b, 0x11, 0x05, 0xad, 0xbb, 0xad,
+	0x07, 0x57, 0xf7, 0x1f, 0xf3, 0x95, 0x5a, 0xe1, 0xe7, 0x59, 0x8e, 0xd0, 0xff, 0xd9, 0x82, 0xeb,
+	0xe7, 0xea, 0xec, 0x26, 0xf8, 0x13, 0x4a, 0x22, 0x99, 0x39, 0x7a, 0x57, 0xac, 0x4d, 0x28, 0x19,
+	0x66, 0x6c, 0x1b, 0xd6, 0xab, 0x72, 0x11, 0xe7, 0x18, 0xb4, 0x9d, 0x70, 0x65, 0x42, 0xc9, 0xbb,
+	0x38, 0x47, 0x76, 0x1b, 0xba, 0x9f, 0x48, 0x4f, 0x51, 0x57, 0xa6, 0x35, 0xa7, 0xad, 0xd7, 0x85,
+	0x61, 0xc6, 0x06, 0xd0, 0x53, 0x52, 0xe1, 0x4c, 0x16, 0x18, 0x91, 0xaa, 0x5a, 0x31, 0x41, 0xc7,
+	0xb5, 0xbd, 0xc5, 0xeb, 0x68, 0xf8, 0x22, 0x1a, 0x7e, 0xe2, 0xa2, 0x11, 0x9b, 0x0b, 0xc3, 0x51,
+	0x7d, 0x9e, 0xbd, 0x87, 0x4d, 0x8d, 0x86, 0x4a, 0x9d, 0x62, 0x34, 0x93, 0xb9, 0xb4, 0x26, 0xf0,
+	0x1c, 0xe2, 0xe1, 0x8a, 0x93, 0x8b, 0xc6, 0x6d, 0xc4, 0xc6, 0x02, 0xf4, 0xc6, 0x71, 0xfa, 0x3f,
+	0xda, 0xd0, 0x5d, 0xaa, 0xec, 0x08, 0xfc, 0x1c, 0x73, 0xd2, 0x5f, 0x9a, 0x64, 0x9f, 0x5e, 0x96,
+	0xcf, 0xdf, 0x3a, 0xbb, 0x68, 0x30, 0xec, 0x25, 0x74, 0x52, 0x55, 0xba, 0xc0, 0x56, 0xbf, 0xa7,
+	0xdf, 0xb4, 0x03, 0x55, 0x8a, 0x0a, 0xc0, 0xc6, 0x70, 0xc3, 0x60, 0x2e, 0x23, 0x85, 0xda, 0x48,
+	0x63, 0xb1, 0xb0, 0x51, 0x26, 0xcd, 0xb4, 0x49, 0xf2, 0xc9, 0xa5, 0xc1, 0x87, 0xd2, 0x4c, 0x05,
+	0xab, 0x90, 0xc7, 0x4b, 0x62, 0x55, 0x0b, 0x77, 0xc0, 0xaf, 0x47, 0x60, 0x0c, 0x3c, 0x23, 0xbf,
+	0xa2, 0x4b, 0xc2, 0x13, 0xee, 0x3b, 0xbc, 0x03, 0x9d, 0x03, 0x55, 0xb2, 0x5b, 0xe0, 0x9b, 0xd3,
+	0x58, 0xa3, 0x71, 0x62, 0x5b, 0x34, 0x7f, 0x61, 0x08, 0x5e, 0x05, 0xf9, 0x97, 0x75, 0xff, 0x7b,
+	0x0b, 0x7a, 0xcb, 0x45, 0x3b, 0x41, 0x3d, 0x97, 0x29, 0xb2, 0x6f, 0x2d, 0xe8, 0xfd, 0xb9, 0xe4,
+	0xec, 0xd9, 0x8a, 0xd3, 0x5c, 0xf0, 0x70, 0xc2, 0xe7, 0xff, 0xed, 0xaf, 0x5f, 0xd7, 0xe0, 0x10,
+	0xee, 0x5d, 0x44, 0x38, 0x0b, 0x18, 0x5c, 0x5b, 0xda, 0x5f, 0x28, 0xf9, 0x61, 0xe3, 0x8c, 0x1a,
+	0xcd, 0xf7, 0x12, 0xdf, 0xad, 0xf5, 0xa3, 0x5f, 0x01, 0x00, 0x00, 0xff, 0xff, 0x6d, 0x4f, 0xe3,
+	0xdd, 0x42, 0x04, 0x00, 0x00,
 }
&lt;p&gt;diff --git a/sdks/go/pkg/beam/util/grpcx/dial.go b/sdks/go/pkg/beam/util/grpcx/dial.go&lt;br/&gt;
index 8467ace1ba4..8f028370cf8 100644&lt;br/&gt;
&amp;#8212; a/sdks/go/pkg/beam/util/grpcx/dial.go&lt;br/&gt;
+++ b/sdks/go/pkg/beam/util/grpcx/dial.go&lt;br/&gt;
@@ -29,7 +29,7 @@ func Dial(ctx context.Context, endpoint string, timeout time.Duration) (*grpc.Cl&lt;br/&gt;
 	ctx, cancel := context.WithTimeout(ctx, timeout)&lt;br/&gt;
 	defer cancel()&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;cc, err := grpc.DialContext(ctx, endpoint, grpc.WithInsecure(), grpc.WithBlock())&lt;br/&gt;
+	cc, err := grpc.DialContext(ctx, endpoint, grpc.WithInsecure(), grpc.WithBlock(), grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(50&amp;lt;&amp;lt;20)))&lt;br/&gt;
 	if err != nil 
{
 		return nil, fmt.Errorf(&quot;failed to dial server at %v: %v&quot;, endpoint, err)
 	}
&lt;p&gt;diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileBasedSink.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileBasedSink.java&lt;br/&gt;
index d4cb57d0f83..2e5d387c63b 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileBasedSink.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileBasedSink.java&lt;br/&gt;
@@ -28,10 +28,11 @@&lt;br/&gt;
 import com.google.common.annotations.VisibleForTesting;&lt;br/&gt;
 import com.google.common.base.MoreObjects;&lt;br/&gt;
 import com.google.common.collect.ImmutableList;&lt;br/&gt;
+import com.google.common.collect.ImmutableSet;&lt;br/&gt;
 import com.google.common.collect.Iterables;&lt;br/&gt;
 import com.google.common.collect.Lists;&lt;br/&gt;
 import com.google.common.collect.Maps;&lt;br/&gt;
-import com.google.common.collect.Ordering;&lt;br/&gt;
+import com.google.common.collect.Sets;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.io.InputStream;&lt;br/&gt;
 import java.io.OutputStream;&lt;br/&gt;
@@ -39,13 +40,14 @@&lt;br/&gt;
 import java.nio.channels.WritableByteChannel;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
+import java.util.Collection;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
-import java.util.Comparator;&lt;br/&gt;
 import java.util.HashSet;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.Objects;&lt;br/&gt;
 import java.util.Set;&lt;br/&gt;
+import java.util.UUID;&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicLong;&lt;br/&gt;
 import javax.annotation.Nullable;&lt;br/&gt;
 import org.apache.beam.sdk.annotations.Experimental;&lt;br/&gt;
@@ -72,6 +74,7 @@&lt;br/&gt;
 import org.apache.beam.sdk.transforms.display.DisplayData;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.display.HasDisplayData;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.BoundedWindow;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.windowing.GlobalWindow;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.PaneInfo;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.PaneInfo.PaneInfoCoder;&lt;br/&gt;
 import org.apache.beam.sdk.util.MimeTypes;&lt;br/&gt;
@@ -103,10 +106,9 @@&lt;br/&gt;
  *&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;In order to ensure fault-tolerance, a bundle may be executed multiple times (e.g., in the&lt;/li&gt;
	&lt;li&gt;event of failure/retry or for redundancy). However, exactly one of these executions will have its&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* result passed to the finalize method. Each call to 
{@link Writer#openWindowed}
&lt;p&gt; or &lt;/p&gt;
{@link
- * Writer#openUnwindowed}
&lt;p&gt; is passed a unique &amp;lt;i&amp;gt;bundle id&amp;lt;/i&amp;gt; when it is called by the WriteFiles&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* transform, so even redundant or retried bundles will have a unique way of identifying their&lt;/li&gt;
	&lt;li&gt;* output.&lt;br/&gt;
+ * result passed to the finalize method. Each call to 
{@link Writer#open} is passed a unique&lt;br/&gt;
+ * &amp;lt;i&amp;gt;bundle id&amp;lt;/i&amp;gt; when it is called by the WriteFiles transform, so even redundant or retried&lt;br/&gt;
+ * bundles will have a unique way of identifying their output.&lt;br/&gt;
  *&lt;br/&gt;
  * &amp;lt;p&amp;gt;The bundle id should be used to guarantee that a bundle&apos;s output is unique. This uniqueness&lt;br/&gt;
  * guarantee is important; if a bundle is to be output to a file, for example, the name of the file&lt;br/&gt;
@@ -447,8 +449,8 @@ public void populateDisplayData(DisplayData.Builder builder) {&lt;br/&gt;
    * written,&lt;br/&gt;
    *&lt;br/&gt;
    * &amp;lt;ol&amp;gt;&lt;br/&gt;
-   *   &amp;lt;li&amp;gt;{@link WriteOperation#finalize} is given a list of the temporary files containing the&lt;br/&gt;
-   *       output bundles.&lt;br/&gt;
+   *   &amp;lt;li&amp;gt;{@link WriteOperation#finalizeDestination} is given a list of the temporary files&lt;br/&gt;
+   *       containing the output bundles.&lt;br/&gt;
    *   &amp;lt;li&amp;gt;During finalize, these temporary files are copied to final output locations and named&lt;br/&gt;
    *       according to a file naming template.&lt;br/&gt;
    *   &amp;lt;li&amp;gt;Finally, any temporary files that were created during the write are removed.&lt;br/&gt;
@@ -577,17 +579,22 @@ public void setWindowedWrites(boolean windowedWrites) {&lt;br/&gt;
      * not be cleaned up. Note that {@link WriteFiles} does attempt clean up files if exceptions&lt;br/&gt;
      * are thrown, however there are still some scenarios where temporary files might be left.&lt;br/&gt;
      */&lt;br/&gt;
-    public void removeTemporaryFiles(Set&amp;lt;ResourceId&amp;gt; filenames) throws IOException {&lt;br/&gt;
+    public void removeTemporaryFiles(Collection&amp;lt;ResourceId&amp;gt; filenames) throws IOException {
       removeTemporaryFiles(filenames, !windowedWrites);
     }&lt;br/&gt;
 &lt;br/&gt;
     @Experimental(Kind.FILESYSTEM)&lt;br/&gt;
-    protected final List&amp;lt;KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt;&amp;gt; buildOutputFilenames(&lt;br/&gt;
+    protected final List&amp;lt;KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt;&amp;gt; finalizeDestination(&lt;br/&gt;
         @Nullable DestinationT dest,&lt;br/&gt;
         @Nullable BoundedWindow window,&lt;br/&gt;
         @Nullable Integer numShards,&lt;br/&gt;
-        Iterable&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; writerResults) {&lt;br/&gt;
-      for (FileResult&amp;lt;DestinationT&amp;gt; res : writerResults) {&lt;br/&gt;
+        Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; existingResults) throws Exception {&lt;br/&gt;
+      Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; completeResults =&lt;br/&gt;
+          windowedWrites&lt;br/&gt;
+              ? existingResults&lt;br/&gt;
+              : createMissingEmptyShards(dest, numShards, existingResults);&lt;br/&gt;
+&lt;br/&gt;
+      for (FileResult&amp;lt;DestinationT&amp;gt; res : completeResults) {&lt;br/&gt;
         checkArgument(&lt;br/&gt;
             Objects.equals(dest, res.getDestination()),&lt;br/&gt;
             &quot;File result has wrong destination: expected %s, got %s&quot;,&lt;br/&gt;
@@ -602,7 +609,7 @@ public void removeTemporaryFiles(Set&amp;lt;ResourceId&amp;gt; filenames) throws IOException {&lt;br/&gt;
       final int effectiveNumShards;&lt;br/&gt;
       if (numShards != null) {&lt;br/&gt;
         effectiveNumShards = numShards;&lt;br/&gt;
-        for (FileResult&amp;lt;DestinationT&amp;gt; res : writerResults) {&lt;br/&gt;
+        for (FileResult&amp;lt;DestinationT&amp;gt; res : completeResults) {&lt;br/&gt;
           checkArgument(&lt;br/&gt;
               res.getShard() != UNKNOWN_SHARDNUM,&lt;br/&gt;
               &quot;Fixed sharding into %s shards was specified, &quot;&lt;br/&gt;
@@ -611,8 +618,8 @@ public void removeTemporaryFiles(Set&amp;lt;ResourceId&amp;gt; filenames) throws IOException {
               res);
         }&lt;br/&gt;
       } else {&lt;br/&gt;
-        effectiveNumShards = Iterables.size(writerResults);&lt;br/&gt;
-        for (FileResult&amp;lt;DestinationT&amp;gt; res : writerResults) {&lt;br/&gt;
+        effectiveNumShards = Iterables.size(completeResults);&lt;br/&gt;
+        for (FileResult&amp;lt;DestinationT&amp;gt; res : completeResults) {&lt;br/&gt;
           checkArgument(&lt;br/&gt;
               res.getShard() == UNKNOWN_SHARDNUM,&lt;br/&gt;
               &quot;Runner-chosen sharding was specified, &quot;&lt;br/&gt;
@@ -623,30 +630,11 @@ public void removeTemporaryFiles(Set&amp;lt;ResourceId&amp;gt; filenames) throws IOException {&lt;br/&gt;
 &lt;br/&gt;
       List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; resultsWithShardNumbers = Lists.newArrayList();&lt;br/&gt;
       if (numShards != null) {
-        resultsWithShardNumbers = Lists.newArrayList(writerResults);
+        resultsWithShardNumbers = Lists.newArrayList(completeResults);
       } else {&lt;br/&gt;
-        checkState(&lt;br/&gt;
-            !windowedWrites,&lt;br/&gt;
-            &quot;When doing windowed writes, shards should have been assigned when writing&quot;);&lt;br/&gt;
-        // Sort files for idempotence. Sort by temporary filename.&lt;br/&gt;
-        // Note that this codepath should not be used when processing triggered windows. In the&lt;br/&gt;
-        // case of triggers, the list of FileResult objects in the Finalize iterable is not&lt;br/&gt;
-        // deterministic, and might change over retries. This breaks the assumption below that&lt;br/&gt;
-        // sorting the FileResult objects provides idempotency.&lt;br/&gt;
-        List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; sortedByTempFilename =&lt;br/&gt;
-            Ordering.from(&lt;br/&gt;
-                    new Comparator&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;() {&lt;br/&gt;
-                      @Override&lt;br/&gt;
-                      public int compare(&lt;br/&gt;
-                          FileResult&amp;lt;DestinationT&amp;gt; first, FileResult&amp;lt;DestinationT&amp;gt; second) {
-                        String firstFilename = first.getTempFilename().toString();
-                        String secondFilename = second.getTempFilename().toString();
-                        return firstFilename.compareTo(secondFilename);
-                      }&lt;br/&gt;
-                    })&lt;br/&gt;
-                .sortedCopy(writerResults);&lt;br/&gt;
-        for (int i = 0; i &amp;lt; sortedByTempFilename.size(); i++) {&lt;br/&gt;
-          resultsWithShardNumbers.add(sortedByTempFilename.get&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/information.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;.withShard&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/information.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;);&lt;br/&gt;
+        int i = 0;&lt;br/&gt;
+        for (FileResult&amp;lt;DestinationT&amp;gt; res : completeResults) {
+          resultsWithShardNumbers.add(res.withShard(i++));
         }&lt;br/&gt;
       }&lt;br/&gt;
 &lt;br/&gt;
@@ -655,6 +643,7 @@ public int compare(&lt;br/&gt;
         checkArgument(&lt;br/&gt;
             result.getShard() != UNKNOWN_SHARDNUM, &quot;Should have set shard number on %s&quot;, result);&lt;br/&gt;
         ResourceId finalFilename = result.getDestinationFile(&lt;br/&gt;
+            windowedWrites,&lt;br/&gt;
             getSink().getDynamicDestinations(),&lt;br/&gt;
             effectiveNumShards,&lt;br/&gt;
             getSink().getWritableByteChannelFactory());&lt;br/&gt;
@@ -671,10 +660,75 @@ public int compare(&lt;br/&gt;
       return outputFilenames;&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
+    private Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; createMissingEmptyShards(&lt;br/&gt;
+        @Nullable DestinationT dest,&lt;br/&gt;
+        @Nullable Integer numShards,&lt;br/&gt;
+        Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; existingResults)&lt;br/&gt;
+        throws Exception {&lt;br/&gt;
+      Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; completeResults;&lt;br/&gt;
+      LOG.info(&quot;Finalizing for destination {} num shards {}.&quot;, dest, existingResults.size());&lt;br/&gt;
+      if (numShards != null) {
+        checkArgument(
+            existingResults.size() &amp;lt;= numShards,
+            &quot;Fixed sharding into %s shards was specified, but got %s file results&quot;,
+            numShards,
+            existingResults.size());
+      }&lt;br/&gt;
+      // We must always output at least 1 shard, and honor user-specified numShards&lt;br/&gt;
+      // if set.&lt;br/&gt;
+      Set&amp;lt;Integer&amp;gt; missingShardNums;&lt;br/&gt;
+      if (numShards == null) {
+        missingShardNums =
+            existingResults.isEmpty()
+                ? ImmutableSet.of(UNKNOWN_SHARDNUM)
+                : ImmutableSet.&amp;lt;Integer&amp;gt;of();
+      } else {&lt;br/&gt;
+        missingShardNums = Sets.newHashSet();&lt;br/&gt;
+        for (int i = 0; i &amp;lt; numShards; ++i) {
+          missingShardNums.add(i);
+        }&lt;br/&gt;
+        for (FileResult&amp;lt;DestinationT&amp;gt; res : existingResults) {
+          checkArgument(
+              res.getShard() != UNKNOWN_SHARDNUM,
+              &quot;Fixed sharding into %s shards was specified, &quot;
+                  + &quot;but file result %s does not specify a shard&quot;,
+              numShards,
+              res);
+          missingShardNums.remove(res.getShard());
+        }&lt;br/&gt;
+      }&lt;br/&gt;
+      completeResults = Lists.newArrayList(existingResults);&lt;br/&gt;
+      if (!missingShardNums.isEmpty()) {&lt;br/&gt;
+        LOG.info(&lt;br/&gt;
+            &quot;Creating {} empty output shards in addition to {} written for destination {}.&quot;,&lt;br/&gt;
+            missingShardNums.size(),&lt;br/&gt;
+            existingResults.size(),&lt;br/&gt;
+            dest);&lt;br/&gt;
+        for (int shard : missingShardNums) {&lt;br/&gt;
+          String uuid = UUID.randomUUID().toString();&lt;br/&gt;
+          LOG.info(&quot;Opening empty writer {} for destination {}&quot;, uuid, dest);&lt;br/&gt;
+          Writer&amp;lt;DestinationT, ?&amp;gt; writer = createWriter();&lt;br/&gt;
+          writer.setDestination(dest);&lt;br/&gt;
+          // Currently this code path is only called in the unwindowed case.&lt;br/&gt;
+          writer.open(uuid);&lt;br/&gt;
+          writer.close();&lt;br/&gt;
+          completeResults.add(&lt;br/&gt;
+              new FileResult&amp;lt;&amp;gt;(&lt;br/&gt;
+                  writer.getOutputFile(),&lt;br/&gt;
+                  shard,&lt;br/&gt;
+                  GlobalWindow.INSTANCE,&lt;br/&gt;
+                  PaneInfo.ON_TIME_AND_ONLY_FIRING,&lt;br/&gt;
+                  dest));&lt;br/&gt;
+        }&lt;br/&gt;
+        LOG.debug(&quot;Done creating extra shards for {}.&quot;, dest);&lt;br/&gt;
+      }&lt;br/&gt;
+      return completeResults;&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
     /**&lt;br/&gt;
      * Copy temporary files to final output filenames using the file naming template.&lt;br/&gt;
      *&lt;br/&gt;
-     * &amp;lt;p&amp;gt;Can be called from subclasses that override {@link WriteOperation#finalize}.&lt;br/&gt;
+     * &amp;lt;p&amp;gt;Can be called from subclasses that override {@link WriteOperation#finalizeDestination}.&lt;br/&gt;
      *&lt;br/&gt;
      * &amp;lt;p&amp;gt;Files will be named according to the {@link FilenamePolicy}. The order of the output files&lt;br/&gt;
      * will be the same as the sorted order of the input filenames. In other words (when using&lt;br/&gt;
@@ -685,40 +739,38 @@ public int compare(&lt;br/&gt;
      */&lt;br/&gt;
     @VisibleForTesting&lt;br/&gt;
     @Experimental(Kind.FILESYSTEM)&lt;br/&gt;
-    final void copyToOutputFiles(&lt;br/&gt;
+    final void moveToOutputFiles(&lt;br/&gt;
         List&amp;lt;KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt;&amp;gt; resultsToFinalFilenames) throws IOException {&lt;br/&gt;
       int numFiles = resultsToFinalFilenames.size();&lt;br/&gt;
-      if (numFiles &amp;gt; 0) {&lt;br/&gt;
-        LOG.debug(&quot;Copying {} files.&quot;, numFiles);&lt;br/&gt;
-        List&amp;lt;ResourceId&amp;gt; srcFiles = new ArrayList&amp;lt;&amp;gt;(resultsToFinalFilenames.size());&lt;br/&gt;
-        List&amp;lt;ResourceId&amp;gt; dstFiles = new ArrayList&amp;lt;&amp;gt;(resultsToFinalFilenames.size());&lt;br/&gt;
-        for (KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt; entry : resultsToFinalFilenames) {&lt;br/&gt;
-          srcFiles.add(entry.getKey().getTempFilename());&lt;br/&gt;
-          dstFiles.add(entry.getValue());&lt;br/&gt;
-          LOG.info(&lt;br/&gt;
-              &quot;Will copy temporary file {} to final location {}&quot;,&lt;br/&gt;
-              entry.getKey().getTempFilename(),&lt;br/&gt;
-              entry.getValue());&lt;br/&gt;
-        }&lt;br/&gt;
-        // During a failure case, files may have been deleted in an earlier step. Thus&lt;br/&gt;
-        // we ignore missing files here.&lt;br/&gt;
-        FileSystems.copy(srcFiles, dstFiles, StandardMoveOptions.IGNORE_MISSING_FILES);&lt;br/&gt;
-      } else {&lt;br/&gt;
-        LOG.info(&quot;No output files to write.&quot;);&lt;br/&gt;
+      LOG.debug(&quot;Copying {} files.&quot;, numFiles);&lt;br/&gt;
+      List&amp;lt;ResourceId&amp;gt; srcFiles = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
+      List&amp;lt;ResourceId&amp;gt; dstFiles = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
+      for (KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt; entry : resultsToFinalFilenames) {&lt;br/&gt;
+        srcFiles.add(entry.getKey().getTempFilename());&lt;br/&gt;
+        dstFiles.add(entry.getValue());&lt;br/&gt;
+        LOG.info(&lt;br/&gt;
+            &quot;Will copy temporary file {} to final location {}&quot;,&lt;br/&gt;
+            entry.getKey().getTempFilename(),&lt;br/&gt;
+            entry.getValue());&lt;br/&gt;
       }&lt;br/&gt;
+      // During a failure case, files may have been deleted in an earlier step. Thus&lt;br/&gt;
+      // we ignore missing files here.&lt;br/&gt;
+      FileSystems.copy(srcFiles, dstFiles, StandardMoveOptions.IGNORE_MISSING_FILES);&lt;br/&gt;
+      removeTemporaryFiles(srcFiles);&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
      * Removes temporary output files. Uses the temporary directory to find files to remove.&lt;br/&gt;
      *&lt;br/&gt;
-     * &amp;lt;p&amp;gt;Can be called from subclasses that override {@link WriteOperation#finalize}.&lt;br/&gt;
+     * &amp;lt;p&amp;gt;Can be called from subclasses that override {@link WriteOperation#finalizeDestination}.&lt;br/&gt;
      * &amp;lt;b&amp;gt;Note:&amp;lt;/b&amp;gt;If finalize is overridden and does &amp;lt;b&amp;gt;not&amp;lt;/b&amp;gt; rename or otherwise finalize&lt;br/&gt;
      * temporary files, this method will remove them.&lt;br/&gt;
      */&lt;br/&gt;
     @VisibleForTesting&lt;br/&gt;
     @Experimental(Kind.FILESYSTEM)&lt;br/&gt;
     final void removeTemporaryFiles(&lt;br/&gt;
-        Set&amp;lt;ResourceId&amp;gt; knownFiles, boolean shouldRemoveTemporaryDirectory) throws IOException {&lt;br/&gt;
+        Collection&amp;lt;ResourceId&amp;gt; knownFiles, boolean shouldRemoveTemporaryDirectory)&lt;br/&gt;
+        throws IOException {&lt;br/&gt;
       ResourceId tempDir = tempDirectory.get();&lt;br/&gt;
       LOG.debug(&quot;Removing temporary bundle output files in {}.&quot;, tempDir);&lt;br/&gt;
 &lt;br/&gt;
@@ -805,9 +857,6 @@ protected final WritableByteChannelFactory getWritableByteChannelFactory() {&lt;br/&gt;
     /** Unique id for this output bundle. */&lt;br/&gt;
     private @Nullable String id;&lt;br/&gt;
 &lt;br/&gt;
-    private @Nullable BoundedWindow window;&lt;br/&gt;
-    private @Nullable PaneInfo paneInfo;&lt;br/&gt;
-    private int shard = -1;&lt;br/&gt;
     private @Nullable DestinationT destination;&lt;br/&gt;
 &lt;br/&gt;
     /** The output file for this bundle. May be null if opening failed. */&lt;br/&gt;
@@ -857,65 +906,14 @@ protected void writeFooter() throws Exception {}&lt;br/&gt;
     protected void finishWrite() throws Exception {}&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
-     * Performs bundle initialization. For example, creates a temporary file for writing or&lt;br/&gt;
-     * initializes any state that will be used across calls to {@link Writer#write}.&lt;br/&gt;
+     * Opens a uniquely named temporary file and initializes the writer using {@link #prepareWrite}.&lt;br/&gt;
      *&lt;br/&gt;
      * &amp;lt;p&amp;gt;The unique id that is given to open should be used to ensure that the writer&apos;s output does&lt;br/&gt;
      * not interfere with the output of other Writers, as a bundle may be executed many times for&lt;br/&gt;
      * fault tolerance.&lt;br/&gt;
-     *&lt;br/&gt;
-     * &amp;lt;p&amp;gt;The window and paneInfo arguments are populated when windowed writes are requested. shard&lt;br/&gt;
-     * id populated for the case of static sharding. In cases where the runner is dynamically&lt;br/&gt;
-     * picking sharding, shard might be set to -1.&lt;br/&gt;
      */&lt;br/&gt;
-    public final void openWindowed(&lt;br/&gt;
-        String uId, BoundedWindow window, PaneInfo paneInfo, int shard, DestinationT destination)&lt;br/&gt;
-        throws Exception {&lt;br/&gt;
-      if (!getWriteOperation().windowedWrites) {
-        throw new IllegalStateException(&quot;openWindowed called a non-windowed sink.&quot;);
-      }&lt;br/&gt;
-      open(uId, window, paneInfo, shard, destination);&lt;br/&gt;
-    }&lt;br/&gt;
-&lt;br/&gt;
-    /** Called for each value in the bundle. */&lt;br/&gt;
-    public abstract void write(OutputT value) throws Exception;&lt;br/&gt;
-&lt;br/&gt;
-    /**&lt;br/&gt;
-     * Similar to {@link #openWindowed} however for the case where unwindowed writes were requested.&lt;br/&gt;
-     */&lt;br/&gt;
-    public final void openUnwindowed(String uId, int shard, DestinationT destination)&lt;br/&gt;
-        throws Exception {&lt;br/&gt;
-      if (getWriteOperation().windowedWrites) {
-        throw new IllegalStateException(&quot;openUnwindowed called a windowed sink.&quot;);
-      }&lt;br/&gt;
-      open(uId, null, null, shard, destination);&lt;br/&gt;
-    }&lt;br/&gt;
-&lt;br/&gt;
-    // Helper function to close a channel, on exception cases.&lt;br/&gt;
-    // Always throws prior exception, with any new closing exception suppressed.&lt;br/&gt;
-    private static void closeChannelAndThrow(&lt;br/&gt;
-        WritableByteChannel channel, ResourceId filename, Exception prior) throws Exception {&lt;br/&gt;
-      try {
-        channel.close();
-      } catch (Exception e) {&lt;br/&gt;
-        LOG.error(&quot;Closing channel for {} failed.&quot;, filename, e);&lt;br/&gt;
-        prior.addSuppressed(e);&lt;br/&gt;
-        throw prior;&lt;br/&gt;
-      }&lt;br/&gt;
-    }&lt;br/&gt;
-&lt;br/&gt;
-    private void open(&lt;br/&gt;
-        String uId,&lt;br/&gt;
-        @Nullable BoundedWindow window,&lt;br/&gt;
-        @Nullable PaneInfo paneInfo,&lt;br/&gt;
-        int shard,&lt;br/&gt;
-        DestinationT destination)&lt;br/&gt;
-        throws Exception {&lt;br/&gt;
+    public final void open(String uId) throws Exception {&lt;br/&gt;
       this.id = uId;&lt;br/&gt;
-      this.window = window;&lt;br/&gt;
-      this.paneInfo = paneInfo;&lt;br/&gt;
-      this.shard = shard;&lt;br/&gt;
-      this.destination = destination;&lt;br/&gt;
       ResourceId tempDirectory = getWriteOperation().tempDirectory.get();&lt;br/&gt;
       outputFile = tempDirectory.resolve(id, StandardResolveOptions.RESOLVE_FILE);&lt;br/&gt;
       verifyNotNull(&lt;br/&gt;
@@ -925,15 +923,6 @@ private void open(&lt;br/&gt;
           getWriteOperation().getSink().writableByteChannelFactory;&lt;br/&gt;
       // The factory may force a MIME type or it may return null, indicating to use the sink&apos;s MIME.&lt;br/&gt;
       String channelMimeType = firstNonNull(factory.getMimeType(), mimeType);&lt;br/&gt;
-      LOG.info(&lt;br/&gt;
-          &quot;Opening temporary file {} with MIME type {} &quot;&lt;br/&gt;
-              + &quot;to write destination {} shard {} window {} pane {}&quot;,&lt;br/&gt;
-          outputFile,&lt;br/&gt;
-          channelMimeType,&lt;br/&gt;
-          destination,&lt;br/&gt;
-          shard,&lt;br/&gt;
-          window,&lt;br/&gt;
-          paneInfo);&lt;br/&gt;
       WritableByteChannel tempChannel = FileSystems.create(outputFile, channelMimeType);&lt;br/&gt;
       try {&lt;br/&gt;
         channel = factory.create(tempChannel);&lt;br/&gt;
@@ -960,6 +949,26 @@ private void open(&lt;br/&gt;
       LOG.debug(&quot;Starting write of bundle {} to {}.&quot;, this.id, outputFile);&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
+    /** Called for each value in the bundle. */&lt;br/&gt;
+    public abstract void write(OutputT value) throws Exception;&lt;br/&gt;
+&lt;br/&gt;
+    public ResourceId getOutputFile() {
+      return outputFile;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    // Helper function to close a channel, on exception cases.&lt;br/&gt;
+    // Always throws prior exception, with any new closing exception suppressed.&lt;br/&gt;
+    private static void closeChannelAndThrow(&lt;br/&gt;
+        WritableByteChannel channel, ResourceId filename, Exception prior) throws Exception {&lt;br/&gt;
+      try {
+        channel.close();
+      } catch (Exception e) {&lt;br/&gt;
+        LOG.error(&quot;Closing channel for {} failed.&quot;, filename, e);&lt;br/&gt;
+        prior.addSuppressed(e);&lt;br/&gt;
+        throw prior;&lt;br/&gt;
+      }&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
     public final void cleanup() throws Exception {&lt;br/&gt;
       if (outputFile != null) {&lt;br/&gt;
         LOG.info(&quot;Deleting temporary file {}&quot;, outputFile);&lt;br/&gt;
@@ -970,22 +979,19 @@ public final void cleanup() throws Exception {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /** Closes the channel and returns the bundle result. */&lt;br/&gt;
-    public final FileResult&amp;lt;DestinationT&amp;gt; close() throws Exception {&lt;br/&gt;
+    public final void close() throws Exception {&lt;br/&gt;
       checkState(outputFile != null, &quot;FileResult.close cannot be called with a null outputFile&quot;);&lt;br/&gt;
+      LOG.debug(&quot;Closing {}&quot;, outputFile);&lt;br/&gt;
 &lt;br/&gt;
-      LOG.debug(&quot;Writing footer to {}.&quot;, outputFile);&lt;br/&gt;
       try {
         writeFooter();
       } catch (Exception e) {&lt;br/&gt;
-        LOG.error(&quot;Writing footer to {} failed, closing channel.&quot;, outputFile, e);&lt;br/&gt;
         closeChannelAndThrow(channel, outputFile, e);&lt;br/&gt;
       }&lt;br/&gt;
 &lt;br/&gt;
-      LOG.debug(&quot;Finishing write to {}.&quot;, outputFile);&lt;br/&gt;
       try {
         finishWrite();
       } catch (Exception e) {&lt;br/&gt;
-        LOG.error(&quot;Finishing write to {} failed, closing channel.&quot;, outputFile, e);&lt;br/&gt;
         closeChannelAndThrow(channel, outputFile, e);&lt;br/&gt;
       }&lt;br/&gt;
 &lt;br/&gt;
@@ -1001,11 +1007,7 @@ public final void cleanup() throws Exception {&lt;br/&gt;
       } catch (Exception e) {
         throw new IOException(String.format(&quot;Failed closing channel to %s&quot;, outputFile), e);
       }&lt;br/&gt;
-&lt;br/&gt;
-      FileResult&amp;lt;DestinationT&amp;gt; result =&lt;br/&gt;
-          new FileResult&amp;lt;&amp;gt;(outputFile, shard, window, paneInfo, destination);&lt;br/&gt;
       LOG.info(&quot;Successfully wrote temporary file {}&quot;, outputFile);&lt;br/&gt;
-      return result;&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     /** Return the WriteOperation that this Writer belongs to. */&lt;br/&gt;
@@ -1013,6 +1015,10 @@ public final void cleanup() throws Exception {
       return writeOperation;
     }&lt;br/&gt;
 &lt;br/&gt;
+    void setDestination(DestinationT destination) {
+      this.destination = destination;
+    }&lt;br/&gt;
+&lt;br/&gt;
     /** Return the user destination object for this writer. */&lt;br/&gt;
     public DestinationT getDestination() {&lt;br/&gt;
       return destination;&lt;br/&gt;
@@ -1026,7 +1032,7 @@ public DestinationT getDestination() {&lt;br/&gt;
   public static final class FileResult&amp;lt;DestinationT&amp;gt; {&lt;br/&gt;
     private final ResourceId tempFilename;&lt;br/&gt;
     private final int shard;&lt;br/&gt;
-    private final @Nullable BoundedWindow window;&lt;br/&gt;
+    private final BoundedWindow window;&lt;br/&gt;
     private final PaneInfo paneInfo;&lt;br/&gt;
     private final DestinationT destination;&lt;br/&gt;
 &lt;br/&gt;
@@ -1034,9 +1040,11 @@ public DestinationT getDestination() {&lt;br/&gt;
     public FileResult(&lt;br/&gt;
         ResourceId tempFilename,&lt;br/&gt;
         int shard,&lt;br/&gt;
-        @Nullable BoundedWindow window,&lt;br/&gt;
+        BoundedWindow window,&lt;br/&gt;
         PaneInfo paneInfo,&lt;br/&gt;
         DestinationT destination) {&lt;br/&gt;
+      checkArgument(window != null, &quot;window can not be null&quot;);&lt;br/&gt;
+      checkArgument(paneInfo != null, &quot;paneInfo can not be null&quot;);&lt;br/&gt;
       this.tempFilename = tempFilename;&lt;br/&gt;
       this.shard = shard;&lt;br/&gt;
       this.window = window;&lt;br/&gt;
@@ -1071,13 +1079,14 @@ public DestinationT getDestination() {&lt;br/&gt;
 &lt;br/&gt;
     @Experimental(Kind.FILESYSTEM)&lt;br/&gt;
     public ResourceId getDestinationFile(&lt;br/&gt;
+        boolean windowedWrites,&lt;br/&gt;
         DynamicDestinations&amp;lt;?, DestinationT, ?&amp;gt; dynamicDestinations,&lt;br/&gt;
         int numShards,&lt;br/&gt;
         OutputFileHints outputFileHints) {&lt;br/&gt;
       checkArgument(getShard() != UNKNOWN_SHARDNUM);&lt;br/&gt;
       checkArgument(numShards &amp;gt; 0);&lt;br/&gt;
       FilenamePolicy policy = dynamicDestinations.getFilenamePolicy(destination);&lt;br/&gt;
-      if (getWindow() != null) {&lt;br/&gt;
+      if (windowedWrites) {
         return policy.windowedFilename(
             getShard(), numShards, getWindow(), getPaneInfo(), outputFileHints);
       } else {&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileIO.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileIO.java&lt;br/&gt;
index a244c070129..4e7124af8a5 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileIO.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileIO.java&lt;br/&gt;
@@ -33,13 +33,17 @@&lt;br/&gt;
 import org.apache.beam.sdk.io.fs.EmptyMatchTreatment;&lt;br/&gt;
 import org.apache.beam.sdk.io.fs.MatchResult;&lt;br/&gt;
 import org.apache.beam.sdk.options.ValueProvider;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Contextful;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Create;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.DoFn;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.PTransform;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.ParDo;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Requirements;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Reshuffle;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.SerializableFunction;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Values;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Watch;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Watch.Growth.PollFn;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Watch.Growth.TerminationCondition;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.display.DisplayData;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.display.HasDisplayData;&lt;br/&gt;
@@ -69,6 +73,11 @@&lt;br/&gt;
    * &amp;lt;p&amp;gt;By default, a filepattern matching no resources is treated according to {@link
    * EmptyMatchTreatment#DISALLOW}. To configure this behavior, use {@link
    * Match#withEmptyMatchTreatment}.&lt;br/&gt;
+   *&lt;br/&gt;
+   * &amp;lt;p&amp;gt;Returned {@link MatchResult.Metadata} are deduplicated by filename. For example, if this&lt;br/&gt;
+   * transform observes a file with the same name several times with different metadata (e.g.&lt;br/&gt;
+   * because the file is growing), it will emit the metadata the first time this file is observed,&lt;br/&gt;
+   * and will ignore future changes to this file.&lt;br/&gt;
    */&lt;br/&gt;
   public static Match match() {
     return new AutoValue_FileIO_Match.Builder()
@@ -317,13 +326,17 @@ public MatchAll continuously(
             &quot;Match filepatterns&quot;,
             ParDo.of(new MatchFn(getConfiguration().getEmptyMatchTreatment())));
       } else {
-        res = input
-            .apply(
-                &quot;Continuously match filepatterns&quot;,
-                Watch.growthOf(new MatchPollFn())
-                    .withPollInterval(getConfiguration().getWatchInterval())
-                    .withTerminationPerInput(getConfiguration().getWatchTerminationCondition()))
-            .apply(Values.&amp;lt;MatchResult.Metadata&amp;gt;create());
+        res =
+            input
+                .apply(
+                    &quot;Continuously match filepatterns&quot;,
+                    Watch.growthOf(
+                            Contextful.&amp;lt;PollFn&amp;lt;String, MatchResult.Metadata&amp;gt;&amp;gt;of(
+                                new MatchPollFn(), Requirements.empty()),
+                            new ExtractFilenameFn())
+                        .withPollInterval(getConfiguration().getWatchInterval())
+                        .withTerminationPerInput(getConfiguration().getWatchTerminationCondition()))
+                .apply(Values.&amp;lt;MatchResult.Metadata&amp;gt;create());
       }&lt;br/&gt;
       return res.apply(Reshuffle.&amp;lt;MatchResult.Metadata&amp;gt;viaRandomKey());&lt;br/&gt;
     }&lt;br/&gt;
@@ -346,7 +359,7 @@ public void process(ProcessContext c) throws Exception {&lt;br/&gt;
       }&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
-    private static class MatchPollFn extends Watch.Growth.PollFn&amp;lt;String, MatchResult.Metadata&amp;gt; {&lt;br/&gt;
+    private static class MatchPollFn extends PollFn&amp;lt;String, MatchResult.Metadata&amp;gt; {&lt;br/&gt;
       @Override&lt;br/&gt;
       public Watch.Growth.PollResult&amp;lt;MatchResult.Metadata&amp;gt; apply(String element, Context c)&lt;br/&gt;
           throws Exception {&lt;br/&gt;
@@ -354,6 +367,14 @@ public void process(ProcessContext c) throws Exception {
             Instant.now(), FileSystems.match(element, EmptyMatchTreatment.ALLOW).metadata());
       }&lt;br/&gt;
     }&lt;br/&gt;
+&lt;br/&gt;
+    private static class ExtractFilenameFn&lt;br/&gt;
+        implements SerializableFunction&amp;lt;MatchResult.Metadata, String&amp;gt; {&lt;br/&gt;
+      @Override&lt;br/&gt;
+      public String apply(MatchResult.Metadata input) {
+        return input.resourceId().toString();
+      }&lt;br/&gt;
+    }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   /** Implementation of {@link #readMatches}. */&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/io/WriteFiles.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/io/WriteFiles.java&lt;br/&gt;
index 8328d7b2fe8..499a1940020 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/main/java/org/apache/beam/sdk/io/WriteFiles.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/io/WriteFiles.java&lt;br/&gt;
@@ -20,36 +20,33 @@&lt;br/&gt;
 &lt;br/&gt;
 import static com.google.common.base.Preconditions.checkArgument;&lt;br/&gt;
 import static com.google.common.base.Preconditions.checkNotNull;&lt;br/&gt;
-import static com.google.common.base.Preconditions.checkState;&lt;br/&gt;
 &lt;br/&gt;
+import com.google.auto.value.AutoValue;&lt;br/&gt;
 import com.google.common.base.Objects;&lt;br/&gt;
 import com.google.common.collect.ArrayListMultimap;&lt;br/&gt;
 import com.google.common.collect.ImmutableList;&lt;br/&gt;
-import com.google.common.collect.ImmutableSet;&lt;br/&gt;
 import com.google.common.collect.Lists;&lt;br/&gt;
 import com.google.common.collect.Maps;&lt;br/&gt;
 import com.google.common.collect.Multimap;&lt;br/&gt;
-import com.google.common.collect.Sets;&lt;br/&gt;
 import com.google.common.hash.Hashing;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
-import java.util.Collections;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
-import java.util.Set;&lt;br/&gt;
 import java.util.UUID;&lt;br/&gt;
 import java.util.concurrent.ThreadLocalRandom;&lt;br/&gt;
 import javax.annotation.Nullable;&lt;br/&gt;
-import org.apache.beam.sdk.Pipeline;&lt;br/&gt;
 import org.apache.beam.sdk.annotations.Experimental;&lt;br/&gt;
+import org.apache.beam.sdk.annotations.Internal;&lt;br/&gt;
 import org.apache.beam.sdk.coders.CannotProvideCoderException;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder.NonDeterministicException;&lt;br/&gt;
 import org.apache.beam.sdk.coders.KvCoder;&lt;br/&gt;
+import org.apache.beam.sdk.coders.ListCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.ShardedKeyCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.StringUtf8Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.VarIntCoder;&lt;br/&gt;
-import org.apache.beam.sdk.coders.VoidCoder;&lt;br/&gt;
+import org.apache.beam.sdk.io.FileBasedSink.DynamicDestinations;&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink.FileResult;&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink.FileResultCoder;&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink.WriteOperation;&lt;br/&gt;
@@ -58,12 +55,12 @@&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.options.ValueProvider;&lt;br/&gt;
 import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;&lt;br/&gt;
-import org.apache.beam.sdk.transforms.Create;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.DoFn;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Flatten;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.GroupByKey;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.PTransform;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.ParDo;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Reify;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Reshuffle;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Values;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.View;&lt;br/&gt;
@@ -71,6 +68,7 @@&lt;br/&gt;
 import org.apache.beam.sdk.transforms.display.DisplayData;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.BoundedWindow;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.DefaultTrigger;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.windowing.GlobalWindow;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.GlobalWindows;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.PaneInfo;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.Window;&lt;br/&gt;
@@ -111,10 +109,15 @@&lt;br/&gt;
  * &amp;lt;pre&amp;gt;{@code p.apply(WriteFiles.to(new MySink(...)).withNumShards(3));}&amp;lt;/pre&amp;gt;&lt;br/&gt;
  */&lt;br/&gt;
 @Experimental(Experimental.Kind.SOURCE_SINK)&lt;br/&gt;
-public class WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt;&lt;br/&gt;
+@AutoValue&lt;br/&gt;
+public abstract class WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt;&lt;br/&gt;
     extends PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, WriteFilesResult&amp;lt;DestinationT&amp;gt;&amp;gt; {&lt;br/&gt;
   private static final Logger LOG = LoggerFactory.getLogger(WriteFiles.class);&lt;br/&gt;
 &lt;br/&gt;
+  /** For internal use by runners. */&lt;br/&gt;
+  @Internal&lt;br/&gt;
+  public static final Class&amp;lt;? extends WriteFiles&amp;gt; CONCRETE_CLASS = AutoValue_WriteFiles.class;&lt;br/&gt;
+&lt;br/&gt;
   // The maximum number of file writers to keep open in a single bundle at a time, since file&lt;br/&gt;
   // writers default to 64mb buffers. This comes into play when writing per-window files.&lt;br/&gt;
   // The first 20 files from a single WriteFiles transform will write files inline in the&lt;br/&gt;
@@ -128,19 +131,7 @@&lt;br/&gt;
   private static final int SPILLED_RECORD_SHARDING_FACTOR = 10;&lt;br/&gt;
 &lt;br/&gt;
   static final int UNKNOWN_SHARDNUM = -1;&lt;br/&gt;
-  private FileBasedSink&amp;lt;UserT, DestinationT, OutputT&amp;gt; sink;&lt;br/&gt;
   private @Nullable WriteOperation&amp;lt;DestinationT, OutputT&amp;gt; writeOperation;&lt;br/&gt;
-  // This allows the number of shards to be dynamically computed based on the input&lt;br/&gt;
-  // PCollection.&lt;br/&gt;
-  private final @Nullable PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, PCollectionView&amp;lt;Integer&amp;gt;&amp;gt; computeNumShards;&lt;br/&gt;
-  // We don&apos;t use a side input for static sharding, as we want this value to be updatable&lt;br/&gt;
-  // when a pipeline is updated.&lt;br/&gt;
-  private final @Nullable ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider;&lt;br/&gt;
-  private final boolean windowedWrites;&lt;br/&gt;
-  private int maxNumWritersPerBundle;&lt;br/&gt;
-  // This is the set of side inputs used by this transform. This is usually populated by the users&apos;s&lt;br/&gt;
-  // DynamicDestinations object.&lt;br/&gt;
-  private final List&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt; sideInputs;&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
    * Creates a {@link WriteFiles} transform that writes to the given {@link FileBasedSink}, letting&lt;br/&gt;
@@ -149,98 +140,59 @@&lt;br/&gt;
   public static &amp;lt;UserT, DestinationT, OutputT&amp;gt; WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt; to(&lt;br/&gt;
       FileBasedSink&amp;lt;UserT, DestinationT, OutputT&amp;gt; sink) {
     checkArgument(sink != null, &quot;sink can not be null&quot;);
-    return new WriteFiles&amp;lt;&amp;gt;(
-        sink,
-        null /* runner-determined sharding */,
-        null,
-        false,
-        DEFAULT_MAX_NUM_WRITERS_PER_BUNDLE,
-        sink.getDynamicDestinations().getSideInputs());
+    return new AutoValue_WriteFiles.Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt;()
+        .setSink(sink)
+        .setComputeNumShards(null)
+        .setNumShardsProvider(null)
+        .setWindowedWrites(false)
+        .setMaxNumWritersPerBundle(DEFAULT_MAX_NUM_WRITERS_PER_BUNDLE)
+        .setSideInputs(sink.getDynamicDestinations().getSideInputs())
+        .build();
   }&lt;br/&gt;
 &lt;br/&gt;
-  private WriteFiles(&lt;br/&gt;
-      FileBasedSink&amp;lt;UserT, DestinationT, OutputT&amp;gt; sink,&lt;br/&gt;
-      @Nullable PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, PCollectionView&amp;lt;Integer&amp;gt;&amp;gt; computeNumShards,&lt;br/&gt;
-      @Nullable ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider,&lt;br/&gt;
-      boolean windowedWrites,&lt;br/&gt;
-      int maxNumWritersPerBundle,&lt;br/&gt;
-      List&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt; sideInputs) {
-    this.sink = sink;
-    this.computeNumShards = computeNumShards;
-    this.numShardsProvider = numShardsProvider;
-    this.windowedWrites = windowedWrites;
-    this.maxNumWritersPerBundle = maxNumWritersPerBundle;
-    this.sideInputs = sideInputs;
-  }&lt;br/&gt;
+  public abstract FileBasedSink&amp;lt;UserT, DestinationT, OutputT&amp;gt; getSink();&lt;br/&gt;
 &lt;br/&gt;
-  @Override&lt;br/&gt;
-  public Map&amp;lt;TupleTag&amp;lt;?&amp;gt;, PValue&amp;gt; getAdditionalInputs() {
-    return PCollectionViews.toAdditionalInputs(sideInputs);
-  }&lt;br/&gt;
+  @Nullable&lt;br/&gt;
+  public abstract PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, PCollectionView&amp;lt;Integer&amp;gt;&amp;gt; getComputeNumShards();&lt;br/&gt;
 &lt;br/&gt;
-  @Override&lt;br/&gt;
-  public WriteFilesResult&amp;lt;DestinationT&amp;gt; expand(PCollection&amp;lt;UserT&amp;gt; input) {&lt;br/&gt;
-    if (input.isBounded() == IsBounded.UNBOUNDED) {
-      checkArgument(windowedWrites,
-          &quot;Must use windowed writes when applying %s to an unbounded PCollection&quot;,
-          WriteFiles.class.getSimpleName());
-    }&lt;br/&gt;
-    if (windowedWrites) {
-      // The reason for this is https://issues.apache.org/jira/browse/BEAM-1438
-      // and similar behavior in other runners.
-      checkArgument(
-          computeNumShards != null || numShardsProvider != null,
-          &quot;When using windowed writes, must specify number of output shards explicitly&quot;,
-          WriteFiles.class.getSimpleName());
-    }&lt;br/&gt;
-    this.writeOperation = sink.createWriteOperation();&lt;br/&gt;
-    this.writeOperation.setWindowedWrites(windowedWrites);&lt;br/&gt;
-    return createWrite(input);&lt;br/&gt;
-  }&lt;br/&gt;
+  // We don&apos;t use a side input for static sharding, as we want this value to be updatable&lt;br/&gt;
+  // when a pipeline is updated.&lt;br/&gt;
+  @Nullable&lt;br/&gt;
+  public abstract ValueProvider&amp;lt;Integer&amp;gt; getNumShardsProvider();&lt;br/&gt;
 &lt;br/&gt;
-  @Override&lt;br/&gt;
-  public void validate(PipelineOptions options) {
-    sink.validate(options);
-  }&lt;br/&gt;
+  public abstract boolean getWindowedWrites();&lt;br/&gt;
 &lt;br/&gt;
-  @Override&lt;br/&gt;
-  public void populateDisplayData(DisplayData.Builder builder) {&lt;br/&gt;
-    super.populateDisplayData(builder);&lt;br/&gt;
-    builder&lt;br/&gt;
-        .add(DisplayData.item(&quot;sink&quot;, sink.getClass()).withLabel(&quot;WriteFiles Sink&quot;))&lt;br/&gt;
-        .include(&quot;sink&quot;, sink);&lt;br/&gt;
-    if (getSharding() != null) {
-      builder.include(&quot;sharding&quot;, getSharding());
-    } else {
-      builder.addIfNotNull(DisplayData.item(&quot;numShards&quot;, getNumShards())
-          .withLabel(&quot;Fixed Number of Shards&quot;));
-    }&lt;br/&gt;
-  }&lt;br/&gt;
+  abstract int getMaxNumWritersPerBundle();&lt;br/&gt;
 &lt;br/&gt;
-  /** Returns the {@link FileBasedSink} associated with this PTransform. */&lt;br/&gt;
-  public FileBasedSink&amp;lt;UserT, DestinationT, OutputT&amp;gt; getSink() {
-    return sink;
-  }&lt;br/&gt;
+  abstract List&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt; getSideInputs();&lt;br/&gt;
 &lt;br/&gt;
-  /**&lt;br/&gt;
-   * Returns whether or not to perform windowed writes.&lt;br/&gt;
-   */&lt;br/&gt;
-  public boolean isWindowedWrites() {
-    return windowedWrites;
-  }&lt;br/&gt;
+  abstract Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt; toBuilder();&lt;br/&gt;
 &lt;br/&gt;
-  /**&lt;br/&gt;
-   * Gets the {@link PTransform} that will be used to determine sharding. This can be either a&lt;br/&gt;
-   * static number of shards (as following a call to {@link #withNumShards(int)}), dynamic (by&lt;br/&gt;
-   * {@link #withSharding(PTransform)}), or runner-determined (by {@link
-   * #withRunnerDeterminedSharding()}.&lt;br/&gt;
-   */&lt;br/&gt;
-  public @Nullable PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, PCollectionView&amp;lt;Integer&amp;gt;&amp;gt; getSharding() {&lt;br/&gt;
-    return computeNumShards;&lt;br/&gt;
+  @AutoValue.Builder&lt;br/&gt;
+  abstract static class Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt; {
+    abstract Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt; setSink(
+        FileBasedSink&amp;lt;UserT, DestinationT, OutputT&amp;gt; sink);
+
+    abstract Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt; setComputeNumShards(
+        @Nullable PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, PCollectionView&amp;lt;Integer&amp;gt;&amp;gt; computeNumShards);
+
+    abstract Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt; setNumShardsProvider(
+        @Nullable ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider);
+
+    abstract Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt; setWindowedWrites(boolean windowedWrites);
+
+    abstract Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt; setMaxNumWritersPerBundle(
+        int maxNumWritersPerBundle);
+
+    abstract Builder&amp;lt;UserT, DestinationT, OutputT&amp;gt; setSideInputs(
+        List&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt; sideInputs);
+
+    abstract WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt; build();
   }&lt;br/&gt;
 &lt;br/&gt;
-  public @Nullable ValueProvider&amp;lt;Integer&amp;gt; getNumShards() {&lt;br/&gt;
-    return numShardsProvider;&lt;br/&gt;
+  @Override&lt;br/&gt;
+  public Map&amp;lt;TupleTag&amp;lt;?&amp;gt;, PValue&amp;gt; getAdditionalInputs() {
+    return PCollectionViews.toAdditionalInputs(getSideInputs());
   }&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
@@ -269,36 +221,18 @@ public boolean isWindowedWrites() {&lt;br/&gt;
    */&lt;br/&gt;
   public WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt; withNumShards(&lt;br/&gt;
       ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider) {
-    return new WriteFiles&amp;lt;&amp;gt;(
-        sink,
-        computeNumShards,
-        numShardsProvider,
-        windowedWrites,
-        maxNumWritersPerBundle,
-        sideInputs);
+    return toBuilder().setNumShardsProvider(numShardsProvider).build();
   }&lt;br/&gt;
 &lt;br/&gt;
   /** Set the maximum number of writers created in a bundle before spilling to shuffle. */&lt;br/&gt;
   public WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt; withMaxNumWritersPerBundle(&lt;br/&gt;
       int maxNumWritersPerBundle) {
-    return new WriteFiles&amp;lt;&amp;gt;(
-        sink,
-        computeNumShards,
-        numShardsProvider,
-        windowedWrites,
-        maxNumWritersPerBundle,
-        sideInputs);
+    return toBuilder().setMaxNumWritersPerBundle(maxNumWritersPerBundle).build();
   }&lt;br/&gt;
 &lt;br/&gt;
   public WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt; withSideInputs(&lt;br/&gt;
       List&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt; sideInputs) {
-    return new WriteFiles&amp;lt;&amp;gt;(
-        sink,
-        computeNumShards,
-        numShardsProvider,
-        windowedWrites,
-        maxNumWritersPerBundle,
-        sideInputs);
+    return toBuilder().setSideInputs(sideInputs).build();
   }&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
@@ -312,8 +246,7 @@ public boolean isWindowedWrites() {&lt;br/&gt;
       PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, PCollectionView&amp;lt;Integer&amp;gt;&amp;gt; sharding) {
     checkArgument(
         sharding != null, &quot;sharding can not be null. Use withRunnerDeterminedSharding() instead.&quot;);
-    return new WriteFiles&amp;lt;&amp;gt;(
-        sink, sharding, null, windowedWrites, maxNumWritersPerBundle, sideInputs);
+    return toBuilder().setComputeNumShards(sharding).build();
   }&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
@@ -321,7 +254,7 @@ public boolean isWindowedWrites() {&lt;br/&gt;
    * runner-determined sharding.&lt;br/&gt;
    */&lt;br/&gt;
   public WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt; withRunnerDeterminedSharding() {
-    return new WriteFiles&amp;lt;&amp;gt;(sink, null, null, windowedWrites, maxNumWritersPerBundle, sideInputs);
+    return toBuilder().setComputeNumShards(null).setNumShardsProvider(null).build();
   }&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
@@ -337,68 +270,206 @@ public boolean isWindowedWrites() {&lt;br/&gt;
    * &amp;lt;p&amp;gt;This option can only be used if {@link #withNumShards(int)} is also set to a positive value.&lt;br/&gt;
    */&lt;br/&gt;
   public WriteFiles&amp;lt;UserT, DestinationT, OutputT&amp;gt; withWindowedWrites() {
-    return new WriteFiles&amp;lt;&amp;gt;(
-        sink, computeNumShards, numShardsProvider, true, maxNumWritersPerBundle, sideInputs);
+    return toBuilder().setWindowedWrites(true).build();
   }&lt;br/&gt;
 &lt;br/&gt;
-  private static class WriterKey&amp;lt;DestinationT&amp;gt; {&lt;br/&gt;
-    private final BoundedWindow window;&lt;br/&gt;
-    private final PaneInfo paneInfo;&lt;br/&gt;
-    private final DestinationT destination;&lt;br/&gt;
+  @Override&lt;br/&gt;
+  public void validate(PipelineOptions options) {
+    getSink().validate(options);
+  }&lt;br/&gt;
 &lt;br/&gt;
-    WriterKey(BoundedWindow window, PaneInfo paneInfo, DestinationT destination) {&lt;br/&gt;
-      this.window = window;&lt;br/&gt;
-      this.paneInfo = paneInfo;&lt;br/&gt;
-      this.destination = destination;&lt;br/&gt;
+  @Override&lt;br/&gt;
+  public WriteFilesResult&amp;lt;DestinationT&amp;gt; expand(PCollection&amp;lt;UserT&amp;gt; input) {&lt;br/&gt;
+    if (input.isBounded() == IsBounded.UNBOUNDED) {
+      checkArgument(
+          getWindowedWrites(),
+          &quot;Must use windowed writes when applying %s to an unbounded PCollection&quot;,
+          WriteFiles.class.getSimpleName());
+      // The reason for this is https://issues.apache.org/jira/browse/BEAM-1438
+      // and similar behavior in other runners.
+      checkArgument(
+          getComputeNumShards() != null || getNumShardsProvider() != null,
+          &quot;When applying %s to an unbounded PCollection, &quot;
+              + &quot;must specify number of output shards explicitly&quot;,
+          WriteFiles.class.getSimpleName());
     }&lt;br/&gt;
+    this.writeOperation = getSink().createWriteOperation();&lt;br/&gt;
+    this.writeOperation.setWindowedWrites(getWindowedWrites());&lt;br/&gt;
 &lt;br/&gt;
-    @Override&lt;br/&gt;
-    public boolean equals(Object o) {&lt;br/&gt;
-      if (!(o instanceof WriterKey)) {
-        return false;
-      }&lt;br/&gt;
-      WriterKey other = (WriterKey) o;&lt;br/&gt;
-      return Objects.equal(window, other.window)&lt;br/&gt;
-          &amp;amp;&amp;amp; Objects.equal(paneInfo, other.paneInfo)&lt;br/&gt;
-          &amp;amp;&amp;amp; Objects.equal(destination, other.destination);&lt;br/&gt;
+    if (!getWindowedWrites()) {
+      // Re-window the data into the global window and remove any existing triggers.
+      input =
+          input.apply(
+              &quot;RewindowIntoGlobal&quot;,
+              Window.&amp;lt;UserT&amp;gt;into(new GlobalWindows())
+                  .triggering(DefaultTrigger.of())
+                  .discardingFiredPanes());
+    }&lt;br/&gt;
+&lt;br/&gt;
+    Coder&amp;lt;DestinationT&amp;gt; destinationCoder;&lt;br/&gt;
+    try {
+      destinationCoder =
+          getDynamicDestinations()
+              .getDestinationCoderWithDefault(input.getPipeline().getCoderRegistry());
+      destinationCoder.verifyDeterministic();
+    } catch (CannotProvideCoderException | NonDeterministicException e) {
+      throw new RuntimeException(e);
+    }&lt;br/&gt;
+    @SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
+    Coder&amp;lt;BoundedWindow&amp;gt; windowCoder =&lt;br/&gt;
+        (Coder&amp;lt;BoundedWindow&amp;gt;) input.getWindowingStrategy().getWindowFn().windowCoder();&lt;br/&gt;
+    FileResultCoder&amp;lt;DestinationT&amp;gt; fileResultCoder =&lt;br/&gt;
+        FileResultCoder.of(windowCoder, destinationCoder);&lt;br/&gt;
+&lt;br/&gt;
+    PCollectionView&amp;lt;Integer&amp;gt; numShardsView =&lt;br/&gt;
+        (getComputeNumShards() == null) ? null : input.apply(getComputeNumShards());&lt;br/&gt;
+&lt;br/&gt;
+    PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; tempFileResults =&lt;br/&gt;
+        (getComputeNumShards() == null &amp;amp;&amp;amp; getNumShardsProvider() == null)&lt;br/&gt;
+            ? input.apply(&lt;br/&gt;
+                &quot;WriteUnshardedBundlesToTempFiles&quot;,&lt;br/&gt;
+                new WriteUnshardedBundlesToTempFiles(destinationCoder, fileResultCoder))&lt;br/&gt;
+            : input.apply(&lt;br/&gt;
+                &quot;WriteShardedBundlesToTempFiles&quot;,&lt;br/&gt;
+                new WriteShardedBundlesToTempFiles(&lt;br/&gt;
+                    destinationCoder, fileResultCoder, numShardsView));&lt;br/&gt;
+&lt;br/&gt;
+    return tempFileResults&lt;br/&gt;
+        .apply(&quot;GatherTempFileResults&quot;, new GatherResults&amp;lt;&amp;gt;(fileResultCoder))&lt;br/&gt;
+        .apply(&lt;br/&gt;
+            &quot;FinalizeTempFileBundles&quot;,&lt;br/&gt;
+            new FinalizeTempFileBundles(numShardsView, destinationCoder));&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Override&lt;br/&gt;
+  public void populateDisplayData(DisplayData.Builder builder) {&lt;br/&gt;
+    super.populateDisplayData(builder);&lt;br/&gt;
+    builder&lt;br/&gt;
+        .add(DisplayData.item(&quot;sink&quot;, getSink().getClass()).withLabel(&quot;WriteFiles Sink&quot;))&lt;br/&gt;
+        .include(&quot;sink&quot;, getSink());&lt;br/&gt;
+    if (getComputeNumShards() != null) {
+      builder.include(&quot;sharding&quot;, getComputeNumShards());
+    } else {
+      builder.addIfNotNull(
+          DisplayData.item(&quot;numShards&quot;, getNumShardsProvider())
+              .withLabel(&quot;Fixed Number of Shards&quot;));
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private DynamicDestinations&amp;lt;UserT, DestinationT, OutputT&amp;gt; getDynamicDestinations() {
+    return (DynamicDestinations&amp;lt;UserT, DestinationT, OutputT&amp;gt;)
+        writeOperation.getSink().getDynamicDestinations();
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private class GatherResults&amp;lt;ResultT&amp;gt;&lt;br/&gt;
+      extends PTransform&amp;lt;PCollection&amp;lt;ResultT&amp;gt;, PCollection&amp;lt;List&amp;lt;ResultT&amp;gt;&amp;gt;&amp;gt; {&lt;br/&gt;
+    private final Coder&amp;lt;ResultT&amp;gt; resultCoder;&lt;br/&gt;
+&lt;br/&gt;
+    private GatherResults(Coder&amp;lt;ResultT&amp;gt; resultCoder) {
+      this.resultCoder = resultCoder;
     }&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
-    public int hashCode() {&lt;br/&gt;
-      return Objects.hashCode(window, paneInfo, destination);&lt;br/&gt;
+    public PCollection&amp;lt;List&amp;lt;ResultT&amp;gt;&amp;gt; expand(PCollection&amp;lt;ResultT&amp;gt; input) {&lt;br/&gt;
+      if (getWindowedWrites()) {
+        // Reshuffle the results to make them stable against retries.
+        // Use a single void key to maximize size of bundles for finalization.
+        return input
+            .apply(&quot;Add void key&quot;, WithKeys.&amp;lt;Void, ResultT&amp;gt;of((Void) null))
+            .apply(&quot;Reshuffle&quot;, Reshuffle.&amp;lt;Void, ResultT&amp;gt;of())
+            .apply(&quot;Drop key&quot;, Values.&amp;lt;ResultT&amp;gt;create())
+            .apply(&quot;Gather bundles&quot;, ParDo.of(new GatherBundlesPerWindowFn&amp;lt;ResultT&amp;gt;()))
+            .setCoder(ListCoder.of(resultCoder))
+            // Reshuffle one more time to stabilize the contents of the bundle lists to finalize.
+            .apply(Reshuffle.&amp;lt;List&amp;lt;ResultT&amp;gt;&amp;gt;viaRandomKey());
+      } else {
+        // Pass results via a side input rather than reshuffle, because we need to get an empty
+        // iterable to finalize if there are no results.
+        return input
+            .getPipeline()
+            .apply(
+                Reify.viewInGlobalWindow(
+                    input.apply(View.&amp;lt;ResultT&amp;gt;asList()), ListCoder.of(resultCoder)));
+      }&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
-  // Hash the destination in a manner that we can then use as a key in a GBK. Since Java&apos;s&lt;br/&gt;
-  // hashCode isn&apos;t guaranteed to be stable across machines, we instead serialize the destination&lt;br/&gt;
-  // and use murmur3_32 to hash it. We enforce that destinationCoder must be deterministic, so&lt;br/&gt;
-  // this can be used as a key.&lt;br/&gt;
-  private static &amp;lt;DestinationT&amp;gt; int hashDestination(&lt;br/&gt;
-      DestinationT destination, Coder&amp;lt;DestinationT&amp;gt; destinationCoder) throws IOException {&lt;br/&gt;
-    return Hashing.murmur3_32()&lt;br/&gt;
-        .hashBytes(CoderUtils.encodeToByteArray(destinationCoder, destination))&lt;br/&gt;
-        .asInt();&lt;br/&gt;
+  private class WriteUnshardedBundlesToTempFiles&lt;br/&gt;
+      extends PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt; {&lt;br/&gt;
+    private final Coder&amp;lt;DestinationT&amp;gt; destinationCoder;&lt;br/&gt;
+    private final Coder&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; fileResultCoder;&lt;br/&gt;
+&lt;br/&gt;
+    private WriteUnshardedBundlesToTempFiles(&lt;br/&gt;
+        Coder&amp;lt;DestinationT&amp;gt; destinationCoder, Coder&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; fileResultCoder) {
+      this.destinationCoder = destinationCoder;
+      this.fileResultCoder = fileResultCoder;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; expand(PCollection&amp;lt;UserT&amp;gt; input) {&lt;br/&gt;
+      TupleTag&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; writtenRecordsTag = new TupleTag&amp;lt;&amp;gt;(&quot;writtenRecords&quot;);&lt;br/&gt;
+      TupleTag&amp;lt;KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;&amp;gt; unwrittenRecordsTag =&lt;br/&gt;
+          new TupleTag&amp;lt;&amp;gt;(&quot;unwrittenRecords&quot;);&lt;br/&gt;
+      PCollectionTuple writeTuple =&lt;br/&gt;
+          input.apply(&lt;br/&gt;
+              &quot;WriteUnshardedBundles&quot;,&lt;br/&gt;
+              ParDo.of(&lt;br/&gt;
+                      new WriteUnshardedTempFilesWithSpillingFn(&lt;br/&gt;
+                          unwrittenRecordsTag, destinationCoder))&lt;br/&gt;
+                  .withSideInputs(getSideInputs())&lt;br/&gt;
+                  .withOutputTags(writtenRecordsTag, TupleTagList.of(unwrittenRecordsTag)));&lt;br/&gt;
+      PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; writtenBundleFiles =&lt;br/&gt;
+          writeTuple.get(writtenRecordsTag).setCoder(fileResultCoder);&lt;br/&gt;
+      // Any &quot;spilled&quot; elements are written using WriteShardedBundles. Assign shard numbers in&lt;br/&gt;
+      // finalize to stay consistent with what WriteWindowedBundles does.&lt;br/&gt;
+      PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; writtenSpilledFiles =&lt;br/&gt;
+          writeTuple&lt;br/&gt;
+              .get(unwrittenRecordsTag)&lt;br/&gt;
+              .setCoder(KvCoder.of(ShardedKeyCoder.of(VarIntCoder.of()), input.getCoder()))&lt;br/&gt;
+              // Here we group by a synthetic shard number in the range [0, spill factor),&lt;br/&gt;
+              // just for the sake of getting some parallelism within each destination when&lt;br/&gt;
+              // writing the spilled records, whereas the non-spilled records don&apos;t have a shard&lt;br/&gt;
+              // number assigned at all. Drop the shard number on the spilled records so that&lt;br/&gt;
+              // shard numbers are assigned together to both the spilled and non-spilled files in&lt;br/&gt;
+              // finalize.&lt;br/&gt;
+              .apply(&quot;GroupUnwritten&quot;, GroupByKey.&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;create())&lt;br/&gt;
+              .apply(&lt;br/&gt;
+                  &quot;WriteUnwritten&quot;,&lt;br/&gt;
+                  ParDo.of(new WriteShardsIntoTempFilesFn()).withSideInputs(getSideInputs()))&lt;br/&gt;
+              .setCoder(fileResultCoder)&lt;br/&gt;
+              .apply(&lt;br/&gt;
+                  &quot;DropShardNum&quot;,&lt;br/&gt;
+                  ParDo.of(&lt;br/&gt;
+                      new DoFn&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;() {&lt;br/&gt;
+                        @ProcessElement&lt;br/&gt;
+                        public void process(ProcessContext c) {
+                          c.output(c.element().withShard(UNKNOWN_SHARDNUM));
+                        }&lt;br/&gt;
+                      }));&lt;br/&gt;
+      return PCollectionList.of(writtenBundleFiles)&lt;br/&gt;
+          .and(writtenSpilledFiles)&lt;br/&gt;
+          .apply(Flatten.&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;pCollections())&lt;br/&gt;
+          .setCoder(fileResultCoder);&lt;br/&gt;
+    }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
    * Writes all the elements in a bundle using a {@link Writer} produced by the {@link
    * WriteOperation} associated with the {@link FileBasedSink}.&lt;br/&gt;
    */&lt;br/&gt;
-  private class WriteBundles extends DoFn&amp;lt;UserT, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; {&lt;br/&gt;
+  private class WriteUnshardedTempFilesWithSpillingFn&lt;br/&gt;
+      extends DoFn&amp;lt;UserT, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; {&lt;br/&gt;
     private final TupleTag&amp;lt;KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;&amp;gt; unwrittenRecordsTag;&lt;br/&gt;
     private final Coder&amp;lt;DestinationT&amp;gt; destinationCoder;&lt;br/&gt;
-    private final boolean windowedWrites;&lt;br/&gt;
 &lt;br/&gt;
     // Initialized in startBundle()&lt;br/&gt;
     private @Nullable Map&amp;lt;WriterKey&amp;lt;DestinationT&amp;gt;, Writer&amp;lt;DestinationT, OutputT&amp;gt;&amp;gt; writers;&lt;br/&gt;
 &lt;br/&gt;
     private int spilledShardNum = UNKNOWN_SHARDNUM;&lt;br/&gt;
 &lt;br/&gt;
-    WriteBundles(&lt;br/&gt;
-        boolean windowedWrites,&lt;br/&gt;
+    WriteUnshardedTempFilesWithSpillingFn(&lt;br/&gt;
         TupleTag&amp;lt;KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;&amp;gt; unwrittenRecordsTag,&lt;br/&gt;
         Coder&amp;lt;DestinationT&amp;gt; destinationCoder) {
-      this.windowedWrites = windowedWrites;
       this.unwrittenRecordsTag = unwrittenRecordsTag;
       this.destinationCoder = destinationCoder;
     }&lt;br/&gt;
@@ -411,32 +482,28 @@ public void startBundle(StartBundleContext c) {&lt;br/&gt;
 &lt;br/&gt;
     @ProcessElement&lt;br/&gt;
     public void processElement(ProcessContext c, BoundedWindow window) throws Exception {&lt;br/&gt;
-      sink.getDynamicDestinations().setSideInputAccessorFromProcessContext(c);&lt;br/&gt;
+      getDynamicDestinations().setSideInputAccessorFromProcessContext(c);&lt;br/&gt;
       PaneInfo paneInfo = c.pane();&lt;br/&gt;
       // If we are doing windowed writes, we need to ensure that we have separate files for&lt;br/&gt;
       // data in different windows/panes. Similar for dynamic writes, make sure that different&lt;br/&gt;
       // destinations go to different writers.&lt;br/&gt;
       // In the case of unwindowed writes, the window and the pane will always be the same, and&lt;br/&gt;
       // the map will only have a single element.&lt;br/&gt;
-      DestinationT destination = sink.getDynamicDestinations().getDestination(c.element());&lt;br/&gt;
+      DestinationT destination = getDynamicDestinations().getDestination(c.element());&lt;br/&gt;
       WriterKey&amp;lt;DestinationT&amp;gt; key = new WriterKey&amp;lt;&amp;gt;(window, c.pane(), destination);&lt;br/&gt;
       Writer&amp;lt;DestinationT, OutputT&amp;gt; writer = writers.get(key);&lt;br/&gt;
       if (writer == null) {&lt;br/&gt;
-        if (writers.size() &amp;lt;= maxNumWritersPerBundle) {&lt;br/&gt;
+        if (writers.size() &amp;lt;= getMaxNumWritersPerBundle()) {&lt;br/&gt;
           String uuid = UUID.randomUUID().toString();&lt;br/&gt;
           LOG.info(&lt;br/&gt;
-              &quot;Opening writer {} for write operation {}, window {} pane {} destination {}&quot;,&lt;br/&gt;
+              &quot;Opening writer {} for window {} pane {} destination {}&quot;,&lt;br/&gt;
               uuid,&lt;br/&gt;
-              writeOperation,&lt;br/&gt;
               window,&lt;br/&gt;
               paneInfo,&lt;br/&gt;
               destination);&lt;br/&gt;
           writer = writeOperation.createWriter();&lt;br/&gt;
-          if (windowedWrites) {
-            writer.openWindowed(uuid, window, paneInfo, UNKNOWN_SHARDNUM, destination);
-          } else {
-            writer.openUnwindowed(uuid, UNKNOWN_SHARDNUM, destination);
-          }&lt;br/&gt;
+          writer.setDestination(destination);&lt;br/&gt;
+          writer.open(uuid);&lt;br/&gt;
           writers.put(key, writer);&lt;br/&gt;
           LOG.debug(&quot;Done opening writer&quot;);&lt;br/&gt;
         } else {
@@ -454,96 +521,30 @@ public void processElement(ProcessContext c, BoundedWindow window) throws Except
           return;
         }&lt;br/&gt;
       }&lt;br/&gt;
-      writeOrClose(writer, getSink().getDynamicDestinations().formatRecord(c.element()));&lt;br/&gt;
+      writeOrClose(writer, getDynamicDestinations().formatRecord(c.element()));&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     @FinishBundle&lt;br/&gt;
     public void finishBundle(FinishBundleContext c) throws Exception {&lt;br/&gt;
       for (Map.Entry&amp;lt;WriterKey&amp;lt;DestinationT&amp;gt;, Writer&amp;lt;DestinationT, OutputT&amp;gt;&amp;gt; entry :&lt;br/&gt;
           writers.entrySet()) {&lt;br/&gt;
+        WriterKey&amp;lt;DestinationT&amp;gt; key = entry.getKey();&lt;br/&gt;
         Writer&amp;lt;DestinationT, OutputT&amp;gt; writer = entry.getValue();&lt;br/&gt;
-        FileResult&amp;lt;DestinationT&amp;gt; result;&lt;br/&gt;
-        try {
-          result = writer.close();
-        } catch (Exception e) {
-          // If anything goes wrong, make sure to delete the temporary file.
-          writer.cleanup();
-          throw e;
-        }&lt;br/&gt;
-        BoundedWindow window = entry.getKey().window;&lt;br/&gt;
-        c.output(result, window.maxTimestamp(), window);&lt;br/&gt;
-      }&lt;br/&gt;
-    }&lt;br/&gt;
-&lt;br/&gt;
-    @Override&lt;br/&gt;
-    public void populateDisplayData(DisplayData.Builder builder) {
-      builder.delegate(WriteFiles.this);
-    }&lt;br/&gt;
-  }&lt;br/&gt;
-&lt;br/&gt;
-  enum ShardAssignment { ASSIGN_IN_FINALIZE, ASSIGN_WHEN_WRITING }&lt;br/&gt;
-&lt;br/&gt;
-  /*&lt;br/&gt;
-   * Like {@link WriteBundles}, but where the elements for each shard have been collected into a&lt;br/&gt;
-   * single iterable.&lt;br/&gt;
-   */&lt;br/&gt;
-  private class WriteShardedBundles&lt;br/&gt;
-      extends DoFn&amp;lt;KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, Iterable&amp;lt;UserT&amp;gt;&amp;gt;, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; {&lt;br/&gt;
-    ShardAssignment shardNumberAssignment;&lt;br/&gt;
-    WriteShardedBundles(ShardAssignment shardNumberAssignment) {
-      this.shardNumberAssignment = shardNumberAssignment;
-    }&lt;br/&gt;
-&lt;br/&gt;
-    @ProcessElement&lt;br/&gt;
-    public void processElement(ProcessContext c, BoundedWindow window) throws Exception {&lt;br/&gt;
-      sink.getDynamicDestinations().setSideInputAccessorFromProcessContext(c);&lt;br/&gt;
-      // Since we key by a 32-bit hash of the destination, there might be multiple destinations&lt;br/&gt;
-      // in this iterable. The number of destinations is generally very small (1000s or less), so&lt;br/&gt;
-      // there will rarely be hash collisions.&lt;br/&gt;
-      Map&amp;lt;DestinationT, Writer&amp;lt;DestinationT, OutputT&amp;gt;&amp;gt; writers = Maps.newHashMap();&lt;br/&gt;
-      for (UserT input : c.element().getValue()) {&lt;br/&gt;
-        DestinationT destination = sink.getDynamicDestinations().getDestination(input);&lt;br/&gt;
-        Writer&amp;lt;DestinationT, OutputT&amp;gt; writer = writers.get(destination);&lt;br/&gt;
-        if (writer == null) {&lt;br/&gt;
-          LOG.debug(&quot;Opening writer for write operation {}&quot;, writeOperation);&lt;br/&gt;
-          writer = writeOperation.createWriter();&lt;br/&gt;
-          int shardNumber =&lt;br/&gt;
-              shardNumberAssignment == ShardAssignment.ASSIGN_WHEN_WRITING&lt;br/&gt;
-                  ? c.element().getKey().getShardNumber()&lt;br/&gt;
-                  : UNKNOWN_SHARDNUM;&lt;br/&gt;
-          if (windowedWrites) {
-            writer.openWindowed(
-                UUID.randomUUID().toString(), window, c.pane(), shardNumber, destination);
-          } else {
-            writer.openUnwindowed(
-                UUID.randomUUID().toString(), shardNumber, destination);
-          }&lt;br/&gt;
-          LOG.debug(&quot;Done opening writer&quot;);&lt;br/&gt;
-          writers.put(destination, writer);&lt;br/&gt;
-        }&lt;br/&gt;
-        writeOrClose(writer, getSink().getDynamicDestinations().formatRecord(input));&lt;br/&gt;
-      }&lt;br/&gt;
-&lt;br/&gt;
-      // Close all writers.&lt;br/&gt;
-      for (Map.Entry&amp;lt;DestinationT, Writer&amp;lt;DestinationT, OutputT&amp;gt;&amp;gt; entry : writers.entrySet()) {&lt;br/&gt;
-        Writer&amp;lt;DestinationT, OutputT&amp;gt; writer = entry.getValue();&lt;br/&gt;
-        FileResult&amp;lt;DestinationT&amp;gt; result;&lt;br/&gt;
         try {
-          // Close the writer; if this throws let the error propagate.
-          result = writer.close();
-          c.output(result);
+          writer.close();
         } catch (Exception e) {
           // If anything goes wrong, make sure to delete the temporary file.
           writer.cleanup();
           throw e;
         }&lt;br/&gt;
+        BoundedWindow window = key.window;&lt;br/&gt;
+        c.output(&lt;br/&gt;
+            new FileResult&amp;lt;&amp;gt;(&lt;br/&gt;
+                writer.getOutputFile(), UNKNOWN_SHARDNUM, window, key.paneInfo, key.destination),&lt;br/&gt;
+            window.maxTimestamp(),&lt;br/&gt;
+            window);&lt;br/&gt;
       }&lt;br/&gt;
     }&lt;br/&gt;
-&lt;br/&gt;
-    @Override&lt;br/&gt;
-    public void populateDisplayData(DisplayData.Builder builder) {-      builder.delegate(WriteFiles.this);-    }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   private static &amp;lt;DestinationT, OutputT&amp;gt; void writeOrClose(&lt;br/&gt;
@@ -567,21 +568,90 @@ public void populateDisplayData(DisplayData.Builder builder) {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
-  private class ApplyShardingKey extends DoFn&amp;lt;UserT, KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;&amp;gt; {&lt;br/&gt;
+  private static class WriterKey&amp;lt;DestinationT&amp;gt; {&lt;br/&gt;
+    private final BoundedWindow window;&lt;br/&gt;
+    private final PaneInfo paneInfo;&lt;br/&gt;
+    private final DestinationT destination;&lt;br/&gt;
+&lt;br/&gt;
+    WriterKey(BoundedWindow window, PaneInfo paneInfo, DestinationT destination) {
+      this.window = window;
+      this.paneInfo = paneInfo;
+      this.destination = destination;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public boolean equals(Object o) {&lt;br/&gt;
+      if (!(o instanceof WriterKey)) {
+        return false;
+      }&lt;br/&gt;
+      WriterKey other = (WriterKey) o;&lt;br/&gt;
+      return Objects.equal(window, other.window)&lt;br/&gt;
+          &amp;amp;&amp;amp; Objects.equal(paneInfo, other.paneInfo)&lt;br/&gt;
+          &amp;amp;&amp;amp; Objects.equal(destination, other.destination);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public int hashCode() {
+      return Objects.hashCode(window, paneInfo, destination);
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  // Hash the destination in a manner that we can then use as a key in a GBK. Since Java&apos;s&lt;br/&gt;
+  // hashCode isn&apos;t guaranteed to be stable across machines, we instead serialize the destination&lt;br/&gt;
+  // and use murmur3_32 to hash it. We enforce that destinationCoder must be deterministic, so&lt;br/&gt;
+  // this can be used as a key.&lt;br/&gt;
+  private static &amp;lt;DestinationT&amp;gt; int hashDestination(&lt;br/&gt;
+      DestinationT destination, Coder&amp;lt;DestinationT&amp;gt; destinationCoder) throws IOException {
+    return Hashing.murmur3_32()
+        .hashBytes(CoderUtils.encodeToByteArray(destinationCoder, destination))
+        .asInt();
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private class WriteShardedBundlesToTempFiles&lt;br/&gt;
+      extends PTransform&amp;lt;PCollection&amp;lt;UserT&amp;gt;, PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt; {&lt;br/&gt;
+    private final Coder&amp;lt;DestinationT&amp;gt; destinationCoder;&lt;br/&gt;
+    private final Coder&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; fileResultCoder;&lt;br/&gt;
+    private final @Nullable PCollectionView&amp;lt;Integer&amp;gt; numShardsView;&lt;br/&gt;
+&lt;br/&gt;
+    private WriteShardedBundlesToTempFiles(&lt;br/&gt;
+        Coder&amp;lt;DestinationT&amp;gt; destinationCoder,&lt;br/&gt;
+        Coder&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; fileResultCoder,&lt;br/&gt;
+        @Nullable PCollectionView&amp;lt;Integer&amp;gt; numShardsView) {
+      this.destinationCoder = destinationCoder;
+      this.fileResultCoder = fileResultCoder;
+      this.numShardsView = numShardsView;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; expand(PCollection&amp;lt;UserT&amp;gt; input) {
+      return input
+          .apply(
+              &quot;ApplyShardingKey&quot;,
+              ParDo.of(new ApplyShardingKeyFn(numShardsView, destinationCoder))
+                  .withSideInputs(
+                      (numShardsView == null)
+                          ? ImmutableList.&amp;lt;PCollectionView&amp;lt;Integer&amp;gt;&amp;gt;of()
+                          : ImmutableList.of(numShardsView)))
+          .setCoder(KvCoder.of(ShardedKeyCoder.of(VarIntCoder.of()), input.getCoder()))
+          .apply(&quot;GroupIntoShards&quot;, GroupByKey.&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;create())
+          .apply(
+              &quot;WriteShardsIntoTempFiles&quot;,
+              ParDo.of(new WriteShardsIntoTempFilesFn()).withSideInputs(getSideInputs()))
+          .setCoder(fileResultCoder);
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private class ApplyShardingKeyFn extends DoFn&amp;lt;UserT, KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;&amp;gt; {&lt;br/&gt;
     private final @Nullable PCollectionView&amp;lt;Integer&amp;gt; numShardsView;&lt;br/&gt;
-    private final ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider;&lt;br/&gt;
     private final Coder&amp;lt;DestinationT&amp;gt; destinationCoder;&lt;br/&gt;
 &lt;br/&gt;
     private int shardNumber;&lt;br/&gt;
 &lt;br/&gt;
-    ApplyShardingKey(&lt;br/&gt;
-        PCollectionView&amp;lt;Integer&amp;gt; numShardsView,&lt;br/&gt;
-        ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider,&lt;br/&gt;
-        Coder&amp;lt;DestinationT&amp;gt; destinationCoder) {&lt;br/&gt;
-      this.destinationCoder = destinationCoder;&lt;br/&gt;
+    ApplyShardingKeyFn(&lt;br/&gt;
+        @Nullable PCollectionView&amp;lt;Integer&amp;gt; numShardsView, Coder&amp;lt;DestinationT&amp;gt; destinationCoder) {
       this.numShardsView = numShardsView;
-      this.numShardsProvider = numShardsProvider;
-      shardNumber = UNKNOWN_SHARDNUM;
+      this.destinationCoder = destinationCoder;
+      this.shardNumber = UNKNOWN_SHARDNUM;
     }&lt;br/&gt;
 &lt;br/&gt;
     @ProcessElement&lt;br/&gt;
@@ -590,8 +660,8 @@ public void processElement(ProcessContext context) throws IOException {&lt;br/&gt;
       if (numShardsView != null) {
         shardCount = context.sideInput(numShardsView);
       } else {
-        checkNotNull(numShardsProvider);
-        shardCount = numShardsProvider.get();
+        checkNotNull(getNumShardsProvider());
+        shardCount = getNumShardsProvider().get();
       }&lt;br/&gt;
       checkArgument(&lt;br/&gt;
           shardCount &amp;gt; 0,&lt;br/&gt;
@@ -613,7 +683,7 @@ public void processElement(ProcessContext context) throws IOException {&lt;br/&gt;
       // the destinations. This does mean that multiple destinations might end up on the same shard,&lt;br/&gt;
       // however the number of collisions should be small, so there&apos;s no need to worry about memory&lt;br/&gt;
       // issues.&lt;br/&gt;
-      DestinationT destination = sink.getDynamicDestinations().getDestination(context.element());&lt;br/&gt;
+      DestinationT destination = getDynamicDestinations().getDestination(context.element());&lt;br/&gt;
       context.output(&lt;br/&gt;
           KV.of(&lt;br/&gt;
               ShardedKey.of(hashDestination(destination, destinationCoder), shardNumber),&lt;br/&gt;
@@ -621,396 +691,153 @@ public void processElement(ProcessContext context) throws IOException {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
-  private static &amp;lt;DestinationT&amp;gt;&lt;br/&gt;
-      Multimap&amp;lt;KV&amp;lt;DestinationT, BoundedWindow&amp;gt;, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&lt;br/&gt;
-          groupByDestinationAndWindow(Iterable&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; results) {&lt;br/&gt;
-    Multimap&amp;lt;KV&amp;lt;DestinationT, BoundedWindow&amp;gt;, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; res =&lt;br/&gt;
-        ArrayListMultimap.create();&lt;br/&gt;
-    for (FileResult&amp;lt;DestinationT&amp;gt; result : results) {&lt;br/&gt;
-      res.put(KV.of(result.getDestination(), result.getWindow()), result);&lt;br/&gt;
+  private class WriteShardsIntoTempFilesFn&lt;br/&gt;
+      extends DoFn&amp;lt;KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, Iterable&amp;lt;UserT&amp;gt;&amp;gt;, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; {&lt;br/&gt;
+    @ProcessElement&lt;br/&gt;
+    public void processElement(ProcessContext c, BoundedWindow window) throws Exception {&lt;br/&gt;
+      getDynamicDestinations().setSideInputAccessorFromProcessContext(c);&lt;br/&gt;
+      // Since we key by a 32-bit hash of the destination, there might be multiple destinations&lt;br/&gt;
+      // in this iterable. The number of destinations is generally very small (1000s or less), so&lt;br/&gt;
+      // there will rarely be hash collisions.&lt;br/&gt;
+      Map&amp;lt;DestinationT, Writer&amp;lt;DestinationT, OutputT&amp;gt;&amp;gt; writers = Maps.newHashMap();&lt;br/&gt;
+      for (UserT input : c.element().getValue()) {&lt;br/&gt;
+        DestinationT destination = getDynamicDestinations().getDestination(input);&lt;br/&gt;
+        Writer&amp;lt;DestinationT, OutputT&amp;gt; writer = writers.get(destination);&lt;br/&gt;
+        if (writer == null) {&lt;br/&gt;
+          String uuid = UUID.randomUUID().toString();&lt;br/&gt;
+          LOG.info(&lt;br/&gt;
+              &quot;Opening writer {} for window {} pane {} destination {}&quot;,&lt;br/&gt;
+              uuid,&lt;br/&gt;
+              window,&lt;br/&gt;
+              c.pane(),&lt;br/&gt;
+              destination);&lt;br/&gt;
+          writer = writeOperation.createWriter();&lt;br/&gt;
+          writer.setDestination(destination);&lt;br/&gt;
+          writer.open(uuid);&lt;br/&gt;
+          writers.put(destination, writer);&lt;br/&gt;
+        }&lt;br/&gt;
+        writeOrClose(writer, getDynamicDestinations().formatRecord(input));&lt;br/&gt;
+      }&lt;br/&gt;
+&lt;br/&gt;
+      // Close all writers.&lt;br/&gt;
+      for (Map.Entry&amp;lt;DestinationT, Writer&amp;lt;DestinationT, OutputT&amp;gt;&amp;gt; entry : writers.entrySet()) {&lt;br/&gt;
+        Writer&amp;lt;DestinationT, OutputT&amp;gt; writer = entry.getValue();&lt;br/&gt;
+        try {
+          // Close the writer; if this throws let the error propagate.
+          writer.close();
+        } catch (Exception e) {
+          // If anything goes wrong, make sure to delete the temporary file.
+          writer.cleanup();
+          throw e;
+        }&lt;br/&gt;
+        int shard = c.element().getKey().getShardNumber();&lt;br/&gt;
+        checkArgument(&lt;br/&gt;
+            shard != UNKNOWN_SHARDNUM,&lt;br/&gt;
+            &quot;Shard should have been set, but is unset for element %s&quot;,&lt;br/&gt;
+            c.element());&lt;br/&gt;
+        c.output(new FileResult&amp;lt;&amp;gt;(writer.getOutputFile(), shard, window, c.pane(), entry.getKey()));&lt;br/&gt;
+      }&lt;br/&gt;
     }&lt;br/&gt;
-    return res;&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
-  /**&lt;br/&gt;
-   * A write is performed as sequence of three {@link ParDo}&apos;s.&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;This singleton collection containing the WriteOperation is then used as a side input to a&lt;br/&gt;
-   * ParDo over the PCollection of elements to write. In this bundle-writing phase, {@link
-   * WriteOperation#createWriter} is called to obtain a {@link Writer}. {@link Writer#open}
&lt;p&gt; and&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* 
{@link Writer#close} are called in {@link DoFn.StartBundle} and {@link DoFn.FinishBundle},&lt;br/&gt;
-   * respectively, and {@link Writer#write} method is called for every element in the bundle. The&lt;br/&gt;
-   * output of this ParDo is a PCollection of &amp;lt;i&amp;gt;writer result&amp;lt;/i&amp;gt; objects (see {@link
-   * FileBasedSink} for a description of writer results)-one for each bundle.&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;The final do-once ParDo uses a singleton collection asinput and the collection of writer&lt;br/&gt;
-   * results as a side-input. In this ParDo, {@link WriteOperation#finalize} is called to finalize&lt;br/&gt;
-   * the write.&lt;br/&gt;
-   *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;If the write of any element in the PCollection fails, {@link Writer#close}
&lt;p&gt; will be called&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* before the exception that caused the write to fail is propagated and the write result will be&lt;/li&gt;
	&lt;li&gt;* discarded.&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* &amp;lt;p&amp;gt;Since the 
{@link WriteOperation}
&lt;p&gt; is serialized after the initialization ParDo and&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* deserialized in the bundle-writing and finalization phases, any state change to the&lt;/li&gt;
	&lt;li&gt;* WriteOperation object that occurs during initialization is visible in the latter phases.&lt;/li&gt;
	&lt;li&gt;* However, the WriteOperation is not serialized after the bundle-writing phase. This is why&lt;/li&gt;
	&lt;li&gt;* implementations should guarantee that 
{@link WriteOperation#createWriter}
&lt;p&gt; does not mutate&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* WriteOperation).&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;private WriteFilesResult&amp;lt;DestinationT&amp;gt; createWrite(PCollection&amp;lt;UserT&amp;gt; input) {&lt;/li&gt;
	&lt;li&gt;Pipeline p = input.getPipeline();&lt;br/&gt;
+  private class FinalizeTempFileBundles&lt;br/&gt;
+      extends PTransform&amp;lt;&lt;br/&gt;
+          PCollection&amp;lt;List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt;, WriteFilesResult&amp;lt;DestinationT&amp;gt;&amp;gt; {&lt;br/&gt;
+    @Nullable private final PCollectionView&amp;lt;Integer&amp;gt; numShardsView;&lt;br/&gt;
+    private final Coder&amp;lt;DestinationT&amp;gt; destinationCoder;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (!windowedWrites) {&lt;/li&gt;
	&lt;li&gt;// Re-window the data into the global window and remove any existing triggers.&lt;/li&gt;
	&lt;li&gt;input =&lt;/li&gt;
	&lt;li&gt;input.apply(&lt;/li&gt;
	&lt;li&gt;Window.&amp;lt;UserT&amp;gt;into(new GlobalWindows())&lt;/li&gt;
	&lt;li&gt;.triggering(DefaultTrigger.of())&lt;/li&gt;
	&lt;li&gt;.discardingFiredPanes());&lt;br/&gt;
+    private FinalizeTempFileBundles(&lt;br/&gt;
+        @Nullable PCollectionView&amp;lt;Integer&amp;gt; numShardsView, Coder&amp;lt;DestinationT&amp;gt; destinationCoder) 
{
+      this.numShardsView = numShardsView;
+      this.destinationCoder = destinationCoder;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;// Perform the per-bundle writes as a ParDo on the input PCollection (with the&lt;/li&gt;
	&lt;li&gt;// WriteOperation as a side input) and collect the results of the writes in a&lt;/li&gt;
	&lt;li&gt;// PCollection. There is a dependency between this ParDo and the first (the&lt;/li&gt;
	&lt;li&gt;// WriteOperation PCollection as a side input), so this will happen after the&lt;/li&gt;
	&lt;li&gt;// initial ParDo.&lt;/li&gt;
	&lt;li&gt;PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; results;&lt;/li&gt;
	&lt;li&gt;final PCollectionView&amp;lt;Integer&amp;gt; numShardsView;&lt;/li&gt;
	&lt;li&gt;@SuppressWarnings(&quot;unchecked&quot;)&lt;/li&gt;
	&lt;li&gt;Coder&amp;lt;BoundedWindow&amp;gt; shardedWindowCoder =&lt;/li&gt;
	&lt;li&gt;(Coder&amp;lt;BoundedWindow&amp;gt;) input.getWindowingStrategy().getWindowFn().windowCoder();&lt;/li&gt;
	&lt;li&gt;final Coder&amp;lt;DestinationT&amp;gt; destinationCoder;&lt;/li&gt;
	&lt;li&gt;try 
{
-      destinationCoder =
-          sink.getDynamicDestinations()
-              .getDestinationCoderWithDefault(input.getPipeline().getCoderRegistry());
-      destinationCoder.verifyDeterministic();
-    }
&lt;p&gt; catch (CannotProvideCoderException | NonDeterministicException e) &lt;/p&gt;
{
-      throw new RuntimeException(e);
-    }
&lt;p&gt;+    @Override&lt;br/&gt;
+    public WriteFilesResult&amp;lt;DestinationT&amp;gt; expand(&lt;br/&gt;
+        PCollection&amp;lt;List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt; input) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (computeNumShards == null &amp;amp;&amp;amp; numShardsProvider == null) 
{
-      numShardsView = null;
-      TupleTag&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; writtenRecordsTag =
-          new TupleTag&amp;lt;&amp;gt;(&quot;writtenRecordsTag&quot;);
-      TupleTag&amp;lt;KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;&amp;gt; unwrittedRecordsTag =
-          new TupleTag&amp;lt;&amp;gt;(&quot;unwrittenRecordsTag&quot;);
-      String writeName = windowedWrites ? &quot;WriteWindowedBundles&quot; : &quot;WriteBundles&quot;;
-      PCollectionTuple writeTuple =
-          input.apply(
-              writeName,
-              ParDo.of(new WriteBundles(windowedWrites, unwrittedRecordsTag, destinationCoder))
-                  .withSideInputs(sideInputs)
-                  .withOutputTags(writtenRecordsTag, TupleTagList.of(unwrittedRecordsTag)));
-      PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; writtenBundleFiles =
-          writeTuple
-              .get(writtenRecordsTag)
-              .setCoder(FileResultCoder.of(shardedWindowCoder, destinationCoder));
-      // Any &quot;spilled&quot; elements are written using WriteShardedBundles. Assign shard numbers in
-      // finalize to stay consistent with what WriteWindowedBundles does.
-      PCollection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; writtenGroupedFiles =
-          writeTuple
-              .get(unwrittedRecordsTag)
-              .setCoder(KvCoder.of(ShardedKeyCoder.of(VarIntCoder.of()), input.getCoder()))
-              .apply(&quot;GroupUnwritten&quot;, GroupByKey.&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;create())
-              .apply(
-                  &quot;WriteUnwritten&quot;,
-                  ParDo.of(new WriteShardedBundles(ShardAssignment.ASSIGN_IN_FINALIZE))
-                      .withSideInputs(sideInputs))
-              .setCoder(FileResultCoder.of(shardedWindowCoder, destinationCoder));
-      results =
-          PCollectionList.of(writtenBundleFiles)
-              .and(writtenGroupedFiles)
-              .apply(Flatten.&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;pCollections());
-    }
&lt;p&gt; else {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;List&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt; shardingSideInputs = Lists.newArrayList();&lt;/li&gt;
	&lt;li&gt;if (computeNumShards != null) 
{
-        numShardsView = input.apply(computeNumShards);
-        shardingSideInputs.add(numShardsView);
-      }
&lt;p&gt; else &lt;/p&gt;
{
-        numShardsView = null;
-      }&lt;/li&gt;
	&lt;li&gt;PCollection&amp;lt;KV&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, Iterable&amp;lt;UserT&amp;gt;&amp;gt;&amp;gt; sharded =&lt;/li&gt;
	&lt;li&gt;input&lt;/li&gt;
	&lt;li&gt;.apply(&lt;/li&gt;
	&lt;li&gt;&quot;ApplyShardLabel&quot;,&lt;/li&gt;
	&lt;li&gt;ParDo.of(&lt;/li&gt;
	&lt;li&gt;new ApplyShardingKey(&lt;/li&gt;
	&lt;li&gt;numShardsView,&lt;/li&gt;
	&lt;li&gt;(numShardsView != null) ? null : numShardsProvider,&lt;/li&gt;
	&lt;li&gt;destinationCoder))&lt;/li&gt;
	&lt;li&gt;.withSideInputs(shardingSideInputs))&lt;/li&gt;
	&lt;li&gt;.setCoder(KvCoder.of(ShardedKeyCoder.of(VarIntCoder.of()), input.getCoder()))&lt;/li&gt;
	&lt;li&gt;.apply(&quot;GroupIntoShards&quot;, GroupByKey.&amp;lt;ShardedKey&amp;lt;Integer&amp;gt;, UserT&amp;gt;create());&lt;/li&gt;
	&lt;li&gt;shardedWindowCoder =&lt;/li&gt;
	&lt;li&gt;(Coder&amp;lt;BoundedWindow&amp;gt;) sharded.getWindowingStrategy().getWindowFn().windowCoder();&lt;/li&gt;
	&lt;li&gt;// Since this path might be used by streaming runners processing triggers, it&apos;s important&lt;/li&gt;
	&lt;li&gt;// to assign shard numbers here so that they are deterministic. The ASSIGN_IN_FINALIZE&lt;/li&gt;
	&lt;li&gt;// strategy works by sorting all FileResult objects and assigning them numbers, which is not&lt;/li&gt;
	&lt;li&gt;// guaranteed to work well when processing triggers - if the finalize step retries it might&lt;/li&gt;
	&lt;li&gt;// see a different Iterable of FileResult objects, and it will assign different shard numbers.&lt;/li&gt;
	&lt;li&gt;results =&lt;/li&gt;
	&lt;li&gt;sharded.apply(&lt;/li&gt;
	&lt;li&gt;&quot;WriteShardedBundles&quot;,&lt;/li&gt;
	&lt;li&gt;ParDo.of(new WriteShardedBundles(ShardAssignment.ASSIGN_WHEN_WRITING))&lt;/li&gt;
	&lt;li&gt;.withSideInputs(sideInputs));&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;results.setCoder(FileResultCoder.of(shardedWindowCoder, destinationCoder));&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;PCollection&amp;lt;KV&amp;lt;DestinationT, String&amp;gt;&amp;gt; outputFilenames;&lt;/li&gt;
	&lt;li&gt;if (windowedWrites) 
{
-      // We need to materialize the FileResult&apos;s before the renaming stage: this can be done either
-      // via a side input or via a GBK. However, when processing streaming windowed writes, results
-      // will arrive multiple times. This means we can&apos;t share the below implementation that turns
-      // the results into a side input, as new data arriving into a side input does not trigger the
-      // listening DoFn. We also can&apos;t use a GBK because we need only the materialization, but not
-      // the (potentially lossy, if the user&apos;s trigger is lossy) continuation triggering that GBK
-      // would give. So, we use a reshuffle (over a single key to maximize bundling).
-      outputFilenames =
-          results
-              .apply(WithKeys.&amp;lt;Void, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;of((Void) null))
-              .setCoder(KvCoder.of(VoidCoder.of(), results.getCoder()))
-              .apply(&quot;Reshuffle&quot;, Reshuffle.&amp;lt;Void, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;of())
-              .apply(Values.&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;create())
-              .apply(
-                  &quot;FinalizeWindowed&quot;,
-                  ParDo.of(
-                          new FinalizeWindowedFn&amp;lt;DestinationT&amp;gt;(
-                              numShardsView, numShardsProvider, writeOperation))
-                      .withSideInputs(
-                          numShardsView == null
-                              ? ImmutableList.&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt;of()
-                              : ImmutableList.of(numShardsView)))
-              .setCoder(KvCoder.of(destinationCoder, StringUtf8Coder.of()));
-    }
&lt;p&gt; else {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;final PCollectionView&amp;lt;Iterable&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt; resultsView =&lt;/li&gt;
	&lt;li&gt;results.apply(View.&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;asIterable());&lt;/li&gt;
	&lt;li&gt;ImmutableList.Builder&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt; finalizeSideInputs =&lt;/li&gt;
	&lt;li&gt;ImmutableList.&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt;builder().add(resultsView);&lt;br/&gt;
+      List&amp;lt;PCollectionView&amp;lt;?&amp;gt;&amp;gt; finalizeSideInputs = Lists.newArrayList(getSideInputs());&lt;br/&gt;
       if (numShardsView != null) 
{
         finalizeSideInputs.add(numShardsView);
       }&lt;/li&gt;
	&lt;li&gt;finalizeSideInputs.addAll(sideInputs);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;// Finalize the write in another do-once ParDo on the singleton collection containing the&lt;/li&gt;
	&lt;li&gt;// Writer. The results from the per-bundle writes are given as an Iterable side input.&lt;/li&gt;
	&lt;li&gt;// The WriteOperation&apos;s state is the same as after its initialization in the first&lt;/li&gt;
	&lt;li&gt;// do-once ParDo. There is a dependency between this ParDo and the parallel write (the writer&lt;/li&gt;
	&lt;li&gt;// results collection as a side input), so it will happen after the parallel write.&lt;/li&gt;
	&lt;li&gt;// For the non-windowed case, we guarantee that  if no data is written but the user has&lt;/li&gt;
	&lt;li&gt;// set numShards, then all shards will be written out as empty files. For this reason we&lt;/li&gt;
	&lt;li&gt;// use a side input here.&lt;/li&gt;
	&lt;li&gt;PCollection&amp;lt;Void&amp;gt; singletonCollection = p.apply(Create.of((Void) null));&lt;/li&gt;
	&lt;li&gt;outputFilenames =&lt;/li&gt;
	&lt;li&gt;singletonCollection&lt;/li&gt;
	&lt;li&gt;.apply(&lt;/li&gt;
	&lt;li&gt;&quot;FinalizeUnwindowed&quot;,&lt;/li&gt;
	&lt;li&gt;ParDo.of(&lt;/li&gt;
	&lt;li&gt;new FinalizeUnwindowedFn&amp;lt;&amp;gt;(&lt;/li&gt;
	&lt;li&gt;numShardsView, numShardsProvider, resultsView, writeOperation))&lt;/li&gt;
	&lt;li&gt;.withSideInputs(finalizeSideInputs.build()))&lt;br/&gt;
+      PCollection&amp;lt;KV&amp;lt;DestinationT, String&amp;gt;&amp;gt; outputFilenames =&lt;br/&gt;
+          input&lt;br/&gt;
+              .apply(&quot;Finalize&quot;, ParDo.of(new FinalizeFn()).withSideInputs(finalizeSideInputs))&lt;br/&gt;
               .setCoder(KvCoder.of(destinationCoder, StringUtf8Coder.of()));&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;TupleTag&amp;lt;KV&amp;lt;DestinationT, String&amp;gt;&amp;gt; perDestinationOutputFilenamesTag =&lt;/li&gt;
	&lt;li&gt;new TupleTag&amp;lt;&amp;gt;(&quot;perDestinationOutputFilenames&quot;);&lt;/li&gt;
	&lt;li&gt;return WriteFilesResult.in(&lt;/li&gt;
	&lt;li&gt;input.getPipeline(),&lt;/li&gt;
	&lt;li&gt;perDestinationOutputFilenamesTag,&lt;/li&gt;
	&lt;li&gt;outputFilenames);&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private static class FinalizeWindowedFn&amp;lt;DestinationT&amp;gt;&lt;/li&gt;
	&lt;li&gt;extends DoFn&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, KV&amp;lt;DestinationT, String&amp;gt;&amp;gt; {&lt;/li&gt;
	&lt;li&gt;@Nullable private final PCollectionView&amp;lt;Integer&amp;gt; numShardsView;&lt;/li&gt;
	&lt;li&gt;@Nullable private final ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider;&lt;/li&gt;
	&lt;li&gt;private final WriteOperation&amp;lt;DestinationT, ?&amp;gt; writeOperation;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Nullable private transient List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; fileResults;&lt;/li&gt;
	&lt;li&gt;@Nullable private Integer fixedNumShards;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public FinalizeWindowedFn(&lt;/li&gt;
	&lt;li&gt;@Nullable PCollectionView&amp;lt;Integer&amp;gt; numShardsView,&lt;/li&gt;
	&lt;li&gt;@Nullable ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider,&lt;/li&gt;
	&lt;li&gt;WriteOperation&amp;lt;DestinationT, ?&amp;gt; writeOperation) 
{
-      this.numShardsView = numShardsView;
-      this.numShardsProvider = numShardsProvider;
-      this.writeOperation = writeOperation;
-    }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;@StartBundle&lt;/li&gt;
	&lt;li&gt;public void startBundle() 
{
-      fileResults = Lists.newArrayList();
-      fixedNumShards = null;
+      TupleTag&amp;lt;KV&amp;lt;DestinationT, String&amp;gt;&amp;gt; perDestinationOutputFilenamesTag =
+          new TupleTag&amp;lt;&amp;gt;(&quot;perDestinationOutputFilenames&quot;);
+      return WriteFilesResult.in(
+          input.getPipeline(), perDestinationOutputFilenamesTag, outputFilenames);
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@ProcessElement&lt;/li&gt;
	&lt;li&gt;public void processElement(ProcessContext c) {&lt;/li&gt;
	&lt;li&gt;fileResults.add(c.element());&lt;/li&gt;
	&lt;li&gt;if (fixedNumShards == null) {&lt;br/&gt;
+    private class FinalizeFn&lt;br/&gt;
+        extends DoFn&amp;lt;List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;, KV&amp;lt;DestinationT, String&amp;gt;&amp;gt; {&lt;br/&gt;
+      @ProcessElement&lt;br/&gt;
+      public void process(ProcessContext c) throws Exception {&lt;br/&gt;
+        getDynamicDestinations().setSideInputAccessorFromProcessContext(c);&lt;br/&gt;
+        @Nullable Integer fixedNumShards;&lt;br/&gt;
         if (numShardsView != null) 
{
           fixedNumShards = c.sideInput(numShardsView);
-        }
&lt;p&gt; else if (numShardsProvider != null) &lt;/p&gt;
{
-          fixedNumShards = numShardsProvider.get();
+        }
&lt;p&gt; else if (getNumShardsProvider() != null) &lt;/p&gt;
{
+          fixedNumShards = getNumShardsProvider().get();
         }
&lt;p&gt; else &lt;/p&gt;
{
           fixedNumShards = null;
         }
&lt;p&gt;+        List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; fileResults = Lists.newArrayList(c.element());&lt;br/&gt;
+        LOG.info(&quot;Finalizing {} file results&quot;, fileResults.size());&lt;br/&gt;
+        DestinationT defaultDest = getDynamicDestinations().getDefaultDestination();&lt;br/&gt;
+        List&amp;lt;KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt;&amp;gt; resultsToFinalFilenames =&lt;br/&gt;
+            fileResults.isEmpty()&lt;br/&gt;
+                ? writeOperation.finalizeDestination(&lt;br/&gt;
+                    defaultDest, GlobalWindow.INSTANCE, fixedNumShards, fileResults)&lt;br/&gt;
+                : finalizeAllDestinations(fileResults, fixedNumShards);&lt;br/&gt;
+        for (KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt; entry : resultsToFinalFilenames) &lt;/p&gt;
{
+          FileResult&amp;lt;DestinationT&amp;gt; res = entry.getKey();
+          c.output(KV.of(res.getDestination(), entry.getValue().toString()));
+        }
&lt;p&gt;+        writeOperation.moveToOutputFiles(resultsToFinalFilenames);&lt;br/&gt;
       }&lt;br/&gt;
     }&lt;br/&gt;
+  }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@FinishBundle&lt;/li&gt;
	&lt;li&gt;public void finishBundle(FinishBundleContext c) throws Exception {&lt;/li&gt;
	&lt;li&gt;Set&amp;lt;ResourceId&amp;gt; tempFiles = Sets.newHashSet();&lt;/li&gt;
	&lt;li&gt;Multimap&amp;lt;KV&amp;lt;DestinationT, BoundedWindow&amp;gt;, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; results =&lt;/li&gt;
	&lt;li&gt;groupByDestinationAndWindow(fileResults);&lt;/li&gt;
	&lt;li&gt;List&amp;lt;KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt;&amp;gt; resultsToFinalFilenames = Lists.newArrayList();&lt;/li&gt;
	&lt;li&gt;for (Map.Entry&amp;lt;KV&amp;lt;DestinationT, BoundedWindow&amp;gt;, Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt;&lt;/li&gt;
	&lt;li&gt;destEntry : results.asMap().entrySet()) 
{
-        DestinationT destination = destEntry.getKey().getKey();
-        BoundedWindow window = destEntry.getKey().getValue();
-        resultsToFinalFilenames.addAll(writeOperation.buildOutputFilenames(
-            destination, window, fixedNumShards, destEntry.getValue()));
-      }&lt;/li&gt;
	&lt;li&gt;LOG.info(&quot;Will finalize {} files&quot;, resultsToFinalFilenames.size());&lt;/li&gt;
	&lt;li&gt;for (KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt; entry : resultsToFinalFilenames) 
{
-        FileResult&amp;lt;DestinationT&amp;gt; res = entry.getKey();
-        tempFiles.add(res.getTempFilename());
-        c.output(
-            KV.of(res.getDestination(), entry.getValue().toString()),
-            res.getWindow().maxTimestamp(),
-            res.getWindow());
-      }&lt;/li&gt;
	&lt;li&gt;writeOperation.copyToOutputFiles(resultsToFinalFilenames);&lt;/li&gt;
	&lt;li&gt;writeOperation.removeTemporaryFiles(tempFiles);&lt;br/&gt;
+  private List&amp;lt;KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt;&amp;gt; finalizeAllDestinations(&lt;br/&gt;
+      List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; fileResults, @Nullable Integer fixedNumShards)&lt;br/&gt;
+      throws Exception 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    Multimap&amp;lt;KV&amp;lt;DestinationT, BoundedWindow&amp;gt;, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; res =+        ArrayListMultimap.create();+    for (FileResult&amp;lt;DestinationT&amp;gt; result }&lt;/span&gt; &lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class FinalizeUnwindowedFn&amp;lt;DestinationT&amp;gt;&lt;/li&gt;
	&lt;li&gt;extends DoFn&amp;lt;Void, KV&amp;lt;DestinationT, String&amp;gt;&amp;gt; {&lt;/li&gt;
	&lt;li&gt;@Nullable private final PCollectionView&amp;lt;Integer&amp;gt; numShardsView;&lt;/li&gt;
	&lt;li&gt;@Nullable private final ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider;&lt;/li&gt;
	&lt;li&gt;private final PCollectionView&amp;lt;Iterable&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt; resultsView;&lt;/li&gt;
	&lt;li&gt;private final WriteOperation&amp;lt;DestinationT, ?&amp;gt; writeOperation;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;public FinalizeUnwindowedFn(&lt;/li&gt;
	&lt;li&gt;@Nullable PCollectionView&amp;lt;Integer&amp;gt; numShardsView,&lt;/li&gt;
	&lt;li&gt;@Nullable ValueProvider&amp;lt;Integer&amp;gt; numShardsProvider,&lt;/li&gt;
	&lt;li&gt;PCollectionView&amp;lt;Iterable&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt; resultsView,&lt;/li&gt;
	&lt;li&gt;WriteOperation&amp;lt;DestinationT, ?&amp;gt; writeOperation) {&lt;/li&gt;
	&lt;li&gt;this.numShardsView = numShardsView;&lt;/li&gt;
	&lt;li&gt;this.numShardsProvider = numShardsProvider;&lt;/li&gt;
	&lt;li&gt;this.resultsView = resultsView;&lt;/li&gt;
	&lt;li&gt;this.writeOperation = writeOperation;&lt;br/&gt;
+  private static class GatherBundlesPerWindowFn&amp;lt;T&amp;gt; extends DoFn&amp;lt;T, List&amp;lt;T&amp;gt;&amp;gt; {&lt;br/&gt;
+    @Nullable private transient Multimap&amp;lt;BoundedWindow, T&amp;gt; bundles = null;&lt;br/&gt;
+&lt;br/&gt;
+    @StartBundle&lt;br/&gt;
+    public void startBundle() 
{
+      bundles = ArrayListMultimap.create();
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @ProcessElement&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public void processElement(ProcessContext c) throws Exception {&lt;/li&gt;
	&lt;li&gt;writeOperation.getSink().getDynamicDestinations().setSideInputAccessorFromProcessContext(c);&lt;/li&gt;
	&lt;li&gt;@Nullable Integer fixedNumShards;&lt;/li&gt;
	&lt;li&gt;if (numShardsView != null) 
{
-        fixedNumShards = c.sideInput(numShardsView);
-      }
&lt;p&gt; else if (numShardsProvider != null) &lt;/p&gt;
{
-        fixedNumShards = numShardsProvider.get();
-      }
&lt;p&gt; else &lt;/p&gt;
{
-        fixedNumShards = null;
-      }&lt;/li&gt;
	&lt;li&gt;Multimap&amp;lt;DestinationT, FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; resultsByDestMultimap =&lt;/li&gt;
	&lt;li&gt;ArrayListMultimap.create();&lt;/li&gt;
	&lt;li&gt;for (FileResult&amp;lt;DestinationT&amp;gt; result : c.sideInput(resultsView)) 
{
-        resultsByDestMultimap.put(result.getDestination(), result);
-      }&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;DestinationT, Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt; resultsByDest =&lt;/li&gt;
	&lt;li&gt;resultsByDestMultimap.asMap();&lt;/li&gt;
	&lt;li&gt;if (resultsByDest.isEmpty()) 
{
-        Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; empty = ImmutableList.of();
-        resultsByDest =
-            Collections.singletonMap(
-                writeOperation.getSink().getDynamicDestinations().getDefaultDestination(), empty);
-      }&lt;/li&gt;
	&lt;li&gt;List&amp;lt;KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt;&amp;gt; resultsToFinalFilenames = Lists.newArrayList();&lt;/li&gt;
	&lt;li&gt;for (Map.Entry&amp;lt;DestinationT, Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt;&amp;gt;&lt;/li&gt;
	&lt;li&gt;destEntry : resultsByDest.entrySet()) 
{
-        resultsToFinalFilenames.addAll(
-            finalizeForDestinationFillEmptyShards(
-                destEntry.getKey(), fixedNumShards, destEntry.getValue()));
-      }&lt;/li&gt;
	&lt;li&gt;Set&amp;lt;ResourceId&amp;gt; tempFiles = Sets.newHashSet();&lt;/li&gt;
	&lt;li&gt;for (KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt; entry :&lt;/li&gt;
	&lt;li&gt;resultsToFinalFilenames) 
{
-        tempFiles.add(entry.getKey().getTempFilename());
-        c.output(KV.of(entry.getKey().getDestination(), entry.getValue().toString()));
-      }&lt;/li&gt;
	&lt;li&gt;writeOperation.copyToOutputFiles(resultsToFinalFilenames);&lt;/li&gt;
	&lt;li&gt;writeOperation.removeTemporaryFiles(tempFiles);&lt;br/&gt;
+    public void process(ProcessContext c, BoundedWindow w) 
{
+      bundles.put(w, c.element());
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/**&lt;/li&gt;
	&lt;li&gt;* Finalize a list of files for a single destination. If a minimum number of shards is needed,&lt;/li&gt;
	&lt;li&gt;* this function will generate empty files for this destination to ensure that all shards are&lt;/li&gt;
	&lt;li&gt;* generated.&lt;/li&gt;
	&lt;li&gt;*/&lt;/li&gt;
	&lt;li&gt;private List&amp;lt;KV&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;, ResourceId&amp;gt;&amp;gt; finalizeForDestinationFillEmptyShards(&lt;/li&gt;
	&lt;li&gt;DestinationT destination,&lt;/li&gt;
	&lt;li&gt;@Nullable Integer fixedNumShards,&lt;/li&gt;
	&lt;li&gt;Collection&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; existingResults)&lt;/li&gt;
	&lt;li&gt;throws Exception {&lt;/li&gt;
	&lt;li&gt;checkState(!writeOperation.windowedWrites);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;LOG.info(&lt;/li&gt;
	&lt;li&gt;&quot;Finalizing write operation {} for destination {} num shards {}.&quot;,&lt;/li&gt;
	&lt;li&gt;writeOperation,&lt;/li&gt;
	&lt;li&gt;destination,&lt;/li&gt;
	&lt;li&gt;existingResults.size());&lt;/li&gt;
	&lt;li&gt;if (fixedNumShards != null) 
{
-        checkArgument(
-            existingResults.size() &amp;lt;= fixedNumShards,
-            &quot;Fixed sharding into %s shards was specified, but got %s file results&quot;,
-            fixedNumShards,
-            existingResults.size());
-      }&lt;/li&gt;
	&lt;li&gt;// We must always output at least 1 shard, and honor user-specified numShards&lt;/li&gt;
	&lt;li&gt;// if set.&lt;/li&gt;
	&lt;li&gt;Set&amp;lt;Integer&amp;gt; missingShardNums;&lt;/li&gt;
	&lt;li&gt;if (fixedNumShards == null) 
{
-        missingShardNums = ImmutableSet.of(UNKNOWN_SHARDNUM);
-      }
&lt;p&gt; else {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;missingShardNums = Sets.newHashSet();&lt;/li&gt;
	&lt;li&gt;for (int i = 0; i &amp;lt; fixedNumShards; ++i) 
{
-          missingShardNums.add(i);
-        }&lt;/li&gt;
	&lt;li&gt;for (FileResult&amp;lt;DestinationT&amp;gt; res : existingResults) 
{
-          checkArgument(
-              res.getShard() != UNKNOWN_SHARDNUM,
-              &quot;Fixed sharding into %s shards was specified, &quot;
-                  + &quot;but file result %s does not specify a shard&quot;,
-              fixedNumShards,
-              res);
-          missingShardNums.remove(res.getShard());
-        }&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;List&amp;lt;FileResult&amp;lt;DestinationT&amp;gt;&amp;gt; completeResults = Lists.newArrayList(existingResults);&lt;/li&gt;
	&lt;li&gt;if (!missingShardNums.isEmpty()) {&lt;/li&gt;
	&lt;li&gt;LOG.info(&lt;/li&gt;
	&lt;li&gt;&quot;Creating {} empty output shards in addition to {} written for destination {}.&quot;,&lt;/li&gt;
	&lt;li&gt;missingShardNums.size(),&lt;/li&gt;
	&lt;li&gt;existingResults.size(),&lt;/li&gt;
	&lt;li&gt;destination);&lt;/li&gt;
	&lt;li&gt;for (int shard : missingShardNums) 
{
-          Writer&amp;lt;DestinationT, ?&amp;gt; writer = writeOperation.createWriter();
-          // Currently this code path is only called in the unwindowed case.
-          writer.openUnwindowed(UUID.randomUUID().toString(), shard, destination);
-          FileResult&amp;lt;DestinationT&amp;gt; emptyWrite = writer.close();
-          completeResults.add(emptyWrite);
-        }&lt;/li&gt;
	&lt;li&gt;LOG.debug(&quot;Done creating extra shards for {}.&quot;, destination);&lt;br/&gt;
+    @FinishBundle&lt;br/&gt;
+    public void finishBundle(FinishBundleContext c) throws Exception {&lt;br/&gt;
+      for (BoundedWindow w : bundles.keySet()) 
{
+        c.output(Lists.newArrayList(bundles.get(w)), w.maxTimestamp(), w);
       }&lt;/li&gt;
	&lt;li&gt;return&lt;/li&gt;
	&lt;li&gt;writeOperation.buildOutputFilenames(&lt;/li&gt;
	&lt;li&gt;destination,&lt;/li&gt;
	&lt;li&gt;null,&lt;/li&gt;
	&lt;li&gt;(fixedNumShards == null) ? null : completeResults.size(),&lt;/li&gt;
	&lt;li&gt;completeResults);&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/testing/CombineFnTester.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/testing/CombineFnTester.java&lt;br/&gt;
index efd2af3544f..896d9556590 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/core/src/main/java/org/apache/beam/sdk/testing/CombineFnTester.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/testing/CombineFnTester.java&lt;br/&gt;
@@ -95,7 +95,7 @@&lt;br/&gt;
       CombineFn&amp;lt;InputT, AccumT, OutputT&amp;gt; fn,&lt;br/&gt;
       List&amp;lt;? extends Iterable&amp;lt;InputT&amp;gt;&amp;gt; shards,&lt;br/&gt;
       Matcher&amp;lt;? super OutputT&amp;gt; matcher) {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;AccumT accumulator = null;&lt;br/&gt;
+    AccumT accumulator = shards.isEmpty() ? fn.createAccumulator() : null;&lt;br/&gt;
     for (AccumT inputAccum : combineInputs(fn, shards)) {&lt;br/&gt;
       if (accumulator == null) {&lt;br/&gt;
         accumulator = inputAccum;&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java&lt;br/&gt;
index 3e023db679d..9f8dd45d110 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java&lt;br/&gt;
@@ -567,6 +567,29 @@ public Duration getAllowedTimestampSkew() {&lt;br/&gt;
   @Target(ElementType.METHOD)&lt;br/&gt;
   public @interface ProcessElement {}&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  /**&lt;br/&gt;
+   * &amp;lt;b&amp;gt;&amp;lt;i&amp;gt;Experimental - no backwards compatibility guarantees. The exact name or usage of this&lt;br/&gt;
+   * feature may change.&amp;lt;/i&amp;gt;&amp;lt;/b&amp;gt;&lt;br/&gt;
+   *&lt;br/&gt;
+   * &amp;lt;p&amp;gt;Annotation that may be added to a &lt;/p&gt;
{@link ProcessElement}
&lt;p&gt; or &lt;/p&gt;
{@link OnTimer}
&lt;p&gt; method to&lt;br/&gt;
+   * indicate that the runner must ensure that the observable contents of the input &lt;/p&gt;
{@link
+   * PCollection} or mutable state must be stable upon retries.&lt;br/&gt;
+   *&lt;br/&gt;
+   * &amp;lt;p&amp;gt;This is important for sinks, which must ensure exactly-once semantics when writing to a&lt;br/&gt;
+   * storage medium outside of your pipeline. A general pattern for a basic sink is to write a&lt;br/&gt;
+   * {@link DoFn} that can perform an idempotent write, and annotate that it requires stable input.&lt;br/&gt;
+   * Combined, these allow the write to be freely retried until success.&lt;br/&gt;
+   *&lt;br/&gt;
+   * &amp;lt;p&amp;gt;An example of an unstable input would be anything computed using nondeterministic logic. In&lt;br/&gt;
+   * Beam, any user-defined function is permitted to be nondeterministic, and any {@link+   * PCollection}
&lt;p&gt; is permitted to be recomputed in any manner.&lt;br/&gt;
+   */&lt;br/&gt;
+  @Documented&lt;br/&gt;
+  @Experimental&lt;br/&gt;
+  @Retention(RetentionPolicy.RUNTIME)&lt;br/&gt;
+  @Target(ElementType.METHOD)&lt;br/&gt;
+  public @interface RequiresStableInput {}&lt;br/&gt;
+&lt;br/&gt;
   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Annotation for the method to use to finish processing a batch of elements.&lt;/li&gt;
	&lt;li&gt;The method annotated with this must satisfy the following constraints:&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Reify.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Reify.java&lt;br/&gt;
index caa89e6e55e..7f5c8815165 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Reify.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Reify.java&lt;br/&gt;
@@ -18,17 +18,69 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; package org.apache.beam.sdk.transforms;&lt;/p&gt;

&lt;p&gt;+import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.KvCoder;&lt;br/&gt;
+import org.apache.beam.sdk.coders.VoidCoder;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.BoundedWindow;&lt;br/&gt;
 import org.apache.beam.sdk.values.KV;&lt;br/&gt;
+import org.apache.beam.sdk.values.PBegin;&lt;br/&gt;
 import org.apache.beam.sdk.values.PCollection;&lt;br/&gt;
+import org.apache.beam.sdk.values.PCollectionView;&lt;br/&gt;
 import org.apache.beam.sdk.values.TimestampedValue;&lt;br/&gt;
 import org.apache.beam.sdk.values.TimestampedValue.TimestampedValueCoder;&lt;br/&gt;
 import org.apache.beam.sdk.values.ValueInSingleWindow;&lt;br/&gt;
 import org.joda.time.Duration;&lt;/p&gt;

&lt;p&gt;-/** &lt;/p&gt;
{@link PTransform PTransforms} for reifying the timestamp, window and pane of values. */&lt;br/&gt;
+/**&lt;br/&gt;
+ * {@link PTransform PTransforms}
&lt;p&gt; for converting between explicit and implicit form of various Beam&lt;br/&gt;
+ * values.&lt;br/&gt;
+ */&lt;br/&gt;
 public class Reify {&lt;br/&gt;
+  private static class ReifyView&amp;lt;K, V&amp;gt;&lt;br/&gt;
+  extends PTransform&amp;lt;PCollection&amp;lt;K&amp;gt;, PCollection&amp;lt;KV&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt; {&lt;br/&gt;
+    private final PCollectionView&amp;lt;V&amp;gt; view;&lt;br/&gt;
+    private final Coder&amp;lt;V&amp;gt; coder;&lt;br/&gt;
+&lt;br/&gt;
+    private ReifyView(PCollectionView&amp;lt;V&amp;gt; view, Coder&amp;lt;V&amp;gt; coder) &lt;/p&gt;
{
+      this.view = view;
+      this.coder = coder;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public PCollection&amp;lt;KV&amp;lt;K, V&amp;gt;&amp;gt; expand(PCollection&amp;lt;K&amp;gt; input) {&lt;br/&gt;
+      return input&lt;br/&gt;
+          .apply(&lt;br/&gt;
+              ParDo.of(&lt;br/&gt;
+                      new DoFn&amp;lt;K, KV&amp;lt;K, V&amp;gt;&amp;gt;() {&lt;br/&gt;
+                        @ProcessElement&lt;br/&gt;
+                        public void process(ProcessContext c) {
+                          c.output(KV.of(c.element(), c.sideInput(view)));
+                        }&lt;br/&gt;
+                      })&lt;br/&gt;
+                  .withSideInputs(view))&lt;br/&gt;
+          .setCoder(KvCoder.of(input.getCoder(), coder));&lt;br/&gt;
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private static class ReifyViewInGlobalWindow&amp;lt;V&amp;gt;&lt;br/&gt;
+  extends PTransform&amp;lt;PBegin, PCollection&amp;lt;V&amp;gt;&amp;gt; {&lt;br/&gt;
+    private final PCollectionView&amp;lt;V&amp;gt; view;&lt;br/&gt;
+    private final Coder&amp;lt;V&amp;gt; coder;&lt;br/&gt;
+&lt;br/&gt;
+    private ReifyViewInGlobalWindow(PCollectionView&amp;lt;V&amp;gt; view, Coder&amp;lt;V&amp;gt; coder) {+      this.view = view;+      this.coder = coder;+    }
&lt;p&gt;+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public PCollection&amp;lt;V&amp;gt; expand(PBegin input) &lt;/p&gt;
{
+      return input
+          .apply(Create.of((Void) null).withCoder(VoidCoder.of()))
+          .apply(Reify.&amp;lt;Void, V&amp;gt;viewAsValues(view, coder))
+          .apply(Values.&amp;lt;V&amp;gt;create());
+    }
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
   /** Private implementation of &lt;/p&gt;
{@link #windows()}
&lt;p&gt;. */&lt;br/&gt;
   private static class Window&amp;lt;T&amp;gt;&lt;br/&gt;
       extends PTransform&amp;lt;PCollection&amp;lt;T&amp;gt;, PCollection&amp;lt;ValueInSingleWindow&amp;lt;T&amp;gt;&amp;gt;&amp;gt; {&lt;br/&gt;
@@ -184,9 +236,28 @@ private Reify() {}&lt;br/&gt;
     return new WindowInValue&amp;lt;&amp;gt;();&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  /** Extracts the timestamps from each value in a &lt;/p&gt;
{@link KV}
&lt;p&gt;. */&lt;br/&gt;
   public static &amp;lt;K, V&amp;gt;&lt;br/&gt;
       PTransform&amp;lt;PCollection&amp;lt;KV&amp;lt;K, TimestampedValue&amp;lt;V&amp;gt;&amp;gt;&amp;gt;, PCollection&amp;lt;KV&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
           extractTimestampsFromValues() &lt;/p&gt;
{
     return new ExtractTimestampsFromValues&amp;lt;&amp;gt;();
   }
&lt;p&gt;+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Pairs each element in a collection with the value of a side input associated with the element&apos;s&lt;br/&gt;
+   * window.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static &amp;lt;K, V&amp;gt; PTransform&amp;lt;PCollection&amp;lt;K&amp;gt;, PCollection&amp;lt;KV&amp;lt;K, V&amp;gt;&amp;gt;&amp;gt; viewAsValues(&lt;br/&gt;
+      PCollectionView&amp;lt;V&amp;gt; view, Coder&amp;lt;V&amp;gt; coder) &lt;/p&gt;
{
+    return new ReifyView&amp;lt;&amp;gt;(view, coder);
+  }
&lt;p&gt;+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Returns a &lt;/p&gt;
{@link PCollection}
&lt;p&gt; consisting of a single element, containing the value of the given&lt;br/&gt;
+   * view in the global window.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static &amp;lt;K, V&amp;gt; PTransform&amp;lt;PBegin, PCollection&amp;lt;V&amp;gt;&amp;gt; viewInGlobalWindow(&lt;br/&gt;
+      PCollectionView&amp;lt;V&amp;gt; view, Coder&amp;lt;V&amp;gt; coder) &lt;/p&gt;
{
+    return new ReifyViewInGlobalWindow&amp;lt;&amp;gt;(view, coder);
+  }
&lt;p&gt; }&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sample.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sample.java&lt;br/&gt;
index 2eb12d6ea96..d7cba7ecc0d 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sample.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sample.java&lt;br/&gt;
@@ -38,16 +38,27 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;{@code PCollection}, or samples of the values associated with each&lt;br/&gt;
  * key in a {@code PCollection}
&lt;p&gt; of &lt;/p&gt;
{@code KV}
&lt;p&gt;s.&lt;br/&gt;
  *&lt;br/&gt;
+ * &lt;/p&gt;
{@link #fixedSizeGlobally(int)}
&lt;p&gt; and &lt;/p&gt;
{@link #fixedSizePerKey(int)}
&lt;p&gt; compute uniformly random&lt;br/&gt;
+ * samples. &lt;/p&gt;
{@link #any(long)}
&lt;p&gt; is faster, but provides no uniformity guarantees.&lt;br/&gt;
+ *&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;
{@link #combineFn}
&lt;p&gt; can also be used manually, in combination with state and with the&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;{@link Combine}
&lt;p&gt; transform.&lt;br/&gt;
  */&lt;br/&gt;
 public class Sample {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/** Returns a 
{@link CombineFn} that computes a fixed-sized sample of its inputs. */&lt;br/&gt;
+  /** Returns a {@link CombineFn}
&lt;p&gt; that computes a fixed-sized uniform sample of its inputs. */&lt;br/&gt;
   public static &amp;lt;T&amp;gt; CombineFn&amp;lt;T, ?, Iterable&amp;lt;T&amp;gt;&amp;gt; combineFn(int sampleSize) &lt;/p&gt;
{
     return new FixedSizedSampleFn&amp;lt;&amp;gt;(sampleSize);
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  /**&lt;br/&gt;
+   * Returns a &lt;/p&gt;
{@link CombineFn}
&lt;p&gt; that computes a fixed-sized potentially non-uniform sample of its&lt;br/&gt;
+   * inputs.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static &amp;lt;T&amp;gt; CombineFn&amp;lt;T, ?, Iterable&amp;lt;T&amp;gt;&amp;gt; anyCombineFn(int sampleSize) &lt;/p&gt;
{
+    return new SampleAnyCombineFn&amp;lt;&amp;gt;(sampleSize);
+  }
&lt;p&gt;+&lt;br/&gt;
   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;{@code Sample#any(long)}
&lt;p&gt; takes a &lt;/p&gt;
{@code PCollection&amp;lt;T&amp;gt;} and a limit, and&lt;br/&gt;
    * produces a new {@code PCollection&amp;lt;T&amp;gt;}
&lt;p&gt; containing up to limit&lt;br/&gt;
@@ -233,10 +244,10 @@ private SampleAnyCombineFn(long limit) {&lt;br/&gt;
       List&amp;lt;T&amp;gt; res = iter.next();&lt;br/&gt;
       while (iter.hasNext()) {&lt;br/&gt;
         for (T t : iter.next()) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;res.add(t);&lt;br/&gt;
           if (res.size() &amp;gt;= limit) 
{
             return res;
           }
&lt;p&gt;+          res.add(t);&lt;br/&gt;
         }&lt;br/&gt;
       }&lt;br/&gt;
       return res;&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Watch.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Watch.java&lt;br/&gt;
index 75c2fe45b80..4b31ae71333 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Watch.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Watch.java&lt;br/&gt;
@@ -58,6 +58,7 @@&lt;br/&gt;
 import org.apache.beam.sdk.coders.NullableCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.StructuredCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.VarIntCoder;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Contextful.Fn;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.BoundedWindow;&lt;br/&gt;
 import org.apache.beam.sdk.values.KV;&lt;br/&gt;
@@ -117,29 +118,46 @@&lt;br/&gt;
   private static final Logger LOG = LoggerFactory.getLogger(Watch.class);&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /** Watches the growth of the given poll function. See class documentation for more details. */&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public static &amp;lt;InputT, OutputT&amp;gt; Growth&amp;lt;InputT, OutputT&amp;gt; growthOf(&lt;/li&gt;
	&lt;li&gt;Contextful&amp;lt;Growth.PollFn&amp;lt;InputT, OutputT&amp;gt;&amp;gt; pollFn) 
{
-    return new AutoValue_Watch_Growth.Builder&amp;lt;InputT, OutputT&amp;gt;()
-        .setTerminationPerInput(Watch.Growth.&amp;lt;InputT&amp;gt;never())
-        .setPollFn(pollFn)
-        .build();
-  }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;/** Watches the growth of the given poll function. See class documentation for more details. */&lt;/li&gt;
	&lt;li&gt;public static &amp;lt;InputT, OutputT&amp;gt; Growth&amp;lt;InputT, OutputT&amp;gt; growthOf(&lt;br/&gt;
+  public static &amp;lt;InputT, OutputT&amp;gt; Growth&amp;lt;InputT, OutputT, OutputT&amp;gt; growthOf(&lt;br/&gt;
       Growth.PollFn&amp;lt;InputT, OutputT&amp;gt; pollFn, Requirements requirements) 
{
-    return growthOf(Contextful.of(pollFn, requirements));
+    return new AutoValue_Watch_Growth.Builder&amp;lt;InputT, OutputT, OutputT&amp;gt;()
+        .setTerminationPerInput(Growth.&amp;lt;InputT&amp;gt;never())
+        .setPollFn(Contextful.of(pollFn, requirements))
+        // use null as a signal that this is the identity function and output coder can be
+        // reused as key coder
+        .setOutputKeyFn(null)
+        .build();
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /** Watches the growth of the given poll function. See class documentation for more details. */&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public static &amp;lt;InputT, OutputT&amp;gt; Growth&amp;lt;InputT, OutputT&amp;gt; growthOf(&lt;br/&gt;
+  public static &amp;lt;InputT, OutputT&amp;gt; Growth&amp;lt;InputT, OutputT, OutputT&amp;gt; growthOf(&lt;br/&gt;
       Growth.PollFn&amp;lt;InputT, OutputT&amp;gt; pollFn) 
{
     return growthOf(pollFn, Requirements.empty());
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;+  /**&lt;br/&gt;
+   * Watches the growth of the given poll function, using the given &quot;key function&quot; to deduplicate&lt;br/&gt;
+   * outputs. For example, if OutputT is a filename + file size, this can be a function that returns&lt;br/&gt;
+   * just the filename, so that if the same file is observed multiple times with different sizes,&lt;br/&gt;
+   * only the first observation is emitted.&lt;br/&gt;
+   *&lt;br/&gt;
+   * &amp;lt;p&amp;gt;By default, this is the identity function, i.e. the output is used as its own key.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static &amp;lt;InputT, OutputT, KeyT&amp;gt; Growth&amp;lt;InputT, OutputT, KeyT&amp;gt; growthOf(&lt;br/&gt;
+      Contextful&amp;lt;Growth.PollFn&amp;lt;InputT, OutputT&amp;gt;&amp;gt; pollFn,&lt;br/&gt;
+      SerializableFunction&amp;lt;OutputT, KeyT&amp;gt; outputKeyFn) &lt;/p&gt;
{
+    checkArgument(pollFn != null, &quot;pollFn can not be null&quot;);
+    checkArgument(outputKeyFn != null, &quot;outputKeyFn can not be null&quot;);
+    return new AutoValue_Watch_Growth.Builder&amp;lt;InputT, OutputT, KeyT&amp;gt;()
+        .setTerminationPerInput(Watch.Growth.&amp;lt;InputT&amp;gt;never())
+        .setPollFn(pollFn)
+        .setOutputKeyFn(outputKeyFn)
+        .build();
+  }
&lt;p&gt;+&lt;br/&gt;
   /** Implementation of &lt;/p&gt;
{@link #growthOf}
&lt;p&gt;. */&lt;br/&gt;
   @AutoValue&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public abstract static class Growth&amp;lt;InputT, OutputT&amp;gt;&lt;br/&gt;
+  public abstract static class Growth&amp;lt;InputT, OutputT, KeyT&amp;gt;&lt;br/&gt;
       extends PTransform&amp;lt;PCollection&amp;lt;InputT&amp;gt;, PCollection&amp;lt;KV&amp;lt;InputT, OutputT&amp;gt;&amp;gt;&amp;gt; {&lt;br/&gt;
     /** The result of a single invocation of a 
{@link PollFn}. */&lt;br/&gt;
     public static final class PollResult&amp;lt;OutputT&amp;gt; {&lt;br/&gt;
@@ -219,7 +237,7 @@ Instant getWatermark() {&lt;br/&gt;
      * {@link PollResult}.&lt;br/&gt;
      */&lt;br/&gt;
     public abstract static class PollFn&amp;lt;InputT, OutputT&amp;gt;&lt;br/&gt;
-        implements Contextful.Fn&amp;lt;InputT, PollResult&amp;lt;OutputT&amp;gt;&amp;gt; {}&lt;br/&gt;
+        implements Fn&amp;lt;InputT, PollResult&amp;lt;OutputT&amp;gt;&amp;gt; {}&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
      * A strategy for determining whether it is time to stop polling the current input regardless of&lt;br/&gt;
@@ -550,6 +568,12 @@ public String toString(KV&amp;lt;FirstStateT, SecondStateT&amp;gt; state) {&lt;br/&gt;
 &lt;br/&gt;
     abstract Contextful&amp;lt;PollFn&amp;lt;InputT, OutputT&amp;gt;&amp;gt; getPollFn();&lt;br/&gt;
 &lt;br/&gt;
+    @Nullable&lt;br/&gt;
+    abstract SerializableFunction&amp;lt;OutputT, KeyT&amp;gt; getOutputKeyFn();&lt;br/&gt;
+&lt;br/&gt;
+    @Nullable&lt;br/&gt;
+    abstract Coder&amp;lt;KeyT&amp;gt; getOutputKeyCoder();&lt;br/&gt;
+&lt;br/&gt;
     @Nullable&lt;br/&gt;
     abstract Duration getPollInterval();&lt;br/&gt;
 &lt;br/&gt;
@@ -559,24 +583,34 @@ public String toString(KV&amp;lt;FirstStateT, SecondStateT&amp;gt; state) {&lt;br/&gt;
     @Nullable&lt;br/&gt;
     abstract Coder&amp;lt;OutputT&amp;gt; getOutputCoder();&lt;br/&gt;
 &lt;br/&gt;
-    abstract Builder&amp;lt;InputT, OutputT&amp;gt; toBuilder();&lt;br/&gt;
+    abstract Builder&amp;lt;InputT, OutputT, KeyT&amp;gt; toBuilder();&lt;br/&gt;
 &lt;br/&gt;
     @AutoValue.Builder&lt;br/&gt;
-    abstract static class Builder&amp;lt;InputT, OutputT&amp;gt; {&lt;br/&gt;
-      abstract Builder&amp;lt;InputT, OutputT&amp;gt; setPollFn(Contextful&amp;lt;PollFn&amp;lt;InputT, OutputT&amp;gt;&amp;gt; pollFn);&lt;br/&gt;
+    abstract static class Builder&amp;lt;InputT, OutputT, KeyT&amp;gt; {
+      abstract Builder&amp;lt;InputT, OutputT, KeyT&amp;gt; setPollFn(Contextful&amp;lt;PollFn&amp;lt;InputT, OutputT&amp;gt;&amp;gt; pollFn);
+
+      abstract Builder&amp;lt;InputT, OutputT, KeyT&amp;gt; setOutputKeyFn(
+          @Nullable SerializableFunction&amp;lt;OutputT, KeyT&amp;gt; outputKeyFn);
 
-      abstract Builder&amp;lt;InputT, OutputT&amp;gt; setTerminationPerInput(
+      abstract Builder&amp;lt;InputT, OutputT, KeyT&amp;gt; setOutputKeyCoder(Coder&amp;lt;KeyT&amp;gt; outputKeyCoder);
+
+      abstract Builder&amp;lt;InputT, OutputT, KeyT&amp;gt; setTerminationPerInput(
           TerminationCondition&amp;lt;InputT, ?&amp;gt; terminationPerInput);
 
-      abstract Builder&amp;lt;InputT, OutputT&amp;gt; setPollInterval(Duration pollInterval);
+      abstract Builder&amp;lt;InputT, OutputT, KeyT&amp;gt; setPollInterval(Duration pollInterval);
+
+      abstract Builder&amp;lt;InputT, OutputT, KeyT&amp;gt; setOutputCoder(Coder&amp;lt;OutputT&amp;gt; outputCoder);
 
-      abstract Builder&amp;lt;InputT, OutputT&amp;gt; setOutputCoder(Coder&amp;lt;OutputT&amp;gt; outputCoder);
+      abstract Growth&amp;lt;InputT, OutputT, KeyT&amp;gt; build();
+    }&lt;br/&gt;
 &lt;br/&gt;
-      abstract Growth&amp;lt;InputT, OutputT&amp;gt; build();&lt;br/&gt;
+    /** Specifies the coder for the output key. */&lt;br/&gt;
+    public Growth&amp;lt;InputT, OutputT, KeyT&amp;gt; withOutputKeyCoder(Coder&amp;lt;KeyT&amp;gt; outputKeyCoder) {
+      return toBuilder().setOutputKeyCoder(outputKeyCoder).build();
     }&lt;br/&gt;
 &lt;br/&gt;
     /** Specifies a {@link TerminationCondition} that will be independently used for every input. */&lt;br/&gt;
-    public Growth&amp;lt;InputT, OutputT&amp;gt; withTerminationPerInput(&lt;br/&gt;
+    public Growth&amp;lt;InputT, OutputT, KeyT&amp;gt; withTerminationPerInput(&lt;br/&gt;
         TerminationCondition&amp;lt;InputT, ?&amp;gt; terminationPerInput) {
       return toBuilder().setTerminationPerInput(terminationPerInput).build();
     }&lt;br/&gt;
@@ -585,7 +619,7 @@ public String toString(KV&amp;lt;FirstStateT, SecondStateT&amp;gt; state) {&lt;br/&gt;
      * Specifies how long to wait after a call to {@link PollFn}
&lt;p&gt; before calling it again (if at all&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;- according to 
{@link PollResult}
&lt;p&gt; and the &lt;/p&gt;
{@link TerminationCondition}
&lt;p&gt;).&lt;br/&gt;
      */&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Growth&amp;lt;InputT, OutputT&amp;gt; withPollInterval(Duration pollInterval) {&lt;br/&gt;
+    public Growth&amp;lt;InputT, OutputT, KeyT&amp;gt; withPollInterval(Duration pollInterval) 
{
       return toBuilder().setPollInterval(pollInterval).build();
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -596,7 +630,7 @@ public String toString(KV&amp;lt;FirstStateT, SecondStateT&amp;gt; state) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;The coder must be deterministic, because the transform will compare encoded outputs for&lt;/li&gt;
	&lt;li&gt;deduplication between polling rounds.&lt;br/&gt;
      */&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public Growth&amp;lt;InputT, OutputT&amp;gt; withOutputCoder(Coder&amp;lt;OutputT&amp;gt; outputCoder) {&lt;br/&gt;
+    public Growth&amp;lt;InputT, OutputT, KeyT&amp;gt; withOutputCoder(Coder&amp;lt;OutputT&amp;gt; outputCoder) 
{
       return toBuilder().setOutputCoder(outputCoder).build();
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -618,36 +652,68 @@ public String toString(KV&amp;lt;FirstStateT, SecondStateT&amp;gt; state) &lt;/p&gt;
{
           outputCoder = input.getPipeline().getCoderRegistry().getCoder(outputT);
         }
&lt;p&gt; catch (CannotProvideCoderException e) &lt;/p&gt;
{
           throw new RuntimeException(
-              &quot;Unable to infer coder for OutputT. Specify it explicitly using withOutputCoder().&quot;);
+              &quot;Unable to infer coder for OutputT (&quot;
+                  + outputT
+                  + &quot;). Specify it explicitly using withOutputCoder().&quot;);
         }
&lt;p&gt;       }&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;try 
{
-        outputCoder.verifyDeterministic();
-      }
&lt;p&gt; catch (Coder.NonDeterministicException e) {&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;throw new IllegalArgumentException(&lt;/li&gt;
	&lt;li&gt;&quot;Output coder &quot; + outputCoder + &quot; must be deterministic&quot;);&lt;br/&gt;
+&lt;br/&gt;
+      Coder&amp;lt;KeyT&amp;gt; outputKeyCoder = getOutputKeyCoder();&lt;br/&gt;
+      SerializableFunction&amp;lt;OutputT, KeyT&amp;gt; outputKeyFn = getOutputKeyFn();&lt;br/&gt;
+      if (getOutputKeyFn() == null) 
{
+        // This by construction can happen only if OutputT == KeyT
+        outputKeyCoder = (Coder) outputCoder;
+        outputKeyFn = (SerializableFunction) SerializableFunctions.identity();
+      }
&lt;p&gt; else {&lt;br/&gt;
+        if (outputKeyCoder == null) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+          // If a coder was not specified explicitly, infer it from the OutputT type parameter+          // of the output key fn.+          TypeDescriptor&amp;lt;KeyT&amp;gt; keyT = TypeDescriptors.outputOf(getOutputKeyFn());+          try {
+            outputKeyCoder = input.getPipeline().getCoderRegistry().getCoder(keyT);
+          } catch (CannotProvideCoderException e) {
+            throw new RuntimeException(
+                &quot;Unable to infer coder for KeyT (&quot;
+                    + keyT
+                    + &quot;). Specify it explicitly using withOutputKeyCoder().&quot;);
+          }+        }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+        try &lt;/p&gt;
{
+          outputKeyCoder.verifyDeterministic();
+        }
&lt;p&gt; catch (Coder.NonDeterministicException e) &lt;/p&gt;
{
+          throw new IllegalArgumentException(
+              &quot;Key coder &quot; + outputKeyCoder + &quot; must be deterministic&quot;);
+        }
&lt;p&gt;       }&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       return input&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.apply(ParDo.of(new WatchGrowthFn&amp;lt;&amp;gt;(this, outputCoder))&lt;br/&gt;
+          .apply(ParDo.of(new WatchGrowthFn&amp;lt;&amp;gt;(this, outputCoder, outputKeyFn, outputKeyCoder))&lt;br/&gt;
           .withSideInputs(getPollFn().getRequirements().getSideInputs()))&lt;br/&gt;
           .setCoder(KvCoder.of(input.getCoder(), outputCoder));&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class WatchGrowthFn&amp;lt;InputT, OutputT, TerminationStateT&amp;gt;&lt;br/&gt;
+  private static class WatchGrowthFn&amp;lt;InputT, OutputT, KeyT, TerminationStateT&amp;gt;&lt;br/&gt;
       extends DoFn&amp;lt;InputT, KV&amp;lt;InputT, OutputT&amp;gt;&amp;gt; {&lt;/li&gt;
	&lt;li&gt;private final Watch.Growth&amp;lt;InputT, OutputT&amp;gt; spec;&lt;br/&gt;
+    private final Watch.Growth&amp;lt;InputT, OutputT, KeyT&amp;gt; spec;&lt;br/&gt;
     private final Coder&amp;lt;OutputT&amp;gt; outputCoder;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private WatchGrowthFn(Growth&amp;lt;InputT, OutputT&amp;gt; spec, Coder&amp;lt;OutputT&amp;gt; outputCoder) {&lt;br/&gt;
+    private final SerializableFunction&amp;lt;OutputT, KeyT&amp;gt; outputKeyFn;&lt;br/&gt;
+    private final Coder&amp;lt;KeyT&amp;gt; outputKeyCoder;&lt;br/&gt;
+&lt;br/&gt;
+    private WatchGrowthFn(&lt;br/&gt;
+        Growth&amp;lt;InputT, OutputT, KeyT&amp;gt; spec,&lt;br/&gt;
+        Coder&amp;lt;OutputT&amp;gt; outputCoder,&lt;br/&gt;
+        SerializableFunction&amp;lt;OutputT, KeyT&amp;gt; outputKeyFn,&lt;br/&gt;
+        Coder&amp;lt;KeyT&amp;gt; outputKeyCoder) 
{
       this.spec = spec;
       this.outputCoder = outputCoder;
+      this.outputKeyFn = outputKeyFn;
+      this.outputKeyCoder = outputKeyCoder;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @ProcessElement&lt;br/&gt;
     public ProcessContinuation process(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ProcessContext c, final GrowthTracker&amp;lt;OutputT, TerminationStateT&amp;gt; tracker)&lt;br/&gt;
+        ProcessContext c, final GrowthTracker&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; tracker)&lt;br/&gt;
         throws Exception {&lt;br/&gt;
       if (!tracker.hasPending() &amp;amp;&amp;amp; !tracker.currentRestriction().isOutputComplete) {&lt;br/&gt;
         LOG.debug(&quot;{} - polling input&quot;, c.element());&lt;br/&gt;
@@ -700,26 +766,27 @@ public ProcessContinuation process(&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @GetInitialRestriction&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; getInitialRestriction(InputT element) {&lt;br/&gt;
+    public GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; getInitialRestriction(InputT element) 
{
       return new GrowthState&amp;lt;&amp;gt;(getTerminationCondition().forNewInput(Instant.now(), element));
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @NewTracker&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;public GrowthTracker&amp;lt;OutputT, TerminationStateT&amp;gt; newTracker(&lt;/li&gt;
	&lt;li&gt;GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; restriction) {&lt;/li&gt;
	&lt;li&gt;return new GrowthTracker&amp;lt;&amp;gt;(outputCoder, restriction, getTerminationCondition());&lt;br/&gt;
+    public GrowthTracker&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; newTracker(&lt;br/&gt;
+        GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; restriction) 
{
+      return new GrowthTracker&amp;lt;&amp;gt;(
+          outputKeyFn, outputKeyCoder, restriction, getTerminationCondition());
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @GetRestrictionCoder&lt;br/&gt;
     @SuppressWarnings(&lt;/p&gt;
{&quot;unchecked&quot;, &quot;rawtypes&quot;})&lt;br/&gt;
-    public Coder&amp;lt;GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt;&amp;gt; getRestrictionCoder() {&lt;br/&gt;
+    public Coder&amp;lt;GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt;&amp;gt; getRestrictionCoder() {
       return GrowthStateCoder.of(
           outputCoder, (Coder) spec.getTerminationPerInput().getStateCoder());
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   @VisibleForTesting&lt;br/&gt;
-  static class GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; {&lt;br/&gt;
+  static class GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; {
     // Hashes and timestamps of outputs that have already been output and should be omitted
     // from future polls. Timestamps are preserved to allow garbage-collecting this state
     // in the future, e.g. dropping elements from &quot;completed&quot; and from addNewAsPending() if their
@@ -781,14 +848,14 @@ public String toString(Growth.TerminationCondition&amp;lt;?, TerminationStateT&amp;gt; termina
   }&lt;br/&gt;
 &lt;br/&gt;
   @VisibleForTesting&lt;br/&gt;
-  static class GrowthTracker&amp;lt;OutputT, TerminationStateT&amp;gt;&lt;br/&gt;
-      implements RestrictionTracker&amp;lt;GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt;&amp;gt; {&lt;br/&gt;
+  static class GrowthTracker&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt;&lt;br/&gt;
+      implements RestrictionTracker&amp;lt;GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt;&amp;gt; {&lt;br/&gt;
     private final Funnel&amp;lt;OutputT&amp;gt; coderFunnel;&lt;br/&gt;
     private final Growth.TerminationCondition&amp;lt;?, TerminationStateT&amp;gt; terminationCondition;&lt;br/&gt;
 &lt;br/&gt;
     // The restriction describing the entire work to be done by the current ProcessElement call.&lt;br/&gt;
     // Changes only in checkpoint().&lt;br/&gt;
-    private GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; state;&lt;br/&gt;
+    private GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; state;&lt;br/&gt;
 &lt;br/&gt;
     // Mutable state changed by the ProcessElement call itself, and used to compute the primary&lt;br/&gt;
     // and residual restrictions in checkpoint().&lt;br/&gt;
@@ -803,14 +870,19 @@ public String toString(Growth.TerminationCondition&amp;lt;?, TerminationStateT&amp;gt; termina&lt;br/&gt;
     @Nullable private Instant pollWatermark;&lt;br/&gt;
     private boolean shouldStop = false;&lt;br/&gt;
 &lt;br/&gt;
-    GrowthTracker(final Coder&amp;lt;OutputT&amp;gt; outputCoder, GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; state,&lt;br/&gt;
-                  Growth.TerminationCondition&amp;lt;?, TerminationStateT&amp;gt; terminationCondition) {&lt;br/&gt;
+    GrowthTracker(&lt;br/&gt;
+        final SerializableFunction&amp;lt;OutputT, KeyT&amp;gt; keyFn,&lt;br/&gt;
+        final Coder&amp;lt;KeyT&amp;gt; outputKeyCoder,&lt;br/&gt;
+        GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; state,&lt;br/&gt;
+        Growth.TerminationCondition&amp;lt;?, TerminationStateT&amp;gt; terminationCondition) {&lt;br/&gt;
       this.coderFunnel =&lt;br/&gt;
           new Funnel&amp;lt;OutputT&amp;gt;() {&lt;br/&gt;
             @Override&lt;br/&gt;
             public void funnel(OutputT from, PrimitiveSink into) {&lt;br/&gt;
               try {
-                outputCoder.encode(from, Funnels.asOutputStream(into));
+                // Rather than hashing the output itself, hash the output key.
+                KeyT outputKey = keyFn.apply(from);
+                outputKeyCoder.encode(outputKey, Funnels.asOutputStream(into));
               } catch (IOException e) {
                 throw new RuntimeException(e);
               }&lt;br/&gt;
@@ -825,15 +897,15 @@ public void funnel(OutputT from, PrimitiveSink into) {&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
-    public synchronized GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; currentRestriction() {&lt;br/&gt;
+    public synchronized GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; currentRestriction() {
       return state;
     }&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
-    public synchronized GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; checkpoint() {&lt;br/&gt;
+    public synchronized GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; checkpoint() {&lt;br/&gt;
       // primary should contain exactly the work claimed in the current ProcessElement call - i.e.&lt;br/&gt;
       // claimed outputs become pending, and it shouldn&apos;t poll again.&lt;br/&gt;
-      GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; primary =&lt;br/&gt;
+      GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; primary =&lt;br/&gt;
           new GrowthState&amp;lt;&amp;gt;(&lt;br/&gt;
               state.completed /* completed */,&lt;br/&gt;
               claimed /* pending */,&lt;br/&gt;
@@ -845,9 +917,10 @@ public void funnel(OutputT from, PrimitiveSink into) {&lt;br/&gt;
       // unclaimed pending outputs plus future polling outputs.&lt;br/&gt;
       Map&amp;lt;HashCode, Instant&amp;gt; newCompleted = Maps.newHashMap(state.completed);&lt;br/&gt;
       for (TimestampedValue&amp;lt;OutputT&amp;gt; claimedOutput : claimed) {
-        newCompleted.put(hash128(claimedOutput.getValue()), claimedOutput.getTimestamp());
+        newCompleted.put(
+            hash128(claimedOutput.getValue()), claimedOutput.getTimestamp());
       }&lt;br/&gt;
-      GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; residual =&lt;br/&gt;
+      GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; residual =&lt;br/&gt;
           new GrowthState&amp;lt;&amp;gt;(&lt;br/&gt;
               newCompleted /* completed */,&lt;br/&gt;
               pending /* pending */,&lt;br/&gt;
@@ -910,10 +983,14 @@ synchronized int addNewAsPending(Growth.PollResult&amp;lt;OutputT&amp;gt; pollResult) {&lt;br/&gt;
           &quot;Should have drained all old pending outputs before adding new, &quot;&lt;br/&gt;
               + &quot;but there are %s old pending outputs&quot;,&lt;br/&gt;
           state.pending.size());&lt;br/&gt;
-      List&amp;lt;TimestampedValue&amp;lt;OutputT&amp;gt;&amp;gt; newPending = Lists.newArrayList();&lt;br/&gt;
+      // Collect results to include as newly pending. Note that the poll result may in theory&lt;br/&gt;
+      // contain multiple outputs mapping to the the same output key - we need to ignore duplicates&lt;br/&gt;
+      // here already.&lt;br/&gt;
+      Map&amp;lt;HashCode, TimestampedValue&amp;lt;OutputT&amp;gt;&amp;gt; newPending = Maps.newHashMap();&lt;br/&gt;
       for (TimestampedValue&amp;lt;OutputT&amp;gt; output : pollResult.getOutputs()) {&lt;br/&gt;
         OutputT value = output.getValue();&lt;br/&gt;
-        if (state.completed.containsKey(hash128(value))) {&lt;br/&gt;
+        HashCode hash = hash128(value);&lt;br/&gt;
+        if (state.completed.containsKey(hash) || newPending.containsKey(hash)) {
           continue;
         }&lt;br/&gt;
         // TODO (&lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-2680):&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/BEAM-2680):&lt;/a&gt;&lt;br/&gt;
@@ -921,7 +998,7 @@ synchronized int addNewAsPending(Growth.PollResult&amp;lt;OutputT&amp;gt; pollResult) {
         // instead relying on future poll rounds to provide them, in order to avoid
         // blowing up the state. Combined with garbage collection of GrowthState.completed,
         // this would make the transform scalable to very large poll results.
-        newPending.add(TimestampedValue.of(value, output.getTimestamp()));
+        newPending.put(hash, TimestampedValue.of(value, output.getTimestamp()));
       }&lt;br/&gt;
       if (!newPending.isEmpty()) {&lt;br/&gt;
         terminationState = terminationCondition.onSeenNewOutput(Instant.now(), terminationState);&lt;br/&gt;
@@ -936,7 +1013,7 @@ public Instant apply(TimestampedValue&amp;lt;OutputT&amp;gt; output) {
                           return output.getTimestamp();
                         }&lt;br/&gt;
                       })&lt;br/&gt;
-                  .sortedCopy(newPending));&lt;br/&gt;
+                  .sortedCopy(newPending.values()));&lt;br/&gt;
       // If poll result doesn&apos;t provide a watermark, assume that future new outputs may&lt;br/&gt;
       // arrive with about the same timestamps as the current new outputs.&lt;br/&gt;
       if (pollResult.getWatermark() != null) {&lt;br/&gt;
@@ -1008,10 +1085,11 @@ public HashCode decode(InputStream is) throws IOException {&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
-  private static class GrowthStateCoder&amp;lt;OutputT, TerminationStateT&amp;gt;&lt;br/&gt;
-      extends StructuredCoder&amp;lt;GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt;&amp;gt; {&lt;br/&gt;
-    public static &amp;lt;OutputT, TerminationStateT&amp;gt; GrowthStateCoder&amp;lt;OutputT, TerminationStateT&amp;gt; of(&lt;br/&gt;
-        Coder&amp;lt;OutputT&amp;gt; outputCoder, Coder&amp;lt;TerminationStateT&amp;gt; terminationStateCoder) {&lt;br/&gt;
+  private static class GrowthStateCoder&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt;&lt;br/&gt;
+      extends StructuredCoder&amp;lt;GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt;&amp;gt; {&lt;br/&gt;
+    public static &amp;lt;OutputT, KeyT, TerminationStateT&amp;gt;&lt;br/&gt;
+        GrowthStateCoder&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; of(&lt;br/&gt;
+            Coder&amp;lt;OutputT&amp;gt; outputCoder, Coder&amp;lt;TerminationStateT&amp;gt; terminationStateCoder) {
       return new GrowthStateCoder&amp;lt;&amp;gt;(outputCoder, terminationStateCoder);
     }&lt;br/&gt;
 &lt;br/&gt;
@@ -1033,7 +1111,7 @@ private GrowthStateCoder(&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
-    public void encode(GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; value, OutputStream os)&lt;br/&gt;
+    public void encode(GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; value, OutputStream os)&lt;br/&gt;
         throws IOException {
       completedCoder.encode(value.completed, os);
       pendingCoder.encode(value.pending, os);
@@ -1043,7 +1121,7 @@ public void encode(GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; value, OutputStream o
     }&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
-    public GrowthState&amp;lt;OutputT, TerminationStateT&amp;gt; decode(InputStream is) throws IOException {&lt;br/&gt;
+    public GrowthState&amp;lt;OutputT, KeyT, TerminationStateT&amp;gt; decode(InputStream is) throws IOException {&lt;br/&gt;
       Map&amp;lt;HashCode, Instant&amp;gt; completed = completedCoder.decode(is);&lt;br/&gt;
       List&amp;lt;TimestampedValue&amp;lt;OutputT&amp;gt;&amp;gt; pending = pendingCoder.decode(is);&lt;br/&gt;
       boolean isOutputComplete = BOOLEAN_CODER.decode(is);&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/reflect/DoFnSignature.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/reflect/DoFnSignature.java&lt;br/&gt;
index bfad69ea776..1e126611452 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/reflect/DoFnSignature.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/reflect/DoFnSignature.java&lt;br/&gt;
@@ -426,6 +426,12 @@ public static TimerParameter timerParameter(TimerDeclaration decl) {&lt;br/&gt;
     @Override&lt;br/&gt;
     public abstract List&amp;lt;Parameter&amp;gt; extraParameters();&lt;br/&gt;
 &lt;br/&gt;
+    /**&lt;br/&gt;
+     * Whether this method requires stable input, expressed via {@link
+     * org.apache.beam.sdk.transforms.DoFn.RequiresStableInput}.&lt;br/&gt;
+     */&lt;br/&gt;
+    public abstract boolean requiresStableInput();&lt;br/&gt;
+&lt;br/&gt;
     /** Concrete type of the {@link RestrictionTracker} parameter, if present. */&lt;br/&gt;
     @Nullable&lt;br/&gt;
     public abstract TypeDescriptor&amp;lt;?&amp;gt; trackerT();&lt;br/&gt;
@@ -440,12 +446,14 @@ public static TimerParameter timerParameter(TimerDeclaration decl) {&lt;br/&gt;
     static ProcessElementMethod create(&lt;br/&gt;
         Method targetMethod,&lt;br/&gt;
         List&amp;lt;Parameter&amp;gt; extraParameters,&lt;br/&gt;
+        boolean requiresStableInput,&lt;br/&gt;
         TypeDescriptor&amp;lt;?&amp;gt; trackerT,&lt;br/&gt;
         @Nullable TypeDescriptor&amp;lt;? extends BoundedWindow&amp;gt; windowT,&lt;br/&gt;
         boolean hasReturnValue) {&lt;br/&gt;
       return new AutoValue_DoFnSignature_ProcessElementMethod(&lt;br/&gt;
           targetMethod,&lt;br/&gt;
           Collections.unmodifiableList(extraParameters),&lt;br/&gt;
+          requiresStableInput,&lt;br/&gt;
           trackerT,&lt;br/&gt;
           windowT,&lt;br/&gt;
           hasReturnValue);&lt;br/&gt;
@@ -487,6 +495,13 @@ public boolean isSplittable() {&lt;br/&gt;
     @Override&lt;br/&gt;
     public abstract Method targetMethod();&lt;br/&gt;
 &lt;br/&gt;
+    /**&lt;br/&gt;
+     * Whether this method requires stable input, expressed via {@link+     * org.apache.beam.sdk.transforms.DoFn.RequiresStableInput}. For timers, this means that any&lt;br/&gt;
+     * state must be stably persisted prior to calling it.&lt;br/&gt;
+     */&lt;br/&gt;
+    public abstract boolean requiresStableInput();&lt;br/&gt;
+&lt;br/&gt;
     /** The window type used by this method, if any. */&lt;br/&gt;
     @Nullable&lt;br/&gt;
     public abstract TypeDescriptor&amp;lt;? extends BoundedWindow&amp;gt; windowT();&lt;br/&gt;
@@ -498,10 +513,15 @@ public boolean isSplittable() {&lt;br/&gt;
     static OnTimerMethod create(&lt;br/&gt;
         Method targetMethod,&lt;br/&gt;
         String id,&lt;br/&gt;
+        boolean requiresStableInput,&lt;br/&gt;
         TypeDescriptor&amp;lt;? extends BoundedWindow&amp;gt; windowT,&lt;br/&gt;
         List&amp;lt;Parameter&amp;gt; extraParameters) {
       return new AutoValue_DoFnSignature_OnTimerMethod(
-          id, targetMethod, windowT, Collections.unmodifiableList(extraParameters));
+          id,
+          targetMethod,
+          requiresStableInput,
+          windowT,
+          Collections.unmodifiableList(extraParameters));
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/reflect/DoFnSignatures.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/reflect/DoFnSignatures.java&lt;br/&gt;
index 52607833f71..98742be3cbb 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/reflect/DoFnSignatures.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/reflect/DoFnSignatures.java&lt;br/&gt;
@@ -679,6 +679,8 @@ private static void verifyUnsplittableMethods(ErrorReporter errors, DoFnSignatur&lt;br/&gt;
 &lt;br/&gt;
     MethodAnalysisContext methodContext = MethodAnalysisContext.create();&lt;br/&gt;
 &lt;br/&gt;
+    boolean requiresStableInput = m.isAnnotationPresent(DoFn.RequiresStableInput.class);&lt;br/&gt;
+&lt;br/&gt;
     @Nullable TypeDescriptor&amp;lt;? extends BoundedWindow&amp;gt; windowT = getWindowType(fnClass, m);&lt;br/&gt;
 &lt;br/&gt;
     List&amp;lt;DoFnSignature.Parameter&amp;gt; extraParameters = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
@@ -706,7 +708,8 @@ private static void verifyUnsplittableMethods(ErrorReporter errors, DoFnSignatur&lt;br/&gt;
       extraParameters.add(parameter);&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
-    return DoFnSignature.OnTimerMethod.create(m, timerId, windowT, extraParameters);&lt;br/&gt;
+    return DoFnSignature.OnTimerMethod.create(&lt;br/&gt;
+        m, timerId, requiresStableInput, windowT, extraParameters);&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   @VisibleForTesting&lt;br/&gt;
@@ -723,9 +726,10 @@ private static void verifyUnsplittableMethods(ErrorReporter errors, DoFnSignatur&lt;br/&gt;
         &quot;Must return void or %s&quot;,&lt;br/&gt;
         DoFn.ProcessContinuation.class.getSimpleName());&lt;br/&gt;
 &lt;br/&gt;
-&lt;br/&gt;
     MethodAnalysisContext methodContext = MethodAnalysisContext.create();&lt;br/&gt;
 &lt;br/&gt;
+    boolean requiresStableInput = m.isAnnotationPresent(DoFn.RequiresStableInput.class);&lt;br/&gt;
+&lt;br/&gt;
     Type[] params = m.getGenericParameterTypes();&lt;br/&gt;
 &lt;br/&gt;
     TypeDescriptor&amp;lt;?&amp;gt; trackerT = getTrackerType(fnClass, m);&lt;br/&gt;
@@ -763,6 +767,7 @@ private static void verifyUnsplittableMethods(ErrorReporter errors, DoFnSignatur&lt;br/&gt;
     return DoFnSignature.ProcessElementMethod.create(&lt;br/&gt;
         m,&lt;br/&gt;
         methodContext.getExtraParameters(),&lt;br/&gt;
+        requiresStableInput,&lt;br/&gt;
         trackerT,&lt;br/&gt;
         windowT,&lt;br/&gt;
         DoFn.ProcessContinuation.class.equals(m.getReturnType()));&lt;br/&gt;
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/values/TypeDescriptors.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/values/TypeDescriptors.java&lt;br/&gt;
index e59f84bb328..8ef2a4deaee 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/main/java/org/apache/beam/sdk/values/TypeDescriptors.java&lt;br/&gt;
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/values/TypeDescriptors.java&lt;br/&gt;
@@ -291,6 +291,10 @@&lt;br/&gt;
     return typeDescriptor;&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
+  public static TypeDescriptor&amp;lt;Void&amp;gt; voids() {&lt;br/&gt;
+    return new TypeDescriptor&amp;lt;Void&amp;gt;() {};&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   /**&lt;br/&gt;
    * A helper interface for use with {@link #extractFromTypeParameters(Object, Class,
    * TypeVariableExtractor)}.&lt;br/&gt;
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/io/FileBasedSinkTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/io/FileBasedSinkTest.java&lt;br/&gt;
index 29f3c1be7f0..0c9bdc1ddec 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/test/java/org/apache/beam/sdk/io/FileBasedSinkTest.java&lt;br/&gt;
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/io/FileBasedSinkTest.java&lt;br/&gt;
@@ -27,7 +27,6 @@&lt;br/&gt;
 import static org.junit.Assert.fail;&lt;br/&gt;
 &lt;br/&gt;
 import com.google.common.collect.Lists;&lt;br/&gt;
-import com.google.common.collect.Sets;&lt;br/&gt;
 import java.io.BufferedReader;&lt;br/&gt;
 import java.io.File;&lt;br/&gt;
 import java.io.FileInputStream;&lt;br/&gt;
@@ -45,7 +44,6 @@&lt;br/&gt;
 import java.util.Arrays;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
-import java.util.Set;&lt;br/&gt;
 import java.util.zip.GZIPInputStream;&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink.CompressionType;&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink.FileResult;&lt;br/&gt;
@@ -54,6 +52,8 @@&lt;br/&gt;
 import org.apache.beam.sdk.io.FileBasedSink.Writer;&lt;br/&gt;
 import org.apache.beam.sdk.io.fs.ResolveOptions.StandardResolveOptions;&lt;br/&gt;
 import org.apache.beam.sdk.io.fs.ResourceId;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.windowing.GlobalWindow;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.windowing.PaneInfo;&lt;br/&gt;
 import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream;&lt;br/&gt;
 import org.apache.commons.compress.compressors.deflate.DeflateCompressorInputStream;&lt;br/&gt;
@@ -102,14 +102,12 @@ public void testWriter() throws Exception {&lt;br/&gt;
 &lt;br/&gt;
     SimpleSink.SimpleWriter&amp;lt;Void&amp;gt; writer =&lt;br/&gt;
         buildWriteOperationWithTempDir(getBaseTempDirectory()).createWriter();&lt;br/&gt;
-    writer.openUnwindowed(testUid, -1, null);&lt;br/&gt;
+    writer.open(testUid);&lt;br/&gt;
     for (String value : values) {
       writer.write(value);
     }&lt;br/&gt;
-    FileResult result = writer.close();&lt;br/&gt;
-&lt;br/&gt;
-    FileBasedSink sink = writer.getWriteOperation().getSink();&lt;br/&gt;
-    assertEquals(expectedTempFile, result.getTempFilename());&lt;br/&gt;
+    writer.close();&lt;br/&gt;
+    assertEquals(expectedTempFile, writer.getOutputFile());&lt;br/&gt;
     assertFileContains(expected, expectedTempFile);&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
@@ -200,20 +198,15 @@ private void runFinalize(SimpleSink.SimpleWriteOperation&amp;lt;Void&amp;gt; writeOp, List&amp;lt;Fil&lt;br/&gt;
           new FileResult&amp;lt;Void&amp;gt;(&lt;br/&gt;
               LocalResources.fromFile(temporaryFiles.get&lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/information.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt;, false),&lt;br/&gt;
               UNKNOWN_SHARDNUM,&lt;br/&gt;
-              null,&lt;br/&gt;
-              null,&lt;br/&gt;
+              GlobalWindow.INSTANCE,&lt;br/&gt;
+              PaneInfo.ON_TIME_AND_ONLY_FIRING,&lt;br/&gt;
               null));&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     // TODO: test with null first argument?&lt;br/&gt;
     List&amp;lt;KV&amp;lt;FileResult&amp;lt;Void&amp;gt;, ResourceId&amp;gt;&amp;gt; resultsToFinalFilenames =&lt;br/&gt;
-        writeOp.buildOutputFilenames(null, null, null, fileResults);&lt;br/&gt;
-    Set&amp;lt;ResourceId&amp;gt; tempFiles = Sets.newHashSet();&lt;br/&gt;
-    for (KV&amp;lt;FileResult&amp;lt;Void&amp;gt;, ResourceId&amp;gt; res : resultsToFinalFilenames) {
-      tempFiles.add(res.getKey().getTempFilename());
-    }&lt;br/&gt;
-    writeOp.copyToOutputFiles(resultsToFinalFilenames);&lt;br/&gt;
-    writeOp.removeTemporaryFiles(tempFiles);&lt;br/&gt;
+        writeOp.finalizeDestination(null, GlobalWindow.INSTANCE, null, fileResults);&lt;br/&gt;
+    writeOp.moveToOutputFiles(resultsToFinalFilenames);&lt;br/&gt;
 &lt;br/&gt;
     for (int i = 0; i &amp;lt; numFiles; i++) {
       ResourceId outputFilename =
@@ -222,7 +215,7 @@ private void runFinalize(SimpleSink.SimpleWriteOperation&amp;lt;Void&amp;gt; writeOp, List&amp;lt;Fil
               .getDynamicDestinations()
               .getFilenamePolicy(null)
               .unwindowedFilename(i, numFiles, CompressionType.UNCOMPRESSED);
-      assertTrue(new File(outputFilename.toString()).exists());
+      assertTrue(outputFilename.toString(), new File(outputFilename.toString()).exists());
       assertFalse(temporaryFiles.get(i).exists());
     }&lt;br/&gt;
 &lt;br/&gt;
@@ -301,12 +294,16 @@ public void testCopyToOutputFiles() throws Exception {
       resultsToFinalFilenames.add(
           KV.of(
               new FileResult&amp;lt;Void&amp;gt;(
-                  LocalResources.fromFile(inputTmpFile, false), UNKNOWN_SHARDNUM, null, null, null),
+                  LocalResources.fromFile(inputTmpFile, false),
+                  UNKNOWN_SHARDNUM,
+                  GlobalWindow.INSTANCE,
+                  PaneInfo.ON_TIME_AND_ONLY_FIRING,
+                  null),
               finalFilename));
     }&lt;br/&gt;
 &lt;br/&gt;
     // Copy input files to output files.&lt;br/&gt;
-    writeOp.copyToOutputFiles(resultsToFinalFilenames);&lt;br/&gt;
+    writeOp.moveToOutputFiles(resultsToFinalFilenames);&lt;br/&gt;
 &lt;br/&gt;
     // Assert that the contents were copied.&lt;br/&gt;
     for (int i = 0; i &amp;lt; expectedOutputPaths.size(); i++) {&lt;br/&gt;
@@ -357,28 +354,28 @@ public void testGenerateOutputFilenames() {&lt;br/&gt;
 &lt;br/&gt;
   /** Reject non-distinct output filenames. */&lt;br/&gt;
   @Test&lt;br/&gt;
-  public void testCollidingOutputFilenames() throws IOException {&lt;br/&gt;
+  public void testCollidingOutputFilenames() throws Exception {&lt;br/&gt;
     ResourceId root = getBaseOutputDirectory();&lt;br/&gt;
     SimpleSink&amp;lt;Void&amp;gt; sink =&lt;br/&gt;
         SimpleSink.makeSimpleSink(root, &quot;file&quot;, &quot;-NN&quot;, &quot;test&quot;, Compression.UNCOMPRESSED);&lt;br/&gt;
     SimpleSink.SimpleWriteOperation&amp;lt;Void&amp;gt; writeOp = new SimpleSink.SimpleWriteOperation&amp;lt;&amp;gt;(sink);&lt;br/&gt;
 &lt;br/&gt;
-    ResourceId temp1 = root.resolve(&quot;temp1&quot;, StandardResolveOptions.RESOLVE_FILE);&lt;br/&gt;
-    ResourceId temp2 = root.resolve(&quot;temp2&quot;, StandardResolveOptions.RESOLVE_FILE);&lt;br/&gt;
-    ResourceId temp3 = root.resolve(&quot;temp3&quot;, StandardResolveOptions.RESOLVE_FILE);&lt;br/&gt;
-    // More than one shard does.&lt;br/&gt;
     try {&lt;br/&gt;
-      Iterable&amp;lt;FileResult&amp;lt;Void&amp;gt;&amp;gt; results =&lt;br/&gt;
-          Lists.newArrayList(&lt;br/&gt;
-              new FileResult&amp;lt;Void&amp;gt;(temp1, 1 /* shard */, null, null, null),&lt;br/&gt;
-              new FileResult&amp;lt;Void&amp;gt;(temp2, 1 /* shard */, null, null, null),&lt;br/&gt;
-              new FileResult&amp;lt;Void&amp;gt;(temp3, 1 /* shard */, null, null, null));&lt;br/&gt;
-      writeOp.buildOutputFilenames(null, null, 5 /* numShards */, results);&lt;br/&gt;
+      List&amp;lt;FileResult&amp;lt;Void&amp;gt;&amp;gt; results = Lists.newArrayList();&lt;br/&gt;
+      for (int i = 0; i &amp;lt; 3; ++i) {
+        results.add(new FileResult&amp;lt;Void&amp;gt;(
+            root.resolve(&quot;temp&quot; + i, StandardResolveOptions.RESOLVE_FILE),
+            1 /* shard - should be different, but is the same */,
+            GlobalWindow.INSTANCE,
+            PaneInfo.ON_TIME_AND_ONLY_FIRING,
+            null));
+      }&lt;br/&gt;
+      writeOp.finalizeDestination(null, GlobalWindow.INSTANCE, 5 /* numShards */, results);&lt;br/&gt;
       fail(&quot;Should have failed.&quot;);&lt;br/&gt;
     } catch (IllegalArgumentException exn) {
       assertThat(exn.getMessage(), containsString(&quot;generated the same name&quot;));
+      assertThat(exn.getMessage(), containsString(&quot;temp0&quot;));
       assertThat(exn.getMessage(), containsString(&quot;temp1&quot;));
-      assertThat(exn.getMessage(), containsString(&quot;temp2&quot;));
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
@@ -514,12 +511,11 @@ public void testFileBasedWriterWithWritableByteChannelFactory() throws Exception&lt;br/&gt;
     expected.add(&quot;footer&quot;);&lt;br/&gt;
     expected.add(&quot;footer&quot;);&lt;br/&gt;
 &lt;br/&gt;
-    writer.openUnwindowed(testUid, -1, null);&lt;br/&gt;
+    writer.open(testUid);&lt;br/&gt;
     writer.write(&quot;a&quot;);&lt;br/&gt;
     writer.write(&quot;b&quot;);&lt;br/&gt;
-    final FileResult result = writer.close();&lt;br/&gt;
-&lt;br/&gt;
-    assertEquals(expectedFile, result.getTempFilename());&lt;br/&gt;
+    writer.close();&lt;br/&gt;
+    assertEquals(expectedFile, writer.getOutputFile());&lt;br/&gt;
     assertFileContains(expected, expectedFile);&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/io/WriteFilesTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/io/WriteFilesTest.java&lt;br/&gt;
index 40ae0ea2b9d..da4e6daa4ec 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/test/java/org/apache/beam/sdk/io/WriteFilesTest.java&lt;br/&gt;
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/io/WriteFilesTest.java&lt;br/&gt;
@@ -329,21 +329,21 @@ public void testBuildWrite() {
     WriteFiles&amp;lt;String, ?, String&amp;gt; write = WriteFiles.to(sink).withNumShards(3);
     assertThat((SimpleSink&amp;lt;Void&amp;gt;) write.getSink(), is(sink));
     PTransform&amp;lt;PCollection&amp;lt;String&amp;gt;, PCollectionView&amp;lt;Integer&amp;gt;&amp;gt; originalSharding =
-        write.getSharding();
+        write.getComputeNumShards();
 
-    assertThat(write.getSharding(), is(nullValue()));
-    assertThat(write.getNumShards(), instanceOf(StaticValueProvider.class));
-    assertThat(write.getNumShards().get(), equalTo(3));
-    assertThat(write.getSharding(), equalTo(originalSharding));
+    assertThat(write.getComputeNumShards(), is(nullValue()));
+    assertThat(write.getNumShardsProvider(), instanceOf(StaticValueProvider.class));
+    assertThat(write.getNumShardsProvider().get(), equalTo(3));
+    assertThat(write.getComputeNumShards(), equalTo(originalSharding));
 
     WriteFiles&amp;lt;String, ?, ?&amp;gt; write2 = write.withSharding(SHARDING_TRANSFORM);
     assertThat((SimpleSink&amp;lt;Void&amp;gt;) write2.getSink(), is(sink));
-    assertThat(write2.getSharding(), equalTo(SHARDING_TRANSFORM));
+    assertThat(write2.getComputeNumShards(), equalTo(SHARDING_TRANSFORM));
     // original unchanged
 
     WriteFiles&amp;lt;String, ?, ?&amp;gt; writeUnsharded = write2.withRunnerDeterminedSharding();
-    assertThat(writeUnsharded.getSharding(), nullValue());
-    assertThat(write.getSharding(), equalTo(originalSharding));
+    assertThat(writeUnsharded.getComputeNumShards(), nullValue());
+    assertThat(write.getComputeNumShards(), equalTo(originalSharding));
   }&lt;br/&gt;
 &lt;br/&gt;
   @Test&lt;br/&gt;
@@ -386,10 +386,11 @@ public void testUnboundedNeedsWindowed() {&lt;br/&gt;
 &lt;br/&gt;
   @Test&lt;br/&gt;
   @Category(NeedsRunner.class)&lt;br/&gt;
-  public void testWindowedWritesNeedSharding() {&lt;br/&gt;
+  public void testUnboundedWritesNeedSharding() {
     thrown.expect(IllegalArgumentException.class);
     thrown.expectMessage(
-        &quot;When using windowed writes, must specify number of output shards explicitly&quot;);
+        &quot;When applying WriteFiles to an unbounded PCollection, &quot;
+            + &quot;must specify number of output shards explicitly&quot;);
 
     SimpleSink&amp;lt;Void&amp;gt; sink = makeSimpleSink();
     p.apply(Create.of(&quot;foo&quot;))
@@ -669,10 +670,10 @@ private void runShardedWrite(
     p.run();
 
     Optional&amp;lt;Integer&amp;gt; numShards =
-        (write.getNumShards() != null &amp;amp;&amp;amp; !write.isWindowedWrites())
-            ? Optional.of(write.getNumShards().get())
+        (write.getNumShardsProvider() != null &amp;amp;&amp;amp; !write.getWindowedWrites())
+            ? Optional.of(write.getNumShardsProvider().get())
             : Optional.&amp;lt;Integer&amp;gt;absent();
-    checkFileContents(baseName, inputs, numShards, !write.isWindowedWrites());
+    checkFileContents(baseName, inputs, numShards, !write.getWindowedWrites());
   }&lt;br/&gt;
 &lt;br/&gt;
   static void checkFileContents(&lt;br/&gt;
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/SampleTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/SampleTest.java&lt;br/&gt;
index 357f25633bb..ed6905d41dd 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/SampleTest.java&lt;br/&gt;
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/SampleTest.java&lt;br/&gt;
@@ -20,6 +20,9 @@&lt;br/&gt;
 import static com.google.common.base.Preconditions.checkArgument;&lt;br/&gt;
 import static org.apache.beam.sdk.transforms.display.DisplayDataMatchers.hasDisplayItem;&lt;br/&gt;
 import static org.hamcrest.MatcherAssert.assertThat;&lt;br/&gt;
+import static org.hamcrest.Matchers.allOf;&lt;br/&gt;
+import static org.hamcrest.Matchers.everyItem;&lt;br/&gt;
+import static org.hamcrest.Matchers.isIn;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
 import static org.junit.Assert.assertTrue;&lt;br/&gt;
 &lt;br/&gt;
@@ -37,6 +40,7 @@&lt;br/&gt;
 import org.apache.beam.sdk.TestUtils;&lt;br/&gt;
 import org.apache.beam.sdk.coders.BigEndianIntegerCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.StringUtf8Coder;&lt;br/&gt;
+import org.apache.beam.sdk.testing.CombineFnTester;&lt;br/&gt;
 import org.apache.beam.sdk.testing.PAssert;&lt;br/&gt;
 import org.apache.beam.sdk.testing.TestPipeline;&lt;br/&gt;
 import org.apache.beam.sdk.testing.ValidatesRunner;&lt;br/&gt;
@@ -46,6 +50,7 @@&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.Window;&lt;br/&gt;
 import org.apache.beam.sdk.values.PCollection;&lt;br/&gt;
 import org.apache.beam.sdk.values.TimestampedValue;&lt;br/&gt;
+import org.hamcrest.Matchers;&lt;br/&gt;
 import org.joda.time.Duration;&lt;br/&gt;
 import org.joda.time.Instant;&lt;br/&gt;
 import org.junit.Rule;&lt;br/&gt;
@@ -174,6 +179,16 @@ void runPickAnyTest(final List&amp;lt;String&amp;gt; lines, int limit) {&lt;br/&gt;
     public void testPickAny() {
       runPickAnyTest(lines, limit);
     }&lt;br/&gt;
+&lt;br/&gt;
+    @Test&lt;br/&gt;
+    public void testCombineFn() {
+      CombineFnTester.testCombineFn(
+          Sample.&amp;lt;String&amp;gt;combineFn(limit),
+          lines,
+          allOf(
+              Matchers.&amp;lt;String&amp;gt;iterableWithSize(Math.min(lines.size(), limit)),
+              everyItem(isIn(lines))));
+    }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/WatchTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/WatchTest.java&lt;br/&gt;
index 89043766cda..ec6880cd588 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/WatchTest.java&lt;br/&gt;
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/WatchTest.java&lt;br/&gt;
@@ -173,6 +173,60 @@ private void testMultiplePolls(boolean terminationConditionElapsesBeforeOutputIs&lt;br/&gt;
     p.run();&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
+  @Test&lt;br/&gt;
+  @Category({NeedsRunner.class, UsesSplittableParDo.class})&lt;br/&gt;
+  public void testMultiplePollsWithKeyExtractor() {&lt;br/&gt;
+    List&amp;lt;KV&amp;lt;Integer, String&amp;gt;&amp;gt; polls =&lt;br/&gt;
+        Arrays.asList(&lt;br/&gt;
+            KV.of(0, &quot;0&quot;),&lt;br/&gt;
+            KV.of(10, &quot;10&quot;),&lt;br/&gt;
+            KV.of(20, &quot;20&quot;),&lt;br/&gt;
+            KV.of(30, &quot;30&quot;),&lt;br/&gt;
+            KV.of(40, &quot;40&quot;),&lt;br/&gt;
+            KV.of(40, &quot;40.1&quot;),&lt;br/&gt;
+            KV.of(20, &quot;20.1&quot;),&lt;br/&gt;
+            KV.of(50, &quot;50&quot;),&lt;br/&gt;
+            KV.of(10, &quot;10.1&quot;),&lt;br/&gt;
+            KV.of(10, &quot;10.2&quot;),&lt;br/&gt;
+            KV.of(60, &quot;60&quot;),&lt;br/&gt;
+            KV.of(70, &quot;70&quot;),&lt;br/&gt;
+            KV.of(60, &quot;60.1&quot;),&lt;br/&gt;
+            KV.of(80, &quot;80&quot;),&lt;br/&gt;
+            KV.of(40, &quot;40.2&quot;),&lt;br/&gt;
+            KV.of(90, &quot;90&quot;),&lt;br/&gt;
+            KV.of(90, &quot;90.1&quot;));&lt;br/&gt;
+&lt;br/&gt;
+    List&amp;lt;Integer&amp;gt; expected = Arrays.asList(0, 10, 20, 30, 40, 50, 60, 70, 80, 90);&lt;br/&gt;
+&lt;br/&gt;
+    PCollection&amp;lt;Integer&amp;gt; res =&lt;br/&gt;
+        p.apply(Create.of(&quot;a&quot;))&lt;br/&gt;
+            .apply(&lt;br/&gt;
+                Watch.growthOf(&lt;br/&gt;
+                        Contextful.&amp;lt;PollFn&amp;lt;String, KV&amp;lt;Integer, String&amp;gt;&amp;gt;&amp;gt;of(&lt;br/&gt;
+                            new TimedPollFn&amp;lt;String, KV&amp;lt;Integer, String&amp;gt;&amp;gt;(&lt;br/&gt;
+                                polls,&lt;br/&gt;
+                                standardSeconds(1) /* timeToOutputEverything */,&lt;br/&gt;
+                                standardSeconds(3) /* timeToDeclareOutputFinal */,&lt;br/&gt;
+                                standardSeconds(30) /* timeToFail */),&lt;br/&gt;
+                            Requirements.empty()),&lt;br/&gt;
+                        new SerializableFunction&amp;lt;KV&amp;lt;Integer, String&amp;gt;, Integer&amp;gt;() {&lt;br/&gt;
+                          @Override&lt;br/&gt;
+                          public Integer apply(KV&amp;lt;Integer, String&amp;gt; input) {
+                            return input.getKey();
+                          }&lt;br/&gt;
+                        })&lt;br/&gt;
+                    .withTerminationPerInput(Watch.Growth.&amp;lt;String&amp;gt;afterTotalOf(standardSeconds(5)))&lt;br/&gt;
+                    .withPollInterval(Duration.millis(100))&lt;br/&gt;
+                    .withOutputCoder(KvCoder.of(VarIntCoder.of(), StringUtf8Coder.of())))&lt;br/&gt;
+            .apply(&quot;Drop input&quot;, Values.&amp;lt;KV&amp;lt;Integer, String&amp;gt;&amp;gt;create())&lt;br/&gt;
+            .apply(&quot;Drop auxiliary string&quot;, Keys.&amp;lt;Integer&amp;gt;create());&lt;br/&gt;
+&lt;br/&gt;
+    PAssert.that(res).containsInAnyOrder(expected);&lt;br/&gt;
+&lt;br/&gt;
+    p.run();&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
   @Test&lt;br/&gt;
   @Category({NeedsRunner.class, UsesSplittableParDo.class})&lt;br/&gt;
   public void testMultiplePollsStopAfterTimeSinceNewOutput() {&lt;br/&gt;
@@ -437,20 +491,23 @@ public void testTerminationConditionsAllOf() {
     assertTrue(c.canStopPolling(now.plus(standardSeconds(12)), state));
   }&lt;br/&gt;
 &lt;br/&gt;
-  private static GrowthTracker&amp;lt;String, Integer&amp;gt; newTracker(GrowthState&amp;lt;String, Integer&amp;gt; state) {&lt;br/&gt;
-    return new GrowthTracker&amp;lt;&amp;gt;(StringUtf8Coder.of(), state, never());&lt;br/&gt;
+  private static GrowthTracker&amp;lt;String, String, Integer&amp;gt; newTracker(&lt;br/&gt;
+      GrowthState&amp;lt;String, String, Integer&amp;gt; state) {
+    return new GrowthTracker&amp;lt;&amp;gt;(
+        SerializableFunctions.&amp;lt;String&amp;gt;identity(), StringUtf8Coder.of(), state, never());
   }&lt;br/&gt;
 &lt;br/&gt;
-  private static GrowthTracker&amp;lt;String, Integer&amp;gt; newTracker() {&lt;br/&gt;
-    return newTracker(new GrowthState&amp;lt;String, Integer&amp;gt;(never().forNewInput(Instant.now(), null)));&lt;br/&gt;
+  private static GrowthTracker&amp;lt;String, String, Integer&amp;gt; newTracker() {
+    return newTracker(
+        new GrowthState&amp;lt;String, String, Integer&amp;gt;(never().forNewInput(Instant.now(), null)));
   }&lt;br/&gt;
 &lt;br/&gt;
   @Test&lt;br/&gt;
   public void testGrowthTrackerCheckpointEmpty() {&lt;br/&gt;
     // Checkpoint an empty tracker.&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
-    GrowthState&amp;lt;String, Integer&amp;gt; residual = tracker.checkpoint();&lt;br/&gt;
-    GrowthState&amp;lt;String, Integer&amp;gt; primary = tracker.currentRestriction();&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+    GrowthState&amp;lt;String, String, Integer&amp;gt; residual = tracker.checkpoint();&lt;br/&gt;
+    GrowthState&amp;lt;String, String, Integer&amp;gt; primary = tracker.currentRestriction();&lt;br/&gt;
     Watch.Growth.Never&amp;lt;String&amp;gt; condition = never();&lt;br/&gt;
     assertEquals(&lt;br/&gt;
         primary.toString(condition),&lt;br/&gt;
@@ -475,7 +532,7 @@ public void testGrowthTrackerCheckpointEmpty() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testGrowthTrackerCheckpointNonEmpty() {&lt;br/&gt;
     Instant now = Instant.now();&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
     tracker.addNewAsPending(&lt;br/&gt;
         PollResult.incomplete(&lt;br/&gt;
                 Arrays.asList(&lt;br/&gt;
@@ -493,8 +550,9 @@ public void testGrowthTrackerCheckpointNonEmpty() {&lt;br/&gt;
     assertTrue(tracker.hasPending());&lt;br/&gt;
     assertEquals(now.plus(standardSeconds(3)), tracker.getWatermark());&lt;br/&gt;
 &lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; primaryTracker = newTracker(tracker.currentRestriction());&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; primaryTracker =&lt;br/&gt;
+        newTracker(tracker.currentRestriction());&lt;br/&gt;
 &lt;br/&gt;
     // Verify primary: should contain what the current tracker claimed, and nothing else.&lt;br/&gt;
     assertEquals(now.plus(standardSeconds(1)), primaryTracker.getWatermark());&lt;br/&gt;
@@ -530,7 +588,7 @@ public void testGrowthTrackerCheckpointNonEmpty() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testGrowthTrackerOutputFullyBeforeCheckpointIncomplete() {&lt;br/&gt;
     Instant now = Instant.now();&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
     tracker.addNewAsPending(&lt;br/&gt;
         PollResult.incomplete(&lt;br/&gt;
                 Arrays.asList(&lt;br/&gt;
@@ -547,8 +605,9 @@ public void testGrowthTrackerOutputFullyBeforeCheckpointIncomplete() {&lt;br/&gt;
     assertFalse(tracker.hasPending());&lt;br/&gt;
     assertEquals(now.plus(standardSeconds(7)), tracker.getWatermark());&lt;br/&gt;
 &lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; primaryTracker = newTracker(tracker.currentRestriction());&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; primaryTracker =&lt;br/&gt;
+        newTracker(tracker.currentRestriction());&lt;br/&gt;
 &lt;br/&gt;
     // Verify primary: should contain what the current tracker claimed, and nothing else.&lt;br/&gt;
     assertEquals(now.plus(standardSeconds(1)), primaryTracker.getWatermark());&lt;br/&gt;
@@ -582,7 +641,7 @@ public void testGrowthTrackerOutputFullyBeforeCheckpointIncomplete() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testGrowthTrackerPollAfterCheckpointIncompleteWithNewOutputs() {&lt;br/&gt;
     Instant now = Instant.now();&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
     tracker.addNewAsPending(&lt;br/&gt;
         PollResult.incomplete(&lt;br/&gt;
                 Arrays.asList(&lt;br/&gt;
@@ -597,10 +656,10 @@ public void testGrowthTrackerPollAfterCheckpointIncompleteWithNewOutputs() {&lt;br/&gt;
     assertEquals(&quot;c&quot;, tracker.tryClaimNextPending().getValue());&lt;br/&gt;
     assertEquals(&quot;d&quot;, tracker.tryClaimNextPending().getValue());&lt;br/&gt;
 &lt;br/&gt;
-    GrowthState&amp;lt;String, Integer&amp;gt; checkpoint = tracker.checkpoint();&lt;br/&gt;
+    GrowthState&amp;lt;String, String, Integer&amp;gt; checkpoint = tracker.checkpoint();&lt;br/&gt;
     // Simulate resuming from the checkpoint and adding more elements.&lt;br/&gt;
     {&lt;br/&gt;
-      GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
+      GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
       residualTracker.addNewAsPending(&lt;br/&gt;
           PollResult.incomplete(&lt;br/&gt;
                   Arrays.asList(&lt;br/&gt;
@@ -623,7 +682,7 @@ public void testGrowthTrackerPollAfterCheckpointIncompleteWithNewOutputs() {&lt;br/&gt;
     }&lt;br/&gt;
     // Try same without an explicitly specified watermark.&lt;br/&gt;
     {&lt;br/&gt;
-      GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
+      GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
       residualTracker.addNewAsPending(&lt;br/&gt;
           PollResult.incomplete(&lt;br/&gt;
               Arrays.asList(&lt;br/&gt;
@@ -648,7 +707,7 @@ public void testGrowthTrackerPollAfterCheckpointIncompleteWithNewOutputs() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testGrowthTrackerPollAfterCheckpointWithoutNewOutputs() {&lt;br/&gt;
     Instant now = Instant.now();&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
     tracker.addNewAsPending(&lt;br/&gt;
         PollResult.incomplete(&lt;br/&gt;
                 Arrays.asList(&lt;br/&gt;
@@ -664,9 +723,9 @@ public void testGrowthTrackerPollAfterCheckpointWithoutNewOutputs() {&lt;br/&gt;
     assertEquals(&quot;d&quot;, tracker.tryClaimNextPending().getValue());&lt;br/&gt;
 &lt;br/&gt;
     // Simulate resuming from the checkpoint but there are no new elements.&lt;br/&gt;
-    GrowthState&amp;lt;String, Integer&amp;gt; checkpoint = tracker.checkpoint();&lt;br/&gt;
+    GrowthState&amp;lt;String, String, Integer&amp;gt; checkpoint = tracker.checkpoint();&lt;br/&gt;
     {&lt;br/&gt;
-      GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
+      GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
       residualTracker.addNewAsPending(&lt;br/&gt;
           PollResult.incomplete(&lt;br/&gt;
                   Arrays.asList(&lt;br/&gt;
@@ -682,7 +741,7 @@ public void testGrowthTrackerPollAfterCheckpointWithoutNewOutputs() {&lt;br/&gt;
     }&lt;br/&gt;
     // Try the same without an explicitly specified watermark&lt;br/&gt;
     {&lt;br/&gt;
-      GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
+      GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
       residualTracker.addNewAsPending(&lt;br/&gt;
           PollResult.incomplete(&lt;br/&gt;
               Arrays.asList(&lt;br/&gt;
@@ -698,7 +757,7 @@ public void testGrowthTrackerPollAfterCheckpointWithoutNewOutputs() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testGrowthTrackerPollAfterCheckpointWithoutNewOutputsNoWatermark() {&lt;br/&gt;
     Instant now = Instant.now();&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
     tracker.addNewAsPending(&lt;br/&gt;
         PollResult.incomplete(&lt;br/&gt;
             Arrays.asList(&lt;br/&gt;
@@ -713,8 +772,8 @@ public void testGrowthTrackerPollAfterCheckpointWithoutNewOutputsNoWatermark() {&lt;br/&gt;
     assertEquals(now.plus(standardSeconds(1)), tracker.getWatermark());&lt;br/&gt;
 &lt;br/&gt;
     // Simulate resuming from the checkpoint but there are no new elements.&lt;br/&gt;
-    GrowthState&amp;lt;String, Integer&amp;gt; checkpoint = tracker.checkpoint();&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
+    GrowthState&amp;lt;String, String, Integer&amp;gt; checkpoint = tracker.checkpoint();&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(checkpoint);&lt;br/&gt;
     residualTracker.addNewAsPending(&lt;br/&gt;
         PollResult.incomplete(&lt;br/&gt;
             Arrays.asList(&lt;br/&gt;
@@ -730,13 +789,13 @@ public void testGrowthTrackerPollAfterCheckpointWithoutNewOutputsNoWatermark() {&lt;br/&gt;
   public void testGrowthTrackerRepeatedEmptyPollWatermark() {&lt;br/&gt;
     // Empty poll result with no watermark&lt;br/&gt;
     {&lt;br/&gt;
-      GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+      GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
       tracker.addNewAsPending(&lt;br/&gt;
           PollResult.incomplete(Collections.&amp;lt;TimestampedValue&amp;lt;String&amp;gt;&amp;gt;emptyList()));&lt;br/&gt;
       assertEquals(BoundedWindow.TIMESTAMP_MIN_VALUE, tracker.getWatermark());&lt;br/&gt;
 &lt;br/&gt;
       // Simulate resuming from the checkpoint but there are still no new elements.&lt;br/&gt;
-      GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
+      GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
       tracker.addNewAsPending(&lt;br/&gt;
           PollResult.incomplete(Collections.&amp;lt;TimestampedValue&amp;lt;String&amp;gt;&amp;gt;emptyList()));&lt;br/&gt;
       // No new elements and no explicit watermark supplied - still no watermark.&lt;br/&gt;
@@ -745,14 +804,14 @@ public void testGrowthTrackerRepeatedEmptyPollWatermark() {&lt;br/&gt;
     // Empty poll result with watermark&lt;br/&gt;
     {&lt;br/&gt;
       Instant now = Instant.now();&lt;br/&gt;
-      GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+      GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
       tracker.addNewAsPending(&lt;br/&gt;
           PollResult.incomplete(Collections.&amp;lt;TimestampedValue&amp;lt;String&amp;gt;&amp;gt;emptyList())&lt;br/&gt;
               .withWatermark(now));&lt;br/&gt;
       assertEquals(now, tracker.getWatermark());&lt;br/&gt;
 &lt;br/&gt;
       // Simulate resuming from the checkpoint but there are still no new elements.&lt;br/&gt;
-      GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
+      GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
       tracker.addNewAsPending(&lt;br/&gt;
           PollResult.incomplete(Collections.&amp;lt;TimestampedValue&amp;lt;String&amp;gt;&amp;gt;emptyList()));&lt;br/&gt;
       // No new elements and no explicit watermark supplied - should keep old watermark.&lt;br/&gt;
@@ -763,7 +822,7 @@ public void testGrowthTrackerRepeatedEmptyPollWatermark() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testGrowthTrackerOutputFullyBeforeCheckpointComplete() {&lt;br/&gt;
     Instant now = Instant.now();&lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; tracker = newTracker();&lt;br/&gt;
     tracker.addNewAsPending(&lt;br/&gt;
         PollResult.complete(&lt;br/&gt;
             Arrays.asList(&lt;br/&gt;
@@ -779,7 +838,7 @@ public void testGrowthTrackerOutputFullyBeforeCheckpointComplete() {&lt;br/&gt;
     assertFalse(tracker.hasPending());&lt;br/&gt;
     assertEquals(BoundedWindow.TIMESTAMP_MAX_VALUE, tracker.getWatermark());&lt;br/&gt;
 &lt;br/&gt;
-    GrowthTracker&amp;lt;String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
+    GrowthTracker&amp;lt;String, String, Integer&amp;gt; residualTracker = newTracker(tracker.checkpoint());&lt;br/&gt;
 &lt;br/&gt;
     // Verify residual: should be empty, since output was final.&lt;br/&gt;
     residualTracker.checkDone();&lt;br/&gt;
diff --git a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/reflect/DoFnSignaturesTest.java b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/reflect/DoFnSignaturesTest.java&lt;br/&gt;
index a961203ffed..d7b5cad48c8 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/reflect/DoFnSignaturesTest.java&lt;br/&gt;
+++ b/sdks/java/core/src/test/java/org/apache/beam/sdk/transforms/reflect/DoFnSignaturesTest.java&lt;br/&gt;
@@ -22,6 +22,7 @@&lt;br/&gt;
 import static org.hamcrest.Matchers.containsString;&lt;br/&gt;
 import static org.hamcrest.Matchers.equalTo;&lt;br/&gt;
 import static org.hamcrest.Matchers.instanceOf;&lt;br/&gt;
+import static org.hamcrest.Matchers.is;&lt;br/&gt;
 import static org.hamcrest.Matchers.not;&lt;br/&gt;
 import static org.junit.Assert.assertThat;&lt;br/&gt;
 import static org.junit.Assert.fail;&lt;br/&gt;
@@ -77,6 +78,17 @@ public void process(ProcessContext c) {}&lt;br/&gt;
         sig.processElement().extraParameters().get(0), instanceOf(ProcessContextParameter.class));&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void testRequiresStableInputProcessElement() throws Exception {&lt;br/&gt;
+    DoFnSignature sig = DoFnSignatures.getSignature(new DoFn&amp;lt;String, String&amp;gt;() {&lt;br/&gt;
+      @ProcessElement&lt;br/&gt;
+      @RequiresStableInput&lt;br/&gt;
+      public void process(ProcessContext c) {}&lt;br/&gt;
+    }.getClass());&lt;br/&gt;
+&lt;br/&gt;
+    assertThat(sig.processElement().requiresStableInput(), is(true));&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testBadExtraContext() throws Exception {&lt;br/&gt;
     thrown.expect(IllegalArgumentException.class);&lt;br/&gt;
diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/BeamSqlSeekableTable.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/BeamSqlSeekableTable.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..dbfe119ccc5&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/BeamSqlSeekableTable.java&lt;br/&gt;
@@ -0,0 +1,35 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.beam.sdk.extensions.sql;&lt;br/&gt;
+&lt;br/&gt;
+import java.io.Serializable;&lt;br/&gt;
+import java.util.List;&lt;br/&gt;
+import org.apache.beam.sdk.annotations.Experimental;&lt;br/&gt;
+import org.apache.beam.sdk.values.BeamRecord;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * A seekable table converts a JOIN operator to an inline lookup.&lt;br/&gt;
+ * It&apos;s triggered by {@code SELECT * FROM FACT_TABLE JOIN LOOKUP_TABLE ON ...}.&lt;br/&gt;
+ */&lt;br/&gt;
+@Experimental&lt;br/&gt;
+public interface BeamSqlSeekableTable extends Serializable{&lt;br/&gt;
+  /**&lt;br/&gt;
+   * return a list of {@code BeamRecord} with given key set.&lt;br/&gt;
+   */&lt;br/&gt;
+  List&amp;lt;BeamRecord&amp;gt; seekRecord(BeamRecord lookupSubRecord);&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamJoinRel.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamJoinRel.java&lt;br/&gt;
index cc26aa6672e..203a739dc59 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamJoinRel.java&lt;br/&gt;
+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamJoinRel.java&lt;br/&gt;
@@ -18,6 +18,7 @@&lt;br/&gt;
 &lt;br/&gt;
 package org.apache.beam.sdk.extensions.sql.impl.rel;&lt;br/&gt;
 &lt;br/&gt;
+import com.google.common.base.Joiner;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
@@ -26,6 +27,8 @@&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.KvCoder;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.BeamRecordSqlType;&lt;br/&gt;
+import org.apache.beam.sdk.extensions.sql.BeamSqlSeekableTable;&lt;br/&gt;
+import org.apache.beam.sdk.extensions.sql.BeamSqlTable;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.impl.BeamSqlEnv;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.impl.transform.BeamJoinTransforms;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;&lt;br/&gt;
@@ -98,9 +101,14 @@ public BeamJoinRel(RelOptCluster cluster, RelTraitSet traits, RelNode left, RelN&lt;br/&gt;
       throws Exception {&lt;br/&gt;
     BeamRelNode leftRelNode = BeamSqlRelUtils.getBeamRelInput(left);&lt;br/&gt;
     BeamRecordSqlType leftRowType = CalciteUtils.toBeamRowType(left.getRowType());&lt;br/&gt;
-    PCollection&amp;lt;BeamRecord&amp;gt; leftRows = leftRelNode.buildBeamPipeline(inputPCollections, sqlEnv);&lt;br/&gt;
-&lt;br/&gt;
     final BeamRelNode rightRelNode = BeamSqlRelUtils.getBeamRelInput(right);&lt;br/&gt;
+&lt;br/&gt;
+    if (!seekable(leftRelNode, sqlEnv) &amp;amp;&amp;amp; seekable(rightRelNode, sqlEnv)) {
+      return joinAsLookup(leftRelNode, rightRelNode, inputPCollections, sqlEnv)
+              .setCoder(CalciteUtils.toBeamRowType(getRowType()).getRecordCoder());
+    }&lt;br/&gt;
+&lt;br/&gt;
+    PCollection&amp;lt;BeamRecord&amp;gt; leftRows = leftRelNode.buildBeamPipeline(inputPCollections, sqlEnv);&lt;br/&gt;
     PCollection&amp;lt;BeamRecord&amp;gt; rightRows = rightRelNode.buildBeamPipeline(inputPCollections, sqlEnv);&lt;br/&gt;
 &lt;br/&gt;
     String stageName = BeamSqlRelUtils.getStageName(this);&lt;br/&gt;
@@ -295,4 +303,37 @@ private BeamRecord buildNullRow(BeamRelNode relNode) {
 
     return new Pair&amp;lt;&amp;gt;(leftIndex, rightIndex);
   }&lt;br/&gt;
+&lt;br/&gt;
+  private PCollection&amp;lt;BeamRecord&amp;gt; joinAsLookup(BeamRelNode leftRelNode, BeamRelNode rightRelNode,&lt;br/&gt;
+      PCollectionTuple inputPCollections, BeamSqlEnv sqlEnv) throws Exception {
+    PCollection&amp;lt;BeamRecord&amp;gt; factStream = leftRelNode.buildBeamPipeline(inputPCollections, sqlEnv);
+    BeamSqlSeekableTable seekableTable = getSeekableTableFromRelNode(rightRelNode, sqlEnv);
+
+    return factStream.apply(&quot;join_as_lookup&quot;,
+        new BeamJoinTransforms.JoinAsLookup(condition, seekableTable,
+            CalciteUtils.toBeamRowType(rightRelNode.getRowType()),
+            CalciteUtils.toBeamRowType(leftRelNode.getRowType()).getFieldCount()));
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private BeamSqlSeekableTable getSeekableTableFromRelNode(BeamRelNode relNode, BeamSqlEnv sqlEnv) {
+    BeamIOSourceRel srcRel = (BeamIOSourceRel) relNode;
+    String tableName = Joiner.on(&apos;.&apos;).join(srcRel.getTable().getQualifiedName());
+    BeamSqlTable sourceTable = sqlEnv.findTable(tableName);
+    return (BeamSqlSeekableTable) sourceTable;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * check if {@code BeamRelNode} implements {@code BeamSeekableTable}.&lt;br/&gt;
+   */&lt;br/&gt;
+  private boolean seekable(BeamRelNode relNode, BeamSqlEnv sqlEnv) {&lt;br/&gt;
+    if (relNode instanceof BeamIOSourceRel) {&lt;br/&gt;
+      BeamIOSourceRel srcRel = (BeamIOSourceRel) relNode;&lt;br/&gt;
+      String tableName = Joiner.on(&apos;.&apos;).join(srcRel.getTable().getQualifiedName());&lt;br/&gt;
+      BeamSqlTable sourceTable = sqlEnv.findTable(tableName);&lt;br/&gt;
+      if (sourceTable instanceof BeamSqlSeekableTable) {
+        return true;
+      }&lt;br/&gt;
+    }&lt;br/&gt;
+    return false;&lt;br/&gt;
+}&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamJoinTransforms.java b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamJoinTransforms.java&lt;br/&gt;
index 3c6b20f1e47..fb578b2c55c 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamJoinTransforms.java&lt;br/&gt;
+++ b/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/transform/BeamJoinTransforms.java&lt;br/&gt;
@@ -24,12 +24,19 @@&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.BeamRecordSqlType;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.BeamSqlRecordHelper;&lt;br/&gt;
+import org.apache.beam.sdk.extensions.sql.BeamSqlSeekableTable;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.DoFn;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.PTransform;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.ParDo;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.SimpleFunction;&lt;br/&gt;
 import org.apache.beam.sdk.values.BeamRecord;&lt;br/&gt;
 import org.apache.beam.sdk.values.KV;&lt;br/&gt;
+import org.apache.beam.sdk.values.PCollection;&lt;br/&gt;
 import org.apache.beam.sdk.values.PCollectionView;&lt;br/&gt;
 import org.apache.calcite.rel.core.JoinRelType;&lt;br/&gt;
+import org.apache.calcite.rex.RexCall;&lt;br/&gt;
+import org.apache.calcite.rex.RexInputRef;&lt;br/&gt;
+import org.apache.calcite.rex.RexNode;&lt;br/&gt;
 import org.apache.calcite.util.Pair;&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
@@ -158,4 +165,78 @@ private static BeamRecord combineTwoRowsIntoOneHelper(BeamRecord leftRow,&lt;br/&gt;
     fieldValues.addAll(rightRow.getDataValues());&lt;br/&gt;
     return new BeamRecord(type, fieldValues);&lt;br/&gt;
   }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Transform to execute Join as Lookup.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static class JoinAsLookup&lt;br/&gt;
+      extends PTransform&amp;lt;PCollection&amp;lt;BeamRecord&amp;gt;, PCollection&amp;lt;BeamRecord&amp;gt;&amp;gt; {&lt;br/&gt;
+//    private RexNode joinCondition;&lt;br/&gt;
+    BeamSqlSeekableTable seekableTable;&lt;br/&gt;
+    BeamRecordSqlType lkpRowType;&lt;br/&gt;
+//    int factTableColSize = 0; // TODO&lt;br/&gt;
+    BeamRecordSqlType joinSubsetType;&lt;br/&gt;
+    List&amp;lt;Integer&amp;gt; factJoinIdx;&lt;br/&gt;
+&lt;br/&gt;
+    public JoinAsLookup(RexNode joinCondition, BeamSqlSeekableTable seekableTable,&lt;br/&gt;
+        BeamRecordSqlType lkpRowType, int factTableColSize) {
+      this.seekableTable = seekableTable;
+      this.lkpRowType = lkpRowType;
+      joinFieldsMapping(joinCondition, factTableColSize);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private void joinFieldsMapping(RexNode joinCondition, int factTableColSize) {&lt;br/&gt;
+      factJoinIdx = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
+      List&amp;lt;String&amp;gt; lkpJoinFieldsName = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
+      List&amp;lt;Integer&amp;gt; lkpJoinFieldsType = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
+&lt;br/&gt;
+      RexCall call = (RexCall) joinCondition;&lt;br/&gt;
+      if (&quot;AND&quot;.equals(call.getOperator().getName())) {&lt;br/&gt;
+        List&amp;lt;RexNode&amp;gt; operands = call.getOperands();&lt;br/&gt;
+        for (RexNode rexNode : operands) {
+          factJoinIdx.add(((RexInputRef) ((RexCall) rexNode).getOperands().get(0)).getIndex());
+          int lkpJoinIdx = ((RexInputRef) ((RexCall) rexNode).getOperands().get(1)).getIndex()
+              - factTableColSize;
+          lkpJoinFieldsName.add(lkpRowType.getFieldNameByIndex(lkpJoinIdx));
+          lkpJoinFieldsType.add(lkpRowType.getFieldTypeByIndex(lkpJoinIdx));
+        }&lt;br/&gt;
+      } else if (&quot;=&quot;.equals(call.getOperator().getName())) {
+        factJoinIdx.add(((RexInputRef) call.getOperands().get(0)).getIndex());
+        int lkpJoinIdx = ((RexInputRef) call.getOperands().get(1)).getIndex()
+            - factTableColSize;
+        lkpJoinFieldsName.add(lkpRowType.getFieldNameByIndex(lkpJoinIdx));
+        lkpJoinFieldsType.add(lkpRowType.getFieldTypeByIndex(lkpJoinIdx));
+      } else {
+        throw new UnsupportedOperationException(
+            &quot;Operator &quot; + call.getOperator().getName() + &quot; is not supported in join condition&quot;);
+      }&lt;br/&gt;
+&lt;br/&gt;
+      joinSubsetType = BeamRecordSqlType.create(lkpJoinFieldsName, lkpJoinFieldsType);&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public PCollection&amp;lt;BeamRecord&amp;gt; expand(PCollection&amp;lt;BeamRecord&amp;gt; input) {&lt;br/&gt;
+      return input.apply(&quot;join_as_lookup&quot;, ParDo.of(new DoFn&amp;lt;BeamRecord, BeamRecord&amp;gt;(){&lt;br/&gt;
+        @ProcessElement&lt;br/&gt;
+        public void processElement(ProcessContext context) {&lt;br/&gt;
+          BeamRecord factRow = context.element();&lt;br/&gt;
+          BeamRecord joinSubRow = extractJoinSubRow(factRow);&lt;br/&gt;
+          List&amp;lt;BeamRecord&amp;gt; lookupRows = seekableTable.seekRecord(joinSubRow);&lt;br/&gt;
+          for (BeamRecord lr : lookupRows) {
+            context.output(combineTwoRowsIntoOneHelper(factRow, lr));
+          }&lt;br/&gt;
+        }&lt;br/&gt;
+&lt;br/&gt;
+        private BeamRecord extractJoinSubRow(BeamRecord factRow) {&lt;br/&gt;
+          List&amp;lt;Object&amp;gt; joinSubsetValues = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
+          for (int i : factJoinIdx) {
+            joinSubsetValues.add(factRow.getFieldValue(i));
+          }&lt;br/&gt;
+          return new BeamRecord(joinSubsetType, joinSubsetValues);&lt;br/&gt;
+        }&lt;br/&gt;
+&lt;br/&gt;
+      }));&lt;br/&gt;
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlApiSurfaceTest.java b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlApiSurfaceTest.java&lt;br/&gt;
index 156d7ff5b01..0cd1a2a95db 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlApiSurfaceTest.java&lt;br/&gt;
+++ b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamSqlApiSurfaceTest.java&lt;br/&gt;
@@ -52,6 +52,7 @@ public void testSdkApiSurface() throws Exception {&lt;br/&gt;
         .includingClass(BeamSqlUdf.class)&lt;br/&gt;
         .includingClass(BeamRecordSqlType.class)&lt;br/&gt;
         .includingClass(BeamSqlRecordHelper.class)&lt;br/&gt;
+        .includingClass(BeamSqlSeekableTable.class)&lt;br/&gt;
         .pruningPrefix(&quot;java&quot;)&lt;br/&gt;
         .pruningPattern(&quot;org&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;apache&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;beam&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;sdk&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;extensions&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;sql&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;.*Test&quot;)&lt;br/&gt;
         .pruningPattern(&quot;org&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;apache&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;beam&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;sdk&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;extensions&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;sql&lt;span class=&quot;error&quot;&gt;&amp;#91;.&amp;#93;&lt;/span&gt;.*TestBase&quot;);&lt;br/&gt;
diff --git a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamJoinRelUnboundedVsBoundedTest.java b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamJoinRelUnboundedVsBoundedTest.java&lt;br/&gt;
index c5145ec1a6d..c6053391f91 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamJoinRelUnboundedVsBoundedTest.java&lt;br/&gt;
+++ b/sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamJoinRelUnboundedVsBoundedTest.java&lt;br/&gt;
@@ -19,17 +19,26 @@&lt;br/&gt;
 package org.apache.beam.sdk.extensions.sql.impl.rel;&lt;br/&gt;
 &lt;br/&gt;
 import java.sql.Types;&lt;br/&gt;
+import java.util.Arrays;&lt;br/&gt;
 import java.util.Date;&lt;br/&gt;
+import java.util.List;&lt;br/&gt;
+import org.apache.beam.sdk.Pipeline;&lt;br/&gt;
+import org.apache.beam.sdk.extensions.sql.BeamRecordSqlType;&lt;br/&gt;
+import org.apache.beam.sdk.extensions.sql.BeamSqlSeekableTable;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.TestUtils;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.impl.BeamSqlEnv;&lt;br/&gt;
+import org.apache.beam.sdk.extensions.sql.impl.schema.BaseBeamTable;&lt;br/&gt;
+import org.apache.beam.sdk.extensions.sql.impl.schema.BeamIOType;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.impl.transform.BeamSqlOutputToConsoleFn;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.mock.MockedBoundedTable;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.sql.mock.MockedUnboundedTable;&lt;br/&gt;
 import org.apache.beam.sdk.testing.PAssert;&lt;br/&gt;
 import org.apache.beam.sdk.testing.TestPipeline;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.PTransform;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.ParDo;&lt;br/&gt;
 import org.apache.beam.sdk.values.BeamRecord;&lt;br/&gt;
 import org.apache.beam.sdk.values.PCollection;&lt;br/&gt;
+import org.apache.beam.sdk.values.PDone;&lt;br/&gt;
 import org.joda.time.Duration;&lt;br/&gt;
 import org.junit.BeforeClass;&lt;br/&gt;
 import org.junit.Rule;&lt;br/&gt;
@@ -84,8 +93,40 @@ public static void prepare() {
             1, &quot;james&quot;,
             2, &quot;bond&quot;
         ));
+    BEAM_SQL_ENV.registerTable(&quot;SITE_LKP&quot;, new SiteLookupTable(
+        TestUtils.buildBeamSqlRowType(Types.INTEGER, &quot;site_id&quot;, Types.VARCHAR, &quot;site_name&quot;)));
   }&lt;br/&gt;
 &lt;br/&gt;
+  /**&lt;br/&gt;
+   * Test table for JOIN-AS-LOOKUP.&lt;br/&gt;
+   *&lt;br/&gt;
+   */&lt;br/&gt;
+  public static class SiteLookupTable extends BaseBeamTable implements BeamSqlSeekableTable{&lt;br/&gt;
+&lt;br/&gt;
+    public SiteLookupTable(BeamRecordSqlType beamRecordSqlType) {
+      super(beamRecordSqlType);
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public BeamIOType getSourceType() {
+      return BeamIOType.BOUNDED;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public PCollection&amp;lt;BeamRecord&amp;gt; buildIOReader(Pipeline pipeline) {
+      throw new UnsupportedOperationException();
+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public PTransform&amp;lt;? super PCollection&amp;lt;BeamRecord&amp;gt;, PDone&amp;gt; buildIOWriter() {+      throw new UnsupportedOperationException();+    }&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public List&amp;lt;BeamRecord&amp;gt; seekRecord(BeamRecord lookupSubRecord) {
+      return Arrays.asList(new BeamRecord(getRowType(), 1, &quot;SITE1&quot;));
+    }&lt;br/&gt;
+  }&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testInnerJoin_unboundedTableOnTheLeftSide() throws Exception {&lt;br/&gt;
     String sql = &quot;SELECT o1.order_id, o1.sum_site_id, o2.buyer FROM &quot;&lt;br/&gt;
@@ -237,4 +278,26 @@ public void testFullOuterJoinError() throws Exception {
     compilePipeline(sql, pipeline, BEAM_SQL_ENV);
     pipeline.run();
   }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void testJoinAsLookup() throws Exception {
+    String sql = &quot;SELECT o1.order_id, o2.site_name FROM &quot;
+        + &quot; ORDER_DETAILS o1 &quot;
+        + &quot; JOIN SITE_LKP o2 &quot;
+        + &quot; on &quot;
+        + &quot; o1.site_id=o2.site_id &quot;
+        + &quot; WHERE o1.site_id=1&quot;
+        ;
+    PCollection&amp;lt;BeamRecord&amp;gt; rows = compilePipeline(sql, pipeline, BEAM_SQL_ENV);
+    PAssert.that(rows.apply(ParDo.of(new TestUtils.BeamSqlRow2StringDoFn())))
+        .containsInAnyOrder(
+            TestUtils.RowsBuilder.of(
+                Types.INTEGER, &quot;order_id&quot;,
+                Types.VARCHAR, &quot;site_name&quot;
+            ).addRows(
+                1, &quot;SITE1&quot;
+            ).getStringRows()
+        );
+    pipeline.run();
+  }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/fn-execution/build.gradle b/sdks/java/fn-execution/build.gradle&lt;br/&gt;
index 69ec54a5a49..45213a75e5f 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/fn-execution/build.gradle&lt;br/&gt;
+++ b/sdks/java/fn-execution/build.gradle&lt;br/&gt;
@@ -24,7 +24,9 @@ description = &quot;Apache Beam :: SDKs :: Java :: Fn Execution&quot;&lt;br/&gt;
 dependencies {&lt;br/&gt;
   compile library.java.guava&lt;br/&gt;
   shadow project(path: &quot;:beam-model-parent:beam-model-pipeline&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
+  shadow project(path: &quot;:beam-model-parent:beam-model-fn-execution&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
   shadow project(path: &quot;:beam-sdks-parent:beam-sdks-java-parent:beam-sdks-java-core&quot;, configuration: &quot;shadow&quot;)&lt;br/&gt;
+  shadow library.java.slf4j_api&lt;br/&gt;
   shadow library.java.grpc_core&lt;br/&gt;
   shadow library.java.grpc_stub&lt;br/&gt;
   shadow library.java.grpc_netty&lt;br/&gt;
diff --git a/sdks/java/fn-execution/pom.xml b/sdks/java/fn-execution/pom.xml&lt;br/&gt;
index 773873e1490..82fc3ec7ce9 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/fn-execution/pom.xml&lt;br/&gt;
+++ b/sdks/java/fn-execution/pom.xml&lt;br/&gt;
@@ -40,6 +40,13 @@&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;beam-model-pipeline&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;br/&gt;
 &lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;beam-model-fn-execution&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+      &amp;lt;!-- The Core SDK is used for utility code and concepts shared between runner and SDK. It&lt;br/&gt;
+      should not be used to refer to any user-defined functions. --&amp;gt;&lt;br/&gt;
     &amp;lt;dependency&amp;gt;&lt;br/&gt;
       &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;beam-sdks-java-core&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
@@ -76,6 +83,18 @@&lt;br/&gt;
       &amp;lt;artifactId&amp;gt;guava&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
     &amp;lt;/dependency&amp;gt;&lt;br/&gt;
 &lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;slf4j-api&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
+    &amp;lt;!-- Build dependencies --&amp;gt;&lt;br/&gt;
+    &amp;lt;dependency&amp;gt;&lt;br/&gt;
+      &amp;lt;groupId&amp;gt;com.google.auto.value&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+      &amp;lt;artifactId&amp;gt;auto-value&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+      &amp;lt;scope&amp;gt;provided&amp;lt;/scope&amp;gt;&lt;br/&gt;
+    &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
     &amp;lt;!-- Test dependencies --&amp;gt;&lt;br/&gt;
     &amp;lt;dependency&amp;gt;&lt;br/&gt;
       &amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;&lt;br/&gt;
diff --git a/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/BeamFnDataBufferingOutboundObserver.java b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/BeamFnDataBufferingOutboundObserver.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..9c5fd36606c&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/BeamFnDataBufferingOutboundObserver.java&lt;br/&gt;
@@ -0,0 +1,133 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.beam.sdk.fn.data;&lt;br/&gt;
+&lt;br/&gt;
+import com.google.common.annotations.VisibleForTesting;&lt;br/&gt;
+import com.google.protobuf.ByteString;&lt;br/&gt;
+import io.grpc.stub.StreamObserver;&lt;br/&gt;
+import java.io.IOException;&lt;br/&gt;
+import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
+import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
+import org.slf4j.Logger;&lt;br/&gt;
+import org.slf4j.LoggerFactory;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * A buffering outbound {@link FnDataReceiver} for the Beam Fn Data API.&lt;br/&gt;
+ *&lt;br/&gt;
+ * &amp;lt;p&amp;gt;Encodes individually consumed elements with the provided {@link Coder} producing&lt;br/&gt;
+ * a single {@link BeamFnApi.Elements} message when the buffer threshold&lt;br/&gt;
+ * is surpassed.&lt;br/&gt;
+ *&lt;br/&gt;
+ * &amp;lt;p&amp;gt;The default buffer threshold can be overridden by specifying the experiment&lt;br/&gt;
+ * {@code beam_fn_api_data_buffer_limit=&amp;lt;bytes&amp;gt;}&lt;br/&gt;
+ *&lt;br/&gt;
+ * &amp;lt;p&amp;gt;TODO: Handle outputting large elements (&amp;gt; 2GiBs). Note that this also applies to the&lt;br/&gt;
+ * input side as well.&lt;br/&gt;
+ *&lt;br/&gt;
+ * &amp;lt;p&amp;gt;TODO: Handle outputting elements that are zero bytes by outputting a single byte as&lt;br/&gt;
+ * a marker, detect on the input side that no bytes were read and force reading a single byte.&lt;br/&gt;
+ */&lt;br/&gt;
+public class BeamFnDataBufferingOutboundObserver&amp;lt;T&amp;gt;&lt;br/&gt;
+    implements CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; {&lt;br/&gt;
+  // TODO: Consider moving this constant out of this class&lt;br/&gt;
+  public static final String BEAM_FN_API_DATA_BUFFER_LIMIT = &quot;beam_fn_api_data_buffer_limit=&quot;;&lt;br/&gt;
+  @VisibleForTesting&lt;br/&gt;
+  static final int DEFAULT_BUFFER_LIMIT_BYTES = 1_000_000;&lt;br/&gt;
+  private static final Logger LOG =&lt;br/&gt;
+      LoggerFactory.getLogger(BeamFnDataBufferingOutboundObserver.class);&lt;br/&gt;
+&lt;br/&gt;
+  public static &amp;lt;T&amp;gt; BeamFnDataBufferingOutboundObserver&amp;lt;T&amp;gt; forLocation(&lt;br/&gt;
+      LogicalEndpoint endpoint,&lt;br/&gt;
+      Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder,&lt;br/&gt;
+      StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt; outboundObserver) {
+    return forLocationWithBufferLimit(
+        DEFAULT_BUFFER_LIMIT_BYTES, endpoint, coder, outboundObserver);
+  }&lt;br/&gt;
+&lt;br/&gt;
+  public static &amp;lt;T&amp;gt; BeamFnDataBufferingOutboundObserver&amp;lt;T&amp;gt; forLocationWithBufferLimit(&lt;br/&gt;
+      int bufferLimit,&lt;br/&gt;
+      LogicalEndpoint endpoint,&lt;br/&gt;
+      Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder,&lt;br/&gt;
+      StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt; outboundObserver) {
+    return new BeamFnDataBufferingOutboundObserver&amp;lt;&amp;gt;(
+        bufferLimit, endpoint, coder, outboundObserver);
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private long byteCounter;&lt;br/&gt;
+  private long counter;&lt;br/&gt;
+  private final int bufferLimit;&lt;br/&gt;
+  private final Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder;&lt;br/&gt;
+  private final LogicalEndpoint outputLocation;&lt;br/&gt;
+  private final StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt; outboundObserver;&lt;br/&gt;
+  private final ByteString.Output bufferedElements;&lt;br/&gt;
+&lt;br/&gt;
+  private BeamFnDataBufferingOutboundObserver(&lt;br/&gt;
+      int bufferLimit,&lt;br/&gt;
+      LogicalEndpoint outputLocation,&lt;br/&gt;
+      Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder,&lt;br/&gt;
+      StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt; outboundObserver) {
+    this.bufferLimit = bufferLimit;
+    this.outputLocation = outputLocation;
+    this.coder = coder;
+    this.outboundObserver = outboundObserver;
+    this.bufferedElements = ByteString.newOutput();
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Override&lt;br/&gt;
+  public void close() throws Exception {&lt;br/&gt;
+    BeamFnApi.Elements.Builder elements = convertBufferForTransmission();&lt;br/&gt;
+    // This will add an empty data block representing the end of stream.&lt;br/&gt;
+    elements.addDataBuilder()&lt;br/&gt;
+        .setInstructionReference(outputLocation.getInstructionId())&lt;br/&gt;
+        .setTarget(outputLocation.getTarget());&lt;br/&gt;
+&lt;br/&gt;
+    LOG.debug(&quot;Closing stream for instruction {} and &quot;&lt;br/&gt;
+        + &quot;target {} having transmitted {} values {} bytes&quot;,&lt;br/&gt;
+        outputLocation.getInstructionId(),&lt;br/&gt;
+        outputLocation.getTarget(),&lt;br/&gt;
+        counter,&lt;br/&gt;
+        byteCounter);&lt;br/&gt;
+    outboundObserver.onNext(elements.build());&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Override&lt;br/&gt;
+  public void accept(WindowedValue&amp;lt;T&amp;gt; t) throws IOException {&lt;br/&gt;
+    coder.encode(t, bufferedElements);&lt;br/&gt;
+    counter += 1;&lt;br/&gt;
+    if (bufferedElements.size() &amp;gt;= bufferLimit) {
+      outboundObserver.onNext(convertBufferForTransmission().build());
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private BeamFnApi.Elements.Builder convertBufferForTransmission() {&lt;br/&gt;
+    BeamFnApi.Elements.Builder elements = BeamFnApi.Elements.newBuilder();&lt;br/&gt;
+    if (bufferedElements.size() == 0) {
+      return elements;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    elements.addDataBuilder()&lt;br/&gt;
+        .setInstructionReference(outputLocation.getInstructionId())&lt;br/&gt;
+        .setTarget(outputLocation.getTarget())&lt;br/&gt;
+        .setData(bufferedElements.toByteString());&lt;br/&gt;
+&lt;br/&gt;
+    byteCounter += bufferedElements.size();&lt;br/&gt;
+    bufferedElements.reset();&lt;br/&gt;
+    return elements;&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnDataReceiver.java b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/CloseableFnDataReceiver.java&lt;br/&gt;
similarity index 59%&lt;br/&gt;
rename from runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnDataReceiver.java&lt;br/&gt;
rename to sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/CloseableFnDataReceiver.java&lt;br/&gt;
index 639d678ad03..d497c8fed25 100644&lt;br/&gt;
&amp;#8212; a/runners/core-java/src/main/java/org/apache/beam/runners/core/fn/FnDataReceiver.java&lt;br/&gt;
+++ b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/CloseableFnDataReceiver.java&lt;br/&gt;
@@ -15,23 +15,20 @@&lt;br/&gt;
  * See the License for the specific language governing permissions and&lt;br/&gt;
  * limitations under the License.&lt;br/&gt;
  */&lt;br/&gt;
-package org.apache.beam.runners.core.fn;&lt;br/&gt;
 &lt;br/&gt;
-import java.io.Closeable;&lt;br/&gt;
+package org.apache.beam.sdk.fn.data;&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
- * A receiver of streamed data.&lt;br/&gt;
+ * A receiver of streamed data that can be closed.&lt;br/&gt;
  *&lt;br/&gt;
- * &amp;lt;p&amp;gt;Provide a {@link FnDataReceiver} and target to a {@link FnDataService} to listen for incoming&lt;br/&gt;
- * data.&lt;br/&gt;
- *&lt;br/&gt;
- * &amp;lt;p&amp;gt;Register a target with a {@link FnDataService} to gain a {@link FnDataReceiver} to which you&lt;br/&gt;
- * may write outgoing data.&lt;br/&gt;
- *&lt;br/&gt;
- * @deprecated Runners should depend on the beam-runners-java-fn-execution module for this&lt;br/&gt;
- *     functionality.&lt;br/&gt;
+ * &amp;lt;p&amp;gt;The close method for a {@link CloseableFnDataReceiver} must be idempotent.&lt;br/&gt;
  */&lt;br/&gt;
-@Deprecated&lt;br/&gt;
-public interface FnDataReceiver&amp;lt;T&amp;gt; extends Closeable {&lt;br/&gt;
-  void accept(T input) throws Exception;&lt;br/&gt;
+public interface CloseableFnDataReceiver&amp;lt;T&amp;gt; extends FnDataReceiver&amp;lt;T&amp;gt;, AutoCloseable {&lt;br/&gt;
+  /**&lt;br/&gt;
+   * {@inheritDoc}.&lt;br/&gt;
+   *&lt;br/&gt;
+   * &amp;lt;p&amp;gt;Does nothing if this {@link CloseableFnDataReceiver} is already closed.&lt;br/&gt;
+   */&lt;br/&gt;
+  @Override&lt;br/&gt;
+  void close() throws Exception;&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/data/FnDataReceiver.java b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/FnDataReceiver.java&lt;br/&gt;
similarity index 87%&lt;br/&gt;
rename from runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/data/FnDataReceiver.java&lt;br/&gt;
rename to sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/FnDataReceiver.java&lt;br/&gt;
index 5573d94f769..387b81aa817 100644&lt;br/&gt;
&amp;#8212; a/runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/data/FnDataReceiver.java&lt;br/&gt;
+++ b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/FnDataReceiver.java&lt;br/&gt;
@@ -15,13 +15,11 @@&lt;br/&gt;
  * See the License for the specific language governing permissions and&lt;br/&gt;
  * limitations under the License.&lt;br/&gt;
  */&lt;br/&gt;
-package org.apache.beam.runners.fnexecution.data;&lt;br/&gt;
-&lt;br/&gt;
-import java.io.Closeable;&lt;br/&gt;
+package org.apache.beam.sdk.fn.data;&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
  * A receiver of streamed data.&lt;br/&gt;
  */&lt;br/&gt;
-public interface FnDataReceiver&amp;lt;T&amp;gt; extends Closeable {&lt;br/&gt;
+public interface FnDataReceiver&amp;lt;T&amp;gt; {
   void accept(T input) throws Exception;
 }&lt;br/&gt;
diff --git a/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/LogicalEndpoint.java b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/LogicalEndpoint.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..785a8c944cb&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/LogicalEndpoint.java&lt;br/&gt;
@@ -0,0 +1,39 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.beam.sdk.fn.data;&lt;br/&gt;
+&lt;br/&gt;
+import com.google.auto.value.AutoValue;&lt;br/&gt;
+import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * A logical endpoint is a pair of an instruction ID corresponding to the {@link
+ * BeamFnApi.ProcessBundleRequest} and the {@link BeamFnApi.Target} within the processing graph.&lt;br/&gt;
+ * This enables the same Data Service or Data Client to be re-used across multiple bundles.&lt;br/&gt;
+ */&lt;br/&gt;
+@AutoValue&lt;br/&gt;
+public abstract class LogicalEndpoint {&lt;br/&gt;
+&lt;br/&gt;
+  public abstract String getInstructionId();&lt;br/&gt;
+&lt;br/&gt;
+  public abstract BeamFnApi.Target getTarget();&lt;br/&gt;
+&lt;br/&gt;
+  public static LogicalEndpoint of(String instructionId, BeamFnApi.Target target) {
+    return new AutoValue_LogicalEndpoint(instructionId, target);
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/package-info.java b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/package-info.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..e7a77c0b427&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/data/package-info.java&lt;br/&gt;
@@ -0,0 +1,22 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Classes to interact with the portability framework data plane.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.beam.sdk.fn.data;&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/stream/StreamObserverFactory.java b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/stream/StreamObserverFactory.java&lt;br/&gt;
similarity index 54%&lt;br/&gt;
rename from sdks/java/harness/src/main/java/org/apache/beam/fn/harness/stream/StreamObserverFactory.java&lt;br/&gt;
rename to sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/stream/StreamObserverFactory.java&lt;br/&gt;
index 1d9c29b6275..cf3957b3dc0 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/stream/StreamObserverFactory.java&lt;br/&gt;
+++ b/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/stream/StreamObserverFactory.java&lt;br/&gt;
@@ -16,57 +16,57 @@&lt;br/&gt;
  * limitations under the License.&lt;br/&gt;
  */&lt;br/&gt;
 &lt;br/&gt;
-package org.apache.beam.fn.harness.stream;&lt;br/&gt;
+package org.apache.beam.sdk.fn.stream;&lt;br/&gt;
 &lt;br/&gt;
 import io.grpc.stub.CallStreamObserver;&lt;br/&gt;
 import io.grpc.stub.StreamObserver;&lt;br/&gt;
-import java.util.List;&lt;br/&gt;
 import java.util.concurrent.ExecutorService;&lt;br/&gt;
-import java.util.function.Function;&lt;br/&gt;
-import org.apache.beam.sdk.extensions.gcp.options.GcsOptions;&lt;br/&gt;
-import org.apache.beam.sdk.fn.stream.AdvancingPhaser;&lt;br/&gt;
-import org.apache.beam.sdk.fn.stream.BufferingStreamObserver;&lt;br/&gt;
-import org.apache.beam.sdk.fn.stream.DirectStreamObserver;&lt;br/&gt;
-import org.apache.beam.sdk.fn.stream.ForwardingClientResponseObserver;&lt;br/&gt;
-import org.apache.beam.sdk.options.ExperimentalOptions;&lt;br/&gt;
-import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
- * Uses {@link PipelineOptions} to configure which underlying {@link StreamObserver} implementation&lt;br/&gt;
- * to use.&lt;br/&gt;
+ * Creates factories which determine an underlying {@link StreamObserver} implementation&lt;br/&gt;
+ * to use in to interact with fn execution APIs.&lt;br/&gt;
  */&lt;br/&gt;
 public abstract class StreamObserverFactory {&lt;br/&gt;
-  public static StreamObserverFactory fromOptions(PipelineOptions options) {&lt;br/&gt;
-    List&amp;lt;String&amp;gt; experiments = options.as(ExperimentalOptions.class).getExperiments();&lt;br/&gt;
-    if (experiments != null &amp;amp;&amp;amp; experiments.contains(&quot;beam_fn_api_buffered_stream&quot;)) {&lt;br/&gt;
-      int bufferSize = Buffered.DEFAULT_BUFFER_SIZE;&lt;br/&gt;
-      for (String experiment : experiments) {&lt;br/&gt;
-        if (experiment.startsWith(&quot;beam_fn_api_buffered_stream_buffer_size=&quot;)) {
-          bufferSize = Integer.parseInt(
-              experiment.substring(&quot;beam_fn_api_buffered_stream_buffer_size=&quot;.length()));
-        }&lt;br/&gt;
-      }&lt;br/&gt;
-      return new Buffered(options.as(GcsOptions.class).getExecutorService(), bufferSize);&lt;br/&gt;
-    }&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Create a buffering {@link StreamObserverFactory} with the specified {@link ExecutorService} and&lt;br/&gt;
+   * the default buffer size.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static StreamObserverFactory buffered(ExecutorService executorService) {
+    return new Buffered(executorService, Buffered.DEFAULT_BUFFER_SIZE);
+  }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Create a buffering {@link StreamObserverFactory} with the specified {@link ExecutorService} and&lt;br/&gt;
+   * buffer size.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static StreamObserverFactory buffered(&lt;br/&gt;
+      ExecutorService executorService, int bufferSize) {
+    return new Buffered(executorService, bufferSize);
+  }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Create the default {@link StreamObserverFactory}.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static StreamObserverFactory direct() {
     return new Direct();
   }&lt;br/&gt;
 &lt;br/&gt;
   public abstract &amp;lt;ReqT, RespT&amp;gt; StreamObserver&amp;lt;RespT&amp;gt; from(&lt;br/&gt;
-      Function&amp;lt;StreamObserver&amp;lt;ReqT&amp;gt;, StreamObserver&amp;lt;RespT&amp;gt;&amp;gt; clientFactory,&lt;br/&gt;
+      StreamObserverClientFactory&amp;lt;ReqT, RespT&amp;gt; clientFactory,&lt;br/&gt;
       StreamObserver&amp;lt;ReqT&amp;gt; responseObserver);&lt;br/&gt;
 &lt;br/&gt;
   private static class Direct extends StreamObserverFactory {&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
     public &amp;lt;ReqT, RespT&amp;gt; StreamObserver&amp;lt;RespT&amp;gt; from(&lt;br/&gt;
-        Function&amp;lt;StreamObserver&amp;lt;ReqT&amp;gt;, StreamObserver&amp;lt;RespT&amp;gt;&amp;gt; clientFactory,&lt;br/&gt;
+        StreamObserverClientFactory&amp;lt;ReqT, RespT&amp;gt; clientFactory,&lt;br/&gt;
         StreamObserver&amp;lt;ReqT&amp;gt; inboundObserver) {
       AdvancingPhaser phaser = new AdvancingPhaser(1);
       CallStreamObserver&amp;lt;RespT&amp;gt; outboundObserver =
           (CallStreamObserver&amp;lt;RespT&amp;gt;)
-              clientFactory.apply(
+              clientFactory.outboundObserverFor(
                   ForwardingClientResponseObserver.&amp;lt;ReqT, RespT&amp;gt;create(
-                      inboundObserver, phaser::arrive));
+                      inboundObserver, StreamObserverFactory.arriveAtPhaserHandler(phaser)));
       return new DirectStreamObserver&amp;lt;&amp;gt;(phaser, outboundObserver);
     }&lt;br/&gt;
   }&lt;br/&gt;
@@ -83,17 +83,38 @@ private Buffered(ExecutorService executorService, int bufferSize) {&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
     public &amp;lt;ReqT, RespT&amp;gt; StreamObserver&amp;lt;RespT&amp;gt; from(&lt;br/&gt;
-        Function&amp;lt;StreamObserver&amp;lt;ReqT&amp;gt;, StreamObserver&amp;lt;RespT&amp;gt;&amp;gt; clientFactory,&lt;br/&gt;
+        StreamObserverClientFactory&amp;lt;ReqT, RespT&amp;gt; clientFactory,&lt;br/&gt;
         StreamObserver&amp;lt;ReqT&amp;gt; inboundObserver) {
       AdvancingPhaser phaser = new AdvancingPhaser(1);
       CallStreamObserver&amp;lt;RespT&amp;gt; outboundObserver =
           (CallStreamObserver&amp;lt;RespT&amp;gt;)
-              clientFactory.apply(
+              clientFactory.outboundObserverFor(
                   ForwardingClientResponseObserver.&amp;lt;ReqT, RespT&amp;gt;create(
-                      inboundObserver, phaser::arrive));
+                      inboundObserver, StreamObserverFactory.arriveAtPhaserHandler(phaser)));
       return new BufferingStreamObserver&amp;lt;&amp;gt;(
           phaser, outboundObserver, executorService, bufferSize);
     }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private static Runnable arriveAtPhaserHandler(final AdvancingPhaser phaser) {&lt;br/&gt;
+    return new Runnable() {&lt;br/&gt;
+      @Override&lt;br/&gt;
+      public void run() {
+        phaser.arrive();
+      }&lt;br/&gt;
+    };&lt;br/&gt;
+  }&lt;br/&gt;
 &lt;br/&gt;
+  /**&lt;br/&gt;
+   * A factory which creates {@link StreamObserver StreamObservers} based on the input stream&lt;br/&gt;
+   * observer.&lt;br/&gt;
+   *&lt;br/&gt;
+   * &amp;lt;p&amp;gt;For example, this could be used to&lt;br/&gt;
+   *&lt;br/&gt;
+   * @param &amp;lt;RequestT&amp;gt; The type of message sent to the inbound stream&lt;br/&gt;
+   * @param &amp;lt;ResponseT&amp;gt; They type of messages sent over the outbound stream&lt;br/&gt;
+   */&lt;br/&gt;
+  public interface StreamObserverClientFactory&amp;lt;RequestT, ResponseT&amp;gt; {
+    StreamObserver&amp;lt;ResponseT&amp;gt; outboundObserverFor(StreamObserver&amp;lt;RequestT&amp;gt; inboundObserver);
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/fn-execution/src/test/java/org/apache/beam/sdk/fn/data/BeamFnDataBufferingOutboundObserverTest.java b/sdks/java/fn-execution/src/test/java/org/apache/beam/sdk/fn/data/BeamFnDataBufferingOutboundObserverTest.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..d2f2cf90988&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/fn-execution/src/test/java/org/apache/beam/sdk/fn/data/BeamFnDataBufferingOutboundObserverTest.java&lt;br/&gt;
@@ -0,0 +1,169 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.beam.sdk.fn.data;&lt;br/&gt;
+&lt;br/&gt;
+import static org.apache.beam.sdk.util.WindowedValue.valueInGlobalWindow;&lt;br/&gt;
+import static org.hamcrest.Matchers.empty;&lt;br/&gt;
+import static org.junit.Assert.assertEquals;&lt;br/&gt;
+import static org.junit.Assert.assertThat;&lt;br/&gt;
+&lt;br/&gt;
+import com.google.common.collect.Iterables;&lt;br/&gt;
+import com.google.protobuf.ByteString;&lt;br/&gt;
+import java.io.IOException;&lt;br/&gt;
+import java.util.ArrayList;&lt;br/&gt;
+import java.util.Collection;&lt;br/&gt;
+import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
+import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
+import org.apache.beam.model.fnexecution.v1.BeamFnApi.Elements;&lt;br/&gt;
+import org.apache.beam.model.fnexecution.v1.BeamFnApi.Target;&lt;br/&gt;
+import org.apache.beam.sdk.coders.ByteArrayCoder;&lt;br/&gt;
+import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.coders.LengthPrefixCoder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.test.Consumer;&lt;br/&gt;
+import org.apache.beam.sdk.fn.test.TestStreams;&lt;br/&gt;
+import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
+import org.junit.Test;&lt;br/&gt;
+import org.junit.runner.RunWith;&lt;br/&gt;
+import org.junit.runners.JUnit4;&lt;br/&gt;
+&lt;br/&gt;
+/** Tests for {@link BeamFnDataBufferingOutboundObserver}. */&lt;br/&gt;
+@RunWith(JUnit4.class)&lt;br/&gt;
+public class BeamFnDataBufferingOutboundObserverTest {&lt;br/&gt;
+  private static final LogicalEndpoint OUTPUT_LOCATION =&lt;br/&gt;
+      LogicalEndpoint.of(&lt;br/&gt;
+          &quot;777L&quot;,&lt;br/&gt;
+          Target.newBuilder()&lt;br/&gt;
+              .setPrimitiveTransformReference(&quot;555L&quot;)&lt;br/&gt;
+              .setName(&quot;Test&quot;)&lt;br/&gt;
+              .build());&lt;br/&gt;
+  private static final Coder&amp;lt;WindowedValue&amp;lt;byte[]&amp;gt;&amp;gt; CODER =&lt;br/&gt;
+      LengthPrefixCoder.of(WindowedValue.getValueOnlyCoder(ByteArrayCoder.of()));&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void testWithDefaultBuffer() throws Exception {
+    final Collection&amp;lt;BeamFnApi.Elements&amp;gt; values = new ArrayList&amp;lt;&amp;gt;();
+    final AtomicBoolean onCompletedWasCalled = new AtomicBoolean();
+    CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;byte[]&amp;gt;&amp;gt; consumer =
+        BeamFnDataBufferingOutboundObserver.forLocation(
+            OUTPUT_LOCATION,
+            CODER,
+            TestStreams.withOnNext(addToValuesConsumer(values))
+                .withOnCompleted(setBooleanToTrue(onCompletedWasCalled))
+                .build());
+
+    // Test that nothing is emitted till the default buffer size is surpassed.
+    consumer.accept(
+        valueInGlobalWindow(
+            new byte[BeamFnDataBufferingOutboundObserver.DEFAULT_BUFFER_LIMIT_BYTES - 50]));
+    assertThat(values, empty());
+
+    // Test that when we cross the buffer, we emit.
+    consumer.accept(valueInGlobalWindow(new byte[50]));
+    assertEquals(
+        messageWithData(
+            new byte[BeamFnDataBufferingOutboundObserver.DEFAULT_BUFFER_LIMIT_BYTES - 50],
+            new byte[50]),
+        Iterables.get(values, 0));
+
+    // Test that nothing is emitted till the default buffer size is surpassed after a reset
+    consumer.accept(
+        valueInGlobalWindow(
+            new byte[BeamFnDataBufferingOutboundObserver.DEFAULT_BUFFER_LIMIT_BYTES - 50]));
+    assertEquals(1, values.size());
+
+    // Test that when we cross the buffer, we emit.
+    consumer.accept(valueInGlobalWindow(new byte[50]));
+    assertEquals(
+        messageWithData(
+            new byte[BeamFnDataBufferingOutboundObserver.DEFAULT_BUFFER_LIMIT_BYTES - 50],
+            new byte[50]),
+        Iterables.get(values, 1));
+
+    // Test that when we close with an empty buffer we only have one end of stream
+    consumer.close();
+    assertEquals(messageWithData(),
+        Iterables.get(values, 2));
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void testConfiguredBufferLimit() throws Exception {
+    Collection&amp;lt;BeamFnApi.Elements&amp;gt; values = new ArrayList&amp;lt;&amp;gt;();
+    AtomicBoolean onCompletedWasCalled = new AtomicBoolean();
+    CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;byte[]&amp;gt;&amp;gt; consumer =
+        BeamFnDataBufferingOutboundObserver.forLocationWithBufferLimit(
+            100,
+            OUTPUT_LOCATION,
+            CODER,
+            TestStreams.withOnNext(addToValuesConsumer(values))
+                .withOnCompleted(setBooleanToTrue(onCompletedWasCalled))
+                .build());
+
+    // Test that nothing is emitted till the default buffer size is surpassed.
+    consumer.accept(valueInGlobalWindow(new byte[51]));
+    assertThat(values, empty());
+
+    // Test that when we cross the buffer, we emit.
+    consumer.accept(valueInGlobalWindow(new byte[49]));
+    assertEquals(
+        messageWithData(new byte[51], new byte[49]),
+        Iterables.get(values, 0));
+
+    // Test that when we close we empty the value, and then the stream terminator as part
+    // of the same message
+    consumer.accept(valueInGlobalWindow(new byte[1]));
+    consumer.close();
+    assertEquals(
+        BeamFnApi.Elements.newBuilder(messageWithData(new byte[1]))
+            .addData(BeamFnApi.Elements.Data.newBuilder()
+                .setInstructionReference(OUTPUT_LOCATION.getInstructionId())
+                .setTarget(OUTPUT_LOCATION.getTarget()))
+            .build(),
+        Iterables.get(values, 1));
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private static BeamFnApi.Elements messageWithData(byte[] ... datum) throws IOException {&lt;br/&gt;
+    ByteString.Output output = ByteString.newOutput();&lt;br/&gt;
+    for (byte[] data : datum) {
+      CODER.encode(valueInGlobalWindow(data), output);
+    }&lt;br/&gt;
+    return BeamFnApi.Elements.newBuilder()&lt;br/&gt;
+        .addData(BeamFnApi.Elements.Data.newBuilder()&lt;br/&gt;
+            .setInstructionReference(OUTPUT_LOCATION.getInstructionId())&lt;br/&gt;
+            .setTarget(OUTPUT_LOCATION.getTarget())&lt;br/&gt;
+            .setData(output.toByteString()))&lt;br/&gt;
+        .build();&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private Consumer&amp;lt;Elements&amp;gt; addToValuesConsumer(final Collection&amp;lt;Elements&amp;gt; values) {&lt;br/&gt;
+    return new Consumer&amp;lt;Elements&amp;gt;() {&lt;br/&gt;
+      @Override&lt;br/&gt;
+      public void accept(Elements item) {
+        values.add(item);
+      }&lt;br/&gt;
+    };&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private Runnable setBooleanToTrue(final AtomicBoolean onCompletedWasCalled) {&lt;br/&gt;
+    return new Runnable() {&lt;br/&gt;
+      @Override&lt;br/&gt;
+      public void run() {
+        onCompletedWasCalled.set(true);
+      }&lt;br/&gt;
+    };&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/sdks/java/fn-execution/src/test/java/org/apache/beam/sdk/fn/stream/StreamObserverFactoryTest.java b/sdks/java/fn-execution/src/test/java/org/apache/beam/sdk/fn/stream/StreamObserverFactoryTest.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..1f05d9aa5de&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/fn-execution/src/test/java/org/apache/beam/sdk/fn/stream/StreamObserverFactoryTest.java&lt;br/&gt;
@@ -0,0 +1,80 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.beam.sdk.fn.stream;&lt;br/&gt;
+&lt;br/&gt;
+import static org.hamcrest.Matchers.instanceOf;&lt;br/&gt;
+import static org.junit.Assert.assertEquals;&lt;br/&gt;
+import static org.junit.Assert.assertThat;&lt;br/&gt;
+&lt;br/&gt;
+import io.grpc.stub.CallStreamObserver;&lt;br/&gt;
+import io.grpc.stub.StreamObserver;&lt;br/&gt;
+import java.util.concurrent.Executors;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory.StreamObserverClientFactory;&lt;br/&gt;
+import org.junit.Before;&lt;br/&gt;
+import org.junit.Test;&lt;br/&gt;
+import org.junit.runner.RunWith;&lt;br/&gt;
+import org.junit.runners.JUnit4;&lt;br/&gt;
+import org.mockito.Mock;&lt;br/&gt;
+import org.mockito.MockitoAnnotations;&lt;br/&gt;
+&lt;br/&gt;
+/** Tests for {@link StreamObserverFactory}. */&lt;br/&gt;
+@RunWith(JUnit4.class)&lt;br/&gt;
+public class StreamObserverFactoryTest {&lt;br/&gt;
+  @Mock private StreamObserver&amp;lt;Integer&amp;gt; mockRequestObserver;&lt;br/&gt;
+  @Mock private CallStreamObserver&amp;lt;String&amp;gt; mockResponseObserver;&lt;br/&gt;
+&lt;br/&gt;
+  @Before&lt;br/&gt;
+  public void setUp() {
+    MockitoAnnotations.initMocks(this);
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void testDefaultInstantiation() {
+    StreamObserver&amp;lt;String&amp;gt; observer =
+        StreamObserverFactory.direct().from(this.fakeFactory(), mockRequestObserver);
+    assertThat(observer, instanceOf(DirectStreamObserver.class));
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void testBufferedStreamInstantiation() {
+    StreamObserver&amp;lt;String&amp;gt; observer =
+        StreamObserverFactory.buffered(Executors.newSingleThreadExecutor())
+            .from(this.fakeFactory(), mockRequestObserver);
+    assertThat(observer, instanceOf(BufferingStreamObserver.class));
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void testBufferedStreamWithLimitInstantiation() {
+    StreamObserver&amp;lt;String&amp;gt; observer =
+        StreamObserverFactory.buffered(Executors.newSingleThreadExecutor(), 1)
+            .from(this.fakeFactory(), mockRequestObserver);
+    assertThat(observer, instanceOf(BufferingStreamObserver.class));
+    assertEquals(1, ((BufferingStreamObserver&amp;lt;String&amp;gt;) observer).getBufferSize());
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private StreamObserverClientFactory&amp;lt;Integer, String&amp;gt; fakeFactory() {&lt;br/&gt;
+    return new StreamObserverClientFactory&amp;lt;Integer, String&amp;gt;() {&lt;br/&gt;
+      @Override&lt;br/&gt;
+      public StreamObserver&amp;lt;String&amp;gt; outboundObserverFor(StreamObserver&amp;lt;Integer&amp;gt; inboundObserver) {
+        assertThat(inboundObserver, instanceOf(ForwardingClientResponseObserver.class));
+        return mockResponseObserver;
+      }&lt;br/&gt;
+    };&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BeamFnDataReadRunner.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BeamFnDataReadRunner.java&lt;br/&gt;
index ff3dfb291db..a72749fa2f2 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BeamFnDataReadRunner.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BeamFnDataReadRunner.java&lt;br/&gt;
@@ -31,24 +31,27 @@&lt;br/&gt;
 import java.util.function.Consumer;&lt;br/&gt;
 import java.util.function.Supplier;&lt;br/&gt;
 import org.apache.beam.fn.harness.data.BeamFnDataClient;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
+import org.apache.beam.fn.harness.data.MultiplexingFnDataReceiver;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BeamFnStateClient;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PCollection;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PTransform;&lt;br/&gt;
 import org.apache.beam.runners.core.construction.CoderTranslation;&lt;br/&gt;
 import org.apache.beam.runners.core.construction.RehydratedComponents;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
  * Registers as a consumer for data over the Beam Fn API. Multiplexes any received data&lt;br/&gt;
- * to all consumers in the specified output map.&lt;br/&gt;
+ * to all receivers in a specified output map.&lt;br/&gt;
  *&lt;br/&gt;
  * &amp;lt;p&amp;gt;Can be re-used serially across {@link BeamFnApi.ProcessBundleRequest}s.&lt;br/&gt;
  * For each request, call {@link #registerInputLocation()} to start and call&lt;br/&gt;
@@ -81,11 +84,12 @@&lt;br/&gt;
         BeamFnDataClient beamFnDataClient,&lt;br/&gt;
         BeamFnStateClient beamFnStateClient,&lt;br/&gt;
         String pTransformId,&lt;br/&gt;
-        RunnerApi.PTransform pTransform,&lt;br/&gt;
+        PTransform pTransform,&lt;br/&gt;
         Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-        Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
+        Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
         Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-        Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+        Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+        Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
         Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
         Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {
 
@@ -96,7 +100,7 @@
       RunnerApi.Coder coderSpec =
           coders.get(
               pCollections.get(getOnlyElement(pTransform.getOutputsMap().values())).getCoderId());
-      Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers =
+      Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers =
           (Collection) pCollectionIdsToConsumers.get(
               getOnlyElement(pTransform.getOutputsMap().values()));
 
@@ -115,7 +119,7 @@
   }&lt;br/&gt;
 &lt;br/&gt;
   private final Endpoints.ApiServiceDescriptor apiServiceDescriptor;&lt;br/&gt;
-  private final Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers;&lt;br/&gt;
+  private final FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt; receiver;&lt;br/&gt;
   private final Supplier&amp;lt;String&amp;gt; processBundleInstructionIdSupplier;&lt;br/&gt;
   private final BeamFnDataClient beamFnDataClientFactory;&lt;br/&gt;
   private final Coder&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt; coder;&lt;br/&gt;
@@ -130,14 +134,14 @@&lt;br/&gt;
       RunnerApi.Coder coderSpec,&lt;br/&gt;
       Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
       BeamFnDataClient beamFnDataClientFactory,&lt;br/&gt;
-      Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers)&lt;br/&gt;
+      Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers)&lt;br/&gt;
           throws IOException {
     this.apiServiceDescriptor =
         BeamFnApi.RemoteGrpcPort.parseFrom(functionSpec.getPayload()).getApiServiceDescriptor();
     this.inputTarget = inputTarget;
     this.processBundleInstructionIdSupplier = processBundleInstructionIdSupplier;
     this.beamFnDataClientFactory = beamFnDataClientFactory;
-    this.consumers = consumers;
+    this.receiver = MultiplexingFnDataReceiver.forConsumers(consumers);
 
     @SuppressWarnings(&quot;unchecked&quot;)
     Coder&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt; coder =
@@ -150,11 +154,11 @@
   }&lt;br/&gt;
 &lt;br/&gt;
   public void registerInputLocation() {
-    this.readFuture = beamFnDataClientFactory.forInboundConsumer(
+    this.readFuture = beamFnDataClientFactory.receive(
         apiServiceDescriptor,
-        KV.of(processBundleInstructionIdSupplier.get(), inputTarget),
+        LogicalEndpoint.of(processBundleInstructionIdSupplier.get(), inputTarget),
         coder,
-        this::multiplexToConsumers);
+        receiver);
   }&lt;br/&gt;
 &lt;br/&gt;
   public void blockTillReadFinishes() throws Exception {&lt;br/&gt;
@@ -162,10 +166,4 @@ public void blockTillReadFinishes() throws Exception {
         processBundleInstructionIdSupplier.get(), inputTarget);
     readFuture.get();
   }&lt;br/&gt;
-&lt;br/&gt;
-  private void multiplexToConsumers(WindowedValue&amp;lt;OutputT&amp;gt; value) throws Exception {&lt;br/&gt;
-    for (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt; consumer : consumers) {
-      consumer.accept(value);
-    }&lt;br/&gt;
-  }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BeamFnDataWriteRunner.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BeamFnDataWriteRunner.java&lt;br/&gt;
index bf1994e658c..2d4df456ec2 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BeamFnDataWriteRunner.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BeamFnDataWriteRunner.java&lt;br/&gt;
@@ -29,19 +29,21 @@&lt;br/&gt;
 import java.util.function.Consumer;&lt;br/&gt;
 import java.util.function.Supplier;&lt;br/&gt;
 import org.apache.beam.fn.harness.data.BeamFnDataClient;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.CloseableThrowingConsumer;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BeamFnStateClient;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PCollection;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PTransform;&lt;br/&gt;
 import org.apache.beam.runners.core.construction.CoderTranslation;&lt;br/&gt;
 import org.apache.beam.runners.core.construction.RehydratedComponents;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 &lt;br/&gt;
 /**&lt;br/&gt;
  * Registers as a consumer with the Beam Fn Data Api. Consumes elements and encodes them for&lt;br/&gt;
@@ -76,11 +78,12 @@&lt;br/&gt;
         BeamFnDataClient beamFnDataClient,&lt;br/&gt;
         BeamFnStateClient beamFnStateClient,&lt;br/&gt;
         String pTransformId,&lt;br/&gt;
-        RunnerApi.PTransform pTransform,&lt;br/&gt;
+        PTransform pTransform,&lt;br/&gt;
         Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-        Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
+        Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
         Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-        Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+        Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+        Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
         Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
         Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {
       BeamFnApi.Target target = BeamFnApi.Target.newBuilder()
@@ -100,8 +103,8 @@
       addStartFunction.accept(runner::registerForOutput);
       pCollectionIdsToConsumers.put(
           getOnlyElement(pTransform.getInputsMap().values()),
-          (ThrowingConsumer)
-              (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;InputT&amp;gt;&amp;gt;) runner::consume);
+          (FnDataReceiver)
+              (FnDataReceiver&amp;lt;WindowedValue&amp;lt;InputT&amp;gt;&amp;gt;) runner::consume);
       addFinishFunction.accept(runner::close);
       return runner;
     }&lt;br/&gt;
@@ -113,7 +116,7 @@&lt;br/&gt;
   private final BeamFnDataClient beamFnDataClientFactory;&lt;br/&gt;
   private final Supplier&amp;lt;String&amp;gt; processBundleInstructionIdSupplier;&lt;br/&gt;
 &lt;br/&gt;
-  private CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;InputT&amp;gt;&amp;gt; consumer;&lt;br/&gt;
+  private CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;InputT&amp;gt;&amp;gt; consumer;&lt;br/&gt;
 &lt;br/&gt;
   BeamFnDataWriteRunner(&lt;br/&gt;
       RunnerApi.FunctionSpec functionSpec,&lt;br/&gt;
@@ -140,9 +143,9 @@&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   public void registerForOutput() {
-    consumer = beamFnDataClientFactory.forOutboundConsumer(
+    consumer = beamFnDataClientFactory.send(
         apiServiceDescriptor,
-        KV.of(processBundleInstructionIdSupplier.get(), outputTarget),
+        LogicalEndpoint.of(processBundleInstructionIdSupplier.get(), outputTarget),
         coder);
   }&lt;br/&gt;
 &lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BoundedSourceRunner.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BoundedSourceRunner.java&lt;br/&gt;
index d52336526fb..f09c77d4ee0 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BoundedSourceRunner.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/BoundedSourceRunner.java&lt;br/&gt;
@@ -28,11 +28,18 @@&lt;br/&gt;
 import java.util.Map;&lt;br/&gt;
 import java.util.function.Consumer;&lt;br/&gt;
 import java.util.function.Supplier;&lt;br/&gt;
+import org.apache.beam.fn.harness.control.ProcessBundleHandler;&lt;br/&gt;
 import org.apache.beam.fn.harness.data.BeamFnDataClient;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BeamFnStateClient;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.Coder;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PCollection;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PTransform;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.ReadPayload;&lt;br/&gt;
+import org.apache.beam.runners.core.construction.PTransformTranslation;&lt;br/&gt;
+import org.apache.beam.runners.core.construction.ReadTranslation;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
 import org.apache.beam.sdk.io.BoundedSource;&lt;br/&gt;
 import org.apache.beam.sdk.io.Source.Reader;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
@@ -45,8 +52,6 @@&lt;br/&gt;
  */&lt;br/&gt;
 public class BoundedSourceRunner&amp;lt;InputT extends BoundedSource&amp;lt;OutputT&amp;gt;, OutputT&amp;gt; {&lt;br/&gt;
 &lt;br/&gt;
-  private static final String URN = &quot;urn:org.apache.beam:source:java:0.1&quot;;&lt;br/&gt;
-&lt;br/&gt;
   /** A registrar which provides a factory to handle Java {@link BoundedSource}s. */&lt;br/&gt;
   @AutoService(PTransformRunnerFactory.Registrar.class)&lt;br/&gt;
   public static class Registrar implements&lt;br/&gt;
@@ -54,7 +59,9 @@&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
     public Map&amp;lt;String, PTransformRunnerFactory&amp;gt; getPTransformRunnerFactories() {
-      return ImmutableMap.of(URN, new Factory());
+      return ImmutableMap.of(
+          ProcessBundleHandler.JAVA_SOURCE_URN, new Factory(),
+          PTransformTranslation.READ_TRANSFORM_URN, new Factory());
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
@@ -67,15 +74,16 @@&lt;br/&gt;
         BeamFnDataClient beamFnDataClient,&lt;br/&gt;
         BeamFnStateClient beamFnStateClient,&lt;br/&gt;
         String pTransformId,&lt;br/&gt;
-        RunnerApi.PTransform pTransform,&lt;br/&gt;
+        PTransform pTransform,&lt;br/&gt;
         Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-        Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
-        Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-        Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+        Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+        Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+        Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+        Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
         Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
         Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) {&lt;br/&gt;
 &lt;br/&gt;
-      ImmutableList.Builder&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = ImmutableList.builder();&lt;br/&gt;
+      ImmutableList.Builder&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = ImmutableList.builder();&lt;br/&gt;
       for (String pCollectionId : pTransform.getOutputsMap().values()) {
         consumers.addAll(pCollectionIdsToConsumers.get(pCollectionId));
       }&lt;br/&gt;
@@ -89,8 +97,8 @@&lt;br/&gt;
       // TODO: Remove and replace with source being sent across gRPC port&lt;br/&gt;
       addStartFunction.accept(runner::start);&lt;br/&gt;
 &lt;br/&gt;
-      ThrowingConsumer runReadLoop =&lt;br/&gt;
-          (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;InputT&amp;gt;&amp;gt;) runner::runReadLoop;&lt;br/&gt;
+      FnDataReceiver runReadLoop =&lt;br/&gt;
+          (FnDataReceiver&amp;lt;WindowedValue&amp;lt;InputT&amp;gt;&amp;gt;) runner::runReadLoop;&lt;br/&gt;
       for (String pCollectionId : pTransform.getInputsMap().values()) {&lt;br/&gt;
         pCollectionIdsToConsumers.put(&lt;br/&gt;
             pCollectionId,&lt;br/&gt;
@@ -103,12 +111,12 @@&lt;br/&gt;
 &lt;br/&gt;
   private final PipelineOptions pipelineOptions;&lt;br/&gt;
   private final RunnerApi.FunctionSpec definition;&lt;br/&gt;
-  private final Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers;&lt;br/&gt;
+  private final Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers;&lt;br/&gt;
 &lt;br/&gt;
   BoundedSourceRunner(&lt;br/&gt;
       PipelineOptions pipelineOptions,&lt;br/&gt;
       RunnerApi.FunctionSpec definition,&lt;br/&gt;
-      Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers) {&lt;br/&gt;
+      Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; consumers) {&lt;br/&gt;
     this.pipelineOptions = pipelineOptions;&lt;br/&gt;
     this.definition = definition;&lt;br/&gt;
     this.consumers = consumers;&lt;br/&gt;
@@ -124,10 +132,19 @@ public void start() throws Exception {&lt;br/&gt;
     try {&lt;br/&gt;
       // The representation here is defined as the java serialized representation of the&lt;br/&gt;
       // bounded source object in a ByteString wrapper.&lt;br/&gt;
-      byte[] bytes = definition.getPayload().toByteArray();&lt;br/&gt;
-      @SuppressWarnings(&quot;unchecked&quot;)&lt;br/&gt;
-      InputT boundedSource =&lt;br/&gt;
-          (InputT) SerializableUtils.deserializeFromByteArray(bytes, definition.toString());&lt;br/&gt;
+      InputT boundedSource;&lt;br/&gt;
+      if (definition.getUrn().equals(ProcessBundleHandler.JAVA_SOURCE_URN)) {
+        byte[] bytes = definition.getPayload().toByteArray();
+        @SuppressWarnings(&quot;unchecked&quot;)
+        InputT boundedSource0 =
+            (InputT) SerializableUtils.deserializeFromByteArray(bytes, definition.toString());
+        boundedSource = boundedSource0;
+      } else if (definition.getUrn().equals(PTransformTranslation.READ_TRANSFORM_URN)) {
+        ReadPayload readPayload = ReadPayload.parseFrom(definition.getPayload());
+        boundedSource = (InputT) ReadTranslation.boundedSourceFromProto(readPayload);
+      } else {
+        throw new IllegalArgumentException(&quot;Unknown source URN: &quot; + definition.getUrn());
+      }&lt;br/&gt;
       runReadLoop(WindowedValue.valueInGlobalWindow(boundedSource));&lt;br/&gt;
     } catch (InvalidProtocolBufferException e) {&lt;br/&gt;
       throw new IOException(String.format(&quot;Failed to decode %s&quot;, definition.getUrn()), e);&lt;br/&gt;
@@ -151,7 +168,7 @@ public void runReadLoop(WindowedValue&amp;lt;InputT&amp;gt; value) throws Exception {&lt;br/&gt;
         // TODO: Should this use the input window as the window for all the outputs?&lt;br/&gt;
         WindowedValue&amp;lt;OutputT&amp;gt; nextValue = WindowedValue.timestampedValueInGlobalWindow(&lt;br/&gt;
             reader.getCurrent(), reader.getCurrentTimestamp());&lt;br/&gt;
-        for (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt; consumer : consumers) {&lt;br/&gt;
+        for (FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt; consumer : consumers) {
           consumer.accept(nextValue);
         }&lt;br/&gt;
       } while (reader.advance());&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/FnApiDoFnRunner.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/FnApiDoFnRunner.java&lt;br/&gt;
index cad8985ba8f..6d29e47a31e 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/FnApiDoFnRunner.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/FnApiDoFnRunner.java&lt;br/&gt;
@@ -27,8 +27,10 @@&lt;br/&gt;
 import com.google.common.collect.ImmutableList;&lt;br/&gt;
 import com.google.common.collect.ImmutableMap;&lt;br/&gt;
 import com.google.common.collect.ImmutableMultimap;&lt;br/&gt;
+import com.google.common.collect.Iterables;&lt;br/&gt;
 import com.google.common.collect.Multimap;&lt;br/&gt;
 import com.google.protobuf.ByteString;&lt;br/&gt;
+import com.google.protobuf.InvalidProtocolBufferException;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
@@ -41,7 +43,6 @@&lt;br/&gt;
 import java.util.function.Function;&lt;br/&gt;
 import java.util.function.Supplier;&lt;br/&gt;
 import org.apache.beam.fn.harness.data.BeamFnDataClient;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BagUserState;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BeamFnStateClient;&lt;br/&gt;
@@ -49,10 +50,16 @@&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateRequest;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateRequest.Builder;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PCollection;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PTransform;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.ParDoPayload;&lt;br/&gt;
 import org.apache.beam.runners.core.DoFnRunner;&lt;br/&gt;
+import org.apache.beam.runners.core.construction.PTransformTranslation;&lt;br/&gt;
 import org.apache.beam.runners.core.construction.ParDoTranslation;&lt;br/&gt;
+import org.apache.beam.runners.core.construction.RehydratedComponents;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.KvCoder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.state.BagState;&lt;br/&gt;
 import org.apache.beam.sdk.state.CombiningState;&lt;br/&gt;
@@ -109,7 +116,9 @@&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
     public Map&amp;lt;String, PTransformRunnerFactory&amp;gt; getPTransformRunnerFactories() {
-      return ImmutableMap.of(ParDoTranslation.CUSTOM_JAVA_DO_FN_URN, new Factory());
+      return ImmutableMap.of(
+          PTransformTranslation.PAR_DO_TRANSFORM_URN, new NewFactory(),
+          ParDoTranslation.CUSTOM_JAVA_DO_FN_URN, new Factory());
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
@@ -123,23 +132,24 @@&lt;br/&gt;
         BeamFnDataClient beamFnDataClient,&lt;br/&gt;
         BeamFnStateClient beamFnStateClient,&lt;br/&gt;
         String pTransformId,&lt;br/&gt;
-        RunnerApi.PTransform pTransform,&lt;br/&gt;
+        PTransform pTransform,&lt;br/&gt;
         Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-        Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
+        Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
         Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-        Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+        Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+        Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
         Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
         Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) {&lt;br/&gt;
 &lt;br/&gt;
       // For every output PCollection, create a map from output name to Consumer&lt;br/&gt;
-      ImmutableMap.Builder&amp;lt;String, Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
+      ImmutableMap.Builder&amp;lt;String, Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
           outputMapBuilder = ImmutableMap.builder();&lt;br/&gt;
       for (Map.Entry&amp;lt;String, String&amp;gt; entry : pTransform.getOutputsMap().entrySet()) {
         outputMapBuilder.put(
             entry.getKey(),
             pCollectionIdsToConsumers.get(entry.getValue()));
       }&lt;br/&gt;
-      ImmutableMap&amp;lt;String, Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt;&amp;gt; outputMap =&lt;br/&gt;
+      ImmutableMap&amp;lt;String, Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt;&amp;gt; outputMap =&lt;br/&gt;
           outputMapBuilder.build();&lt;br/&gt;
 &lt;br/&gt;
       // Get the DoFnInfo from the serialized blob.&lt;br/&gt;
@@ -158,16 +168,16 @@&lt;br/&gt;
           doFnInfo.getOutputMap());&lt;br/&gt;
 &lt;br/&gt;
       ImmutableMultimap.Builder&amp;lt;TupleTag&amp;lt;?&amp;gt;,&lt;br/&gt;
-          ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; tagToOutputMapBuilder =&lt;br/&gt;
+          FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; tagToOutputMapBuilder =&lt;br/&gt;
           ImmutableMultimap.builder();&lt;br/&gt;
       for (Map.Entry&amp;lt;Long, TupleTag&amp;lt;?&amp;gt;&amp;gt; entry : doFnInfo.getOutputMap().entrySet()) {&lt;br/&gt;
         @SuppressWarnings({&quot;unchecked&quot;, &quot;rawtypes&quot;}
&lt;p&gt;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers =&lt;br/&gt;
+        Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers =&lt;br/&gt;
             outputMap.get(Long.toString(entry.getKey()));&lt;br/&gt;
         tagToOutputMapBuilder.putAll(entry.getValue(), consumers);&lt;br/&gt;
       }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ImmutableMultimap&amp;lt;TupleTag&amp;lt;?&amp;gt;, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; tagToOutputMap =&lt;br/&gt;
+      ImmutableMultimap&amp;lt;TupleTag&amp;lt;?&amp;gt;, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; tagToOutputMap =&lt;br/&gt;
           tagToOutputMapBuilder.build();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       @SuppressWarnings(&lt;/p&gt;
{&quot;unchecked&quot;, &quot;rawtypes&quot;})&lt;br/&gt;
@@ -180,23 +190,106 @@&lt;br/&gt;
           WindowedValue.getFullCoder(&lt;br/&gt;
               doFnInfo.getInputCoder(),&lt;br/&gt;
               doFnInfo.getWindowingStrategy().getWindowFn().windowCoder()),&lt;br/&gt;
-          (Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt;) (Collection)&lt;br/&gt;
+          (Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt;) (Collection)&lt;br/&gt;
               tagToOutputMap.get(doFnInfo.getOutputMap().get(doFnInfo.getMainOutput())),&lt;br/&gt;
           tagToOutputMap,&lt;br/&gt;
           doFnInfo.getWindowingStrategy());&lt;br/&gt;
 &lt;br/&gt;
-      // Register the appropriate handlers.&lt;br/&gt;
-      addStartFunction.accept(runner::startBundle);&lt;br/&gt;
-      for (String pcollectionId : pTransform.getInputsMap().values()) {
-        pCollectionIdsToConsumers.put(
-            pcollectionId,
-            (ThrowingConsumer) (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;InputT&amp;gt;&amp;gt;) runner::processElement);
+      registerHandlers(
+          runner, pTransform, addStartFunction, addFinishFunction, pCollectionIdsToConsumers);
+      return runner;
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  static class NewFactory&amp;lt;InputT, OutputT&amp;gt;&lt;br/&gt;
+      implements PTransformRunnerFactory&amp;lt;DoFnRunner&amp;lt;InputT, OutputT&amp;gt;&amp;gt; {&lt;br/&gt;
+&lt;br/&gt;
+    @Override&lt;br/&gt;
+    public DoFnRunner&amp;lt;InputT, OutputT&amp;gt; createRunnerForPTransform(&lt;br/&gt;
+        PipelineOptions pipelineOptions,&lt;br/&gt;
+        BeamFnDataClient beamFnDataClient,&lt;br/&gt;
+        BeamFnStateClient beamFnStateClient,&lt;br/&gt;
+        String pTransformId,&lt;br/&gt;
+        RunnerApi.PTransform pTransform,&lt;br/&gt;
+        Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
+        Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
+        Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
+        Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+        Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+        Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
+        Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) {&lt;br/&gt;
+&lt;br/&gt;
+      DoFn&amp;lt;InputT, OutputT&amp;gt; doFn;&lt;br/&gt;
+      TupleTag&amp;lt;OutputT&amp;gt; mainOutputTag;&lt;br/&gt;
+      WindowedValueCoder&amp;lt;InputT&amp;gt; inputCoder;&lt;br/&gt;
+      WindowingStrategy&amp;lt;InputT, ?&amp;gt; windowingStrategy;&lt;br/&gt;
+&lt;br/&gt;
+      try {&lt;br/&gt;
+        RehydratedComponents rehydratedComponents = RehydratedComponents.forComponents(&lt;br/&gt;
+            RunnerApi.Components.newBuilder()&lt;br/&gt;
+                .putAllCoders(coders).putAllWindowingStrategies(windowingStrategies).build());&lt;br/&gt;
+        ParDoPayload parDoPayload = ParDoPayload.parseFrom(pTransform.getSpec().getPayload());&lt;br/&gt;
+        if (parDoPayload.getSideInputsCount() != 0) {
+          throw new UnsupportedOperationException(&quot;Side inputs not yet supported.&quot;);
+        }&lt;br/&gt;
+        doFn = (DoFn) ParDoTranslation.getDoFn(parDoPayload);&lt;br/&gt;
+        mainOutputTag = (TupleTag) ParDoTranslation.getMainOutputTag(parDoPayload);&lt;br/&gt;
+        // There will only be one due to the check above.&lt;br/&gt;
+        RunnerApi.PCollection mainInput = pCollections.get(&lt;br/&gt;
+            Iterables.getOnlyElement(pTransform.getInputsMap().values()));&lt;br/&gt;
+        inputCoder = (WindowedValueCoder&amp;lt;InputT&amp;gt;) rehydratedComponents.getCoder(&lt;br/&gt;
+            mainInput.getCoderId());&lt;br/&gt;
+        windowingStrategy = (WindowingStrategy) rehydratedComponents.getWindowingStrategy(&lt;br/&gt;
+            mainInput.getWindowingStrategyId());&lt;br/&gt;
+      } catch (InvalidProtocolBufferException exn) {
+        throw new IllegalArgumentException(&quot;Malformed ParDoPayload&quot;, exn);
+      } catch (IOException exn) {+        throw new IllegalArgumentException(&quot;Malformed ParDoPayload&quot;, exn);+      }&lt;br/&gt;
+&lt;br/&gt;
+      ImmutableMultimap.Builder&amp;lt;TupleTag&amp;lt;?&amp;gt;, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
+          tagToConsumerBuilder = ImmutableMultimap.builder();&lt;br/&gt;
+      for (Map.Entry&amp;lt;String, String&amp;gt; entry : pTransform.getOutputsMap().entrySet()) {
+        tagToConsumerBuilder.putAll(
+            new TupleTag&amp;lt;&amp;gt;(entry.getKey()), pCollectionIdsToConsumers.get(entry.getValue()));
       }&lt;br/&gt;
-      addFinishFunction.accept(runner::finishBundle);&lt;br/&gt;
+      Multimap&amp;lt;TupleTag&amp;lt;?&amp;gt;, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; tagToConsumer =&lt;br/&gt;
+          tagToConsumerBuilder.build();&lt;br/&gt;
+&lt;br/&gt;
+      @SuppressWarnings({&quot;unchecked&quot;, &quot;rawtypes&quot;}
&lt;p&gt;)&lt;br/&gt;
+      DoFnRunner&amp;lt;InputT, OutputT&amp;gt; runner = new FnApiDoFnRunner&amp;lt;&amp;gt;(&lt;br/&gt;
+          pipelineOptions,&lt;br/&gt;
+          beamFnStateClient,&lt;br/&gt;
+          pTransformId,&lt;br/&gt;
+          processBundleInstructionId,&lt;br/&gt;
+          doFn,&lt;br/&gt;
+          inputCoder,&lt;br/&gt;
+          (Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt;) (Collection)&lt;br/&gt;
+              tagToConsumer.get(mainOutputTag),&lt;br/&gt;
+          tagToConsumer,&lt;br/&gt;
+          windowingStrategy);&lt;br/&gt;
+      registerHandlers(&lt;br/&gt;
+          runner, pTransform, addStartFunction, addFinishFunction, pCollectionIdsToConsumers);&lt;br/&gt;
       return runner;&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;/p&gt;

&lt;p&gt;+  private static &amp;lt;InputT, OutputT&amp;gt; void registerHandlers(&lt;br/&gt;
+      DoFnRunner&amp;lt;InputT, OutputT&amp;gt; runner,&lt;br/&gt;
+      RunnerApi.PTransform pTransform,&lt;br/&gt;
+      Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
+      Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction,&lt;br/&gt;
+      Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers) {&lt;br/&gt;
+    // Register the appropriate handlers.&lt;br/&gt;
+    addStartFunction.accept(runner::startBundle);&lt;br/&gt;
+    for (String pcollectionId : pTransform.getInputsMap().values()) &lt;/p&gt;
{
+      pCollectionIdsToConsumers.put(
+          pcollectionId,
+          (FnDataReceiver) (FnDataReceiver&amp;lt;WindowedValue&amp;lt;InputT&amp;gt;&amp;gt;) runner::processElement);
+    }
&lt;p&gt;+    addFinishFunction.accept(runner::finishBundle);&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
   //////////////////////////////////////////////////////////////////////////////////////////////////&lt;/p&gt;

&lt;p&gt;   private final PipelineOptions pipelineOptions;&lt;br/&gt;
@@ -205,8 +298,8 @@&lt;br/&gt;
   private final Supplier&amp;lt;String&amp;gt; processBundleInstructionId;&lt;br/&gt;
   private final DoFn&amp;lt;InputT, OutputT&amp;gt; doFn;&lt;br/&gt;
   private final WindowedValueCoder&amp;lt;InputT&amp;gt; inputCoder;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; mainOutputConsumers;&lt;/li&gt;
	&lt;li&gt;private final Multimap&amp;lt;TupleTag&amp;lt;?&amp;gt;, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; outputMap;&lt;br/&gt;
+  private final Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; mainOutputConsumers;&lt;br/&gt;
+  private final Multimap&amp;lt;TupleTag&amp;lt;?&amp;gt;, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; outputMap;&lt;br/&gt;
   private final WindowingStrategy windowingStrategy;&lt;br/&gt;
   private final DoFnSignature doFnSignature;&lt;br/&gt;
   private final DoFnInvoker&amp;lt;InputT, OutputT&amp;gt; doFnInvoker;&lt;br/&gt;
@@ -243,8 +336,8 @@&lt;br/&gt;
       Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
       DoFn&amp;lt;InputT, OutputT&amp;gt; doFn,&lt;br/&gt;
       WindowedValueCoder&amp;lt;InputT&amp;gt; inputCoder,&lt;/li&gt;
	&lt;li&gt;Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; mainOutputConsumers,&lt;/li&gt;
	&lt;li&gt;Multimap&amp;lt;TupleTag&amp;lt;?&amp;gt;, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; outputMap,&lt;br/&gt;
+      Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;OutputT&amp;gt;&amp;gt;&amp;gt; mainOutputConsumers,&lt;br/&gt;
+      Multimap&amp;lt;TupleTag&amp;lt;?&amp;gt;, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; outputMap,&lt;br/&gt;
       WindowingStrategy windowingStrategy) {&lt;br/&gt;
     this.pipelineOptions = pipelineOptions;&lt;br/&gt;
     this.beamFnStateClient = beamFnStateClient;&lt;br/&gt;
@@ -316,11 +409,11 @@ public void finishBundle() {&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;Outputs the given element to the specified set of consumers wrapping any exceptions.&lt;br/&gt;
    */&lt;br/&gt;
   private &amp;lt;T&amp;gt; void outputTo(&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumers,&lt;br/&gt;
+      Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumers,&lt;br/&gt;
       WindowedValue&amp;lt;T&amp;gt; output) {&lt;/li&gt;
	&lt;li&gt;Iterator&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumerIterator;&lt;br/&gt;
+    Iterator&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumerIterator;&lt;br/&gt;
     try {&lt;/li&gt;
	&lt;li&gt;for (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer : consumers) 
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      for (FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt; catch (Throwable t) {&lt;br/&gt;
@@ -492,7 +585,7 @@ public void outputWithTimestamp(OutputT output, Instant timestamp) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
     public &amp;lt;T&amp;gt; void output(TupleTag&amp;lt;T&amp;gt; tag, T output) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumers = (Collection) outputMap.get(tag);&lt;br/&gt;
+      Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumers = (Collection) outputMap.get(tag);&lt;br/&gt;
       if (consumers == null) 
{
         throw new IllegalArgumentException(String.format(&quot;Unknown output tag %s&quot;, tag));
       }&lt;br/&gt;
@@ -506,7 +599,7 @@ public void outputWithTimestamp(OutputT output, Instant timestamp) {&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
     public &amp;lt;T&amp;gt; void outputWithTimestamp(TupleTag&amp;lt;T&amp;gt; tag, T output, Instant timestamp) {&lt;br/&gt;
-      Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumers = (Collection) outputMap.get(tag);&lt;br/&gt;
+      Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumers = (Collection) outputMap.get(tag);&lt;br/&gt;
       if (consumers == null) {         throw new IllegalArgumentException(String.format(&quot;Unknown output tag %s&quot;, tag));       }
&lt;p&gt;@@ -622,7 +715,7 @@ public void output(OutputT output, Instant timestamp, BoundedWindow window) {&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     @Override&lt;br/&gt;
     public &amp;lt;T&amp;gt; void output(TupleTag&amp;lt;T&amp;gt; tag, T output, Instant timestamp, BoundedWindow window) {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumers = (Collection) outputMap.get(tag);&lt;br/&gt;
+      Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt;&amp;gt; consumers = (Collection) outputMap.get(tag);&lt;br/&gt;
       if (consumers == null) 
{
         throw new IllegalArgumentException(String.format(&quot;Unknown output tag %s&quot;, tag));
       }
&lt;p&gt;diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/FnHarness.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/FnHarness.java&lt;br/&gt;
index 1df26238480..7c0590dfd69 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/FnHarness.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/FnHarness.java&lt;br/&gt;
@@ -29,13 +29,14 @@&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingFunction;&lt;br/&gt;
 import org.apache.beam.fn.harness.logging.BeamFnLoggingClient;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BeamFnStateGrpcClientCache;&lt;br/&gt;
-import org.apache.beam.fn.harness.stream.StreamObserverFactory;&lt;br/&gt;
+import org.apache.beam.fn.harness.stream.HarnessStreamObserverFactories;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.InstructionRequest;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.InstructionResponse.Builder;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
 import org.apache.beam.sdk.extensions.gcp.options.GcsOptions;&lt;br/&gt;
 import org.apache.beam.sdk.fn.channel.ManagedChannelFactory;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory;&lt;br/&gt;
 import org.apache.beam.sdk.options.ExperimentalOptions;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.util.common.ReflectHelpers;&lt;br/&gt;
@@ -101,7 +102,8 @@ public static void main(PipelineOptions options,&lt;br/&gt;
     } else 
{
       channelFactory = ManagedChannelFactory.createDefault();
     }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;StreamObserverFactory streamObserverFactory = StreamObserverFactory.fromOptions(options);&lt;br/&gt;
+    StreamObserverFactory streamObserverFactory =&lt;br/&gt;
+        HarnessStreamObserverFactories.fromOptions(options);&lt;br/&gt;
     try (BeamFnLoggingClient logging = new BeamFnLoggingClient(&lt;br/&gt;
         options,&lt;br/&gt;
         loggingApiServiceDescriptor,&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/PTransformRunnerFactory.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/PTransformRunnerFactory.java&lt;br/&gt;
index 126055a659c..a432332d84d 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/PTransformRunnerFactory.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/PTransformRunnerFactory.java&lt;br/&gt;
@@ -23,10 +23,13 @@&lt;br/&gt;
 import java.util.function.Consumer;&lt;br/&gt;
 import java.util.function.Supplier;&lt;br/&gt;
 import org.apache.beam.fn.harness.data.BeamFnDataClient;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BeamFnStateClient;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.Coder;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PCollection;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PTransform;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -37,8 +40,8 @@&lt;/p&gt;

&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Creates and returns a handler for a given PTransform. Note that the handler must support&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* processing multiple bundles. The handler will be discarded if an error is thrown during&lt;/li&gt;
	&lt;li&gt;* element processing, or during execution of start/finish.&lt;br/&gt;
+   * processing multiple bundles. The handler will be discarded if an error is thrown during element&lt;br/&gt;
+   * processing, or during execution of start/finish.&lt;br/&gt;
    *&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param pipelineOptions Pipeline options&lt;/li&gt;
	&lt;li&gt;@param beamFnDataClient A client for handling inbound and outbound data streams.&lt;br/&gt;
@@ -46,14 +49,15 @@&lt;/li&gt;
	&lt;li&gt;@param pTransformId The id of the PTransform.&lt;/li&gt;
	&lt;li&gt;@param pTransform The PTransform definition.&lt;/li&gt;
	&lt;li&gt;@param processBundleInstructionId A supplier containing the active process bundle instruction&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* id.&lt;br/&gt;
+   *     id.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param pCollections A mapping from PCollection id to PCollection definition.&lt;/li&gt;
	&lt;li&gt;@param coders A mapping from coder id to coder definition.&lt;br/&gt;
+   * @param windowingStrategies&lt;/li&gt;
	&lt;li&gt;@param pCollectionIdsToConsumers A mapping from PCollection id to a collection of consumers.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* Note that if this handler is a consumer, it should register itself within this multimap under&lt;/li&gt;
	&lt;li&gt;* the appropriate PCollection ids. Also note that all output consumers needed by this PTransform&lt;/li&gt;
	&lt;li&gt;* (based on the values of the 
{@link RunnerApi.PTransform#getOutputsMap()}
&lt;p&gt; will have already&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;* registered within this multimap.&lt;br/&gt;
+   *     Note that if this handler is a consumer, it should register itself within this multimap&lt;br/&gt;
+   *     under the appropriate PCollection ids. Also note that all output consumers needed by this&lt;br/&gt;
+   *     PTransform (based on the values of the 
{@link PTransform#getOutputsMap()}
&lt;p&gt; will have already&lt;br/&gt;
+   *     registered within this multimap.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;@param addStartFunction A consumer to register a start bundle handler with.&lt;/li&gt;
	&lt;li&gt;@param addFinishFunction A consumer to register a finish bundle handler with.&lt;br/&gt;
    */&lt;br/&gt;
@@ -64,11 +68,13 @@ T createRunnerForPTransform(&lt;br/&gt;
       String pTransformId,&lt;br/&gt;
       RunnerApi.PTransform pTransform,&lt;br/&gt;
       Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;/li&gt;
	&lt;li&gt;Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+      Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+      Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+      Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+      Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
       Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;/li&gt;
	&lt;li&gt;Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException;&lt;br/&gt;
+      Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction)&lt;br/&gt;
+      throws IOException;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   /**&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;A registrar which can return a mapping from 
{@link RunnerApi.FunctionSpec#getUrn()}
&lt;p&gt; to&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/control/BeamFnControlClient.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/control/BeamFnControlClient.java&lt;br/&gt;
index 3c98e7777c6..64ab03de039 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/control/BeamFnControlClient.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/control/BeamFnControlClient.java&lt;br/&gt;
@@ -33,8 +33,10 @@&lt;br/&gt;
 import java.util.function.Function;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingFunction;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
+import org.apache.beam.model.fnexecution.v1.BeamFnApi.InstructionRequest;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnControlGrpc;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory.StreamObserverClientFactory;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -68,13 +70,15 @@&lt;br/&gt;
   public BeamFnControlClient(&lt;br/&gt;
       Endpoints.ApiServiceDescriptor apiServiceDescriptor,&lt;br/&gt;
       Function&amp;lt;Endpoints.ApiServiceDescriptor, ManagedChannel&amp;gt; channelFactory,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BiFunction&amp;lt;Function&amp;lt;StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt;,&lt;/li&gt;
	&lt;li&gt;StreamObserver&amp;lt;BeamFnApi.InstructionResponse&amp;gt;&amp;gt;,&lt;/li&gt;
	&lt;li&gt;StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt;,&lt;/li&gt;
	&lt;li&gt;StreamObserver&amp;lt;BeamFnApi.InstructionResponse&amp;gt;&amp;gt; streamObserverFactory,&lt;/li&gt;
	&lt;li&gt;EnumMap&amp;lt;BeamFnApi.InstructionRequest.RequestCase,&lt;/li&gt;
	&lt;li&gt;ThrowingFunction&amp;lt;BeamFnApi.InstructionRequest,&lt;/li&gt;
	&lt;li&gt;BeamFnApi.InstructionResponse.Builder&amp;gt;&amp;gt; handlers) {&lt;br/&gt;
+      BiFunction&amp;lt;&lt;br/&gt;
+              StreamObserverClientFactory&amp;lt;InstructionRequest, BeamFnApi.InstructionResponse&amp;gt;,&lt;br/&gt;
+              StreamObserver&amp;lt;BeamFnApi.InstructionRequest&amp;gt;,&lt;br/&gt;
+              StreamObserver&amp;lt;BeamFnApi.InstructionResponse&amp;gt;&amp;gt;&lt;br/&gt;
+          streamObserverFactory,&lt;br/&gt;
+      EnumMap&amp;lt;&lt;br/&gt;
+              BeamFnApi.InstructionRequest.RequestCase,&lt;br/&gt;
+              ThrowingFunction&amp;lt;BeamFnApi.InstructionRequest, BeamFnApi.InstructionResponse.Builder&amp;gt;&amp;gt;&lt;br/&gt;
+          handlers) {&lt;br/&gt;
     this.bufferedInstructions = new LinkedBlockingDeque&amp;lt;&amp;gt;();&lt;br/&gt;
     this.outboundObserver = streamObserverFactory.apply(&lt;br/&gt;
         BeamFnControlGrpc.newStub(channelFactory.apply(apiServiceDescriptor))::control,&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/control/ProcessBundleHandler.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/control/ProcessBundleHandler.java&lt;br/&gt;
index 598583c9e51..b71f3816902 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/control/ProcessBundleHandler.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/control/ProcessBundleHandler.java&lt;br/&gt;
@@ -39,7 +39,6 @@&lt;br/&gt;
 import org.apache.beam.fn.harness.PTransformRunnerFactory;&lt;br/&gt;
 import org.apache.beam.fn.harness.PTransformRunnerFactory.Registrar;&lt;br/&gt;
 import org.apache.beam.fn.harness.data.BeamFnDataClient;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BeamFnStateClient;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.BeamFnStateGrpcClientCache;&lt;br/&gt;
@@ -50,6 +49,11 @@&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateResponse;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints.ApiServiceDescriptor;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.Coder;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PCollection;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PTransform;&lt;br/&gt;
+import org.apache.beam.runners.core.construction.PTransformTranslation;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
 import org.apache.beam.sdk.util.common.ReflectHelpers;&lt;br/&gt;
@@ -128,11 +132,12 @@ public Object createRunnerForPTransform(&lt;br/&gt;
           BeamFnDataClient beamFnDataClient,&lt;br/&gt;
           BeamFnStateClient beanFnStateClient,&lt;br/&gt;
           String pTransformId,&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;RunnerApi.PTransform pTransform,&lt;br/&gt;
+          PTransform pTransform,&lt;br/&gt;
           Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;/li&gt;
	&lt;li&gt;Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+          Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+          Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+          Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+          Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
           Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
           Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) {&lt;br/&gt;
         throw new IllegalStateException(String.format(&lt;br/&gt;
@@ -150,13 +155,14 @@ private void createRunnerAndConsumersForPTransformRecursively(&lt;br/&gt;
       Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
       BeamFnApi.ProcessBundleDescriptor processBundleDescriptor,&lt;br/&gt;
       Multimap&amp;lt;String, String&amp;gt; pCollectionIdsToConsumingPTransforms,&lt;/li&gt;
	&lt;li&gt;Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+      Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
       Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
       Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Recursively ensure that all consumers of the output PCollection have been created.&lt;br/&gt;
     // Since we are creating the consumers first, we know that the we are building the DAG&lt;br/&gt;
     // in reverse topological order.&lt;br/&gt;
+    System.out.println(&quot;* Create &quot; + pTransform.toString().replace(&quot;\n&quot;, &quot; &quot;));&lt;br/&gt;
     for (String pCollectionId : pTransform.getOutputsMap().values()) {&lt;br/&gt;
       // If we have created the consumers for this PCollection we can skip it.&lt;br/&gt;
       if (pCollectionIdsToConsumers.containsKey(pCollectionId)) {&lt;br/&gt;
@@ -188,6 +194,7 @@ private void createRunnerAndConsumersForPTransformRecursively(&lt;br/&gt;
             processBundleInstructionId,&lt;br/&gt;
             processBundleDescriptor.getPcollectionsMap(),&lt;br/&gt;
             processBundleDescriptor.getCodersMap(),&lt;br/&gt;
+            processBundleDescriptor.getWindowingStrategiesMap(),&lt;br/&gt;
             pCollectionIdsToConsumers,&lt;br/&gt;
             addStartFunction,&lt;br/&gt;
             addFinishFunction);&lt;br/&gt;
@@ -205,7 +212,7 @@ private void createRunnerAndConsumersForPTransformRecursively(&lt;/p&gt;

&lt;p&gt;     Multimap&amp;lt;String, String&amp;gt; pCollectionIdsToConsumingPTransforms = HashMultimap.create();&lt;br/&gt;
     Multimap&amp;lt;String,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers =&lt;br/&gt;
+        FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers =&lt;br/&gt;
         HashMultimap.create();&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; startFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; finishFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
@@ -231,7 +238,9 @@ private void createRunnerAndConsumersForPTransformRecursively(&lt;br/&gt;
         // Skip anything which isn&apos;t a root&lt;br/&gt;
         // TODO: Remove source as a root and have it be triggered by the Runner.&lt;br/&gt;
         if (!DATA_INPUT_URN.equals(entry.getValue().getSpec().getUrn())&lt;/li&gt;
	&lt;li&gt;&amp;amp;&amp;amp; !JAVA_SOURCE_URN.equals(entry.getValue().getSpec().getUrn())) {&lt;br/&gt;
+            &amp;amp;&amp;amp; !JAVA_SOURCE_URN.equals(entry.getValue().getSpec().getUrn())&lt;br/&gt;
+            &amp;amp;&amp;amp; !PTransformTranslation.READ_TRANSFORM_URN.equals(&lt;br/&gt;
+                entry.getValue().getSpec().getUrn())) 
{
           continue;
         }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataBufferingOutboundObserver.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataBufferingOutboundObserver.java&lt;br/&gt;
index 97396e7d2ea..2b67bee11fc 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataBufferingOutboundObserver.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataBufferingOutboundObserver.java&lt;br/&gt;
@@ -23,13 +23,13 @@&lt;br/&gt;
 import java.util.Collections;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.function.Consumer;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.CloseableThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.options.ExperimentalOptions;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;/p&gt;

&lt;p&gt;@@ -50,7 +50,7 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;a marker, detect on the input side that no bytes were read and force reading a single byte.&lt;br/&gt;
  */&lt;br/&gt;
 public class BeamFnDataBufferingOutboundObserver&amp;lt;T&amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;implements CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; {&lt;br/&gt;
+    implements CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; {&lt;br/&gt;
   private static final String BEAM_FN_API_DATA_BUFFER_LIMIT = &quot;beam_fn_api_data_buffer_limit=&quot;;&lt;br/&gt;
   private static final int DEFAULT_BUFFER_LIMIT_BYTES = 1_000_000;&lt;br/&gt;
   private static final Logger LOG =&lt;br/&gt;
@@ -60,13 +60,13 @@&lt;br/&gt;
   private long counter;&lt;br/&gt;
   private final int bufferLimit;&lt;br/&gt;
   private final Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder;&lt;/li&gt;
	&lt;li&gt;private final KV&amp;lt;String, BeamFnApi.Target&amp;gt; outputLocation;&lt;br/&gt;
+  private final LogicalEndpoint outputLocation;&lt;br/&gt;
   private final StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt; outboundObserver;&lt;br/&gt;
   private final ByteString.Output bufferedElements;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   public BeamFnDataBufferingOutboundObserver(&lt;br/&gt;
       PipelineOptions options,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;KV&amp;lt;String, BeamFnApi.Target&amp;gt; outputLocation,&lt;br/&gt;
+      LogicalEndpoint outputLocation,&lt;br/&gt;
       Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder,&lt;br/&gt;
       StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt; outboundObserver) {&lt;br/&gt;
     this.bufferLimit = getBufferLimit(options);&lt;br/&gt;
@@ -95,13 +95,13 @@ public void close() throws Exception {&lt;br/&gt;
     BeamFnApi.Elements.Builder elements = convertBufferForTransmission();&lt;br/&gt;
     // This will add an empty data block representing the end of stream.&lt;br/&gt;
     elements.addDataBuilder()&lt;/li&gt;
	&lt;li&gt;.setInstructionReference(outputLocation.getKey())&lt;/li&gt;
	&lt;li&gt;.setTarget(outputLocation.getValue());&lt;br/&gt;
+        .setInstructionReference(outputLocation.getInstructionId())&lt;br/&gt;
+        .setTarget(outputLocation.getTarget());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     LOG.debug(&quot;Closing stream for instruction {} and &quot;&lt;br/&gt;
         + &quot;target {} having transmitted {} values {} bytes&quot;,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;outputLocation.getKey(),&lt;/li&gt;
	&lt;li&gt;outputLocation.getValue(),&lt;br/&gt;
+        outputLocation.getInstructionId(),&lt;br/&gt;
+        outputLocation.getTarget(),&lt;br/&gt;
         counter,&lt;br/&gt;
         byteCounter);&lt;br/&gt;
     outboundObserver.onNext(elements.build());&lt;br/&gt;
@@ -123,8 +123,8 @@ public void accept(WindowedValue&amp;lt;T&amp;gt; t) throws IOException {&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     elements.addDataBuilder()&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.setInstructionReference(outputLocation.getKey())&lt;/li&gt;
	&lt;li&gt;.setTarget(outputLocation.getValue())&lt;br/&gt;
+        .setInstructionReference(outputLocation.getInstructionId())&lt;br/&gt;
+        .setTarget(outputLocation.getTarget())&lt;br/&gt;
         .setData(bufferedElements.toByteString());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     byteCounter += bufferedElements.size();&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataClient.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataClient.java&lt;br/&gt;
index c3b7fd25065..baf67db35d5 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataClient.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataClient.java&lt;br/&gt;
@@ -19,47 +19,46 @@&lt;br/&gt;
 package org.apache.beam.fn.harness.data;&lt;/p&gt;

&lt;p&gt; import java.util.concurrent.CompletableFuture;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.CloseableThrowingConsumer;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
-import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;/p&gt;

&lt;p&gt; /**&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* The 
{@link BeamFnDataClient} is able to forward inbound elements to a consumer and is also a&lt;br/&gt;
- * consumer of outbound elements. Callers can register themselves as consumers for inbound elements&lt;br/&gt;
- * or can get a handle for a consumer for outbound elements.&lt;br/&gt;
+ * The {@link BeamFnDataClient}
&lt;p&gt; is able to forward inbound elements to a &lt;/p&gt;
{@link FnDataReceiver} and&lt;br/&gt;
+ * provide a receiver of outbound elements. Callers can register themselves as receivers for inbound&lt;br/&gt;
+ * elements or can get a handle for a receiver of outbound elements.&lt;br/&gt;
  */&lt;br/&gt;
 public interface BeamFnDataClient {&lt;br/&gt;
   /**&lt;br/&gt;
-   * Registers the following inbound consumer for the provided instruction id and target.&lt;br/&gt;
+   * Registers the following inbound receiver for the provided instruction id and target.&lt;br/&gt;
    *&lt;br/&gt;
    * &amp;lt;p&amp;gt;The provided coder is used to decode inbound elements. The decoded elements&lt;br/&gt;
-   * are passed to the provided consumer. Any failure during decoding or processing of the element&lt;br/&gt;
+   * are passed to the provided receiver. Any failure during decoding or processing of the element&lt;br/&gt;
    * will complete the returned future exceptionally. On successful termination of the stream,&lt;br/&gt;
    * the returned future is completed successfully.&lt;br/&gt;
    *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;The consumer is not required to be thread safe.&lt;br/&gt;
+   * &amp;lt;p&amp;gt;The receiver is not required to be thread safe.&lt;br/&gt;
    */&lt;br/&gt;
-  &amp;lt;T&amp;gt; CompletableFuture&amp;lt;Void&amp;gt; forInboundConsumer(&lt;br/&gt;
+  &amp;lt;T&amp;gt; CompletableFuture&amp;lt;Void&amp;gt; receive(&lt;br/&gt;
       Endpoints.ApiServiceDescriptor apiServiceDescriptor,&lt;br/&gt;
-      KV&amp;lt;String, BeamFnApi.Target&amp;gt; inputLocation,&lt;br/&gt;
+      LogicalEndpoint inputLocation,&lt;br/&gt;
       Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder,&lt;br/&gt;
-      ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer);&lt;br/&gt;
+      FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; receiver);&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
-   * Creates a closeable consumer using the provided instruction id and target.&lt;br/&gt;
+   * Creates a {@link CloseableFnDataReceiver} using the provided instruction id and target.&lt;br/&gt;
    *&lt;br/&gt;
    * &amp;lt;p&amp;gt;The provided coder is used to encode elements on the outbound stream.&lt;br/&gt;
    *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;Closing the returned consumer signals the end of the stream.&lt;br/&gt;
+   * &amp;lt;p&amp;gt;Closing the returned receiver signals the end of the stream.&lt;br/&gt;
    *&lt;br/&gt;
-   * &amp;lt;p&amp;gt;The returned closeable consumer is not thread safe.&lt;br/&gt;
+   * &amp;lt;p&amp;gt;The returned closeable receiver is not thread safe.&lt;br/&gt;
    */&lt;br/&gt;
-  &amp;lt;T&amp;gt; CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; forOutboundConsumer(&lt;br/&gt;
+  &amp;lt;T&amp;gt; CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; send(&lt;br/&gt;
       Endpoints.ApiServiceDescriptor apiServiceDescriptor,&lt;br/&gt;
-      KV&amp;lt;String, BeamFnApi.Target&amp;gt; outputLocation,&lt;br/&gt;
+      LogicalEndpoint outputLocation,&lt;br/&gt;
       Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder);&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcClient.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcClient.java&lt;br/&gt;
index 9333410b1e7..26083da55b5 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcClient.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcClient.java&lt;br/&gt;
@@ -25,15 +25,16 @@&lt;br/&gt;
 import java.util.concurrent.ConcurrentMap;&lt;br/&gt;
 import java.util.function.BiFunction;&lt;br/&gt;
 import java.util.function.Function;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.CloseableThrowingConsumer;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnDataGrpc;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory.StreamObserverClientFactory;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;br/&gt;
 &lt;br/&gt;
@@ -47,18 +48,19 @@&lt;br/&gt;
 &lt;br/&gt;
   private final ConcurrentMap&amp;lt;Endpoints.ApiServiceDescriptor, BeamFnDataGrpcMultiplexer&amp;gt; cache;&lt;br/&gt;
   private final Function&amp;lt;Endpoints.ApiServiceDescriptor, ManagedChannel&amp;gt; channelFactory;&lt;br/&gt;
-  private final BiFunction&amp;lt;Function&amp;lt;StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;,&lt;br/&gt;
-                                    StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;&amp;gt;,&lt;br/&gt;
-                           StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;,&lt;br/&gt;
-                           StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;&amp;gt; streamObserverFactory;&lt;br/&gt;
+  private final BiFunction&amp;lt;&lt;br/&gt;
+          StreamObserverClientFactory&amp;lt;BeamFnApi.Elements, BeamFnApi.Elements&amp;gt;,&lt;br/&gt;
+          StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;, StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;&amp;gt;&lt;br/&gt;
+      streamObserverFactory;&lt;br/&gt;
   private final PipelineOptions options;&lt;br/&gt;
 &lt;br/&gt;
   public BeamFnDataGrpcClient(&lt;br/&gt;
       PipelineOptions options,&lt;br/&gt;
       Function&amp;lt;Endpoints.ApiServiceDescriptor, ManagedChannel&amp;gt; channelFactory,&lt;br/&gt;
-      BiFunction&amp;lt;Function&amp;lt;StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;, StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;&amp;gt;,&lt;br/&gt;
-                 StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;,&lt;br/&gt;
-                 StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;&amp;gt; streamObserverFactory) {&lt;br/&gt;
+      BiFunction&amp;lt;&lt;br/&gt;
+              StreamObserverClientFactory&amp;lt;BeamFnApi.Elements, BeamFnApi.Elements&amp;gt;,&lt;br/&gt;
+              StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;, StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt;&amp;gt;&lt;br/&gt;
+          streamObserverFactory) {&lt;br/&gt;
     this.options = options;&lt;br/&gt;
     this.channelFactory = channelFactory;&lt;br/&gt;
     this.streamObserverFactory = streamObserverFactory;&lt;br/&gt;
@@ -74,14 +76,14 @@ public BeamFnDataGrpcClient(&lt;br/&gt;
    * (signaled by an empty data block), the returned future is completed successfully.&lt;br/&gt;
    */&lt;br/&gt;
   @Override&lt;br/&gt;
-  public &amp;lt;T&amp;gt; CompletableFuture&amp;lt;Void&amp;gt; forInboundConsumer(&lt;br/&gt;
+  public &amp;lt;T&amp;gt; CompletableFuture&amp;lt;Void&amp;gt; receive(&lt;br/&gt;
       Endpoints.ApiServiceDescriptor apiServiceDescriptor,&lt;br/&gt;
-      KV&amp;lt;String, BeamFnApi.Target&amp;gt; inputLocation,&lt;br/&gt;
+      LogicalEndpoint inputLocation,&lt;br/&gt;
       Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder,&lt;br/&gt;
-      ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer) {&lt;br/&gt;
+      FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer) {&lt;br/&gt;
     LOG.debug(&quot;Registering consumer for instruction {} and target {}&quot;,&lt;br/&gt;
-        inputLocation.getKey(),&lt;br/&gt;
-        inputLocation.getValue());&lt;br/&gt;
+        inputLocation.getInstructionId(),&lt;br/&gt;
+        inputLocation.getTarget());&lt;br/&gt;
 &lt;br/&gt;
     CompletableFuture&amp;lt;Void&amp;gt; readFuture = new CompletableFuture&amp;lt;&amp;gt;();&lt;br/&gt;
     BeamFnDataGrpcMultiplexer client = getClientFor(apiServiceDescriptor);&lt;br/&gt;
@@ -101,15 +103,15 @@ public BeamFnDataGrpcClient(&lt;br/&gt;
    * &amp;lt;p&amp;gt;The returned closeable consumer is not thread safe.&lt;br/&gt;
    */&lt;br/&gt;
   @Override&lt;br/&gt;
-  public &amp;lt;T&amp;gt; CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; forOutboundConsumer(&lt;br/&gt;
+  public &amp;lt;T&amp;gt; CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; send(&lt;br/&gt;
       Endpoints.ApiServiceDescriptor apiServiceDescriptor,&lt;br/&gt;
-      KV&amp;lt;String, BeamFnApi.Target&amp;gt; outputLocation,&lt;br/&gt;
+      LogicalEndpoint outputLocation,&lt;br/&gt;
       Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder) {&lt;br/&gt;
     BeamFnDataGrpcMultiplexer client = getClientFor(apiServiceDescriptor);&lt;br/&gt;
 &lt;br/&gt;
     LOG.debug(&quot;Creating output consumer for instruction {} and target {}&quot;,&lt;br/&gt;
-        outputLocation.getKey(),&lt;br/&gt;
-        outputLocation.getValue());&lt;br/&gt;
+        outputLocation.getInstructionId(),&lt;br/&gt;
+        outputLocation.getTarget());&lt;br/&gt;
     return new BeamFnDataBufferingOutboundObserver&amp;lt;&amp;gt;(&lt;br/&gt;
         options, outputLocation, coder, client.getOutboundObserver());&lt;br/&gt;
   }&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcMultiplexer.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcMultiplexer.java&lt;br/&gt;
index cfe726a390f..b18cc7c997c 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcMultiplexer.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcMultiplexer.java&lt;br/&gt;
@@ -28,7 +28,7 @@&lt;br/&gt;
 import java.util.function.Function;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;br/&gt;
 &lt;br/&gt;
@@ -53,7 +53,7 @@&lt;br/&gt;
   private final StreamObserver&amp;lt;BeamFnApi.Elements&amp;gt; outboundObserver;&lt;br/&gt;
   @VisibleForTesting&lt;br/&gt;
   final ConcurrentMap&amp;lt;&lt;br/&gt;
-          KV&amp;lt;String, BeamFnApi.Target&amp;gt;, CompletableFuture&amp;lt;Consumer&amp;lt;BeamFnApi.Elements.Data&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
+          LogicalEndpoint, CompletableFuture&amp;lt;Consumer&amp;lt;BeamFnApi.Elements.Data&amp;gt;&amp;gt;&amp;gt;&lt;br/&gt;
       consumers;&lt;br/&gt;
 &lt;br/&gt;
   public BeamFnDataGrpcMultiplexer(&lt;br/&gt;
@@ -83,10 +83,8 @@ public String toString() {&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   public CompletableFuture&amp;lt;Consumer&amp;lt;BeamFnApi.Elements.Data&amp;gt;&amp;gt; futureForKey(&lt;br/&gt;
-      KV&amp;lt;String, BeamFnApi.Target&amp;gt; key) {&lt;br/&gt;
-    return consumers.computeIfAbsent(&lt;br/&gt;
-        key,&lt;br/&gt;
-        (KV&amp;lt;String, BeamFnApi.Target&amp;gt; unused) -&amp;gt; new CompletableFuture&amp;lt;&amp;gt;());&lt;br/&gt;
+      LogicalEndpoint key) {
+    return consumers.computeIfAbsent(key, (LogicalEndpoint unused) -&amp;gt; new CompletableFuture&amp;lt;&amp;gt;());
   }&lt;br/&gt;
 &lt;br/&gt;
   /**&lt;br/&gt;
@@ -102,8 +100,8 @@ public String toString() {&lt;br/&gt;
     public void onNext(BeamFnApi.Elements value) {&lt;br/&gt;
       for (BeamFnApi.Elements.Data data : value.getDataList()) {&lt;br/&gt;
         try {&lt;br/&gt;
-          KV&amp;lt;String, BeamFnApi.Target&amp;gt; key =&lt;br/&gt;
-              KV.of(data.getInstructionReference(), data.getTarget());&lt;br/&gt;
+          LogicalEndpoint key =&lt;br/&gt;
+              LogicalEndpoint.of(data.getInstructionReference(), data.getTarget());&lt;br/&gt;
           CompletableFuture&amp;lt;Consumer&amp;lt;BeamFnApi.Elements.Data&amp;gt;&amp;gt; consumer = futureForKey(key);&lt;br/&gt;
           if (!consumer.isDone()) {&lt;br/&gt;
             LOG.debug(&quot;Received data for key {} without consumer ready. &quot;&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataInboundObserver.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataInboundObserver.java&lt;br/&gt;
index 64a12e07168..c8122bf0f72 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataInboundObserver.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/BeamFnDataInboundObserver.java&lt;br/&gt;
@@ -20,9 +20,9 @@&lt;br/&gt;
 import java.io.InputStream;&lt;br/&gt;
 import java.util.concurrent.CompletableFuture;&lt;br/&gt;
 import java.util.function.Consumer;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;br/&gt;
@@ -33,7 +33,7 @@&lt;br/&gt;
  */&lt;br/&gt;
 public class BeamFnDataInboundObserver&amp;lt;T&amp;gt; implements Consumer&amp;lt;BeamFnApi.Elements.Data&amp;gt; {&lt;br/&gt;
   private static final Logger LOG = LoggerFactory.getLogger(BeamFnDataInboundObserver.class);&lt;br/&gt;
-  private final ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer;&lt;br/&gt;
+  private final FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer;&lt;br/&gt;
   private final Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder;&lt;br/&gt;
   private final CompletableFuture&amp;lt;Void&amp;gt; readFuture;&lt;br/&gt;
   private long byteCounter;&lt;br/&gt;
@@ -41,7 +41,7 @@&lt;br/&gt;
 &lt;br/&gt;
   public BeamFnDataInboundObserver(&lt;br/&gt;
       Coder&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; coder,&lt;br/&gt;
-      ThrowingConsumer&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer,&lt;br/&gt;
+      FnDataReceiver&amp;lt;WindowedValue&amp;lt;T&amp;gt;&amp;gt; consumer,&lt;br/&gt;
       CompletableFuture&amp;lt;Void&amp;gt; readFuture) {&lt;br/&gt;
     this.coder = coder;&lt;br/&gt;
     this.consumer = consumer;&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/MultiplexingFnDataReceiver.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/MultiplexingFnDataReceiver.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..95a9cc920ad&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/data/MultiplexingFnDataReceiver.java&lt;br/&gt;
@@ -0,0 +1,50 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.beam.fn.harness.data;&lt;br/&gt;
+&lt;br/&gt;
+import com.google.common.collect.Iterables;&lt;br/&gt;
+import java.util.Collection;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * A {@link FnDataReceiver}
&lt;p&gt; which forwards all received inputs to a collection of &lt;/p&gt;
{@link
+ * FnDataReceiver receivers}
&lt;p&gt;.&lt;br/&gt;
+ */&lt;br/&gt;
+public class MultiplexingFnDataReceiver&amp;lt;T&amp;gt; implements FnDataReceiver&amp;lt;T&amp;gt; {&lt;br/&gt;
+  public static &amp;lt;T&amp;gt; FnDataReceiver&amp;lt;T&amp;gt; forConsumers(&lt;br/&gt;
+      Collection&amp;lt;FnDataReceiver&amp;lt;T&amp;gt;&amp;gt; consumers) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    if (consumers.size() == 1) {
+      return Iterables.getOnlyElement(consumers);
+    }+    return new MultiplexingFnDataReceiver&amp;lt;&amp;gt;(consumers);+  }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+&lt;br/&gt;
+  private final Collection&amp;lt;FnDataReceiver&amp;lt;T&amp;gt;&amp;gt; consumers;&lt;br/&gt;
+&lt;br/&gt;
+  private MultiplexingFnDataReceiver(Collection&amp;lt;FnDataReceiver&amp;lt;T&amp;gt;&amp;gt; consumers) &lt;/p&gt;
{
+    this.consumers = consumers;
+  }
&lt;p&gt;+&lt;br/&gt;
+  @Override&lt;br/&gt;
+  public void accept(T input) throws Exception &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    for (FnDataReceiver&amp;lt;T&amp;gt; consumer }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+}&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/logging/BeamFnLoggingClient.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/logging/BeamFnLoggingClient.java&lt;br/&gt;
index e7e0c71e127..87c06360757 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/logging/BeamFnLoggingClient.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/logging/BeamFnLoggingClient.java&lt;br/&gt;
@@ -115,7 +115,7 @@ public BeamFnLoggingClient(&lt;br/&gt;
     logManager.reset();&lt;br/&gt;
     Logger rootLogger = logManager.getLogger(ROOT_LOGGER_NAME);&lt;br/&gt;
     for (Handler handler : rootLogger.getHandlers()) 
{
-      rootLogger.removeHandler(handler);
+      //rootLogger.removeHandler(handler);
     }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Use the passed in logging options to configure the various logger levels.&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/state/BeamFnStateGrpcClientCache.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/state/BeamFnStateGrpcClientCache.java&lt;br/&gt;
index 2ca07044b4f..457d5703d33 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/state/BeamFnStateGrpcClientCache.java&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/state/BeamFnStateGrpcClientCache.java&lt;br/&gt;
@@ -33,6 +33,7 @@&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnStateGrpc;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints.ApiServiceDescriptor;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory.StreamObserverClientFactory;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.slf4j.Logger;&lt;br/&gt;
 import org.slf4j.LoggerFactory;&lt;br/&gt;
@@ -47,10 +48,10 @@&lt;/p&gt;

&lt;p&gt;   private final ConcurrentMap&amp;lt;ApiServiceDescriptor, BeamFnStateClient&amp;gt; cache;&lt;br/&gt;
   private final Function&amp;lt;ApiServiceDescriptor, ManagedChannel&amp;gt; channelFactory;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private final BiFunction&amp;lt;Function&amp;lt;StreamObserver&amp;lt;StateResponse&amp;gt;,&lt;/li&gt;
	&lt;li&gt;StreamObserver&amp;lt;StateRequest&amp;gt;&amp;gt;,&lt;/li&gt;
	&lt;li&gt;StreamObserver&amp;lt;StateResponse&amp;gt;,&lt;/li&gt;
	&lt;li&gt;StreamObserver&amp;lt;StateRequest&amp;gt;&amp;gt; streamObserverFactory;&lt;br/&gt;
+  private final BiFunction&amp;lt;&lt;br/&gt;
+          StreamObserverClientFactory&amp;lt;StateResponse, StateRequest&amp;gt;, StreamObserver&amp;lt;StateResponse&amp;gt;,&lt;br/&gt;
+          StreamObserver&amp;lt;StateRequest&amp;gt;&amp;gt;&lt;br/&gt;
+      streamObserverFactory;&lt;br/&gt;
   private final PipelineOptions options;&lt;br/&gt;
   private final Supplier&amp;lt;String&amp;gt; idGenerator;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -58,7 +59,7 @@ public BeamFnStateGrpcClientCache(&lt;br/&gt;
       PipelineOptions options,&lt;br/&gt;
       Supplier&amp;lt;String&amp;gt; idGenerator,&lt;br/&gt;
       Function&amp;lt;Endpoints.ApiServiceDescriptor, ManagedChannel&amp;gt; channelFactory,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BiFunction&amp;lt;Function&amp;lt;StreamObserver&amp;lt;StateResponse&amp;gt;, StreamObserver&amp;lt;StateRequest&amp;gt;&amp;gt;,&lt;br/&gt;
+      BiFunction&amp;lt;StreamObserverClientFactory&amp;lt;StateResponse, StateRequest&amp;gt;,&lt;br/&gt;
           StreamObserver&amp;lt;StateResponse&amp;gt;,&lt;br/&gt;
           StreamObserver&amp;lt;StateRequest&amp;gt;&amp;gt; streamObserverFactory) {&lt;br/&gt;
     this.options = options;&lt;br/&gt;
diff --git a/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/stream/HarnessStreamObserverFactories.java b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/stream/HarnessStreamObserverFactories.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..0ef5f448d5a
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;/dev/null&lt;br/&gt;
+++ b/sdks/java/harness/src/main/java/org/apache/beam/fn/harness/stream/HarnessStreamObserverFactories.java&lt;br/&gt;
@@ -0,0 +1,57 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.beam.fn.harness.stream;&lt;br/&gt;
+&lt;br/&gt;
+import io.grpc.stub.StreamObserver;&lt;br/&gt;
+import java.util.List;&lt;br/&gt;
+import org.apache.beam.sdk.extensions.gcp.options.GcsOptions;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory;&lt;br/&gt;
+import org.apache.beam.sdk.options.ExperimentalOptions;&lt;br/&gt;
+import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Uses 
{@link PipelineOptions}
&lt;p&gt; to configure which underlying &lt;/p&gt;
{@link StreamObserver}
&lt;p&gt; implementation&lt;br/&gt;
+ * to use in the java SDK harness.&lt;br/&gt;
+ */&lt;br/&gt;
+public abstract class HarnessStreamObserverFactories {&lt;br/&gt;
+  public static org.apache.beam.sdk.fn.stream.StreamObserverFactory fromOptions(&lt;br/&gt;
+      PipelineOptions options) {&lt;br/&gt;
+    List&amp;lt;String&amp;gt; experiments = options.as(ExperimentalOptions.class).getExperiments();&lt;br/&gt;
+    if (experiments != null &amp;amp;&amp;amp; experiments.contains(&quot;beam_fn_api_buffered_stream&quot;)) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      int bufferSize = getBufferSize(experiments);+      if (bufferSize &amp;gt; 0) {
+        return StreamObserverFactory.buffered(
+            options.as(GcsOptions.class).getExecutorService(), bufferSize);
+      }+      return StreamObserverFactory.buffered(+          options.as(GcsOptions.class).getExecutorService());+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+    return StreamObserverFactory.direct();&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  private static int getBufferSize(List&amp;lt;String&amp;gt; experiments) {&lt;br/&gt;
+    for (String experiment : experiments) &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+      if (experiment.startsWith(&amp;quot;beam_fn_api_buffered_stream_buffer_size=&amp;quot;)) {
+        return Integer.parseInt(
+            experiment.substring(&quot;beam_fn_api_buffered_stream_buffer_size=&quot;.length()));
+      }+    }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+    return -1;&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BeamFnDataReadRunnerTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BeamFnDataReadRunnerTest.java&lt;br/&gt;
index b7d0bb0db59..d32b912bd75 100644&lt;/p&gt;&lt;/li&gt;
			&lt;li&gt;a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BeamFnDataReadRunnerTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BeamFnDataReadRunnerTest.java&lt;br/&gt;
@@ -47,7 +47,6 @@&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicReference;&lt;br/&gt;
 import org.apache.beam.fn.harness.PTransformRunnerFactory.Registrar;&lt;br/&gt;
 import org.apache.beam.fn.harness.data.BeamFnDataClient;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
@@ -56,12 +55,13 @@&lt;br/&gt;
 import org.apache.beam.runners.core.construction.CoderTranslation;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.StringUtf8Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.fn.test.TestExecutors;&lt;br/&gt;
 import org.apache.beam.sdk.fn.test.TestExecutors.TestExecutorService;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.GlobalWindow;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.hamcrest.collection.IsMapContaining;&lt;br/&gt;
 import org.junit.Before;&lt;br/&gt;
 import org.junit.Rule;&lt;br/&gt;
@@ -109,7 +109,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @Rule public TestExecutorService executor = TestExecutors.from(Executors::newCachedThreadPool);&lt;br/&gt;
   @Mock private BeamFnDataClient mockBeamFnDataClient;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Captor private ArgumentCaptor&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;&amp;gt; consumerCaptor;&lt;br/&gt;
+  @Captor private ArgumentCaptor&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;&amp;gt; consumerCaptor;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @Before&lt;br/&gt;
   public void setUp() {&lt;br/&gt;
@@ -123,9 +123,9 @@ public void testCreatingAndProcessingBeamFnDataReadRunner() throws Exception {&lt;/p&gt;

&lt;p&gt;     List&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; outputValues = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
+    Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
     consumers.put(&quot;outputPC&quot;,&lt;/li&gt;
	&lt;li&gt;(ThrowingConsumer) (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) outputValues::add);&lt;br/&gt;
+        (FnDataReceiver) (FnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) outputValues::add);&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; startFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; finishFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -149,6 +149,7 @@ public void testCreatingAndProcessingBeamFnDataReadRunner() throws Exception {&lt;br/&gt;
         ImmutableMap.of(&quot;outputPC&quot;,&lt;br/&gt;
             RunnerApi.PCollection.newBuilder().setCoderId(CODER_SPEC_ID).build()),&lt;br/&gt;
         COMPONENTS.getCodersMap(),&lt;br/&gt;
+        COMPONENTS.getWindowingStrategiesMap(),&lt;br/&gt;
         consumers,&lt;br/&gt;
         startFunctions::add,&lt;br/&gt;
         finishFunctions::add);&lt;br/&gt;
@@ -156,12 +157,12 @@ public void testCreatingAndProcessingBeamFnDataReadRunner() throws Exception {&lt;br/&gt;
     verifyZeroInteractions(mockBeamFnDataClient);&lt;/p&gt;

&lt;p&gt;     CompletableFuture&amp;lt;Void&amp;gt; completionFuture = new CompletableFuture&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;when(mockBeamFnDataClient.forInboundConsumer(any(), any(), any(), any()))&lt;br/&gt;
+    when(mockBeamFnDataClient.receive(any(), any(), any(), any()))&lt;br/&gt;
         .thenReturn(completionFuture);&lt;br/&gt;
     Iterables.getOnlyElement(startFunctions).run();&lt;/li&gt;
	&lt;li&gt;verify(mockBeamFnDataClient).forInboundConsumer(&lt;br/&gt;
+    verify(mockBeamFnDataClient).receive(&lt;br/&gt;
         eq(PORT_SPEC.getApiServiceDescriptor()),&lt;/li&gt;
	&lt;li&gt;eq(KV.of(bundleId, BeamFnApi.Target.newBuilder()&lt;br/&gt;
+        eq(LogicalEndpoint.of(bundleId, BeamFnApi.Target.newBuilder()&lt;br/&gt;
             .setPrimitiveTransformReference(&quot;pTransformId&quot;)&lt;br/&gt;
             .setName(outputId)&lt;br/&gt;
             .build())),&lt;br/&gt;
@@ -184,7 +185,7 @@ public void testCreatingAndProcessingBeamFnDataReadRunner() throws Exception {&lt;br/&gt;
   public void testReuseForMultipleBundles() throws Exception {&lt;br/&gt;
     CompletableFuture&amp;lt;Void&amp;gt; bundle1Future = new CompletableFuture&amp;lt;&amp;gt;();&lt;br/&gt;
     CompletableFuture&amp;lt;Void&amp;gt; bundle2Future = new CompletableFuture&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;when(mockBeamFnDataClient.forInboundConsumer(&lt;br/&gt;
+    when(mockBeamFnDataClient.receive(&lt;br/&gt;
         any(),&lt;br/&gt;
         any(),&lt;br/&gt;
         any(),&lt;br/&gt;
@@ -205,9 +206,9 @@ public void testReuseForMultipleBundles() throws Exception {&lt;br/&gt;
     // Process for bundle id 0&lt;br/&gt;
     readRunner.registerInputLocation();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verify(mockBeamFnDataClient).forInboundConsumer(&lt;br/&gt;
+    verify(mockBeamFnDataClient).receive(&lt;br/&gt;
         eq(PORT_SPEC.getApiServiceDescriptor()),&lt;/li&gt;
	&lt;li&gt;eq(KV.of(bundleId.get(), INPUT_TARGET)),&lt;br/&gt;
+        eq(LogicalEndpoint.of(bundleId.get(), INPUT_TARGET)),&lt;br/&gt;
         eq(CODER),&lt;br/&gt;
         consumerCaptor.capture());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -237,9 +238,9 @@ public void run() {&lt;br/&gt;
     valuesB.clear();&lt;br/&gt;
     readRunner.registerInputLocation();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verify(mockBeamFnDataClient).forInboundConsumer(&lt;br/&gt;
+    verify(mockBeamFnDataClient).receive(&lt;br/&gt;
         eq(PORT_SPEC.getApiServiceDescriptor()),&lt;/li&gt;
	&lt;li&gt;eq(KV.of(bundleId.get(), INPUT_TARGET)),&lt;br/&gt;
+        eq(LogicalEndpoint.of(bundleId.get(), INPUT_TARGET)),&lt;br/&gt;
         eq(CODER),&lt;br/&gt;
         consumerCaptor.capture());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BeamFnDataWriteRunnerTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BeamFnDataWriteRunnerTest.java&lt;br/&gt;
index 486f114828a..79d61654bac 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BeamFnDataWriteRunnerTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BeamFnDataWriteRunnerTest.java&lt;br/&gt;
@@ -45,8 +45,6 @@&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicReference;&lt;br/&gt;
 import org.apache.beam.fn.harness.PTransformRunnerFactory.Registrar;&lt;br/&gt;
 import org.apache.beam.fn.harness.data.BeamFnDataClient;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.CloseableThrowingConsumer;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
@@ -55,10 +53,12 @@&lt;br/&gt;
 import org.apache.beam.runners.core.construction.CoderTranslation;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.StringUtf8Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.GlobalWindow;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.hamcrest.collection.IsMapContaining;&lt;br/&gt;
 import org.junit.Before;&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
@@ -111,7 +111,7 @@ public void testCreatingAndProcessingBeamFnDataWriteRunner() throws Exception {&lt;br/&gt;
     String bundleId = &quot;57L&quot;;&lt;br/&gt;
     String inputId = &quot;100L&quot;;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
+    Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; startFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; finishFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -135,6 +135,7 @@ public void testCreatingAndProcessingBeamFnDataWriteRunner() throws Exception {&lt;br/&gt;
         ImmutableMap.of(&quot;inputPC&quot;,&lt;br/&gt;
             RunnerApi.PCollection.newBuilder().setCoderId(CODER_ID).build()),&lt;br/&gt;
         COMPONENTS.getCodersMap(),&lt;br/&gt;
+        COMPONENTS.getWindowingStrategiesMap(),&lt;br/&gt;
         consumers,&lt;br/&gt;
         startFunctions::add,&lt;br/&gt;
         finishFunctions::add);&lt;br/&gt;
@@ -143,8 +144,8 @@ public void testCreatingAndProcessingBeamFnDataWriteRunner() throws Exception {&lt;/p&gt;

&lt;p&gt;     List&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; outputValues = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     AtomicBoolean wasCloseCalled = new AtomicBoolean();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; outputConsumer =&lt;/li&gt;
	&lt;li&gt;new CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;(){&lt;br/&gt;
+    CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; outputConsumer =&lt;br/&gt;
+        new CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;() {&lt;br/&gt;
           @Override&lt;br/&gt;
           public void close() throws Exception {&lt;br/&gt;
             wasCloseCalled.set(true);&lt;br/&gt;
@@ -156,14 +157,14 @@ public void accept(WindowedValue&amp;lt;String&amp;gt; t) throws Exception {&lt;br/&gt;
           }&lt;br/&gt;
         };&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;when(mockBeamFnDataClient.forOutboundConsumer(&lt;br/&gt;
+    when(mockBeamFnDataClient.send(&lt;br/&gt;
         any(),&lt;br/&gt;
         any(),&lt;br/&gt;
         Matchers.&amp;lt;Coder&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;&amp;gt;any())).thenReturn(outputConsumer);&lt;br/&gt;
     Iterables.getOnlyElement(startFunctions).run();&lt;/li&gt;
	&lt;li&gt;verify(mockBeamFnDataClient).forOutboundConsumer(&lt;br/&gt;
+    verify(mockBeamFnDataClient).send(&lt;br/&gt;
         eq(PORT_SPEC.getApiServiceDescriptor()),&lt;/li&gt;
	&lt;li&gt;eq(KV.of(bundleId, BeamFnApi.Target.newBuilder()&lt;br/&gt;
+        eq(LogicalEndpoint.of(bundleId, BeamFnApi.Target.newBuilder()&lt;br/&gt;
             .setPrimitiveTransformReference(&quot;ptransformId&quot;)&lt;br/&gt;
             .setName(inputId)&lt;br/&gt;
             .build())),&lt;br/&gt;
@@ -183,9 +184,9 @@ public void accept(WindowedValue&amp;lt;String&amp;gt; t) throws Exception {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @Test&lt;br/&gt;
   public void testReuseForMultipleBundles() throws Exception {&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;RecordingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; valuesA = new RecordingConsumer&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;RecordingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; valuesB = new RecordingConsumer&amp;lt;&amp;gt;();&lt;/li&gt;
	&lt;li&gt;when(mockBeamFnDataClient.forOutboundConsumer(&lt;br/&gt;
+    RecordingReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; valuesA = new RecordingReceiver&amp;lt;&amp;gt;();&lt;br/&gt;
+    RecordingReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; valuesB = new RecordingReceiver&amp;lt;&amp;gt;();&lt;br/&gt;
+    when(mockBeamFnDataClient.send(&lt;br/&gt;
         any(),&lt;br/&gt;
         any(),&lt;br/&gt;
         Matchers.&amp;lt;Coder&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;&amp;gt;any())).thenReturn(valuesA).thenReturn(valuesB);&lt;br/&gt;
@@ -201,9 +202,9 @@ public void testReuseForMultipleBundles() throws Exception {&lt;br/&gt;
     // Process for bundle id 0&lt;br/&gt;
     writeRunner.registerForOutput();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verify(mockBeamFnDataClient).forOutboundConsumer(&lt;br/&gt;
+    verify(mockBeamFnDataClient).send(&lt;br/&gt;
         eq(PORT_SPEC.getApiServiceDescriptor()),&lt;/li&gt;
	&lt;li&gt;eq(KV.of(bundleId.get(), OUTPUT_TARGET)),&lt;br/&gt;
+        eq(LogicalEndpoint.of(bundleId.get(), OUTPUT_TARGET)),&lt;br/&gt;
         eq(CODER));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     writeRunner.consume(valueInGlobalWindow(&quot;ABC&quot;));&lt;br/&gt;
@@ -219,9 +220,9 @@ public void testReuseForMultipleBundles() throws Exception {&lt;br/&gt;
     valuesB.clear();&lt;br/&gt;
     writeRunner.registerForOutput();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;verify(mockBeamFnDataClient).forOutboundConsumer(&lt;br/&gt;
+    verify(mockBeamFnDataClient).send(&lt;br/&gt;
         eq(PORT_SPEC.getApiServiceDescriptor()),&lt;/li&gt;
	&lt;li&gt;eq(KV.of(bundleId.get(), OUTPUT_TARGET)),&lt;br/&gt;
+        eq(LogicalEndpoint.of(bundleId.get(), OUTPUT_TARGET)),&lt;br/&gt;
         eq(CODER));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     writeRunner.consume(valueInGlobalWindow(&quot;GHI&quot;));&lt;br/&gt;
@@ -233,8 +234,8 @@ public void testReuseForMultipleBundles() throws Exception &lt;/p&gt;
{
     verifyNoMoreInteractions(mockBeamFnDataClient);
   }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static class RecordingConsumer&amp;lt;T&amp;gt; extends ArrayList&amp;lt;T&amp;gt;&lt;/li&gt;
	&lt;li&gt;implements CloseableThrowingConsumer&amp;lt;T&amp;gt; {&lt;br/&gt;
+  private static class RecordingReceiver&amp;lt;T&amp;gt; extends ArrayList&amp;lt;T&amp;gt;&lt;br/&gt;
+      implements CloseableFnDataReceiver&amp;lt;T&amp;gt; {&lt;br/&gt;
     private boolean closed;&lt;br/&gt;
     @Override&lt;br/&gt;
     public void close() throws Exception {&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BoundedSourceRunnerTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BoundedSourceRunnerTest.java&lt;br/&gt;
index 50009c09587..4189f9b7aa2 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BoundedSourceRunnerTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/BoundedSourceRunnerTest.java&lt;br/&gt;
@@ -28,18 +28,19 @@&lt;br/&gt;
 import com.google.common.base.Suppliers;&lt;br/&gt;
 import com.google.common.collect.HashMultimap;&lt;br/&gt;
 import com.google.common.collect.ImmutableList;&lt;br/&gt;
-import com.google.common.collect.ImmutableMap;&lt;br/&gt;
 import com.google.common.collect.Iterables;&lt;br/&gt;
 import com.google.common.collect.Multimap;&lt;br/&gt;
 import com.google.protobuf.ByteString;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
+import java.util.Collections;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.ServiceLoader;&lt;br/&gt;
 import org.apache.beam.fn.harness.PTransformRunnerFactory.Registrar;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
+import org.apache.beam.fn.harness.control.ProcessBundleHandler;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
 import org.apache.beam.sdk.io.BoundedSource;&lt;br/&gt;
 import org.apache.beam.sdk.io.CountingSource;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
@@ -61,7 +62,7 @@&lt;br/&gt;
   public void testRunReadLoopWithMultipleSources() throws Exception {&lt;br/&gt;
     List&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt; out1Values = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     List&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt; out2Values = new ArrayList&amp;lt;&amp;gt;();&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt;&amp;gt; consumers =&lt;br/&gt;
+    Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt;&amp;gt; consumers =&lt;br/&gt;
         ImmutableList.of(out1Values::add, out2Values::add);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     BoundedSourceRunner&amp;lt;BoundedSource&amp;lt;Long&amp;gt;, Long&amp;gt; runner = new BoundedSourceRunner&amp;lt;&amp;gt;(&lt;br/&gt;
@@ -81,7 +82,7 @@ public void testRunReadLoopWithMultipleSources() throws Exception {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testRunReadLoopWithEmptySource() throws Exception {&lt;br/&gt;
     List&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt; outValues = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt;&amp;gt; consumers =&lt;br/&gt;
+    Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt;&amp;gt; consumers =&lt;br/&gt;
         ImmutableList.of(outValues::add);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     BoundedSourceRunner&amp;lt;BoundedSource&amp;lt;Long&amp;gt;, Long&amp;gt; runner = new BoundedSourceRunner&amp;lt;&amp;gt;(&lt;br/&gt;
@@ -97,7 +98,7 @@ public void testRunReadLoopWithEmptySource() throws Exception {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testStart() throws Exception {&lt;br/&gt;
     List&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt; outValues = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Collection&amp;lt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt;&amp;gt; consumers =&lt;br/&gt;
+    Collection&amp;lt;FnDataReceiver&amp;lt;WindowedValue&amp;lt;Long&amp;gt;&amp;gt;&amp;gt; consumers =&lt;br/&gt;
         ImmutableList.of(outValues::add);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     ByteString encodedSource =&lt;br/&gt;
@@ -105,7 +106,8 @@ public void testStart() throws Exception {&lt;/p&gt;

&lt;p&gt;     BoundedSourceRunner&amp;lt;BoundedSource&amp;lt;Long&amp;gt;, Long&amp;gt; runner = new BoundedSourceRunner&amp;lt;&amp;gt;(&lt;br/&gt;
         PipelineOptionsFactory.create(),&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;RunnerApi.FunctionSpec.newBuilder().setPayload(encodedSource).build(),&lt;br/&gt;
+        RunnerApi.FunctionSpec.newBuilder()&lt;br/&gt;
+            .setUrn(ProcessBundleHandler.JAVA_SOURCE_URN).setPayload(encodedSource).build(),&lt;br/&gt;
         consumers);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     runner.start();&lt;br/&gt;
@@ -118,9 +120,9 @@ public void testStart() throws Exception {&lt;br/&gt;
   public void testCreatingAndProcessingSourceFromFactory() throws Exception {&lt;br/&gt;
     List&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; outputValues = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
+    Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
     consumers.put(&quot;outputPC&quot;,&lt;/li&gt;
	&lt;li&gt;(ThrowingConsumer) (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) outputValues::add);&lt;br/&gt;
+        (FnDataReceiver) (FnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) outputValues::add);&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; startFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; finishFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -144,8 +146,9 @@ public void testCreatingAndProcessingSourceFromFactory() throws Exception {&lt;br/&gt;
         &quot;pTransformId&quot;,&lt;br/&gt;
         pTransform,&lt;br/&gt;
         Suppliers.ofInstance(&quot;57L&quot;)::get,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ImmutableMap.of(),&lt;/li&gt;
	&lt;li&gt;ImmutableMap.of(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
         consumers,&lt;br/&gt;
         startFunctions::add,&lt;br/&gt;
         finishFunctions::add);&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/FnApiDoFnRunnerTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/FnApiDoFnRunnerTest.java&lt;br/&gt;
index e4422a34099..b132336d0cc 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/FnApiDoFnRunnerTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/FnApiDoFnRunnerTest.java&lt;br/&gt;
@@ -36,10 +36,10 @@&lt;br/&gt;
 import com.google.protobuf.ByteString;&lt;br/&gt;
 import java.io.IOException;&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
+import java.util.Collections;&lt;br/&gt;
 import java.util.List;&lt;br/&gt;
 import java.util.ServiceLoader;&lt;br/&gt;
 import org.apache.beam.fn.harness.PTransformRunnerFactory.Registrar;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingRunnable;&lt;br/&gt;
 import org.apache.beam.fn.harness.state.FakeBeamFnStateClient;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateKey;&lt;br/&gt;
@@ -47,6 +47,7 @@&lt;br/&gt;
 import org.apache.beam.runners.core.construction.ParDoTranslation;&lt;br/&gt;
 import org.apache.beam.sdk.coders.KvCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.StringUtf8Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
 import org.apache.beam.sdk.state.BagState;&lt;br/&gt;
 import org.apache.beam.sdk.state.CombiningState;&lt;br/&gt;
@@ -134,11 +135,11 @@ public void testCreatingAndProcessingDoFn() throws Exception {&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     List&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; mainOutputValues = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     List&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; additionalOutputValues = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
+    Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
     consumers.put(&quot;mainOutputTarget&quot;,&lt;/li&gt;
	&lt;li&gt;(ThrowingConsumer) (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) mainOutputValues::add);&lt;br/&gt;
+        (FnDataReceiver) (FnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) mainOutputValues::add);&lt;br/&gt;
     consumers.put(&quot;additionalOutputTarget&quot;,&lt;/li&gt;
	&lt;li&gt;(ThrowingConsumer) (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) additionalOutputValues::add);&lt;br/&gt;
+        (FnDataReceiver) (FnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) additionalOutputValues::add);&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; startFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; finishFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -149,8 +150,9 @@ public void testCreatingAndProcessingDoFn() throws Exception {&lt;br/&gt;
         pTransformId,&lt;br/&gt;
         pTransform,&lt;br/&gt;
         Suppliers.ofInstance(&quot;57L&quot;)::get,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ImmutableMap.of(),&lt;/li&gt;
	&lt;li&gt;ImmutableMap.of(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
         consumers,&lt;br/&gt;
         startFunctions::add,&lt;br/&gt;
         finishFunctions::add);&lt;br/&gt;
@@ -304,9 +306,9 @@ public void testUsingUserState() throws Exception {&lt;br/&gt;
     ));&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     List&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; mainOutputValues = new ArrayList&amp;lt;&amp;gt;();&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
+    Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; consumers = HashMultimap.create();&lt;br/&gt;
     consumers.put(&quot;mainOutputTarget&quot;,&lt;/li&gt;
	&lt;li&gt;(ThrowingConsumer) (ThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) mainOutputValues::add);&lt;br/&gt;
+        (FnDataReceiver) (FnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;) mainOutputValues::add);&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; startFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     List&amp;lt;ThrowingRunnable&amp;gt; finishFunctions = new ArrayList&amp;lt;&amp;gt;();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -317,8 +319,9 @@ public void testUsingUserState() throws Exception {&lt;br/&gt;
         TEST_PTRANSFORM_ID,&lt;br/&gt;
         pTransform,&lt;br/&gt;
         Suppliers.ofInstance(&quot;57L&quot;)::get,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ImmutableMap.of(),&lt;/li&gt;
	&lt;li&gt;ImmutableMap.of(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
+        Collections.emptyMap(),&lt;br/&gt;
         consumers,&lt;br/&gt;
         startFunctions::add,&lt;br/&gt;
         finishFunctions::add);&lt;br/&gt;
@@ -330,7 +333,7 @@ public void testUsingUserState() throws Exception {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     // Ensure that bag user state that is initially empty or populated works.&lt;br/&gt;
     // Ensure that the key order does not matter when we traverse over KV pairs.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt; mainInput =&lt;br/&gt;
+    FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt; mainInput =&lt;br/&gt;
         Iterables.getOnlyElement(consumers.get(&quot;inputTarget&quot;));&lt;br/&gt;
     mainInput.accept(valueInGlobalWindow(KV.of(&quot;X&quot;, &quot;X1&quot;)));&lt;br/&gt;
     mainInput.accept(valueInGlobalWindow(KV.of(&quot;Y&quot;, &quot;Y1&quot;)));&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/BeamFnControlClientTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/BeamFnControlClientTest.java&lt;br/&gt;
index 26b50268f22..fcb82d1765c 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/BeamFnControlClientTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/BeamFnControlClientTest.java&lt;br/&gt;
@@ -37,11 +37,11 @@&lt;br/&gt;
 import java.util.concurrent.Future;&lt;br/&gt;
 import java.util.concurrent.LinkedBlockingQueue;&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
-import java.util.function.Function;&lt;br/&gt;
 import org.apache.beam.fn.harness.fn.ThrowingFunction;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnControlGrpc;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory.StreamObserverClientFactory;&lt;br/&gt;
 import org.apache.beam.sdk.fn.test.TestStreams;&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
 import org.junit.runner.RunWith;&lt;br/&gt;
@@ -176,8 +176,7 @@ public Void call() throws Exception {&lt;br/&gt;
   }&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   private &amp;lt;ReqT, RespT&amp;gt; StreamObserver&amp;lt;RespT&amp;gt; createStreamForTest(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Function&amp;lt;StreamObserver&amp;lt;ReqT&amp;gt;, StreamObserver&amp;lt;RespT&amp;gt;&amp;gt; clientFactory,&lt;/li&gt;
	&lt;li&gt;StreamObserver&amp;lt;ReqT&amp;gt; handler) {&lt;/li&gt;
	&lt;li&gt;return clientFactory.apply(handler);&lt;br/&gt;
+      StreamObserverClientFactory&amp;lt;ReqT, RespT&amp;gt; clientFactory, StreamObserver&amp;lt;ReqT&amp;gt; handler) 
{
+    return clientFactory.outboundObserverFor(handler);
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/ProcessBundleHandlerTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/ProcessBundleHandlerTest.java&lt;br/&gt;
index 15b58668ab4..2f16c7573d5 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/ProcessBundleHandlerTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/ProcessBundleHandlerTest.java&lt;br/&gt;
@@ -49,6 +49,10 @@&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateResponse;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints.ApiServiceDescriptor;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.RunnerApi;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.Coder;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PCollection;&lt;br/&gt;
+import org.apache.beam.model.pipeline.v1.RunnerApi.PTransform;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptions;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
@@ -108,11 +112,12 @@ public Object createRunnerForPTransform(&lt;br/&gt;
           BeamFnDataClient beamFnDataClient,&lt;br/&gt;
           BeamFnStateClient beamFnStateClient,&lt;br/&gt;
           String pTransformId,&lt;br/&gt;
-          RunnerApi.PTransform pTransform,&lt;br/&gt;
+          PTransform pTransform,&lt;br/&gt;
           Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-          Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
-          Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-          Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+          Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+          Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+          Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+          Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
           Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
           Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {&lt;br/&gt;
 &lt;br/&gt;
@@ -172,11 +177,12 @@ public Object createRunnerForPTransform(&lt;br/&gt;
               BeamFnDataClient beamFnDataClient,&lt;br/&gt;
               BeamFnStateClient beamFnStateClient,&lt;br/&gt;
               String pTransformId,&lt;br/&gt;
-              RunnerApi.PTransform pTransform,&lt;br/&gt;
+              PTransform pTransform,&lt;br/&gt;
               Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-              Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+              Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+              Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+              Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+              Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {&lt;br/&gt;
             thrown.expect(IllegalStateException.class);&lt;br/&gt;
@@ -212,11 +218,12 @@ public Object createRunnerForPTransform(&lt;br/&gt;
               BeamFnDataClient beamFnDataClient,&lt;br/&gt;
               BeamFnStateClient beamFnStateClient,&lt;br/&gt;
               String pTransformId,&lt;br/&gt;
-              RunnerApi.PTransform pTransform,&lt;br/&gt;
+              PTransform pTransform,&lt;br/&gt;
               Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-              Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+              Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+              Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+              Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+              Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {&lt;br/&gt;
             thrown.expect(IllegalStateException.class);&lt;br/&gt;
@@ -253,11 +260,12 @@ public Object createRunnerForPTransform(&lt;br/&gt;
               BeamFnDataClient beamFnDataClient,&lt;br/&gt;
               BeamFnStateClient beamFnStateClient,&lt;br/&gt;
               String pTransformId,&lt;br/&gt;
-              RunnerApi.PTransform pTransform,&lt;br/&gt;
+              PTransform pTransform,&lt;br/&gt;
               Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-              Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+              Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+              Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+              Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+              Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {&lt;br/&gt;
             thrown.expect(IllegalStateException.class);&lt;br/&gt;
@@ -330,11 +338,12 @@ public Object createRunnerForPTransform(&lt;br/&gt;
               BeamFnDataClient beamFnDataClient,&lt;br/&gt;
               BeamFnStateClient beamFnStateClient,&lt;br/&gt;
               String pTransformId,&lt;br/&gt;
-              RunnerApi.PTransform pTransform,&lt;br/&gt;
+              PTransform pTransform,&lt;br/&gt;
               Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-              Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+              Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+              Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+              Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+              Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {&lt;br/&gt;
             addStartFunction.accept(() -&amp;gt; doStateCalls(beamFnStateClient));&lt;br/&gt;
@@ -380,11 +389,12 @@ public Object createRunnerForPTransform(&lt;br/&gt;
               BeamFnDataClient beamFnDataClient,&lt;br/&gt;
               BeamFnStateClient beamFnStateClient,&lt;br/&gt;
               String pTransformId,&lt;br/&gt;
-              RunnerApi.PTransform pTransform,&lt;br/&gt;
+              PTransform pTransform,&lt;br/&gt;
               Supplier&amp;lt;String&amp;gt; processBundleInstructionId,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.PCollection&amp;gt; pCollections,&lt;br/&gt;
-              Map&amp;lt;String, RunnerApi.Coder&amp;gt; coders,&lt;br/&gt;
-              Multimap&amp;lt;String, ThrowingConsumer&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
+              Map&amp;lt;String, PCollection&amp;gt; pCollections,&lt;br/&gt;
+              Map&amp;lt;String, Coder&amp;gt; coders,&lt;br/&gt;
+              Map&amp;lt;String, RunnerApi.WindowingStrategy&amp;gt; windowingStrategies,&lt;br/&gt;
+              Multimap&amp;lt;String, FnDataReceiver&amp;lt;WindowedValue&amp;lt;?&amp;gt;&amp;gt;&amp;gt; pCollectionIdsToConsumers,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addStartFunction,&lt;br/&gt;
               Consumer&amp;lt;ThrowingRunnable&amp;gt; addFinishFunction) throws IOException {&lt;br/&gt;
             addStartFunction.accept(() -&amp;gt; doStateCalls(beamFnStateClient));&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataBufferingOutboundObserverTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataBufferingOutboundObserverTest.java&lt;br/&gt;
index 74dec1ea981..8f36013dc87 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataBufferingOutboundObserverTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataBufferingOutboundObserverTest.java&lt;br/&gt;
@@ -28,15 +28,16 @@&lt;br/&gt;
 import java.util.ArrayList;&lt;br/&gt;
 import java.util.Collection;&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicBoolean;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.CloseableThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
+import org.apache.beam.model.fnexecution.v1.BeamFnApi.Target;&lt;br/&gt;
 import org.apache.beam.sdk.coders.ByteArrayCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.LengthPrefixCoder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.fn.test.TestStreams;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
 import org.junit.runner.RunWith;&lt;br/&gt;
 import org.junit.runners.JUnit4;&lt;br/&gt;
@@ -45,10 +46,10 @@&lt;br/&gt;
 @RunWith(JUnit4.class)&lt;br/&gt;
 public class BeamFnDataBufferingOutboundObserverTest {&lt;br/&gt;
   private static final int DEFAULT_BUFFER_LIMIT = 1_000_000;&lt;br/&gt;
-  private static final KV&amp;lt;String, BeamFnApi.Target&amp;gt; OUTPUT_LOCATION =&lt;br/&gt;
-      KV.of(&lt;br/&gt;
+  private static final LogicalEndpoint OUTPUT_LOCATION =&lt;br/&gt;
+      LogicalEndpoint.of(&lt;br/&gt;
           &quot;777L&quot;,&lt;br/&gt;
-          BeamFnApi.Target.newBuilder()&lt;br/&gt;
+          Target.newBuilder()&lt;br/&gt;
               .setPrimitiveTransformReference(&quot;555L&quot;)&lt;br/&gt;
               .setName(&quot;Test&quot;)&lt;br/&gt;
               .build());&lt;br/&gt;
@@ -59,7 +60,7 @@&lt;br/&gt;
   public void testWithDefaultBuffer() throws Exception {&lt;br/&gt;
     Collection&amp;lt;BeamFnApi.Elements&amp;gt; values = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     AtomicBoolean onCompletedWasCalled = new AtomicBoolean();&lt;br/&gt;
-    CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;byte[]&amp;gt;&amp;gt; consumer =&lt;br/&gt;
+    CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;byte[]&amp;gt;&amp;gt; consumer =&lt;br/&gt;
         new BeamFnDataBufferingOutboundObserver&amp;lt;&amp;gt;(&lt;br/&gt;
         PipelineOptionsFactory.create(),&lt;br/&gt;
         OUTPUT_LOCATION,&lt;br/&gt;
@@ -98,7 +99,7 @@ public void testWithDefaultBuffer() throws Exception {&lt;br/&gt;
   public void testExperimentConfiguresBufferLimit() throws Exception {&lt;br/&gt;
     Collection&amp;lt;BeamFnApi.Elements&amp;gt; values = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     AtomicBoolean onCompletedWasCalled = new AtomicBoolean();&lt;br/&gt;
-    CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;byte[]&amp;gt;&amp;gt; consumer =&lt;br/&gt;
+    CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;byte[]&amp;gt;&amp;gt; consumer =&lt;br/&gt;
         new BeamFnDataBufferingOutboundObserver&amp;lt;&amp;gt;(&lt;br/&gt;
         PipelineOptionsFactory.fromArgs(&lt;br/&gt;
             new String[] { &quot;--experiments=beam_fn_api_data_buffer_limit=100&quot; }).create(),&lt;br/&gt;
@@ -125,8 +126,8 @@ public void testExperimentConfiguresBufferLimit() throws Exception {
     assertEquals(
         BeamFnApi.Elements.newBuilder(messageWithData(new byte[1]))
             .addData(BeamFnApi.Elements.Data.newBuilder()
-                .setInstructionReference(OUTPUT_LOCATION.getKey())
-                .setTarget(OUTPUT_LOCATION.getValue()))
+                .setInstructionReference(OUTPUT_LOCATION.getInstructionId())
+                .setTarget(OUTPUT_LOCATION.getTarget()))
             .build(),
         Iterables.get(values, 1));
   }&lt;br/&gt;
@@ -138,8 +139,8 @@ public void testExperimentConfiguresBufferLimit() throws Exception {&lt;br/&gt;
     }&lt;br/&gt;
     return BeamFnApi.Elements.newBuilder()&lt;br/&gt;
         .addData(BeamFnApi.Elements.Data.newBuilder()&lt;br/&gt;
-            .setInstructionReference(OUTPUT_LOCATION.getKey())&lt;br/&gt;
-            .setTarget(OUTPUT_LOCATION.getValue())&lt;br/&gt;
+            .setInstructionReference(OUTPUT_LOCATION.getInstructionId())&lt;br/&gt;
+            .setTarget(OUTPUT_LOCATION.getTarget())&lt;br/&gt;
             .setData(output.toByteString()))&lt;br/&gt;
         .build();&lt;br/&gt;
   }&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcClientTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcClientTest.java&lt;br/&gt;
index 55c0b4305bd..d62278af840 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcClientTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcClientTest.java&lt;br/&gt;
@@ -41,22 +41,22 @@&lt;br/&gt;
 import java.util.concurrent.ExecutionException;&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicInteger;&lt;br/&gt;
 import java.util.concurrent.atomic.AtomicReference;&lt;br/&gt;
-import java.util.function.Function;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.CloseableThrowingConsumer;&lt;br/&gt;
-import org.apache.beam.fn.harness.fn.ThrowingConsumer;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.Elements;&lt;br/&gt;
+import org.apache.beam.model.fnexecution.v1.BeamFnApi.Target;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnDataGrpc;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
 import org.apache.beam.sdk.coders.Coder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.LengthPrefixCoder;&lt;br/&gt;
 import org.apache.beam.sdk.coders.StringUtf8Coder;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.CloseableFnDataReceiver;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory.StreamObserverClientFactory;&lt;br/&gt;
 import org.apache.beam.sdk.fn.test.Consumer;&lt;br/&gt;
 import org.apache.beam.sdk.fn.test.TestStreams;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.windowing.GlobalWindow;&lt;br/&gt;
 import org.apache.beam.sdk.util.WindowedValue;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
 import org.junit.runner.RunWith;&lt;br/&gt;
 import org.junit.runners.JUnit4;&lt;br/&gt;
@@ -68,16 +68,16 @@&lt;br/&gt;
       LengthPrefixCoder.of(&lt;br/&gt;
           WindowedValue.getFullCoder(StringUtf8Coder.of(),&lt;br/&gt;
               GlobalWindow.Coder.INSTANCE));&lt;br/&gt;
-  private static final KV&amp;lt;String, BeamFnApi.Target&amp;gt; KEY_A =&lt;br/&gt;
-      KV.of(&lt;br/&gt;
+  private static final LogicalEndpoint ENDPOINT_A =&lt;br/&gt;
+      LogicalEndpoint.of(&lt;br/&gt;
           &quot;12L&quot;,&lt;br/&gt;
-          BeamFnApi.Target.newBuilder()&lt;br/&gt;
+          Target.newBuilder()&lt;br/&gt;
               .setPrimitiveTransformReference(&quot;34L&quot;)&lt;br/&gt;
               .setName(&quot;targetA&quot;)&lt;br/&gt;
               .build());&lt;br/&gt;
 &lt;br/&gt;
-  private static final KV&amp;lt;String, BeamFnApi.Target&amp;gt; KEY_B =&lt;br/&gt;
-      KV.of(&lt;br/&gt;
+  private static final LogicalEndpoint ENDPOINT_B =&lt;br/&gt;
+      LogicalEndpoint.of(&lt;br/&gt;
           &quot;56L&quot;,&lt;br/&gt;
           BeamFnApi.Target.newBuilder()&lt;br/&gt;
               .setPrimitiveTransformReference(&quot;78L&quot;)&lt;br/&gt;
@@ -91,29 +91,29 @@&lt;br/&gt;
     try {
     ELEMENTS_A_1 = BeamFnApi.Elements.newBuilder()
         .addData(BeamFnApi.Elements.Data.newBuilder()
-            .setInstructionReference(KEY_A.getKey())
-            .setTarget(KEY_A.getValue())
+            .setInstructionReference(ENDPOINT_A.getInstructionId())
+            .setTarget(ENDPOINT_A.getTarget())
             .setData(ByteString.copyFrom(encodeToByteArray(CODER, valueInGlobalWindow(&quot;ABC&quot;)))
                 .concat(ByteString.copyFrom(encodeToByteArray(CODER, valueInGlobalWindow(&quot;DEF&quot;))))))
         .build();
     ELEMENTS_A_2 = BeamFnApi.Elements.newBuilder()
         .addData(BeamFnApi.Elements.Data.newBuilder()
-            .setInstructionReference(KEY_A.getKey())
-            .setTarget(KEY_A.getValue())
+            .setInstructionReference(ENDPOINT_A.getInstructionId())
+            .setTarget(ENDPOINT_A.getTarget())
             .setData(ByteString.copyFrom(encodeToByteArray(CODER, valueInGlobalWindow(&quot;GHI&quot;)))))
         .addData(BeamFnApi.Elements.Data.newBuilder()
-            .setInstructionReference(KEY_A.getKey())
-            .setTarget(KEY_A.getValue()))
+            .setInstructionReference(ENDPOINT_A.getInstructionId())
+            .setTarget(ENDPOINT_A.getTarget()))
         .build();
     ELEMENTS_B_1 = BeamFnApi.Elements.newBuilder()
         .addData(BeamFnApi.Elements.Data.newBuilder()
-            .setInstructionReference(KEY_B.getKey())
-            .setTarget(KEY_B.getValue())
+            .setInstructionReference(ENDPOINT_B.getInstructionId())
+            .setTarget(ENDPOINT_B.getTarget())
             .setData(ByteString.copyFrom(encodeToByteArray(CODER, valueInGlobalWindow(&quot;JKL&quot;)))
                 .concat(ByteString.copyFrom(encodeToByteArray(CODER, valueInGlobalWindow(&quot;MNO&quot;))))))
         .addData(BeamFnApi.Elements.Data.newBuilder()
-            .setInstructionReference(KEY_B.getKey())
-            .setTarget(KEY_B.getValue()))
+            .setInstructionReference(ENDPOINT_B.getInstructionId())
+            .setTarget(ENDPOINT_B.getTarget()))
         .build();
     } catch (Exception e) {&lt;br/&gt;
       throw new ExceptionInInitializerError(e);&lt;br/&gt;
@@ -156,11 +156,9 @@ public void testForInboundConsumer() throws Exception {&lt;br/&gt;
         (Endpoints.ApiServiceDescriptor descriptor) -&amp;gt; channel,&lt;br/&gt;
         this::createStreamForTest);&lt;br/&gt;
 &lt;br/&gt;
-    CompletableFuture&amp;lt;Void&amp;gt; readFutureA = clientFactory.forInboundConsumer(&lt;br/&gt;
-        apiServiceDescriptor,&lt;br/&gt;
-        KEY_A,&lt;br/&gt;
-        CODER,&lt;br/&gt;
-        inboundValuesA::add);&lt;br/&gt;
+      CompletableFuture&amp;lt;Void&amp;gt; readFutureA =&lt;br/&gt;
+          clientFactory.receive(&lt;br/&gt;
+              apiServiceDescriptor, ENDPOINT_A, CODER, inboundValuesA::add);&lt;br/&gt;
 &lt;br/&gt;
       waitForClientToConnect.await();&lt;br/&gt;
       outboundServerObserver.get().onNext(ELEMENTS_A_1);&lt;br/&gt;
@@ -169,11 +167,9 @@ public void testForInboundConsumer() throws Exception {&lt;br/&gt;
       outboundServerObserver.get().onNext(ELEMENTS_B_1);&lt;br/&gt;
       Thread.sleep(100);&lt;br/&gt;
 &lt;br/&gt;
-      CompletableFuture&amp;lt;Void&amp;gt; readFutureB = clientFactory.forInboundConsumer(&lt;br/&gt;
-          apiServiceDescriptor,&lt;br/&gt;
-          KEY_B,&lt;br/&gt;
-          CODER,&lt;br/&gt;
-          inboundValuesB::add);&lt;br/&gt;
+      CompletableFuture&amp;lt;Void&amp;gt; readFutureB =&lt;br/&gt;
+          clientFactory.receive(&lt;br/&gt;
+              apiServiceDescriptor, ENDPOINT_B, CODER, inboundValuesB::add);&lt;br/&gt;
 &lt;br/&gt;
       // Show that out of order stream completion can occur.&lt;br/&gt;
       readFutureB.get();&lt;br/&gt;
@@ -225,17 +221,15 @@ public void testForInboundConsumerThatThrows() throws Exception {&lt;br/&gt;
           (Endpoints.ApiServiceDescriptor descriptor) -&amp;gt; channel,&lt;br/&gt;
           this::createStreamForTest);&lt;br/&gt;
 &lt;br/&gt;
-      CompletableFuture&amp;lt;Void&amp;gt; readFuture = clientFactory.forInboundConsumer(&lt;br/&gt;
-          apiServiceDescriptor,&lt;br/&gt;
-          KEY_A,&lt;br/&gt;
-          CODER,&lt;br/&gt;
-          new ThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt;() {&lt;br/&gt;
-            @Override&lt;br/&gt;
-            public void accept(WindowedValue&amp;lt;String&amp;gt; t) throws Exception {
-              consumerInvoked.incrementAndGet();
-              throw exceptionToThrow;
-            }&lt;br/&gt;
-          });&lt;br/&gt;
+      CompletableFuture&amp;lt;Void&amp;gt; readFuture =&lt;br/&gt;
+          clientFactory.receive(&lt;br/&gt;
+              apiServiceDescriptor,&lt;br/&gt;
+              ENDPOINT_A,&lt;br/&gt;
+              CODER,&lt;br/&gt;
+              t -&amp;gt; {
+                consumerInvoked.incrementAndGet();
+                throw exceptionToThrow;
+              });&lt;br/&gt;
 &lt;br/&gt;
       waitForClientToConnect.await();&lt;br/&gt;
 &lt;br/&gt;
@@ -297,8 +291,8 @@ public void accept(BeamFnApi.Elements t) {&lt;br/&gt;
           (Endpoints.ApiServiceDescriptor descriptor) -&amp;gt; channel,&lt;br/&gt;
           this::createStreamForTest);&lt;br/&gt;
 &lt;br/&gt;
-      try (CloseableThrowingConsumer&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; consumer =&lt;br/&gt;
-          clientFactory.forOutboundConsumer(apiServiceDescriptor, KEY_A, CODER)) {&lt;br/&gt;
+      try (CloseableFnDataReceiver&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; consumer =&lt;br/&gt;
+          clientFactory.send(apiServiceDescriptor, ENDPOINT_A, CODER)) {&lt;br/&gt;
         consumer.accept(valueInGlobalWindow(&quot;ABC&quot;));&lt;br/&gt;
         consumer.accept(valueInGlobalWindow(&quot;DEF&quot;));&lt;br/&gt;
         consumer.accept(valueInGlobalWindow(&quot;GHI&quot;));&lt;br/&gt;
@@ -313,8 +307,8 @@ public void accept(BeamFnApi.Elements t) {&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   private &amp;lt;ReqT, RespT&amp;gt; StreamObserver&amp;lt;RespT&amp;gt; createStreamForTest(&lt;br/&gt;
-      Function&amp;lt;StreamObserver&amp;lt;ReqT&amp;gt;, StreamObserver&amp;lt;RespT&amp;gt;&amp;gt; clientFactory,&lt;br/&gt;
+      StreamObserverClientFactory&amp;lt;ReqT, RespT&amp;gt; clientFactory,&lt;br/&gt;
       StreamObserver&amp;lt;ReqT&amp;gt; handler) {
-    return clientFactory.apply(handler);
+    return clientFactory.outboundObserverFor(handler);
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcMultiplexerTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcMultiplexerTest.java&lt;br/&gt;
index 94e561de025..aae3f51bd3d 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcMultiplexerTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataGrpcMultiplexerTest.java&lt;br/&gt;
@@ -32,16 +32,16 @@&lt;br/&gt;
 import java.util.concurrent.TimeUnit;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.LogicalEndpoint;&lt;br/&gt;
 import org.apache.beam.sdk.fn.test.TestStreams;&lt;br/&gt;
-import org.apache.beam.sdk.values.KV;&lt;br/&gt;
 import org.junit.Test;&lt;br/&gt;
 &lt;br/&gt;
 /** Tests for {@link BeamFnDataGrpcMultiplexer}. */&lt;br/&gt;
 public class BeamFnDataGrpcMultiplexerTest {&lt;br/&gt;
   private static final Endpoints.ApiServiceDescriptor DESCRIPTOR =&lt;br/&gt;
       Endpoints.ApiServiceDescriptor.newBuilder().setUrl(&quot;test&quot;).build();&lt;br/&gt;
-  private static final KV&amp;lt;String, BeamFnApi.Target&amp;gt; OUTPUT_LOCATION =&lt;br/&gt;
-      KV.of(&lt;br/&gt;
+  private static final LogicalEndpoint OUTPUT_LOCATION =&lt;br/&gt;
+      LogicalEndpoint.of(&lt;br/&gt;
           &quot;777L&quot;,&lt;br/&gt;
           BeamFnApi.Target.newBuilder()&lt;br/&gt;
               .setName(&quot;name&quot;)&lt;br/&gt;
@@ -49,14 +49,14 @@&lt;br/&gt;
               .build());&lt;br/&gt;
   private static final BeamFnApi.Elements ELEMENTS = BeamFnApi.Elements.newBuilder()&lt;br/&gt;
       .addData(BeamFnApi.Elements.Data.newBuilder()&lt;br/&gt;
-          .setInstructionReference(OUTPUT_LOCATION.getKey())&lt;br/&gt;
-          .setTarget(OUTPUT_LOCATION.getValue())&lt;br/&gt;
+          .setInstructionReference(OUTPUT_LOCATION.getInstructionId())&lt;br/&gt;
+          .setTarget(OUTPUT_LOCATION.getTarget())&lt;br/&gt;
           .setData(ByteString.copyFrom(new byte&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;)))&lt;br/&gt;
       .build();&lt;br/&gt;
   private static final BeamFnApi.Elements TERMINAL_ELEMENTS = BeamFnApi.Elements.newBuilder()&lt;br/&gt;
       .addData(BeamFnApi.Elements.Data.newBuilder()&lt;br/&gt;
-          .setInstructionReference(OUTPUT_LOCATION.getKey())&lt;br/&gt;
-          .setTarget(OUTPUT_LOCATION.getValue()))&lt;br/&gt;
+          .setInstructionReference(OUTPUT_LOCATION.getInstructionId())&lt;br/&gt;
+          .setTarget(OUTPUT_LOCATION.getTarget()))&lt;br/&gt;
       .build();&lt;br/&gt;
 &lt;br/&gt;
   @Test&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataInboundObserverTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataInboundObserverTest.java&lt;br/&gt;
index c93942372d4..7cafd1aad56 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataInboundObserverTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/BeamFnDataInboundObserverTest.java&lt;br/&gt;
@@ -51,10 +51,8 @@&lt;br/&gt;
   public void testDecodingElements() throws Exception {&lt;br/&gt;
     Collection&amp;lt;WindowedValue&amp;lt;String&amp;gt;&amp;gt; values = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
     CompletableFuture&amp;lt;Void&amp;gt; readFuture = new CompletableFuture&amp;lt;&amp;gt;();&lt;br/&gt;
-    BeamFnDataInboundObserver&amp;lt;String&amp;gt; observer = new BeamFnDataInboundObserver&amp;lt;&amp;gt;(&lt;br/&gt;
-        CODER,&lt;br/&gt;
-        values::add,&lt;br/&gt;
-        readFuture);&lt;br/&gt;
+    BeamFnDataInboundObserver&amp;lt;String&amp;gt; observer =&lt;br/&gt;
+        new BeamFnDataInboundObserver&amp;lt;&amp;gt;(CODER, values::add, readFuture);&lt;br/&gt;
 &lt;br/&gt;
     // Test decoding multiple messages&lt;br/&gt;
     observer.accept(dataWith(&quot;ABC&quot;, &quot;DEF&quot;, &quot;GHI&quot;));&lt;br/&gt;
@@ -75,10 +73,8 @@ public void testDecodingElements() throws Exception {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testConsumptionFailureCompletesReadFutureAndDiscardsMessages() throws Exception {&lt;br/&gt;
     CompletableFuture&amp;lt;Void&amp;gt; readFuture = new CompletableFuture&amp;lt;&amp;gt;();&lt;br/&gt;
-    BeamFnDataInboundObserver&amp;lt;String&amp;gt; observer = new BeamFnDataInboundObserver&amp;lt;&amp;gt;(&lt;br/&gt;
-        CODER,&lt;br/&gt;
-        this::throwOnDefValue,&lt;br/&gt;
-        readFuture);&lt;br/&gt;
+    BeamFnDataInboundObserver&amp;lt;String&amp;gt; observer =&lt;br/&gt;
+        new BeamFnDataInboundObserver&amp;lt;&amp;gt;(CODER, this::throwOnDefValue, readFuture);&lt;br/&gt;
 &lt;br/&gt;
     assertFalse(readFuture.isDone());&lt;br/&gt;
     observer.accept(dataWith(&quot;ABC&quot;, &quot;DEF&quot;, &quot;GHI&quot;));&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/MultiplexingFnDataReceiverTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/MultiplexingFnDataReceiverTest.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..3af1cdb54aa&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/data/MultiplexingFnDataReceiverTest.java&lt;br/&gt;
@@ -0,0 +1,115 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.beam.fn.harness.data;&lt;br/&gt;
+&lt;br/&gt;
+import static org.hamcrest.Matchers.contains;&lt;br/&gt;
+import static org.hamcrest.Matchers.containsInAnyOrder;&lt;br/&gt;
+import static org.junit.Assert.assertThat;&lt;br/&gt;
+&lt;br/&gt;
+import com.google.common.collect.ImmutableList;&lt;br/&gt;
+import java.util.ArrayList;&lt;br/&gt;
+import java.util.HashSet;&lt;br/&gt;
+import java.util.List;&lt;br/&gt;
+import java.util.Set;&lt;br/&gt;
+import org.apache.beam.sdk.fn.data.FnDataReceiver;&lt;br/&gt;
+import org.junit.Rule;&lt;br/&gt;
+import org.junit.Test;&lt;br/&gt;
+import org.junit.rules.ExpectedException;&lt;br/&gt;
+import org.junit.runner.RunWith;&lt;br/&gt;
+import org.junit.runners.JUnit4;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Tests for {@link MultiplexingFnDataReceiver}.&lt;br/&gt;
+ */&lt;br/&gt;
+@RunWith(JUnit4.class)&lt;br/&gt;
+public class MultiplexingFnDataReceiverTest {&lt;br/&gt;
+  @Rule&lt;br/&gt;
+  public ExpectedException thrown = ExpectedException.none();&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void singleConsumer() throws Exception {
+    List&amp;lt;String&amp;gt; consumer = new ArrayList&amp;lt;&amp;gt;();
+    FnDataReceiver&amp;lt;String&amp;gt; multiplexer =
+        MultiplexingFnDataReceiver.forConsumers(
+            ImmutableList.&amp;lt;FnDataReceiver&amp;lt;String&amp;gt;&amp;gt;of(consumer::add));
+
+    multiplexer.accept(&quot;foo&quot;);
+    multiplexer.accept(&quot;bar&quot;);
+
+    assertThat(consumer, contains(&quot;foo&quot;, &quot;bar&quot;));
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void singleConsumerException() throws Exception {&lt;br/&gt;
+    String message = &quot;my_exception&quot;;&lt;br/&gt;
+    FnDataReceiver&amp;lt;Integer&amp;gt; multiplexer =&lt;br/&gt;
+        MultiplexingFnDataReceiver.forConsumers(&lt;br/&gt;
+            ImmutableList.&amp;lt;FnDataReceiver&amp;lt;Integer&amp;gt;&amp;gt;of(&lt;br/&gt;
+                (Integer i) -&amp;gt; {&lt;br/&gt;
+                  if (i &amp;gt; 1) {
+                    throw new Exception(message);
+                  }&lt;br/&gt;
+                }));&lt;br/&gt;
+&lt;br/&gt;
+    multiplexer.accept(0);&lt;br/&gt;
+    multiplexer.accept(1);&lt;br/&gt;
+    thrown.expectMessage(message);&lt;br/&gt;
+    thrown.expect(Exception.class);&lt;br/&gt;
+    multiplexer.accept(2);&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void multipleConsumers() throws Exception {
+    List&amp;lt;String&amp;gt; consumer = new ArrayList&amp;lt;&amp;gt;();
+    Set&amp;lt;String&amp;gt; otherConsumer = new HashSet&amp;lt;&amp;gt;();
+    FnDataReceiver&amp;lt;String&amp;gt; multiplexer =
+        MultiplexingFnDataReceiver.forConsumers(
+            ImmutableList.&amp;lt;FnDataReceiver&amp;lt;String&amp;gt;&amp;gt;of(consumer::add, otherConsumer::add));
+
+    multiplexer.accept(&quot;foo&quot;);
+    multiplexer.accept(&quot;bar&quot;);
+    multiplexer.accept(&quot;foo&quot;);
+
+    assertThat(consumer, contains(&quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;));
+    assertThat(otherConsumer, containsInAnyOrder(&quot;foo&quot;, &quot;bar&quot;));
+  }&lt;br/&gt;
+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void multipleConsumersException() throws Exception {&lt;br/&gt;
+    String message = &quot;my_exception&quot;;&lt;br/&gt;
+    List&amp;lt;Integer&amp;gt; consumer = new ArrayList&amp;lt;&amp;gt;();&lt;br/&gt;
+    FnDataReceiver&amp;lt;Integer&amp;gt; multiplexer =&lt;br/&gt;
+        MultiplexingFnDataReceiver.forConsumers(&lt;br/&gt;
+            ImmutableList.&amp;lt;FnDataReceiver&amp;lt;Integer&amp;gt;&amp;gt;of(&lt;br/&gt;
+                consumer::add,&lt;br/&gt;
+                (Integer i) -&amp;gt; {&lt;br/&gt;
+                  if (i &amp;gt; 1) {+                    throw new Exception(message);+                  }&lt;br/&gt;
+                }));&lt;br/&gt;
+&lt;br/&gt;
+    multiplexer.accept(0);&lt;br/&gt;
+    multiplexer.accept(1);&lt;br/&gt;
+    assertThat(consumer, containsInAnyOrder(0, 1));&lt;br/&gt;
+&lt;br/&gt;
+    thrown.expectMessage(message);&lt;br/&gt;
+    thrown.expect(Exception.class);&lt;br/&gt;
+    multiplexer.accept(2);&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/state/BeamFnStateGrpcClientCacheTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/state/BeamFnStateGrpcClientCacheTest.java&lt;br/&gt;
index 86a24b288e5..05acbd69d3f 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/state/BeamFnStateGrpcClientCacheTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/state/BeamFnStateGrpcClientCacheTest.java&lt;br/&gt;
@@ -38,12 +38,12 @@&lt;br/&gt;
 import java.util.concurrent.CompletableFuture;&lt;br/&gt;
 import java.util.concurrent.ExecutionException;&lt;br/&gt;
 import java.util.concurrent.LinkedBlockingQueue;&lt;br/&gt;
-import java.util.function.Function;&lt;br/&gt;
 import org.apache.beam.fn.harness.IdGenerator;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateRequest;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnApi.StateResponse;&lt;br/&gt;
 import org.apache.beam.model.fnexecution.v1.BeamFnStateGrpc;&lt;br/&gt;
 import org.apache.beam.model.pipeline.v1.Endpoints;&lt;br/&gt;
+import org.apache.beam.sdk.fn.stream.StreamObserverFactory.StreamObserverClientFactory;&lt;br/&gt;
 import org.apache.beam.sdk.fn.test.TestStreams;&lt;br/&gt;
 import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
 import org.junit.After;&lt;br/&gt;
@@ -227,8 +227,7 @@ private void handleServerRequest(&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
   private &amp;lt;ReqT, RespT&amp;gt; StreamObserver&amp;lt;RespT&amp;gt; createStreamForTest(&lt;br/&gt;
-      Function&amp;lt;StreamObserver&amp;lt;ReqT&amp;gt;, StreamObserver&amp;lt;RespT&amp;gt;&amp;gt; clientFactory,&lt;br/&gt;
-      StreamObserver&amp;lt;ReqT&amp;gt; handler) {&lt;br/&gt;
-    return clientFactory.apply(handler);&lt;br/&gt;
+      StreamObserverClientFactory&amp;lt;ReqT, RespT&amp;gt; clientFactory, StreamObserver&amp;lt;ReqT&amp;gt; handler) {+    return clientFactory.outboundObserverFor(handler);   }
&lt;p&gt; }&lt;br/&gt;
diff --git a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/stream/StreamObserverFactoryTest.java b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/stream/HarnessStreamObserverFactoriesTest.java&lt;br/&gt;
similarity index 89%&lt;br/&gt;
rename from sdks/java/harness/src/test/java/org/apache/beam/fn/harness/stream/StreamObserverFactoryTest.java&lt;br/&gt;
rename to sdks/java/harness/src/test/java/org/apache/beam/fn/harness/stream/HarnessStreamObserverFactoriesTest.java&lt;br/&gt;
index f80e8c484b2..22d9fcb79bc 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/stream/StreamObserverFactoryTest.java&lt;br/&gt;
+++ b/sdks/java/harness/src/test/java/org/apache/beam/fn/harness/stream/HarnessStreamObserverFactoriesTest.java&lt;br/&gt;
@@ -35,9 +35,9 @@&lt;br/&gt;
 import org.mockito.Mock;&lt;br/&gt;
 import org.mockito.MockitoAnnotations;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-/** Tests for &lt;/p&gt;
{@link StreamObserverFactory}
&lt;p&gt;. */&lt;br/&gt;
+/** Tests for &lt;/p&gt;
{@link HarnessStreamObserverFactoriesTest}
&lt;p&gt;. */&lt;br/&gt;
 @RunWith(JUnit4.class)&lt;br/&gt;
-public class StreamObserverFactoryTest {&lt;br/&gt;
+public class HarnessStreamObserverFactoriesTest {&lt;br/&gt;
   @Mock private StreamObserver&amp;lt;Integer&amp;gt; mockRequestObserver;&lt;br/&gt;
   @Mock private CallStreamObserver&amp;lt;String&amp;gt; mockResponseObserver;&lt;/p&gt;

&lt;p&gt;@@ -49,7 +49,7 @@ public void setUp() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testDefaultInstantiation() &lt;/p&gt;
{
     StreamObserver&amp;lt;String&amp;gt; observer =
-        StreamObserverFactory.fromOptions(PipelineOptionsFactory.create())
+        HarnessStreamObserverFactories.fromOptions(PipelineOptionsFactory.create())
             .from(this::fakeFactory, mockRequestObserver);
     assertThat(observer, instanceOf(DirectStreamObserver.class));
   }
&lt;p&gt;@@ -57,7 +57,7 @@ public void testDefaultInstantiation() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testBufferedStreamInstantiation() {&lt;br/&gt;
     StreamObserver&amp;lt;String&amp;gt; observer =&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;StreamObserverFactory.fromOptions(&lt;br/&gt;
+        HarnessStreamObserverFactories.fromOptions(&lt;br/&gt;
                 PipelineOptionsFactory.fromArgs(&lt;br/&gt;
                         new String[] 
{&quot;--experiments=beam_fn_api_buffered_stream&quot;}
&lt;p&gt;)&lt;br/&gt;
                     .create())&lt;br/&gt;
@@ -68,11 +68,11 @@ public void testBufferedStreamInstantiation() {&lt;br/&gt;
   @Test&lt;br/&gt;
   public void testBufferedStreamWithLimitInstantiation() {&lt;br/&gt;
     StreamObserver&amp;lt;String&amp;gt; observer =&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;StreamObserverFactory.fromOptions(&lt;br/&gt;
+        HarnessStreamObserverFactories.fromOptions(&lt;br/&gt;
                 PipelineOptionsFactory.fromArgs(&lt;br/&gt;
                         new String[] 
{
                           &quot;--experiments=beam_fn_api_buffered_stream,&quot;
-                          + &quot;beam_fn_api_buffered_stream_buffer_size=1&quot;
+                              + &quot;beam_fn_api_buffered_stream_buffer_size=1&quot;
                         }
&lt;p&gt;)&lt;br/&gt;
                     .create())&lt;br/&gt;
             .from(this::fakeFactory, mockRequestObserver);&lt;br/&gt;
diff --git a/sdks/java/io/common/src/test/java/org/apache/beam/sdk/io/common/IOTestPipelineOptions.java b/sdks/java/io/common/src/test/java/org/apache/beam/sdk/io/common/IOTestPipelineOptions.java&lt;br/&gt;
index 5a29d4f8126..e7b475d4caa 100644&lt;/p&gt;
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/io/common/src/test/java/org/apache/beam/sdk/io/common/IOTestPipelineOptions.java&lt;br/&gt;
+++ b/sdks/java/io/common/src/test/java/org/apache/beam/sdk/io/common/IOTestPipelineOptions.java&lt;br/&gt;
@@ -19,6 +19,7 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; import org.apache.beam.sdk.options.Default;&lt;br/&gt;
 import org.apache.beam.sdk.options.Description;&lt;br/&gt;
+import org.apache.beam.sdk.options.Validation;&lt;br/&gt;
 import org.apache.beam.sdk.testing.TestPipelineOptions;&lt;/p&gt;

&lt;p&gt; /**&lt;br/&gt;
@@ -96,7 +97,7 @@&lt;br/&gt;
   void setNumberOfRecords(Long count);&lt;/p&gt;

&lt;p&gt;   @Description(&quot;Destination prefix for files generated by the test&quot;)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;@Default.String(&quot;TEXTIOIT&quot;)&lt;br/&gt;
+  @Validation.Required&lt;br/&gt;
   String getFilenamePrefix();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   void setFilenamePrefix(String prefix);&lt;br/&gt;
diff --git a/sdks/java/io/elasticsearch-tests/elasticsearch-tests-2/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTest.java b/sdks/java/io/elasticsearch-tests/elasticsearch-tests-2/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTest.java&lt;br/&gt;
index 06298cd23b6..c1e76625666 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/io/elasticsearch-tests/elasticsearch-tests-2/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTest.java&lt;br/&gt;
+++ b/sdks/java/io/elasticsearch-tests/elasticsearch-tests-2/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTest.java&lt;br/&gt;
@@ -20,11 +20,14 @@&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIO.BoundedElasticsearchSource;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIO.ConnectionConfiguration;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIO.Read;&lt;br/&gt;
+import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIOTestCommon.ACCEPTABLE_EMPTY_SPLITS_PERCENTAGE;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIOTestCommon.ES_INDEX;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIOTestCommon.ES_TYPE;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIOTestCommon.NUM_DOCS_UTESTS;&lt;br/&gt;
 import static org.apache.beam.sdk.testing.SourceTestUtils.readFromSource;&lt;br/&gt;
+import static org.hamcrest.Matchers.lessThan;&lt;br/&gt;
 import static org.junit.Assert.assertEquals;&lt;br/&gt;
+import static org.junit.Assert.assertThat;&lt;/p&gt;

&lt;p&gt; import java.io.IOException;&lt;br/&gt;
 import java.io.Serializable;&lt;br/&gt;
@@ -172,14 +175,17 @@ public void testSplit() throws Exception {&lt;br/&gt;
     SourceTestUtils.assertSourcesEqualReferenceSource(initialSource, splits, options);&lt;br/&gt;
     //this is the number of ES shards&lt;br/&gt;
     // (By default, each index in Elasticsearch is allocated 5 primary shards)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;int expectedNumSplits = 5;&lt;/li&gt;
	&lt;li&gt;assertEquals(expectedNumSplits, splits.size());&lt;/li&gt;
	&lt;li&gt;int nonEmptySplits = 0;&lt;br/&gt;
+    int expectedNumSources = 5;&lt;br/&gt;
+    assertEquals(&quot;Wrong number of splits&quot;, expectedNumSources, splits.size());&lt;br/&gt;
+    int emptySplits = 0;&lt;br/&gt;
     for (BoundedSource&amp;lt;String&amp;gt; subSource : splits) {&lt;/li&gt;
	&lt;li&gt;if (readFromSource(subSource, options).size() &amp;gt; 0) {&lt;/li&gt;
	&lt;li&gt;nonEmptySplits += 1;&lt;br/&gt;
+      if (readFromSource(subSource, options).isEmpty()) 
{
+        emptySplits += 1;
       }&lt;br/&gt;
     }&lt;br/&gt;
-    assertEquals(&quot;Wrong number of non empty splits&quot;, expectedNumSplits, nonEmptySplits);&lt;br/&gt;
+    assertThat(&lt;br/&gt;
+        &quot;There are too many empty splits, parallelism is sub-optimal&quot;,&lt;br/&gt;
+        emptySplits,&lt;br/&gt;
+        lessThan((int) (ACCEPTABLE_EMPTY_SPLITS_PERCENTAGE * splits.size())));&lt;br/&gt;
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/io/elasticsearch-tests/elasticsearch-tests-5/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTest.java b/sdks/java/io/elasticsearch-tests/elasticsearch-tests-5/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTest.java&lt;br/&gt;
index 50a87646d3d..ec81074bec7 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/io/elasticsearch-tests/elasticsearch-tests-5/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTest.java&lt;br/&gt;
+++ b/sdks/java/io/elasticsearch-tests/elasticsearch-tests-5/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTest.java&lt;br/&gt;
@@ -20,10 +20,12 @@&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIO.BoundedElasticsearchSource;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIO.ConnectionConfiguration;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIO.Read;&lt;br/&gt;
+import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIOTestCommon.ACCEPTABLE_EMPTY_SPLITS_PERCENTAGE;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIOTestCommon.ES_INDEX;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIOTestCommon.ES_TYPE;&lt;br/&gt;
 import static org.apache.beam.sdk.io.elasticsearch.ElasticsearchIOTestCommon.NUM_DOCS_UTESTS;&lt;br/&gt;
 import static org.apache.beam.sdk.testing.SourceTestUtils.readFromSource;&lt;br/&gt;
+import static org.hamcrest.Matchers.lessThan;&lt;br/&gt;
 &lt;br/&gt;
 import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;&lt;br/&gt;
 import java.io.Serializable;&lt;br/&gt;
@@ -166,20 +168,23 @@ public void testSplit() throws Exception {&lt;br/&gt;
         ElasticsearchIO.read().withConnectionConfiguration(connectionConfiguration);&lt;br/&gt;
    BoundedElasticsearchSource initialSource = new BoundedElasticsearchSource(read, null, null,&lt;br/&gt;
        null);&lt;br/&gt;
-   int desiredBundleSizeBytes = 1000;&lt;br/&gt;
+   int desiredBundleSizeBytes = 2000;&lt;br/&gt;
     List&amp;lt;? extends BoundedSource&amp;lt;String&amp;gt;&amp;gt; splits =&lt;br/&gt;
         initialSource.split(desiredBundleSizeBytes, options);&lt;br/&gt;
     SourceTestUtils.assertSourcesEqualReferenceSource(initialSource, splits, options);&lt;br/&gt;
    long indexSize = BoundedElasticsearchSource.estimateIndexSize(connectionConfiguration);&lt;br/&gt;
    float expectedNumSourcesFloat = (float) indexSize / desiredBundleSizeBytes;&lt;br/&gt;
    int expectedNumSources = (int) Math.ceil(expectedNumSourcesFloat);&lt;br/&gt;
-   assertEquals(expectedNumSources, splits.size());&lt;br/&gt;
-    int nonEmptySplits = 0;&lt;br/&gt;
+   assertEquals(&quot;Wrong number of splits&quot;, expectedNumSources, splits.size());&lt;br/&gt;
+    int emptySplits = 0;&lt;br/&gt;
     for (BoundedSource&amp;lt;String&amp;gt; subSource : splits) {&lt;br/&gt;
-      if (readFromSource(subSource, options).size() &amp;gt; 0) {&lt;br/&gt;
-        nonEmptySplits += 1;&lt;br/&gt;
+      if (readFromSource(subSource, options).isEmpty()) {+        emptySplits += 1;       }
&lt;p&gt;     }&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;assertEquals(&quot;Wrong number of non empty splits&quot;, expectedNumSources, nonEmptySplits);&lt;br/&gt;
+    assertThat(&lt;br/&gt;
+        &quot;There are too many empty splits, parallelism is sub-optimal&quot;,&lt;br/&gt;
+        emptySplits,&lt;br/&gt;
+        lessThan((int) (ACCEPTABLE_EMPTY_SPLITS_PERCENTAGE * splits.size())));&lt;br/&gt;
   }&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/io/elasticsearch-tests/elasticsearch-tests-common/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTestCommon.java b/sdks/java/io/elasticsearch-tests/elasticsearch-tests-common/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTestCommon.java&lt;br/&gt;
index 03eaf005da9..55d1fe712e6 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/java/io/elasticsearch-tests/elasticsearch-tests-common/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTestCommon.java&lt;br/&gt;
+++ b/sdks/java/io/elasticsearch-tests/elasticsearch-tests-common/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOTestCommon.java&lt;br/&gt;
@@ -59,6 +59,7 @@&lt;br/&gt;
   static final String ES_TYPE = &quot;test&quot;;&lt;br/&gt;
   static final long NUM_DOCS_UTESTS = 400L;&lt;br/&gt;
   static final long NUM_DOCS_ITESTS = 50000L;&lt;br/&gt;
+  static final float ACCEPTABLE_EMPTY_SPLITS_PERCENTAGE = 0.5f;&lt;br/&gt;
   private static final long AVERAGE_DOC_SIZE = 25L;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;diff --git a/sdks/java/io/file-based-io-tests/pom.xml b/sdks/java/io/file-based-io-tests/pom.xml&lt;br/&gt;
index 6c3a7e3718b..44119ec79ff 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/io/file-based-io-tests/pom.xml&lt;br/&gt;
+++ b/sdks/java/io/file-based-io-tests/pom.xml&lt;br/&gt;
@@ -124,6 +124,11 @@&lt;br/&gt;
                                 &amp;lt;argument&amp;gt;-beam_it_class=${fileBasedIoItClass}&amp;lt;/argument&amp;gt;&lt;br/&gt;
                                 &amp;lt;!-- arguments typically defined by user --&amp;gt;&lt;br/&gt;
                                 &amp;lt;argument&amp;gt;-beam_it_options=${integrationTestPipelineOptions}&amp;lt;/argument&amp;gt;&lt;br/&gt;
+                                &amp;lt;!--&lt;br/&gt;
+                                optional array of key=value items. It will be passed to&lt;br/&gt;
+                                target mvn command by pkb. eg. -DpkbExtraProperties=&apos;&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;quot;filesystem=local&amp;quot;&amp;#93;&lt;/span&gt;&apos;&lt;br/&gt;
+                                --&amp;gt;&lt;br/&gt;
+                                &amp;lt;argument&amp;gt;-beam_extra_mvn_properties=${pkbExtraProperties}&amp;lt;/argument&amp;gt;&lt;br/&gt;
                             &amp;lt;/arguments&amp;gt;&lt;br/&gt;
                         &amp;lt;/configuration&amp;gt;&lt;br/&gt;
                     &amp;lt;/plugin&amp;gt;&lt;br/&gt;
@@ -139,6 +144,24 @@&lt;br/&gt;
                 &amp;lt;/plugins&amp;gt;&lt;br/&gt;
             &amp;lt;/build&amp;gt;&lt;br/&gt;
         &amp;lt;/profile&amp;gt;&lt;br/&gt;
+        &amp;lt;profile&amp;gt;&lt;br/&gt;
+            &amp;lt;!-- Include the google-cloud-platform activated by -Dfilesystem=gcs&lt;br/&gt;
+            Support for protocol scheme gs:// - allow to read/write to google storage --&amp;gt;&lt;br/&gt;
+            &amp;lt;id&amp;gt;google-cloud-storage&amp;lt;/id&amp;gt;&lt;br/&gt;
+            &amp;lt;activation&amp;gt;&lt;br/&gt;
+                &amp;lt;property&amp;gt;&lt;br/&gt;
+                    &amp;lt;name&amp;gt;filesystem&amp;lt;/name&amp;gt;&lt;br/&gt;
+                    &amp;lt;value&amp;gt;gcs&amp;lt;/value&amp;gt;&lt;br/&gt;
+                &amp;lt;/property&amp;gt;&lt;br/&gt;
+            &amp;lt;/activation&amp;gt;&lt;br/&gt;
+            &amp;lt;dependencies&amp;gt;&lt;br/&gt;
+                &amp;lt;dependency&amp;gt;&lt;br/&gt;
+                    &amp;lt;groupId&amp;gt;org.apache.beam&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+                    &amp;lt;artifactId&amp;gt;beam-sdks-java-io-google-cloud-platform&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+                    &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt;&lt;br/&gt;
+                &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+            &amp;lt;/dependencies&amp;gt;&lt;br/&gt;
+        &amp;lt;/profile&amp;gt;&lt;br/&gt;
     &amp;lt;/profiles&amp;gt;&lt;/p&gt;

&lt;p&gt;     &amp;lt;dependencies&amp;gt;&lt;br/&gt;
@@ -178,5 +201,11 @@&lt;br/&gt;
             &amp;lt;artifactId&amp;gt;beam-sdks-java-io-common&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
             &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
         &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+        &amp;lt;dependency&amp;gt;&lt;br/&gt;
+            &amp;lt;groupId&amp;gt;org.apache.avro&amp;lt;/groupId&amp;gt;&lt;br/&gt;
+            &amp;lt;artifactId&amp;gt;avro&amp;lt;/artifactId&amp;gt;&lt;br/&gt;
+            &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;&lt;br/&gt;
+        &amp;lt;/dependency&amp;gt;&lt;br/&gt;
+&lt;br/&gt;
     &amp;lt;/dependencies&amp;gt;&lt;br/&gt;
 &amp;lt;/project&amp;gt;&lt;br/&gt;
diff --git a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/avro/AvroIOIT.java b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/avro/AvroIOIT.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..ce8da3357c9&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/avro/AvroIOIT.java&lt;br/&gt;
@@ -0,0 +1,137 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+package org.apache.beam.sdk.io.avro;&lt;br/&gt;
+&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.appendTimestampToPrefix;&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.getExpectedHashForLineCount;&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.readTestPipelineOptions;&lt;br/&gt;
+&lt;br/&gt;
+import org.apache.avro.Schema;&lt;br/&gt;
+import org.apache.avro.generic.GenericRecord;&lt;br/&gt;
+import org.apache.avro.generic.GenericRecordBuilder;&lt;br/&gt;
+import org.apache.beam.sdk.coders.AvroCoder;&lt;br/&gt;
+import org.apache.beam.sdk.io.AvroIO;&lt;br/&gt;
+import org.apache.beam.sdk.io.GenerateSequence;&lt;br/&gt;
+import org.apache.beam.sdk.io.common.FileBasedIOITHelper;&lt;br/&gt;
+import org.apache.beam.sdk.io.common.HashingFn;&lt;br/&gt;
+import org.apache.beam.sdk.io.common.IOTestPipelineOptions;&lt;br/&gt;
+import org.apache.beam.sdk.testing.PAssert;&lt;br/&gt;
+import org.apache.beam.sdk.testing.TestPipeline;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Combine;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.DoFn;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.ParDo;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Values;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.View;&lt;br/&gt;
+import org.apache.beam.sdk.values.PCollection;&lt;br/&gt;
+import org.junit.BeforeClass;&lt;br/&gt;
+import org.junit.Rule;&lt;br/&gt;
+import org.junit.Test;&lt;br/&gt;
+import org.junit.runner.RunWith;&lt;br/&gt;
+import org.junit.runners.JUnit4;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * An integration test for &lt;/p&gt;
{@link AvroIO}
&lt;p&gt;.&lt;br/&gt;
+ *&lt;br/&gt;
+ * &amp;lt;p&amp;gt;Run this test using the command below. Pass in connection information via PipelineOptions:&lt;br/&gt;
+ * &amp;lt;pre&amp;gt;&lt;br/&gt;
+ *  mvn -e -Pio-it verify -pl sdks/java/io/file-based-io-tests&lt;br/&gt;
+ *  -Dit.test=org.apache.beam.sdk.io.avro.AvroIOIT&lt;br/&gt;
+ *  -DintegrationTestPipelineOptions=&apos;[&lt;br/&gt;
+ *  &quot;--numberOfRecords=100000&quot;,&lt;br/&gt;
+ *  &quot;--filenamePrefix=output_file_path&quot;&lt;br/&gt;
+ *  ]&apos;&lt;br/&gt;
+ * &amp;lt;/pre&amp;gt;&lt;br/&gt;
+ * &amp;lt;/p&amp;gt;&lt;br/&gt;
+ * &amp;lt;p&amp;gt;Please see &apos;sdks/java/io/file-based-io-tests/pom.xml&apos; for instructions regarding&lt;br/&gt;
+ * running this test using Beam performance testing framework.&amp;lt;/p&amp;gt;&lt;br/&gt;
+ */&lt;br/&gt;
+@RunWith(JUnit4.class)&lt;br/&gt;
+public class AvroIOIT {&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+  private static final Schema AVRO_SCHEMA = new Schema.Parser().parse(&quot;{\n&quot;&lt;br/&gt;
+      + &quot; \&quot;namespace\&quot;: \&quot;ioitavro\&quot;,\n&quot;&lt;br/&gt;
+      + &quot; \&quot;type\&quot;: \&quot;record\&quot;,\n&quot;&lt;br/&gt;
+      + &quot; \&quot;name\&quot;: \&quot;TestAvroLine\&quot;,\n&quot;&lt;br/&gt;
+      + &quot; \&quot;fields\&quot;: [\n&quot;&lt;br/&gt;
+      + &quot;     &lt;/p&gt;
{\&quot;name\&quot;: \&quot;row\&quot;, \&quot;type\&quot;: \&quot;string\&quot;}
&lt;p&gt;\n&quot;&lt;br/&gt;
+      + &quot; ]\n&quot;&lt;br/&gt;
+      + &quot;}&quot;);&lt;br/&gt;
+&lt;br/&gt;
+  private static String filenamePrefix;&lt;br/&gt;
+  private static Long numberOfTextLines;&lt;br/&gt;
+&lt;br/&gt;
+  @Rule&lt;br/&gt;
+  public TestPipeline pipeline = TestPipeline.create();&lt;br/&gt;
+&lt;br/&gt;
+  @BeforeClass&lt;br/&gt;
+  public static void setup() &lt;/p&gt;
{
+    IOTestPipelineOptions options = readTestPipelineOptions();
+
+    numberOfTextLines = options.getNumberOfRecords();
+    filenamePrefix = appendTimestampToPrefix(options.getFilenamePrefix());
+  }
&lt;p&gt;+&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void writeThenReadAll() &lt;/p&gt;
{
+
+    PCollection&amp;lt;String&amp;gt; testFilenames = pipeline
+        .apply(&quot;Generate sequence&quot;, GenerateSequence.from(0).to(numberOfTextLines))
+        .apply(&quot;Produce text lines&quot;,
+            ParDo.of(new FileBasedIOITHelper.DeterministicallyConstructTestTextLineFn()))
+        .apply(
+            &quot;Produce Avro records&quot;,
+            ParDo.of(new DeterministicallyConstructAvroRecordsFn()))
+        .setCoder(AvroCoder.of(AVRO_SCHEMA))
+        .apply(
+            &quot;Write Avro records to files&quot;,
+            AvroIO.writeGenericRecords(AVRO_SCHEMA).to(filenamePrefix)
+                .withOutputFilenames().withSuffix(&quot;.avro&quot;))
+        .getPerDestinationOutputFilenames().apply(Values.&amp;lt;String&amp;gt;create());
+
+    PCollection&amp;lt;String&amp;gt; consolidatedHashcode = testFilenames
+        .apply(&quot;Read all files&quot;, AvroIO.readAllGenericRecords(AVRO_SCHEMA))
+        .apply(&quot;Parse Avro records to Strings&quot;, ParDo.of(new ParseAvroRecordsFn()))
+        .apply(&quot;Calculate hashcode&quot;, Combine.globally(new HashingFn()));
+
+    String expectedHash = getExpectedHashForLineCount(numberOfTextLines);
+    PAssert.thatSingleton(consolidatedHashcode).isEqualTo(expectedHash);
+
+    testFilenames.apply(&quot;Delete test files&quot;, ParDo.of(new FileBasedIOITHelper.DeleteFileFn())
+        .withSideInputs(consolidatedHashcode.apply(View.&amp;lt;String&amp;gt;asSingleton())));
+
+    pipeline.run().waitUntilFinish();
+  }
&lt;p&gt;+&lt;br/&gt;
+  private static class DeterministicallyConstructAvroRecordsFn extends DoFn&amp;lt;String, GenericRecord&amp;gt; {&lt;br/&gt;
+    @ProcessElement&lt;br/&gt;
+    public void processElement(ProcessContext c)&lt;/p&gt;
{
+      c.output(
+          new GenericRecordBuilder(AVRO_SCHEMA).set(&quot;row&quot;, c.element()).build()
+      );
+    }
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
+  private static class ParseAvroRecordsFn extends DoFn&amp;lt;GenericRecord, String&amp;gt; {&lt;br/&gt;
+    @ProcessElement&lt;br/&gt;
+    public void processElement(ProcessContext c)&lt;/p&gt;
{
+      c.output(String.valueOf(c.element().get(&quot;row&quot;)));
+    }
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/common/FileBasedIOITHelper.java b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/common/FileBasedIOITHelper.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..cf20d8e5954&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/common/FileBasedIOITHelper.java&lt;br/&gt;
@@ -0,0 +1,103 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.beam.sdk.io.common;&lt;br/&gt;
+&lt;br/&gt;
+import com.google.common.collect.ImmutableMap;&lt;br/&gt;
+import com.google.common.collect.Iterables;&lt;br/&gt;
+import java.io.IOException;&lt;br/&gt;
+import java.util.Collections;&lt;br/&gt;
+import java.util.Date;&lt;br/&gt;
+import java.util.HashSet;&lt;br/&gt;
+import java.util.Map;&lt;br/&gt;
+import java.util.Set;&lt;br/&gt;
+import org.apache.beam.sdk.io.FileSystems;&lt;br/&gt;
+import org.apache.beam.sdk.io.fs.MatchResult;&lt;br/&gt;
+import org.apache.beam.sdk.io.fs.ResourceId;&lt;br/&gt;
+import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
+import org.apache.beam.sdk.options.PipelineOptionsValidator;&lt;br/&gt;
+import org.apache.beam.sdk.testing.TestPipeline;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.DoFn;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Contains helper methods for file based IO Integration tests.&lt;br/&gt;
+ */&lt;br/&gt;
+public class FileBasedIOITHelper {&lt;br/&gt;
+&lt;br/&gt;
+  private FileBasedIOITHelper() &lt;/p&gt;
{
+  }
&lt;p&gt;+&lt;br/&gt;
+  public static IOTestPipelineOptions readTestPipelineOptions() &lt;/p&gt;
{
+    PipelineOptionsFactory.register(IOTestPipelineOptions.class);
+    IOTestPipelineOptions options = TestPipeline
+        .testingPipelineOptions()
+        .as(IOTestPipelineOptions.class);
+
+    return PipelineOptionsValidator.validate(IOTestPipelineOptions.class, options);
+  }
&lt;p&gt;+&lt;br/&gt;
+  public static String appendTimestampToPrefix(String filenamePrefix) &lt;/p&gt;
{
+    return String.format(&quot;%s_%s&quot;, filenamePrefix, new Date().getTime());
+  }
&lt;p&gt;+&lt;br/&gt;
+  public static String getExpectedHashForLineCount(Long lineCount) {&lt;br/&gt;
+    Map&amp;lt;Long, String&amp;gt; expectedHashes = ImmutableMap.of(&lt;br/&gt;
+        100_000L, &quot;4c8bb3b99dcc59459b20fefba400d446&quot;,&lt;br/&gt;
+        1_000_000L, &quot;9796db06e7a7960f974d5a91164afff1&quot;,&lt;br/&gt;
+        100_000_000L, &quot;6ce05f456e2fdc846ded2abd0ec1de95&quot;&lt;br/&gt;
+    );&lt;br/&gt;
+&lt;br/&gt;
+    String hash = expectedHashes.get(lineCount);&lt;br/&gt;
+    if (hash == null) &lt;/p&gt;
{
+      throw new UnsupportedOperationException(
+          String.format(&quot;No hash for that line count: %s&quot;, lineCount)
+      );
+    }
&lt;p&gt;+    return hash;&lt;br/&gt;
+  }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Constructs text lines in files used for testing.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static class DeterministicallyConstructTestTextLineFn extends DoFn&amp;lt;Long, String&amp;gt; {&lt;br/&gt;
+&lt;br/&gt;
+    @ProcessElement&lt;br/&gt;
+    public void processElement(ProcessContext c) &lt;/p&gt;
{
+      c.output(String.format(&quot;IO IT Test line of text. Line seed: %s&quot;, c.element()));
+    }
&lt;p&gt;+  }&lt;br/&gt;
+&lt;br/&gt;
+  /**&lt;br/&gt;
+   * Deletes matching files using the FileSystems API.&lt;br/&gt;
+   */&lt;br/&gt;
+  public static class DeleteFileFn extends DoFn&amp;lt;String, Void&amp;gt; {&lt;br/&gt;
+&lt;br/&gt;
+    @ProcessElement&lt;br/&gt;
+    public void processElement(ProcessContext c) throws IOException {&lt;br/&gt;
+      MatchResult match = Iterables&lt;br/&gt;
+          .getOnlyElement(FileSystems.match(Collections.singletonList(c.element())));&lt;br/&gt;
+&lt;br/&gt;
+      Set&amp;lt;ResourceId&amp;gt; resourceIds = new HashSet&amp;lt;&amp;gt;();&lt;br/&gt;
+      for (MatchResult.Metadata metadataElem : match.metadata()) &lt;/p&gt;
{
+        resourceIds.add(metadataElem.resourceId());
+      }
&lt;p&gt;+&lt;br/&gt;
+      FileSystems.delete(resourceIds);&lt;br/&gt;
+    }&lt;br/&gt;
+  }&lt;br/&gt;
+}&lt;br/&gt;
diff --git a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/text/TextIOIT.java b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/text/TextIOIT.java&lt;br/&gt;
index e9aac8001b1..1a4ecccc0ef 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/text/TextIOIT.java&lt;br/&gt;
+++ b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/text/TextIOIT.java&lt;br/&gt;
@@ -19,33 +19,22 @@&lt;br/&gt;
 package org.apache.beam.sdk.io.text;&lt;/p&gt;

&lt;p&gt; import static org.apache.beam.sdk.io.Compression.AUTO;&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.appendTimestampToPrefix;&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.getExpectedHashForLineCount;&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.readTestPipelineOptions;&lt;/p&gt;

&lt;p&gt;-import com.google.common.base.Function;&lt;br/&gt;
-import com.google.common.collect.FluentIterable;&lt;br/&gt;
-import com.google.common.collect.ImmutableMap;&lt;br/&gt;
-import com.google.common.collect.Iterables;&lt;br/&gt;
-&lt;br/&gt;
-import java.io.IOException;&lt;br/&gt;
 import java.text.ParseException;&lt;br/&gt;
-import java.util.Collection;&lt;br/&gt;
-import java.util.Collections;&lt;br/&gt;
-import java.util.Date;&lt;br/&gt;
-import java.util.Map;&lt;br/&gt;
-&lt;br/&gt;
 import org.apache.beam.sdk.io.Compression;&lt;br/&gt;
-import org.apache.beam.sdk.io.FileSystems;&lt;br/&gt;
 import org.apache.beam.sdk.io.GenerateSequence;&lt;br/&gt;
 import org.apache.beam.sdk.io.TextIO;&lt;br/&gt;
+import org.apache.beam.sdk.io.common.FileBasedIOITHelper;&lt;br/&gt;
 import org.apache.beam.sdk.io.common.HashingFn;&lt;br/&gt;
 import org.apache.beam.sdk.io.common.IOTestPipelineOptions;&lt;br/&gt;
-import org.apache.beam.sdk.io.fs.MatchResult;&lt;br/&gt;
-import org.apache.beam.sdk.io.fs.ResourceId;&lt;br/&gt;
-import org.apache.beam.sdk.options.PipelineOptionsFactory;&lt;br/&gt;
 import org.apache.beam.sdk.testing.PAssert;&lt;br/&gt;
 import org.apache.beam.sdk.testing.TestPipeline;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Combine;&lt;br/&gt;
-import org.apache.beam.sdk.transforms.DoFn;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.ParDo;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Reshuffle;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.Values;&lt;br/&gt;
 import org.apache.beam.sdk.transforms.View;&lt;br/&gt;
 import org.apache.beam.sdk.values.PCollection;&lt;br/&gt;
@@ -64,14 +53,14 @@&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;-Dit.test=org.apache.beam.sdk.io.text.TextIOIT&lt;/li&gt;
	&lt;li&gt;-DintegrationTestPipelineOptions=&apos;[&lt;/li&gt;
	&lt;li&gt;&quot;--numberOfRecords=100000&quot;,&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;*  &quot;--filenamePrefix=TEXTIOIT&quot;&lt;br/&gt;
+ *  &quot;--filenamePrefix=output_file_path&quot;,&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;&quot;--compressionType=GZIP&quot;&lt;/li&gt;
	&lt;li&gt;]&apos;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/pre&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;/p&amp;gt;&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;Please see &apos;sdks/java/io/file-based-io-tests/pom.xml&apos; for instructions regarding&lt;/li&gt;
	&lt;li&gt;running this test using Beam performance testing framework.&amp;lt;/p&amp;gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* */&lt;br/&gt;
+ */&lt;br/&gt;
 @RunWith(JUnit4.class)&lt;br/&gt;
 public class TextIOIT {&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -84,26 +73,11 @@&lt;/p&gt;

&lt;p&gt;   @BeforeClass&lt;br/&gt;
   public static void setup() throws ParseException &lt;/p&gt;
{
-    PipelineOptionsFactory.register(IOTestPipelineOptions.class);
-    IOTestPipelineOptions options = TestPipeline.testingPipelineOptions()
-        .as(IOTestPipelineOptions.class);
+    IOTestPipelineOptions options = readTestPipelineOptions();
 
     numberOfTextLines = options.getNumberOfRecords();
-    filenamePrefix = appendTimestamp(options.getFilenamePrefix());
-    compressionType = parseCompressionType(options.getCompressionType());
-  }
&lt;p&gt;-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static Compression parseCompressionType(String compressionType) {&lt;/li&gt;
	&lt;li&gt;try 
{
-      return Compression.valueOf(compressionType.toUpperCase());
-    }
&lt;p&gt; catch (IllegalArgumentException ex) &lt;/p&gt;
{
-      throw new IllegalArgumentException(
-          String.format(&quot;Unsupported compression type: %s&quot;, compressionType));
-    }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private static String appendTimestamp(String filenamePrefix) 
{
-    return String.format(&quot;%s_%s&quot;, filenamePrefix, new Date().getTime());
+    filenamePrefix = appendTimestampToPrefix(options.getFilenamePrefix());
+    compressionType = Compression.valueOf(options.getCompressionType());
   }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @Test&lt;br/&gt;
@@ -116,9 +90,11 @@ public void writeThenReadAll() {&lt;/p&gt;

&lt;p&gt;     PCollection&amp;lt;String&amp;gt; testFilenames = pipeline&lt;br/&gt;
         .apply(&quot;Generate sequence&quot;, GenerateSequence.from(0).to(numberOfTextLines))&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;.apply(&quot;Produce text lines&quot;, ParDo.of(new DeterministicallyConstructTestTextLineFn()))&lt;br/&gt;
+        .apply(&quot;Produce text lines&quot;,&lt;br/&gt;
+            ParDo.of(new FileBasedIOITHelper.DeterministicallyConstructTestTextLineFn()))&lt;br/&gt;
         .apply(&quot;Write content to files&quot;, write)&lt;/li&gt;
	&lt;li&gt;.getPerDestinationOutputFilenames().apply(Values.&amp;lt;String&amp;gt;create());&lt;br/&gt;
+        .getPerDestinationOutputFilenames().apply(Values.&amp;lt;String&amp;gt;create())&lt;br/&gt;
+        .apply(Reshuffle.&amp;lt;String&amp;gt;viaRandomKey());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     PCollection&amp;lt;String&amp;gt; consolidatedHashcode = testFilenames&lt;br/&gt;
         .apply(&quot;Read all files&quot;, TextIO.readAll().withCompression(AUTO))&lt;br/&gt;
@@ -127,53 +103,9 @@ public void writeThenReadAll() &lt;/p&gt;
{
     String expectedHash = getExpectedHashForLineCount(numberOfTextLines);
     PAssert.thatSingleton(consolidatedHashcode).isEqualTo(expectedHash);
 
-    testFilenames.apply(&quot;Delete test files&quot;, ParDo.of(new DeleteFileFn())
+    testFilenames.apply(&quot;Delete test files&quot;, ParDo.of(new FileBasedIOITHelper.DeleteFileFn())
         .withSideInputs(consolidatedHashcode.apply(View.&amp;lt;String&amp;gt;asSingleton())));
 
     pipeline.run().waitUntilFinish();
   }
&lt;p&gt;-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;private static String getExpectedHashForLineCount(Long lineCount) {&lt;/li&gt;
	&lt;li&gt;Map&amp;lt;Long, String&amp;gt; expectedHashes = ImmutableMap.of(&lt;/li&gt;
	&lt;li&gt;100_000L, &quot;4c8bb3b99dcc59459b20fefba400d446&quot;,&lt;/li&gt;
	&lt;li&gt;1_000_000L, &quot;9796db06e7a7960f974d5a91164afff1&quot;,&lt;/li&gt;
	&lt;li&gt;100_000_000L, &quot;6ce05f456e2fdc846ded2abd0ec1de95&quot;&lt;/li&gt;
	&lt;li&gt;);&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;String hash = expectedHashes.get(lineCount);&lt;/li&gt;
	&lt;li&gt;if (hash == null) 
{
-      throw new UnsupportedOperationException(
-          String.format(&quot;No hash for that line count: %s&quot;, lineCount));
-    }&lt;/li&gt;
	&lt;li&gt;return hash;&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private static class DeterministicallyConstructTestTextLineFn extends DoFn&amp;lt;Long, String&amp;gt; {&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@ProcessElement&lt;/li&gt;
	&lt;li&gt;public void processElement(ProcessContext c) 
{
-      c.output(String.format(&quot;IO IT Test line of text. Line seed: %s&quot;, c.element()));
-    }&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;private static class DeleteFileFn extends DoFn&amp;lt;String, Void&amp;gt; {&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@ProcessElement&lt;/li&gt;
	&lt;li&gt;public void processElement(ProcessContext c) throws IOException 
{
-      MatchResult match = Iterables
-          .getOnlyElement(FileSystems.match(Collections.singletonList(c.element())));
-      FileSystems.delete(toResourceIds(match));
-    }
&lt;p&gt;-&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;private Collection&amp;lt;ResourceId&amp;gt; toResourceIds(MatchResult match) throws IOException {&lt;/li&gt;
	&lt;li&gt;return FluentIterable.from(match.metadata())&lt;/li&gt;
	&lt;li&gt;.transform(new Function&amp;lt;MatchResult.Metadata, ResourceId&amp;gt;() {&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@Override&lt;/li&gt;
	&lt;li&gt;public ResourceId apply(MatchResult.Metadata metadata) 
{
-              return metadata.resourceId();
-            }&lt;/li&gt;
	&lt;li&gt;}).toList();&lt;/li&gt;
	&lt;li&gt;}&lt;/li&gt;
	&lt;li&gt;}&lt;br/&gt;
 }&lt;br/&gt;
diff --git a/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/tfrecord/TFRecordIOIT.java b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/tfrecord/TFRecordIOIT.java&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..b887316b187
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;/dev/null&lt;br/&gt;
+++ b/sdks/java/io/file-based-io-tests/src/test/java/org/apache/beam/sdk/io/tfrecord/TFRecordIOIT.java&lt;br/&gt;
@@ -0,0 +1,137 @@&lt;br/&gt;
+/*&lt;br/&gt;
+ * Licensed to the Apache Software Foundation (ASF) under one&lt;br/&gt;
+ * or more contributor license agreements.  See the NOTICE file&lt;br/&gt;
+ * distributed with this work for additional information&lt;br/&gt;
+ * regarding copyright ownership.  The ASF licenses this file&lt;br/&gt;
+ * to you under the Apache License, Version 2.0 (the&lt;br/&gt;
+ * &quot;License&quot;); you may not use this file except in compliance&lt;br/&gt;
+ * with the License.  You may obtain a copy of the License at&lt;br/&gt;
+ *&lt;br/&gt;
+ *     &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+ *&lt;br/&gt;
+ * Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+ * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+ * See the License for the specific language governing permissions and&lt;br/&gt;
+ * limitations under the License.&lt;br/&gt;
+ */&lt;br/&gt;
+&lt;br/&gt;
+package org.apache.beam.sdk.io.tfrecord;&lt;br/&gt;
+&lt;br/&gt;
+import static org.apache.beam.sdk.io.Compression.AUTO;&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.appendTimestampToPrefix;&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.getExpectedHashForLineCount;&lt;br/&gt;
+import static org.apache.beam.sdk.io.common.FileBasedIOITHelper.readTestPipelineOptions;&lt;br/&gt;
+&lt;br/&gt;
+import java.text.ParseException;&lt;br/&gt;
+import org.apache.beam.sdk.io.Compression;&lt;br/&gt;
+import org.apache.beam.sdk.io.GenerateSequence;&lt;br/&gt;
+import org.apache.beam.sdk.io.TFRecordIO;&lt;br/&gt;
+import org.apache.beam.sdk.io.common.FileBasedIOITHelper;&lt;br/&gt;
+import org.apache.beam.sdk.io.common.HashingFn;&lt;br/&gt;
+import org.apache.beam.sdk.io.common.IOTestPipelineOptions;&lt;br/&gt;
+import org.apache.beam.sdk.testing.PAssert;&lt;br/&gt;
+import org.apache.beam.sdk.testing.TestPipeline;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Combine;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.Create;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.MapElements;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.ParDo;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.SimpleFunction;&lt;br/&gt;
+import org.apache.beam.sdk.transforms.View;&lt;br/&gt;
+import org.apache.beam.sdk.values.PCollection;&lt;br/&gt;
+import org.junit.BeforeClass;&lt;br/&gt;
+import org.junit.Rule;&lt;br/&gt;
+import org.junit.Test;&lt;br/&gt;
+import org.junit.runner.RunWith;&lt;br/&gt;
+import org.junit.runners.JUnit4;&lt;br/&gt;
+&lt;br/&gt;
+/**&lt;br/&gt;
+ * Integration tests for 
{@link org.apache.beam.sdk.io.TFRecordIO}
&lt;p&gt;.&lt;br/&gt;
+ *&lt;br/&gt;
+ * &amp;lt;p&amp;gt;Run this test using the command below. Pass in connection information via PipelineOptions:&lt;br/&gt;
+ * &amp;lt;pre&amp;gt;&lt;br/&gt;
+ *  mvn -e -Pio-it verify -pl sdks/java/io/file-based-io-tests&lt;br/&gt;
+ *  -Dit.test=org.apache.beam.sdk.io.tfrecord.TFRecordIOIT&lt;br/&gt;
+ *  -DintegrationTestPipelineOptions=&apos;[&lt;br/&gt;
+ *  &quot;--numberOfRecords=100000&quot;,&lt;br/&gt;
+ *  &quot;--filenamePrefix=output_file_path&quot;,&lt;br/&gt;
+ *  &quot;--compressionType=GZIP&quot;&lt;br/&gt;
+ *  ]&apos;&lt;br/&gt;
+ * &amp;lt;/pre&amp;gt;&lt;br/&gt;
+ * &amp;lt;/p&amp;gt;&lt;br/&gt;
+ * &amp;lt;p&amp;gt;Please &lt;/p&gt;
{@see &apos;sdks/java/io/file-based-io-tests/pom.xml&apos;}
&lt;p&gt; for instructions regarding&lt;br/&gt;
+ * running this test using Beam performance testing framework.&amp;lt;/p&amp;gt;&lt;br/&gt;
+ */&lt;br/&gt;
+@RunWith(JUnit4.class)&lt;br/&gt;
+public class TFRecordIOIT {&lt;br/&gt;
+&lt;br/&gt;
+  private static String filenamePrefix;&lt;br/&gt;
+  private static Long numberOfTextLines;&lt;br/&gt;
+  private static Compression compressionType;&lt;br/&gt;
+&lt;br/&gt;
+  @Rule&lt;br/&gt;
+  public TestPipeline writePipeline = TestPipeline.create();&lt;br/&gt;
+&lt;br/&gt;
+  @Rule&lt;br/&gt;
+  public TestPipeline readPipeline = TestPipeline.create();&lt;br/&gt;
+&lt;br/&gt;
+  @BeforeClass&lt;br/&gt;
+  public static void setup() throws ParseException &lt;/p&gt;
{
+    IOTestPipelineOptions options = readTestPipelineOptions();
+
+    numberOfTextLines = options.getNumberOfRecords();
+    filenamePrefix = appendTimestampToPrefix(options.getFilenamePrefix());
+    compressionType = Compression.valueOf(options.getCompressionType());
+  }
&lt;p&gt;+&lt;br/&gt;
+  private static String createFilenamePattern() &lt;/p&gt;
{
+    return filenamePrefix + &quot;*&quot;;
+  }
&lt;p&gt;+&lt;br/&gt;
+  // TODO: There are two pipelines due to: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3267&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/BEAM-3267&lt;/a&gt;&lt;br/&gt;
+  @Test&lt;br/&gt;
+  public void writeThenReadAll() &lt;/p&gt;
{
+    TFRecordIO.Write writeTransform = TFRecordIO
+        .write()
+        .to(filenamePrefix)
+        .withCompression(compressionType)
+        .withSuffix(&quot;.tfrecord&quot;);
+
+    writePipeline
+        .apply(&quot;Generate sequence&quot;, GenerateSequence.from(0).to(numberOfTextLines))
+        .apply(&quot;Produce text lines&quot;,
+            ParDo.of(new FileBasedIOITHelper.DeterministicallyConstructTestTextLineFn()))
+        .apply(&quot;Transform strings to bytes&quot;, MapElements.via(new StringToByteArray()))
+        .apply(&quot;Write content to files&quot;, writeTransform);
+
+    writePipeline.run().waitUntilFinish();
+
+    String filenamePattern = createFilenamePattern();
+    PCollection&amp;lt;String&amp;gt; consolidatedHashcode = readPipeline
+        .apply(TFRecordIO.read().from(filenamePattern).withCompression(AUTO))
+        .apply(&quot;Transform bytes to strings&quot;, MapElements.via(new ByteArrayToString()))
+        .apply(&quot;Calculate hashcode&quot;, Combine.globally(new HashingFn()));
+
+    String expectedHash = getExpectedHashForLineCount(numberOfTextLines);
+    PAssert.thatSingleton(consolidatedHashcode).isEqualTo(expectedHash);
+
+    readPipeline.apply(Create.of(filenamePattern))
+        .apply(&quot;Delete test files&quot;, ParDo.of(new FileBasedIOITHelper.DeleteFileFn())
+        .withSideInputs(consolidatedHashcode.apply(View.&amp;lt;String&amp;gt;asSingleton())));
+    readPipeline.run().waitUntilFinish();
+  }
&lt;p&gt;+&lt;br/&gt;
+  static class StringToByteArray extends SimpleFunction&amp;lt;String, byte[]&amp;gt; &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    @Override+    public byte[] apply(String input) {
+      return input.getBytes();
+    }+  }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+&lt;br/&gt;
+  static class ByteArrayToString extends SimpleFunction&amp;lt;byte[], String&amp;gt; &lt;/p&gt;
&lt;div class=&quot;error&quot;&gt;&lt;span class=&quot;error&quot;&gt;Unknown macro: {+    @Override+    public String apply(byte[] input) {
+      return new String(input);
+    }+  }&lt;/span&gt; &lt;/div&gt;
&lt;p&gt;+}&lt;br/&gt;
diff --git a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIO.java b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIO.java&lt;br/&gt;
index 8b4609da224..febdc1f53b0 100644&lt;/p&gt;&lt;/li&gt;
			&lt;li&gt;a/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIO.java&lt;br/&gt;
+++ b/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIO.java&lt;br/&gt;
@@ -122,43 +122,19 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;idempotent transformation to that row.&lt;br/&gt;
  *&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;To configure a Cloud Bigtable sink, you must supply a table id, a project id, an instance id&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* and optionally and optionally a 
{@link BigtableOptions} to provide more specific connection&lt;br/&gt;
- * configuration, for example:&lt;br/&gt;
+ * and optionally a configuration function for {@link BigtableOptions}
&lt;p&gt; to provide more specific&lt;br/&gt;
+ * connection configuration, for example:&lt;br/&gt;
  *&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;pre&amp;gt;
{@code
  * PCollection&amp;lt;KV&amp;lt;ByteString, Iterable&amp;lt;Mutation&amp;gt;&amp;gt;&amp;gt; data = ...;
  *
  * data.apply(&quot;write&quot;,
  *     BigtableIO.write()
- *         .setProjectId(&quot;project&quot;)
- *         .setInstanceId(&quot;instance&quot;)
+ *         .withProjectId(&quot;project&quot;)
+ *         .withInstanceId(&quot;instance&quot;)
  *         .withTableId(&quot;table&quot;));
  * }
&lt;p&gt;&amp;lt;/pre&amp;gt;&lt;br/&gt;
  *&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;* &amp;lt;h3&amp;gt;Using local emulator&amp;lt;/h3&amp;gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* &amp;lt;p&amp;gt;In order to use local emulator for Bigtable you should use:&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
	&lt;li&gt;* &amp;lt;pre&amp;gt;
{@code
- * BigtableOptions.Builder optionsBuilder =
- *     new BigtableOptions.Builder()
- *         .setUsePlaintextNegotiation(true)
- *         .setCredentialOptions(CredentialOptions.nullCredential())
- *         .setDataHost(&quot;127.0.0.1&quot;) // network interface where Bigtable emulator is bound
- *         .setInstanceAdminHost(&quot;127.0.0.1&quot;)
- *         .setTableAdminHost(&quot;127.0.0.1&quot;)
- *         .setPort(LOCAL_EMULATOR_PORT))
- *
- * PCollection&amp;lt;KV&amp;lt;ByteString, Iterable&amp;lt;Mutation&amp;gt;&amp;gt;&amp;gt; data = ...;
- *
- * data.apply(&quot;write&quot;,
- *     BigtableIO.write()
- *         .withBigtableOptions(optionsBuilder)
- *         .setProjectId(&quot;project&quot;)
- *         .setInstanceId(&quot;instance&quot;)
- *         .withTableId(&quot;table&quot;);
- * }
&lt;p&gt;&amp;lt;/pre&amp;gt;&lt;/p&gt;&lt;/li&gt;
	&lt;li&gt;*&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;&amp;lt;h3&amp;gt;Experimental&amp;lt;/h3&amp;gt;&lt;br/&gt;
  *&lt;/li&gt;
	&lt;li&gt;&amp;lt;p&amp;gt;This connector for Cloud Bigtable is considered experimental and may break or receive&lt;br/&gt;
@@ -239,12 +215,23 @@ public static Write write() {&lt;br/&gt;
     @Nullable&lt;br/&gt;
     abstract BigtableService getBigtableService();&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;/** Returns the Google Cloud Bigtable instance being read from, and other parameters. */&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Returns the Google Cloud Bigtable instance being read from, and other parameters.&lt;br/&gt;
+     * @deprecated will be replaced by bigtable options configurator.&lt;br/&gt;
+     */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     @Nullable&lt;br/&gt;
     public abstract BigtableOptions getBigtableOptions();&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     public abstract boolean getValidate();&lt;/p&gt;

&lt;p&gt;+    /**&lt;br/&gt;
+     * Configurator of the effective Bigtable Options.&lt;br/&gt;
+     */&lt;br/&gt;
+    @Nullable&lt;br/&gt;
+    abstract SerializableFunction&amp;lt;BigtableOptions.Builder,&lt;br/&gt;
+      BigtableOptions.Builder&amp;gt; getBigtableOptionsConfigurator();&lt;br/&gt;
+&lt;br/&gt;
     abstract Builder toBuilder();&lt;/p&gt;

&lt;p&gt;     @AutoValue.Builder&lt;br/&gt;
@@ -260,12 +247,17 @@ public static Write write() &lt;/p&gt;
{
 
       abstract Builder setTableId(String tableId);
 
+      /** @deprecated will be replaced by bigtable options configurator. */
+      @Deprecated
       abstract Builder setBigtableOptions(BigtableOptions options);
 
       abstract Builder setBigtableService(BigtableService bigtableService);
 
       abstract Builder setValidate(boolean validate);
 
+      abstract Builder setBigtableOptionsConfigurator(
+        SerializableFunction&amp;lt;BigtableOptions.Builder, BigtableOptions.Builder&amp;gt; optionsConfigurator);
+
       abstract Read build();
     }

&lt;p&gt;@@ -302,7 +294,10 @@ public Read withInstanceId(String instanceId) {&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;indicated by 
{@link #withProjectId(String)}, and using any other specified customizations.&lt;br/&gt;
      *&lt;br/&gt;
      * &amp;lt;p&amp;gt;Does not modify this object.&lt;br/&gt;
+     *&lt;br/&gt;
+     * @deprecated will be replaced by bigtable options configurator.&lt;br/&gt;
      */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     public Read withBigtableOptions(BigtableOptions options) {&lt;br/&gt;
       checkArgument(options != null, &quot;options can not be null&quot;);&lt;br/&gt;
       return withBigtableOptions(options.toBuilder());&lt;br/&gt;
@@ -320,17 +315,29 @@ public Read withBigtableOptions(BigtableOptions options) {&lt;br/&gt;
      * will have no effect on the returned {@link BigtableIO.Read}.&lt;br/&gt;
      *&lt;br/&gt;
      * &amp;lt;p&amp;gt;Does not modify this object.&lt;br/&gt;
+     *&lt;br/&gt;
+     * @deprecated will be replaced by bigtable options configurator.&lt;br/&gt;
      */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     public Read withBigtableOptions(BigtableOptions.Builder optionsBuilder) {
       checkArgument(optionsBuilder != null, &quot;optionsBuilder can not be null&quot;);
       // TODO: is there a better way to clone a Builder? Want it to be immune from user changes.
-      BigtableOptions options = optionsBuilder.build();
-
-      BigtableOptions.Builder clonedBuilder = options.toBuilder()
-          .setUseCachedDataPool(true);
-      BigtableOptions clonedOptions = clonedBuilder.build();
+      return toBuilder().setBigtableOptions(optionsBuilder.build().toBuilder().build()).build();
+    }&lt;br/&gt;
 &lt;br/&gt;
-      return toBuilder().setBigtableOptions(clonedOptions).build();&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Returns a new {@link BigtableIO.Read} that will read from the Cloud Bigtable instance&lt;br/&gt;
+     * with customized options provided by given configurator.&lt;br/&gt;
+     *&lt;br/&gt;
+     * &amp;lt;p&amp;gt;WARNING: instanceId and projectId should not be provided here and should be provided over&lt;br/&gt;
+     * {@link #withProjectId(String)}
&lt;p&gt; and &lt;/p&gt;
{@link #withInstanceId(String)}.&lt;br/&gt;
+     *&lt;br/&gt;
+     * &amp;lt;p&amp;gt;Does not modify this object.&lt;br/&gt;
+     */&lt;br/&gt;
+    public Read withBigtableOptionsConfigurator(&lt;br/&gt;
+      SerializableFunction&amp;lt;BigtableOptions.Builder, BigtableOptions.Builder&amp;gt; configurator) {
+      checkArgument(configurator != null, &quot;configurator can not be null&quot;);
+      return toBuilder().setBigtableOptionsConfigurator(configurator).build();
     }&lt;br/&gt;
 &lt;br/&gt;
     /**&lt;br/&gt;
@@ -427,17 +434,25 @@ public void populateDisplayData(DisplayData.Builder builder) {
         builder.add(DisplayData.item(&quot;rowFilter&quot;, getRowFilter().toString())
           .withLabel(&quot;Table Row Filter&quot;));
       }&lt;br/&gt;
+&lt;br/&gt;
+      builder.add(DisplayData.item(&quot;effectiveBigtableOptions&quot;,&lt;br/&gt;
+        effectiveUserProvidedBigtableOptions().build().toString())&lt;br/&gt;
+        .withLabel(&quot;Effective BigtableOptions resulted from configuration of given options&quot;));&lt;br/&gt;
     }&lt;br/&gt;
 &lt;br/&gt;
     @Override&lt;br/&gt;
     public String toString() {
       return MoreObjects.toStringHelper(Read.class)
           .add(&quot;options&quot;, getBigtableOptions())
+          .add(&quot;effectiveOptions&quot;, effectiveUserProvidedBigtableOptions())
           .add(&quot;projectId&quot;, getProjectId())
           .add(&quot;instanceId&quot;, getInstanceId())
           .add(&quot;tableId&quot;, getTableId())
           .add(&quot;keyRange&quot;, getKeyRange())
           .add(&quot;filter&quot;, getRowFilter())
+          .add(&quot;bigtableOptionsConfigurator&quot;,
+            getBigtableOptionsConfigurator() == null ? null : getBigtableOptionsConfigurator()
+              .getClass().getName())
           .toString();
     }&lt;br/&gt;
 &lt;br/&gt;
@@ -468,25 +483,41 @@ BigtableService getBigtableService(PipelineOptions pipelineOptions) {
         return getBigtableService();
       }&lt;br/&gt;
 &lt;br/&gt;
-      BigtableOptions.Builder clonedOptions = getBigtableOptions() != null&lt;br/&gt;
-          ? getBigtableOptions().toBuilder()&lt;br/&gt;
-          : new BigtableOptions.Builder();&lt;br/&gt;
+      BigtableOptions.Builder bigtableOptions = effectiveUserProvidedBigtableOptions();&lt;br/&gt;
 &lt;br/&gt;
-      clonedOptions.setUserAgent(pipelineOptions.getUserAgent());&lt;br/&gt;
-      if (getInstanceId() != null) {
-        clonedOptions.setInstanceId(getInstanceId());
-      }&lt;br/&gt;
-      if (getProjectId() != null) {
-        clonedOptions.setProjectId(getProjectId());
-      }&lt;br/&gt;
+      bigtableOptions.setUserAgent(pipelineOptions.getUserAgent());&lt;br/&gt;
 &lt;br/&gt;
       if (getBigtableOptions() != null &amp;amp;&amp;amp; getBigtableOptions().getCredentialOptions()&lt;br/&gt;
           .getCredentialType() == CredentialType.DefaultCredentials) {
-        clonedOptions.setCredentialOptions(
+        bigtableOptions.setCredentialOptions(
             CredentialOptions.credential(
                 pipelineOptions.as(GcpOptions.class).getGcpCredential()));
       }&lt;br/&gt;
-      return new BigtableServiceImpl(clonedOptions.build());&lt;br/&gt;
+&lt;br/&gt;
+      // Default option that should be forced&lt;br/&gt;
+      bigtableOptions.setUseCachedDataPool(true);&lt;br/&gt;
+&lt;br/&gt;
+      return new BigtableServiceImpl(bigtableOptions.build());&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private BigtableOptions.Builder effectiveUserProvidedBigtableOptions() {&lt;br/&gt;
+      BigtableOptions.Builder effectiveOptions = getBigtableOptions() != null&lt;br/&gt;
+        ? getBigtableOptions().toBuilder()&lt;br/&gt;
+        : new BigtableOptions.Builder();&lt;br/&gt;
+&lt;br/&gt;
+      if (getBigtableOptionsConfigurator() != null) {
+        effectiveOptions = getBigtableOptionsConfigurator().apply(effectiveOptions);
+      }&lt;br/&gt;
+&lt;br/&gt;
+      if (getInstanceId() != null) {
+        effectiveOptions.setInstanceId(getInstanceId());
+      }&lt;br/&gt;
+&lt;br/&gt;
+      if (getProjectId() != null) {
+        effectiveOptions.setProjectId(getProjectId());
+      }&lt;br/&gt;
+&lt;br/&gt;
+      return effectiveOptions;&lt;br/&gt;
     }&lt;br/&gt;
   }&lt;br/&gt;
 &lt;br/&gt;
@@ -516,10 +547,21 @@ BigtableService getBigtableService(PipelineOptions pipelineOptions) {&lt;br/&gt;
     @Nullable&lt;br/&gt;
     abstract BigtableService getBigtableService();&lt;br/&gt;
 &lt;br/&gt;
-    /** Returns the Google Cloud Bigtable instance being written to, and other parameters. */&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Returns the Google Cloud Bigtable instance being written to, and other parameters.&lt;br/&gt;
+     * @deprecated will be replaced by bigtable options configurator.&lt;br/&gt;
+     */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     @Nullable&lt;br/&gt;
     public abstract BigtableOptions getBigtableOptions();&lt;br/&gt;
 &lt;br/&gt;
+    /**&lt;br/&gt;
+     * Configurator of the effective Bigtable Options.&lt;br/&gt;
+     */&lt;br/&gt;
+    @Nullable&lt;br/&gt;
+    abstract SerializableFunction&amp;lt;BigtableOptions.Builder,&lt;br/&gt;
+      BigtableOptions.Builder&amp;gt; getBigtableOptionsConfigurator();&lt;br/&gt;
+&lt;br/&gt;
     abstract boolean getValidate();&lt;br/&gt;
 &lt;br/&gt;
     abstract Builder toBuilder();&lt;br/&gt;
@@ -533,12 +575,17 @@ BigtableService getBigtableService(PipelineOptions pipelineOptions) {
 
       abstract Builder setTableId(String tableId);
 
+      /** @deprecated will be replaced by bigtable options configurator. */
+      @Deprecated
       abstract Builder setBigtableOptions(BigtableOptions options);
 
       abstract Builder setBigtableService(BigtableService bigtableService);
 
       abstract Builder setValidate(boolean validate);
 
+      abstract Builder setBigtableOptionsConfigurator(
+        SerializableFunction&amp;lt;BigtableOptions.Builder, BigtableOptions.Builder&amp;gt; optionsConfigurator);
+
       abstract Write build();
     }&lt;br/&gt;
 &lt;br/&gt;
@@ -575,7 +622,10 @@ public Write withInstanceId(String instanceId) {&lt;br/&gt;
      * indicated by the given options, and using any other specified customizations.&lt;br/&gt;
      *&lt;br/&gt;
      * &amp;lt;p&amp;gt;Does not modify this object.&lt;br/&gt;
+     *&lt;br/&gt;
+     * @deprecated will be replaced by bigtable options configurator.&lt;br/&gt;
      */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     public Write withBigtableOptions(BigtableOptions options) {
       return withBigtableOptions(options.toBuilder());
     }&lt;br/&gt;
@@ -592,21 +642,29 @@ public Write withBigtableOptions(BigtableOptions options) {&lt;br/&gt;
      * will have no effect on the returned {@link BigtableIO.Write}.&lt;br/&gt;
      *&lt;br/&gt;
      * &amp;lt;p&amp;gt;Does not modify this object.&lt;br/&gt;
+     *&lt;br/&gt;
+     * @deprecated will be replaced by bigtable options configurator.&lt;br/&gt;
      */&lt;br/&gt;
+    @Deprecated&lt;br/&gt;
     public Write withBigtableOptions(BigtableOptions.Builder optionsBuilder) {
       checkArgument(optionsBuilder != null, &quot;optionsBuilder can not be null&quot;);
       // TODO: is there a better way to clone a Builder? Want it to be immune from user changes.
-      BigtableOptions options = optionsBuilder.build();
+      return toBuilder().setBigtableOptions(optionsBuilder.build().toBuilder().build()).build();
+    }&lt;br/&gt;
 &lt;br/&gt;
-      // Set useBulkApi to true for enabling bulk writes&lt;br/&gt;
-      BigtableOptions.Builder clonedBuilder = options.toBuilder()&lt;br/&gt;
-          .setBulkOptions(&lt;br/&gt;
-              options.getBulkOptions().toBuilder()&lt;br/&gt;
-                  .setUseBulkApi(true)&lt;br/&gt;
-                  .build())&lt;br/&gt;
-          .setUseCachedDataPool(true);&lt;br/&gt;
-      BigtableOptions clonedOptions = clonedBuilder.build();&lt;br/&gt;
-      return toBuilder().setBigtableOptions(clonedOptions).build();&lt;br/&gt;
+    /**&lt;br/&gt;
+     * Returns a new {@link BigtableIO.Write} that will read from the Cloud Bigtable instance&lt;br/&gt;
+     * with customized options provided by given configurator.&lt;br/&gt;
+     *&lt;br/&gt;
+     * &amp;lt;p&amp;gt;WARNING: instanceId and projectId should not be provided here and should be provided over&lt;br/&gt;
+     * {@link #withProjectId(String)} and {@link #withInstanceId(String)}
&lt;p&gt;.&lt;br/&gt;
+     *&lt;br/&gt;
+     * &amp;lt;p&amp;gt;Does not modify this object.&lt;br/&gt;
+     */&lt;br/&gt;
+    public Write withBigtableOptionsConfigurator(&lt;br/&gt;
+      SerializableFunction&amp;lt;BigtableOptions.Builder, BigtableOptions.Builder&amp;gt; configurator) &lt;/p&gt;
{
+      checkArgument(configurator != null, &quot;configurator can not be null&quot;);
+      return toBuilder().setBigtableOptionsConfigurator(configurator).build();
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     /** Disables validation that the table being written to exists. */&lt;br/&gt;
@@ -687,15 +745,23 @@ public void populateDisplayData(DisplayData.Builder builder) &lt;/p&gt;
{
         builder.add(DisplayData.item(&quot;instanceId&quot;, getInstanceId())
             .withLabel(&quot;Bigtable Instnace Id&quot;));
       }
&lt;p&gt;+&lt;br/&gt;
+      builder.add(DisplayData.item(&quot;effectiveBigtableOptions&quot;,&lt;br/&gt;
+        effectiveUserProvidedBigtableOptions().build().toString())&lt;br/&gt;
+        .withLabel(&quot;Effective BigtableOptions resulted from configuration of given options&quot;));&lt;br/&gt;
     }&lt;/p&gt;

&lt;p&gt;     @Override&lt;br/&gt;
     public String toString() &lt;/p&gt;
{
       return MoreObjects.toStringHelper(Write.class)
           .add(&quot;options&quot;, getBigtableOptions())
+          .add(&quot;effectiveOptions&quot;, effectiveUserProvidedBigtableOptions())
           .add(&quot;tableId&quot;, getTableId())
           .add(&quot;projectId&quot;, getProjectId())
           .add(&quot;instanceId&quot;, getInstanceId())
+          .add(&quot;bigtableOptionsConfigurator&quot;,
+          getBigtableOptionsConfigurator() == null ? null : getBigtableOptionsConfigurator()
+            .getClass().getName())
           .toString();
     }

&lt;p&gt;@@ -713,25 +779,45 @@ BigtableService getBigtableService(PipelineOptions pipelineOptions) &lt;/p&gt;
{
         return getBigtableService();
       }

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;BigtableOptions.Builder clonedOptions = getBigtableOptions() != null&lt;/li&gt;
	&lt;li&gt;? getBigtableOptions().toBuilder()&lt;/li&gt;
	&lt;li&gt;: new BigtableOptions.Builder();&lt;br/&gt;
+      BigtableOptions.Builder bigtableOptions = effectiveUserProvidedBigtableOptions();&lt;br/&gt;
+&lt;br/&gt;
+      bigtableOptions.setUserAgent(pipelineOptions.getUserAgent());&lt;br/&gt;
+&lt;br/&gt;
+      if (getBigtableOptions() != null &amp;amp;&amp;amp; getBigtableOptions().getCredentialOptions()&lt;br/&gt;
+        .getCredentialType() == CredentialType.DefaultCredentials) 
{
+        bigtableOptions.setCredentialOptions(
+          CredentialOptions.credential(
+            pipelineOptions.as(GcpOptions.class).getGcpCredential()));
+      }
&lt;p&gt;+&lt;br/&gt;
+      // Set useBulkApi to true for enabling bulk writes&lt;br/&gt;
+      bigtableOptions&lt;br/&gt;
+        .setUseCachedDataPool(true)&lt;br/&gt;
+        .setBulkOptions(&lt;br/&gt;
+          effectiveUserProvidedBigtableOptions().build().getBulkOptions().toBuilder()&lt;br/&gt;
+            .setUseBulkApi(true)&lt;br/&gt;
+            .build());&lt;br/&gt;
+&lt;br/&gt;
+      return new BigtableServiceImpl(bigtableOptions.build());&lt;br/&gt;
+    }&lt;br/&gt;
+&lt;br/&gt;
+    private BigtableOptions.Builder effectiveUserProvidedBigtableOptions() {&lt;br/&gt;
+      BigtableOptions.Builder effectiveOptions = getBigtableOptions() != null&lt;br/&gt;
+        ? getBigtableOptions().toBuilder()&lt;br/&gt;
+        : new BigtableOptions.Builder();&lt;br/&gt;
+&lt;br/&gt;
+      if (getBigtableOptionsConfigurator() != null) &lt;/p&gt;
{
+        effectiveOptions = getBigtableOptionsConfigurator().apply(effectiveOptions);
+      }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;clonedOptions.setUserAgent(pipelineOptions.getUserAgent());&lt;br/&gt;
       if (getInstanceId() != null) 
{
-        clonedOptions.setInstanceId(getInstanceId());
+        effectiveOptions.setInstanceId(getInstanceId());
       }
&lt;p&gt;       if (getProjectId() != null) &lt;/p&gt;
{
-        clonedOptions.setProjectId(getProjectId());
+        effectiveOptions.setProjectId(getProjectId());
       }&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if (getBigtableOptions() != null &amp;amp;&amp;amp; getBigtableOptions().getCredentialOptions()&lt;/li&gt;
	&lt;li&gt;.getCredentialType() == CredentialType.DefaultCredentials) 
{
-        clonedOptions.setCredentialOptions(
-            CredentialOptions.credential(
-                pipelineOptions.as(GcpOptions.class).getGcpCredential()));
-      }&lt;/li&gt;
	&lt;li&gt;return new BigtableServiceImpl(clonedOptions.build());&lt;br/&gt;
+      return effectiveOptions;&lt;br/&gt;
     }&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     private class BigtableWriterFn extends DoFn&amp;lt;KV&amp;lt;ByteString, Iterable&amp;lt;Mutation&amp;gt;&amp;gt;, Void&amp;gt; {&lt;br/&gt;
diff --git a/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIOTest.java b/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIOTest.java&lt;br/&gt;
index a976e4ad351..418db92c4bf 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIOTest.java&lt;br/&gt;
+++ b/sdks/java/io/google-cloud-platform/src/test/java/org/apache/beam/sdk/io/gcp/bigtable/BigtableIOTest.java&lt;br/&gt;
@@ -140,6 +140,15 @@ public BigtableService apply(PipelineOptions input) {&lt;br/&gt;
   private static final TypeDescriptor&amp;lt;KV&amp;lt;ByteString, Iterable&amp;lt;Mutation&amp;gt;&amp;gt;&amp;gt; BIGTABLE_WRITE_TYPE =&lt;br/&gt;
       new TypeDescriptor&amp;lt;KV&amp;lt;ByteString, Iterable&amp;lt;Mutation&amp;gt;&amp;gt;&amp;gt;() {};&lt;/p&gt;

&lt;p&gt;+  private static final SerializableFunction&amp;lt;BigtableOptions.Builder, BigtableOptions.Builder&amp;gt;&lt;br/&gt;
+    PORT_CONFIGURATOR =&lt;br/&gt;
+    new SerializableFunction&amp;lt;BigtableOptions.Builder, BigtableOptions.Builder&amp;gt;() {&lt;br/&gt;
+      @Override&lt;br/&gt;
+      public BigtableOptions.Builder apply(BigtableOptions.Builder input) &lt;/p&gt;
{
+        return input.setPort(1234);
+      }
&lt;p&gt;+    };&lt;br/&gt;
+&lt;br/&gt;
   @Before&lt;br/&gt;
   public void setup() throws Exception {&lt;br/&gt;
     service = new FakeBigtableService();&lt;br/&gt;
@@ -158,12 +167,14 @@ public void testReadBuildsCorrectly() &lt;/p&gt;
{
         BigtableIO.read().withBigtableOptions(BIGTABLE_OPTIONS)
             .withTableId(&quot;table&quot;)
             .withInstanceId(&quot;instance&quot;)
-            .withProjectId(&quot;project&quot;);
+            .withProjectId(&quot;project&quot;)
+            .withBigtableOptionsConfigurator(PORT_CONFIGURATOR);
     assertEquals(&quot;options_project&quot;, read.getBigtableOptions().getProjectId());
     assertEquals(&quot;options_instance&quot;, read.getBigtableOptions().getInstanceId());
     assertEquals(&quot;instance&quot;, read.getInstanceId());
     assertEquals(&quot;project&quot;, read.getProjectId());
     assertEquals(&quot;table&quot;, read.getTableId());
+    assertEquals(PORT_CONFIGURATOR, read.getBigtableOptionsConfigurator());
   }

&lt;p&gt;   @Test&lt;br/&gt;
@@ -214,12 +225,14 @@ public void testWriteBuildsCorrectly() &lt;/p&gt;
{
         BigtableIO.write().withBigtableOptions(BIGTABLE_OPTIONS)
             .withTableId(&quot;table&quot;)
             .withInstanceId(&quot;instance&quot;)
-            .withProjectId(&quot;project&quot;);
+            .withProjectId(&quot;project&quot;)
+            .withBigtableOptionsConfigurator(PORT_CONFIGURATOR);
     assertEquals(&quot;table&quot;, write.getTableId());
     assertEquals(&quot;options_project&quot;, write.getBigtableOptions().getProjectId());
     assertEquals(&quot;options_instance&quot;, write.getBigtableOptions().getInstanceId());
     assertEquals(&quot;instance&quot;, write.getInstanceId());
     assertEquals(&quot;project&quot;, write.getProjectId());
+    assertEquals(PORT_CONFIGURATOR, write.getBigtableOptionsConfigurator());
   }

&lt;p&gt;   @Test&lt;br/&gt;
diff --git a/sdks/java/io/pom.xml b/sdks/java/io/pom.xml&lt;br/&gt;
index 0f8bc78fbe1..07e1b5cb9ff 100644&lt;br/&gt;
&amp;#8212; a/sdks/java/io/pom.xml&lt;br/&gt;
+++ b/sdks/java/io/pom.xml&lt;br/&gt;
@@ -37,6 +37,7 @@&lt;br/&gt;
     &amp;lt;integrationTestPipelineOptions /&amp;gt;&lt;br/&gt;
     &amp;lt;pkbBeamRunnerProfile /&amp;gt;&lt;br/&gt;
     &amp;lt;pkbBeamRunnerOption /&amp;gt;&lt;br/&gt;
+    &amp;lt;pkbExtraProperties /&amp;gt;&lt;br/&gt;
   &amp;lt;/properties&amp;gt;&lt;/p&gt;

&lt;p&gt;   &amp;lt;modules&amp;gt;&lt;br/&gt;
diff --git a/sdks/python/apache_beam/io/localfilesystem_test.py b/sdks/python/apache_beam/io/localfilesystem_test.py&lt;br/&gt;
index 8c34ecdf0d3..31741c9f740 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/io/localfilesystem_test.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/io/localfilesystem_test.py&lt;br/&gt;
@@ -146,7 +146,7 @@ def test_match_file_exception(self):&lt;br/&gt;
         error.exception.message.startswith(&apos;Match operation failed&apos;))&lt;br/&gt;
     self.assertEqual(error.exception.exception_details.keys(), &lt;span class=&quot;error&quot;&gt;&amp;#91;None&amp;#93;&lt;/span&gt;)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def test_match_directory(self):&lt;br/&gt;
+  def test_match_glob(self):&lt;br/&gt;
     path1 = os.path.join(self.tmpdir, &apos;f1&apos;)&lt;br/&gt;
     path2 = os.path.join(self.tmpdir, &apos;f2&apos;)&lt;br/&gt;
     open(path1, &apos;a&apos;).close()&lt;br/&gt;
diff --git a/sdks/python/apache_beam/io/vcfio.py b/sdks/python/apache_beam/io/vcfio.py&lt;br/&gt;
index b877a32d01b..80f4631e462 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/io/vcfio.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/io/vcfio.py&lt;br/&gt;
@@ -22,6 +22,8 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; from _&lt;em&gt;future&lt;/em&gt;_ import absolute_import&lt;/p&gt;

&lt;p&gt;+import logging&lt;br/&gt;
+import traceback&lt;br/&gt;
 from collections import namedtuple&lt;/p&gt;

&lt;p&gt; import vcf&lt;br/&gt;
@@ -33,8 +35,8 @@&lt;br/&gt;
 from apache_beam.io.textio import _TextSource as TextSource&lt;br/&gt;
 from apache_beam.transforms import PTransform&lt;/p&gt;

&lt;p&gt;-_&lt;em&gt;all&lt;/em&gt;_ = &lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;#39;ReadFromVcf&amp;#39;, &amp;#39;Variant&amp;#39;, &amp;#39;VariantCall&amp;#39;, &amp;#39;VariantInfo&amp;#39;&amp;#93;&lt;/span&gt;&lt;br/&gt;
-&lt;br/&gt;
+_&lt;em&gt;all&lt;/em&gt;_ = [&apos;ReadFromVcf&apos;, &apos;Variant&apos;, &apos;VariantCall&apos;, &apos;VariantInfo&apos;,&lt;br/&gt;
+           &apos;MalformedVcfRecord&apos;]&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Stores data about variant INFO fields. The type of &apos;data&apos; is specified in the&lt;/li&gt;
	&lt;li&gt;VCF headers. &apos;field_count&apos; is a string that specifies the number of fields&lt;br/&gt;
@@ -45,6 +47,10 @@&lt;/li&gt;
	&lt;li&gt;- &apos;G&apos;: one value for each possible genotype.&lt;/li&gt;
	&lt;li&gt;- &apos;R&apos;: one value for each possible allele (including the reference).&lt;br/&gt;
 VariantInfo = namedtuple(&apos;VariantInfo&apos;, &lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;#39;data&amp;#39;, &amp;#39;field_count&amp;#39;&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+# Stores data about failed VCF record reads. `line` is the text line that&lt;br/&gt;
+# caused the failed read and `file_name` is the name of the file that the read&lt;br/&gt;
+# failed in.&lt;br/&gt;
+MalformedVcfRecord = namedtuple(&apos;MalformedVcfRecord&apos;, &lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;#39;file_name&amp;#39;, &amp;#39;line&amp;#39;&amp;#93;&lt;/span&gt;)&lt;br/&gt;
 MISSING_FIELD_VALUE = &apos;.&apos;  # Indicates field is missing in VCF record.&lt;br/&gt;
 PASS_FILTER = &apos;PASS&apos;  # Indicates that all filters have been passed.&lt;br/&gt;
 END_INFO_KEY = &apos;END&apos;  # The info key that explicitly specifies end of a record.&lt;br/&gt;
@@ -223,7 +229,8 @@ def _&lt;em&gt;init&lt;/em&gt;_(self,&lt;br/&gt;
                file_pattern,&lt;br/&gt;
                compression_type=CompressionTypes.AUTO,&lt;br/&gt;
                buffer_size=DEFAULT_VCF_READ_BUFFER_SIZE,&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;validate=True):&lt;br/&gt;
+               validate=True,&lt;br/&gt;
+               allow_malformed_records=False):&lt;br/&gt;
     super(&lt;em&gt;VcfSource, self).&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;_(file_pattern,&lt;br/&gt;
                                      compression_type=compression_type,&lt;br/&gt;
                                      validate=validate)&lt;br/&gt;
@@ -231,6 +238,7 @@ def _&lt;em&gt;init&lt;/em&gt;_(self,&lt;br/&gt;
     self._header_lines_per_file = {}&lt;br/&gt;
     self._compression_type = compression_type&lt;br/&gt;
     self._buffer_size = buffer_size&lt;br/&gt;
+    self._allow_malformed_records = allow_malformed_records&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def read_records(self, file_name, range_tracker):&lt;br/&gt;
     record_iterator = _VcfSource._VcfRecordIterator(&lt;br/&gt;
@@ -238,6 +246,7 @@ def read_records(self, file_name, range_tracker):&lt;br/&gt;
         range_tracker,&lt;br/&gt;
         self._pattern,&lt;br/&gt;
         self._compression_type,&lt;br/&gt;
+        self._allow_malformed_records,&lt;br/&gt;
         buffer_size=self._buffer_size,&lt;br/&gt;
         skip_header_lines=0)&lt;/p&gt;

&lt;p&gt;@@ -253,10 +262,12 @@ def _&lt;em&gt;init&lt;/em&gt;_(self,&lt;br/&gt;
                  range_tracker,&lt;br/&gt;
                  file_pattern,&lt;br/&gt;
                  compression_type,&lt;br/&gt;
+                 allow_malformed_records,&lt;br/&gt;
                  **kwargs):&lt;br/&gt;
       self._header_lines = []&lt;br/&gt;
       self._last_record = None&lt;br/&gt;
       self._file_name = file_name&lt;br/&gt;
+      self._allow_malformed_records = allow_malformed_records&lt;/p&gt;

&lt;p&gt;       text_source = TextSource(&lt;br/&gt;
           file_pattern,&lt;br/&gt;
@@ -274,7 +285,9 @@ def _&lt;em&gt;init&lt;/em&gt;_(self,&lt;br/&gt;
       try:&lt;br/&gt;
         self._vcf_reader = vcf.Reader(fsock=self._create_generator())&lt;br/&gt;
       except SyntaxError as e:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;raise ValueError(&apos;Invalid VCF header %s&apos; % str(e))&lt;br/&gt;
+        raise ValueError(&apos;An exception was raised when reading header from VCF &apos;&lt;br/&gt;
+                         &apos;file %s: %s&apos; % (self._file_name,&lt;br/&gt;
+                                          traceback.format_exc(e)))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     def _store_header_lines(self, header_lines):&lt;br/&gt;
       self._header_lines = header_lines&lt;br/&gt;
@@ -301,7 +314,18 @@ def next(self):&lt;br/&gt;
         return self._convert_to_variant_record(record, self._vcf_reader.infos,&lt;br/&gt;
                                                self._vcf_reader.formats)&lt;br/&gt;
       except (LookupError, ValueError) as e:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;raise ValueError(&apos;Invalid record in VCF file. Error: %s&apos; % str(e))&lt;br/&gt;
+        if self._allow_malformed_records:&lt;br/&gt;
+          logging.warning(&lt;br/&gt;
+              &apos;An exception was raised when reading record from VCF file &apos;&lt;br/&gt;
+              &apos;%s. Invalid record was %s: %s&apos;,&lt;br/&gt;
+              self._file_name, self._last_record, traceback.format_exc(e))&lt;br/&gt;
+          return MalformedVcfRecord(self._file_name, self._last_record)&lt;br/&gt;
+&lt;br/&gt;
+        raise ValueError(&apos;An exception was raised when reading record from VCF &apos;&lt;br/&gt;
+                         &apos;file %s. Invalid record was %s: %s&apos; % (&lt;br/&gt;
+                             self._file_name,&lt;br/&gt;
+                             self._last_record,&lt;br/&gt;
+                             traceback.format_exc(e)))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     def _convert_to_variant_record(self, record, infos, formats):&lt;br/&gt;
       &quot;&quot;&quot;Converts the PyVCF record to a :class:`Variant` object.&lt;br/&gt;
@@ -407,7 +431,7 @@ class ReadFromVcf(PTransform):&lt;br/&gt;
   Parses VCF files (version 4) using PyVCF library. If file_pattern specifies&lt;br/&gt;
   multiple files, then the header from each file is used separately to parse&lt;br/&gt;
   the content. However, the output will be a PCollection of&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;:class:`Variant` objects.&lt;br/&gt;
+  :class:`Variant` (or :class:`MalformedVcfRecord` for failed reads) objects.&lt;br/&gt;
   &quot;&quot;&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def _&lt;em&gt;init&lt;/em&gt;_(&lt;br/&gt;
@@ -415,6 +439,7 @@ def _&lt;em&gt;init&lt;/em&gt;_(&lt;br/&gt;
       file_pattern=None,&lt;br/&gt;
       compression_type=CompressionTypes.AUTO,&lt;br/&gt;
       validate=True,&lt;br/&gt;
+      allow_malformed_records=False,&lt;br/&gt;
       **kwargs):&lt;br/&gt;
     &quot;&quot;&quot;Initialize the :class:`ReadFromVcf` transform.&lt;/p&gt;

&lt;p&gt;@@ -427,10 +452,17 @@ def _&lt;em&gt;init&lt;/em&gt;_(&lt;br/&gt;
         underlying file_path&apos;s extension will be used to detect the compression.&lt;br/&gt;
       validate (bool): flag to verify that the files exist during the pipeline&lt;br/&gt;
         creation time.&lt;br/&gt;
+      allow_malformed_records (bool): determines if failed VCF&lt;br/&gt;
+        record reads will be tolerated. Failed record reads will result in a&lt;br/&gt;
+        :class:`MalformedVcfRecord` being returned from the read of the record&lt;br/&gt;
+        rather than a :class:`Variant`.&lt;br/&gt;
     &quot;&quot;&quot;&lt;br/&gt;
     super(ReadFromVcf, self)._&lt;em&gt;init&lt;/em&gt;_(**kwargs)&lt;br/&gt;
     self._source = _VcfSource(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;file_pattern, compression_type, validate=validate)&lt;br/&gt;
+        file_pattern,&lt;br/&gt;
+        compression_type,&lt;br/&gt;
+        validate=validate,&lt;br/&gt;
+        allow_malformed_records=allow_malformed_records)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def expand(self, pvalue):&lt;br/&gt;
     return pvalue.pipeline | Read(self._source)&lt;br/&gt;
diff --git a/sdks/python/apache_beam/io/vcfio_test.py b/sdks/python/apache_beam/io/vcfio_test.py&lt;br/&gt;
index 871b6e9c8c0..029515fe341 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/io/vcfio_test.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/io/vcfio_test.py&lt;br/&gt;
@@ -20,12 +20,14 @@&lt;br/&gt;
 import logging&lt;br/&gt;
 import os&lt;br/&gt;
 import unittest&lt;br/&gt;
+from itertools import chain&lt;br/&gt;
 from itertools import permutations&lt;/p&gt;

&lt;p&gt; import apache_beam.io.source_test_utils as source_test_utils&lt;br/&gt;
 from apache_beam.io.vcfio import _VcfSource as VcfSource&lt;br/&gt;
 from apache_beam.io.vcfio import DEFAULT_PHASESET_VALUE&lt;br/&gt;
 from apache_beam.io.vcfio import MISSING_GENOTYPE_VALUE&lt;br/&gt;
+from apache_beam.io.vcfio import MalformedVcfRecord&lt;br/&gt;
 from apache_beam.io.vcfio import ReadFromVcf&lt;br/&gt;
 from apache_beam.io.vcfio import Variant&lt;br/&gt;
 from apache_beam.io.vcfio import VariantCall&lt;br/&gt;
@@ -95,8 +97,9 @@ class VcfSourceTest(unittest.TestCase):&lt;br/&gt;
   def _create_temp_vcf_file(self, lines, tempdir):&lt;br/&gt;
     return tempdir.create_temp_file(suffix=&apos;.vcf&apos;, lines=lines)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def _read_records(self, file_or_pattern):&lt;/li&gt;
	&lt;li&gt;return source_test_utils.read_from_source(VcfSource(file_or_pattern))&lt;br/&gt;
+  def _read_records(self, file_or_pattern, **kwargs):&lt;br/&gt;
+    return source_test_utils.read_from_source(&lt;br/&gt;
+        VcfSource(file_or_pattern, **kwargs))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def _create_temp_file_and_read_records(self, lines):&lt;br/&gt;
     with TempDir() as tempdir:&lt;br/&gt;
@@ -177,6 +180,51 @@ def _get_sample_variant_3(self):&lt;br/&gt;
                     info=&lt;/p&gt;
{&apos;GQ&apos;: None}
&lt;p&gt;))&lt;br/&gt;
     return variant, vcf_line&lt;/p&gt;

&lt;p&gt;+  def _get_invalid_file_contents(self):&lt;br/&gt;
+    &quot;&quot;&quot;Gets sample invalid files contents.&lt;br/&gt;
+&lt;br/&gt;
+    Returns:&lt;br/&gt;
+       A `tuple` where the first element is contents that are invalid because&lt;br/&gt;
+       of record errors and the second element is contents that are invalid&lt;br/&gt;
+       because of header errors.&lt;br/&gt;
+    &quot;&quot;&quot;&lt;br/&gt;
+    malformed_vcf_records = [&lt;br/&gt;
+        # Malfromed record.&lt;br/&gt;
+        [&lt;br/&gt;
+            &apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample\n&apos;,&lt;br/&gt;
+            &apos;1    1  &apos;&lt;br/&gt;
+        ],&lt;br/&gt;
+        # GT is not an integer.&lt;br/&gt;
+        [&lt;br/&gt;
+            &apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample\n&apos;,&lt;br/&gt;
+            &apos;19	123	rs12345	T	C	50	q10	AF=0.2;NS=2	GT	A|0&apos;&lt;br/&gt;
+        ],&lt;br/&gt;
+        # POS should be an integer.&lt;br/&gt;
+        [&lt;br/&gt;
+            &apos;##FILTER=&amp;lt;ID=PASS,Description=&quot;All filters passed&quot;&amp;gt;\n&apos;,&lt;br/&gt;
+            &apos;##FILTER=&amp;lt;ID=q10,Description=&quot;Quality is less than 10.&quot;&amp;gt;\n&apos;,&lt;br/&gt;
+            &apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample\n&apos;,&lt;br/&gt;
+            &apos;19	abc	rs12345	T	C	9	q10	AF=0.2;NS=2	GT:GQ	1|0:48\n&apos;,&lt;br/&gt;
+        ]&lt;br/&gt;
+    ]&lt;br/&gt;
+    malformed_header_lines = [&lt;br/&gt;
+        # Malformed FILTER.&lt;br/&gt;
+        [&lt;br/&gt;
+            &apos;##FILTER=&amp;lt;ID=PASS,Description=&quot;All filters passed&quot;&amp;gt;\n&apos;,&lt;br/&gt;
+            &apos;##FILTER=&amp;lt;ID=LowQual,Descri\n&apos;,&lt;br/&gt;
+            &apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample\n&apos;,&lt;br/&gt;
+            &apos;19	123	rs12345	T	C	50	q10	AF=0.2;NS=2	GT:GQ	1|0:48&apos;,&lt;br/&gt;
+        ],&lt;br/&gt;
+        # Invalid Number value for INFO.&lt;br/&gt;
+        [&lt;br/&gt;
+            &apos;##INFO=&amp;lt;ID=G,Number=U,Type=String,Description=&quot;InvalidNumber&quot;&amp;gt;\n&apos;,&lt;br/&gt;
+            &apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample\n&apos;,&lt;br/&gt;
+            &apos;19	123	rs12345	T	C	50	q10	AF=0.2;NS=2	GT:GQ	1|0:48\n&apos;,&lt;br/&gt;
+        ]&lt;br/&gt;
+    ]&lt;br/&gt;
+&lt;br/&gt;
+    return (malformed_vcf_records, malformed_header_lines)&lt;br/&gt;
+&lt;br/&gt;
   def test_sort_variants(self):&lt;br/&gt;
     sorted_variants = [&lt;br/&gt;
         Variant(reference_name=&apos;a&apos;, start=20, end=22),&lt;br/&gt;
@@ -286,59 +334,33 @@ def test_read_after_splitting(self):&lt;br/&gt;
     self.assertEqual(9882, len(split_records))&lt;/p&gt;

&lt;p&gt;   def test_invalid_file(self):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;invalid_file_contents = [&lt;/li&gt;
	&lt;li&gt;# Malfromed record.&lt;/li&gt;
	&lt;li&gt;[&lt;/li&gt;
	&lt;li&gt;&apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SampleName\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;1    1  &apos;&lt;/li&gt;
	&lt;li&gt;],&lt;/li&gt;
	&lt;li&gt;# Missing &quot;GT:GQ&quot; format, but GQ is provided.&lt;/li&gt;
	&lt;li&gt;[&lt;/li&gt;
	&lt;li&gt;&apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SampleName\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;19	123	rs12345	T	C	50	q10	AF=0.2;NS=2	GT	1|0:48&apos;&lt;/li&gt;
	&lt;li&gt;],&lt;/li&gt;
	&lt;li&gt;# GT is not an integer.&lt;/li&gt;
	&lt;li&gt;[&lt;/li&gt;
	&lt;li&gt;&apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SampleName\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;19	123	rs12345	T	C	50	q10	AF=0.2;NS=2	GT	A|0&apos;&lt;/li&gt;
	&lt;li&gt;],&lt;/li&gt;
	&lt;li&gt;# Malformed FILTER.&lt;/li&gt;
	&lt;li&gt;[&lt;/li&gt;
	&lt;li&gt;&apos;##FILTER=&amp;lt;ID=PASS,Description=&quot;All filters passed&quot;&amp;gt;\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;##FILTER=&amp;lt;ID=LowQual,Descri\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SampleName\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;19	123	rs12345	T	C	50	q10	AF=0.2;NS=2	GT:GQ	1|0:48&apos;,&lt;/li&gt;
	&lt;li&gt;],&lt;/li&gt;
	&lt;li&gt;# Invalid Number value for INFO.&lt;/li&gt;
	&lt;li&gt;[&lt;/li&gt;
	&lt;li&gt;&apos;##INFO=&amp;lt;ID=G,Number=U,Type=String,Description=&quot;InvalidNumber&quot;&amp;gt;\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SampleName\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;19	123	rs12345	T	C	50	q10	AF=0.2;NS=2	GT:GQ	1|0:48\n&apos;,&lt;/li&gt;
	&lt;li&gt;],&lt;/li&gt;
	&lt;li&gt;# POS should be an integer.&lt;/li&gt;
	&lt;li&gt;[&lt;/li&gt;
	&lt;li&gt;&apos;##FILTER=&amp;lt;ID=PASS,Description=&quot;All filters passed&quot;&amp;gt;\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;##FILTER=&amp;lt;ID=LowQual,Descri\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SampleName\n&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;19	abc	rs12345	T	C	50	q10	AF=0.2;NS=2	GT:GQ	1|0:48\n&apos;,&lt;/li&gt;
	&lt;li&gt;],&lt;/li&gt;
	&lt;li&gt;]&lt;/li&gt;
	&lt;li&gt;for content in invalid_file_contents:&lt;/li&gt;
	&lt;li&gt;try:&lt;/li&gt;
	&lt;li&gt;with TempDir() as tempdir:&lt;/li&gt;
	&lt;li&gt;self._read_records(self._create_temp_vcf_file(content, tempdir))&lt;/li&gt;
	&lt;li&gt;self.fail(&apos;Invalid VCF file must throw an exception&apos;)&lt;/li&gt;
	&lt;li&gt;except ValueError:&lt;/li&gt;
	&lt;li&gt;pass&lt;br/&gt;
+    invalid_file_contents = self._get_invalid_file_contents()&lt;br/&gt;
+    for content in chain(*invalid_file_contents):&lt;br/&gt;
+      with TempDir() as tempdir, self.assertRaises(ValueError):&lt;br/&gt;
+        self._read_records(self._create_temp_vcf_file(content, tempdir))&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;Try with multiple files (any one of them will throw an exception).&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;with TempDir() as tempdir:&lt;/li&gt;
	&lt;li&gt;for content in invalid_file_contents:&lt;br/&gt;
+    with TempDir() as tempdir, self.assertRaises(ValueError):&lt;br/&gt;
+      for content in chain(*invalid_file_contents):&lt;br/&gt;
         self._create_temp_vcf_file(content, tempdir)&lt;/li&gt;
	&lt;li&gt;try:&lt;/li&gt;
	&lt;li&gt;self._read_records(os.path.join(tempdir.get_path(), &apos;*.vcf&apos;))&lt;/li&gt;
	&lt;li&gt;self.fail(&apos;Invalid VCF file must throw an exception.&apos;)&lt;/li&gt;
	&lt;li&gt;except ValueError:&lt;/li&gt;
	&lt;li&gt;pass&lt;br/&gt;
+      self._read_records(os.path.join(tempdir.get_path(), &apos;*.vcf&apos;))&lt;br/&gt;
+&lt;br/&gt;
+  def test_allow_malformed_records(self):&lt;br/&gt;
+    invalid_records, invalid_headers = self._get_invalid_file_contents()&lt;br/&gt;
+&lt;br/&gt;
+    # Invalid records should not raise errors&lt;br/&gt;
+    for content in invalid_records:&lt;br/&gt;
+      with TempDir() as tempdir:&lt;br/&gt;
+        records = self._read_records(&lt;br/&gt;
+            self._create_temp_vcf_file(content, tempdir),&lt;br/&gt;
+            allow_malformed_records=True)&lt;br/&gt;
+        for record in records:&lt;br/&gt;
+          self.assertIsInstance(record, MalformedVcfRecord)&lt;br/&gt;
+&lt;br/&gt;
+    # Invalid headers should still raise errors&lt;br/&gt;
+    for content in invalid_headers:&lt;br/&gt;
+      with TempDir() as tempdir, self.assertRaises(ValueError):&lt;br/&gt;
+        self._read_records(self._create_temp_vcf_file(content, tempdir),&lt;br/&gt;
+                           allow_malformed_records=True)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def test_no_samples(self):&lt;br/&gt;
     header_line = &apos;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO\n&apos;&lt;br/&gt;
diff --git a/sdks/python/apache_beam/pipeline.py b/sdks/python/apache_beam/pipeline.py&lt;br/&gt;
index 62626a36489..5725e51a775 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/pipeline.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/pipeline.py&lt;br/&gt;
@@ -521,7 +521,7 @@ def visit_value(self, value, _):&lt;br/&gt;
     self.visit(Visitor())&lt;br/&gt;
     return Visitor.ok&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def to_runner_api(self):&lt;br/&gt;
+  def to_runner_api(self, return_context=False):&lt;br/&gt;
     &quot;&quot;&quot;For internal use only; no backwards-compatibility guarantees.&quot;&quot;&quot;&lt;br/&gt;
     from apache_beam.runners import pipeline_context&lt;br/&gt;
     from apache_beam.portability.api import beam_runner_api_pb2&lt;br/&gt;
@@ -532,10 +532,13 @@ def to_runner_api(self):&lt;br/&gt;
     proto = beam_runner_api_pb2.Pipeline(&lt;br/&gt;
         root_transform_ids=&lt;span class=&quot;error&quot;&gt;&amp;#91;root_transform_id&amp;#93;&lt;/span&gt;,&lt;br/&gt;
         components=context.to_runner_api())&lt;/li&gt;
	&lt;li&gt;return proto&lt;br/&gt;
+    if return_context:&lt;br/&gt;
+      return proto, context&lt;br/&gt;
+    else:&lt;br/&gt;
+      return proto&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @staticmethod&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def from_runner_api(proto, runner, options):&lt;br/&gt;
+  def from_runner_api(proto, runner, options, return_context=False):&lt;br/&gt;
     &quot;&quot;&quot;For internal use only; no backwards-compatibility guarantees.&quot;&quot;&quot;&lt;br/&gt;
     p = Pipeline(runner=runner, options=options)&lt;br/&gt;
     from apache_beam.runners import pipeline_context&lt;br/&gt;
@@ -549,6 +552,8 @@ def from_runner_api(proto, runner, options):&lt;br/&gt;
     for id in proto.components.pcollections:&lt;br/&gt;
       pcollection = context.pcollections.get_by_id(id)&lt;br/&gt;
       pcollection.pipeline = p&lt;br/&gt;
+      if not pcollection.producer:&lt;br/&gt;
+        raise ValueError(&apos;No producer for %s&apos; % id)&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;Inject PBegin input where necessary.&lt;br/&gt;
     from apache_beam.io.iobase import Read&lt;br/&gt;
@@ -559,7 +564,10 @@ def from_runner_api(proto, runner, options):&lt;br/&gt;
       if not transform.inputs and transform.transform._&lt;em&gt;class&lt;/em&gt;_ in has_pbegin:&lt;br/&gt;
         transform.inputs = (pvalue.PBegin(p),)&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return p&lt;br/&gt;
+    if return_context:&lt;br/&gt;
+      return p, context&lt;br/&gt;
+    else:&lt;br/&gt;
+      return p&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; class PipelineVisitor(object):&lt;br/&gt;
@@ -790,10 +798,11 @@ def is_side_input(tag):&lt;br/&gt;
       result.transform.output_tags = set(proto.outputs.keys()).difference(&lt;br/&gt;
           &lt;/p&gt;
{&apos;None&apos;}
&lt;p&gt;)&lt;br/&gt;
     if not result.parts:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;for tag, pc in result.outputs.items():&lt;/li&gt;
	&lt;li&gt;if pc not in result.inputs:&lt;br/&gt;
+      for tag, pcoll_id in proto.outputs.items():&lt;br/&gt;
+        if pcoll_id not in proto.inputs.values():&lt;br/&gt;
+          pc = context.pcollections.get_by_id(pcoll_id)&lt;br/&gt;
           pc.producer = result&lt;/li&gt;
	&lt;li&gt;pc.tag = tag&lt;br/&gt;
+          pc.tag = None if tag == &apos;None&apos; else tag&lt;br/&gt;
     result.update_input_refcounts()&lt;br/&gt;
     return result&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/sdks/python/apache_beam/runners/common.py b/sdks/python/apache_beam/runners/common.py&lt;br/&gt;
index 64abe41a0ad..08ddf6593aa 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/common.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/common.py&lt;br/&gt;
@@ -319,15 +319,9 @@ def _&lt;em&gt;init&lt;/em&gt;_(self,&lt;br/&gt;
                kwargs,&lt;br/&gt;
                side_inputs,&lt;br/&gt;
                windowing,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;context=None,&lt;br/&gt;
                tagged_receivers=None,&lt;/li&gt;
	&lt;li&gt;logger=None,&lt;br/&gt;
                step_name=None,&lt;/li&gt;
	&lt;li&gt;# Preferred alternative to logger&lt;/li&gt;
	&lt;li&gt;# TODO(robertwb): Remove once all runners are updated.&lt;br/&gt;
                logging_context=None,&lt;/li&gt;
	&lt;li&gt;# Preferred alternative to context&lt;/li&gt;
	&lt;li&gt;# TODO(robertwb): Remove once all runners are updated.&lt;br/&gt;
                state=None,&lt;br/&gt;
                scoped_metrics_container=None):&lt;br/&gt;
     &quot;&quot;&quot;Initializes a DoFnRunner.&lt;br/&gt;
@@ -338,45 +332,31 @@ def _&lt;em&gt;init&lt;/em&gt;_(self,&lt;br/&gt;
       kwargs: keyword side input arguments (static and placeholder), if any&lt;br/&gt;
       side_inputs: list of sideinput.SideInputMaps for deferred side inputs&lt;br/&gt;
       windowing: windowing properties of the output PCollection(s)&lt;/li&gt;
	&lt;li&gt;context: a DoFnContext to use (deprecated)&lt;br/&gt;
       tagged_receivers: a dict of tag name to Receiver objects&lt;/li&gt;
	&lt;li&gt;logger: a logging module (deprecated)&lt;br/&gt;
       step_name: the name of this step&lt;br/&gt;
       logging_context: a LoggingContext object&lt;br/&gt;
       state: handle for accessing DoFn state&lt;br/&gt;
       scoped_metrics_container: Context switcher for metrics container&lt;br/&gt;
     &quot;&quot;&quot;&lt;/li&gt;
	&lt;li&gt;self.scoped_metrics_container = (scoped_metrics_container&lt;/li&gt;
	&lt;li&gt;or ScopedMetricsContainer())&lt;/li&gt;
	&lt;li&gt;self.step_name = step_name&lt;br/&gt;
-&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;Need to support multiple iterations.&lt;br/&gt;
     side_inputs = list(side_inputs)&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;if logging_context:&lt;/li&gt;
	&lt;li&gt;self.logging_context = logging_context&lt;/li&gt;
	&lt;li&gt;else:&lt;/li&gt;
	&lt;li&gt;self.logging_context = get_logging_context(logger, step_name=step_name)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;# TODO(sourabh): Deprecate the use of context&lt;/li&gt;
	&lt;li&gt;if state:&lt;/li&gt;
	&lt;li&gt;assert context is None&lt;/li&gt;
	&lt;li&gt;context = DoFnContext(step_name, state=state)&lt;/li&gt;
	&lt;li&gt;else:&lt;/li&gt;
	&lt;li&gt;assert context is not None&lt;/li&gt;
	&lt;li&gt;context = context&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;self.context = context&lt;br/&gt;
+    self.scoped_metrics_container = (&lt;br/&gt;
+        scoped_metrics_container or ScopedMetricsContainer())&lt;br/&gt;
+    self.step_name = step_name&lt;br/&gt;
+    self.logging_context = logging_context or LoggingContext()&lt;br/&gt;
+    self.context = DoFnContext(step_name, state=state)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     do_fn_signature = DoFnSignature(fn)&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Optimize for the common case.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;main_receivers = as_receiver(tagged_receivers&lt;span class=&quot;error&quot;&gt;&amp;#91;None&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+    main_receivers = tagged_receivers&lt;span class=&quot;error&quot;&gt;&amp;#91;None&amp;#93;&lt;/span&gt;&lt;br/&gt;
     output_processor = _OutputProcessor(&lt;br/&gt;
         windowing.windowfn, main_receivers, tagged_receivers)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     self.do_fn_invoker = DoFnInvoker.create_invoker(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;output_processor, do_fn_signature, context, side_inputs, args, kwargs)&lt;br/&gt;
+        output_processor, do_fn_signature, self.context,&lt;br/&gt;
+        side_inputs, args, kwargs)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def receive(self, windowed_value):&lt;br/&gt;
     self.process(windowed_value)&lt;br/&gt;
@@ -479,7 +459,7 @@ def process_outputs(self, windowed_input_element, results):&lt;br/&gt;
       if tag is None:&lt;br/&gt;
         self.main_receivers.receive(windowed_value)&lt;br/&gt;
       else:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;self.tagged_receivers&lt;span class=&quot;error&quot;&gt;&amp;#91;tag&amp;#93;&lt;/span&gt;.output(windowed_value)&lt;br/&gt;
+        self.tagged_receivers&lt;span class=&quot;error&quot;&gt;&amp;#91;tag&amp;#93;&lt;/span&gt;.receive(windowed_value)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def start_bundle_outputs(self, results):&lt;br/&gt;
     &quot;&quot;&quot;Validate that start_bundle does not output any elements&quot;&quot;&quot;&lt;br/&gt;
@@ -514,7 +494,7 @@ def finish_bundle_outputs(self, results):&lt;br/&gt;
       if tag is None:&lt;br/&gt;
         self.main_receivers.receive(windowed_value)&lt;br/&gt;
       else:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;self.tagged_receivers&lt;span class=&quot;error&quot;&gt;&amp;#91;tag&amp;#93;&lt;/span&gt;.output(windowed_value)&lt;br/&gt;
+        self.tagged_receivers&lt;span class=&quot;error&quot;&gt;&amp;#91;tag&amp;#93;&lt;/span&gt;.receive(windowed_value)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; class _NoContext(WindowFn.AssignContext):&lt;br/&gt;
@@ -586,42 +566,3 @@ def windows(self):&lt;br/&gt;
       raise AttributeError(&apos;windows not accessible in this context&apos;)&lt;br/&gt;
     else:&lt;br/&gt;
       return self.windowed_value.windows&lt;br/&gt;
-&lt;br/&gt;
-&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;TODO(robertwb): Remove all these adapters once service is updated out.&lt;br/&gt;
-class _LoggingContextAdapter(LoggingContext):&lt;br/&gt;
-&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
	&lt;li&gt;def _&lt;em&gt;init&lt;/em&gt;_(self, underlying):&lt;/li&gt;
	&lt;li&gt;self.underlying = underlying&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def enter(self):&lt;/li&gt;
	&lt;li&gt;self.underlying.enter()&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def exit(self):&lt;/li&gt;
	&lt;li&gt;self.underlying.exit()&lt;br/&gt;
-&lt;br/&gt;
-&lt;br/&gt;
-def get_logging_context(maybe_logger, **kwargs):&lt;/li&gt;
	&lt;li&gt;if maybe_logger:&lt;/li&gt;
	&lt;li&gt;maybe_context = maybe_logger.PerThreadLoggingContext(**kwargs)&lt;/li&gt;
	&lt;li&gt;if isinstance(maybe_context, LoggingContext):&lt;/li&gt;
	&lt;li&gt;return maybe_context&lt;/li&gt;
	&lt;li&gt;return _LoggingContextAdapter(maybe_context)&lt;/li&gt;
	&lt;li&gt;return LoggingContext()&lt;br/&gt;
-&lt;br/&gt;
-&lt;br/&gt;
-class _ReceiverAdapter(Receiver):&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def _&lt;em&gt;init&lt;/em&gt;_(self, underlying):&lt;/li&gt;
	&lt;li&gt;self.underlying = underlying&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def receive(self, windowed_value):&lt;/li&gt;
	&lt;li&gt;self.underlying.output(windowed_value)&lt;br/&gt;
-&lt;br/&gt;
-&lt;br/&gt;
-def as_receiver(maybe_receiver):&lt;/li&gt;
	&lt;li&gt;&quot;&quot;&quot;For internal use only; no backwards-compatibility guarantees.&quot;&quot;&quot;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;if isinstance(maybe_receiver, Receiver):&lt;/li&gt;
	&lt;li&gt;return maybe_receiver&lt;/li&gt;
	&lt;li&gt;return _ReceiverAdapter(maybe_receiver)&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py b/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py&lt;br/&gt;
index 6253c80f83b..38c6df1ab12 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/dataflow/dataflow_runner.py&lt;br/&gt;
@@ -936,7 +936,7 @@ def _is_in_terminal_state(self):&lt;br/&gt;
     return self._job.currentState in [&lt;br/&gt;
         values_enum.JOB_STATE_STOPPED, values_enum.JOB_STATE_DONE,&lt;br/&gt;
         values_enum.JOB_STATE_FAILED, values_enum.JOB_STATE_CANCELLED,&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;values_enum.JOB_STATE_DRAINED]&lt;br/&gt;
+        values_enum.JOB_STATE_UPDATED, values_enum.JOB_STATE_DRAINED]&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def wait_until_finish(self, duration=None):&lt;br/&gt;
     if not self._is_in_terminal_state():&lt;br/&gt;
@@ -957,7 +957,7 @@ def wait_until_finish(self, duration=None):&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;TODO: Merge the termination code in poll_for_job_completion and&lt;/li&gt;
	&lt;li&gt;_is_in_terminal_state.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;terminated = (str(self._job.currentState) != &apos;JOB_STATE_RUNNING&apos;)&lt;br/&gt;
+      terminated = self._is_in_terminal_state()&lt;br/&gt;
       assert duration or terminated, (&lt;br/&gt;
           &apos;Job did not reach to a terminal state after waiting indefinitely.&apos;)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py b/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py&lt;br/&gt;
index 64c4ac98ac2..dd6bf95706e 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/dataflow/internal/apiclient.py&lt;br/&gt;
@@ -569,7 +569,7 @@ def modify_job_state(self, job_id, new_state):&lt;br/&gt;
     request.location = self.google_cloud_options.region&lt;br/&gt;
     request.job = dataflow.Job(requestedState=new_state)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;self._client.projects_jobs.Update(request)&lt;br/&gt;
+    self._client.projects_locations_jobs.Update(request)&lt;br/&gt;
     return True&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @retry.with_exponential_backoff()  # Using retry defaults from utils/retry.py&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/dataflow/internal/clients/dataflow/dataflow_v1b3_messages.py b/sdks/python/apache_beam/runners/dataflow/internal/clients/dataflow/dataflow_v1b3_messages.py&lt;br/&gt;
index b0d4e44816c..6c55d4e830f 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/dataflow/internal/clients/dataflow/dataflow_v1b3_messages.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/dataflow/internal/clients/dataflow/dataflow_v1b3_messages.py&lt;br/&gt;
@@ -16,7 +16,6 @@&lt;br/&gt;
 #&lt;/p&gt;

&lt;p&gt; &quot;&quot;&quot;Generated message classes for dataflow version v1b3.&lt;br/&gt;
-&lt;br/&gt;
 Develops and executes data processing patterns like ETL, batch computation,&lt;br/&gt;
 and continuous computation.&lt;br/&gt;
 &quot;&quot;&quot;&lt;br/&gt;
@@ -347,11 +346,19 @@ class CounterStructuredName(_messages.Message):&lt;br/&gt;
       workers.&lt;br/&gt;
     executionStepName: Name of the stage. An execution step contains multiple&lt;br/&gt;
       component steps.&lt;br/&gt;
+    inputIndex: Index of an input collection that&apos;s being read from/written to&lt;br/&gt;
+      as a side input. The index identifies a step&apos;s side inputs starting by 1&lt;br/&gt;
+      (e.g. the first side input has input_index 1, the third has input_index&lt;br/&gt;
+      3). Side inputs are identified by a pair of (original_step_name,&lt;br/&gt;
+      input_index). This field helps uniquely identify them.&lt;br/&gt;
     name: Counter name. Not necessarily globally-unique, but unique within the&lt;br/&gt;
       context of the other fields. Required.&lt;br/&gt;
     origin: One of the standard Origins defined above.&lt;br/&gt;
     originNamespace: A string containing a more specific namespace of the&lt;br/&gt;
       counter&apos;s origin.&lt;br/&gt;
+    originalRequestingStepName: The step name requesting an operation, such as&lt;br/&gt;
+      GBK. I.e. the ParDo causing a read/write from shuffle to occur, or a&lt;br/&gt;
+      read from side inputs.&lt;br/&gt;
     originalStepName: System generated name of the original step in the user&apos;s&lt;br/&gt;
       graph, before optimization.&lt;br/&gt;
     portion: Portion of this counter, either key or value.&lt;br/&gt;
@@ -382,12 +389,14 @@ class PortionValueValuesEnum(_messages.Enum):&lt;/p&gt;

&lt;p&gt;   componentStepName = _messages.StringField(1)&lt;br/&gt;
   executionStepName = _messages.StringField(2)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;name = _messages.StringField(3)&lt;/li&gt;
	&lt;li&gt;origin = _messages.EnumField(&apos;OriginValueValuesEnum&apos;, 4)&lt;/li&gt;
	&lt;li&gt;originNamespace = _messages.StringField(5)&lt;/li&gt;
	&lt;li&gt;originalStepName = _messages.StringField(6)&lt;/li&gt;
	&lt;li&gt;portion = _messages.EnumField(&apos;PortionValueValuesEnum&apos;, 7)&lt;/li&gt;
	&lt;li&gt;workerId = _messages.StringField(8)&lt;br/&gt;
+  inputIndex = _messages.IntegerField(3, variant=_messages.Variant.INT32)&lt;br/&gt;
+  name = _messages.StringField(4)&lt;br/&gt;
+  origin = _messages.EnumField(&apos;OriginValueValuesEnum&apos;, 5)&lt;br/&gt;
+  originNamespace = _messages.StringField(6)&lt;br/&gt;
+  originalRequestingStepName = _messages.StringField(7)&lt;br/&gt;
+  originalStepName = _messages.StringField(8)&lt;br/&gt;
+  portion = _messages.EnumField(&apos;PortionValueValuesEnum&apos;, 9)&lt;br/&gt;
+  workerId = _messages.StringField(10)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; class CounterStructuredNameAndMetadata(_messages.Message):&lt;br/&gt;
@@ -1401,8 +1410,7 @@ class DistributionUpdate(_messages.Message):&lt;/p&gt;

&lt;p&gt;   Fields:&lt;br/&gt;
     count: The count of the number of elements present in the distribution.&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;logBuckets: (Optional) Logarithmic histogram of values. Each log may be in&lt;/li&gt;
	&lt;li&gt;no more than one bucket. Order does not matter.&lt;br/&gt;
+    histogram: (Optional) Histogram of value counts for the distribution.&lt;br/&gt;
     max: The maximum value present in the distribution.&lt;br/&gt;
     min: The minimum value present in the distribution.&lt;br/&gt;
     sum: Use an int64 since we&apos;d prefer the added precision. If overflow is a&lt;br/&gt;
@@ -1412,7 +1420,7 @@ class DistributionUpdate(_messages.Message):&lt;br/&gt;
   &quot;&quot;&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   count = _messages.MessageField(&apos;SplitInt64&apos;, 1)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;logBuckets = _messages.MessageField(&apos;LogBucket&apos;, 2, repeated=True)&lt;br/&gt;
+  histogram = _messages.MessageField(&apos;Histogram&apos;, 2)&lt;br/&gt;
   max = _messages.MessageField(&apos;SplitInt64&apos;, 3)&lt;br/&gt;
   min = _messages.MessageField(&apos;SplitInt64&apos;, 4)&lt;br/&gt;
   sum = _messages.MessageField(&apos;SplitInt64&apos;, 5)&lt;br/&gt;
@@ -1808,6 +1816,27 @@ class GetTemplateResponse(_messages.Message):&lt;br/&gt;
   status = _messages.MessageField(&apos;Status&apos;, 2)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;+class Histogram(_messages.Message):&lt;br/&gt;
+  &quot;&quot;&quot;Histogram of value counts for a distribution.  Buckets have an inclusive&lt;br/&gt;
+  lower bound and exclusive upper bound and use &quot;1,2,5 bucketing&quot;: The first&lt;br/&gt;
+  bucket range is from [0,1) and all subsequent bucket boundaries are powers&lt;br/&gt;
+  of ten multiplied by 1, 2, or 5. Thus, bucket boundaries are 0, 1, 2, 5, 10,&lt;br/&gt;
+  20, 50, 100, 200, 500, 1000, ... Negative values are not supported.&lt;br/&gt;
+&lt;br/&gt;
+  Fields:&lt;br/&gt;
+    bucketCounts: Counts of values in each bucket. For efficiency, prefix and&lt;br/&gt;
+      trailing buckets with count = 0 are elided. Buckets can store the full&lt;br/&gt;
+      range of values of an unsigned long, with ULLONG_MAX falling into the&lt;br/&gt;
+      59th bucket with range [1e19, 2e19).&lt;br/&gt;
+    firstBucketOffset: Starting index of first stored bucket. The non-&lt;br/&gt;
+      inclusive upper-bound of the ith bucket is given by:&lt;br/&gt;
+      pow(10,(i-first_bucket_offset)/3) * (1,2,5)&lt;span class=&quot;error&quot;&gt;&amp;#91;(i-first_bucket_offset)%3&amp;#93;&lt;/span&gt;&lt;br/&gt;
+  &quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+  bucketCounts = _messages.IntegerField(1, repeated=True)&lt;br/&gt;
+  firstBucketOffset = _messages.IntegerField(2, variant=_messages.Variant.INT32)&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
 class InstructionInput(_messages.Message):&lt;br/&gt;
   &quot;&quot;&quot;An input of an instruction, as a reference to an output of a producer&lt;br/&gt;
   instruction.&lt;br/&gt;
@@ -2493,20 +2522,6 @@ class ListJobsResponse(_messages.Message):&lt;br/&gt;
   nextPageToken = _messages.StringField(3)&lt;/p&gt;


&lt;p&gt;-class LogBucket(_messages.Message):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;&quot;&quot;Bucket of values for Distribution&apos;s logarithmic histogram.&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;Fields:&lt;/li&gt;
	&lt;li&gt;count: Number of values in this bucket.&lt;/li&gt;
	&lt;li&gt;log: floor(log2(value)); defined to be zero for nonpositive values.&lt;/li&gt;
	&lt;li&gt;log(-1) = 0   log(0) = 0   log(1) = 0   log(2) = 1   log(3) = 1   log(4)&lt;/li&gt;
	&lt;li&gt;= 2   log(5) = 2&lt;/li&gt;
	&lt;li&gt;&quot;&quot;&quot;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;count = _messages.IntegerField(1)&lt;/li&gt;
	&lt;li&gt;log = _messages.IntegerField(2, variant=_messages.Variant.INT32)&lt;br/&gt;
-&lt;br/&gt;
-&lt;br/&gt;
 class MapTask(_messages.Message):&lt;br/&gt;
   &quot;&quot;&quot;MapTask consists of an ordered set of instructions, each of which&lt;br/&gt;
   describes one particular low-level operation for the worker to perform in&lt;br/&gt;
@@ -3068,6 +3083,7 @@ class ResourceUtilizationReportResponse(_messages.Message):&lt;br/&gt;
   &quot;&quot;&quot;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;+&lt;br/&gt;
 class RuntimeEnvironment(_messages.Message):&lt;br/&gt;
   &quot;&quot;&quot;The environment values to set at runtime.&lt;/p&gt;

&lt;p&gt;@@ -3501,11 +3517,22 @@ class SourceOperationRequest(_messages.Message):&lt;/p&gt;

&lt;p&gt;   Fields:&lt;br/&gt;
     getMetadata: Information about a request to get metadata about a source.&lt;br/&gt;
+    name: User-provided name of the Read instruction for this source.&lt;br/&gt;
+    originalName: System-defined name for the Read instruction for this source&lt;br/&gt;
+      in the original workflow graph.&lt;br/&gt;
     split: Information about a request to split a source.&lt;br/&gt;
+    stageName: System-defined name of the stage containing the source&lt;br/&gt;
+      operation. Unique across the workflow.&lt;br/&gt;
+    systemName: System-defined name of the Read instruction for this source.&lt;br/&gt;
+      Unique across the workflow.&lt;br/&gt;
   &quot;&quot;&quot;&lt;/p&gt;

&lt;p&gt;   getMetadata = _messages.MessageField(&apos;SourceGetMetadataRequest&apos;, 1)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;split = _messages.MessageField(&apos;SourceSplitRequest&apos;, 2)&lt;br/&gt;
+  name = _messages.StringField(2)&lt;br/&gt;
+  originalName = _messages.StringField(3)&lt;br/&gt;
+  split = _messages.MessageField(&apos;SourceSplitRequest&apos;, 4)&lt;br/&gt;
+  stageName = _messages.StringField(5)&lt;br/&gt;
+  systemName = _messages.StringField(6)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; class SourceOperationResponse(_messages.Message):&lt;br/&gt;
@@ -4426,6 +4453,8 @@ class WorkItemStatus(_messages.Message):&lt;br/&gt;
       progress and proposed_stop_position should be interpreted relative to P,&lt;br/&gt;
       and in a potential subsequent dynamic_source_split into &lt;/p&gt;
{P&apos;, R&apos;}
&lt;p&gt;, P&apos; and&lt;br/&gt;
       R&apos; must be together equivalent to P, etc.&lt;br/&gt;
+    totalThrottlerWaitTimeSeconds: Total time the worker spent being throttled&lt;br/&gt;
+      by external systems.&lt;br/&gt;
     workItemId: Identifies the WorkItem.&lt;br/&gt;
   &quot;&quot;&quot;&lt;/p&gt;

&lt;p&gt;@@ -4441,7 +4470,8 @@ class WorkItemStatus(_messages.Message):&lt;br/&gt;
   sourceFork = _messages.MessageField(&apos;SourceFork&apos;, 10)&lt;br/&gt;
   sourceOperationResponse = _messages.MessageField(&apos;SourceOperationResponse&apos;, 11)&lt;br/&gt;
   stopPosition = _messages.MessageField(&apos;Position&apos;, 12)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;workItemId = _messages.StringField(13)&lt;br/&gt;
+  totalThrottlerWaitTimeSeconds = _messages.FloatField(13)&lt;br/&gt;
+  workItemId = _messages.StringField(14)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; class WorkerHealthReport(_messages.Message):&lt;br/&gt;
@@ -4532,6 +4562,7 @@ class WorkerMessage(_messages.Message):&lt;br/&gt;
     workerHealthReport: The health of a worker.&lt;br/&gt;
     workerMessageCode: A worker message code.&lt;br/&gt;
     workerMetrics: Resource metrics reported by workers.&lt;br/&gt;
+    workerShutdownNotice: Shutdown notice by workers.&lt;br/&gt;
   &quot;&quot;&quot;&lt;/p&gt;

&lt;p&gt;   @encoding.MapUnrecognizedFields(&apos;additionalProperties&apos;)&lt;br/&gt;
@@ -4568,6 +4599,7 @@ class AdditionalProperty(_messages.Message):&lt;br/&gt;
   workerHealthReport = _messages.MessageField(&apos;WorkerHealthReport&apos;, 3)&lt;br/&gt;
   workerMessageCode = _messages.MessageField(&apos;WorkerMessageCode&apos;, 4)&lt;br/&gt;
   workerMetrics = _messages.MessageField(&apos;ResourceUtilizationReport&apos;, 5)&lt;br/&gt;
+  workerShutdownNotice = _messages.MessageField(&apos;WorkerShutdownNotice&apos;, 6)&lt;/p&gt;


&lt;p&gt; class WorkerMessageCode(_messages.Message):&lt;br/&gt;
@@ -4664,10 +4696,13 @@ class WorkerMessageResponse(_messages.Message):&lt;br/&gt;
       report.&lt;br/&gt;
     workerMetricsResponse: Service&apos;s response to reporting worker metrics&lt;br/&gt;
       (currently empty).&lt;br/&gt;
+    workerShutdownNoticeResponse: Service&apos;s response to shutdown notice&lt;br/&gt;
+      (currently empty).&lt;br/&gt;
   &quot;&quot;&quot;&lt;/p&gt;

&lt;p&gt;   workerHealthReportResponse = _messages.MessageField(&apos;WorkerHealthReportResponse&apos;, 1)&lt;br/&gt;
   workerMetricsResponse = _messages.MessageField(&apos;ResourceUtilizationReportResponse&apos;, 2)&lt;br/&gt;
+  workerShutdownNoticeResponse = _messages.MessageField(&apos;WorkerShutdownNoticeResponse&apos;, 3)&lt;/p&gt;


&lt;p&gt; class WorkerPool(_messages.Message):&lt;br/&gt;
@@ -4913,6 +4948,24 @@ class WorkerSettings(_messages.Message):&lt;br/&gt;
   workerId = _messages.StringField(6)&lt;/p&gt;


&lt;p&gt;+class WorkerShutdownNotice(_messages.Message):&lt;br/&gt;
+  &quot;&quot;&quot;Shutdown notification from workers. This is to be sent by the shutdown&lt;br/&gt;
+  script of the worker VM so that the backend knows that the VM is being shut&lt;br/&gt;
+  down.&lt;br/&gt;
+&lt;br/&gt;
+  Fields:&lt;br/&gt;
+    reason: The reason for the worker shutdown. Current possible values are:&lt;br/&gt;
+      &quot;UNKNOWN&quot;: shutdown reason is unknown.   &quot;PREEMPTION&quot;: shutdown reason&lt;br/&gt;
+      is preemption. Other possible reasons may be added in the future.&lt;br/&gt;
+  &quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+  reason = _messages.StringField(1)&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+class WorkerShutdownNoticeResponse(_messages.Message):&lt;br/&gt;
+  &quot;&quot;&quot;Service-side response to WorkerMessage issuing shutdown notice.&quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
 class WriteInstruction(_messages.Message):&lt;br/&gt;
   &quot;&quot;&quot;An instruction that writes records. Takes one input, produces no outputs.&lt;/p&gt;

&lt;p&gt;diff --git a/sdks/python/apache_beam/runners/dataflow/internal/names.py b/sdks/python/apache_beam/runners/dataflow/internal/names.py&lt;br/&gt;
index 559b445f432..6b0fa001365 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/dataflow/internal/names.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/dataflow/internal/names.py&lt;br/&gt;
@@ -17,7 +17,7 @@&lt;/p&gt;

&lt;p&gt; &quot;&quot;&quot;Various names for properties, transforms, etc.&quot;&quot;&quot;&lt;/p&gt;

&lt;p&gt;-&lt;br/&gt;
+# TODO (altay): Move shared names to a common location.&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Standard file names used for staging files.&lt;br/&gt;
 PICKLED_MAIN_SESSION_FILE = &apos;pickled_main_session&apos;&lt;br/&gt;
 DATAFLOW_SDK_TARBALL_FILE = &apos;dataflow_python_sdk.tar&apos;&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/direct/bundle_factory.py b/sdks/python/apache_beam/runners/direct/bundle_factory.py&lt;br/&gt;
index 0182b4c9e9c..942d2824dbf 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/runners/direct/bundle_factory.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/direct/bundle_factory.py&lt;br/&gt;
@@ -20,6 +20,7 @@&lt;br/&gt;
 from _&lt;em&gt;future&lt;/em&gt;_ import absolute_import&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt; from apache_beam import pvalue&lt;br/&gt;
+from apache_beam.runners import common&lt;br/&gt;
 from apache_beam.utils.windowed_value import WindowedValue&lt;/p&gt;


&lt;p&gt;@@ -47,7 +48,7 @@ def create_empty_committed_bundle(self, output_pcollection):&lt;/p&gt;


&lt;ol&gt;
	&lt;li&gt;a bundle represents a unit of work that will be processed by a transform.&lt;br/&gt;
-class _Bundle(object):&lt;br/&gt;
+class _Bundle(common.Receiver):&lt;br/&gt;
   &quot;&quot;&quot;Part of a PCollection with output elements.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   Part of a PCollection. Elements are output to a bundle, which will cause them&lt;br/&gt;
@@ -185,6 +186,9 @@ def add(self, element):&lt;br/&gt;
   def output(self, element):&lt;br/&gt;
     self.add(element)&lt;/p&gt;

&lt;p&gt;+  def receive(self, element):&lt;br/&gt;
+    self.add(element)&lt;br/&gt;
+&lt;br/&gt;
   def commit(self, synchronized_processing_time):&lt;br/&gt;
     &quot;&quot;&quot;Commits this bundle.&lt;/p&gt;

&lt;p&gt;diff --git a/sdks/python/apache_beam/runners/direct/clock.py b/sdks/python/apache_beam/runners/direct/clock.py&lt;br/&gt;
index 84d52f79948..ad079941466 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/direct/clock.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/direct/clock.py&lt;br/&gt;
@@ -15,36 +15,37 @@&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
 #&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;-&quot;&quot;&quot;Clock implementations for real time processing and testing.&quot;&quot;&quot;&lt;br/&gt;
+&quot;&quot;&quot;Clock implementations for real time processing and testing.&lt;/p&gt;

&lt;p&gt;+For internal use only. No backwards compatibility guarantees.&lt;br/&gt;
+&quot;&quot;&quot;&lt;br/&gt;
 from _&lt;em&gt;future&lt;/em&gt;_ import absolute_import&lt;/p&gt;

&lt;p&gt; import time&lt;/p&gt;


&lt;p&gt; class Clock(object):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;&quot;&quot;For internal use only; no backwards-compatibility guarantees.&quot;&quot;&quot;&lt;br/&gt;
-&lt;br/&gt;
   def time(self):&lt;/li&gt;
	&lt;li&gt;&quot;&quot;&quot;Returns the number of milliseconds since epoch.&quot;&quot;&quot;&lt;/li&gt;
	&lt;li&gt;return int(time.time() * 1000)&lt;br/&gt;
+    &quot;&quot;&quot;Returns the number of seconds since epoch.&quot;&quot;&quot;&lt;br/&gt;
+    raise NotImplementedError()&lt;br/&gt;
+&lt;br/&gt;
+  def advance_time(self, advance_by):&lt;br/&gt;
+    &quot;&quot;&quot;Advances the clock by a number of seconds.&quot;&quot;&quot;&lt;br/&gt;
+    raise NotImplementedError()&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-class MockClock(Clock):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;&quot;&quot;For internal use only; no backwards-compatibility guarantees.&lt;br/&gt;
+class RealClock(object):&lt;br/&gt;
+  def time(self):&lt;br/&gt;
+    return time.time()&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Mock clock implementation for testing.&quot;&quot;&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def _&lt;em&gt;init&lt;/em&gt;_(self, now_in_ms):&lt;/li&gt;
	&lt;li&gt;self._now_in_ms = now_in_ms&lt;br/&gt;
+class TestClock(object):&lt;br/&gt;
+  &quot;&quot;&quot;Clock used for Testing&quot;&quot;&quot;&lt;br/&gt;
+  def _&lt;em&gt;init&lt;/em&gt;_(self, current_time=0):&lt;br/&gt;
+    self._current_time = current_time&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def time(self):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return self._now_in_ms&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def set_time(self, value_in_ms):&lt;/li&gt;
	&lt;li&gt;assert value_in_ms &amp;gt;= self._now_in_ms&lt;/li&gt;
	&lt;li&gt;self._now_in_ms = value_in_ms&lt;br/&gt;
+    return self._current_time&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def advance(self, duration_in_ms):&lt;/li&gt;
	&lt;li&gt;assert duration_in_ms &amp;gt;= 0&lt;/li&gt;
	&lt;li&gt;self._now_in_ms += duration_in_ms&lt;br/&gt;
+  def advance_time(self, advance_by):&lt;br/&gt;
+    self._current_time += advance_by&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/direct/direct_runner.py b/sdks/python/apache_beam/runners/direct/direct_runner.py&lt;br/&gt;
index 794a96be12b..053584a2a2a 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/runners/direct/direct_runner.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/direct/direct_runner.py&lt;br/&gt;
@@ -36,6 +36,8 @@&lt;br/&gt;
 from apache_beam.options.value_provider import RuntimeValueProvider&lt;br/&gt;
 from apache_beam.pvalue import PCollection&lt;br/&gt;
 from apache_beam.runners.direct.bundle_factory import BundleFactory&lt;br/&gt;
+from apache_beam.runners.direct.clock import RealClock&lt;br/&gt;
+from apache_beam.runners.direct.clock import TestClock&lt;br/&gt;
 from apache_beam.runners.runner import PipelineResult&lt;br/&gt;
 from apache_beam.runners.runner import PipelineRunner&lt;br/&gt;
 from apache_beam.runners.runner import PipelineState&lt;br/&gt;
@@ -90,15 +92,14 @@ class DirectRunner(PipelineRunner):&lt;br/&gt;
   &quot;&quot;&quot;Executes a single pipeline on the local machine.&quot;&quot;&quot;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;A list of PTransformOverride objects to be applied before running a pipeline&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;# using DirectRunner.&lt;/li&gt;
	&lt;li&gt;# Currently this only works for overrides where the input and output types do&lt;/li&gt;
	&lt;li&gt;# not change.&lt;/li&gt;
	&lt;li&gt;# For internal SDK use only. This should not be updated by Beam pipeline&lt;/li&gt;
	&lt;li&gt;# authors.&lt;br/&gt;
+  # using DirectRunner. Currently, this only works for overrides where the input&lt;br/&gt;
+  # and output types do not change.&lt;br/&gt;
+  # For internal use only; no backwards-compatibility guarantees.&lt;br/&gt;
   _PTRANSFORM_OVERRIDES = []&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def _&lt;em&gt;init&lt;/em&gt;_(self):&lt;br/&gt;
     self._cache = None&lt;br/&gt;
+    self._use_test_clock = False  # use RealClock() in production&lt;/p&gt;

&lt;p&gt;   def apply_CombinePerKey(self, transform, pcoll):&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;TODO: Move imports to top. Pipeline &amp;lt;-&amp;gt; Runner dependency cause problems&lt;br/&gt;
@@ -111,6 +112,10 @@ def apply_CombinePerKey(self, transform, pcoll):&lt;br/&gt;
     except NotImplementedError:&lt;br/&gt;
       return transform.expand(pcoll)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;+  def apply_TestStream(self, transform, pcoll):&lt;br/&gt;
+    self._use_test_clock = True  # use TestClock() for testing&lt;br/&gt;
+    return transform.expand(pcoll)&lt;br/&gt;
+&lt;br/&gt;
   def apply__GroupByKeyOnly(self, transform, pcoll):&lt;br/&gt;
     if (transform._&lt;em&gt;class&lt;/em&gt;_ == _GroupByKeyOnly and&lt;br/&gt;
         pcoll.pipeline._options.view_as(StandardOptions).streaming):&lt;br/&gt;
@@ -204,6 +209,7 @@ def run(self, pipeline):&lt;br/&gt;
     self.consumer_tracking_visitor = ConsumerTrackingPipelineVisitor()&lt;br/&gt;
     pipeline.visit(self.consumer_tracking_visitor)&lt;/p&gt;

&lt;p&gt;+    clock = TestClock() if self._use_test_clock else RealClock()&lt;br/&gt;
     evaluation_context = EvaluationContext(&lt;br/&gt;
         pipeline._options,&lt;br/&gt;
         BundleFactory(stacked=pipeline._options.view_as(DirectOptions)&lt;br/&gt;
@@ -211,7 +217,8 @@ def run(self, pipeline):&lt;br/&gt;
         self.consumer_tracking_visitor.root_transforms,&lt;br/&gt;
         self.consumer_tracking_visitor.value_to_consumers,&lt;br/&gt;
         self.consumer_tracking_visitor.step_names,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;self.consumer_tracking_visitor.views)&lt;br/&gt;
+        self.consumer_tracking_visitor.views,&lt;br/&gt;
+        clock)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     evaluation_context.use_pvalue_cache(self._cache)&lt;/p&gt;

&lt;p&gt;diff --git a/sdks/python/apache_beam/runners/direct/evaluation_context.py b/sdks/python/apache_beam/runners/direct/evaluation_context.py&lt;br/&gt;
index abb2dc470ed..718dafa5d70 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/direct/evaluation_context.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/direct/evaluation_context.py&lt;br/&gt;
@@ -22,7 +22,6 @@&lt;br/&gt;
 import collections&lt;br/&gt;
 import threading&lt;/p&gt;

&lt;p&gt;-from apache_beam.runners.direct.clock import Clock&lt;br/&gt;
 from apache_beam.runners.direct.direct_metrics import DirectMetrics&lt;br/&gt;
 from apache_beam.runners.direct.executor import TransformExecutor&lt;br/&gt;
 from apache_beam.runners.direct.watermark_manager import WatermarkManager&lt;br/&gt;
@@ -138,7 +137,7 @@ class EvaluationContext(object):&lt;br/&gt;
   &quot;&quot;&quot;&lt;/p&gt;

&lt;p&gt;   def _&lt;em&gt;init&lt;/em&gt;_(self, pipeline_options, bundle_factory, root_transforms,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;value_to_consumers, step_names, views):&lt;br/&gt;
+               value_to_consumers, step_names, views, clock):&lt;br/&gt;
     self.pipeline_options = pipeline_options&lt;br/&gt;
     self._bundle_factory = bundle_factory&lt;br/&gt;
     self._root_transforms = root_transforms&lt;br/&gt;
@@ -151,7 +150,7 @@ def _&lt;em&gt;init&lt;/em&gt;_(self, pipeline_options, bundle_factory, root_transforms,&lt;br/&gt;
     self._transform_keyed_states = self._initialize_keyed_states(&lt;br/&gt;
         root_transforms, value_to_consumers)&lt;br/&gt;
     self._watermark_manager = WatermarkManager(&lt;/li&gt;
	&lt;li&gt;Clock(), root_transforms, value_to_consumers,&lt;br/&gt;
+        clock, root_transforms, value_to_consumers,&lt;br/&gt;
         self._transform_keyed_states)&lt;br/&gt;
     self._side_inputs_container = _SideInputsContainer(views)&lt;br/&gt;
     self._pending_unblocked_tasks = []&lt;br/&gt;
@@ -286,8 +285,8 @@ def create_empty_committed_bundle(self, output_pcollection):&lt;br/&gt;
     return self._bundle_factory.create_empty_committed_bundle(&lt;br/&gt;
         output_pcollection)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def extract_fired_timers(self):&lt;/li&gt;
	&lt;li&gt;return self._watermark_manager.extract_fired_timers()&lt;br/&gt;
+  def extract_all_timers(self):&lt;br/&gt;
+    return self._watermark_manager.extract_all_timers()&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def is_done(self, transform=None):&lt;br/&gt;
     &quot;&quot;&quot;Checks completion of a step or the pipeline.&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/direct/executor.py b/sdks/python/apache_beam/runners/direct/executor.py&lt;br/&gt;
index 853f19f81f0..93490536ed8 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/direct/executor.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/direct/executor.py&lt;br/&gt;
@@ -545,22 +545,19 @@ def call(self):&lt;br/&gt;
           self._executor.executor_service.submit(self)&lt;/p&gt;

&lt;p&gt;     def _should_shutdown(self):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;&quot;&quot;_should_shutdown checks whether pipeline is completed or not.&lt;br/&gt;
+      &quot;&quot;&quot;Checks whether the pipeline is completed and should be shut down.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;It will check for successful completion by checking the watermarks of all&lt;/li&gt;
	&lt;li&gt;transforms. If they all reached the maximum watermark it means that&lt;/li&gt;
	&lt;li&gt;pipeline successfully reached to completion.&lt;br/&gt;
+      If there is anything in the queue of tasks to do, do not shut down.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;If the above is not true, it will check that at least one executor is&lt;/li&gt;
	&lt;li&gt;making progress. Otherwise pipeline will be declared stalled.&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;If the pipeline reached to a terminal state as explained above&lt;/li&gt;
	&lt;li&gt;_should_shutdown will request executor to gracefully shutdown.&lt;br/&gt;
+      Otherwise, check if all the transforms&apos; watermarks are complete.&lt;br/&gt;
+      If they are not, the pipeline is not progressing (stall detected).&lt;br/&gt;
+      Whether the pipeline has stalled or not, the executor should shut&lt;br/&gt;
+      down the pipeline.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;       Returns:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;True if pipeline reached a terminal state and monitor task could finish.&lt;/li&gt;
	&lt;li&gt;Otherwise monitor task should schedule itself again for future&lt;/li&gt;
	&lt;li&gt;execution.&lt;br/&gt;
+        True only if the pipeline has reached a terminal state and should&lt;br/&gt;
+        be shut down.&lt;br/&gt;
+&lt;br/&gt;
       &quot;&quot;&quot;&lt;br/&gt;
       if self._is_executing():&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;There are some bundles still in progress.&lt;br/&gt;
@@ -585,8 +582,8 @@ def _fire_timers(self):&lt;br/&gt;
       Returns:&lt;br/&gt;
         True if timers fired.&lt;br/&gt;
       &quot;&quot;&quot;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;transform_fired_timers = (&lt;/li&gt;
	&lt;li&gt;self._executor.evaluation_context.extract_fired_timers())&lt;br/&gt;
+      transform_fired_timers, _ = (&lt;br/&gt;
+          self._executor.evaluation_context.extract_all_timers())&lt;br/&gt;
       for applied_ptransform, fired_timers in transform_fired_timers:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;Use an empty committed bundle. just to trigger.&lt;br/&gt;
         empty_bundle = (&lt;br/&gt;
@@ -602,7 +599,17 @@ def _fire_timers(self):&lt;br/&gt;
       return bool(transform_fired_timers)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;     def _is_executing(self):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;&quot;&quot;Returns True if there is at least one non-blocked TransformExecutor.&quot;&quot;&quot;&lt;br/&gt;
+      &quot;&quot;&quot;Checks whether the job is still executing.&lt;br/&gt;
+&lt;br/&gt;
+      Returns:&lt;br/&gt;
+        True if there are any timers set or if there is at least&lt;br/&gt;
+        one non-blocked TransformExecutor active.&quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+      watermark_manager = self._executor.evaluation_context._watermark_manager&lt;br/&gt;
+      _, any_unfired_realtime_timers = watermark_manager.extract_all_timers()&lt;br/&gt;
+      if any_unfired_realtime_timers:&lt;br/&gt;
+        return True&lt;br/&gt;
+&lt;br/&gt;
       executors = self._executor.transform_executor_services.executors&lt;br/&gt;
       if not executors:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;Nothing is executing.&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/direct/transform_evaluator.py b/sdks/python/apache_beam/runners/direct/transform_evaluator.py&lt;br/&gt;
index 2f3ac4fd989..ce67f737b0a 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/runners/direct/transform_evaluator.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/direct/transform_evaluator.py&lt;br/&gt;
@@ -28,6 +28,7 @@&lt;br/&gt;
 from apache_beam import pvalue&lt;br/&gt;
 from apache_beam.internal import pickler&lt;br/&gt;
 from apache_beam.options.pipeline_options import TypeOptions&lt;br/&gt;
+from apache_beam.runners import common&lt;br/&gt;
 from apache_beam.runners.common import DoFnRunner&lt;br/&gt;
 from apache_beam.runners.common import DoFnState&lt;br/&gt;
 from apache_beam.runners.dataflow.native_io.iobase import _NativeWrite  # pylint: disable=protected-access&lt;br/&gt;
@@ -484,20 +485,20 @@ def undeclared_in_memory_tag_values(self):&lt;br/&gt;
             or self._evaluation_context.has_cache)&lt;br/&gt;
     return self._undeclared_in_memory_tag_values&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;class NullReceiver(object):&lt;br/&gt;
+  class NullReceiver(common.Receiver):&lt;br/&gt;
     &quot;&quot;&quot;Ignores undeclared outputs, default execution mode.&quot;&quot;&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def output(self, element):&lt;br/&gt;
+    def receive(self, element):&lt;br/&gt;
       pass&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;class _InMemoryReceiver(object):&lt;br/&gt;
+  class _InMemoryReceiver(common.Receiver):&lt;br/&gt;
     &quot;&quot;&quot;Buffers undeclared outputs to the given dictionary.&quot;&quot;&quot;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     def _&lt;em&gt;init&lt;/em&gt;_(self, target, tag):&lt;br/&gt;
       self._target = target&lt;br/&gt;
       self._tag = tag&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def output(self, element):&lt;br/&gt;
+    def receive(self, element):&lt;br/&gt;
       self._target&lt;span class=&quot;error&quot;&gt;&amp;#91;self._tag&amp;#93;&lt;/span&gt;.append(element)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def _&lt;em&gt;missing&lt;/em&gt;_(self, key):&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/direct/watermark_manager.py b/sdks/python/apache_beam/runners/direct/watermark_manager.py&lt;br/&gt;
index 935998d27de..084073f4fe7 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/direct/watermark_manager.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/direct/watermark_manager.py&lt;br/&gt;
@@ -39,7 +39,7 @@ class WatermarkManager(object):&lt;/p&gt;

&lt;p&gt;   def _&lt;em&gt;init&lt;/em&gt;_(self, clock, root_transforms, value_to_consumers,&lt;br/&gt;
                transform_keyed_states):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;self._clock = clock  # processing time clock&lt;br/&gt;
+    self._clock = clock&lt;br/&gt;
     self._root_transforms = root_transforms&lt;br/&gt;
     self._value_to_consumers = value_to_consumers&lt;br/&gt;
     self._transform_keyed_states = transform_keyed_states&lt;br/&gt;
@@ -143,13 +143,18 @@ def _refresh_watermarks(self, applied_ptransform):&lt;br/&gt;
             for consumer in consumers:&lt;br/&gt;
               self._refresh_watermarks(consumer)&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def extract_fired_timers(self):&lt;br/&gt;
+  def extract_all_timers(self):&lt;br/&gt;
+    &quot;&quot;&quot;Extracts fired timers for all transforms&lt;br/&gt;
+    and reports if there are any timers set.&quot;&quot;&quot;&lt;br/&gt;
     all_timers = []&lt;br/&gt;
+    has_realtime_timer = False&lt;br/&gt;
     for applied_ptransform, tw in self._transform_to_watermarks.iteritems():&lt;/li&gt;
	&lt;li&gt;fired_timers = tw.extract_fired_timers()&lt;br/&gt;
+      fired_timers, had_realtime_timer = tw.extract_transform_timers()&lt;br/&gt;
       if fired_timers:&lt;br/&gt;
         all_timers.append((applied_ptransform, fired_timers))&lt;/li&gt;
	&lt;li&gt;return all_timers&lt;br/&gt;
+      if had_realtime_timer:&lt;br/&gt;
+        has_realtime_timer = True&lt;br/&gt;
+    return all_timers, has_realtime_timer&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; class _TransformWatermarks(object):&lt;br/&gt;
@@ -246,17 +251,20 @@ def refresh(self):&lt;br/&gt;
   def synchronized_processing_output_time(self):&lt;br/&gt;
     return self._clock.time()&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def extract_fired_timers(self):&lt;br/&gt;
+  def extract_transform_timers(self):&lt;br/&gt;
+    &quot;&quot;&quot;Extracts fired timers and reports of any timers set per transform.&quot;&quot;&quot;&lt;br/&gt;
     with self._lock:&lt;/li&gt;
	&lt;li&gt;if self._fired_timers:&lt;/li&gt;
	&lt;li&gt;return False&lt;br/&gt;
-&lt;br/&gt;
       fired_timers = []&lt;br/&gt;
+      has_realtime_timer = False&lt;br/&gt;
       for encoded_key, state in self._keyed_states.iteritems():&lt;/li&gt;
	&lt;li&gt;timers = state.get_timers(watermark=self._input_watermark)&lt;br/&gt;
+        timers, had_realtime_timer = state.get_timers(&lt;br/&gt;
+            watermark=self._input_watermark,&lt;br/&gt;
+            processing_time=self._clock.time())&lt;br/&gt;
+        if had_realtime_timer:&lt;br/&gt;
+          has_realtime_timer = True&lt;br/&gt;
         for expired in timers:&lt;br/&gt;
           window, (name, time_domain, timestamp) = expired&lt;br/&gt;
           fired_timers.append(&lt;br/&gt;
               TimerFiring(encoded_key, window, name, time_domain, timestamp))&lt;br/&gt;
       self._fired_timers.update(fired_timers)&lt;/li&gt;
	&lt;li&gt;return fired_timers&lt;br/&gt;
+      return fired_timers, has_realtime_timer&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/portability/fn_api_runner.py b/sdks/python/apache_beam/runners/portability/fn_api_runner.py&lt;br/&gt;
index 674d5233bc2..9b143c60a1a 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/runners/portability/fn_api_runner.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/portability/fn_api_runner.py&lt;br/&gt;
@@ -33,7 +33,6 @@&lt;br/&gt;
 from apache_beam.coders.coder_impl import create_InputStream&lt;br/&gt;
 from apache_beam.coders.coder_impl import create_OutputStream&lt;br/&gt;
 from apache_beam.internal import pickler&lt;br/&gt;
-from apache_beam.io import iobase&lt;br/&gt;
 from apache_beam.metrics.execution import MetricsEnvironment&lt;br/&gt;
 from apache_beam.portability.api import beam_fn_api_pb2&lt;br/&gt;
 from apache_beam.portability.api import beam_fn_api_pb2_grpc&lt;br/&gt;
@@ -100,29 +99,6 @@ def done(self):&lt;br/&gt;
   return StreamingRpcHandler()&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;-class OldeSourceSplittableDoFn(beam.DoFn):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;&quot;&quot;A DoFn that reads and emits an entire source.&lt;/li&gt;
	&lt;li&gt;&quot;&quot;&quot;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;# TODO(robertwb): Make this a full SDF with progress splitting, etc.&lt;/li&gt;
	&lt;li&gt;def process(self, source):&lt;/li&gt;
	&lt;li&gt;if isinstance(source, iobase.SourceBundle):&lt;/li&gt;
	&lt;li&gt;for value in source.source.read(source.source.get_range_tracker(&lt;/li&gt;
	&lt;li&gt;source.start_position, source.stop_position)):&lt;/li&gt;
	&lt;li&gt;yield value&lt;/li&gt;
	&lt;li&gt;else:&lt;/li&gt;
	&lt;li&gt;# Dataflow native source&lt;/li&gt;
	&lt;li&gt;with source.reader() as reader:&lt;/li&gt;
	&lt;li&gt;for value in reader:&lt;/li&gt;
	&lt;li&gt;yield value&lt;br/&gt;
-&lt;br/&gt;
-
	&lt;ol&gt;
		&lt;li&gt;See DataflowRunner._pardo_fn_data&lt;br/&gt;
-OLDE_SOURCE_SPLITTABLE_DOFN_DATA = pickler.dumps(&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
	&lt;li&gt;(OldeSourceSplittableDoFn(), (), {}, [],&lt;/li&gt;
	&lt;li&gt;beam.transforms.core.Windowing(GlobalWindows())))&lt;br/&gt;
-&lt;br/&gt;
-&lt;br/&gt;
 class _GroupingBuffer(object):&lt;br/&gt;
   &quot;&quot;&quot;Used to accumulate groupded (shuffled) results.&quot;&quot;&quot;&lt;br/&gt;
   def _&lt;em&gt;init&lt;/em&gt;_(self, pre_grouped_coder, post_grouped_coder, windowing):&lt;br/&gt;
@@ -134,22 +110,32 @@ def _&lt;em&gt;init&lt;/em&gt;_(self, pre_grouped_coder, post_grouped_coder, windowing):&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def append(self, elements_data):&lt;br/&gt;
     input_stream = create_InputStream(elements_data)&lt;br/&gt;
+    coder_impl = self._pre_grouped_coder.get_impl()&lt;br/&gt;
+    key_coder_impl = self._key_coder.get_impl()&lt;br/&gt;
+    # TODO(robertwb): We could optimize this even more by using a&lt;br/&gt;
+    # window-dropping coder for the data plane.&lt;br/&gt;
+    is_trivial_windowing = self._windowing.is_default()&lt;br/&gt;
     while input_stream.size() &amp;gt; 0:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;windowed_key_value = self._pre_grouped_coder.get_impl(&lt;/li&gt;
	&lt;li&gt;).decode_from_stream(input_stream, True)&lt;/li&gt;
	&lt;li&gt;key = windowed_key_value.value&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;windowed_value = windowed_key_value.with_value(&lt;/li&gt;
	&lt;li&gt;windowed_key_value.value&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;)&lt;/li&gt;
	&lt;li&gt;self._table&lt;span class=&quot;error&quot;&gt;&amp;#91;self._key_coder.encode(key)&amp;#93;&lt;/span&gt;.append(windowed_value)&lt;br/&gt;
+      windowed_key_value = coder_impl.decode_from_stream(input_stream, True)&lt;br/&gt;
+      key, value = windowed_key_value.value&lt;br/&gt;
+      self._table&lt;span class=&quot;error&quot;&gt;&amp;#91;key_coder_impl.encode(key)&amp;#93;&lt;/span&gt;.append(&lt;br/&gt;
+          value if is_trivial_windowing&lt;br/&gt;
+          else windowed_key_value.with_value(value))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def _&lt;em&gt;iter&lt;/em&gt;_(self):&lt;br/&gt;
     output_stream = create_OutputStream()&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;trigger_driver = trigger.create_trigger_driver(self._windowing, True)&lt;br/&gt;
+    if self._windowing.is_default():&lt;br/&gt;
+      globally_window = GlobalWindows.windowed_value(None).with_value&lt;br/&gt;
+      windowed_key_values = lambda key, values: &lt;span class=&quot;error&quot;&gt;&amp;#91;globally_window((key, values))&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    else:&lt;br/&gt;
+      trigger_driver = trigger.create_trigger_driver(self._windowing, True)&lt;br/&gt;
+      windowed_key_values = trigger_driver.process_entire_key&lt;br/&gt;
+    coder_impl = self._post_grouped_coder.get_impl()&lt;br/&gt;
+    key_coder_impl = self._key_coder.get_impl()&lt;br/&gt;
     for encoded_key, windowed_values in self._table.items():&lt;/li&gt;
	&lt;li&gt;key = self._key_coder.decode(encoded_key)&lt;/li&gt;
	&lt;li&gt;for wkvs in trigger_driver.process_entire_key(key, windowed_values):&lt;/li&gt;
	&lt;li&gt;self._post_grouped_coder.get_impl().encode_to_stream(&lt;/li&gt;
	&lt;li&gt;wkvs, output_stream, True)&lt;br/&gt;
+      key = key_coder_impl.decode(encoded_key)&lt;br/&gt;
+      for wkvs in windowed_key_values(key, windowed_values):&lt;br/&gt;
+        coder_impl.encode_to_stream(wkvs, output_stream, True)&lt;br/&gt;
     return iter(&lt;span class=&quot;error&quot;&gt;&amp;#91;output_stream.get()&amp;#93;&lt;/span&gt;)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;@@ -759,10 +745,12 @@ def extract_endpoints(stage):&lt;br/&gt;
             state_key, elements_data, process_bundle.instruction_id)&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Register and start running the bundle.&lt;br/&gt;
+    logging.debug(&apos;Register and start running the bundle&apos;)&lt;br/&gt;
     controller.control_handler.push(process_bundle_registration)&lt;br/&gt;
     controller.control_handler.push(process_bundle)&lt;/li&gt;
&lt;/ol&gt;


&lt;ol&gt;
	&lt;li&gt;Wait for the bundle to finish.&lt;br/&gt;
+    logging.debug(&apos;Wait for the bundle to finish.&apos;)&lt;br/&gt;
     while True:&lt;br/&gt;
       result = controller.control_handler.pull()&lt;br/&gt;
       if result and result.instruction_id == process_bundle.instruction_id:&lt;br/&gt;
@@ -770,11 +758,14 @@ def extract_endpoints(stage):&lt;br/&gt;
           raise RuntimeError(result.error)&lt;br/&gt;
         break&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;# Gather all output data.&lt;br/&gt;
     expected_targets = [&lt;br/&gt;
         beam_fn_api_pb2.Target(primitive_transform_reference=transform_id,&lt;br/&gt;
                                name=output_name)&lt;br/&gt;
         for (transform_id, output_name), _ in data_output.items()]&lt;br/&gt;
+&lt;br/&gt;
+    # Gather all output data.&lt;br/&gt;
+    logging.debug(&apos;Gather all output data from %s.&apos;, expected_targets)&lt;br/&gt;
+&lt;br/&gt;
     for output in controller.data_plane_handler.input_elements(&lt;br/&gt;
         process_bundle.instruction_id, expected_targets):&lt;br/&gt;
       target_tuple = (&lt;br/&gt;
@@ -867,9 +858,9 @@ def _&lt;em&gt;init&lt;/em&gt;_(self):&lt;br/&gt;
               self.data_plane_handler.inverse()))&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     def push(self, request):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;logging.info(&apos;CONTROL REQUEST %s&apos;, request)&lt;br/&gt;
+      logging.debug(&apos;CONTROL REQUEST %s&apos;, request)&lt;br/&gt;
       response = self.worker.do_instruction(request)&lt;/li&gt;
	&lt;li&gt;logging.info(&apos;CONTROL RESPONSE %s&apos;, response)&lt;br/&gt;
+      logging.debug(&apos;CONTROL RESPONSE %s&apos;, response)&lt;br/&gt;
       self._responses.append(response)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;     def pull(self):&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/portability/universal_local_runner.py b/sdks/python/apache_beam/runners/portability/universal_local_runner.py&lt;br/&gt;
index b9511949973..365803df639 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/portability/universal_local_runner.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/portability/universal_local_runner.py&lt;br/&gt;
@@ -31,6 +31,7 @@&lt;br/&gt;
 import grpc&lt;br/&gt;
 from google.protobuf import text_format&lt;/p&gt;

&lt;p&gt;+from apache_beam.portability.api import beam_fn_api_pb2_grpc&lt;br/&gt;
 from apache_beam.portability.api import beam_job_api_pb2&lt;br/&gt;
 from apache_beam.portability.api import beam_job_api_pb2_grpc&lt;br/&gt;
 from apache_beam.portability.api import endpoints_pb2&lt;br/&gt;
@@ -241,6 +242,7 @@ def run(self):&lt;br/&gt;
             use_grpc=self._use_grpc,&lt;br/&gt;
             sdk_harness_factory=self._sdk_harness_factory&lt;br/&gt;
         ).run_via_runner_api(self._pipeline_proto)&lt;br/&gt;
+        logging.info(&quot;Successfully completed job.&quot;)&lt;br/&gt;
         self.state = beam_job_api_pb2.JobState.DONE&lt;br/&gt;
       except:  # pylint: disable=bare-except&lt;br/&gt;
         logging.exception(&quot;Error running pipeline.&quot;)&lt;br/&gt;
@@ -271,10 +273,12 @@ def start_grpc(self, port=0):&lt;br/&gt;
     port = self._server.add_insecure_port(&apos;localhost:%d&apos; % port)&lt;br/&gt;
     beam_job_api_pb2_grpc.add_JobServiceServicer_to_server(self, self._server)&lt;br/&gt;
     self._server.start()&lt;br/&gt;
+    logging.info(&quot;Grpc server started on port %s&quot;, port)&lt;br/&gt;
     return port&lt;/p&gt;

&lt;p&gt;   def Prepare(self, request, context=None):&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;For now, just use the job name as the job id.&lt;br/&gt;
+    logging.debug(&quot;Got Prepare request.&quot;)&lt;br/&gt;
     preparation_id = &quot;%s-%s&quot; % (request.job_name, uuid.uuid4())&lt;br/&gt;
     if self._worker_command_line:&lt;br/&gt;
       sdk_harness_factory = functools.partial(&lt;br/&gt;
@@ -284,10 +288,12 @@ def Prepare(self, request, context=None):&lt;br/&gt;
     self._jobs&lt;span class=&quot;error&quot;&gt;&amp;#91;preparation_id&amp;#93;&lt;/span&gt; = BeamJob(&lt;br/&gt;
         preparation_id, request.pipeline_options, request.pipeline,&lt;br/&gt;
         use_grpc=self._use_grpc, sdk_harness_factory=sdk_harness_factory)&lt;br/&gt;
+    logging.debug(&quot;Prepared job &apos;%s&apos; as &apos;%s&apos;&quot;, request.job_name, preparation_id)&lt;br/&gt;
     return beam_job_api_pb2.PrepareJobResponse(preparation_id=preparation_id)&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   def Run(self, request, context=None):&lt;br/&gt;
     job_id = request.preparation_id&lt;br/&gt;
+    logging.debug(&quot;Runing job &apos;%s&apos;&quot;, job_id)&lt;br/&gt;
     self._jobs&lt;span class=&quot;error&quot;&gt;&amp;#91;job_id&amp;#93;&lt;/span&gt;.start()&lt;br/&gt;
     return beam_job_api_pb2.RunJobResponse(job_id=job_id)&lt;/p&gt;

&lt;p&gt;@@ -330,6 +336,14 @@ def GetMessageStream(self, request, context=None):&lt;br/&gt;
       pass&lt;/p&gt;


&lt;p&gt;+class BeamFnLoggingServicer(beam_fn_api_pb2_grpc.BeamFnLoggingServicer):&lt;br/&gt;
+  def Logging(self, log_bundles, context=None):&lt;br/&gt;
+    for log_bundle in log_bundles:&lt;br/&gt;
+      for log_entry in log_bundle.log_entries:&lt;br/&gt;
+        logging.info(&apos;Worker: %s&apos;, str(log_entry).replace(&apos;\n&apos;, &apos; &apos;))&lt;br/&gt;
+    return iter([])&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
 class SubprocessSdkWorker(object):&lt;br/&gt;
   &quot;&quot;&quot;Manages a SDK worker implemented as a subprocess communicating over grpc.&lt;br/&gt;
   &quot;&quot;&quot;&lt;br/&gt;
@@ -339,13 +353,25 @@ def _&lt;em&gt;init&lt;/em&gt;_(self, worker_command_line, control_address):&lt;br/&gt;
     self._control_address = control_address&lt;/p&gt;

&lt;p&gt;   def run(self):&lt;br/&gt;
+    logging_server = grpc.server(&lt;br/&gt;
+        futures.ThreadPoolExecutor(max_workers=10))&lt;br/&gt;
+    logging_port = logging_server.add_insecure_port(&apos;&lt;span class=&quot;error&quot;&gt;&amp;#91;::&amp;#93;&lt;/span&gt;:0&apos;)&lt;br/&gt;
+    logging_server.start()&lt;br/&gt;
+    logging_servicer = BeamFnLoggingServicer()&lt;br/&gt;
+    beam_fn_api_pb2_grpc.add_BeamFnLoggingServicer_to_server(&lt;br/&gt;
+        logging_servicer, logging_server)&lt;br/&gt;
+    logging_descriptor = text_format.MessageToString(&lt;br/&gt;
+        endpoints_pb2.ApiServiceDescriptor(url=&apos;localhost:%s&apos; % logging_port))&lt;br/&gt;
+&lt;br/&gt;
     control_descriptor = text_format.MessageToString(&lt;br/&gt;
         endpoints_pb2.ApiServiceDescriptor(url=self._control_address))&lt;br/&gt;
+&lt;br/&gt;
     p = subprocess.Popen(&lt;br/&gt;
         self._worker_command_line,&lt;br/&gt;
         shell=True,&lt;br/&gt;
         env=dict(os.environ,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;CONTROL_API_SERVICE_DESCRIPTOR=control_descriptor))&lt;br/&gt;
+                 CONTROL_API_SERVICE_DESCRIPTOR=control_descriptor,&lt;br/&gt;
+                 LOGGING_API_SERVICE_DESCRIPTOR=logging_descriptor))&lt;br/&gt;
     try:&lt;br/&gt;
       p.wait()&lt;br/&gt;
       if p.returncode:&lt;br/&gt;
@@ -354,6 +380,7 @@ def run(self):&lt;br/&gt;
     finally:&lt;br/&gt;
       if p.poll() is None:&lt;br/&gt;
         p.kill()&lt;br/&gt;
+      logging_server.stop(0)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; class JobLogHandler(logging.Handler):&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/portability/universal_local_runner_main.py b/sdks/python/apache_beam/runners/portability/universal_local_runner_main.py&lt;br/&gt;
index 9dd3a7e5166..93781e1c6f5 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/portability/universal_local_runner_main.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/portability/universal_local_runner_main.py&lt;br/&gt;
@@ -41,4 +41,5 @@ def run(argv):&lt;/p&gt;


&lt;p&gt; if _&lt;em&gt;name&lt;/em&gt;_ == &apos;_&lt;em&gt;main&lt;/em&gt;_&apos;:&lt;br/&gt;
+  logging.getLogger().setLevel(logging.INFO)&lt;br/&gt;
   run(sys.argv)&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/worker/bundle_processor.py b/sdks/python/apache_beam/runners/worker/bundle_processor.py&lt;br/&gt;
index 689eab7b842..94dca8b242a 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/worker/bundle_processor.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/worker/bundle_processor.py&lt;br/&gt;
@@ -36,7 +36,6 @@&lt;br/&gt;
 from apache_beam.portability.api import beam_fn_api_pb2&lt;br/&gt;
 from apache_beam.portability.api import beam_runner_api_pb2&lt;br/&gt;
 from apache_beam.runners import pipeline_context&lt;br/&gt;
-from apache_beam.runners.dataflow.native_io import iobase as native_iobase&lt;br/&gt;
 from apache_beam.runners.worker import operation_specs&lt;br/&gt;
 from apache_beam.runners.worker import operations&lt;br/&gt;
 from apache_beam.transforms import sideinputs&lt;br/&gt;
@@ -71,6 +70,7 @@ def _&lt;em&gt;init&lt;/em&gt;_(self, operation_name, step_name, consumers, counter_factory,&lt;br/&gt;
     super(RunnerIOOperation, self)._&lt;em&gt;init&lt;/em&gt;_(&lt;br/&gt;
         operation_name, None, counter_factory, state_sampler)&lt;br/&gt;
     self.windowed_coder = windowed_coder&lt;br/&gt;
+    self.windowed_coder_impl = windowed_coder.get_impl()&lt;br/&gt;
     self.step_name = step_name&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;target represents the consumer for the bytes in the data plane for a&lt;/li&gt;
	&lt;li&gt;DataInputOperation or a producer of these bytes for a DataOutputOperation.&lt;br/&gt;
@@ -89,7 +89,7 @@ def set_output_stream(self, output_stream):&lt;br/&gt;
     self.output_stream = output_stream&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;   def process(self, windowed_value):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;self.windowed_coder.get_impl().encode_to_stream(&lt;br/&gt;
+    self.windowed_coder_impl.encode_to_stream(&lt;br/&gt;
         windowed_value, self.output_stream, True)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def finish(self):&lt;br/&gt;
@@ -118,47 +118,11 @@ def process(self, windowed_value):&lt;br/&gt;
   def process_encoded(self, encoded_windowed_values):&lt;br/&gt;
     input_stream = coder_impl.create_InputStream(encoded_windowed_values)&lt;br/&gt;
     while input_stream.size() &amp;gt; 0:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;decoded_value = self.windowed_coder.get_impl().decode_from_stream(&lt;br/&gt;
+      decoded_value = self.windowed_coder_impl.decode_from_stream(&lt;br/&gt;
           input_stream, True)&lt;br/&gt;
       self.output(decoded_value)&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;TODO(robertwb): Revise side input API to not be in terms of native sources.&lt;/li&gt;
		&lt;li&gt;This will enable lookups, but there&apos;s an open question as to how to handle&lt;/li&gt;
		&lt;li&gt;custom sources without forcing intermediate materialization.  This seems very&lt;/li&gt;
		&lt;li&gt;related to the desire to inject key and window preserving &lt;span class=&quot;error&quot;&gt;&amp;#91;Splittable&amp;#93;&lt;/span&gt;DoFns&lt;/li&gt;
		&lt;li&gt;into the view computation.&lt;br/&gt;
-class SideInputSource(native_iobase.NativeSource,&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
	&lt;li&gt;native_iobase.NativeSourceReader):&lt;/li&gt;
	&lt;li&gt;&quot;&quot;&quot;A &apos;source&apos; for reading side inputs via state API calls.&lt;/li&gt;
	&lt;li&gt;&quot;&quot;&quot;&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def _&lt;em&gt;init&lt;/em&gt;_(self, state_handler, state_key, coder):&lt;/li&gt;
	&lt;li&gt;self._state_handler = state_handler&lt;/li&gt;
	&lt;li&gt;self._state_key = state_key&lt;/li&gt;
	&lt;li&gt;self._coder = coder&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def reader(self):&lt;/li&gt;
	&lt;li&gt;return self&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;@property&lt;/li&gt;
	&lt;li&gt;def returns_windowed_values(self):&lt;/li&gt;
	&lt;li&gt;return True&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def _&lt;em&gt;enter&lt;/em&gt;_(self):&lt;/li&gt;
	&lt;li&gt;return self&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def _&lt;em&gt;exit&lt;/em&gt;_(self, *exn_info):&lt;/li&gt;
	&lt;li&gt;pass&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;def _&lt;em&gt;iter&lt;/em&gt;_(self):&lt;/li&gt;
	&lt;li&gt;# TODO(robertwb): Support pagination.&lt;/li&gt;
	&lt;li&gt;input_stream = coder_impl.create_InputStream(&lt;/li&gt;
	&lt;li&gt;self._state_handler.Get(self._state_key).data)&lt;/li&gt;
	&lt;li&gt;while input_stream.size() &amp;gt; 0:&lt;/li&gt;
	&lt;li&gt;yield self._coder.get_impl().decode_from_stream(input_stream, True)&lt;br/&gt;
-&lt;br/&gt;
-&lt;br/&gt;
 class StateBackedSideInputMap(object):&lt;br/&gt;
   def _&lt;em&gt;init&lt;/em&gt;_(self, state_handler, transform_id, tag, side_input_data):&lt;br/&gt;
     self._state_handler = state_handler&lt;br/&gt;
@@ -565,9 +529,10 @@ class WindowIntoDoFn(beam.DoFn):&lt;br/&gt;
     def _&lt;em&gt;init&lt;/em&gt;_(self, windowing):&lt;br/&gt;
       self.windowing = windowing&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def process(self, element, timestamp=beam.DoFn.TimestampParam):&lt;br/&gt;
+    def process(self, element, timestamp=beam.DoFn.TimestampParam,&lt;br/&gt;
+                window=beam.DoFn.WindowParam):&lt;br/&gt;
       new_windows = self.windowing.windowfn.assign(&lt;/li&gt;
	&lt;li&gt;WindowFn.AssignContext(timestamp, element=element))&lt;br/&gt;
+          WindowFn.AssignContext(timestamp, element=element, window=window))&lt;br/&gt;
       yield WindowedValue(element, timestamp, new_windows)&lt;br/&gt;
   from apache_beam.transforms.core import Windowing&lt;br/&gt;
   from apache_beam.transforms.window import WindowFn, WindowedValue&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/worker/operations.py b/sdks/python/apache_beam/runners/worker/operations.py&lt;br/&gt;
index 6b5f0246c10..c245655b847 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/runners/worker/operations.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/worker/operations.py&lt;br/&gt;
@@ -78,9 +78,6 @@ def _&lt;em&gt;init&lt;/em&gt;_(&lt;br/&gt;
     self.output_index = output_index&lt;br/&gt;
     self.coder = coder&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def output(self, windowed_value):  # For old SDKs.&lt;/li&gt;
	&lt;li&gt;self.receive(windowed_value)&lt;br/&gt;
-&lt;br/&gt;
   def receive(self, windowed_value):&lt;br/&gt;
     self.update_counters_start(windowed_value)&lt;br/&gt;
     for consumer in self.consumers:&lt;br/&gt;
@@ -326,9 +323,6 @@ def start(self):&lt;br/&gt;
       state = common.DoFnState(self.counter_factory)&lt;br/&gt;
       state.step_name = self.step_name&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;# TODO(silviuc): What is the proper label here? PCollection being&lt;/li&gt;
	&lt;li&gt;# processed?&lt;/li&gt;
	&lt;li&gt;context = common.DoFnContext(&apos;label&apos;, state=state)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;Tag to output index map used to dispatch the side output values emitted&lt;/li&gt;
	&lt;li&gt;by the DoFn function to the appropriate receivers. The main output is&lt;/li&gt;
	&lt;li&gt;tagged with None and is associated with its corresponding index.&lt;br/&gt;
@@ -352,9 +346,12 @@ def start(self):&lt;br/&gt;
           self.side_input_maps = []&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;       self.dofn_runner = common.DoFnRunner(&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;fn, args, kwargs, self.side_input_maps,&lt;/li&gt;
	&lt;li&gt;window_fn, context, self.tagged_receivers,&lt;/li&gt;
	&lt;li&gt;logger, self.step_name,&lt;br/&gt;
+          fn, args, kwargs, self.side_input_maps, window_fn,&lt;br/&gt;
+          tagged_receivers=self.tagged_receivers,&lt;br/&gt;
+          step_name=self.step_name,&lt;br/&gt;
+          logging_context=logger.PerThreadLoggingContext(&lt;br/&gt;
+              step_name=self.step_name),&lt;br/&gt;
+          state=state,&lt;br/&gt;
           scoped_metrics_container=self.scoped_metrics_container)&lt;br/&gt;
       self.dofn_receiver = (self.dofn_runner&lt;br/&gt;
                             if isinstance(self.dofn_runner, Receiver)&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/worker/sdk_worker_main.py b/sdks/python/apache_beam/runners/worker/sdk_worker_main.py&lt;br/&gt;
index 70e4c96dfec..1db8b29175f 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/runners/worker/sdk_worker_main.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/worker/sdk_worker_main.py&lt;br/&gt;
@@ -14,22 +14,72 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
	&lt;li&gt;See the License for the specific language governing permissions and&lt;/li&gt;
	&lt;li&gt;limitations under the License.&lt;br/&gt;
 #&lt;br/&gt;
-&lt;br/&gt;
 &quot;&quot;&quot;SDK Fn Harness entry point.&quot;&quot;&quot;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;+import BaseHTTPServer&lt;br/&gt;
+import json&lt;br/&gt;
 import logging&lt;br/&gt;
 import os&lt;br/&gt;
 import sys&lt;br/&gt;
+import threading&lt;br/&gt;
+import traceback&lt;/p&gt;

&lt;p&gt; from google.protobuf import text_format&lt;/p&gt;

&lt;p&gt;+from apache_beam.internal import pickler&lt;br/&gt;
 from apache_beam.portability.api import endpoints_pb2&lt;br/&gt;
+from apache_beam.runners.dataflow.internal import names&lt;br/&gt;
 from apache_beam.runners.worker.log_handler import FnApiLogRecordHandler&lt;br/&gt;
 from apache_beam.runners.worker.sdk_worker import SdkHarness&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;This module is experimental. No backwards-compatibility guarantees.&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;+class StatusServer(object):&lt;br/&gt;
+&lt;br/&gt;
+  @classmethod&lt;br/&gt;
+  def get_thread_dump(cls):&lt;br/&gt;
+    lines = []&lt;br/&gt;
+    frames = sys._current_frames()  # pylint: disable=protected-access&lt;br/&gt;
+&lt;br/&gt;
+    for t in threading.enumerate():&lt;br/&gt;
+      lines.append(&apos;--- Thread #%s name: %s ---\n&apos; % (t.ident, t.name))&lt;br/&gt;
+      lines.append(&apos;&apos;.join(traceback.format_stack(frames&lt;span class=&quot;error&quot;&gt;&amp;#91;t.ident&amp;#93;&lt;/span&gt;)))&lt;br/&gt;
+&lt;br/&gt;
+    return lines&lt;br/&gt;
+&lt;br/&gt;
+  def start(self, status_http_port=0):&lt;br/&gt;
+    &quot;&quot;&quot;Executes the serving loop for the status server.&lt;br/&gt;
+&lt;br/&gt;
+    Args:&lt;br/&gt;
+      status_http_port(int): Binding port for the debug server.&lt;br/&gt;
+        Default is 0 which means any free unsecured port&lt;br/&gt;
+    &quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+    class StatusHttpHandler(BaseHTTPServer.BaseHTTPRequestHandler):&lt;br/&gt;
+      &quot;&quot;&quot;HTTP handler for serving stacktraces of all threads.&quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+      def do_GET(self):  # pylint: disable=invalid-name&lt;br/&gt;
+        &quot;&quot;&quot;Return all thread stacktraces information for GET request.&quot;&quot;&quot;&lt;br/&gt;
+        self.send_response(200)&lt;br/&gt;
+        self.send_header(&apos;Content-Type&apos;, &apos;text/plain&apos;)&lt;br/&gt;
+        self.end_headers()&lt;br/&gt;
+&lt;br/&gt;
+        for line in StatusServer.get_thread_dump():&lt;br/&gt;
+          self.wfile.write(line)&lt;br/&gt;
+&lt;br/&gt;
+      def log_message(self, f, *args):&lt;br/&gt;
+        &quot;&quot;&quot;Do not log any messages.&quot;&quot;&quot;&lt;br/&gt;
+        pass&lt;br/&gt;
+&lt;br/&gt;
+    self.httpd = httpd = BaseHTTPServer.HTTPServer(&lt;br/&gt;
+        (&apos;localhost&apos;, status_http_port), StatusHttpHandler)&lt;br/&gt;
+    logging.info(&apos;Status HTTP server running at %s:%s&apos;, httpd.server_name,&lt;br/&gt;
+                 httpd.server_port)&lt;br/&gt;
+&lt;br/&gt;
+    httpd.serve_forever()&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
 def main(unused_argv):&lt;br/&gt;
   &quot;&quot;&quot;Main entry point for SDK Fn Harness.&quot;&quot;&quot;&lt;br/&gt;
   if &apos;LOGGING_API_SERVICE_DESCRIPTOR&apos; in os.environ:&lt;br/&gt;
@@ -45,8 +95,34 @@ def main(unused_argv):&lt;br/&gt;
   else:&lt;br/&gt;
     fn_log_handler = None&lt;/p&gt;

&lt;p&gt;+  # Start status HTTP server thread.&lt;br/&gt;
+  thread = threading.Thread(target=StatusServer().start)&lt;br/&gt;
+  thread.daemon = True&lt;br/&gt;
+  thread.setName(&apos;status-server-demon&apos;)&lt;br/&gt;
+  thread.start()&lt;br/&gt;
+&lt;br/&gt;
+  if &apos;PIPELINE_OPTIONS&apos; in os.environ:&lt;br/&gt;
+    sdk_pipeline_options = json.loads(os.environ&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;#39;PIPELINE_OPTIONS&amp;#39;&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+  else:&lt;br/&gt;
+    sdk_pipeline_options = {}&lt;br/&gt;
+&lt;br/&gt;
+  if &apos;SEMI_PERSISTENT_DIRECTORY&apos; in os.environ:&lt;br/&gt;
+    semi_persistent_directory = os.environ&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;#39;SEMI_PERSISTENT_DIRECTORY&amp;#39;&amp;#93;&lt;/span&gt;&lt;br/&gt;
+  else:&lt;br/&gt;
+    semi_persistent_directory = None&lt;br/&gt;
+&lt;br/&gt;
+  logging.info(&apos;semi_persistent_directory: %s&apos;, semi_persistent_directory)&lt;br/&gt;
+&lt;br/&gt;
+  try:&lt;br/&gt;
+    _load_main_session(semi_persistent_directory)&lt;br/&gt;
+  except Exception:  # pylint: disable=broad-except&lt;br/&gt;
+    exception_details = traceback.format_exc()&lt;br/&gt;
+    logging.error(&lt;br/&gt;
+        &apos;Could not load main session: %s&apos;, exception_details, exc_info=True)&lt;br/&gt;
+&lt;br/&gt;
   try:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;logging.info(&apos;Python sdk harness started.&apos;)&lt;br/&gt;
+    logging.info(&apos;Python sdk harness started with pipeline_options: %s&apos;,&lt;br/&gt;
+                 sdk_pipeline_options)&lt;br/&gt;
     service_descriptor = endpoints_pb2.ApiServiceDescriptor()&lt;br/&gt;
     text_format.Merge(os.environ&lt;span class=&quot;error&quot;&gt;&amp;#91;&amp;#39;CONTROL_API_SERVICE_DESCRIPTOR&amp;#39;&amp;#93;&lt;/span&gt;,&lt;br/&gt;
                       service_descriptor)&lt;br/&gt;
@@ -62,5 +138,22 @@ def main(unused_argv):&lt;br/&gt;
       fn_log_handler.close()&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;+def _load_main_session(semi_persistent_directory):&lt;br/&gt;
+  &quot;&quot;&quot;Loads a pickled main session from the path specified.&quot;&quot;&quot;&lt;br/&gt;
+  if semi_persistent_directory:&lt;br/&gt;
+    session_file = os.path.join(semi_persistent_directory, &apos;staged&apos;,&lt;br/&gt;
+                                names.PICKLED_MAIN_SESSION_FILE)&lt;br/&gt;
+    if os.path.isfile(session_file):&lt;br/&gt;
+      pickler.load_session(session_file)&lt;br/&gt;
+    else:&lt;br/&gt;
+      logging.warning(&lt;br/&gt;
+          &apos;No session file found: %s. Functions defined in _&lt;em&gt;main&lt;/em&gt;_ &apos;&lt;br/&gt;
+          &apos;(interactive session) may fail.&apos;, session_file)&lt;br/&gt;
+  else:&lt;br/&gt;
+    logging.warning(&lt;br/&gt;
+        &apos;No semi_persistent_directory found: Functions defined in _&lt;em&gt;main&lt;/em&gt;_ &apos;&lt;br/&gt;
+        &apos;(interactive session) may fail.&apos;)&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
 if _&lt;em&gt;name&lt;/em&gt;_ == &apos;_&lt;em&gt;main&lt;/em&gt;_&apos;:&lt;br/&gt;
   main(sys.argv)&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/worker/sdk_worker_main_test.py b/sdks/python/apache_beam/runners/worker/sdk_worker_main_test.py&lt;br/&gt;
new file mode 100644&lt;br/&gt;
index 00000000000..9305c990b10&lt;br/&gt;
&amp;#8212; /dev/null&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/worker/sdk_worker_main_test.py&lt;br/&gt;
@@ -0,0 +1,44 @@&lt;br/&gt;
+#&lt;br/&gt;
+# Licensed to the Apache Software Foundation (ASF) under one or more&lt;br/&gt;
+# contributor license agreements.  See the NOTICE file distributed with&lt;br/&gt;
+# this work for additional information regarding copyright ownership.&lt;br/&gt;
+# The ASF licenses this file to You under the Apache License, Version 2.0&lt;br/&gt;
+# (the &quot;License&quot;); you may not use this file except in compliance with&lt;br/&gt;
+# the License.  You may obtain a copy of the License at&lt;br/&gt;
+#&lt;br/&gt;
+#    &lt;a href=&quot;http://www.apache.org/licenses/LICENSE-2.0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;http://www.apache.org/licenses/LICENSE-2.0&lt;/a&gt;&lt;br/&gt;
+#&lt;br/&gt;
+# Unless required by applicable law or agreed to in writing, software&lt;br/&gt;
+# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,&lt;br/&gt;
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;br/&gt;
+# See the License for the specific language governing permissions and&lt;br/&gt;
+# limitations under the License.&lt;br/&gt;
+#&lt;br/&gt;
+&quot;&quot;&quot;Tests for apache_beam.runners.worker.sdk_worker_main.&quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+from _&lt;em&gt;future&lt;/em&gt;_ import absolute_import&lt;br/&gt;
+from _&lt;em&gt;future&lt;/em&gt;_ import division&lt;br/&gt;
+from _&lt;em&gt;future&lt;/em&gt;_ import print_function&lt;br/&gt;
+&lt;br/&gt;
+import logging&lt;br/&gt;
+import unittest&lt;br/&gt;
+&lt;br/&gt;
+from apache_beam.runners.worker import sdk_worker_main&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+class SdkWorkerMainTest(unittest.TestCase):&lt;br/&gt;
+&lt;br/&gt;
+  def test_status_server(self):&lt;br/&gt;
+&lt;br/&gt;
+    # Wrapping the method to see if it appears in threadump&lt;br/&gt;
+    def wrapped_method_for_test():&lt;br/&gt;
+      lines = sdk_worker_main.StatusServer.get_thread_dump()&lt;br/&gt;
+      threaddump = &apos;\n&apos;.join(lines)&lt;br/&gt;
+      self.assertRegexpMatches(threaddump, &quot;.&lt;b&gt;wrapped_method_for_test.&lt;/b&gt;&quot;)&lt;br/&gt;
+&lt;br/&gt;
+    wrapped_method_for_test()&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+if _&lt;em&gt;name&lt;/em&gt;_ == &quot;_&lt;em&gt;main&lt;/em&gt;_&quot;:&lt;br/&gt;
+  logging.getLogger().setLevel(logging.INFO)&lt;br/&gt;
+  unittest.main()&lt;br/&gt;
diff --git a/sdks/python/apache_beam/runners/worker/statesampler_test.py b/sdks/python/apache_beam/runners/worker/statesampler_test.py&lt;br/&gt;
index 44b2f725c45..2f2c8bea4f7 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/runners/worker/statesampler_test.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/runners/worker/statesampler_test.py&lt;br/&gt;
@@ -33,7 +33,7 @@ def setUp(self):&lt;br/&gt;
     try:&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;pylint: disable=global-variable-not-assigned&lt;br/&gt;
       global statesampler&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;from . import statesampler&lt;br/&gt;
+      from apache_beam.runners.worker import statesampler&lt;br/&gt;
     except ImportError:&lt;br/&gt;
       raise SkipTest(&apos;State sampler not compiled.&apos;)&lt;br/&gt;
     super(StateSamplerTest, self).setUp()&lt;br/&gt;
diff --git a/sdks/python/apache_beam/testing/test_utils.py b/sdks/python/apache_beam/testing/test_utils.py&lt;br/&gt;
index c28b6926e63..5676186b752 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/testing/test_utils.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/testing/test_utils.py&lt;br/&gt;
@@ -62,14 +62,13 @@ def create_temp_file(self, suffix=&apos;&apos;, lines=None):&lt;br/&gt;
     Returns:&lt;br/&gt;
       The name of the temporary file created.&lt;br/&gt;
     &quot;&quot;&quot;&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;f = tempfile.NamedTemporaryFile(delete=False,&lt;/li&gt;
	&lt;li&gt;dir=self._tempdir,&lt;/li&gt;
	&lt;li&gt;suffix=suffix)&lt;/li&gt;
	&lt;li&gt;if lines:&lt;/li&gt;
	&lt;li&gt;for line in lines:&lt;/li&gt;
	&lt;li&gt;f.write(line)&lt;br/&gt;
-&lt;/li&gt;
	&lt;li&gt;return f.name&lt;br/&gt;
+    with tempfile.NamedTemporaryFile(&lt;br/&gt;
+        delete=False, dir=self._tempdir, suffix=suffix) as f:&lt;br/&gt;
+      if lines:&lt;br/&gt;
+        for line in lines:&lt;br/&gt;
+          f.write(line)&lt;br/&gt;
+&lt;br/&gt;
+      return f.name&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; def compute_hash(content, hashing_alg=DEFAULT_HASHING_ALG):&lt;br/&gt;
diff --git a/sdks/python/apache_beam/testing/util.py b/sdks/python/apache_beam/testing/util.py&lt;br/&gt;
index 34c15f9c191..2f18bdee0b1 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/testing/util.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/testing/util.py&lt;br/&gt;
@@ -19,13 +19,16 @@&lt;/p&gt;

&lt;p&gt; from _&lt;em&gt;future&lt;/em&gt;_ import absolute_import&lt;/p&gt;

&lt;p&gt;+import collections&lt;br/&gt;
 import glob&lt;br/&gt;
 import tempfile&lt;/p&gt;

&lt;p&gt; from apache_beam import pvalue&lt;br/&gt;
 from apache_beam.transforms import window&lt;br/&gt;
 from apache_beam.transforms.core import Create&lt;br/&gt;
+from apache_beam.transforms.core import DoFn&lt;br/&gt;
 from apache_beam.transforms.core import Map&lt;br/&gt;
+from apache_beam.transforms.core import ParDo&lt;br/&gt;
 from apache_beam.transforms.core import WindowInto&lt;br/&gt;
 from apache_beam.transforms.ptransform import PTransform&lt;br/&gt;
 from apache_beam.transforms.util import CoGroupByKey&lt;br/&gt;
@@ -37,6 +40,7 @@&lt;br/&gt;
     &apos;is_empty&apos;,&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;open_shards is internal and has no backwards compatibility guarantees.&lt;br/&gt;
     &apos;open_shards&apos;,&lt;br/&gt;
+    &apos;TestWindowedValue&apos;,&lt;br/&gt;
     ]&lt;/li&gt;
&lt;/ol&gt;



&lt;p&gt;@@ -46,11 +50,32 @@ class BeamAssertException(Exception):&lt;br/&gt;
   pass&lt;/p&gt;


&lt;p&gt;+# Used for reifying timestamps and windows for assert_that matchers.&lt;br/&gt;
+TestWindowedValue = collections.namedtuple(&lt;br/&gt;
+    &apos;TestWindowedValue&apos;, &apos;value timestamp windows&apos;)&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+def contains_in_any_order(iterable):&lt;br/&gt;
+  &quot;&quot;&quot;Creates an object that matches another iterable if they both have the&lt;br/&gt;
+  same count of items.&lt;br/&gt;
+&lt;br/&gt;
+  Arguments:&lt;br/&gt;
+    iterable: An iterable of hashable objects.&lt;br/&gt;
+  &quot;&quot;&quot;&lt;br/&gt;
+  class InAnyOrder(object):&lt;br/&gt;
+    def _&lt;em&gt;init&lt;/em&gt;_(self, iterable):&lt;br/&gt;
+      self._counter = collections.Counter(iterable)&lt;br/&gt;
+&lt;br/&gt;
+    def _&lt;em&gt;eq&lt;/em&gt;_(self, other):&lt;br/&gt;
+      return self._counter == collections.Counter(other)&lt;br/&gt;
+&lt;br/&gt;
+  return InAnyOrder(iterable)&lt;br/&gt;
+&lt;br/&gt;
+&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;Note that equal_to always sorts the expected and actual since what we&lt;/li&gt;
	&lt;li&gt;compare are PCollections for which there is no guaranteed order.&lt;/li&gt;
	&lt;li&gt;However the sorting does not go beyond top level therefore &lt;span class=&quot;error&quot;&gt;&amp;#91;1,2&amp;#93;&lt;/span&gt; and &lt;span class=&quot;error&quot;&gt;&amp;#91;2,1&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;are considered equal and [&lt;span class=&quot;error&quot;&gt;&amp;#91;1,2&amp;#93;&lt;/span&gt;] and [&lt;span class=&quot;error&quot;&gt;&amp;#91;2,1&amp;#93;&lt;/span&gt;] are not.
	&lt;ol&gt;
		&lt;li&gt;TODO(silviuc): Add contains_in_any_order-style matchers.&lt;br/&gt;
 def equal_to(expected):&lt;br/&gt;
   expected = list(expected)&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;@@ -72,7 +97,7 @@ def _empty(actual):&lt;br/&gt;
   return _empty&lt;/p&gt;


&lt;p&gt;-def assert_that(actual, matcher, label=&apos;assert_that&apos;):&lt;br/&gt;
+def assert_that(actual, matcher, label=&apos;assert_that&apos;, reify_windows=False):&lt;br/&gt;
   &quot;&quot;&quot;A PTransform that checks a PCollection has an expected value.&lt;/p&gt;

&lt;p&gt;   Note that assert_that should be used only for testing pipelines since the&lt;br/&gt;
@@ -85,15 +110,27 @@ def assert_that(actual, matcher, label=&apos;assert_that&apos;):&lt;br/&gt;
       expectations and raises BeamAssertException if they are not met.&lt;br/&gt;
     label: Optional string label. This is needed in case several assert_that&lt;br/&gt;
       transforms are introduced in the same pipeline.&lt;br/&gt;
+    reify_windows: If True, matcher is passed a list of TestWindowedValue.&lt;/p&gt;

&lt;p&gt;   Returns:&lt;br/&gt;
     Ignored.&lt;br/&gt;
   &quot;&quot;&quot;&lt;br/&gt;
   assert isinstance(actual, pvalue.PCollection)&lt;/p&gt;

&lt;p&gt;+  class ReifyTimestampWindow(DoFn):&lt;br/&gt;
+    def process(self, element, timestamp=DoFn.TimestampParam,&lt;br/&gt;
+                window=DoFn.WindowParam):&lt;br/&gt;
+      # This returns TestWindowedValue instead of&lt;br/&gt;
+      # beam.utils.windowed_value.WindowedValue because ParDo will extract&lt;br/&gt;
+      # the timestamp and window out of the latter.&lt;br/&gt;
+      return [TestWindowedValue(element, timestamp, &lt;span class=&quot;error&quot;&gt;&amp;#91;window&amp;#93;&lt;/span&gt;)]&lt;br/&gt;
+&lt;br/&gt;
   class AssertThat(PTransform):&lt;/p&gt;

&lt;p&gt;     def expand(self, pcoll):&lt;br/&gt;
+      if reify_windows:&lt;br/&gt;
+        pcoll = pcoll | ParDo(ReifyTimestampWindow())&lt;br/&gt;
+&lt;/p&gt;
&lt;ol&gt;
	&lt;li&gt;We must have at least a single element to ensure the matcher&lt;/li&gt;
	&lt;li&gt;code gets run even if the input pcollection is empty.&lt;br/&gt;
       keyed_singleton = pcoll.pipeline | Create(&lt;span class=&quot;error&quot;&gt;&amp;#91;(None, None)&amp;#93;&lt;/span&gt;)&lt;br/&gt;
diff --git a/sdks/python/apache_beam/testing/util_test.py b/sdks/python/apache_beam/testing/util_test.py&lt;br/&gt;
index 9d3869381b6..e4e86941669 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/apache_beam/testing/util_test.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/testing/util_test.py&lt;br/&gt;
@@ -21,9 +21,13 @@&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt; from apache_beam import Create&lt;br/&gt;
 from apache_beam.testing.test_pipeline import TestPipeline&lt;br/&gt;
+from apache_beam.testing.util import TestWindowedValue&lt;br/&gt;
 from apache_beam.testing.util import assert_that&lt;br/&gt;
 from apache_beam.testing.util import equal_to&lt;br/&gt;
 from apache_beam.testing.util import is_empty&lt;br/&gt;
+from apache_beam.transforms.window import GlobalWindow&lt;br/&gt;
+from apache_beam.transforms.window import IntervalWindow&lt;br/&gt;
+from apache_beam.utils.timestamp import MIN_TIMESTAMP&lt;/p&gt;


&lt;p&gt; class UtilTest(unittest.TestCase):&lt;br/&gt;
@@ -32,11 +36,49 @@ def test_assert_that_passes(self):&lt;br/&gt;
     with TestPipeline() as p:&lt;br/&gt;
       assert_that(p | Create(&lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 3&amp;#93;&lt;/span&gt;), equal_to(&lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 3&amp;#93;&lt;/span&gt;))&lt;/p&gt;

&lt;p&gt;+  def test_assert_that_passes_empty_equal_to(self):&lt;br/&gt;
+    with TestPipeline() as p:&lt;br/&gt;
+      assert_that(p | Create([]), equal_to([]))&lt;br/&gt;
+&lt;br/&gt;
+  def test_assert_that_passes_empty_is_empty(self):&lt;br/&gt;
+    with TestPipeline() as p:&lt;br/&gt;
+      assert_that(p | Create([]), is_empty())&lt;br/&gt;
+&lt;br/&gt;
+  def test_windowed_value_passes(self):&lt;br/&gt;
+    expected = [TestWindowedValue(v, MIN_TIMESTAMP, &lt;span class=&quot;error&quot;&gt;&amp;#91;GlobalWindow()&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+                for v in &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 3&amp;#93;&lt;/span&gt;]&lt;br/&gt;
+    with TestPipeline() as p:&lt;br/&gt;
+      assert_that(p | Create(&lt;span class=&quot;error&quot;&gt;&amp;#91;2, 3, 1&amp;#93;&lt;/span&gt;), equal_to(expected), reify_windows=True)&lt;br/&gt;
+&lt;br/&gt;
   def test_assert_that_fails(self):&lt;br/&gt;
     with self.assertRaises(Exception):&lt;br/&gt;
       with TestPipeline() as p:&lt;br/&gt;
         assert_that(p | Create(&lt;span class=&quot;error&quot;&gt;&amp;#91;1, 10, 100&amp;#93;&lt;/span&gt;), equal_to(&lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 3&amp;#93;&lt;/span&gt;))&lt;/p&gt;

&lt;p&gt;+  def test_windowed_value_assert_fail_unmatched_value(self):&lt;br/&gt;
+    expected = [TestWindowedValue(v + 1, MIN_TIMESTAMP, &lt;span class=&quot;error&quot;&gt;&amp;#91;GlobalWindow()&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+                for v in &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 3&amp;#93;&lt;/span&gt;]&lt;br/&gt;
+    with self.assertRaises(Exception):&lt;br/&gt;
+      with TestPipeline() as p:&lt;br/&gt;
+        assert_that(p | Create(&lt;span class=&quot;error&quot;&gt;&amp;#91;2, 3, 1&amp;#93;&lt;/span&gt;), equal_to(expected),&lt;br/&gt;
+                    reify_windows=True)&lt;br/&gt;
+&lt;br/&gt;
+  def test_windowed_value_assert_fail_unmatched_timestamp(self):&lt;br/&gt;
+    expected = [TestWindowedValue(v, 1, &lt;span class=&quot;error&quot;&gt;&amp;#91;GlobalWindow()&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+                for v in &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 3&amp;#93;&lt;/span&gt;]&lt;br/&gt;
+    with self.assertRaises(Exception):&lt;br/&gt;
+      with TestPipeline() as p:&lt;br/&gt;
+        assert_that(p | Create(&lt;span class=&quot;error&quot;&gt;&amp;#91;2, 3, 1&amp;#93;&lt;/span&gt;), equal_to(expected),&lt;br/&gt;
+                    reify_windows=True)&lt;br/&gt;
+&lt;br/&gt;
+  def test_windowed_value_assert_fail_unmatched_window(self):&lt;br/&gt;
+    expected = [TestWindowedValue(v, MIN_TIMESTAMP, &lt;span class=&quot;error&quot;&gt;&amp;#91;IntervalWindow(0, 1)&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+                for v in &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 3&amp;#93;&lt;/span&gt;]&lt;br/&gt;
+    with self.assertRaises(Exception):&lt;br/&gt;
+      with TestPipeline() as p:&lt;br/&gt;
+        assert_that(p | Create(&lt;span class=&quot;error&quot;&gt;&amp;#91;2, 3, 1&amp;#93;&lt;/span&gt;), equal_to(expected),&lt;br/&gt;
+                    reify_windows=True)&lt;br/&gt;
+&lt;br/&gt;
   def test_assert_that_fails_on_empty_input(self):&lt;br/&gt;
     with self.assertRaises(Exception):&lt;br/&gt;
       with TestPipeline() as p:&lt;br/&gt;
diff --git a/sdks/python/apache_beam/transforms/core.py b/sdks/python/apache_beam/transforms/core.py&lt;br/&gt;
index e650b399a07..533634dba58 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/transforms/core.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/transforms/core.py&lt;br/&gt;
@@ -1579,8 +1579,10 @@ class WindowIntoFn(DoFn):&lt;br/&gt;
     def _&lt;em&gt;init&lt;/em&gt;_(self, windowing):&lt;br/&gt;
       self.windowing = windowing&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def process(self, element, timestamp=DoFn.TimestampParam):&lt;/li&gt;
	&lt;li&gt;context = WindowFn.AssignContext(timestamp, element=element)&lt;br/&gt;
+    def process(self, element, timestamp=DoFn.TimestampParam,&lt;br/&gt;
+                window=DoFn.WindowParam):&lt;br/&gt;
+      context = WindowFn.AssignContext(timestamp, element=element,&lt;br/&gt;
+                                       window=window)&lt;br/&gt;
       new_windows = self.windowing.windowfn.assign(context)&lt;br/&gt;
       yield WindowedValue(element, context.timestamp, new_windows)&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/sdks/python/apache_beam/transforms/trigger.py b/sdks/python/apache_beam/transforms/trigger.py&lt;br/&gt;
index bd994010ef2..45aba6e5bcd 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/transforms/trigger.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/transforms/trigger.py&lt;br/&gt;
@@ -1138,20 +1138,37 @@ def clear_state(self, window, tag):&lt;br/&gt;
     if not self.state&lt;span class=&quot;error&quot;&gt;&amp;#91;window&amp;#93;&lt;/span&gt;:&lt;br/&gt;
       self.state.pop(window, None)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def get_timers(self, clear=False, watermark=MAX_TIMESTAMP):&lt;br/&gt;
+  def get_timers(self, clear=False, watermark=MAX_TIMESTAMP,&lt;br/&gt;
+                 processing_time=None):&lt;br/&gt;
+    &quot;&quot;&quot;Gets expired timers and reports if there&lt;br/&gt;
+    are any realtime timers set per state.&lt;br/&gt;
+&lt;br/&gt;
+    Expiration is measured against the watermark for event-time timers,&lt;br/&gt;
+    and against a wall clock for processing-time timers.&lt;br/&gt;
+    &quot;&quot;&quot;&lt;br/&gt;
     expired = []&lt;br/&gt;
+    has_realtime_timer = False&lt;br/&gt;
     for window, timers in list(self.timers.items()):&lt;br/&gt;
       for (name, time_domain), timestamp in list(timers.items()):&lt;/li&gt;
	&lt;li&gt;if timestamp &amp;lt;= watermark:&lt;br/&gt;
+        if time_domain == TimeDomain.REAL_TIME:&lt;br/&gt;
+          time_marker = processing_time&lt;br/&gt;
+          has_realtime_timer = True&lt;br/&gt;
+        elif time_domain == TimeDomain.WATERMARK:&lt;br/&gt;
+          time_marker = watermark&lt;br/&gt;
+        else:&lt;br/&gt;
+          logging.error(&lt;br/&gt;
+              &apos;TimeDomain error: No timers defined for time domain %s.&apos;,&lt;br/&gt;
+              time_domain)&lt;br/&gt;
+        if timestamp &amp;lt;= time_marker:&lt;br/&gt;
           expired.append((window, (name, time_domain, timestamp)))&lt;br/&gt;
           if clear:&lt;br/&gt;
             del timers&lt;span class=&quot;error&quot;&gt;&amp;#91;(name, time_domain)&amp;#93;&lt;/span&gt;&lt;br/&gt;
       if not timers and clear:&lt;br/&gt;
         del self.timers&lt;span class=&quot;error&quot;&gt;&amp;#91;window&amp;#93;&lt;/span&gt;&lt;/li&gt;
	&lt;li&gt;return expired&lt;br/&gt;
+    return expired, has_realtime_timer&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def get_and_clear_timers(self, watermark=MAX_TIMESTAMP):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return self.get_timers(clear=True, watermark=watermark)&lt;br/&gt;
+    return self.get_timers(clear=True, watermark=watermark)&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   def get_earliest_hold(self):&lt;br/&gt;
     earliest_hold = MAX_TIMESTAMP&lt;br/&gt;
diff --git a/sdks/python/apache_beam/transforms/util.py b/sdks/python/apache_beam/transforms/util.py&lt;br/&gt;
index 85d4975e3f5..332387ad414 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/transforms/util.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/transforms/util.py&lt;br/&gt;
@@ -22,6 +22,7 @@&lt;/p&gt;

&lt;p&gt; import collections&lt;br/&gt;
 import contextlib&lt;br/&gt;
+import random&lt;br/&gt;
 import time&lt;/p&gt;

&lt;p&gt; from apache_beam import typehints&lt;br/&gt;
@@ -29,12 +30,20 @@&lt;br/&gt;
 from apache_beam.transforms import window&lt;br/&gt;
 from apache_beam.transforms.core import CombinePerKey&lt;br/&gt;
 from apache_beam.transforms.core import DoFn&lt;br/&gt;
+from apache_beam.transforms.core import FlatMap&lt;br/&gt;
 from apache_beam.transforms.core import Flatten&lt;br/&gt;
 from apache_beam.transforms.core import GroupByKey&lt;br/&gt;
 from apache_beam.transforms.core import Map&lt;br/&gt;
 from apache_beam.transforms.core import ParDo&lt;br/&gt;
+from apache_beam.transforms.core import WindowInto&lt;br/&gt;
 from apache_beam.transforms.ptransform import PTransform&lt;br/&gt;
 from apache_beam.transforms.ptransform import ptransform_fn&lt;br/&gt;
+from apache_beam.transforms.trigger import AccumulationMode&lt;br/&gt;
+from apache_beam.transforms.trigger import AfterCount&lt;br/&gt;
+from apache_beam.transforms.window import NonMergingWindowFn&lt;br/&gt;
+from apache_beam.transforms.window import TimestampCombiner&lt;br/&gt;
+from apache_beam.transforms.window import TimestampedValue&lt;br/&gt;
+from apache_beam.utils import urns&lt;br/&gt;
 from apache_beam.utils import windowed_value&lt;/p&gt;

&lt;p&gt; _&lt;em&gt;all&lt;/em&gt;_ = [&lt;br/&gt;
@@ -43,10 +52,12 @@&lt;br/&gt;
     &apos;Keys&apos;,&lt;br/&gt;
     &apos;KvSwap&apos;,&lt;br/&gt;
     &apos;RemoveDuplicates&apos;,&lt;br/&gt;
+    &apos;Reshuffle&apos;,&lt;br/&gt;
     &apos;Values&apos;,&lt;br/&gt;
     ]&lt;/p&gt;

&lt;p&gt;-&lt;br/&gt;
+K = typehints.TypeVariable(&apos;K&apos;)&lt;br/&gt;
+V = typehints.TypeVariable(&apos;V&apos;)&lt;br/&gt;
 T = typehints.TypeVariable(&apos;T&apos;)&lt;/p&gt;


&lt;p&gt;@@ -423,3 +434,102 @@ def expand(self, pcoll):&lt;br/&gt;
           self._batch_size_estimator))&lt;br/&gt;
     else:&lt;br/&gt;
       return pcoll | ParDo(_WindowAwareBatchingDoFn(self._batch_size_estimator))&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+class _IdentityWindowFn(NonMergingWindowFn):&lt;br/&gt;
+  &quot;&quot;&quot;Windowing function that preserves existing windows.&lt;br/&gt;
+&lt;br/&gt;
+  To be used internally with the Reshuffle transform.&lt;br/&gt;
+  Will raise an exception when used after DoFns that return TimestampedValue&lt;br/&gt;
+  elements.&lt;br/&gt;
+  &quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+  def _&lt;em&gt;init&lt;/em&gt;_(self, window_coder):&lt;br/&gt;
+    &quot;&quot;&quot;Create a new WindowFn with compatible coder.&lt;br/&gt;
+    To be applied to PCollections with windows that are compatible with the&lt;br/&gt;
+    given coder.&lt;br/&gt;
+&lt;br/&gt;
+    Arguments:&lt;br/&gt;
+      window_coder: coders.Coder object to be used on windows.&lt;br/&gt;
+    &quot;&quot;&quot;&lt;br/&gt;
+    super(&lt;em&gt;IdentityWindowFn, self).&lt;/em&gt;&lt;em&gt;init&lt;/em&gt;_()&lt;br/&gt;
+    if window_coder is None:&lt;br/&gt;
+      raise ValueError(&apos;window_coder should not be None&apos;)&lt;br/&gt;
+    self._window_coder = window_coder&lt;br/&gt;
+&lt;br/&gt;
+  def assign(self, assign_context):&lt;br/&gt;
+    if assign_context.window is None:&lt;br/&gt;
+      raise ValueError(&lt;br/&gt;
+          &apos;assign_context.window should not be None. &apos;&lt;br/&gt;
+          &apos;This might be due to a DoFn returning a TimestampedValue.&apos;)&lt;br/&gt;
+    return &lt;span class=&quot;error&quot;&gt;&amp;#91;assign_context.window&amp;#93;&lt;/span&gt;&lt;br/&gt;
+&lt;br/&gt;
+  def get_window_coder(self):&lt;br/&gt;
+    return self._window_coder&lt;br/&gt;
+&lt;br/&gt;
+  def to_runner_api_parameter(self, unused_context):&lt;br/&gt;
+    pass  # Overridden by register_pickle_urn below.&lt;br/&gt;
+&lt;br/&gt;
+  urns.RunnerApiFn.register_pickle_urn(urns.RESHUFFLE_TRANSFORM)&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+@typehints.with_input_types(typehints.KV&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+@typehints.with_output_types(typehints.KV&lt;span class=&quot;error&quot;&gt;&amp;#91;K, V&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+class ReshufflePerKey(PTransform):&lt;br/&gt;
+  &quot;&quot;&quot;PTransform that returns a PCollection equivalent to its input,&lt;br/&gt;
+  but operationally provides some of the side effects of a GroupByKey,&lt;br/&gt;
+  in particular preventing fusion of the surrounding transforms,&lt;br/&gt;
+  checkpointing, and deduplication by id.&lt;br/&gt;
+&lt;br/&gt;
+  ReshufflePerKey is experimental. No backwards compatibility guarantees.&lt;br/&gt;
+  &quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+  def expand(self, pcoll):&lt;br/&gt;
+    class ReifyTimestamps(DoFn):&lt;br/&gt;
+      def process(self, element, timestamp=DoFn.TimestampParam):&lt;br/&gt;
+        yield element&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;, TimestampedValue(element&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;, timestamp)&lt;br/&gt;
+&lt;br/&gt;
+    class RestoreTimestamps(DoFn):&lt;br/&gt;
+      def process(self, element, window=DoFn.WindowParam):&lt;br/&gt;
+        # Pass the current window since _IdentityWindowFn wouldn&apos;t know how&lt;br/&gt;
+        # to generate it.&lt;br/&gt;
+        yield windowed_value.WindowedValue(&lt;br/&gt;
+            (element&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;, element&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;.value), element&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;.timestamp, &lt;span class=&quot;error&quot;&gt;&amp;#91;window&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+&lt;br/&gt;
+    windowing_saved = pcoll.windowing&lt;br/&gt;
+    result = (pcoll&lt;br/&gt;
+              | ParDo(ReifyTimestamps())&lt;br/&gt;
+              | &apos;IdentityWindow&apos; &amp;gt;&amp;gt; WindowInto(&lt;br/&gt;
+                  _IdentityWindowFn(&lt;br/&gt;
+                      windowing_saved.windowfn.get_window_coder()),&lt;br/&gt;
+                  trigger=AfterCount(1),&lt;br/&gt;
+                  accumulation_mode=AccumulationMode.DISCARDING,&lt;br/&gt;
+                  timestamp_combiner=TimestampCombiner.OUTPUT_AT_EARLIEST,&lt;br/&gt;
+                  )&lt;br/&gt;
+              | GroupByKey()&lt;br/&gt;
+              | &apos;ExpandIterable&apos; &amp;gt;&amp;gt; FlatMap(&lt;br/&gt;
+                  lambda e: [(e&lt;span class=&quot;error&quot;&gt;&amp;#91;0&amp;#93;&lt;/span&gt;, value) for value in e&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;])&lt;br/&gt;
+              | ParDo(RestoreTimestamps()))&lt;br/&gt;
+    result._windowing = windowing_saved&lt;br/&gt;
+    return result&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+@typehints.with_input_types(T)&lt;br/&gt;
+@typehints.with_output_types(T)&lt;br/&gt;
+class Reshuffle(PTransform):&lt;br/&gt;
+  &quot;&quot;&quot;PTransform that returns a PCollection equivalent to its input,&lt;br/&gt;
+  but operationally provides some of the side effects of a GroupByKey,&lt;br/&gt;
+  in particular preventing fusion of the surrounding transforms,&lt;br/&gt;
+  checkpointing, and deduplication by id.&lt;br/&gt;
+&lt;br/&gt;
+  Reshuffle adds a temporary random key to each element, performs a&lt;br/&gt;
+  ReshufflePerKey, and finally removes the temporary key.&lt;br/&gt;
+&lt;br/&gt;
+  Reshuffle is experimental. No backwards compatibility guarantees.&lt;br/&gt;
+  &quot;&quot;&quot;&lt;br/&gt;
+&lt;br/&gt;
+  def expand(self, pcoll):&lt;br/&gt;
+    return (pcoll&lt;br/&gt;
+            | &apos;AddRandomKeys&apos; &amp;gt;&amp;gt; Map(lambda t: (random.getrandbits(32), t))&lt;br/&gt;
+            | ReshufflePerKey()&lt;br/&gt;
+            | &apos;RemoveRandomKeys&apos; &amp;gt;&amp;gt; Map(lambda t: t&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;))&lt;br/&gt;
diff --git a/sdks/python/apache_beam/transforms/util_test.py b/sdks/python/apache_beam/transforms/util_test.py&lt;br/&gt;
index 6064e2ccce1..0be418028be 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/transforms/util_test.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/transforms/util_test.py&lt;br/&gt;
@@ -21,11 +21,24 @@&lt;br/&gt;
 import unittest&lt;/p&gt;

&lt;p&gt; import apache_beam as beam&lt;br/&gt;
+from apache_beam.coders import coders&lt;br/&gt;
+from apache_beam.options.pipeline_options import PipelineOptions&lt;br/&gt;
+from apache_beam.options.pipeline_options import StandardOptions&lt;br/&gt;
 from apache_beam.testing.test_pipeline import TestPipeline&lt;br/&gt;
+from apache_beam.testing.util import TestWindowedValue&lt;br/&gt;
 from apache_beam.testing.util import assert_that&lt;br/&gt;
+from apache_beam.testing.util import contains_in_any_order&lt;br/&gt;
 from apache_beam.testing.util import equal_to&lt;br/&gt;
 from apache_beam.transforms import util&lt;br/&gt;
 from apache_beam.transforms import window&lt;br/&gt;
+from apache_beam.transforms.window import GlobalWindow&lt;br/&gt;
+from apache_beam.transforms.window import GlobalWindows&lt;br/&gt;
+from apache_beam.transforms.window import IntervalWindow&lt;br/&gt;
+from apache_beam.transforms.window import Sessions&lt;br/&gt;
+from apache_beam.transforms.window import SlidingWindows&lt;br/&gt;
+from apache_beam.transforms.window import TimestampedValue&lt;br/&gt;
+from apache_beam.utils import timestamp&lt;br/&gt;
+from apache_beam.utils.windowed_value import WindowedValue&lt;/p&gt;


&lt;p&gt; class FakeClock(object):&lt;br/&gt;
@@ -106,3 +119,220 @@ def test_target_overhead(self):&lt;br/&gt;
       with batch_estimator.record_time(actual_sizes&lt;span class=&quot;error&quot;&gt;&amp;#91;-1&amp;#93;&lt;/span&gt;):&lt;br/&gt;
         clock.sleep(batch_duration(actual_sizes&lt;span class=&quot;error&quot;&gt;&amp;#91;-1&amp;#93;&lt;/span&gt;))&lt;br/&gt;
     self.assertEqual(expected_sizes, actual_sizes)&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+class IdentityWindowTest(unittest.TestCase):&lt;br/&gt;
+&lt;br/&gt;
+  def test_window_preserved(self):&lt;br/&gt;
+    expected_timestamp = timestamp.Timestamp(5)&lt;br/&gt;
+    expected_window = window.IntervalWindow(1.0, 2.0)&lt;br/&gt;
+&lt;br/&gt;
+    class AddWindowDoFn(beam.DoFn):&lt;br/&gt;
+      def process(self, element):&lt;br/&gt;
+        yield WindowedValue(&lt;br/&gt;
+            element, expected_timestamp, &lt;span class=&quot;error&quot;&gt;&amp;#91;expected_window&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 4)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    expected_windows = [&lt;br/&gt;
+        TestWindowedValue(kv, expected_timestamp, &lt;span class=&quot;error&quot;&gt;&amp;#91;expected_window&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+        for kv in data]&lt;br/&gt;
+    before_identity = (pipeline&lt;br/&gt;
+                       | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                       | &apos;add_windows&apos; &amp;gt;&amp;gt; beam.ParDo(AddWindowDoFn()))&lt;br/&gt;
+    assert_that(before_identity, equal_to(expected_windows),&lt;br/&gt;
+                label=&apos;before_identity&apos;, reify_windows=True)&lt;br/&gt;
+    after_identity = (before_identity&lt;br/&gt;
+                      | &apos;window&apos; &amp;gt;&amp;gt; beam.WindowInto(&lt;br/&gt;
+                          beam.transforms.util._IdentityWindowFn(&lt;br/&gt;
+                              coders.IntervalWindowCoder())))&lt;br/&gt;
+    assert_that(after_identity, equal_to(expected_windows),&lt;br/&gt;
+                label=&apos;after_identity&apos;, reify_windows=True)&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+  def test_no_window_context_fails(self):&lt;br/&gt;
+    expected_timestamp = timestamp.Timestamp(5)&lt;br/&gt;
+    # Assuming the default window function is window.GlobalWindows.&lt;br/&gt;
+    expected_window = window.GlobalWindow()&lt;br/&gt;
+&lt;br/&gt;
+    class AddTimestampDoFn(beam.DoFn):&lt;br/&gt;
+      def process(self, element):&lt;br/&gt;
+        yield window.TimestampedValue(element, expected_timestamp)&lt;br/&gt;
+&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 4)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    expected_windows = [&lt;br/&gt;
+        TestWindowedValue(kv, expected_timestamp, &lt;span class=&quot;error&quot;&gt;&amp;#91;expected_window&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+        for kv in data]&lt;br/&gt;
+    before_identity = (pipeline&lt;br/&gt;
+                       | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                       | &apos;add_timestamps&apos; &amp;gt;&amp;gt; beam.ParDo(AddTimestampDoFn()))&lt;br/&gt;
+    assert_that(before_identity, equal_to(expected_windows),&lt;br/&gt;
+                label=&apos;before_identity&apos;, reify_windows=True)&lt;br/&gt;
+    after_identity = (before_identity&lt;br/&gt;
+                      | &apos;window&apos; &amp;gt;&amp;gt; beam.WindowInto(&lt;br/&gt;
+                          beam.transforms.util._IdentityWindowFn(&lt;br/&gt;
+                              coders.GlobalWindowCoder()))&lt;br/&gt;
+                      # This DoFn will return TimestampedValues, making&lt;br/&gt;
+                      # WindowFn.AssignContext passed to IdentityWindowFn&lt;br/&gt;
+                      # contain a window of None. IdentityWindowFn should&lt;br/&gt;
+                      # raise an exception.&lt;br/&gt;
+                      | &apos;add_timestamps2&apos; &amp;gt;&amp;gt; beam.ParDo(AddTimestampDoFn()))&lt;br/&gt;
+    assert_that(after_identity, equal_to(expected_windows),&lt;br/&gt;
+                label=&apos;after_identity&apos;, reify_windows=True)&lt;br/&gt;
+    with self.assertRaisesRegexp(ValueError, r&apos;window.*None.*add_timestamps2&apos;):&lt;br/&gt;
+      pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+&lt;br/&gt;
+class ReshuffleTest(unittest.TestCase):&lt;br/&gt;
+&lt;br/&gt;
+  def test_reshuffle_contents_unchanged(self):&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 3)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    result = (pipeline&lt;br/&gt;
+              | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+              | &apos;reshuffle&apos; &amp;gt;&amp;gt; beam.Reshuffle())&lt;br/&gt;
+    assert_that(result, equal_to(data))&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+  def test_reshuffle_after_gbk_contents_unchanged(self):&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 3)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    expected_result = [(1, &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 3&amp;#93;&lt;/span&gt;), (2, &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2&amp;#93;&lt;/span&gt;), (3, &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;)]&lt;br/&gt;
+&lt;br/&gt;
+    after_gbk = (pipeline&lt;br/&gt;
+                 | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                 | &apos;group_by_key&apos; &amp;gt;&amp;gt; beam.GroupByKey())&lt;br/&gt;
+    assert_that(after_gbk, equal_to(expected_result), label=&apos;after_gbk&apos;)&lt;br/&gt;
+    after_reshuffle = (after_gbk&lt;br/&gt;
+                       | &apos;reshuffle&apos; &amp;gt;&amp;gt; beam.Reshuffle())&lt;br/&gt;
+    assert_that(after_reshuffle, equal_to(expected_result),&lt;br/&gt;
+                label=&apos;after_reshuffle&apos;)&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+  def test_reshuffle_timestamps_unchanged(self):&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    timestamp = 5&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 3)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    expected_result = [TestWindowedValue(v, timestamp, &lt;span class=&quot;error&quot;&gt;&amp;#91;GlobalWindow()&amp;#93;&lt;/span&gt;)&lt;br/&gt;
+                       for v in data]&lt;br/&gt;
+    before_reshuffle = (pipeline&lt;br/&gt;
+                        | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                        | &apos;add_timestamp&apos; &amp;gt;&amp;gt; beam.Map(&lt;br/&gt;
+                            lambda v: beam.window.TimestampedValue(v,&lt;br/&gt;
+                                                                   timestamp)))&lt;br/&gt;
+    assert_that(before_reshuffle, equal_to(expected_result),&lt;br/&gt;
+                label=&apos;before_reshuffle&apos;, reify_windows=True)&lt;br/&gt;
+    after_reshuffle = (before_reshuffle&lt;br/&gt;
+                       | &apos;reshuffle&apos; &amp;gt;&amp;gt; beam.Reshuffle())&lt;br/&gt;
+    assert_that(after_reshuffle, equal_to(expected_result),&lt;br/&gt;
+                label=&apos;after_reshuffle&apos;, reify_windows=True)&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+  def test_reshuffle_windows_unchanged(self):&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 4)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    expected_data = [TestWindowedValue(v, t, &lt;span class=&quot;error&quot;&gt;&amp;#91;w&amp;#93;&lt;/span&gt;) for (v, t, w) in&lt;br/&gt;
+                     [((1, &lt;span class=&quot;error&quot;&gt;&amp;#91;2, 1&amp;#93;&lt;/span&gt;), 4.0, IntervalWindow(1.0, 4.0)),&lt;br/&gt;
+                      ((2, &lt;span class=&quot;error&quot;&gt;&amp;#91;2, 1&amp;#93;&lt;/span&gt;), 4.0, IntervalWindow(1.0, 4.0)),&lt;br/&gt;
+                      ((3, &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;), 3.0, IntervalWindow(1.0, 3.0)),&lt;br/&gt;
+                      ((1, &lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt;), 6.0, IntervalWindow(4.0, 6.0))]]&lt;br/&gt;
+    before_reshuffle = (pipeline&lt;br/&gt;
+                        | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                        | &apos;add_timestamp&apos; &amp;gt;&amp;gt; beam.Map(&lt;br/&gt;
+                            lambda v: beam.window.TimestampedValue(v, v&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;))&lt;br/&gt;
+                        | &apos;window&apos; &amp;gt;&amp;gt; beam.WindowInto(Sessions(gap_size=2))&lt;br/&gt;
+                        | &apos;group_by_key&apos; &amp;gt;&amp;gt; beam.GroupByKey())&lt;br/&gt;
+    assert_that(before_reshuffle, equal_to(expected_data),&lt;br/&gt;
+                label=&apos;before_reshuffle&apos;, reify_windows=True)&lt;br/&gt;
+    after_reshuffle = (before_reshuffle&lt;br/&gt;
+                       | &apos;reshuffle&apos; &amp;gt;&amp;gt; beam.Reshuffle())&lt;br/&gt;
+    assert_that(after_reshuffle, equal_to(expected_data),&lt;br/&gt;
+                label=&apos;after reshuffle&apos;, reify_windows=True)&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+  def test_reshuffle_window_fn_preserved(self):&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 4)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    expected_windows = [TestWindowedValue(v, t, &lt;span class=&quot;error&quot;&gt;&amp;#91;w&amp;#93;&lt;/span&gt;) for (v, t, w) in [&lt;br/&gt;
+        ((1, 1), 1.0, IntervalWindow(1.0, 3.0)),&lt;br/&gt;
+        ((2, 1), 1.0, IntervalWindow(1.0, 3.0)),&lt;br/&gt;
+        ((3, 1), 1.0, IntervalWindow(1.0, 3.0)),&lt;br/&gt;
+        ((1, 2), 2.0, IntervalWindow(2.0, 4.0)),&lt;br/&gt;
+        ((2, 2), 2.0, IntervalWindow(2.0, 4.0)),&lt;br/&gt;
+        ((1, 4), 4.0, IntervalWindow(4.0, 6.0))]]&lt;br/&gt;
+    expected_merged_windows = [TestWindowedValue(v, t, &lt;span class=&quot;error&quot;&gt;&amp;#91;w&amp;#93;&lt;/span&gt;) for (v, t, w) in [&lt;br/&gt;
+        ((1, contains_in_any_order(&lt;span class=&quot;error&quot;&gt;&amp;#91;2, 1&amp;#93;&lt;/span&gt;)), 4.0, IntervalWindow(1.0, 4.0)),&lt;br/&gt;
+        ((2, contains_in_any_order(&lt;span class=&quot;error&quot;&gt;&amp;#91;2, 1&amp;#93;&lt;/span&gt;)), 4.0, IntervalWindow(1.0, 4.0)),&lt;br/&gt;
+        ((3, &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;), 3.0, IntervalWindow(1.0, 3.0)),&lt;br/&gt;
+        ((1, &lt;span class=&quot;error&quot;&gt;&amp;#91;4&amp;#93;&lt;/span&gt;), 6.0, IntervalWindow(4.0, 6.0))]]&lt;br/&gt;
+    before_reshuffle = (pipeline&lt;br/&gt;
+                        | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                        | &apos;add_timestamp&apos; &amp;gt;&amp;gt; beam.Map(&lt;br/&gt;
+                            lambda v: TimestampedValue(v, v&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;))&lt;br/&gt;
+                        | &apos;window&apos; &amp;gt;&amp;gt; beam.WindowInto(Sessions(gap_size=2)))&lt;br/&gt;
+    assert_that(before_reshuffle, equal_to(expected_windows),&lt;br/&gt;
+                label=&apos;before_reshuffle&apos;, reify_windows=True)&lt;br/&gt;
+    after_reshuffle = (before_reshuffle&lt;br/&gt;
+                       | &apos;reshuffle&apos; &amp;gt;&amp;gt; beam.Reshuffle())&lt;br/&gt;
+    assert_that(after_reshuffle, equal_to(expected_windows),&lt;br/&gt;
+                label=&apos;after_reshuffle&apos;, reify_windows=True)&lt;br/&gt;
+    after_group = (after_reshuffle&lt;br/&gt;
+                   | &apos;group_by_key&apos; &amp;gt;&amp;gt; beam.GroupByKey())&lt;br/&gt;
+    assert_that(after_group, equal_to(expected_merged_windows),&lt;br/&gt;
+                label=&apos;after_group&apos;, reify_windows=True)&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+  def test_reshuffle_global_window(self):&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 4)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    expected_data = [(1, &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 4&amp;#93;&lt;/span&gt;), (2, &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2&amp;#93;&lt;/span&gt;), (3, &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;)]&lt;br/&gt;
+    before_reshuffle = (pipeline&lt;br/&gt;
+                        | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                        | &apos;window&apos; &amp;gt;&amp;gt; beam.WindowInto(GlobalWindows())&lt;br/&gt;
+                        | &apos;group_by_key&apos; &amp;gt;&amp;gt; beam.GroupByKey())&lt;br/&gt;
+    assert_that(before_reshuffle, equal_to(expected_data),&lt;br/&gt;
+                label=&apos;before_reshuffle&apos;)&lt;br/&gt;
+    after_reshuffle = (before_reshuffle&lt;br/&gt;
+                       | &apos;reshuffle&apos; &amp;gt;&amp;gt; beam.Reshuffle())&lt;br/&gt;
+    assert_that(after_reshuffle, equal_to(expected_data),&lt;br/&gt;
+                label=&apos;after reshuffle&apos;)&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+  def test_reshuffle_sliding_window(self):&lt;br/&gt;
+    pipeline = TestPipeline()&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 4)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    window_size = 2&lt;br/&gt;
+    expected_data = [(1, &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 4&amp;#93;&lt;/span&gt;), (2, &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2&amp;#93;&lt;/span&gt;), (3, &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;)] * window_size&lt;br/&gt;
+    before_reshuffle = (pipeline&lt;br/&gt;
+                        | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                        | &apos;window&apos; &amp;gt;&amp;gt; beam.WindowInto(SlidingWindows(&lt;br/&gt;
+                            size=window_size, period=1))&lt;br/&gt;
+                        | &apos;group_by_key&apos; &amp;gt;&amp;gt; beam.GroupByKey())&lt;br/&gt;
+    assert_that(before_reshuffle, equal_to(expected_data),&lt;br/&gt;
+                label=&apos;before_reshuffle&apos;)&lt;br/&gt;
+    after_reshuffle = (before_reshuffle&lt;br/&gt;
+                       | &apos;reshuffle&apos; &amp;gt;&amp;gt; beam.Reshuffle())&lt;br/&gt;
+    # If Reshuffle applies the sliding window function a second time there&lt;br/&gt;
+    # should be extra values for each key.&lt;br/&gt;
+    assert_that(after_reshuffle, equal_to(expected_data),&lt;br/&gt;
+                label=&apos;after reshuffle&apos;)&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
+&lt;br/&gt;
+  def test_reshuffle_streaming_global_window(self):&lt;br/&gt;
+    options = PipelineOptions()&lt;br/&gt;
+    options.view_as(StandardOptions).streaming = True&lt;br/&gt;
+    pipeline = TestPipeline(options=options)&lt;br/&gt;
+    data = &lt;span class=&quot;error&quot;&gt;&amp;#91;(1, 1), (2, 1), (3, 1), (1, 2), (2, 2), (1, 4)&amp;#93;&lt;/span&gt;&lt;br/&gt;
+    expected_data = [(1, &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2, 4&amp;#93;&lt;/span&gt;), (2, &lt;span class=&quot;error&quot;&gt;&amp;#91;1, 2&amp;#93;&lt;/span&gt;), (3, &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;)]&lt;br/&gt;
+    before_reshuffle = (pipeline&lt;br/&gt;
+                        | &apos;start&apos; &amp;gt;&amp;gt; beam.Create(data)&lt;br/&gt;
+                        | &apos;window&apos; &amp;gt;&amp;gt; beam.WindowInto(GlobalWindows())&lt;br/&gt;
+                        | &apos;group_by_key&apos; &amp;gt;&amp;gt; beam.GroupByKey())&lt;br/&gt;
+    assert_that(before_reshuffle, equal_to(expected_data),&lt;br/&gt;
+                label=&apos;before_reshuffle&apos;)&lt;br/&gt;
+    after_reshuffle = (before_reshuffle&lt;br/&gt;
+                       | &apos;reshuffle&apos; &amp;gt;&amp;gt; beam.Reshuffle())&lt;br/&gt;
+    assert_that(after_reshuffle, equal_to(expected_data),&lt;br/&gt;
+                label=&apos;after reshuffle&apos;)&lt;br/&gt;
+    pipeline.run()&lt;br/&gt;
diff --git a/sdks/python/apache_beam/transforms/window.py b/sdks/python/apache_beam/transforms/window.py&lt;br/&gt;
index 8c8bf336bab..ee9d6f97187 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/transforms/window.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/transforms/window.py&lt;br/&gt;
@@ -114,13 +114,21 @@ class WindowFn(urns.RunnerApiFn):&lt;br/&gt;
   class AssignContext(object):&lt;br/&gt;
     &quot;&quot;&quot;Context passed to WindowFn.assign().&quot;&quot;&quot;&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;def _&lt;em&gt;init&lt;/em&gt;_(self, timestamp, element=None):&lt;br/&gt;
+    def _&lt;em&gt;init&lt;/em&gt;_(self, timestamp, element=None, window=None):&lt;br/&gt;
       self.timestamp = Timestamp.of(timestamp)&lt;br/&gt;
       self.element = element&lt;br/&gt;
+      self.window = window&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   @abc.abstractmethod&lt;br/&gt;
   def assign(self, assign_context):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;&quot;&quot;Associates a timestamp to an element.&quot;&quot;&quot;&lt;br/&gt;
+    &quot;&quot;&quot;Associates windows to an element.&lt;br/&gt;
+&lt;br/&gt;
+    Arguments:&lt;br/&gt;
+      assign_context: Instance of AssignContext.&lt;br/&gt;
+&lt;br/&gt;
+    Returns:&lt;br/&gt;
+      An iterable of BoundedWindow.&lt;br/&gt;
+    &quot;&quot;&quot;&lt;br/&gt;
     raise NotImplementedError&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;   class MergeContext(object):&lt;br/&gt;
diff --git a/sdks/python/apache_beam/utils/counters.py b/sdks/python/apache_beam/utils/counters.py&lt;br/&gt;
index ae974344259..e2e0a1a730b 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/utils/counters.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/utils/counters.py&lt;br/&gt;
@@ -29,19 +29,18 @@&lt;br/&gt;
 from apache_beam.transforms import cy_combiners&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;Information identifying the IO being measured by a counter.&lt;br/&gt;
-IOTargetName = namedtuple(&apos;IOTargetName&apos;, [&apos;side_input_step_name&apos;,&lt;/li&gt;
&lt;/ol&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&apos;side_input_index&apos;,&lt;/li&gt;
	&lt;li&gt;&apos;original_shuffle_step_name&apos;])&lt;br/&gt;
+IOTargetName = namedtuple(&apos;IOTargetName&apos;, [&apos;requesting_step_name&apos;,&lt;br/&gt;
+                                           &apos;input_index&apos;])&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; def side_input_id(step_name, input_index):&lt;br/&gt;
   &quot;&quot;&quot;Create an IOTargetName that identifies the reading of a side input.&quot;&quot;&quot;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return IOTargetName(step_name, input_index, None)&lt;br/&gt;
+  return IOTargetName(step_name, input_index)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; def shuffle_id(step_name):&lt;br/&gt;
   &quot;&quot;&quot;Create an IOTargetName that identifies a GBK step.&quot;&quot;&quot;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;return IOTargetName(None, None, step_name)&lt;br/&gt;
+  return IOTargetName(step_name, None)&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; _CounterName = namedtuple(&apos;_CounterName&apos;, [&apos;name&apos;,&lt;br/&gt;
diff --git a/sdks/python/apache_beam/utils/urns.py b/sdks/python/apache_beam/utils/urns.py&lt;br/&gt;
index 1359f323bd9..6bdc29fbc6f 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/apache_beam/utils/urns.py&lt;br/&gt;
+++ b/sdks/python/apache_beam/utils/urns.py&lt;br/&gt;
@@ -37,13 +37,14 @@&lt;/p&gt;

&lt;p&gt; PICKLED_TRANSFORM = &quot;beam:ptransform:pickled_python:v0.1&quot;&lt;br/&gt;
 PARDO_TRANSFORM = &quot;beam:ptransform:pardo:v0.1&quot;&lt;br/&gt;
-GROUP_BY_KEY_TRANSFORM = &quot;beam:ptransform:group_by_key:v0.1&quot;&lt;br/&gt;
+GROUP_BY_KEY_TRANSFORM = &quot;urn:beam:transform:groupbykey:v1&quot;&lt;br/&gt;
 GROUP_BY_KEY_ONLY_TRANSFORM = &quot;beam:ptransform:group_by_key_only:v0.1&quot;&lt;br/&gt;
 GROUP_ALSO_BY_WINDOW_TRANSFORM = &quot;beam:ptransform:group_also_by_window:v0.1&quot;&lt;br/&gt;
 COMBINE_PER_KEY_TRANSFORM = &quot;beam:ptransform:combine_per_key:v0.1&quot;&lt;br/&gt;
 COMBINE_GROUPED_VALUES_TRANSFORM = &quot;beam:ptransform:combine_grouped_values:v0.1&quot;&lt;br/&gt;
 FLATTEN_TRANSFORM = &quot;beam:ptransform:flatten:v0.1&quot;&lt;br/&gt;
 READ_TRANSFORM = &quot;beam:ptransform:read:v0.1&quot;&lt;br/&gt;
+RESHUFFLE_TRANSFORM = &quot;beam:ptransform:reshuffle:v0.1&quot;&lt;br/&gt;
 WINDOW_INTO_TRANSFORM = &quot;beam:ptransform:window_into:v0.1&quot;&lt;/p&gt;

&lt;p&gt; PICKLED_SOURCE = &quot;beam:source:pickled_python:v0.1&quot;&lt;br/&gt;
@@ -90,9 +91,9 @@ def to_runner_api_parameter(self, unused_context):&lt;/p&gt;

&lt;p&gt;   @classmethod&lt;br/&gt;
   def register_urn(cls, urn, parameter_type, fn=None):&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&quot;&quot;&quot;Registeres a urn with a constructor.&lt;br/&gt;
+    &quot;&quot;&quot;Registers a urn with a constructor.&lt;/li&gt;
&lt;/ul&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;For example, if &apos;beam:fn:foo&apos; had paramter type FooPayload, one could&lt;br/&gt;
+    For example, if &apos;beam:fn:foo&apos; had parameter type FooPayload, one could&lt;br/&gt;
     write `RunnerApiFn.register_urn(&apos;bean:fn:foo&apos;, FooPayload, foo_from_proto)`&lt;br/&gt;
     where foo_from_proto took as arguments a FooPayload and a PipelineContext.&lt;br/&gt;
     This function can also be used as a decorator rather than passing the&lt;br/&gt;
diff --git a/sdks/python/container/boot.go b/sdks/python/container/boot.go&lt;br/&gt;
index fea0935c31f..31c82674d51 100644
	&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
		&lt;li&gt;
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/sdks/python/container/boot.go&lt;br/&gt;
+++ b/sdks/python/container/boot.go&lt;br/&gt;
@@ -95,6 +95,7 @@ func main() {&lt;br/&gt;
 	// (3) Invoke python&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	os.Setenv(&quot;PIPELINE_OPTIONS&quot;, options)&lt;br/&gt;
+	os.Setenv(&quot;SEMI_PERSISTENT_DIRECTORY&quot;, *semiPersistDir)&lt;br/&gt;
 	os.Setenv(&quot;LOGGING_API_SERVICE_DESCRIPTOR&quot;, proto.MarshalTextString(&amp;amp;pb.ApiServiceDescriptor&lt;/p&gt;
{Url: *loggingEndpoint}
&lt;p&gt;))&lt;br/&gt;
 	os.Setenv(&quot;CONTROL_API_SERVICE_DESCRIPTOR&quot;, proto.MarshalTextString(&amp;amp;pb.ApiServiceDescriptor&lt;/p&gt;
{Url: *controlEndpoint}
&lt;p&gt;))&lt;/p&gt;

&lt;p&gt;diff --git a/sdks/python/gen_protos.py b/sdks/python/gen_protos.py&lt;br/&gt;
index 6caf3ac43e1..09066ee92e4 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/gen_protos.py&lt;br/&gt;
+++ b/sdks/python/gen_protos.py&lt;br/&gt;
@@ -136,9 +136,13 @@ def _install_grpcio_tools_and_generate_proto_files():&lt;br/&gt;
     logging.warning(&lt;br/&gt;
         &apos;Installing grpcio-tools took %0.2f seconds.&apos; % (time.time() - start))&lt;br/&gt;
   finally:&lt;br/&gt;
+    sys.stderr.flush()&lt;br/&gt;
     shutil.rmtree(build_path)&lt;br/&gt;
   sys.path.append(install_path)&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;generate_proto_files()&lt;br/&gt;
+  try:&lt;br/&gt;
+    generate_proto_files()&lt;br/&gt;
+  finally:&lt;br/&gt;
+    sys.stderr.flush()&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt; if _&lt;em&gt;name&lt;/em&gt;_ == &apos;_&lt;em&gt;main&lt;/em&gt;_&apos;:&lt;br/&gt;
diff --git a/sdks/python/run_pylint.sh b/sdks/python/run_pylint.sh&lt;br/&gt;
index 4c57e751188..d2d424e28d9 100755&lt;br/&gt;
&amp;#8212; a/sdks/python/run_pylint.sh&lt;br/&gt;
+++ b/sdks/python/run_pylint.sh&lt;br/&gt;
@@ -81,7 +81,7 @@ for file in &quot;${EXCLUDED_GENERATED_FILES&lt;span class=&quot;error&quot;&gt;&amp;#91;@&amp;#93;&lt;/span&gt;}&quot;; do&lt;br/&gt;
   SKIP_PARAM=&quot;$SKIP_PARAM --skip $(basename $file)&quot;&lt;br/&gt;
 done&lt;br/&gt;
 pushd &quot;$MODULE&quot;&lt;br/&gt;
-isort -p apache_beam -w 120 -y -c -ot -cs -sl ${SKIP_PARAM}&lt;br/&gt;
+isort -p apache_beam --line-width 120 --check-only --order-by-type --combine-star --force-single-line-imports --diff ${SKIP_PARAM}&lt;br/&gt;
 popd&lt;br/&gt;
 FUTURIZE_EXCLUDED=(&lt;br/&gt;
   &quot;typehints.py&quot;&lt;br/&gt;
diff --git a/sdks/python/setup.py b/sdks/python/setup.py&lt;br/&gt;
index e83a49000e6..b1ec92f1821 100644&lt;br/&gt;
&amp;#8212; a/sdks/python/setup.py&lt;br/&gt;
+++ b/sdks/python/setup.py&lt;br/&gt;
@@ -118,10 +118,6 @@ def get_version():&lt;/p&gt;

&lt;p&gt; REQUIRED_TEST_PACKAGES = [&lt;br/&gt;
     &apos;pyhamcrest&amp;gt;=1.9,&amp;lt;2.0&apos;,&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;# Six required by nose plugins management.&lt;/li&gt;
	&lt;li&gt;# Six 1.11.0 incompatible with apitools.&lt;/li&gt;
	&lt;li&gt;# TODO(&lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-2964&quot; title=&quot;Latest six (1.11.0) produces &amp;quot;metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases&amp;quot;&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-2964&quot;&gt;&lt;del&gt;BEAM-2964&lt;/del&gt;&lt;/a&gt;): Remove the upper bound.&lt;/li&gt;
	&lt;li&gt;&apos;six&amp;gt;=1.9,&amp;lt;1.11&apos;,&lt;br/&gt;
     ]&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; GCP_REQUIREMENTS = [&lt;br/&gt;
diff --git a/settings.gradle b/settings.gradle&lt;br/&gt;
index 7eb25aac362..1ed6564cbca 100644&lt;br/&gt;
&amp;#8212; a/settings.gradle&lt;br/&gt;
+++ b/settings.gradle&lt;br/&gt;
@@ -76,6 +76,7 @@ include &apos;:beam-runners-parent:beam-java-fn-execution&apos;&lt;br/&gt;
 include &apos;:beam-runners-parent:beam-runners-core-construction-java&apos;&lt;br/&gt;
 include &apos;:beam-runners-parent:beam-runners-core-java&apos;&lt;br/&gt;
 include &apos;:beam-runners-parent:beam-local-artifact-service-java&apos;&lt;br/&gt;
+include &apos;:beam-runners-parent:beam-runners-reference-parent:beam-runners-reference-java&apos;&lt;br/&gt;
 include &apos;:beam-runners-parent:beam-runners-reference-parent:beam-runners-reference-job-orchestrator&apos;&lt;br/&gt;
 include &apos;:beam-runners-parent:beam-runners-reference-parent&apos;&lt;br/&gt;
 include &apos;:beam-runners-parent:beam-runners-direct-java&apos;&lt;br/&gt;
@@ -153,6 +154,7 @@ project(&apos;:beam-runners-parent:beam-java-fn-execution&apos;).projectDir = &quot;$rootDir/ru&lt;br/&gt;
 project(&apos;:beam-runners-parent:beam-runners-core-construction-java&apos;).projectDir = &quot;$rootDir/runners/core-construction-java&quot; as File&lt;br/&gt;
 project(&apos;:beam-runners-parent:beam-runners-core-java&apos;).projectDir = &quot;$rootDir/runners/core-java&quot; as File&lt;br/&gt;
 project(&apos;:beam-runners-parent:beam-local-artifact-service-java&apos;).projectDir = &quot;$rootDir/runners/local-artifact-service-java&quot; as File&lt;br/&gt;
+project(&apos;:beam-runners-parent:beam-runners-reference-parent:beam-runners-reference-java&apos;).projectDir = &quot;$rootDir/runners/reference/java&quot; as File&lt;br/&gt;
 project(&apos;:beam-runners-parent:beam-runners-reference-parent:beam-runners-reference-job-orchestrator&apos;).projectDir = &quot;$rootDir/runners/reference/job-server&quot; as File&lt;br/&gt;
 project(&apos;:beam-runners-parent:beam-runners-reference-parent&apos;).projectDir = &quot;$rootDir/runners/reference&quot; as File&lt;br/&gt;
 project(&apos;:beam-runners-parent:beam-runners-direct-java&apos;).projectDir = &quot;$rootDir/runners/direct-java&quot; as File&lt;/p&gt;




&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16295611" author="githubbot" created="Mon, 18 Dec 2017 20:10:24 +0000"  >&lt;p&gt;wcn3 opened a new pull request #4285: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3361&quot; title=&quot;Go SDK needs to increase gRPC receive buffer size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3361&quot;&gt;&lt;del&gt;BEAM-3361&lt;/del&gt;&lt;/a&gt; Increase Go gRPC message size&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/beam/pull/4285&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/4285&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Increases the buffer for gRPC messages from 4M to 50M.&lt;/p&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16297367" author="githubbot" created="Tue, 19 Dec 2017 20:17:38 +0000"  >&lt;p&gt;lukecwik closed pull request #4285: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3361&quot; title=&quot;Go SDK needs to increase gRPC receive buffer size&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3361&quot;&gt;&lt;del&gt;BEAM-3361&lt;/del&gt;&lt;/a&gt; Increase Go gRPC message size&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/beam/pull/4285&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/4285&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/sdks/go/pkg/beam/core/runtime/harness/harness.go b/sdks/go/pkg/beam/core/runtime/harness/harness.go&lt;br/&gt;
index 76d516fba02..59df85734fc 100644&lt;br/&gt;
&amp;#8212; a/sdks/go/pkg/beam/core/runtime/harness/harness.go&lt;br/&gt;
+++ b/sdks/go/pkg/beam/core/runtime/harness/harness.go&lt;br/&gt;
@@ -243,7 +243,8 @@ func fail(id, format string, args ...interface{}) *fnpb.InstructionResponse {&lt;br/&gt;
 func dial(ctx context.Context, endpoint string, timeout time.Duration) (*grpc.ClientConn, error) {&lt;br/&gt;
 	log.Infof(ctx, &quot;Connecting via grpc @ %s ...&quot;, endpoint)&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;opts := []grpc.DialOption
{grpc.WithInsecure(), grpc.WithBlock()}
&lt;p&gt;+	opts := []grpc.DialOption&lt;/p&gt;
{grpc.WithInsecure(), grpc.WithBlock(),
+		grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(50 &amp;lt;&amp;lt; 20))}&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; 	// TODO(wcn): Update this code to not use deprecated grpc.WithTimeout&lt;br/&gt;
 	if timeout &amp;gt; 0 {&lt;br/&gt;
diff --git a/sdks/go/pkg/beam/util/grpcx/dial.go b/sdks/go/pkg/beam/util/grpcx/dial.go&lt;br/&gt;
index 8467ace1ba4..d0dd1f7dc75 100644&lt;br/&gt;
&amp;#8212; a/sdks/go/pkg/beam/util/grpcx/dial.go&lt;br/&gt;
+++ b/sdks/go/pkg/beam/util/grpcx/dial.go&lt;br/&gt;
@@ -29,7 +29,8 @@ func Dial(ctx context.Context, endpoint string, timeout time.Duration) (*grpc.Cl&lt;br/&gt;
 	ctx, cancel := context.WithTimeout(ctx, timeout)&lt;br/&gt;
 	defer cancel()&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;cc, err := grpc.DialContext(ctx, endpoint, grpc.WithInsecure(), grpc.WithBlock())&lt;br/&gt;
+	cc, err := grpc.DialContext(ctx, endpoint, grpc.WithInsecure(), grpc.WithBlock(),&lt;br/&gt;
+		grpc.WithDefaultCallOptions(grpc.MaxCallRecvMsgSize(50&amp;lt;&amp;lt;20)))&lt;br/&gt;
 	if err != nil 
{
 		return nil, fmt.Errorf(&quot;failed to dial server at %v: %v&quot;, endpoint, err)
 	}&lt;/li&gt;
&lt;/ul&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16377613" author="wcn3" created="Mon, 26 Feb 2018 21:36:07 +0000"  >&lt;p&gt;Fixed in&#160;&lt;a href=&quot;https://github.com/apache/beam/pull/4285&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/4285&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 38 weeks ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3nynz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>