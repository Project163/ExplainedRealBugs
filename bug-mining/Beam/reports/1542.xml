<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 11:04:45 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-8944] Python SDK harness performance degradation with UnboundedThreadPoolExecutor</title>
                <link>https://issues.apache.org/jira/browse/BEAM-8944</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>&lt;p&gt;We are seeing a performance degradation for python streaming word count load tests.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;After some investigation, it appears to be caused by swapping the original ThreadPoolExecutor to UnboundedThreadPoolExecutor in sdk worker. Suspicion is that python performance is worse with more threads on cpu-bounded tasks.&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;A simple test for comparing the multiple thread pool executor performance:&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-python&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; test_performance(&lt;span class=&quot;code-keyword&quot;&gt;self&lt;/span&gt;):
 &#160; &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; run_perf(executor):
 &#160; &#160; total_number = 1000000
 &#160; &#160; q = queue.Queue()

&#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; task(number):
 &#160; &#160; &#160; &lt;span class=&quot;code-object&quot;&gt;hash&lt;/span&gt;(number)
 &#160; &#160; &#160; q.put(number + 200)
 &#160; &#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; number

&#160; &#160; t = time.time()
 &#160; &#160; count = 0
 &#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;range&lt;/span&gt;(200):
 &#160; &#160; &#160; q.put(i)

&#160; &#160; &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; count &amp;lt; total_number:
 &#160; &#160; &#160; executor.submit(task, q.get(block=&lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;True&lt;/span&gt;&lt;/span&gt;))
 &#160; &#160; &#160; count += 1
 &#160; &#160; &lt;span class=&quot;code-object&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&apos;%s uses %s&apos;&lt;/span&gt; % (executor, time.time() - t))

&#160;  &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; UnboundedThreadPoolExecutor() &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; executor:
 &#160; &#160; run_perf(executor)
 &#160; &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; futures.ThreadPoolExecutor(max_workers=1) &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; executor:
 &#160; &#160; run_perf(executor)
 &#160; &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; futures.ThreadPoolExecutor(max_workers=12) &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; executor:
 &#160; &#160; run_perf(executor)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;



&lt;p&gt;Results:&lt;/p&gt;


&lt;p&gt;&amp;lt;apache_beam.utils.thread_pool_executor.UnboundedThreadPoolExecutor object at 0x7fab400dbe50&amp;gt; uses 268.160675049&lt;br/&gt;
 &amp;lt;concurrent.futures.thread.ThreadPoolExecutor object at 0x7fab40096290&amp;gt; uses 79.904583931&lt;br/&gt;
 &amp;lt;concurrent.futures.thread.ThreadPoolExecutor object at 0x7fab400dbe50&amp;gt; uses 191.179054976&lt;br/&gt;
 ```&lt;/p&gt;

&lt;p&gt;Profiling:&lt;br/&gt;
UnboundedThreadPoolExecutor:&lt;br/&gt;
 &lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12988582/12988582_profiling.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt; &lt;/p&gt;

&lt;p&gt;1 Thread ThreadPoolExecutor:&lt;br/&gt;
 &lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12988583/12988583_profiling_one_thread.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt; &lt;/p&gt;

&lt;p&gt;12 Threads ThreadPoolExecutor:&lt;br/&gt;
 &lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12988584/12988584_profiling_twelve_threads.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt; &lt;/p&gt;


</description>
                <environment></environment>
        <key id="13273743">BEAM-8944</key>
            <summary>Python SDK harness performance degradation with UnboundedThreadPoolExecutor</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10101" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">P1</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="lcwik">Luke Cwik</assignee>
                                    <reporter username="yichi">Yichi Zhang</reporter>
                        <labels>
                    </labels>
                <created>Wed, 11 Dec 2019 02:23:53 +0000</created>
                <updated>Fri, 29 May 2020 22:02:25 +0000</updated>
                            <resolved>Thu, 7 May 2020 15:32:38 +0000</resolved>
                                    <version>2.18.0</version>
                                    <fixVersion>2.22.0</fixVersion>
                                    <component>sdk-py-harness</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="29400">8h 10m</timespent>
                                <comments>
                            <comment id="16993141" author="yichi" created="Wed, 11 Dec 2019 02:28:16 +0000"  >&lt;p&gt;CC: &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=angoenka&quot; class=&quot;user-hover&quot; rel=&quot;angoenka&quot;&gt;angoenka&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lcwik&quot; class=&quot;user-hover&quot; rel=&quot;lcwik&quot;&gt;lcwik&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16994104" author="yichi" created="Thu, 12 Dec 2019 02:36:53 +0000"  >&lt;p&gt;Seems like the original change was to solve deadlock and stuckness issue.&lt;/p&gt;

&lt;p&gt;While the usage of UnboundedThreadPoolExecutor does seem to impact pipelines that saturate cpu usage (~90%) quite a bit, it has less effect on under loaded pipelines.&lt;/p&gt;</comment>
                            <comment id="17000313" author="udim" created="Thu, 19 Dec 2019 19:15:20 +0000"  >&lt;p&gt;Does this bug affect current production runners (such as Dataflow runner mention in the TODO in #10387)?&lt;/p&gt;</comment>
                            <comment id="17000341" author="yichi" created="Thu, 19 Dec 2019 20:10:20 +0000"  >&lt;p&gt;This bug doesn&apos;t affect current production runners since the change of using more threads in SDK Harness doesn&apos;t exist in current released beam versions (the&#160;Dataflow runner issue mentioned in #10387 TODO affect current production runners but has limited impact with this fix, and will be investigated later).&lt;/p&gt;</comment>
                            <comment id="17000443" author="udim" created="Thu, 19 Dec 2019 22:03:39 +0000"  >&lt;p&gt;By current I don&apos;t mean the current Beam release but the current production-ready runners (for example IIUC portability on Dataflow is not production ready).&lt;/p&gt;</comment>
                            <comment id="17000445" author="udim" created="Thu, 19 Dec 2019 22:04:25 +0000"  >&lt;p&gt;The point of my question is to figure whether this issue is a 2.18 blocker or not, and how it affects users.&lt;/p&gt;</comment>
                            <comment id="17000448" author="yichi" created="Thu, 19 Dec 2019 22:09:37 +0000"  >&lt;p&gt;then yeah, it&apos;ll affect python streaming jobs (which is only on portable runner with fnapi).&lt;/p&gt;</comment>
                            <comment id="17001589" author="altay" created="Sat, 21 Dec 2019 00:58:05 +0000"  >&lt;p&gt;Could this be closed after the cherry pick PR (&lt;a href=&quot;https://github.com/apache/beam/pull/10430&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/10430&lt;/a&gt;) ?&lt;/p&gt;</comment>
                            <comment id="17001802" author="yichi" created="Sun, 22 Dec 2019 00:19:41 +0000"  >&lt;p&gt;I think so&lt;/p&gt;</comment>
                            <comment id="17003768" author="yichi" created="Thu, 26 Dec 2019 21:25:00 +0000"  >&lt;p&gt;Mitigation is merged, future investigation of how to improve performance will be followed in &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-8998&quot; title=&quot;Avoid excessive bundle progress polling in Dataflow Runner&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-8998&quot;&gt;&lt;del&gt;BEAM-8998&lt;/del&gt;&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17071949" author="mxm" created="Tue, 31 Mar 2020 16:34:16 +0000"  >&lt;p&gt;Reopening because this poses quite a performance degradation for us. We&apos;ve just migrated to 2.18.0 and have been observing sub-par checkpointing performance on Flink. After reverting the commits which introduced the UnboundedThreadPoolExecutor, the checkpoint duration is 2-3x lower.&lt;/p&gt;</comment>
                            <comment id="17071998" author="yichi" created="Tue, 31 Mar 2020 17:29:19 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mxm&quot; class=&quot;user-hover&quot; rel=&quot;mxm&quot;&gt;mxm&lt;/a&gt;&#160;the checkpoint duration is lower means that without UnboundedThreadPoolExecutor FlinkRunner is faster?&#160;&lt;/p&gt;</comment>
                            <comment id="17072103" author="mxm" created="Tue, 31 Mar 2020 19:29:34 +0000"  >&lt;p&gt;Essentially, yes. Especially, this is a concern for latency because Flink has to hold back in-flight elements while performing the checkpoint alignment of the operators. It appears the alignment is off due to the Python bundles not completing in time. Not sure why that is the case. We use the load-balancing feature of DefaultJobBundleFactory where we use 16 Python environment and round-robin them.&lt;/p&gt;</comment>
                            <comment id="17072693" author="mxm" created="Wed, 1 Apr 2020 12:04:58 +0000"  >&lt;p&gt; &lt;span class=&quot;image-wrap&quot; style=&quot;&quot;&gt;&lt;img src=&quot;https://issues.apache.org/jira/secure/attachment/12998450/12998450_checkpoint-duration.png&quot; style=&quot;border: 0px solid black&quot; /&gt;&lt;/span&gt; &lt;/p&gt;

&lt;p&gt;yellow: 2.18.0 as released&lt;br/&gt;
turquoise: 2.18.0 with &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-8944&quot; title=&quot;Python SDK harness performance degradation with UnboundedThreadPoolExecutor&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-8944&quot;&gt;&lt;del&gt;BEAM-8944&lt;/del&gt;&lt;/a&gt; reverted&lt;/p&gt;</comment>
                            <comment id="17072840" author="lcwik" created="Wed, 1 Apr 2020 14:54:21 +0000"  >&lt;p&gt;So the original analysis done in the description of the bug isn&apos;t typical usage because it is comparing creating `M` threads which each process one item vs creating a fixed number of threads which then process that then process the items off a queue. It is easy to see that the performance difference will be in the number of threads created. It is expected that in typical usage threads would be reused many times before being garbage collected.&lt;/p&gt;

&lt;p&gt;Max, for your analysis in the above comment:&lt;br/&gt;
Is Flink is now able to schedule so much more work since the Python SDK harness will do an infinite number due to the UnboundedThreadPool vs the fixed number it supported before (so increased contention)?&lt;br/&gt;
Is it possible that ThreadPoolExecutor has a C++ implementation which is making up for the difference?&lt;br/&gt;
Do you have timing information between the two run that compares the two implementations?&lt;br/&gt;
Do you have a graph showing how many threads are alive in the Python process between the two runs?&lt;/p&gt;</comment>
                            <comment id="17072842" author="lcwik" created="Wed, 1 Apr 2020 14:59:07 +0000"  >&lt;p&gt;The Python 3.5 implementation of the ThreadPoolExecutor: &lt;a href=&quot;https://github.com/python/cpython/blob/3.5/Lib/concurrent/futures/thread.py&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/python/cpython/blob/3.5/Lib/concurrent/futures/thread.py&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="17072860" author="mxm" created="Wed, 1 Apr 2020 15:18:42 +0000"  >&lt;p&gt;I see that the usage pattern in the description is a bit different but since the regression is caused by the new thread pool logic, I posted my findings here.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Is Flink is now able to schedule so much more work since the Python SDK harness will do an infinite number due to the UnboundedThreadPool vs the fixed number it supported before (so increased contention)?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;We are not primarily using the worker threads for parallelism. Instead, we are using 16 separate environments per Flink task manager. These 16 environments are served with work round-robin. In the particular pipeline there are 12 task slots per task manager and at most two fused stages per task slot. That makes for a max of 24 stages which are distributed across the 16 environments. So the environments will spawn more than one worker thread. I&apos;ve tried increasing the life time of the threads but that didn&apos;t have an effect. &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Is it possible that ThreadPoolExecutor has a C++ implementation which is making up for the difference?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Possibly, I suppose we need to profile the execution.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Do you have timing information between the two run that compares the two implementations?&lt;br/&gt;
Do you have a graph showing how many threads are alive in the Python process between the two runs?&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;I don&apos;t have such data yet. I only have the repeatable data for checkpointing. &lt;/p&gt;

&lt;p&gt;Note, I was running this on both Python 2.7.6 and Python 3.6.8 which showed the same behavior.&lt;/p&gt;
</comment>
                            <comment id="17073142" author="lcwik" created="Wed, 1 Apr 2020 19:48:44 +0000"  >&lt;p&gt;I took a look at the implementation of the UnboundedThreadPoolExecutor again to see if I could reduce the overhead and got to &lt;a href=&quot;https://github.com/lukecwik/incubator-beam/commit/4cabd7e11c35b67901ba19a55d7f8bc6a585be3b&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/lukecwik/incubator-beam/commit/4cabd7e11c35b67901ba19a55d7f8bc6a585be3b&lt;/a&gt; but it doesn&apos;t have the same strict guarantees that a thread will exit after getting no work for a certain amount of time and also a new thread will be created when necessary.&lt;/p&gt;</comment>
                            <comment id="17073657" author="mxm" created="Thu, 2 Apr 2020 11:52:19 +0000"  >&lt;p&gt;My first though was to change the implementation to allow two worker thread allocation methods: (a) a static number of threads and (b) dynamically created worker threads. However, I don&apos;t like that the user has to worry about configuring such things. I very much prefer the self-tuning capabilities that we added with UnboundedThreadPoolExecutor. We just have to make sure there is no performance regression.&lt;/p&gt;

&lt;p&gt;Thanks &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lcwik&quot; class=&quot;user-hover&quot; rel=&quot;lcwik&quot;&gt;lcwik&lt;/a&gt;. The implementation looks much simpler. I wonder, could we keep the thread timeout feature? I think it should be possible to build this without the use of threading.Event and threading.Condition. For example, we could add a check after distributing work which checks for the activity of a worker thread and terminates it if it hasn&apos;t been active for a while.&lt;/p&gt;</comment>
                            <comment id="17073871" author="lcwik" created="Thu, 2 Apr 2020 16:26:01 +0000"  >&lt;p&gt;I was having difficulty in producing a solution that both created threads when needed and also was able to clean up threads without emptying the pool completely. Some ideas I had were:&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Have a base pool of threads that never &quot;exit&quot; unless shutdown happens&lt;/li&gt;
	&lt;li&gt;Having a dedicated thread that checked queue size every N secs and generate new threads for what was outstanding (lag in creation, maybe non issue if the base pool size is like 8-16 threads)&lt;/li&gt;
	&lt;li&gt;Whenever a worker gets an item from the queue, it checks queue size and spawns a new worker thread if there are any items there (will get stuck if *&lt;b&gt;work&lt;/b&gt;* never completes)&lt;/li&gt;
	&lt;li&gt;Only create threads on new submission with a certain amount of lag between.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;All of these are worse then the idle worker queue. Would be good to know what was expensive in that solution so that we could address that directly since the cost might just be coming from the &quot;timed&quot; wait aspect.&lt;/p&gt;</comment>
                            <comment id="17074641" author="mxm" created="Fri, 3 Apr 2020 15:05:33 +0000"  >&lt;p&gt;Thank you for your thoughts Luke. I agree that the best approach is to work on a solution based on profiling the current code.&lt;/p&gt;

&lt;p&gt;Here is my attempt to write a benchmark which most closely resembles our setup. There are at most two active bundles per SDK harness (remember, we use 16 of them and distribute bundles round-robin), hence two active tasks. This is adjustable in the &lt;tt&gt;run_benchmark&lt;/tt&gt; method:&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-python&quot;&gt;
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; time
&lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; concurrent &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; futures
&lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; future.moves &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; queue
&lt;span class=&quot;code-keyword&quot;&gt;from&lt;/span&gt; utils.thread_pool_executor &lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; UnboundedThreadPoolExecutor
&lt;span class=&quot;code-keyword&quot;&gt;import&lt;/span&gt; cProfile &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; profiler

&lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; run_benchmark(executor,
                  max_concurrent_threads=2,
                  total_iterations=10000,
                  warmup_iterations=100):
  q = queue.Queue()
  &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;code-keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;range&lt;/span&gt;(max_concurrent_threads):
    q.put(i)

  &lt;span class=&quot;code-keyword&quot;&gt;def&lt;/span&gt; task(number):
    q.put(task)
    &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; number

  count = 0
  start_time = &lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;None&lt;/span&gt;&lt;/span&gt;
  profile = profiler.Profile()

  &lt;span class=&quot;code-keyword&quot;&gt;while&lt;/span&gt; count &amp;lt; total_iterations:
    &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; count == warmup_iterations:
      start_time = time.time()
      profile.enable()
    executor.submit(task, q.get(block=&lt;span class=&quot;code-keyword&quot;&gt;&lt;span class=&quot;code-object&quot;&gt;True&lt;/span&gt;&lt;/span&gt;))
    count += 1

  profile.disable()
  &lt;span class=&quot;code-object&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;code-quote&quot;&gt;&apos;%s uses %s&apos;&lt;/span&gt; % (executor, time.time() - start_time))
  profile.print_stats(sort=&lt;span class=&quot;code-quote&quot;&gt;&apos;time&apos;&lt;/span&gt;)


&lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;code-object&quot;&gt;__name__&lt;/span&gt; == &lt;span class=&quot;code-quote&quot;&gt;&apos;__main__&apos;&lt;/span&gt;:
  &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; UnboundedThreadPoolExecutor() &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; executor:
    run_benchmark(executor)
  &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; futures.ThreadPoolExecutor(max_workers=1) &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; executor:
    run_benchmark(executor)
  &lt;span class=&quot;code-keyword&quot;&gt;with&lt;/span&gt; futures.ThreadPoolExecutor(max_workers=12) &lt;span class=&quot;code-keyword&quot;&gt;as&lt;/span&gt; executor:
    run_benchmark(executor)

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The results clearly reveal the cost of the current implementation:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;&amp;lt;utils.thread_pool_executor.UnboundedThreadPoolExecutor object at 0x10da1f750&amp;gt; uses 7.32124900818
         575749 function calls in 7.302 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    83878    6.701    0.000    6.701    0.000 {method &apos;acquire&apos; of &apos;thread.lock&apos; objects}
    19800    0.087    0.000    6.958    0.000 Queue.py:150(get)
     8595    0.064    0.000    6.662    0.001 threading.py:309(wait)
    29698    0.062    0.000    0.157    0.000 threading.py:373(notify)
     9903    0.045    0.000    0.086    0.000 threading.py:260(__init__)
     9900    0.043    0.000    0.481    0.000 thread_pool_executor.py:134(submit)
     9899    0.040    0.000    0.176    0.000 thread_pool_executor.py:103(accepted_work)
    38293    0.028    0.000    0.099    0.000 threading.py:300(_is_owned)
     9899    0.025    0.000    0.136    0.000 threading.py:576(set)
     9900    0.020    0.000    0.020    0.000 {method &apos;__enter__&apos; of &apos;thread.lock&apos; objects}
     9900    0.020    0.000    0.117    0.000 _base.py:318(__init__)
     9900    0.014    0.000    0.024    0.000 threading.py:132(__init__)
    38294    0.013    0.000    0.013    0.000 threading.py:64(_note)
    28394    0.013    0.000    0.018    0.000 Queue.py:200(_qsize)
    19806    0.012    0.000    0.012    0.000 threading.py:59(__init__)
    19799    0.012    0.000    0.014    0.000 Queue.py:208(_get)
     9899    0.011    0.000    0.076    0.000 threading.py:400(notifyAll)
     9903    0.011    0.000    0.098    0.000 threading.py:242(Condition)
     8595    0.010    0.000    0.053    0.000 threading.py:297(_acquire_restore)
    18499    0.009    0.000    0.009    0.000 {thread.allocate_lock}
     9900    0.009    0.000    0.033    0.000 threading.py:114(RLock)
    38294    0.009    0.000    0.009    0.000 {method &apos;release&apos; of &apos;thread.lock&apos; objects}
     9900    0.007    0.000    0.007    0.000 thread_pool_executor.py:34(__init__)
     9900    0.007    0.000    0.026    0.000 threading.py:285(__enter__)
    38293    0.007    0.000    0.007    0.000 {len}
     9900    0.007    0.000    0.008    0.000 threading.py:288(__exit__)
     9899    0.004    0.000    0.004    0.000 {method &apos;remove&apos; of &apos;list&apos; objects}
     8595    0.004    0.000    0.006    0.000 threading.py:294(_release_save)
     8595    0.003    0.000    0.003    0.000 {method &apos;append&apos; of &apos;list&apos; objects}
    19799    0.003    0.000    0.003    0.000 {method &apos;popleft&apos; of &apos;collections.deque&apos; objects}
     9900    0.002    0.000    0.002    0.000 {method &apos;__exit__&apos; of &apos;thread.lock&apos; objects}
        1    0.000    0.000    0.000    0.000 {thread.start_new_thread}
        1    0.000    0.000    0.000    0.000 threading.py:647(__init__)
        1    0.000    0.000    0.000    0.000 threading.py:717(start)
        2    0.000    0.000    0.000    0.000 threading.py:561(__init__)
        1    0.000    0.000    0.000    0.000 threading.py:620(_newname)
        1    0.000    0.000    0.000    0.000 threading.py:597(wait)
        1    0.000    0.000    0.000    0.000 _weakrefset.py:83(add)
        1    0.000    0.000    0.000    0.000 thread_pool_executor.py:58(__init__)
        1    0.000    0.000    0.000    0.000 threading.py:700(_set_daemon)
        1    0.000    0.000    0.000    0.000 threading.py:1143(currentThread)
        1    0.000    0.000    0.000    0.000 threading.py:1015(daemon)
        2    0.000    0.000    0.000    0.000 threading.py:542(Event)
        1    0.000    0.000    0.000    0.000 {thread.get_ident}
        1    0.000    0.000    0.000    0.000 {method &apos;add&apos; of &apos;set&apos; objects}
        2    0.000    0.000    0.000    0.000 threading.py:570(isSet)
        1    0.000    0.000    0.000    0.000 threading.py:999(daemon)
        1    0.000    0.000    0.000    0.000 {method &apos;disable&apos; of &apos;_lsprof.Profiler&apos; objects}


&amp;lt;concurrent.futures.thread.ThreadPoolExecutor object at 0x10da12110&amp;gt; uses 0.855124950409
         419751 function calls in 0.840 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    53064    0.452    0.000    0.452    0.000 {method &apos;acquire&apos; of &apos;thread.lock&apos; objects}
     9900    0.063    0.000    0.063    0.000 {method &apos;__enter__&apos; of &apos;thread.lock&apos; objects}
     9900    0.047    0.000    0.385    0.000 thread.py:128(submit)
     9900    0.031    0.000    0.455    0.000 Queue.py:150(get)
     9900    0.028    0.000    0.054    0.000 threading.py:260(__init__)
    19800    0.024    0.000    0.072    0.000 threading.py:373(notify)
     9900    0.024    0.000    0.103    0.000 threading.py:440(acquire)
     9900    0.023    0.000    0.145    0.000 Queue.py:107(put)
     3366    0.016    0.000    0.314    0.000 threading.py:309(wait)
    26329    0.015    0.000    0.015    0.000 {method &apos;release&apos; of &apos;thread.lock&apos; objects}
     9900    0.015    0.000    0.078    0.000 _base.py:318(__init__)
    23166    0.012    0.000    0.045    0.000 threading.py:300(_is_owned)
     9900    0.010    0.000    0.016    0.000 threading.py:132(__init__)
     9900    0.009    0.000    0.063    0.000 threading.py:242(Condition)
     9900    0.007    0.000    0.111    0.000 thread.py:141(_adjust_thread_count)
    19800    0.007    0.000    0.007    0.000 threading.py:59(__init__)
     9900    0.006    0.000    0.022    0.000 threading.py:114(RLock)
     9900    0.006    0.000    0.069    0.000 threading.py:285(__enter__)
    33066    0.006    0.000    0.006    0.000 threading.py:64(_note)
     9900    0.005    0.000    0.005    0.000 thread.py:52(__init__)
     9900    0.005    0.000    0.008    0.000 threading.py:288(__exit__)
     9900    0.005    0.000    0.006    0.000 Queue.py:204(_put)
    13266    0.004    0.000    0.006    0.000 Queue.py:200(_qsize)
     9900    0.004    0.000    0.005    0.000 Queue.py:208(_get)
    13266    0.004    0.000    0.004    0.000 {thread.allocate_lock}
     9900    0.003    0.000    0.003    0.000 {method &apos;__exit__&apos; of &apos;thread.lock&apos; objects}
     3366    0.002    0.000    0.007    0.000 threading.py:297(_acquire_restore)
     3366    0.002    0.000    0.002    0.000 threading.py:294(_release_save)
    13266    0.002    0.000    0.002    0.000 {len}
     3163    0.001    0.000    0.001    0.000 {method &apos;remove&apos; of &apos;list&apos; objects}
     9900    0.001    0.000    0.001    0.000 {method &apos;append&apos; of &apos;collections.deque&apos; objects}
     3366    0.001    0.000    0.001    0.000 {method &apos;append&apos; of &apos;list&apos; objects}
     9900    0.001    0.000    0.001    0.000 {method &apos;popleft&apos; of &apos;collections.deque&apos; objects}
        1    0.000    0.000    0.000    0.000 {method &apos;disable&apos; of &apos;_lsprof.Profiler&apos; objects}


&amp;lt;concurrent.futures.thread.ThreadPoolExecutor object at 0x10da18e50&amp;gt; uses 1.18780708313
         409313 function calls in 1.168 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    46328    0.518    0.000    0.518    0.000 {method &apos;acquire&apos; of &apos;thread.lock&apos; objects}
     9900    0.103    0.000    0.728    0.000 thread.py:128(submit)
     9900    0.095    0.000    0.095    0.000 {method &apos;__enter__&apos; of &apos;thread.lock&apos; objects}
     9900    0.067    0.000    0.187    0.000 threading.py:440(acquire)
    19800    0.054    0.000    0.135    0.000 threading.py:373(notify)
     9900    0.052    0.000    0.440    0.000 Queue.py:150(get)
     9900    0.038    0.000    0.328    0.000 Queue.py:107(put)
    31214    0.035    0.000    0.035    0.000 {method &apos;release&apos; of &apos;thread.lock&apos; objects}
     9900    0.033    0.000    0.061    0.000 threading.py:260(__init__)
     9900    0.020    0.000    0.090    0.000 _base.py:318(__init__)
    21482    0.017    0.000    0.062    0.000 threading.py:300(_is_owned)
     9900    0.015    0.000    0.202    0.000 thread.py:141(_adjust_thread_count)
     1682    0.015    0.000    0.184    0.000 threading.py:309(wait)
     9900    0.011    0.000    0.106    0.000 threading.py:285(__enter__)
     9900    0.011    0.000    0.017    0.000 threading.py:132(__init__)
    31382    0.010    0.000    0.010    0.000 threading.py:64(_note)
    11582    0.010    0.000    0.011    0.000 Queue.py:200(_qsize)
     9900    0.009    0.000    0.070    0.000 threading.py:242(Condition)
    19800    0.008    0.000    0.008    0.000 threading.py:59(__init__)
     9900    0.007    0.000    0.024    0.000 threading.py:114(RLock)
     9900    0.006    0.000    0.007    0.000 Queue.py:204(_put)
     9900    0.005    0.000    0.005    0.000 thread.py:52(__init__)
     9900    0.005    0.000    0.010    0.000 threading.py:288(__exit__)
     9900    0.005    0.000    0.006    0.000 Queue.py:208(_get)
     9900    0.004    0.000    0.004    0.000 {method &apos;__exit__&apos; of &apos;thread.lock&apos; objects}
    11582    0.004    0.000    0.004    0.000 {thread.allocate_lock}
     9732    0.004    0.000    0.004    0.000 {method &apos;remove&apos; of &apos;list&apos; objects}
     1682    0.002    0.000    0.003    0.000 threading.py:294(_release_save)
    11582    0.002    0.000    0.002    0.000 {len}
     1682    0.002    0.000    0.033    0.000 threading.py:297(_acquire_restore)
     9900    0.001    0.000    0.001    0.000 {method &apos;append&apos; of &apos;collections.deque&apos; objects}
     9900    0.001    0.000    0.001    0.000 {method &apos;popleft&apos; of &apos;collections.deque&apos; objects}
     1682    0.001    0.000    0.001    0.000 {method &apos;append&apos; of &apos;list&apos; objects}
        1    0.000    0.000    0.000    0.000 {method &apos;disable&apos; of &apos;_lsprof.Profiler&apos; objects}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It appears that the lock which has to be acquired per work item is very expensive.&lt;/p&gt;</comment>
                            <comment id="17097302" author="mxm" created="Fri, 1 May 2020 11:10:48 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=lcwik&quot; class=&quot;user-hover&quot; rel=&quot;lcwik&quot;&gt;lcwik&lt;/a&gt; For the time being, do you think we could support two modes?&lt;/p&gt;

&lt;p&gt;1) dynamic thread allocation &lt;br/&gt;
2) a static number of threads&lt;/p&gt;

&lt;p&gt;The second mode could be removed once we can ensure that it performs as efficient as the first one. We can default to mode (1). What do you think?&lt;/p&gt;</comment>
                            <comment id="17097665" author="lcwik" created="Fri, 1 May 2020 20:34:39 +0000"  >&lt;p&gt;I was able to come up with a compromise that I believe should work well on how many idle threads sit around, see &lt;a href=&quot;https://github.com/apache/beam/pull/11590&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/11590&lt;/a&gt;. &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mxm&quot; class=&quot;user-hover&quot; rel=&quot;mxm&quot;&gt;mxm&lt;/a&gt;, if you can try out the patch locally with a larger pipeline to see if it addresses the issue and by how much.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310560">
                    <name>Problem/Incident</name>
                                                                <inwardlinks description="is caused by">
                                        <issuelink>
            <issuekey id="13254852">BEAM-8151</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10030">
                    <name>Reference</name>
                                                                <inwardlinks description="is related to">
                                        <issuelink>
            <issuekey id="13308408">BEAM-10158</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="12998450" name="checkpoint-duration.png" size="320220" author="mxm" created="Wed, 1 Apr 2020 12:01:50 +0000"/>
                            <attachment id="12988582" name="profiling.png" size="149327" author="yichi" created="Wed, 11 Dec 2019 19:42:21 +0000"/>
                            <attachment id="12988583" name="profiling_one_thread.png" size="144436" author="yichi" created="Wed, 11 Dec 2019 19:51:05 +0000"/>
                            <attachment id="12988584" name="profiling_twelve_threads.png" size="144071" author="yichi" created="Wed, 11 Dec 2019 19:53:19 +0000"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>4.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            5 years, 28 weeks, 3 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z09jk0:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>