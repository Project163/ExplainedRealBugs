<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 11:01:35 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-7856] BigQuery table creation race condition error when executing pipeline on multiple workers</title>
                <link>https://issues.apache.org/jira/browse/BEAM-7856</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>
&lt;p&gt;This is non-fatal issue and just prints error in the logs as far as I can tell.&lt;br/&gt;
The issue is when we check and create big query table on multiple workers at the same time. This causes the race condition.&lt;br/&gt;
&#160;&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/runners/worker/sdk_worker.py&quot;, line 157, in _execute response = task() File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/runners/worker/sdk_worker.py&quot;, line 190, in &amp;lt;lambda&amp;gt; self._execute(lambda: worker.do_instruction(work), work) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/runners/worker/sdk_worker.py&quot;, line 342, in do_instruction request.instruction_id) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/runners/worker/sdk_worker.py&quot;, line 368, in process_bundle bundle_processor.process_bundle(instruction_id)) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/runners/worker/bundle_processor.py&quot;, line 593, in process_bundle data.ptransform_id].process_encoded(data.data) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/runners/worker/bundle_processor.py&quot;, line 143, in process_encoded self.output(decoded_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 255, in apache_beam.runners.worker.operations.Operation.output def output(self, windowed_value, output_index=0): File &quot;apache_beam/runners/worker/operations.py&quot;, line 256, in apache_beam.runners.worker.operations.Operation.output cython.cast(Receiver, self.receivers[output_index]).receive(windowed_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 143, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive self.consumer.process(windowed_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 593, in apache_beam.runners.worker.operations.DoOperation.process with self.scoped_process_state: File &quot;apache_beam/runners/worker/operations.py&quot;, line 594, in apache_beam.runners.worker.operations.DoOperation.process delayed_application = self.dofn_receiver.receive(o) File &quot;apache_beam/runners/common.py&quot;, line 799, in apache_beam.runners.common.DoFnRunner.receive self.process(windowed_value) File &quot;apache_beam/runners/common.py&quot;, line 805, in apache_beam.runners.common.DoFnRunner.process self._reraise_augmented(exn) File &quot;apache_beam/runners/common.py&quot;, line 857, in apache_beam.runners.common.DoFnRunner._reraise_augmented raise File &quot;apache_beam/runners/common.py&quot;, line 803, in apache_beam.runners.common.DoFnRunner.process return self.do_fn_invoker.invoke_process(windowed_value) File &quot;apache_beam/runners/common.py&quot;, line 610, in apache_beam.runners.common.PerWindowInvoker.invoke_process self._invoke_process_per_window( File &quot;apache_beam/runners/common.py&quot;, line 682, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window output_processor.process_outputs( File &quot;apache_beam/runners/common.py&quot;, line 903, in apache_beam.runners.common._OutputProcessor.process_outputs def process_outputs(self, windowed_input_element, results): File &quot;apache_beam/runners/common.py&quot;, line 942, in apache_beam.runners.common._OutputProcessor.process_outputs self.main_receivers.receive(windowed_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 143, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive self.consumer.process(windowed_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 593, in apache_beam.runners.worker.operations.DoOperation.process with self.scoped_process_state: File &quot;apache_beam/runners/worker/operations.py&quot;, line 594, in apache_beam.runners.worker.operations.DoOperation.process delayed_application = self.dofn_receiver.receive(o) File &quot;apache_beam/runners/common.py&quot;, line 799, in apache_beam.runners.common.DoFnRunner.receive self.process(windowed_value) File &quot;apache_beam/runners/common.py&quot;, line 805, in apache_beam.runners.common.DoFnRunner.process self._reraise_augmented(exn) File &quot;apache_beam/runners/common.py&quot;, line 857, in apache_beam.runners.common.DoFnRunner._reraise_augmented raise File &quot;apache_beam/runners/common.py&quot;, line 803, in apache_beam.runners.common.DoFnRunner.process return self.do_fn_invoker.invoke_process(windowed_value) File &quot;apache_beam/runners/common.py&quot;, line 465, in apache_beam.runners.common.SimpleInvoker.invoke_process output_processor.process_outputs( File &quot;apache_beam/runners/common.py&quot;, line 942, in apache_beam.runners.common._OutputProcessor.process_outputs self.main_receivers.receive(windowed_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 143, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive self.consumer.process(windowed_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 593, in apache_beam.runners.worker.operations.DoOperation.process with self.scoped_process_state: File &quot;apache_beam/runners/worker/operations.py&quot;, line 594, in apache_beam.runners.worker.operations.DoOperation.process delayed_application = self.dofn_receiver.receive(o) File &quot;apache_beam/runners/common.py&quot;, line 799, in apache_beam.runners.common.DoFnRunner.receive self.process(windowed_value) File &quot;apache_beam/runners/common.py&quot;, line 805, in apache_beam.runners.common.DoFnRunner.process self._reraise_augmented(exn) File &quot;apache_beam/runners/common.py&quot;, line 857, in apache_beam.runners.common.DoFnRunner._reraise_augmented raise File &quot;apache_beam/runners/common.py&quot;, line 803, in apache_beam.runners.common.DoFnRunner.process return self.do_fn_invoker.invoke_process(windowed_value) File &quot;apache_beam/runners/common.py&quot;, line 465, in apache_beam.runners.common.SimpleInvoker.invoke_process output_processor.process_outputs( File &quot;apache_beam/runners/common.py&quot;, line 942, in apache_beam.runners.common._OutputProcessor.process_outputs self.main_receivers.receive(windowed_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 143, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive self.consumer.process(windowed_value) File &quot;apache_beam/runners/worker/operations.py&quot;, line 593, in apache_beam.runners.worker.operations.DoOperation.process with self.scoped_process_state: File &quot;apache_beam/runners/worker/operations.py&quot;, line 594, in apache_beam.runners.worker.operations.DoOperation.process delayed_application = self.dofn_receiver.receive(o) File &quot;apache_beam/runners/common.py&quot;, line 799, in apache_beam.runners.common.DoFnRunner.receive self.process(windowed_value) File &quot;apache_beam/runners/common.py&quot;, line 805, in apache_beam.runners.common.DoFnRunner.process self._reraise_augmented(exn) File &quot;apache_beam/runners/common.py&quot;, line 872, in apache_beam.runners.common.DoFnRunner._reraise_augmented raise_with_traceback(new_exn) File &quot;apache_beam/runners/common.py&quot;, line 803, in apache_beam.runners.common.DoFnRunner.process return self.do_fn_invoker.invoke_process(windowed_value) File &quot;apache_beam/runners/common.py&quot;, line 466, in apache_beam.runners.common.SimpleInvoker.invoke_process windowed_value, self.process_method(windowed_value.value)) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/io/gcp/bigquery.py&quot;, line 819, in process schema) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/io/gcp/bigquery.py&quot;, line 804, in _create_table_if_needed additional_create_parameters=self.additional_bq_parameters) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/utils/retry.py&quot;, line 197, in wrapper return fun(*args, **kwargs) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/io/gcp/bigquery_tools.py&quot;, line 667, in get_or_create_table additional_parameters=additional_create_parameters) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/io/gcp/bigquery_tools.py&quot;, line 444, in _create_table response = self.client.tables.Insert(request) File &quot;/usr/local/lib/python2.7/dist-packages/apache_beam/io/gcp/internal/clients/bigquery/bigquery_v2_client.py&quot;, line 606, in Insert config, request, global_params=global_params) File &quot;/usr/local/lib/python2.7/dist-packages/apitools/base/py/base_api.py&quot;, line 731, in _RunMethod return self.ProcessHttpResponse(method_config, http_response, request) File &quot;/usr/local/lib/python2.7/dist-packages/apitools/base/py/base_api.py&quot;, line 737, in ProcessHttpResponse self.__ProcessHttpResponse(method_config, http_response, request)) File &quot;/usr/local/lib/python2.7/dist-packages/apitools/base/py/base_api.py&quot;, line 604, in __ProcessHttpResponse http_response, method_config=method_config, request=request) RuntimeError: HttpConflictError: HttpError accessing &amp;lt;https://www.googleapis.com/bigquery/v2/projects/google.com%3Aclouddfe/datasets/integration_test_data/tables?alt=json&amp;gt;: response: &amp;lt;{&apos;status&apos;: &apos;409&apos;, &apos;content-length&apos;: &apos;440&apos;, &apos;x-xss-protection&apos;: &apos;0&apos;, &apos;x-content-type-options&apos;: &apos;nosniff&apos;, &apos;transfer-encoding&apos;: &apos;chunked&apos;, &apos;vary&apos;: &apos;Origin, X-Origin, Referer&apos;, &apos;server&apos;: &apos;ESF&apos;, &apos;-content-encoding&apos;: &apos;gzip&apos;, &apos;cache-control&apos;: &apos;private&apos;, &apos;date&apos;: &apos;Wed, 31 Jul 2019 03:15:15 GMT&apos;, &apos;x-frame-options&apos;: &apos;SAMEORIGIN&apos;, &apos;content-type&apos;: &apos;application/json; charset=UTF-8&apos;}&amp;gt;, content &amp;lt;{ &quot;error&quot;: { &quot;code&quot;: 409, &quot;message&quot;: &quot;Already Exists: Table google.com:clouddfe:integration_test_data.dataflow_status_by_environment_python_07302008337162&quot;, &quot;errors&quot;: [ { &quot;message&quot;: &quot;Already Exists: Table google.com:clouddfe:integration_test_data.dataflow_status_by_environment_python_07302008337162&quot;, &quot;domain&quot;: &quot;global&quot;, &quot;reason&quot;: &quot;duplicate&quot; } ], &quot;status&quot;: &quot;ALREADY_EXISTS&quot; } } &amp;gt; [while running &apos;generatedPtransform-1091&apos;] &quot;&#160; portability_worker_id:&#160;&quot;sdk0&quot;&#160; thread:&#160;&quot;ThreadPoolExecutor-1_9&quot;&#160; worker:&#160;&quot;df2-long-running-streamin-07302010-wy16-harness-wn53&quot;&#160; } labels:&#160;{&#8230;}&#160; logName:&#160;&quot;projects/google.com:clouddfe/logs/dataflow.googleapis.com%2Fworker&quot;&#160; receiveTimestamp:&#160;&quot;2019-07-31T03:15:16.031402142Z&quot;&#160; resource:&#160;{&#8230;}&#160; severity:&#160;&quot;ERROR&quot;&#160; timestamp:&#160;&quot;2019-07-31T03:15:15.369057893Z&quot;&#160; }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;</description>
                <environment></environment>
        <key id="13247994">BEAM-7856</key>
            <summary>BigQuery table creation race condition error when executing pipeline on multiple workers</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10102" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.svg">P2</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="angoenka">Ankur Goenka</assignee>
                                    <reporter username="angoenka">Ankur Goenka</reporter>
                        <labels>
                    </labels>
                <created>Wed, 31 Jul 2019 03:33:49 +0000</created>
                <updated>Sat, 16 May 2020 14:07:03 +0000</updated>
                            <resolved>Wed, 4 Sep 2019 19:59:05 +0000</resolved>
                                                    <fixVersion>Not applicable</fixVersion>
                                    <component>io-py-gcp</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>1</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="7200">2h</timespent>
                                <comments>
                            <comment id="16906800" author="angoenka" created="Wed, 14 Aug 2019 02:04:35 +0000"  >&lt;p&gt;The right fix for this would be to use a single element transform to create the table before writing to it. Some thing similar to what java does here &lt;a href=&quot;https://github.com/apache/beam/blob/08d0146791e38be4641ff80ffb2539cdc81f5b6d/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/StreamingInserts.java#L178&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/08d0146791e38be4641ff80ffb2539cdc81f5b6d/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/StreamingInserts.java#L178&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For now PR #9204 is a stop gap solution to mitigate this error.&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 13 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z056kg:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>