<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 10:47:16 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-3374] Images incorrectly rendering/missing</title>
                <link>https://issues.apache.org/jira/browse/BEAM-3374</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>&lt;p&gt;For example, mobile gaming has some stretched images, and a couple images in the programming guide are missing.&lt;/p&gt;</description>
                <environment></environment>
        <key id="13126012">BEAM-3374</key>
            <summary>Images incorrectly rendering/missing</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10103" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">P3</priority>
                        <status id="5" iconUrl="https://issues.apache.org/jira/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="green"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="melap">Melissa Pashniak</assignee>
                                    <reporter username="melap">Melissa Pashniak</reporter>
                        <labels>
                    </labels>
                <created>Tue, 19 Dec 2017 19:26:11 +0000</created>
                <updated>Sat, 16 May 2020 13:15:33 +0000</updated>
                            <resolved>Thu, 18 Jan 2018 19:20:53 +0000</resolved>
                                                    <fixVersion>Not applicable</fixVersion>
                                    <component>website</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>2</watches>
                                                                                                                <comments>
                            <comment id="16297343" author="githubbot" created="Tue, 19 Dec 2017 20:00:50 +0000"  >&lt;p&gt;melap opened a new pull request #368: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3374&quot; title=&quot;Images incorrectly rendering/missing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3374&quot;&gt;&lt;del&gt;BEAM-3374&lt;/del&gt;&lt;/a&gt; Fix missing/stretched images, improve alt text&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/beam-site/pull/368&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam-site/pull/368&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;   Changes:&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;Add 2 missing images in programming guide&lt;/li&gt;
	&lt;li&gt;Update all images to use a consistent markdown format&lt;/li&gt;
	&lt;li&gt;Update width of some images to fix distortion&lt;/li&gt;
	&lt;li&gt;Update all images to use alt text for accessibility (some were using image title instead of alt)&lt;/li&gt;
	&lt;li&gt;Improve existing alt text&lt;/li&gt;
	&lt;li&gt;Some minor line length/style tweaks&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                            <comment id="16297653" author="githubbot" created="Tue, 19 Dec 2017 23:48:25 +0000"  >&lt;p&gt;asfgit closed pull request #368: &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-3374&quot; title=&quot;Images incorrectly rendering/missing&quot; class=&quot;issue-link&quot; data-issue-key=&quot;BEAM-3374&quot;&gt;&lt;del&gt;BEAM-3374&lt;/del&gt;&lt;/a&gt; Fix missing/stretched images, improve alt text&lt;br/&gt;
URL: &lt;a href=&quot;https://github.com/apache/beam-site/pull/368&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam-site/pull/368&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;This is a PR merged from a forked repository.&lt;br/&gt;
As GitHub hides the original diff on merge, it is displayed below for&lt;br/&gt;
the sake of provenance:&lt;/p&gt;

&lt;p&gt;As this is a foreign pull request (from a fork), the diff is supplied&lt;br/&gt;
below (as it won&apos;t show otherwise due to GitHub magic):&lt;/p&gt;

&lt;p&gt;diff --git a/src/contribute/contribution-guide.md b/src/contribute/contribution-guide.md&lt;br/&gt;
index bb6a589e3..5a7f0b9c6 100644&lt;br/&gt;
&amp;#8212; a/src/contribute/contribution-guide.md&lt;br/&gt;
+++ b/src/contribute/contribution-guide.md&lt;br/&gt;
@@ -17,7 +17,8 @@ or participate on the documentation effort.&lt;/p&gt;

&lt;p&gt; We use a review-then-commit workflow in Beam for all contributions.&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;Alt text&amp;#93;&lt;/span&gt;({{ &quot;/images/contribution-guide-1.png&quot; | prepend: site.baseurl }} &quot;Workflow image&quot;)&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;The Beam contribution workflow has 5 steps: engage, design, code, review, and commit.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/contribution-guide-1.png&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt; *&lt;b&gt;For larger contributions or those that affect multiple components:&lt;/b&gt;*&lt;/p&gt;

&lt;p&gt;diff --git a/src/contribute/maturity-model.md b/src/contribute/maturity-model.md&lt;br/&gt;
index 60593a49b..429b04abf 100644&lt;br/&gt;
&amp;#8212; a/src/contribute/maturity-model.md&lt;br/&gt;
+++ b/src/contribute/maturity-model.md&lt;br/&gt;
@@ -258,7 +258,8 @@ While the majority of commits is still provided by a single organization, it is&lt;/p&gt;

&lt;p&gt; Finally, the contributor diversity has increased significantly. Over each of the last three months, no organization has had more than ~50% of the unique contributors per month. (Assumptions: commits to master branch of the main repository, excludes merge commits, best effort to identify unique contributors).&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;Alt text&amp;#93;&lt;/span&gt;({{ &quot;/images/contribution-diversity.png&quot; | prepend: site.baseurl }} &quot;Contributor Diversity&quot;)&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;Contributor diversity graph&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/contribution-diversity.png&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Dependency analysis&lt;br/&gt;
 This section analyses project&apos;s direct and transitive dependencies to ensure compliance with Apache Software Foundation&apos;s policies and guidelines.&lt;br/&gt;
diff --git a/src/documentation/execution-model.md b/src/documentation/execution-model.md&lt;br/&gt;
index 4f839cad3..11b53b8e4 100644
		&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
			&lt;li&gt;a/src/documentation/execution-model.md&lt;br/&gt;
+++ b/src/documentation/execution-model.md&lt;br/&gt;
@@ -11,9 +11,6 @@ The Beam model allows runners to execute your pipeline in different ways. You&lt;br/&gt;
 may observe various effects as a result of the runner&#8217;s choices. This page&lt;br/&gt;
 describes these effects so you can better understand how Beam pipelines execute.&lt;/li&gt;
		&lt;/ul&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;toc&lt;br/&gt;
-{:toc}&lt;br/&gt;
-&lt;/li&gt;
	&lt;/ul&gt;
	&lt;ol&gt;
		&lt;li&gt;Processing of elements&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; The serialization and communication of elements between machines is one of the&lt;br/&gt;
@@ -78,27 +75,28 @@ in parallel, and how transforms are retried when failures occur.&lt;br/&gt;
 When executing a single `ParDo`, a runner might divide an example input&lt;br/&gt;
 collection of nine elements into two bundles as shown in figure 1.&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;bundling&amp;#93;&lt;/span&gt;({{ site.baseurl }}/images/execution_model_bundling.svg)&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;Bundle A contains five elements. Bundle B contains four elements.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/execution_model_bundling.svg&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt;-*&lt;b&gt;Figure 1:&lt;/b&gt;* A runner divides an input collection with nine elements&lt;br/&gt;
-into two bundles.&lt;br/&gt;
+&lt;b&gt;Figure 1: A runner divides an input collection into two bundles.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt; When the `ParDo` executes, workers may process the two bundles in parallel as&lt;br/&gt;
 shown in figure 2.&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;bundling_gantt&amp;#93;&lt;/span&gt;({{ site.baseurl }}/images/execution_model_bundling_gantt.svg)&lt;br/&gt;
+![Two workers process the two bundles in parallel. Worker one processes bundle&lt;br/&gt;
+  A. Worker two processes bundle B.](&lt;br/&gt;
+  {{ &quot;/images/execution_model_bundling_gantt.svg&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt;-*&lt;b&gt;Figure 2:&lt;/b&gt;* Two workers process the two bundles in parallel. The elements in&lt;br/&gt;
-each bundle are processed in sequence.&lt;br/&gt;
+&lt;b&gt;Figure 2: Two workers process the two bundles in parallel.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt; Since elements cannot be split, the maximum parallelism for a transform depends&lt;br/&gt;
-on the number of elements in the collection. In our example, the input&lt;br/&gt;
-collection has nine elements, so the maximum parallelism is nine.&lt;br/&gt;
+on the number of elements in the collection. In figure 3, the input collection&lt;br/&gt;
+has nine elements, so the maximum parallelism is nine.&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;bundling_gantt_max&amp;#93;&lt;/span&gt;({{ site.baseurl }}/images/execution_model_bundling_gantt_max.svg)&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;Nine workers process a nine element input collection in parallel.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/execution_model_bundling_gantt_max.svg&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt;-*&lt;b&gt;Figure 3:&lt;/b&gt;* The maximum parallelism is nine, as there are nine elements in the&lt;br/&gt;
-input collection.&lt;br/&gt;
+&lt;b&gt;Figure 3: Nine workers process a nine element input collection in parallel.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt; Note: Splittable ParDo allows splitting the processing of a single input across&lt;br/&gt;
 multiple bundles. This feature is a work in progress.&lt;br/&gt;
@@ -111,9 +109,11 @@ output elements without altering the bundling. In figure 4, `ParDo1` and&lt;br/&gt;
 `ParDo2` are &lt;em&gt;dependently parallel&lt;/em&gt; if the output of `ParDo1` for a given&lt;br/&gt;
 element must be processed on the same worker.&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;bundling_multi&amp;#93;&lt;/span&gt;({{ site.baseurl }}/images/execution_model_bundling_multi.svg)&lt;br/&gt;
+![ParDo1 processes an input collection that contains bundles A and B. ParDo2 then&lt;br/&gt;
+  processes the output collection from ParDo1, which contains bundles C and D.](&lt;br/&gt;
+  {{ &quot;/images/execution_model_bundling_multi.svg&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt;-*&lt;b&gt;Figure 4:&lt;/b&gt;* Two transforms in sequence and their corresponding input collections.&lt;br/&gt;
+&lt;b&gt;Figure 4: Two transforms in sequence and their corresponding input collections.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt; Figure 5 shows how these dependently parallel transforms might execute. The&lt;br/&gt;
 first worker executes `ParDo1` on the elements in bundle A (which results in&lt;br/&gt;
@@ -121,9 +121,11 @@ bundle C), and then executes `ParDo2` on the elements in bundle C. Similarly,&lt;br/&gt;
 the second worker executes `ParDo1` on the elements in bundle B (which results&lt;br/&gt;
 in bundle D), and then executes `ParDo2` on the elements in bundle D.&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;bundling_multi_gantt.svg&amp;#93;&lt;/span&gt;({{ site.baseurl }}/images/execution_model_bundling_multi_gantt.svg)&lt;br/&gt;
+![Worker one executes ParDo1 on bundle A and Pardo2 on bundle C. Worker two&lt;br/&gt;
+  executes ParDo1 on bundle B and ParDo2 on bundle D.](&lt;br/&gt;
+  {{ &quot;/images/execution_model_bundling_multi_gantt.svg&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt;-*&lt;b&gt;Figure 5:&lt;/b&gt;* Two workers execute dependently parallel ParDo transforms.&lt;br/&gt;
+&lt;b&gt;Figure 5: Two workers execute dependently parallel ParDo transforms.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt; Executing transforms this way allows a runner to avoid redistributing elements&lt;br/&gt;
 between workers, which saves on communication costs. However, the maximum parallelism&lt;br/&gt;
@@ -147,12 +149,14 @@ there is one element still awaiting processing.&lt;br/&gt;
 We see that the runner retries all elements in bundle B and the processing&lt;br/&gt;
 completes successfully the second time. Note that the retry does not necessarily&lt;br/&gt;
 happen on the same worker as the original processing attempt, as shown in the&lt;br/&gt;
-diagram.&lt;br/&gt;
+figure.&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;failure_retry&amp;#93;&lt;/span&gt;({{ site.baseurl }}/images/execution_model_failure_retry.svg)&lt;br/&gt;
+![Worker two fails to process an element in bundle B. Worker one finishes&lt;br/&gt;
+  processing bundle A and then successfully retries to execute bundle B.](&lt;br/&gt;
+  {{ &quot;/images/execution_model_failure_retry.svg&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt;-*&lt;b&gt;Figure 6:&lt;/b&gt;* The processing of an element within bundle B fails, and another worker&lt;br/&gt;
-retries the entire bundle.&lt;br/&gt;
+*Figure 6: The processing of an element within bundle B fails, and another worker&lt;br/&gt;
+retries the entire bundle.*&lt;/p&gt;

&lt;p&gt; Because we encountered a failure while processing an element in the input&lt;br/&gt;
 bundle, we had to reprocess &lt;em&gt;all&lt;/em&gt; of the elements in the input bundle. This means&lt;br/&gt;
@@ -176,10 +180,12 @@ the output of `ParDo2`. Because the runner was executing `ParDo1` and `ParDo2`&lt;br/&gt;
 together, the output bundle from `ParDo1` must also be thrown away, and all&lt;br/&gt;
 elements in the input bundle must be retried. These two `ParDo`s are co-failing.&lt;/p&gt;

&lt;p&gt;-!&lt;span class=&quot;error&quot;&gt;&amp;#91;bundling_coupled failure&amp;#93;&lt;/span&gt;({{ site.baseurl }}/images/execution_model_bundling_coupled_failure.svg)&lt;br/&gt;
+![Worker two fails to process en element in bundle D, so all elements in both&lt;br/&gt;
+  bundle B and bundle D must be retried.](&lt;br/&gt;
+  {{ &quot;/images/execution_model_bundling_coupled_failure.svg&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt;-*&lt;b&gt;Figure 7:&lt;/b&gt;* Processing of an element within bundle D fails, so all elements in&lt;br/&gt;
-the input bundle are retried.&lt;br/&gt;
+*Figure 7: Processing of an element within bundle D fails, so all elements in&lt;br/&gt;
+the input bundle are retried.*&lt;/p&gt;

&lt;p&gt; Note that the retry does not necessarily have the same processing time as the&lt;br/&gt;
 original attempt, as shown in the diagram.&lt;br/&gt;
diff --git a/src/documentation/pipelines/design-your-pipeline.md b/src/documentation/pipelines/design-your-pipeline.md&lt;br/&gt;
index 87250afe1..52ae34134 100644&lt;br/&gt;
&amp;#8212; a/src/documentation/pipelines/design-your-pipeline.md&lt;br/&gt;
+++ b/src/documentation/pipelines/design-your-pipeline.md&lt;br/&gt;
@@ -24,13 +24,14 @@ When designing your Beam pipeline, consider a few basic questions:&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;A basic pipeline&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;-The simplest pipelines represent a linear flow of operations, as shown in Figure 1 below:&lt;br/&gt;
+The simplest pipelines represent a linear flow of operations, as shown in figure&lt;br/&gt;
+1.&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig1&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/design-your-pipeline-linear.png&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;A linear pipeline.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-Figure 1: A linear pipeline.&lt;br/&gt;
+![A linear pipeline starts with one input collection, sequentially applies&lt;br/&gt;
+  three transforms, and ends with one output collection.](&lt;br/&gt;
+  {{ &quot;/images/design-your-pipeline-linear.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+&lt;br/&gt;
+&lt;b&gt;Figure 1: A linear pipeline.&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; However, your pipeline can be significantly more complex. A pipeline represents a &lt;span class=&quot;error&quot;&gt;&amp;#91;Directed Acyclic Graph&amp;#93;&lt;/span&gt;(&lt;a href=&quot;https://en.wikipedia.org/wiki/Directed_acyclic_graph&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://en.wikipedia.org/wiki/Directed_acyclic_graph&lt;/a&gt;) of steps. It can have multiple input sources, multiple output sinks, and its operations (`PTransform`s) can both read and output multiple `PCollection`s. The following examples show some of the different shapes your pipeline can take.&lt;/p&gt;

&lt;p&gt;@@ -42,13 +43,17 @@ It&apos;s important to understand that transforms do not consume `PCollection`s; inst&lt;/p&gt;

&lt;p&gt; You can use the same `PCollection` as input for multiple transforms without consuming the input or altering it.&lt;/p&gt;

&lt;p&gt;-The pipeline illustrated in Figure 2 below reads its input, first names (Strings), from a single source, a database table, and creates a `PCollection` of table rows. Then, the pipeline applies multiple transforms to the *&lt;b&gt;same&lt;/b&gt;* `PCollection`. Transform A extracts all the names in that `PCollection` that start with the letter &apos;A&apos;, and Transform B extracts all the names in that `PCollection` that start with the letter &apos;B&apos;. Both transforms A and B have the same input `PCollection`.&lt;br/&gt;
+The pipeline in figure 2 is a branching pipeline. The pipeline reads its input (first names represented as strings) from a database table and creates a `PCollection` of table rows. Then, the pipeline applies multiple transforms to the *&lt;b&gt;same&lt;/b&gt;* `PCollection`. Transform A extracts all the names in that `PCollection` that start with the letter &apos;A&apos;, and Transform B extracts all the names in that `PCollection` that start with the letter &apos;B&apos;. Both transforms A and B have the same input `PCollection`.&lt;br/&gt;
+&lt;br/&gt;
+![The pipeline applies two transforms to a single input collection. Each&lt;br/&gt;
+  transform produces an output collection.](&lt;br/&gt;
+  {{ &quot;/images/design-your-pipeline-multiple-pcollections.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+&lt;br/&gt;
+*Figure 2: A branching pipeline. Two transforms are applied to a single&lt;br/&gt;
+PCollection of database table rows.*&lt;br/&gt;
+&lt;br/&gt;
+The following example code applies two transforms to a single input collection.&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig2&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/design-your-pipeline-multiple-pcollections.png&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;A pipeline with multiple transforms. Note that the PCollection of table rows is processed by two transforms.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-Figure 2: A pipeline with multiple transforms. Note that the PCollection of the database table rows is processed by two transforms. See the example code below:&lt;br/&gt;
 ```java&lt;br/&gt;
 PCollection&amp;lt;String&amp;gt; dbRowCollection = ...;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;@@ -75,15 +80,17 @@ PCollection&amp;lt;String&amp;gt; bCollection = dbRowCollection.apply(&quot;bTrans&quot;, ParDo.of(new D&lt;/p&gt;

&lt;p&gt; Another way to branch a pipeline is to have a *&lt;b&gt;single&lt;/b&gt;* transform output to multiple `PCollection`s by using &lt;span class=&quot;error&quot;&gt;&amp;#91;tagged outputs&amp;#93;&lt;/span&gt;({{ site.baseurl }}/documentation/programming-guide/#additional-outputs). Transforms that produce more than one output process each element of the input once, and output to zero or more `PCollection`s.&lt;/p&gt;

&lt;p&gt;-Figure 3 below illustrates the same example described above, but with one transform that produces multiple outputs. Names that start with &apos;A&apos; are added to the main output `PCollection`, and names that start with &apos;B&apos; are added to an additional output `PCollection`.&lt;br/&gt;
+Figure 3 illustrates the same example described above, but with one transform that produces multiple outputs. Names that start with &apos;A&apos; are added to the main output `PCollection`, and names that start with &apos;B&apos; are added to an additional output `PCollection`.&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig3&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/design-your-pipeline-additional-outputs.png&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;A pipeline with a transform that outputs multiple PCollections.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-Figure 3: A pipeline with a transform that outputs multiple PCollections.&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;The pipeline applies one transform that produces multiple output collections.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/design-your-pipeline-additional-outputs.png&quot; | prepend: site.baseurl }})&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-The pipeline in Figure 2 contains two transforms that process the elements in the same input `PCollection`. One transform uses the following logic:&lt;br/&gt;
+&lt;b&gt;Figure 3: A pipeline with a transform that outputs multiple PCollections.&lt;/b&gt;&lt;br/&gt;
+&lt;br/&gt;
+If we compare the pipelines in figure 2 and figure 3, you can see they perform&lt;br/&gt;
+the same operation in different ways. The pipeline in figure 2 contains two&lt;br/&gt;
+transforms that process the elements in the same input `PCollection`. One&lt;br/&gt;
+transform uses the following logic:&lt;/p&gt;

&lt;p&gt; &amp;lt;pre&amp;gt;if (starts with &apos;A&apos;) &lt;/p&gt;
{ outputToPCollectionA }&amp;lt;/pre&amp;gt;&lt;br/&gt;
 &lt;br/&gt;
@@ -93,11 +100,15 @@ while the other transform uses:&lt;br/&gt;
 &lt;br/&gt;
 Because each transform reads the entire input `PCollection`, each element in the input `PCollection` is processed twice.&lt;br/&gt;
 &lt;br/&gt;
-The pipeline in Figure 3 performs the same operation in a different way - with only one transform that uses the following logic:&lt;br/&gt;
+The pipeline in figure 3 performs the same operation in a different way - with only one transform that uses the following logic:&lt;br/&gt;
 &lt;br/&gt;
 &amp;lt;pre&amp;gt;if (starts with &apos;A&apos;) { outputToPCollectionA }
&lt;p&gt; else if (starts with &apos;B&apos;) &lt;/p&gt;
{ outputToPCollectionB }
&lt;p&gt;&amp;lt;/pre&amp;gt;&lt;/p&gt;

&lt;p&gt;-where each element in the input `PCollection` is processed once. See the example code below:&lt;br/&gt;
+where each element in the input `PCollection` is processed once.&lt;br/&gt;
+&lt;br/&gt;
+The following example code applies one transform that processes each element&lt;br/&gt;
+once and outputs two collections.&lt;br/&gt;
+&lt;br/&gt;
 ```java&lt;br/&gt;
 // Define two TupleTags, one for each output.&lt;br/&gt;
 final TupleTag&amp;lt;String&amp;gt; startsWithATag = new TupleTag&amp;lt;String&amp;gt;(){};&lt;br/&gt;
@@ -139,32 +150,43 @@ Often, after you&apos;ve branched your `PCollection` into multiple `PCollection`s via&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;*&lt;b&gt;Flatten&lt;/b&gt;* - You can use the `Flatten` transform in the Beam SDKs to merge multiple `PCollection`s of the *&lt;b&gt;same type&lt;/b&gt;*.&lt;/li&gt;
	&lt;li&gt;*&lt;b&gt;Join&lt;/b&gt;* - You can use the `CoGroupByKey` transform in the Beam SDK to perform a relational join between two `PCollection`s. The `PCollection`s must be keyed (i.e. they must be collections of key/value pairs) and they must use the same key type.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-The example depicted in Figure 4 below is a continuation of the example illustrated in Figure 2 in &lt;span class=&quot;error&quot;&gt;&amp;#91;the section above&amp;#93;&lt;/span&gt;(#multiple-transforms-process-the-same-pcollection). After branching into two `PCollection`s, one with names that begin with &apos;A&apos; and one with names that begin with &apos;B&apos;, the pipeline merges the two together into a single `PCollection` that now contains all names that begin with either &apos;A&apos; or &apos;B&apos;. Here, it makes sense to use `Flatten` because the `PCollection`s being merged both contain the same type.&lt;br/&gt;
+The example in figure 4 is a continuation of the example in figure 2 in [the&lt;br/&gt;
+section above](#multiple-transforms-process-the-same-pcollection). After&lt;br/&gt;
+branching into two `PCollection`s, one with names that begin with &apos;A&apos; and one&lt;br/&gt;
+with names that begin with &apos;B&apos;, the pipeline merges the two together into a&lt;br/&gt;
+single `PCollection` that now contains all names that begin with either &apos;A&apos; or&lt;br/&gt;
+&apos;B&apos;. Here, it makes sense to use `Flatten` because the `PCollection`s being&lt;br/&gt;
+merged both contain the same type.&lt;br/&gt;
+&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;The pipeline merges two collections into one collection with the Flatten transform.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/design-your-pipeline-flatten.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+&lt;br/&gt;
+*Figure 4: A pipeline that merges two collections into one collection with the Flatten&lt;br/&gt;
+transform.*&lt;br/&gt;
+&lt;br/&gt;
+The following example code applies `Flatten` to merge two collections.&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig4&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/design-your-pipeline-flatten.png&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;Part of a pipeline that merges multiple PCollections.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-Figure 4: Part of a pipeline that merges multiple PCollections. See the example code below:&lt;br/&gt;
 ```java&lt;br/&gt;
 //merge the two PCollections with Flatten&lt;br/&gt;
 PCollectionList&amp;lt;String&amp;gt; collectionList = PCollectionList.of(aCollection).and(bCollection);&lt;br/&gt;
 PCollection&amp;lt;String&amp;gt; mergedCollectionWithFlatten = collectionList&lt;br/&gt;
     .apply(Flatten.&amp;lt;String&amp;gt;pCollections());&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-// continue with the new merged PCollection		&lt;br/&gt;
+// continue with the new merged PCollection&lt;br/&gt;
 mergedCollectionWithFlatten.apply(...);&lt;br/&gt;
 ```&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Multiple sources&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;-Your pipeline can read its input from one or more sources. If your pipeline reads from multiple sources and the data from those sources is related, it can be useful to join the inputs together. In the example illustrated in Figure 5 below, the pipeline reads names and addresses from a database table, and names and order numbers from a Kafka topic. The pipeline then uses `CoGroupByKey` to join this information, where the key is the name; the resulting `PCollection` contains all the combinations of names, addresses, and orders.&lt;br/&gt;
+Your pipeline can read its input from one or more sources. If your pipeline reads from multiple sources and the data from those sources is related, it can be useful to join the inputs together. In the example illustrated in figure 5 below, the pipeline reads names and addresses from a database table, and names and order numbers from a Kafka topic. The pipeline then uses `CoGroupByKey` to join this information, where the key is the name; the resulting `PCollection` contains all the combinations of names, addresses, and orders.&lt;br/&gt;
+&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;The pipeline joins two input collections into one collection with the Join transform.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/design-your-pipeline-join.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+&lt;br/&gt;
+&lt;b&gt;Figure 5: A pipeline that does a relational join of two input collections.&lt;/b&gt;&lt;br/&gt;
+&lt;br/&gt;
+The following example code applies `Join` to join two input collections.&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig5&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/design-your-pipeline-join.png&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;A pipeline with multiple input sources.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-Figure 5: A pipeline with multiple input sources. See the example code below:&lt;br/&gt;
 ```java&lt;br/&gt;
 PCollection&amp;lt;KV&amp;lt;String, String&amp;gt;&amp;gt; userAddress = pipeline.apply(JdbcIO.&amp;lt;KV&amp;lt;String, String&amp;gt;&amp;gt;read()...);&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;diff --git a/src/documentation/programming-guide.md b/src/documentation/programming-guide.md&lt;br/&gt;
index f746d7dc2..a817d99be 100644&lt;br/&gt;
&amp;#8212; a/src/documentation/programming-guide.md&lt;br/&gt;
+++ b/src/documentation/programming-guide.md&lt;br/&gt;
@@ -467,9 +467,13 @@ you can chain transforms to create a sequential pipeline, like this one:&lt;/p&gt;
&lt;div class=&apos;table-wrap&apos;&gt;
&lt;table class=&apos;confluenceTable&apos;&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&apos;confluenceTd&apos;&gt; &lt;span class=&quot;error&quot;&gt;&amp;#91;Third Transform&amp;#93;&lt;/span&gt;)&lt;br/&gt;
 ```&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;


&lt;p&gt;-The resulting workflow graph of the above pipeline looks like this:&lt;br/&gt;
+The resulting workflow graph of the above pipeline looks like this.&lt;/p&gt;

&lt;p&gt;-&lt;span class=&quot;error&quot;&gt;&amp;#91;Sequential Graph Graphic&amp;#93;&lt;/span&gt;&lt;br/&gt;
+![This linear pipeline starts with one input collection, sequentially applies&lt;br/&gt;
+  three transforms, and ends with one output collection.](&lt;br/&gt;
+  {{ &quot;/images/design-your-pipeline-linear.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+&lt;br/&gt;
+&lt;b&gt;Figure: A linear pipeline with three sequential transforms.&lt;/b&gt;&lt;/p&gt;

&lt;p&gt; However, note that a transform &lt;b&gt;does not consume or otherwise alter&lt;/b&gt; the input&lt;br/&gt;
 collection--remember that a `PCollection` is immutable by definition. This means&lt;br/&gt;
@@ -485,9 +489,14 @@ a branching pipeline, like so:&lt;br/&gt;
 &lt;span class=&quot;error&quot;&gt;&amp;#91;Output PCollection 2&amp;#93;&lt;/span&gt; = &lt;span class=&quot;error&quot;&gt;&amp;#91;Input PCollection&amp;#93;&lt;/span&gt; | &lt;span class=&quot;error&quot;&gt;&amp;#91;Transform 2&amp;#93;&lt;/span&gt;&lt;br/&gt;
 ```&lt;/p&gt;

&lt;p&gt;-The resulting workflow graph from the branching pipeline above looks like this:&lt;br/&gt;
+The resulting workflow graph from the branching pipeline above looks like this.&lt;br/&gt;
+&lt;br/&gt;
+![This pipeline applies two transforms to a single input collection. Each&lt;br/&gt;
+  transform produces an output collection.](&lt;br/&gt;
+  {{ &quot;/images/design-your-pipeline-multiple-pcollections.png&quot; | prepend: site.baseurl }})&lt;/p&gt;

&lt;p&gt;-&lt;span class=&quot;error&quot;&gt;&amp;#91;Branching Graph Graphic&amp;#93;&lt;/span&gt;&lt;br/&gt;
+*Figure: A branching pipeline. Two transforms are applied to a single&lt;br/&gt;
+PCollection of database table rows.*&lt;/p&gt;

&lt;p&gt; You can also build your own &lt;span class=&quot;error&quot;&gt;&amp;#91;composite transforms&amp;#93;&lt;/span&gt;(#composite-transforms) that&lt;br/&gt;
 nest multiple sub-steps inside a single, larger transform. Composite transforms&lt;br/&gt;
diff --git a/src/get-started/beam-overview.md b/src/get-started/beam-overview.md&lt;br/&gt;
index e3a474a6d..3fe733ed7 100644&lt;br/&gt;
&amp;#8212; a/src/get-started/beam-overview.md&lt;br/&gt;
+++ b/src/get-started/beam-overview.md&lt;br/&gt;
@@ -20,10 +20,8 @@ The Beam SDKs provide a unified programming model that can represent and transfo&lt;/p&gt;

&lt;p&gt; Beam currently supports the following language-specific SDKs:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;Java &amp;lt;img src=&quot;{{ site.baseurl }}/images/logos/sdks/java.png&quot;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;alt=&quot;Java SDK&quot;&amp;gt;
	&lt;ul&gt;
		&lt;li&gt;Python &amp;lt;img src=&quot;{{ site.baseurl }}/images/logos/sdks/python.png&quot;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;alt=&quot;Python SDK &quot;&amp;gt;&lt;br/&gt;
+* Java !&lt;span class=&quot;error&quot;&gt;&amp;#91;Java logo&amp;#93;&lt;/span&gt;({{ &quot;/images/logos/sdks/java.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+* Python !&lt;span class=&quot;error&quot;&gt;&amp;#91;Python logo&amp;#93;&lt;/span&gt;({{ &quot;/images/logos/sdks/python.png&quot; | prepend: site.baseurl }})&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;Apache Beam Pipeline Runners&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;@@ -31,16 +29,11 @@ The Beam Pipeline Runners translate the data processing pipeline you define with&lt;/p&gt;

&lt;p&gt; Beam currently supports Runners that work with the following distributed processing back-ends:&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;Apache Apex &amp;lt;img src=&quot;{{ site.baseurl }}/images/logos/runners/apex.png&quot;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;alt=&quot;Apache Apex&quot;&amp;gt;
	&lt;ul&gt;
		&lt;li&gt;Apache Flink &amp;lt;img src=&quot;{{ site.baseurl }}/images/logos/runners/flink.png&quot;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;alt=&quot;Apache Flink&quot;&amp;gt;
	&lt;ul&gt;
		&lt;li&gt;Apache Gearpump (incubating) &amp;lt;img src=&quot;{{ site.baseurl }}/images/logos/runners/gearpump.png&quot;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;alt=&quot;Apache Gearpump&quot;&amp;gt;
	&lt;ul&gt;
		&lt;li&gt;Apache Spark &amp;lt;img src=&quot;{{ site.baseurl }}/images/logos/runners/spark.png&quot;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;alt=&quot;Apache Spark&quot;&amp;gt;
	&lt;ul&gt;
		&lt;li&gt;Google Cloud Dataflow &amp;lt;img src=&quot;{{ site.baseurl }}/images/logos/runners/dataflow.png&quot;&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
	&lt;li&gt;alt=&quot;Google Cloud Dataflow&quot;&amp;gt;&lt;br/&gt;
+* Apache Apex  !&lt;span class=&quot;error&quot;&gt;&amp;#91;Apache Apex logo&amp;#93;&lt;/span&gt;({{ &quot;/images/logos/runners/apex.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+* Apache Flink !&lt;span class=&quot;error&quot;&gt;&amp;#91;Apache Flink logo&amp;#93;&lt;/span&gt;({{ &quot;/images/logos/runners/flink.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+* Apache Gearpump (incubating) !&lt;span class=&quot;error&quot;&gt;&amp;#91;Apache Gearpump logo&amp;#93;&lt;/span&gt;({{ &quot;/images/logos/runners/gearpump.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+* Apache Spark !&lt;span class=&quot;error&quot;&gt;&amp;#91;Apache Spark logo&amp;#93;&lt;/span&gt;({{ &quot;/images/logos/runners/spark.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+* Google Cloud Dataflow !&lt;span class=&quot;error&quot;&gt;&amp;#91;Google Cloud Dataflow logo&amp;#93;&lt;/span&gt;({{ &quot;/images/logos/runners/dataflow.png&quot; | prepend: site.baseurl }})&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; *&lt;b&gt;Note:&lt;/b&gt;* You can always execute your pipeline locally for testing and debugging purposes.&lt;/p&gt;

&lt;p&gt;diff --git a/src/get-started/mobile-gaming-example.md b/src/get-started/mobile-gaming-example.md&lt;br/&gt;
index bcc16b32d..9a734c050 100644&lt;br/&gt;
&amp;#8212; a/src/get-started/mobile-gaming-example.md&lt;br/&gt;
+++ b/src/get-started/mobile-gaming-example.md&lt;br/&gt;
@@ -38,12 +38,14 @@ When the user completes an instance of the game, their phone sends the data even&lt;/p&gt;

&lt;p&gt; The following diagram shows the ideal situation (events are processed as they occur) vs. reality (there is often a time delay before processing).&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig1&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/gaming-example-basic.png&quot;&lt;/li&gt;
	&lt;li&gt;width=&quot;264&quot; height=&quot;260&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;Score data for three users.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-*&lt;b&gt;Figure 1:&lt;/b&gt;* The X-axis represents event time: the actual time a game event occurred. The Y-axis represents processing time: the time at which a game event was processed. Ideally, events should be processed as they occur, depicted by the dotted line in the diagram. However, in reality that is not the case and it looks more like what is depicted by the red squiggly line.&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;There is often a time delay before processing events.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/gaming-example-basic.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+&lt;br/&gt;
+*Figure 1: The X-axis represents event time: the actual time a game event&lt;br/&gt;
+occurred. The Y-axis represents processing time: the time at which a game event&lt;br/&gt;
+was processed. Ideally, events should be processed as they occur, depicted by&lt;br/&gt;
+the dotted line in the diagram. However, in reality that is not the case and it&lt;br/&gt;
+looks more like what is depicted by the red squiggly line above the ideal line.*&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; The data events might be received by the game server significantly later than users generate them. This time difference (called *&lt;b&gt;skew&lt;/b&gt;*) can have processing implications for pipelines that make calculations that consider when each score was generated. Such pipelines might track scores generated during each hour of a day, for example, or they calculate the length of time that users are continuously playing the game&#8212;both of which depend on each data record&apos;s event time.&lt;/p&gt;

&lt;p&gt;@@ -79,14 +81,12 @@ As the pipeline processes each event, the event score gets added to the sum tota&lt;br/&gt;
 2. Sum the score values for each unique user by grouping each game event by user ID and combining the score values to get the total score for that particular user.&lt;br/&gt;
 3. Write the result data to a text file.&lt;/p&gt;

&lt;p&gt;-The following diagram shows score data for several users over the pipeline analysis period. In the diagram, each data point is an event that results in one user/score pair:&lt;br/&gt;
+The following diagram shows score data for several users over the pipeline analysis period. In the diagram, each data point is an event that results in one user/score pair.&lt;br/&gt;
+&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;A pipeline processes score data for three users.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/gaming-example.gif&quot; | prepend: site.baseurl }}){: width=&quot;850px&quot;}&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig2&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/gaming-example.gif&quot;&lt;/li&gt;
	&lt;li&gt;width=&quot;900&quot; height=&quot;263&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;Score data for three users.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-*&lt;b&gt;Figure 2:&lt;/b&gt;* Score data for three users.&lt;br/&gt;
+&lt;b&gt;Figure 2: Score data for three users.&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; This example uses batch processing, and the diagram&apos;s Y axis represents processing time: the pipeline processes events lower on the Y-axis first, and events higher up the axis later. The diagram&apos;s X axis represents the event time for each game event, as denoted by that event&apos;s timestamp. Note that the individual events in the diagram are not processed by the pipeline in the same order as they occurred (according to their timestamps).&lt;/p&gt;

&lt;p&gt;@@ -152,12 +152,11 @@ Using fixed-time windowing lets the pipeline provide better information on how e&lt;/p&gt;

&lt;p&gt; The following diagram shows how the pipeline processes a day&apos;s worth of a single team&apos;s scoring data after applying fixed-time windowing:&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig3&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/gaming-example-team-scores-narrow.gif&quot;&lt;/li&gt;
	&lt;li&gt;width=&quot;900&quot; height=&quot;390&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;Score data for two teams.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-*&lt;b&gt;Figure 3:&lt;/b&gt;* Score data for two teams. Each team&apos;s scores are divided into logical windows based on when those scores occurred in event time.&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;A pipeline processes score data for two teams.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/gaming-example-team-scores-narrow.gif&quot; | prepend: site.baseurl }}){: width=&quot;800px&quot;}&lt;br/&gt;
+&lt;br/&gt;
+*Figure 3: Score data for two teams. Each team&apos;s scores are divided into&lt;br/&gt;
+logical windows based on when those scores occurred in event time.*&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; Notice that as processing time advances, the sums are now &lt;em&gt;per window&lt;/em&gt;; each window represents an hour of &lt;em&gt;event time&lt;/em&gt; during the day in which the scores occurred.&lt;/p&gt;

&lt;p&gt;@@ -250,12 +249,12 @@ Because we want all the data that has arrived in the pipeline every time we upda&lt;/p&gt;

&lt;p&gt; When we specify a ten-minute processing time trigger for the single global window, the pipeline effectively takes a &quot;snapshot&quot; of the contents of the window every time the trigger fires. This snapshot happens after ten minutes have passed since data was received. If no data has arrived, the pipeline takes its next &quot;snapshot&quot; 10 minutes after an element arrives. Since we&apos;re using a single global window, each snapshot contains all the data collected &lt;em&gt;to that point in time&lt;/em&gt;. The following diagram shows the effects of using a processing time trigger on the single global window:&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig4&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/gaming-example-proc-time-narrow.gif&quot;&lt;/li&gt;
	&lt;li&gt;width=&quot;900&quot; height=&quot;263&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;Score data for three users.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-*&lt;b&gt;Figure 4:&lt;/b&gt;* Score data for three users. Each user&apos;s scores are grouped together in a single global window, with a trigger that generates a snapshot for output ten minutes after data is received.&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;A pipeline processes score data for three users.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/gaming-example-proc-time-narrow.gif&quot; | prepend: site.baseurl }}){: width=&quot;850px&quot;}&lt;br/&gt;
+&lt;br/&gt;
+*Figure 4: Score data for three users. Each user&apos;s scores are grouped together&lt;br/&gt;
+in a single global window, with a trigger that generates a snapshot for output&lt;br/&gt;
+ten minutes after data is received.*&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; As processing time advances and more scores are processed, the trigger outputs the updated sum for each user.&lt;/p&gt;

&lt;p&gt;@@ -282,12 +281,12 @@ In an ideal world, all data would be processed immediately when it occurs, so th&lt;/p&gt;

&lt;p&gt; The following diagram shows the relationship between ongoing processing time and each score&apos;s event time for two teams:&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig5&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/gaming-example-event-time-narrow.gif&quot;&lt;/li&gt;
	&lt;li&gt;width=&quot;900&quot; height=&quot;390&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;Score data by team, windowed by event time.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-*&lt;b&gt;Figure 5:&lt;/b&gt;* Score data by team, windowed by event time. A trigger based on processing time causes the window to emit speculative early results and include late results.&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;A pipeline processes score data by team, windowed by event time.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/gaming-example-event-time-narrow.gif&quot; | prepend: site.baseurl }}){: width=&quot;800px&quot;}&lt;br/&gt;
+&lt;br/&gt;
+*Figure 5: Score data by team, windowed by event time. A trigger based on&lt;br/&gt;
+processing time causes the window to emit speculative early results and include&lt;br/&gt;
+late results.*&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; The dotted line in the diagram is the &quot;ideal&quot; *&lt;b&gt;watermark&lt;/b&gt;*: Beam&apos;s notion of when all data in a given window can reasonably be considered to have arrived. The irregular solid line represents the actual watermark, as determined by the data source.&lt;/p&gt;

&lt;p&gt;@@ -359,13 +358,12 @@ When you set session windowing, you specify a &lt;em&gt;minimum gap duration&lt;/em&gt; between eve&lt;/p&gt;

&lt;p&gt; The following diagram shows how data might look when grouped into session windows. Unlike fixed windows, session windows are &lt;em&gt;different for each user&lt;/em&gt; and is dependent on each individual user&apos;s play pattern:&lt;/p&gt;

&lt;p&gt;-&amp;lt;figure id=&quot;fig6&quot;&amp;gt;&lt;/p&gt;
&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;&amp;lt;img src=&quot;{{ site.baseurl }}/images/gaming-example-session-windows.png&quot;&lt;/li&gt;
	&lt;li&gt;width=&quot;662&quot; height=&quot;521&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;A diagram representing session windowing.&quot;&lt;/li&gt;
	&lt;li&gt;alt=&quot;User sessions, with a minimum gap duration.&quot;&amp;gt;&lt;br/&gt;
-&amp;lt;/figure&amp;gt;&lt;br/&gt;
-*&lt;b&gt;Figure 6:&lt;/b&gt;* User sessions, with a minimum gap duration. Note how each user has different sessions, according to how many instances they play and how long their breaks between instances are.&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;User sessions with a minimum gap duration.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/gaming-example-session-windows.png&quot; | prepend: site.baseurl }})&lt;br/&gt;
+&lt;br/&gt;
+*Figure 6: User sessions with a minimum gap duration. Each user has different&lt;br/&gt;
+sessions, according to how many instances they play and how long their breaks&lt;br/&gt;
+between instances are.*&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; We can use the session-windowed data to determine the average length of uninterrupted play time for all of our users, as well as the total score they achieve during each session. We can do this in the code by first applying session windows, summing the score per user and session, and then using a transform to calculate the length of each individual session:&lt;/p&gt;

&lt;p&gt;diff --git a/src/get-started/wordcount-example.md b/src/get-started/wordcount-example.md&lt;br/&gt;
index 82d64b03b..408ce5b71 100644&lt;br/&gt;
&amp;#8212; a/src/get-started/wordcount-example.md&lt;br/&gt;
+++ b/src/get-started/wordcount-example.md&lt;br/&gt;
@@ -26,21 +26,21 @@ four successively more detailed WordCount examples that build on each other. The&lt;br/&gt;
 input text for all the examples is a set of Shakespeare&apos;s texts.&lt;/p&gt;

&lt;p&gt; Each WordCount example introduces different concepts in the Beam programming&lt;br/&gt;
-model. Begin by understanding Minimal WordCount, the simplest of the examples.&lt;br/&gt;
+model. Begin by understanding MinimalWordCount, the simplest of the examples.&lt;br/&gt;
 Once you feel comfortable with the basic principles in building a pipeline,&lt;br/&gt;
 continue on to learn more concepts in the other examples.&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ul&gt;
		&lt;li&gt;*&lt;b&gt;Minimal WordCount&lt;/b&gt;* demonstrates the basic principles involved in building a&lt;br/&gt;
+* *&lt;b&gt;MinimalWordCount&lt;/b&gt;* demonstrates the basic principles involved in building a&lt;br/&gt;
   pipeline.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
	&lt;li&gt;*&lt;b&gt;WordCount&lt;/b&gt;* introduces some of the more common best practices in creating&lt;br/&gt;
   re-usable and maintainable pipelines.
	&lt;ul&gt;
		&lt;li&gt;*&lt;b&gt;Debugging WordCount&lt;/b&gt;* introduces logging and debugging practices.&lt;/li&gt;
		&lt;li&gt;*&lt;b&gt;Windowed WordCount&lt;/b&gt;* demonstrates how you can use Beam&apos;s programming model&lt;br/&gt;
+* *&lt;b&gt;DebuggingWordCount&lt;/b&gt;* introduces logging and debugging practices.&lt;br/&gt;
+* *&lt;b&gt;WindowedWordCount&lt;/b&gt;* demonstrates how you can use Beam&apos;s programming model&lt;br/&gt;
   to handle both bounded and unbounded datasets.&lt;/li&gt;
	&lt;/ul&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;MinimalWordCount example&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;-Minimal WordCount demonstrates a simple pipeline that can read from a text file,&lt;br/&gt;
+MinimalWordCount demonstrates a simple pipeline that can read from a text file,&lt;br/&gt;
 apply transforms to tokenize and count the words, and write the data to an&lt;br/&gt;
 output text file. This example hard-codes the locations for its input and output&lt;br/&gt;
 files and doesn&apos;t perform any error checking; it is intended to only show you&lt;br/&gt;
@@ -110,7 +110,7 @@ To view the full code in Python, see&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Running the Pipeline&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt; The following sections explain these concepts in detail, using the relevant code&lt;br/&gt;
-excerpts from the Minimal WordCount pipeline.&lt;br/&gt;
+excerpts from the MinimalWordCount pipeline.&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Creating the pipeline&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;@@ -160,7 +160,7 @@ Pipeline p = Pipeline.create(options);&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Applying pipeline transforms&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;-The Minimal WordCount pipeline contains several transforms to read data into the&lt;br/&gt;
+The MinimalWordCount pipeline contains several transforms to read data into the&lt;br/&gt;
 pipeline, manipulate or otherwise transform the data, and write out the results.&lt;br/&gt;
 Transforms can consist of an individual operation, or can contain multiple&lt;br/&gt;
 nested transforms (which is a &lt;span class=&quot;error&quot;&gt;&amp;#91;composite transform&amp;#93;&lt;/span&gt;({{ site.baseurl }}/documentation/programming-guide#composite-transforms)).&lt;br/&gt;
@@ -170,10 +170,12 @@ input and output data is often represented by the SDK class `PCollection`.&lt;br/&gt;
 `PCollection` is a special class, provided by the Beam SDK, that you can use to&lt;br/&gt;
 represent a data set of virtually any size, including unbounded data sets.&lt;/p&gt;

&lt;p&gt;-&amp;lt;img src=&quot;{{ &quot;/images/wordcount-pipeline.png&quot; | prepend: site.baseurl }}&quot; alt=&quot;Word Count pipeline diagram&quot;&amp;gt;&lt;br/&gt;
-Figure 1: The pipeline data flow.&lt;br/&gt;
+!&lt;span class=&quot;error&quot;&gt;&amp;#91;The MinimalWordCount pipeline data flow.&amp;#93;&lt;/span&gt;(&lt;br/&gt;
+  {{ &quot;/images/wordcount-pipeline.png&quot; | prepend: site.baseurl }}){: width=&quot;800px&quot;}&lt;/p&gt;

&lt;p&gt;-The Minimal WordCount pipeline contains five transforms:&lt;br/&gt;
+&lt;b&gt;Figure 1: The MinimalWordCount pipeline data flow.&lt;/b&gt;&lt;br/&gt;
+&lt;br/&gt;
+The MinimalWordCount pipeline contains five transforms:&lt;/p&gt;

&lt;p&gt; 1.  A text file `Read` transform is applied to the `Pipeline` object itself, and&lt;br/&gt;
     produces a `PCollection` as output. Each element in the output `PCollection`&lt;br/&gt;
@@ -298,7 +300,7 @@ your pipeline, and help make your pipeline&apos;s code reusable.&lt;/p&gt;

&lt;p&gt; This section assumes that you have a good understanding of the basic concepts in&lt;br/&gt;
 building a pipeline. If you feel that you aren&apos;t at that point yet, read the&lt;br/&gt;
-above section, &lt;span class=&quot;error&quot;&gt;&amp;#91;Minimal WordCount&amp;#93;&lt;/span&gt;(#minimalwordcount-example).&lt;br/&gt;
+above section, &lt;span class=&quot;error&quot;&gt;&amp;#91;MinimalWordCount&amp;#93;&lt;/span&gt;(#minimalwordcount-example).&lt;/p&gt;

&lt;p&gt; *&lt;b&gt;To run this example in Java:&lt;/b&gt;*&lt;/p&gt;

&lt;p&gt;@@ -402,7 +404,7 @@ When using `ParDo` transforms, you need to specify the processing operation that&lt;br/&gt;
 gets applied to each element in the input `PCollection`. This processing&lt;br/&gt;
 operation is a subclass of the SDK class `DoFn`. You can create the `DoFn`&lt;br/&gt;
 subclasses for each `ParDo` inline, as an anonymous inner class instance, as is&lt;br/&gt;
-done in the previous example (Minimal WordCount). However, it&apos;s often a good&lt;br/&gt;
+done in the previous example (MinimalWordCount). However, it&apos;s often a good&lt;br/&gt;
 idea to define the `DoFn` at the global level, which makes it easier to unit&lt;br/&gt;
 test and can make the `ParDo` code more readable.&lt;/p&gt;

&lt;p&gt;@@ -502,9 +504,9 @@ public static void main(String[] args) {&lt;br/&gt;
 &lt;/p&gt;
{% github_sample /apache/beam/blob/master/sdks/python/apache_beam/examples/snippets/snippets.py tag:examples_wordcount_wordcount_options
 %}
&lt;p&gt;```&lt;/p&gt;

&lt;ul class=&quot;alternate&quot; type=&quot;square&quot;&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;
		&lt;ol&gt;
			&lt;li&gt;Debugging WordCount example&lt;br/&gt;
+## DebuggingWordCount example&lt;/li&gt;
		&lt;/ol&gt;
		&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;-The Debugging WordCount example demonstrates some best practices for&lt;br/&gt;
+The DebuggingWordCount example demonstrates some best practices for&lt;br/&gt;
 instrumenting your pipeline code.&lt;/p&gt;

&lt;p&gt; *&lt;b&gt;To run this example in Java:&lt;/b&gt;*&lt;br/&gt;
@@ -710,7 +712,7 @@ public static void main(String[] args) {&lt;/p&gt;

&lt;ol&gt;
	&lt;li&gt;
	&lt;ol&gt;
		&lt;li&gt;WindowedWordCount example&lt;/li&gt;
	&lt;/ol&gt;
	&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;-This example, `WindowedWordCount`, counts words in text just as the previous&lt;br/&gt;
+The WindowedWordCount example counts words in text just as the previous&lt;br/&gt;
 examples did, but introduces several advanced concepts.&lt;/p&gt;

&lt;p&gt; *&lt;b&gt;New Concepts:&lt;/b&gt;*&lt;br/&gt;
@@ -866,7 +868,7 @@ bounded sets of elements. PTransforms that aggregate multiple elements process&lt;br/&gt;
 each `PCollection` as a succession of multiple, finite windows, even though the&lt;br/&gt;
 entire collection itself may be of infinite size (unbounded).&lt;/p&gt;

&lt;p&gt;-The `WindowedWordCount` example applies fixed-time windowing, wherein each&lt;br/&gt;
+The WindowedWordCount example applies fixed-time windowing, wherein each&lt;br/&gt;
 window represents a fixed time interval. The fixed window size for this example&lt;br/&gt;
 defaults to 1 minute (you can change this with a command-line option).&lt;/p&gt;





&lt;p&gt;----------------------------------------------------------------&lt;br/&gt;
This is an automated message from the Apache Git Service.&lt;br/&gt;
To respond to the message, please log on GitHub and use the&lt;br/&gt;
URL above to go to the specific comment.&lt;/p&gt;

&lt;p&gt;For queries about this service, please contact Infrastructure at:&lt;br/&gt;
users@infra.apache.org&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            7 years, 47 weeks, 6 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i3o327:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>