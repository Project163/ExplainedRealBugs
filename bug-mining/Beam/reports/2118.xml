<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 11:13:06 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-11224] Spark runner side inputs causing SIGNAL TERM</title>
                <link>https://issues.apache.org/jira/browse/BEAM-11224</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>&lt;p&gt;I wish to use side-inputs in order to pass some configuration to my pipeline, however the driver commands a shutdown after the `PCollectionView` has been created when running on my local spark-cluster (spark version 2.4.7, 1 master, 1 worker, running on localhost). This however works perfectly on the DirectRunner.&lt;/p&gt;

&lt;p&gt;I have attempted to strip the code to its bare essentials (see below). Still the issue persists when running on the spark cluster. DirectRunner still works fine.&lt;/p&gt;

&lt;p&gt;The spark-cluster does accept jobs, and I have sucessfully run a &quot;hello-world&quot; pipeline that completed without issue.&lt;/p&gt;

&lt;p&gt;What is happening here?&lt;/p&gt;

&lt;p&gt;Logs pasted below.&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
    &lt;span class=&quot;code-comment&quot;&gt;// Pipeline
&lt;/span&gt;    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; PipelineResult runPipeline(PipelineOptions options) {

        Pipeline p = Pipeline.create(options);

        PCollectionView&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; schema = p
                .apply(&lt;span class=&quot;code-quote&quot;&gt;&quot;Dummy tabular schema builder&quot;&lt;/span&gt;, Create.of(&lt;span class=&quot;code-quote&quot;&gt;&quot;This is a string&quot;&lt;/span&gt;))
                .apply(&lt;span class=&quot;code-quote&quot;&gt;&quot;Collect&quot;&lt;/span&gt;, View.asSingleton());

        p
                .apply(&lt;span class=&quot;code-quote&quot;&gt;&quot;Hello world&quot;&lt;/span&gt;, Create.of(&lt;span class=&quot;code-quote&quot;&gt;&quot;Hello world&quot;&lt;/span&gt;))
                .apply(&lt;span class=&quot;code-quote&quot;&gt;&quot;Side input test&quot;&lt;/span&gt;, ParDo.of(DummyFn.builder().setSchemaView(schema).build()).withSideInput(&lt;span class=&quot;code-quote&quot;&gt;&quot;schema&quot;&lt;/span&gt;, schema))
                .apply(ConsoleIO.create());

        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; p.run();
    }
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// Simple FN that prints the side input
&lt;/span&gt;@AutoValue
&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;DummyFn &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; DoFn&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; {
    &lt;span class=&quot;code-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; Logger LOG = LoggerFactory.getLogger(DummyFn.class);

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; Builder builder() {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; org.odp.beam.io.fn.AutoValue_DummyFn.Builder();
    }

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; PCollectionView&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; getSchemaView();

    @ProcessElement
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void processElement(@Element &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; element,
                               OutputReceiver&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; out,
                               ProcessContext context) {

        &lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt; schema = context.sideInput(getSchemaView());

        LOG.warn(schema.toString());

        out.output(element.toUpperCase());
    }

    @AutoValue.Builder
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;Builder {
        &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; Builder setSchemaView(PCollectionView&amp;lt;&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;&amp;gt; value);

        &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;abstract&lt;/span&gt; DummyFn build();
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
&lt;span class=&quot;code-comment&quot;&gt;// Simple PTransform that prints the output of the toString-method
&lt;/span&gt;&lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;ConsoleIO&amp;lt;T&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; PTransform&amp;lt;PCollection&amp;lt;T&amp;gt;, PDone&amp;gt; {

    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &amp;lt;T&amp;gt; ConsoleIO&amp;lt;T&amp;gt; create() {
        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; ConsoleIO();
    }

    @Override
    &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; PDone expand(PCollection&amp;lt;T&amp;gt; input) {

        input
                .apply(&lt;span class=&quot;code-quote&quot;&gt;&quot;Print elements&quot;&lt;/span&gt;, ParDo.of(&lt;span class=&quot;code-keyword&quot;&gt;new&lt;/span&gt; PrintElementFn&amp;lt;T&amp;gt;()));

        &lt;span class=&quot;code-keyword&quot;&gt;return&lt;/span&gt; PDone.in(input.getPipeline());
    }

    &lt;span class=&quot;code-keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;PrintElementFn&amp;lt;T&amp;gt; &lt;span class=&quot;code-keyword&quot;&gt;extends&lt;/span&gt; DoFn&amp;lt;T, &lt;span class=&quot;code-object&quot;&gt;Void&lt;/span&gt;&amp;gt; {

        @DoFn.ProcessElement
        &lt;span class=&quot;code-keyword&quot;&gt;public&lt;/span&gt; void processElement(@Element T element, ProcessContext context) &lt;span class=&quot;code-keyword&quot;&gt;throws&lt;/span&gt; Exception {

            &lt;span class=&quot;code-object&quot;&gt;System&lt;/span&gt;.out.println(element.toString());
        }
    }
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;spark-submit output&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ spark-submit \
--&lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;org.odp.beam.extractors.CsvToCdfRawExtractor \
--verbose \
--driver-memory 4G \
--executor-memory 4G \
--total-executor-cores 4 \
--deploy-mode client \
--supervise \
--conf spark.dynamicAllocation.enabled=&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt; \
--conf spark.network.timeout=420000 \
--master spark:&lt;span class=&quot;code-comment&quot;&gt;//192.168.10.172:7077 \
&lt;/span&gt;target/beam-poc-0.1-shaded.jar \
--runner=SparkRunner

Using properties file: &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
20/11/10 15:46:44 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 192.168.10.172 instead (on &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; enp7s0)
20/11/10 15:46:44 WARN Utils: Set SPARK_LOCAL_IP &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/tom/app/spark/spark-2.4.7-bin-hadoop2.7/jars/spark-unsafe_2.11-2.4.7.jar) to method java.nio.Bits.unaligned()
WARNING: Please consider reporting &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; release
Parsed arguments:
  master                  spark:&lt;span class=&quot;code-comment&quot;&gt;//192.168.10.172:7077
&lt;/span&gt;  deployMode              client
  executorMemory          4G
  executorCores           &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  totalExecutorCores      4
  propertiesFile          &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  driverMemory            4G
  driverCores             &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  driverExtraClassPath    &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  driverExtraLibraryPath  &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  driverExtraJavaOptions  &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  supervise               &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;
  queue                   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  numExecutors            &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  files                   &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  pyFiles                 &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  archives                &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  mainClass               org.odp.beam.extractors.CsvToCdfRawExtractor
  primaryResource         file:/home/tom/project/odf/beam-poc/target/beam-poc-0.1-shaded.jar
  name                    org.odp.beam.extractors.CsvToCdfRawExtractor
  childArgs               [--runner=SparkRunner]
  jars                    &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  packages                &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  packagesExclusions      &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  repositories            &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;
  verbose                 &lt;span class=&quot;code-keyword&quot;&gt;true&lt;/span&gt;

Spark properties used, including those specified through
 --conf and those from the properties file &lt;span class=&quot;code-keyword&quot;&gt;null&lt;/span&gt;:
  (spark.network.timeout,420000)
  (spark.driver.memory,4G)
  (spark.dynamicAllocation.enabled,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)

    
20/11/10 15:46:45 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
Main class:
org.odp.beam.extractors.CsvToCdfRawExtractor
Arguments:
--runner=SparkRunner
Spark config:
(spark.jars,file:/home/tom/project/odf/beam-poc/target/beam-poc-0.1-shaded.jar)
(spark.app.name,org.odp.beam.extractors.CsvToCdfRawExtractor)
(spark.cores.max,4)
(spark.network.timeout,420000)
(spark.driver.memory,4G)
(spark.submit.deployMode,client)
(spark.master,spark:&lt;span class=&quot;code-comment&quot;&gt;//192.168.10.172:7077)
&lt;/span&gt;(spark.executor.memory,4G)
(spark.dynamicAllocation.enabled,&lt;span class=&quot;code-keyword&quot;&gt;false&lt;/span&gt;)
Classpath elements:
file:/home/tom/project/odf/beam-poc/target/beam-poc-0.1-shaded.jar


log4j:WARN No appenders could be found &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; logger (org.apache.beam.sdk.options.PipelineOptionsFactory).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http:&lt;span class=&quot;code-comment&quot;&gt;//logging.apache.org/log4j/1.2/faq.html#noconfig &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; more info.
&lt;/span&gt;Using Spark&apos;s &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; log4j profile: org/apache/spark/log4j-defaults.properties
20/11/10 15:46:46 INFO SparkContext: Running Spark version 2.4.7
20/11/10 15:46:47 INFO SparkContext: Submitted application: CsvToCdfRawExtractor
20/11/10 15:46:47 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: tom
20/11/10 15:46:47 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: tom
20/11/10 15:46:47 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls groups to: 
20/11/10 15:46:47 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls groups to: 
20/11/10 15:46:47 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users  with view permissions: Set(tom); groups with view permissions: Set(); users  with modify permissions: Set(tom); groups with modify permissions: Set()
20/11/10 15:46:47 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;sparkDriver&apos;&lt;/span&gt; on port 35103.
20/11/10 15:46:47 INFO SparkEnv: Registering MapOutputTracker
20/11/10 15:46:47 INFO SparkEnv: Registering BlockManagerMaster
20/11/10 15:46:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; getting topology information
20/11/10 15:46:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
20/11/10 15:46:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-58419068-d0ad-45c9-b90b-92b659dee1c3
20/11/10 15:46:47 INFO MemoryStore: MemoryStore started with capacity 2.2 GB
20/11/10 15:46:47 INFO SparkEnv: Registering OutputCommitCoordinator
20/11/10 15:46:47 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;SparkUI&apos;&lt;/span&gt; on port 4040.
20/11/10 15:46:47 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http:&lt;span class=&quot;code-comment&quot;&gt;//fedora:4040
&lt;/span&gt;20/11/10 15:46:47 INFO SparkContext: Added JAR file:/home/tom/project/odf/beam-poc/target/beam-poc-0.1-shaded.jar at spark:&lt;span class=&quot;code-comment&quot;&gt;//fedora:35103/jars/beam-poc-0.1-shaded.jar with timestamp 1605019607514
&lt;/span&gt;20/11/10 15:46:47 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark:&lt;span class=&quot;code-comment&quot;&gt;//192.168.10.172:7077...
&lt;/span&gt;20/11/10 15:46:47 INFO TransportClientFactory: Successfully created connection to /192.168.10.172:7077 after 25 ms (0 ms spent in bootstraps)
20/11/10 15:46:47 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20201110154647-0020
20/11/10 15:46:47 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20201110154647-0020/0 on worker-20201109144752-192.168.10.172-45535 (192.168.10.172:45535) with 4 core(s)
20/11/10 15:46:47 INFO StandaloneSchedulerBackend: Granted executor ID app-20201110154647-0020/0 on hostPort 192.168.10.172:45535 with 4 core(s), 4.0 GB RAM
20/11/10 15:46:47 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.spark.network.netty.NettyBlockTransferService&apos;&lt;/span&gt; on port 33169.
20/11/10 15:46:47 INFO NettyBlockTransferService: Server created on fedora:33169
20/11/10 15:46:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block replication policy
20/11/10 15:46:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20201110154647-0020/0 is now RUNNING
20/11/10 15:46:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, fedora, 33169, None)
20/11/10 15:46:47 INFO BlockManagerMasterEndpoint: Registering block manager fedora:33169 with 2.2 GB RAM, BlockManagerId(driver, fedora, 33169, None)
20/11/10 15:46:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, fedora, 33169, None)
20/11/10 15:46:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, fedora, 33169, None)
20/11/10 15:46:47 INFO StandaloneSchedulerBackend: SchedulerBackend is ready &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; scheduling beginning after reached minRegisteredResourcesRatio: 0.0
20/11/10 15:46:48 INFO SparkRunner$Evaluator: Entering directly-translatable composite transform: &lt;span class=&quot;code-quote&quot;&gt;&apos;Collect/Combine.GloballyAsSingletonView/Combine.globally(Singleton)&apos;&lt;/span&gt;
20/11/10 15:46:48 INFO MetricsAccumulator: Instantiated metrics accumulator: MetricQueryResults()
20/11/10 15:46:48 INFO AggregatorsAccumulator: Instantiated aggregators accumulator: 
20/11/10 15:46:48 INFO SparkRunner$Evaluator: Evaluating Read(CreateSource)
20/11/10 15:46:48 INFO SparkRunner$Evaluator: Entering directly-translatable composite transform: &lt;span class=&quot;code-quote&quot;&gt;&apos;Collect/Combine.GloballyAsSingletonView/Combine.globally(Singleton)&apos;&lt;/span&gt;
20/11/10 15:46:48 INFO SparkRunner$Evaluator: Evaluating Combine.globally(Singleton)
20/11/10 15:46:48 INFO SparkContext: Starting job: aggregate at GroupCombineFunctions.java:107
20/11/10 15:46:48 INFO DAGScheduler: Got job 0 (aggregate at GroupCombineFunctions.java:107) with 1 output partitions
20/11/10 15:46:48 INFO DAGScheduler: Final stage: ResultStage 0 (aggregate at GroupCombineFunctions.java:107)
20/11/10 15:46:48 INFO DAGScheduler: Parents of &lt;span class=&quot;code-keyword&quot;&gt;final&lt;/span&gt; stage: List()
20/11/10 15:46:48 INFO DAGScheduler: Missing parents: List()
20/11/10 15:46:48 INFO DAGScheduler: Submitting ResultStage 0 (Dummy tabular schema builder/Read(CreateSource).out Bounded[0] at RDD at SourceRDD.java:80), which has no missing parents
20/11/10 15:46:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 16.2 KB, free 2.2 GB)
20/11/10 15:46:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KB, free 2.2 GB)
20/11/10 15:46:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on fedora:33169 (size: 6.8 KB, free: 2.2 GB)
20/11/10 15:46:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1184
20/11/10 15:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (Dummy tabular schema builder/Read(CreateSource).out Bounded[0] at RDD at SourceRDD.java:80) (first 15 tasks are &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; partitions Vector(0))
20/11/10 15:46:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
20/11/10 15:46:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client:&lt;span class=&quot;code-comment&quot;&gt;//Executor) (192.168.10.172:48382) with ID 0
&lt;/span&gt;20/11/10 15:46:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.10.172, executor 0, partition 0, PROCESS_LOCAL, 8546 bytes)
20/11/10 15:46:49 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.10.172:43781 with 2.2 GB RAM, BlockManagerId(0, 192.168.10.172, 43781, None)
20/11/10 15:46:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.10.172:43781 (size: 6.8 KB, free: 2.2 GB)
20/11/10 15:46:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2056 ms on 192.168.10.172 (executor 0) (1/1)
20/11/10 15:46:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
20/11/10 15:46:51 INFO DAGScheduler: ResultStage 0 (aggregate at GroupCombineFunctions.java:107) finished in 3.091 s
20/11/10 15:46:51 INFO DAGScheduler: Job 0 finished: aggregate at GroupCombineFunctions.java:107, took 3.132405 s
20/11/10 15:46:51 INFO SparkRunner$Evaluator: Evaluating org.apache.beam.sdk.transforms.View$VoidKeyToMultimapMaterialization$VoidKeyToMultimapMaterializationDoFn@14924f41
20/11/10 15:46:51 INFO SparkRunner$Evaluator: Evaluating View.CreatePCollectionView
20/11/10 15:46:51 INFO SparkContext: Invoking stop() from shutdown hook
20/11/10 15:46:51 INFO SparkUI: Stopped Spark web UI at http:&lt;span class=&quot;code-comment&quot;&gt;//fedora:4040
&lt;/span&gt;20/11/10 15:46:51 INFO StandaloneSchedulerBackend: Shutting down all executors
20/11/10 15:46:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
20/11/10 15:46:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
20/11/10 15:46:51 INFO MemoryStore: MemoryStore cleared
20/11/10 15:46:51 INFO BlockManager: BlockManager stopped
20/11/10 15:46:51 INFO BlockManagerMaster: BlockManagerMaster stopped
20/11/10 15:46:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
20/11/10 15:46:51 INFO SparkContext: Successfully stopped SparkContext
20/11/10 15:46:51 INFO ShutdownHookManager: Shutdown hook called
20/11/10 15:46:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-665a903f-22db-497e-989f-a5ca3e0635e2
20/11/10 15:46:51 INFO ShutdownHookManager: Deleting directory /tmp/spark-d4b5a04f-f6a3-48ff-b229-4eb966151d86

&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;stderr from spark worker:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Spark Executor Command: &lt;span class=&quot;code-quote&quot;&gt;&quot;/usr/lib/jvm/java-11-openjdk-11.0.9.6-0.0.ea.fc33.x86_64/bin/java&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-cp&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;/home/tom/app/spark/spark/conf/:/home/tom/app/spark/spark/jars/*&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-Xmx4096M&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-Dspark.driver.port=35103&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;-Dspark.network.timeout=420000&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;org.apache.spark.executor.CoarseGrainedExecutorBackend&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--driver-url&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;spark:&lt;span class=&quot;code-comment&quot;&gt;//CoarseGrainedScheduler@fedora:35103&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--executor-id&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;0&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--hostname&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;192.168.10.172&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--cores&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;4&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--app-id&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;app-20201110154647-0020&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;--worker-url&quot;&lt;/span&gt; &lt;span class=&quot;code-quote&quot;&gt;&quot;spark://Worker@192.168.10.172:45535&quot;&lt;/span&gt;
&lt;/span&gt;========================================

Using Spark&apos;s &lt;span class=&quot;code-keyword&quot;&gt;default&lt;/span&gt; log4j profile: org/apache/spark/log4j-defaults.properties
20/11/10 15:46:48 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 360353@localhost.localdomain
20/11/10 15:46:48 INFO SignalUtils: Registered signal handler &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; TERM
20/11/10 15:46:48 INFO SignalUtils: Registered signal handler &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; HUP
20/11/10 15:46:48 INFO SignalUtils: Registered signal handler &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; INT
20/11/10 15:46:48 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 192.168.10.172 instead (on &lt;span class=&quot;code-keyword&quot;&gt;interface&lt;/span&gt; enp7s0)
20/11/10 15:46:48 WARN Utils: Set SPARK_LOCAL_IP &lt;span class=&quot;code-keyword&quot;&gt;if&lt;/span&gt; you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/tom/app/spark/spark-2.4.7-bin-hadoop2.7/jars/spark-unsafe_2.11-2.4.7.jar) to method java.nio.Bits.unaligned()
WARNING: Please consider reporting &lt;span class=&quot;code-keyword&quot;&gt;this&lt;/span&gt; to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a &lt;span class=&quot;code-keyword&quot;&gt;future&lt;/span&gt; release
20/11/10 15:46:48 WARN NativeCodeLoader: Unable to load &lt;span class=&quot;code-keyword&quot;&gt;native&lt;/span&gt;-hadoop library &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; your platform... using builtin-java classes where applicable
20/11/10 15:46:48 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: tom
20/11/10 15:46:48 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: tom
20/11/10 15:46:48 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls groups to: 
20/11/10 15:46:48 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls groups to: 
20/11/10 15:46:48 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users  with view permissions: Set(tom); groups with view permissions: Set(); users  with modify permissions: Set(tom); groups with modify permissions: Set()
20/11/10 15:46:49 INFO TransportClientFactory: Successfully created connection to fedora/192.168.10.172:35103 after 54 ms (0 ms spent in bootstraps)
20/11/10 15:46:49 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls to: tom
20/11/10 15:46:49 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls to: tom
20/11/10 15:46:49 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing view acls groups to: 
20/11/10 15:46:49 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: Changing modify acls groups to: 
20/11/10 15:46:49 INFO &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: &lt;span class=&quot;code-object&quot;&gt;SecurityManager&lt;/span&gt;: authentication disabled; ui acls disabled; users  with view permissions: Set(tom); groups with view permissions: Set(); users  with modify permissions: Set(tom); groups with modify permissions: Set()
20/11/10 15:46:49 INFO TransportClientFactory: Successfully created connection to fedora/192.168.10.172:35103 after 4 ms (0 ms spent in bootstraps)
20/11/10 15:46:49 INFO DiskBlockManager: Created local directory at /tmp/spark-0e47fa97-8714-4e8e-950e-b1032fe36995/executor-e7667d04-198d-4144-8897-ddada0bfd1de/blockmgr-019262b3-4d3e-4158-b984-ff85c0846191
20/11/10 15:46:49 INFO MemoryStore: MemoryStore started with capacity 2.2 GB
20/11/10 15:46:49 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark:&lt;span class=&quot;code-comment&quot;&gt;//CoarseGrainedScheduler@fedora:35103
&lt;/span&gt;20/11/10 15:46:49 INFO WorkerWatcher: Connecting to worker spark:&lt;span class=&quot;code-comment&quot;&gt;//Worker@192.168.10.172:45535
&lt;/span&gt;20/11/10 15:46:49 INFO TransportClientFactory: Successfully created connection to /192.168.10.172:45535 after 2 ms (0 ms spent in bootstraps)
20/11/10 15:46:49 INFO WorkerWatcher: Successfully connected to spark:&lt;span class=&quot;code-comment&quot;&gt;//Worker@192.168.10.172:45535
&lt;/span&gt;20/11/10 15:46:49 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
20/11/10 15:46:49 INFO Executor: Starting executor ID 0 on host 192.168.10.172
20/11/10 15:46:49 INFO Utils: Successfully started service &lt;span class=&quot;code-quote&quot;&gt;&apos;org.apache.spark.network.netty.NettyBlockTransferService&apos;&lt;/span&gt; on port 43781.
20/11/10 15:46:49 INFO NettyBlockTransferService: Server created on 192.168.10.172:43781
20/11/10 15:46:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; block replication policy
20/11/10 15:46:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 192.168.10.172, 43781, None)
20/11/10 15:46:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 192.168.10.172, 43781, None)
20/11/10 15:46:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 192.168.10.172, 43781, None)
20/11/10 15:46:49 INFO CoarseGrainedExecutorBackend: Got assigned task 0
20/11/10 15:46:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
20/11/10 15:46:49 INFO Executor: Fetching spark:&lt;span class=&quot;code-comment&quot;&gt;//fedora:35103/jars/beam-poc-0.1-shaded.jar with timestamp 1605019607514
&lt;/span&gt;20/11/10 15:46:49 INFO TransportClientFactory: Successfully created connection to fedora/192.168.10.172:35103 after 2 ms (0 ms spent in bootstraps)
20/11/10 15:46:49 INFO Utils: Fetching spark:&lt;span class=&quot;code-comment&quot;&gt;//fedora:35103/jars/beam-poc-0.1-shaded.jar to /tmp/spark-0e47fa97-8714-4e8e-950e-b1032fe36995/executor-e7667d04-198d-4144-8897-ddada0bfd1de/spark-62556d02-a044-4c2c-8f97-c7f25ef3e337/fetchFileTemp6325880319900581024.tmp
&lt;/span&gt;20/11/10 15:46:49 INFO Utils: Copying /tmp/spark-0e47fa97-8714-4e8e-950e-b1032fe36995/executor-e7667d04-198d-4144-8897-ddada0bfd1de/spark-62556d02-a044-4c2c-8f97-c7f25ef3e337/2058038551605019607514_cache to /home/tom/app/spark/spark-2.4.7-bin-hadoop2.7/work/app-20201110154647-0020/0/./beam-poc-0.1-shaded.jar
20/11/10 15:46:50 INFO Executor: Adding file:/home/tom/app/spark/spark-2.4.7-bin-hadoop2.7/work/app-20201110154647-0020/0/./beam-poc-0.1-shaded.jar to &lt;span class=&quot;code-keyword&quot;&gt;class &lt;/span&gt;loader
20/11/10 15:46:50 INFO TorrentBroadcast: Started reading broadcast variable 0
20/11/10 15:46:50 INFO TransportClientFactory: Successfully created connection to fedora/192.168.10.172:33169 after 2 ms (0 ms spent in bootstraps)
20/11/10 15:46:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.8 KB, free 2.2 GB)
20/11/10 15:46:50 INFO TorrentBroadcast: Reading broadcast variable 0 took 112 ms
20/11/10 15:46:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 16.2 KB, free 2.2 GB)
20/11/10 15:46:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 6312 bytes result sent to driver
20/11/10 15:46:51 INFO CoarseGrainedExecutorBackend: Driver commanded a shutdown
20/11/10 15:46:51 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
tdown
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;</description>
                <environment>Beam: 2.25&lt;br/&gt;
SparkRunner: 2.25&lt;br/&gt;
Java version: 11.0.9-ea&lt;br/&gt;
Maven Compiler Source: 1.8&lt;br/&gt;
Maven Compiler Target: 1.8&lt;br/&gt;
Spark version: 2.4.7</environment>
        <key id="13339777">BEAM-11224</key>
            <summary>Spark runner side inputs causing SIGNAL TERM</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10103" iconUrl="https://issues.apache.org/jira/images/icons/priorities/minor.svg">P3</priority>
                        <status id="10722" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Triage Needed</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="-1">Unresolved</resolution>
                                        <assignee username="-1">Unassigned</assignee>
                                    <reporter username="thomafred90@gmail.com">Thomas Li Fredriksen</reporter>
                        <labels>
                            <label>sideinput</label>
                            <label>spark</label>
                            <label>spark-runner</label>
                    </labels>
                <created>Tue, 10 Nov 2020 15:03:25 +0000</created>
                <updated>Sat, 4 Jun 2022 18:10:49 +0000</updated>
                                            <version>2.25.0</version>
                                                    <component>runner-spark</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>4</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="600">10m</timespent>
                                <comments>
                            <comment id="17261907" author="beamjirabot" created="Sat, 9 Jan 2021 17:12:56 +0000"  >&lt;p&gt;This issue is P2 but has been unassigned without any comment for 60 days so it has been labeled &quot;stale-P2&quot;. If this issue is still affecting you, we care! Please comment and remove the label. Otherwise, in 14 days the issue will be moved to P3.&lt;/p&gt;

&lt;p&gt;Please see &lt;a href=&quot;https://beam.apache.org/contribute/jira-priorities/&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://beam.apache.org/contribute/jira-priorities/&lt;/a&gt; for a detailed explanation of what these priorities mean.&lt;/p&gt;</comment>
                            <comment id="17270712" author="beamjirabot" created="Sat, 23 Jan 2021 17:13:07 +0000"  >&lt;p&gt;This issue was marked &quot;stale-P2&quot; and has not received a public comment in 14 days. It is now automatically moved to P3. If you are still affected by it, you can comment and move it back to P2.&lt;/p&gt;</comment>
                            <comment id="17548945" author="JIRAUSER282469" created="Sat, 4 Jun 2022 18:10:49 +0000"  >&lt;p&gt;This issue has been migrated to &lt;a href=&quot;https://github.com/apache/beam/issues/20555&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/issues/20555&lt;/a&gt;&lt;/p&gt;</comment>
                    </comments>
                    <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            3 years, 23 weeks, 2 days ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z0kg1c:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>