<!-- 
RSS generated by JIRA (8.20.10#820010-sha1:ace47f9899e9ee25d7157d59aa17ab06aee30d3d) at Tue Nov 11 11:02:39 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>ASF JIRA</title>
    <link>https://issues.apache.org/jira</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-uk</language>    <build-info>
        <version>8.20.10</version>
        <build-number>820010</build-number>
        <build-date>22-06-2022</build-date>
    </build-info>


<item>
            <title>[BEAM-8303] Filesystems not properly registered using FileIO.write() on FlinkRunner</title>
                <link>https://issues.apache.org/jira/browse/BEAM-8303</link>
                <project id="12319527" key="BEAM">Beam</project>
                    <description>&lt;p&gt;I&#8217;m getting the following error when attempting to use the FileIO apis (beam-2.15.0) and integrating with AWS S3. &#160;I have setup the PipelineOptions with all the relevant AWS options, so the filesystem registry *&lt;b&gt;should&lt;/b&gt;* be properly seeded by the time the graph is compiled and executed:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 java.lang.IllegalArgumentException: No filesystem found &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; scheme s3
&#160;&#160;&#160; at org.apache.beam.sdk.io.FileSystems.getFileSystemInternal(FileSystems.java:456)
&#160;&#160;&#160; at org.apache.beam.sdk.io.FileSystems.matchNewResource(FileSystems.java:526)
&#160;&#160;&#160; at org.apache.beam.sdk.io.FileBasedSink$FileResultCoder.decode(FileBasedSink.java:1149)
&#160;&#160;&#160; at org.apache.beam.sdk.io.FileBasedSink$FileResultCoder.decode(FileBasedSink.java:1105)
&#160;&#160;&#160; at org.apache.beam.sdk.coders.Coder.decode(Coder.java:159)
&#160;&#160;&#160; at org.apache.beam.sdk.transforms.join.UnionCoder.decode(UnionCoder.java:83)
&#160;&#160;&#160; at org.apache.beam.sdk.transforms.join.UnionCoder.decode(UnionCoder.java:32)
&#160;&#160;&#160; at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:543)
&#160;&#160;&#160; at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:534)
&#160;&#160;&#160; at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:480)
&#160;&#160;&#160; at org.apache.beam.runners.flink.translation.types.CoderTypeSerializer.deserialize(CoderTypeSerializer.java:93)
&#160;&#160;&#160; at org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate.read(NonReusingDeserializationDelegate.java:55)
&#160;&#160;&#160; at org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer.getNextRecord(SpillingAdaptiveSpanningRecordDeserializer.java:106)
&#160;&#160;&#160; at org.apache.flink.runtime.io.network.api.reader.AbstractRecordReader.getNextRecord(AbstractRecordReader.java:72)
&#160;&#160;&#160; at org.apache.flink.runtime.io.network.api.reader.MutableRecordReader.next(MutableRecordReader.java:47)
&#160;&#160;&#160; at org.apache.flink.runtime.operators.util.ReaderIterator.next(ReaderIterator.java:73)
&#160;&#160;&#160; at org.apache.flink.runtime.operators.FlatMapDriver.run(FlatMapDriver.java:107)
&#160;&#160;&#160; at org.apache.flink.runtime.operators.BatchTask.run(BatchTask.java:503)
&#160;&#160;&#160; at org.apache.flink.runtime.operators.BatchTask.invoke(BatchTask.java:368)
&#160;&#160;&#160; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
&#160;&#160;&#160; at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)
&#160;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;For reference, the write code resembles this:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 FileIO.Write&amp;lt;?, GenericRecord&amp;gt; write = FileIO.&amp;lt;GenericRecord&amp;gt;write()
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; .via(ParquetIO.sink(schema))
&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; .to(options.getOutputDir()). &lt;span class=&quot;code-comment&quot;&gt;// will be something like: s3://&amp;lt;bucket&amp;gt;/&amp;lt;path&amp;gt;
&lt;/span&gt;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; .withSuffix(&lt;span class=&quot;code-quote&quot;&gt;&quot;.parquet&quot;&lt;/span&gt;);

records.apply(&lt;span class=&quot;code-object&quot;&gt;String&lt;/span&gt;.format(&lt;span class=&quot;code-quote&quot;&gt;&quot;Write(%s)&quot;&lt;/span&gt;, options.getOutputDir()), write);&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The issue does not appear to be related to ParquetIO.sink().&#160; I am able to reliably reproduce the issue using JSON formatted records and TextIO.sink(), as well.&#160; Moreover, AvroIO is affected if withWindowedWrites() option is added.&lt;/p&gt;

&lt;p&gt;Just trying some different knobs, I went ahead and set the following option:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
write = write.withNoSpilling();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This actually seemed to fix the issue, only to have it reemerge as I scaled up the data set size.&#160; The stack trace, while very similar, reads:&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 java.lang.IllegalArgumentException: No filesystem found &lt;span class=&quot;code-keyword&quot;&gt;for&lt;/span&gt; scheme s3
&#160;&#160;&#160; at org.apache.beam.sdk.io.FileSystems.getFileSystemInternal(FileSystems.java:456)
&#160;&#160;&#160; at org.apache.beam.sdk.io.FileSystems.matchNewResource(FileSystems.java:526)
&#160;&#160;&#160; at org.apache.beam.sdk.io.FileBasedSink$FileResultCoder.decode(FileBasedSink.java:1149)
&#160;&#160;&#160; at org.apache.beam.sdk.io.FileBasedSink$FileResultCoder.decode(FileBasedSink.java:1105)
&#160;&#160;&#160; at org.apache.beam.sdk.coders.Coder.decode(Coder.java:159)
&#160;&#160;&#160; at org.apache.beam.sdk.coders.KvCoder.decode(KvCoder.java:82)
&#160;&#160;&#160; at org.apache.beam.sdk.coders.KvCoder.decode(KvCoder.java:36)
&#160;&#160;&#160; at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:543)
&#160;&#160;&#160; at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:534)
&#160;&#160;&#160; at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:480)
&#160;&#160;&#160; at org.apache.beam.runners.flink.translation.types.CoderTypeSerializer.deserialize(CoderTypeSerializer.java:93)
&#160;&#160;&#160; at org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate.read(NonReusingDeserializationDelegate.java:55)
&#160;&#160; &#160;at org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer.getNextRecord(SpillingAdaptiveSpanningRecordDeserializer.java:106)
&#160;&#160;&#160; at org.apache.flink.runtime.io.network.api.reader.AbstractRecordReader.getNextRecord(AbstractRecordReader.java:72)
&#160;&#160;&#160; at org.apache.flink.runtime.io.network.api.reader.MutableRecordReader.next(MutableRecordReader.java:47)
&#160;&#160;&#160; at org.apache.flink.runtime.operators.util.ReaderIterator.next(ReaderIterator.java:73)
&#160;&#160;&#160; at org.apache.flink.runtime.operators.NoOpDriver.run(NoOpDriver.java:94)
&#160;&#160;&#160; at org.apache.flink.runtime.operators.BatchTask.run(BatchTask.java:503)
&#160;&#160;&#160; at org.apache.flink.runtime.operators.BatchTask.invoke(BatchTask.java:368)
&#160;&#160;&#160; at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
&#160;&#160;&#160; at java.lang.&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.run(&lt;span class=&quot;code-object&quot;&gt;Thread&lt;/span&gt;.java:748)&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;And lastly, I tried adding the following deprecated option (with and without the withNoSpilling() option):&lt;/p&gt;
&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 write = write.withIgnoreWindowing();&#160;&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This seemed to fix the issue altogether but aside from having to rely on a deprecated feature, there is the bigger issue of why?&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;In reading through some of the source, it seems a common pattern to have to manually register the pipeline options to seed the filesystem registry during the setup part of the operator lifecycle, e.g.:&#160;&lt;a href=&quot;https://nam01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fapache%2Fbeam%2Fblob%2Frelease-2.15.0%2Frunners%2Fflink%2Fsrc%2Fmain%2Fjava%2Forg%2Fapache%2Fbeam%2Frunners%2Fflink%2Ftranslation%2Fwrappers%2Fstreaming%2FDoFnOperator.java%23L304-L313&amp;amp;data=02%7C01%7CPreston.B.Koprivica%40cerner.com%7C024bc6b438914e7351c008d74037641d%7Cfbc493a80d244454a815f4ca58e8c09d%7C0%7C0%7C637048478964357677&amp;amp;sdata=iGNAsktzEA9T2hlKQ4e3oscwL8xLQFuCZ6hsGHQb1So%3D&amp;amp;reserved=0&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/release-2.15.0/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java#L304-L313&lt;/a&gt;&#160;&#160;&#160;&lt;/p&gt;

&lt;p&gt;&#160;&lt;/p&gt;

&lt;p&gt;Is it possible that I have hit upon a couple scenarios where that has not taken place?&lt;/p&gt;</description>
                <environment></environment>
        <key id="13258384">BEAM-8303</key>
            <summary>Filesystems not properly registered using FileIO.write() on FlinkRunner</summary>
                <type id="1" iconUrl="https://issues.apache.org/jira/secure/viewavatar?size=xsmall&amp;avatarId=21133&amp;avatarType=issuetype">Bug</type>
                                            <priority id="10101" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.svg">P1</priority>
                        <status id="10722" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Triage Needed</status>
                    <statusCategory id="2" key="new" colorName="blue-gray"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="mxm">Maximilian Michels</assignee>
                                    <reporter username="preston">Preston Koprivica</reporter>
                        <labels>
                            <label>Done</label>
                    </labels>
                <created>Mon, 23 Sep 2019 19:10:36 +0000</created>
                <updated>Thu, 13 Apr 2023 10:57:13 +0000</updated>
                            <resolved>Mon, 7 Oct 2019 08:51:30 +0000</resolved>
                                    <version>2.15.0</version>
                                    <fixVersion>2.17.0</fixVersion>
                                    <component>runner-flink</component>
                    <component>sdk-java-core</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>7</watches>
                                                    <progress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </progress>
                                    <aggregateprogress percentage="100">
                                    <originalProgress>
                                                    <row percentage="0" backgroundColor="#89afd7"/>
                                                    <row percentage="100" backgroundColor="transparent"/>
                                            </originalProgress>
                                                    <currentProgress>
                                                    <row percentage="100" backgroundColor="#51a825"/>
                                                    <row percentage="0" backgroundColor="#ec8e00"/>
                                            </currentProgress>
                            </aggregateprogress>
                                            <timeestimate seconds="0">0h</timeestimate>
                            <timespent seconds="10200">2h 50m</timespent>
                                <comments>
                            <comment id="16936130" author="preston" created="Mon, 23 Sep 2019 19:13:19 +0000"  >&lt;p&gt;I&apos;ll defer to the experts on the priority of this issue.&#160; Currently, I am able to workaround it by setting FileIO.write().withIgnoreWindowing(), which is also the default for AvroIO (&lt;a href=&quot;https://github.com/apache/beam/blob/release-2.15.0/sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroIO.java#L516&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/release-2.15.0/sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroIO.java#L516&lt;/a&gt;), and I suspect other FileBasedSink apis as well.&lt;/p&gt;</comment>
                            <comment id="16937955" author="aiyangar" created="Wed, 25 Sep 2019 18:05:04 +0000"  >&lt;p&gt;Can you check what is the security provider that is being used by your pipeline ? We faced the issue and found that it was using SUN provider.&lt;/p&gt;

&lt;p&gt;Changing it to conscript or bouncy castle will help you resolve the issue.&lt;/p&gt;</comment>
                            <comment id="16937963" author="kenn" created="Wed, 25 Sep 2019 18:18:00 +0000"  >&lt;p&gt;Copying reply from mailing list here, so it is more discoverable:&lt;/p&gt;

&lt;p&gt;Are you building a fat jar? I don&apos;t know if this is your issue. I don&apos;t know Flink&apos;s operation in any close detail, and I&apos;m not sure how it relates to what Max has described. But it is a common cause of this kind of error.&lt;/p&gt;

&lt;p&gt;The registration of the filesystem is here: &lt;a href=&quot;https://github.com/apache/beam/blob/master/sdks/java/io/amazon-web-services/src/main/java/org/apache/beam/sdk/io/aws/s3/S3FileSystemRegistrar.java#L32&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/master/sdks/java/io/amazon-web-services/src/main/java/org/apache/beam/sdk/io/aws/s3/S3FileSystemRegistrar.java#L32&lt;/a&gt;. This results in the built jar for beam-sdks-java-io-amazon-web-services to have a file META-INF/services/org.apache.beam.sdk.io.FileSystemRegistrar with the line org.apache.beam.sdk.io.aws.s3.S3FileSystemRegistrar&lt;/p&gt;

&lt;p&gt;The file META-INF/services/org.apache.beam.sdk.io.FileSystemRegistrar exists in many dependencies, including the core SDK. The default for many fat jar tools (maven shade and gradle shadow) is that they nondeterministically clobber each other, and you have to add a line like &quot;mergeServiceFiles&quot; to your configuration to keep all the registrations.&lt;/p&gt;</comment>
                            <comment id="16937975" author="preston" created="Wed, 25 Sep 2019 18:28:58 +0000"  >&lt;p&gt;Yes, we are building a fat jar using the maven-shade-plugin.&#160; Here are the contents of that services file:&#160;&lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
$ tar -xvf  target/&amp;lt;jar&amp;gt;.jar META-INF/services/org.apache.beam.sdk.io.FileSystemRegistrar
x META-INF/services/org.apache.beam.sdk.io.FileSystemRegistrarmlecosystem
$ cat META-INF/services/org.apache.beam.sdk.io.FileSystemRegistrar
org.apache.beam.sdk.io.LocalFileSystemRegistrar
org.apache.beam.sdk.io.aws.s3.S3FileSystemRegistrar 
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I&apos;m sure you guys have seen this error quite a bit, so bear with me.  The issue here does not seem to be classpath nor improperly initialized options.  Just to reiterate, if I specify write#withIgnoreWindowing(), everything works fine.&lt;/p&gt;</comment>
                            <comment id="16938049" author="mxm" created="Wed, 25 Sep 2019 20:31:25 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=kenn&quot; class=&quot;user-hover&quot; rel=&quot;kenn&quot;&gt;kenn&lt;/a&gt; Thanks for the help, but the service files are not an issue here. I wrote the same reply as you, but then deleted it again before sending &lt;img class=&quot;emoticon&quot; src=&quot;https://issues.apache.org/jira/images/icons/emoticons/wink.png&quot; height=&quot;16&quot; width=&quot;16&quot; align=&quot;absmiddle&quot; alt=&quot;&quot; border=&quot;0&quot;/&gt; Given Preston&apos;s full description and a bit of Flink context, it is pretty much impossible to have anything to do with service files. Please see my explanation on the mailing list. The issue comes from a coder the FileIO uses which depends on the S3 file system. If we use a native Flink transformation, e.g. Union, on a TaskManager we never get to load the FileSystems code in the current classloader. However, the coder depends on the file systems, so it will error.&lt;/p&gt;

&lt;p&gt;Maybe the question is, why does the coder need access to the file system in the first place? That is probably the the more important fix to consider: &lt;a href=&quot;https://github.com/apache/beam/blob/04dc3c3b14ab780e9736d5f769c6bf2a27a390bb/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileBasedSink.java#L1152&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/04dc3c3b14ab780e9736d5f769c6bf2a27a390bb/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileBasedSink.java#L1152&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16938079" author="preston" created="Wed, 25 Sep 2019 21:25:47 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mxm&quot; class=&quot;user-hover&quot; rel=&quot;mxm&quot;&gt;mxm&lt;/a&gt; I was able to reproduce this issue in a couple different contexts, and each of them somehow involved temporary directories.  I tried to decouple the target directory and the temporary directory filesystems using #withTempDirectory(...), but something is enforcing them to be the same filesystem.  I&apos;m trying to hunt down the source now, will reply with any findings. &lt;/p&gt;</comment>
                            <comment id="16938088" author="preston" created="Wed, 25 Sep 2019 21:44:08 +0000"  >&lt;p&gt;In hindsight this test seems irrelevant, but I&apos;ll post for posterity.  Here&apos;s the error after having specified #withTempDirectory(... a local filesystem ... ): &lt;/p&gt;

&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
Caused by: java.lang.IllegalArgumentException: Expect srcResourceIds and destResourceIds have the same scheme, but received file, s3.
	at org.apache.beam.vendor.guava.v20_0.com.google.common.base.Preconditions.checkArgument(Preconditions.java:122)
	at org.apache.beam.sdk.io.FileSystems.validateSrcDestLists(FileSystems.java:421)
	at org.apache.beam.sdk.io.FileSystems.rename(FileSystems.java:307)
	at org.apache.beam.sdk.io.FileBasedSink$WriteOperation.moveToOutputFiles(FileBasedSink.java:755)
	at org.apache.beam.sdk.io.WriteFiles$FinalizeTempFileBundles$FinalizeFn.process(WriteFiles.java:850)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Looks like one of the final steps in the processing graph is to rename files from the temp dir to the final output dir.  And, of course, it makes sense that those should be on the same filesystem.  I&apos;m not sure if this informs anything regarding why &quot;coders&quot; need access to the filesystem, other than they seem to share the same temporary filesystem with the broader processing graph.&lt;/p&gt;</comment>
                            <comment id="16939002" author="preston" created="Thu, 26 Sep 2019 22:26:28 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mxm&quot; class=&quot;user-hover&quot; rel=&quot;mxm&quot;&gt;mxm&lt;/a&gt; Sorry for the delay.  I was struggling with my local build and I had to track down some issues.  Totally unrelated, but if you have some time, I think I may have found an issue related to some recent build changes &lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt;.  In any case, I was able to finally get the local build working and pulled into my test project.  &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Just to proof this theory, do you mind building Beam and testing your pipeline with the following line added before line 75?&lt;br/&gt;
&lt;a href=&quot;https://github.com/apache/beam/blob/04dc3c3b14ab780e9736d5f769c6bf2a27a390bb/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/types/CoderTypeInformation.java#L75&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/04dc3c3b14ab780e9736d5f769c6bf2a27a390bb/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/types/CoderTypeInformation.java#L75&lt;/a&gt;&lt;br/&gt;
    FileSystems.setDefaultPipelineOptions(PipelineOptionsFactory.create());&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;This change did not impact the behavior at all.  And I guess the question is, would we have expected it to using the default PipelineOptions (which I&apos;m assuming wouldn&apos;t include the S3 options).&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;error&quot;&gt;&amp;#91;1&amp;#93;&lt;/span&gt; &lt;a href=&quot;https://issues.apache.org/jira/browse/BEAM-8021&quot; class=&quot;external-link&quot; rel=&quot;nofollow&quot;&gt;https://issues.apache.org/jira/browse/BEAM-8021&lt;/a&gt;&lt;/p&gt;</comment>
                            <comment id="16939207" author="mxm" created="Fri, 27 Sep 2019 08:31:45 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=preston&quot; class=&quot;user-hover&quot; rel=&quot;preston&quot;&gt;preston&lt;/a&gt; The suggested experiment on the mailing list was not meant as a proper fix. It was to proof the theory, that &lt;tt&gt;FileSystems&lt;/tt&gt; is not initialized when the File coders, which rely on FileSystems being initialized, are first used. I was assuming you didn&apos;t have any configuration regarding S3 in the pipeline options, hence the passing of the default pipeline options. If you do, you may have to copy the options in there, for testing.&lt;/p&gt;</comment>
                            <comment id="16939447" author="pk020157" created="Fri, 27 Sep 2019 13:24:55 +0000"  >&lt;div class=&quot;code panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;codeContent panelContent&quot;&gt;
&lt;pre class=&quot;code-java&quot;&gt;
 It was to proof the theory, that FileSystems is not initialized when the File coders, which rely on FileSystems being initialized, are first used.
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;I may need a little more detail on the experiment and what observations should be made - and then how to interpret them.  (Sorry...I&apos;m still trying to catch up)&lt;/p&gt;</comment>
                            <comment id="16939511" author="mxm" created="Fri, 27 Sep 2019 14:46:43 +0000"  >&lt;p&gt;The code change I suggested does not work because it is executed during job compilation, not during cluster runtime. Could you instead try to insert the following static block here? &lt;a href=&quot;https://github.com/apache/beam/blob/04dc3c3b14ab780e9736d5f769c6bf2a27a390bb/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/types/CoderTypeInformation.java#L34&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/blob/04dc3c3b14ab780e9736d5f769c6bf2a27a390bb/runners/flink/src/main/java/org/apache/beam/runners/flink/translation/types/CoderTypeInformation.java#L34&lt;/a&gt; &lt;br/&gt;
 Again, this is just to verify that the problem goes away when this code is present:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;static {
    FileSystems.setDefaultPipelineOptions(PipelineOptionsFactory.create());
}
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Also, could you share your execution environment? Do you execute this from your IDE or on a cluster? If on a cluster, how many taskmanager/taskslots to do use?&lt;/p&gt;</comment>
                            <comment id="16939669" author="pk020157" created="Fri, 27 Sep 2019 18:36:27 +0000"  >&lt;p&gt;Yup.  I can give it a shot.  I&apos;m currently running these tests where the issue was originally discovered: on an AWS EMR cluster with 5 nodes and 5 task managers ( 1 slot per taskmanager ).&lt;/p&gt;</comment>
                            <comment id="16940742" author="mxm" created="Mon, 30 Sep 2019 08:25:45 +0000"  >&lt;p&gt;I managed to reproduce the problem on a single node (1 TM , 1 JM) Flink cluster with a custom File system:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);
options.setRunner(FlinkRunner.class);

Pipeline pipeline = Pipeline.create(options);

PCollection&amp;lt;String&amp;gt; input = pipeline.apply(Create.of(&quot;hello&quot;, &quot;world&quot;));

FileIO.Write&amp;lt;?, String&amp;gt; write = FileIO.&amp;lt;String&amp;gt;write()
    .via(TextIO.sink())
    .to(&quot;max://this/does/not/exist&quot;)
    .withSuffix(&quot;.txt&quot;);
input.apply(write);

pipeline.run();&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This gives me:&lt;/p&gt;
&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;Caused by: java.lang.IllegalArgumentException: No filesystem found for scheme max
	at org.apache.beam.sdk.io.FileSystems.getFileSystemInternal(FileSystems.java:463)
	at org.apache.beam.sdk.io.FileSystems.matchNewResource(FileSystems.java:533)
	at org.apache.beam.sdk.io.FileBasedSink$FileResultCoder.decode(FileBasedSink.java:1149)
	at org.apache.beam.sdk.io.FileBasedSink$FileResultCoder.decode(FileBasedSink.java:1105)
	at org.apache.beam.sdk.coders.Coder.decode(Coder.java:159)
	at org.apache.beam.sdk.transforms.join.UnionCoder.decode(UnionCoder.java:83)
	at org.apache.beam.sdk.transforms.join.UnionCoder.decode(UnionCoder.java:32)
	at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:592)
	at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:583)
	at org.apache.beam.sdk.util.WindowedValue$FullWindowedValueCoder.decode(WindowedValue.java:529)
	at org.apache.beam.runners.flink.translation.types.CoderTypeSerializer.deserialize(CoderTypeSerializer.java:93)
	at org.apache.flink.runtime.plugable.NonReusingDeserializationDelegate.read(NonReusingDeserializationDelegate.java:55)
	at org.apache.flink.runtime.io.network.api.serialization.SpillingAdaptiveSpanningRecordDeserializer.getNextRecord(SpillingAdaptiveSpanningRecordDeserializer.java:106)
	at org.apache.flink.runtime.io.network.api.reader.AbstractRecordReader.getNextRecord(AbstractRecordReader.java:72)
	at org.apache.flink.runtime.io.network.api.reader.MutableRecordReader.next(MutableRecordReader.java:47)
	at org.apache.flink.runtime.operators.util.ReaderIterator.next(ReaderIterator.java:73)
	at org.apache.flink.runtime.operators.FlatMapDriver.run(FlatMapDriver.java:107)
	at org.apache.flink.runtime.operators.BatchTask.run(BatchTask.java:503)
	at org.apache.flink.runtime.operators.BatchTask.invoke(BatchTask.java:368)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:711)
	at java.lang.Thread.run(Thread.java:745)
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that this one does not fail:&lt;/p&gt;

&lt;div class=&quot;preformatted panel&quot; style=&quot;border-width: 1px;&quot;&gt;&lt;div class=&quot;preformattedContent panelContent&quot;&gt;
&lt;pre&gt;    input.apply(TextIO.write().to(&quot;max://this/does/not/exist&quot;).withSuffix(&quot;.txt&quot;));
&lt;/pre&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The cause of this is what I suspected before. The coder (&lt;tt&gt;FileResultCoder&lt;/tt&gt;) accesses the custom file system before the operator, which receives the data from the coder, initializes it. Now, we had previously assumed that coders would not access file systems. Coders should be operating on a lower level than the user code.&lt;/p&gt;

&lt;p&gt;In Flink, all operators are pipelined, i.e. a parallel instance of each operator runs in the same task slot. They do not share the same class loader, but each operator, unless chained (aka fused), has its own classloader. If we want to access the FileSystems code, we need to initialize it for each of those operators.&lt;/p&gt;

&lt;p&gt;The &quot;easy&quot; solution would be to not let the coder use the file system and defer file resolution until later, but I suppose it is a fair assumption that the file system code is always initialized when Beam code runs.&lt;/p&gt;

&lt;p&gt;Alternatively, from the Flink Runner side, we can make sure to always initialize the FileSystems even if we do not run user code in the operator.&lt;/p&gt;

</comment>
                            <comment id="16940770" author="mxm" created="Mon, 30 Sep 2019 09:13:38 +0000"  >&lt;p&gt;PR: &lt;a href=&quot;https://github.com/apache/beam/pull/9688&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://github.com/apache/beam/pull/9688&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If still possible, this should be backported to release-2.16.0.&lt;/p&gt;</comment>
                            <comment id="16940771" author="mxm" created="Mon, 30 Sep 2019 09:17:26 +0000"  >&lt;p&gt;I&apos;ve verified this fixes the issue. In the pipeline the problem was the lack of initialization in &lt;tt&gt;FlinkMultiOutputPruningFunction&lt;/tt&gt;, but I&apos;ve went ahead and fixed initialization in all operators.&lt;/p&gt;</comment>
                            <comment id="16941177" author="markflyhigh" created="Mon, 30 Sep 2019 17:44:27 +0000"  >&lt;p&gt;Do you have ETA for the fix? I&apos;m ready to cut a RC. &lt;/p&gt;</comment>
                            <comment id="16941273" author="preston" created="Mon, 30 Sep 2019 19:24:35 +0000"  >&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mxm&quot; class=&quot;user-hover&quot; rel=&quot;mxm&quot;&gt;mxm&lt;/a&gt; &lt;a href=&quot;https://issues.apache.org/jira/secure/ViewProfile.jspa?name=markflyhigh&quot; class=&quot;user-hover&quot; rel=&quot;markflyhigh&quot;&gt;markflyhigh&lt;/a&gt; I was able to test the fix by pulling Max&apos;s branch.  I can verify that with the fix I&apos;m no longer seeing the original error.  Thanks so much for diagnosing and thanks for the quick turnaround.&lt;/p&gt;</comment>
                            <comment id="16941407" author="markflyhigh" created="Mon, 30 Sep 2019 23:47:46 +0000"  >&lt;p&gt;Looks like this issue happened in 2.15.0, thus it&apos;s not a regression for 2.16.0. According to the policy in &lt;a href=&quot;https://beam.apache.org/contribute/release-guide/#4-triage-release-blocking-issues-in-jira&quot; class=&quot;external-link&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;https://beam.apache.org/contribute/release-guide/#4-triage-release-blocking-issues-in-jira&lt;/a&gt;, it&apos;s not necessary a blocker for 2.16.0. I&apos;ll move this issue to 2.17.0 but if it&apos;s possible, we can still back port it to 2.16.0.&lt;/p&gt;</comment>
                            <comment id="16942693" author="mxm" created="Wed, 2 Oct 2019 10:47:19 +0000"  >&lt;p&gt;AFAIK this issue is present since the introduction of the &lt;tt&gt;FileResultCoder&lt;/tt&gt;. It was introduced quite a while ago. I&apos;ll merge this to the release branch and we can see what we do with it from there.&lt;/p&gt;</comment>
                            <comment id="16943039" author="mxm" created="Wed, 2 Oct 2019 17:51:08 +0000"  >&lt;p&gt;Backported to &lt;tt&gt;release-2.16.0&lt;/tt&gt;. Closing this when it is clear whether it can be included in the next RC.&lt;/p&gt;</comment>
                            <comment id="16944708" author="kenn" created="Fri, 4 Oct 2019 17:41:56 +0000"  >&lt;p&gt;Is the pain mild, given the presence of a workaround?&lt;/p&gt;</comment>
                            <comment id="16945689" author="mxm" created="Mon, 7 Oct 2019 08:51:30 +0000"  >&lt;p&gt;Yes, the workaround seems appropriate for now. The next release will contain the fix.&lt;/p&gt;</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="12310051">
                    <name>Supercedes</name>
                                                                <inwardlinks description="is superceded by">
                                        <issuelink>
            <issuekey id="13266839">BEAM-8577</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
                        <customfieldname>Attachment count</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0.0</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        <customfield id="customfield_12314020" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_12313422" key="com.atlassian.jirafisheyeplugin:jobcheckbox">
                        <customfieldname>Enable Automatic Patch Review</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue><![CDATA[no_permission]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Global Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                        <customfield id="customfield_12312521" key="com.atlassian.jira.toolkit:LastCommentDate">
                        <customfieldname>Last public comment date</customfieldname>
                        <customfieldvalues>
                            6 years, 6 weeks, 1 day ago
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                <customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|z06xn4:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </customfields>
    </item>
</channel>
</rss>